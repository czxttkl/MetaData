<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date></start_date>
		<end_date></end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>74333</proc_id>
	<acronym>SIGGRAPH '89</acronym>
	<proc_desc>Proceedings of the 16th annual conference</proc_desc>
	<conference_number>16</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-312-4</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1989</copyright_year>
	<publication_date>07-01-1989</publication_date>
	<pages>408</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3.5</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
		<other_category>
			<cat_node>I.3.0</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
		<other_category>
			<cat_node>I.3.3</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
		<other_category>
			<cat_node>I.3.7</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010371.10010352</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010372</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010382</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
			<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10003752.10010061</concept_id>
			<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10003752.10010061.10010063</concept_id>
			<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010396</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Algorithms</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP40041417</person_id>
			<author_profile_id><![CDATA[81100411412]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[James]]></first_name>
			<middle_name><![CDATA[J.]]></middle_name>
			<last_name><![CDATA[Thomas]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Battelle Pacific Northwest Labs, Richland, WA]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1989</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>74335</article_id>
		<sort_key>21</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Simulation of object and human skin formations in a grasping task]]></title>
		<page_from>21</page_from>
		<page_to>30</page_to>
		<doi_number>10.1145/74333.74335</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74335</url>
		<abstract>
			<par><![CDATA[This paper addresses the problem of simulating deformations between objects and the hand of a synthetic character during a grasping process. A numerical method based on finite element theory allows us to take into account the active forces of the fingers on the object and the reactive forces of the object on the fingers. The method improves control of synthetic human behavior in a task level animation system because it provides information about the environment of a synthetic human and so can be compared to the sense of touch. Finite element theory currently used in engineering seems one of the best approaches for modeling both elastic and plastic deformation of objects, as well as shocks with or without penetration between deformable objects. We show that intrinsic properties of the method based on composition/decomposition of elements have an impact in computer animation. We also state that the use of the same method for modeling both objects and human bodies improves the modeling both objects and human bodies improves the modeling of the contacts between them. Moreover, it allows a realistic envelope deformation of the human fingers comparable to existing methods. To show what we can expect from the method, we apply it to the grasping and pressing of a ball. Our solution to the grasping problem is based on displacement commands instead of force commands used in robotics and human behavior.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.8</cat_node>
				<descriptor>Finite element methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003718</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations in finite fields</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P130117</person_id>
				<author_profile_id><![CDATA[81100283414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.-P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gourret]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIRALab, University of Montreal]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35046641</person_id>
				<author_profile_id><![CDATA[81332531807]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Swiss Federal Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40037154</person_id>
				<author_profile_id><![CDATA[81100534488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thalmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong WW and Green MW. The dynamics of articulated rigid bodies for purpose of animation. The Visual Computer, Vol 1, 1985, pp 231-240]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Badler NI and Morris MA. Modeling flexible articulated objects. Proc. Comp. Graphics '82, Online conf., 1982, pp 305-314.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356760</ref_obj_id>
				<ref_obj_pid>356757</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Badler NI and Smoliar SW. Digital representation of human movement. Computing Surveys, Vol 11, No 1, I979, pp 19-38]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Badler NI. Design of a human movement representation incorporating dynamics. Tech. rep., Dept. of computer and infor.science, Univ. of Pennsylvania, Philadelphia 1984]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Barr AH. Global and local deformations of solid primitives. Proc. SIGGRAPH '84, pp 21-30]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bathe KJ'. Finite element procedures in engineering analysis. Prentice Hall, 1982]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Blinn JF. A generalization of algebraic surface drawing. ACM Trans. on graphics, Vol 1 No 3, 1982, pp 235- 256]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bohm J. A comparison of different contact algorithms with applications. Comp.Struc., Vol 26 N 1-2, 1987, pp 207-221]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Calvert TW, Chapman J, and Patla A. Aspects of the kinematic simulation of human movement. IEEE Computer Graphics and applications, nov 1982, pp 41-52]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569952</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Catmull E. A System for Computer-generated Movies. Proc. ACM Annual Conference, Vol. 1, 1972, pp.422- 431.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Chaudary AB and Bathe KJ. A solution method for static and dynamic analysis of three dimensional contact problems with friction. Comp.Struc. Vol 24 N 6, 1986, pp 855-873]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>536866</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cutkosky MR. Robotic grasping and fine manipulation. Kluwer Academic Publ., 1985]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gourret JP. Modeling 3D contacts and Deformations using finite element theory in synthetic human tactile perception, in: D. Thalmann et al., SIGGRAPH '88 course notes on synthetic actors, 1988, pp 222-230]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hollerbach JM. A recursive Lagrangian formulation of manipulator dynamics and a comparative study of dynamics formulation. IEEE Trans. on systems, man and cyber., SMC-10 No 11, 1980, pp 730-736]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Isaacs PM and Cohen MF. Controling Dynamic simulation with kinematic constraints, behavior functions and inverse dynamics. Pro~. SIGGRAPH' 87, pp 215-224]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Jacobsen SC, McCammon ID, Biggers KB and Phillips RP. Design of tactile sensing systems for dextrous manipulators. IEEE Control Systems Magazine, Vol 8, N 1, 1988, pp 3-13]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Komatsu K. Human skin model capable of natural shape variation. The Visual Computer, No 3, 1988, pp 265- 271]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lee CSG, Gonzales RC and Fu KS. Tutorial on robotics. IEEE Comp. Soc. Press, 1983]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Luciani A. Un outil informatique de creation d'images anim~es: modules d'objets, langage, controle gestuel en temps r6et. Le syst/:me ANIMA. These Docteur-Ing. INP Grenoble 1985]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4132</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann N and Thalmann D. Computer animation: Theory and Practice. Springer, Tokyo, 1985]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann N and Thalmann D. 3D Computer Animation: More an Evolution Problem than a Motion Problem, IEEE Computer Graphics and Applications, Vol. 5, No 10, 1985, pp.47-57.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>39276</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann N and Thalmann D. Image Synthesis" Theory and practice. Springer, Tokyo, 1987]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmarm N and Thalmann D. The direction of synthetic actors in the film Rendez-vous /t Montreal. IEEE Computer Graphics &amp; applications, Vol 7, No 12, 1987, pp 7-19]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102317</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann N, Laperri~re R and Thalmann D. Joint-Dependent Local Deformations for hand animation and object grasping, Proc. Graphics Interface '88, Edmonton]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Moore M and Wilhelms J. Collision detection and response for computer animation. Proc.SIGGRAPH '88, pp 289-298]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>600999</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Paul RP. Robot manipulators: mathematics, programming and control. The MIT Press, Cambridge, Mass., 1981]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Platt JC and Barr AH. Constraint method for flexible models. Proc. SIGGRAPH '88, pp 279-288]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Pugh A(ed.). Robot sensors. Vol 2. Tactile and nonvision. IFS publications Ltd (Bedford) and Springer Verlag, 1986]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>573692</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Slotine JJE and Asada H. Robot analysis and control. Wiley, 1986]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos D, Platt J, Barr A and Fleischer K. Elastically deformable models. Proe.SIGGRAPH '87, pp 205-214]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378540</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Thomson DE, Buford WL, Myers LM, Giurintano DJ and Brewer III JA. A hand biomechanics workstation. Proc. SIGGRAPH '88, pp 335-343]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Timoshenko S and Goodier JN. Theory of elasticity. 3rd.ed., McGraw-Hill, NY, 1970]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Wilhelms J. Toward automatic motion control. IEEE Computer Graphics and applications, Vol 7, No 4, 1987, pp 11-22]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Witkin A and Kass M. Spacetime Constraints. Proc. SIGGRAPH '88, pp. 159-168]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Wyvill G, McPheeters C, Wyvill B. Data structure for soft objects. The Visual Computer, No 2, 1986, pp 227-234]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Zienkiewiez OC. The finite element method. Third edition, McGraw-Hill, London, 1977]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Simulation of Object and Human Skin in a Grasping Task Jean-Paul Gourred MIRALab, University of Montreal 
Nadia Magnenat Thalmarm 2 University of Geneva Daniel Thalmarm 3 Swiss Federal Institute of Technology 
ABSTRACT This paper addresses the problem of simulating deformations between objects and the hand of 
a synthetic character during a grasping process. A numerical method based on finite element theory allows 
us to take into account the active forces of the fingers on the object and the reactive forces of the 
object on the fingers. The method improves control of synthetic human behavior in a task level animation 
system because it provides information about the environment of a synthetic human and so can be compared 
to the sense of touch. Finite element theory currently used in engineering seems one of the best approaches 
for modeling both elastic and plastic deformation of objects, as well as shocks with or without penetration 
between deformable objects. We show that intrinsic properties of the method based on composition/decomposition 
of elements have an impact in computer animation. We also state that the use of the same method for modeling 
both objects and human bodies improves the modeling of the contacts between them. Moreover, it allows 
a realistic envelope deformation of the human fingers comparable to existing methods. To show what we 
can expect from the method, we apply it to the grasping and pressing of a ball. Our solution to the grasping 
problem is based on displacement commands instead of force commands used in robotics and human behavior. 
keywords: synthetic human animation, grasping task, tactile sensing modeling, simulation, contact, physical 
interaction, deformation on leave from Lab. de Traitement du Signal Num6rique, Ecole Nationale Sup6rieure 
de Physique, Marseille, France MIRALab, CUI, University of Geneva, Switzerland CH 1207 Geneva, phone: 
41-22-787-6581 e-mail: thalmann@ CGEUGE51 .BITNET Computer Graphics Lab., Swiss Federal Institute of 
Technology, CH 1207 Lausanne, Switzerland phone: 41-21- 693-5214, e-mail: thalrnarm@elma.epfl.ch Perinission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee aud/or specific permission. Deformations 
INTRODUCTION Along with walking and speaking, grasping is an important task to be included in a system 
for animating synthetic actors. In character animation, the notion of task planning is divided into three 
phases: world modeling, task specification and code generation. World modeling consists mainly of describing 
the geometry and the physical characteristics of the synthetic actors and the objects. Task specification 
and code generation are more language oriented; they are not treated in this paper. World modeling for 
synthetic actors frequently uses skeletons made up of segments linked at joints. This is suitable for 
parametric key-frame animation, kinematic algorithmic animation or dynamic based techniques [23]. The 
skeleton is generally surrounded by surfaces or elementary volumes [3] [20] whose sole purpose is to 
give a realistic appearance to body. The model developed by Komatsu [17] uses biquartie Bezier surfaces, 
and control points are assigned to the links. Magnenat-Thalmann et al. [24] used a technique based on 
Joint-Dependent Local Deformations OLD) to tie skin points to joint points obtaining realistic stretching 
and inflation of flesh. Catmull used polygons [10], and Badler and Morris [2] used the combination of 
elementary spheres and B-splines to model the human fingers. On the other hand, the environment of characters 
is made up of rigid objects, key-frame deformable objects, mathematically deformable objects [5], soft 
objects represented by scalar combinations of fields around key points [35] [7], or physically deformable 
objects based on elasticity theory [27] [30]. With physical models, the objects act as if they had a 
mind. They react to applied forces such as gravity, pressure and contact. Platt and Barr [27] used finite 
element software and discuss constraint methods in terms of animator tools for physical model control. 
The models developed by Terzopoulos et el. [30] are implemented using the Finite Difference Method. Collisions 
between elastic objects are simulated by creating potential energy around each object, i.e,, intersections 
between deformable bodies are avoided by surrounding the object surfaces with a repulsive collision force. 
This approach is also developed by Luciani [19] who deals with 2D real time animation of objects and 
characters based on springs, dampers and masses, controlled by gestural transducers with mechanical feedback. 
&#38;#169;1989 ACM-0-89791- 312-4/89/007/0021 $OO.75 "~,~..~SIGGRAPH '89, Boston, 31 July-4 August, 1989 
 Moore and Wilhems [25] treat collision response, developing two methods based on springs and analytical 
solutions. They state that spring solutions are applicable to the surface shapes of flexible bodies but 
do not explain how the shapes are obtained before initiation of contact calculations nor how the shapes 
are modified as a result of a contact. Our main objective is to model the world in a grasping task context 
by using a finite element theory. The method allows simulation of both motion and shape of objects in 
accordance with physical laws, as well as the deformations of human flesh due to contact forces between 
flesh and objects. The following two arguments support use of the same method for modeling deformation 
of objects and human flesh. First, we want to develop a method which will deal with penetrating impacts 
and true contacts. For this reason, we prefer to consider true contact forces with possibilities of sliding 
and sticking rather than only repulsive forces. Our approach based on volume properties of bodies permits 
calculation of the shape of world constituents before contact, and to treat their shape during contact. 
When a contact is initiated we use a global resolution procedure which considers bodies in contact as 
an unique body. Simulation of impact with penetration can be used to model the grasping of ductile objects 
or to model ballistic problems. It requires decomposition of objects into small geometrically simple 
objects. Second, all the advantages of the physical modeling of objects can be transferred to human flesh 
[13]. For example, we expect the hand grasping an object to lead to realistic flesh deformation as well 
as an exchange of information between the object and the hand which will not only be geometrical. When 
a deformable object is grasped, the contact forces on it and on the fingertips will lead to deformation 
of both the object and of the fingertips, giving rise to reactive forces which provide significant information 
about the object and more generally about the environment of the synthetic human body. It is important 
to note that even if the deformations of the object and of the fingers are not visible, or if the object 
is rigid, the exchange of information will exist because the fingers are always deformable. This exchange 
of information using active and reactive forces is significant for a good and realistic grip and can 
influence the behavior of the hand and of the arm skeleton. For grip, interacting information is as important 
as that provided by tactile sensors in a robot manipulator. This is a well known problem of robotics 
called "compliant motion control". It consists of taking into account external forces and commanding 
the joints and links of the fingers using inverse kinematic or dynamic controls. In the past, authors 
dealing with kinematic and dynamic animation models oriented towards automatic animation control [1] 
[4] [9] [33], have often referred to works of roboticians [14] [18] [26]. In the same way, we believe 
that methods intensively used in CAD systems may improve the control of synthetic human animation. However, 
the method must be adapted to computer animation because the problems here are not the same as in CAD 
or robotics. In robotics, it is impossible to expect a grip controller to perform a complete environmental 
finite element analysis in real time. Consequently, the adopted solution generally uses well-located 
fingertip sensors to measure the terms that are difficult to compute. In synthetic human modeling, complete 
computations are possible, though they represent a gigantic problem. To grasp an object, robots and humans 
apply a prescribed force to the object, whose intensity is related to environment knowledge. This process 
will not work in animation because force transducers are not yet used in computer animation systems. 
Hence, our grasping method for animation is based on prescribed displacements instead of prescribed forces. 
In the next section, we emphasize the properties of the numerical method developed for computer animation 
purposes. In the second part, we show how a global approach can contribute to animation of synthetic 
actors in their environment, using the same method for modeling deformation of objects and human bodies. 
We describe in detail the grasping and pressing of a ball, and show envelope deformation during finger 
flexing. In the last section, we discuss how our numerical approach enhances the HUMAN FACTORY system 
[23]. NUMERICAL METHOD FOR COMPUTER ANIMATION This section does not describe the finite element theory 
in detail, but rather introduces those concepts used for computer animation purposes. A comprehensive 
study of the finite element theory is given in Bathe [6] and Zienkiewicz [36]. A summary of the theory 
of elasticity can be found in Timoshenko and Goodier [32]. cube prism pyramid tetrahedron (8 pts) (6 
pts) (5 pts) (4pts) a. linear elements with zero order continr in ~ nil ~dlF''"ql't "'*'ala-l,mla,U._~ 
I1 l] b. cubic element with zero order continu Figure 1 -elements and their deformations Solid three-dimensional 
objects and human flesh are discretized using simple or complex volume elements, depending on the choice 
of the interpolation function. Zero order simple linear elements and complex cubic elements with their 
deformations are shown in Figure 1. The finite element approach is compatible with requirements of visual 
realism because a body surface corresponds to an element face that lies on the body boundary. As with 
surface patches, it is possible to ensure high order of continuity between elements. However, this procedure 
is expensive in terms of memory space and CPU time. For this reason, our calculations are based on linear 
elements with zero order continuity. Nevertheless, the use of complex elements and high order continuity 
allows us to obtain the same visual effects as with surface patches. Indeed, elements are parametric 
volumes and the boundary object surface is a parametric surface. Once the various kinds of elements are 
defined, the modeled shape is obtained by composition. Each element is linked to other elements at nodal 
points. In continuum mechanics, the equilibrium of a body presenting a shape can be expressed by using 
the stationary principle of the total potential or the principle of virtual displacements: wR = wB + 
wS + wF (1) where wB represents the virtual work due to the body forces such as gravity, centrifugal 
loading, inertia and damping, wS represents virtual work of distributed surface forces such as pressure, 
wF represents the virtual work of concentrated forces and wR represents the internal virtual work due 
to internal stresses. In the finite element method, the equilibrium relation (1) is applied to each element 
e WRe = WBe + WSe + WFe (2) and the whole body is obtained by composing all elements NBEL I~,BEL ~ NBP 
Z WRe= EWBe + ZWSe + ZWFe (3) e.le..ment=l e.kmaamt=l et.mea"a=l node=l Our three-dimensional model 
uses elements with eight nodes and NBDOF = 3 degrees of freedom per node. These elements are easily modified 
to prismatic or tetrahedral elements to approximate most existing 3D shapes. The composition of NBEL 
dements with 8 points give NBP points and NB = NBP*NBDOF equations. From the relation (3) we can write 
the following matrix equation between vectors of size [NB*I] as follows: R+RI=RB+RS+RF (4) where RB 
is the composition of body forces, RS is the composition of surface forces and RF represents the concentrated 
forces acting on the nodes. R + RI is the composition of internal forces due to internal stresses. These 
stresses are initial stresses which give the RI term, and reactions to deformations created by RB, RS 
and RF which give the R term. In the following sections we will use the equilibrium relation (4) under 
the form (5) K.U = R (5) where K is the [NB*NB] stiffness matrix, a function of material and flesh constitution, 
R is the [NB*I] load vector including the effects of the body forces, surface tractions and initial stresses, 
and U is the [NB*I] displacement vector from the unloaded configuration. Relation (5) is valid in static 
equilibrium and also in pseudo- static equilibrium at instant t i. Instants t i are considered as variables 
which represent different load intensities. In this paper, we do not deal with dynamics when loads are 
applied rapidly. In this case, true time inertia and damping, displacement velocity and acceleration 
must be added to (5). Under this form, the body can be viewed as a huge three-dimensional spring of stiffness 
K and return force R. The equilibrium relation (3) is a function of volume properties because each component 
is obtained by the summation of integrations over the volume and the area of each element (see [36] for 
more details). Since the process used consists of the composition of elements to create a global deformable 
object, we believe that this property and its inverse, i.e. the decomposition of a global deformable 
object into two or multiple sub-objects, should be used in computer animation. The decomposition is very 
easy to implement because the constitutive properties of each element as well as inter-element forces 
are memorized and are taken into account during numerical calculations. It is possible for example to 
create a global object made of different sub-objects; each sub-object would have its own constitutive 
properties and be composed of one or more elements. There are several ways to exploit the intrinsic properties 
of this method: The decomposition approach can be exploited to model penetrating shocks between two or 
more deformable objects. Each object is subdivided into many deformable sub-objects which are able themselves 
to interact with each other because each inherits its own properties. The decomposition approach may 
also be used in contact problems when contact is released. The composition approach can be used for modeling 
contacts without penetration between two or more objects. In this case, objects can be considered as 
sub-objects evolve independently until contact is detected and a global object is composed following 
contact. In practice this means that relations Kn.U n = R n are resolved independently before contact 
and a unique relation K.U = R is resolved after contact of n bodies. This process works if we take into 
account the contact forces that prevent overlapping in equation (5). We use the composition approach 
for the grasping and pressing of a ball described in the following section. A survey of contact problems 
is given by Bottm [8]. Example of 3D treatments can be found in Chaudary and Bathe [11]. BALL GRASPING 
AND PRESSING To show how the physical modeling of deformable objects can contribute to human animation, 
we present an example of a contact problem dealing with the grasping and pressing of a ball. Starting 
with the facet-based envelopes of ball and hand obtained from our image synthesis system SABRINA [22], 
we mesh the volume of the objects to create full 3D bodies or shell bodies depending on the application. 
After calculations of the deformations using our method based on finite element theory, the facet-based 
deformed envelopes are extracted from the data base used in our calculations and   ,:~,~~SIGG RAPH 
'89, Boston, 31 July-4 August, 1989 In a first step, sight allows us to evaluate certain dimensions, 
mass, roughness, elasticity etc. i.e. to imagine our position in relation to the bali. In the domain 
of animation, this information is contained in the ball data base (e.g. volume point coordinates, and 
physical characteristics such as constitutive law, mass density, and texture which can be related to 
roughness). The hand grasps or presses the ball applying a prescribed force, whose intensity is dictated 
by the knowledge acquired by the sense of sight. The prescribed contact force is created by muscular 
forces acting on bones and using flesh as an intermediary. Generally, the grip is as gentle as possible 
without letting go of the ball. This can be viewed as a "minimization of the power due to the muscles", 
as pointed out by Witkin and Kass [34]. A gentle grip not only prevents damage to a fragile object, but 
also results in a grip that is more stable [12] [29]. In a second step, the sense of touch allows an 
exchange of information between the ball and the fingers, implying contact forces, sliding contacts, 
deformations, and internal stresses in the fingers. In computer animation the first step is difficult 
to implement because the animator does not dispose of force transducers for forces applied directly to 
the bones. Consequently the first step based on given prescribed forces R k on bones is not presently 
possible. For this reason our solution for the grasping problem is different from the robot or human 
solution. It is displacement-driven rather than force-driven. In this way, the animator is not concerned 
with forces but with the hand key position required by the script. For ball grasping, shown in figure 
4, the ball is made up of a rubber envelope and is submitted to internal pressure. The animator imposes 
prescribed displacements U k on the hand bones using a "classical" method (parametric, kinematic or dynamic) 
and places the ball between the fingers. During this process the animator can ignore the material of 
which the ball is built. It can be a very soft ball or a very stiff bowl. The animator positions the 
fingers (skin and eventually bones) inside the ball. The purpose of calculations is to decide if the 
chosen finger position is or is not a realistic one and its consequences on skin and ball shapes. This 
is the reaction of the ball on the fingers which will decide the validity of grasping. Since finger position 
is prescribed by the animator, the ball must be repelled to prevent overlaps, ignoring, as a first approximation, 
whether it is stiff or soft. The computational geometry procedure used for determination of repelling 
points is beyond the scope of this paper. We show in figure 5 an example of overlap. When a ball node 
B penetrates the finger and/or palm, it is repelled over the skin surface (point C) in the direction 
of polygon normal n F. Ball and hand surface patches are polygon faces of finite elements. With linear 
elements of zero order continuity, patches are triangular or quadrilateral. The normal direction n F 
of each polygon face is calculated at the polygon center. It is a true normal if the patch is triangular 
and an approximated normal if the patch is quadrilateral because the four surface points are generally 
not in the same plane. For this reason we use triangular polygons for fingers in our contact calculations. 
P3 R1 P1  Y~B P2 Figure 5 -Overlapping of a ball node. The ball node B is repelled over point C of 
the skin facet P1, P2, P3 in direction of normal n F to the facet. The reactive force created by overlapping 
suppression is shared out among R 1, R 2 and R 3. Ri=hi.R c (i=l, 2, 3) where h i is the interpolation 
function corresponding to node i, evaluated at point c. Value of h i is unity at node i and zero at all 
other nodes. The overlap suppression creates reactive forces on the ball surface, which are applied 
to the skin. At equilibrium, these forces maintain compatible surface displacements between the two deformable 
bodies. The following is an iterative procedure for obtaining both the contact forces and the displacements 
under contact: 1 - move links and joints using some "classical" method (parametric, kinematic or dynamic) 
and calculate new prescribed bone displacements U k. While equilibrium between ball and hand is not reached 
or reactive force on bones has not overrun a threshold force, do: begin 2 -prescribe displacements U 
k of skin; repel ball nodes to prevent overlapping; prescribe displacements U k of repelled ball nodes; 
3 - resolve (7) and (8) to obtain displacements U u on ball and reactive forces R u on contact points 
of the ball; 4 - affect equal and opposite reactive forces R u on contact points of the skin; 5 - assume 
the contact forces R u are prescribed forces R k, i.e. release all degrees of freedom of ball and skin; 
6 - resolve (7) and (8) to obtain displacements U u of ball and skin, and reactive forces R u on bones; 
end; Relation (7) is solved using a direct solution (Gauss method). Convergence occurs when for all points 
the variation between two successive iterations is less than some fixed threshold. In this procedure, 
relations (7) and (8) represent the global system made up of ball and hand. The first step requires animator 
manipulation and has been described previously. In the second step all skin displacements, and those 
ball displacements resulting from overlap suppression are prescribed, In.this way, resolution of (7) 
and (8) in step 3 will give displacements U u on ball and reacting forces on repelled ball nodes. Step 
4 ensures that at equilibrium, contact forces between ball and skin will be equal and opposite to maintain 
compatible surface displacements. Because ball nodes are not repelled in coincidence with skin nodes, 
but on skin polygon surfaces, the reacting force calculated in step 4 is distributed among the three 
nodes constituting the skin facet (Figure 5), with weights depending on the position of the ball node 
on the facet. In steps 5 and 6, reacting forces are assumed to be known and all degrees of freedom of 
ball and skin are released. In other words, we rearrange matrix relation (6) because the number of equations 
is modified in comparison with step 3. The method ean be interpreted as a Lagrangian multiplier method 
that forces the non-penetration condition between the ball and the hand with additional equations. Steps 
2 to 6 are repeated until convergence is reached. Otherwise they are stopped when the evaluation of the 
reacting force on bones overruns a force threshold allowable by the human musculature. Indeed, assume 
that animator places finger skin and bones into a very stiff bowl. The reacting force R k on bones obtained 
in step 6 can then be gigantic and overrun the threshold force attributed to the muscular command of 
this bone. In a parametric computer animation system, the reacting force on bones can be used to suggest 
solutions to the animator as in an expert system. In a system with inverse dynamics, the position of 
bones is modified automatically using calculated reacting force. Calculation of finger deformations are 
necessary even if fingers and palm deformations are not visible. An exchange of information will take 
place since the fingers are always deformed. It is finger flexibility and frictional resistance which 
permit human grasp of rigid objects. This is the reason why actual robot hands are made up of elastic 
extremities equipped with tactile sensors [16] [28]. Our actual simulation is based on prescribing and 
releasing the displacement of contact points during each iteration. This allows us to release dynamically 
the parts of the two bodies. A more sophisticated model, now being developed, must include an evaluation 
of frictional resistance. For example a Coulomb friction law may be used to simulate the adhesion of 
papillary ridges. In this law, a coefficient of friction u relates the normal force F n to the tangential 
force F t at contact points. Force u.F n represents the frictional resistance during contact, and sliding 
contact is initiated when F t _> u.Fn. During the second step of grasping, if the initial prescribed 
force R k has been poorly evaluated by the sense of sight, the ball and finger(s) will slide. This information 
can then be used to increase the prescribed force, or to modify the position of fingers on the ball. 
The evaluation of sliding and Computer Graphics, Volume 23, Number 3, July 1989 the increase in the prescribed 
force must be repeated until an equilibrium or an unstable condition is obtained. Both the tactile sensor 
model and the command model must be included in a complete automatic motion control, because the stiffness 
of grip is a function of the stiffness of finger tissue and of the disposition of fingers around the 
ball. This compliant motion control scheme, which is made to sustain the environmental factors, might 
be made easier by the fact that kinematic and dynamic models dealing with articulated bodies can be looked 
upon as a displacement based finite element method applied on trusses and bars. The global treatment 
of contact presented here can be applied to inter-deformation of fingers, deformation between fingers 
and palm, or, more generally, between two synthetic human parts following a compression or a stretching 
of skin. For this purpose, each part of the body must be considered as an entity able to interact with 
each other part. An entity cannot interpenetrate itself and some entities cannot reach all others because 
of joint angle limits imposed on the skeleton [15]. For example, during finger flexing, we consider the 
third phalanx unable to interpenetrate the second and first phalanges. In the same way we also consider 
that a foot cannot reach the face unless we are simulating a chubby baby. FINGER FLEXION WITHOUT CONTACT 
The problem of 3D modeling of human skin deformations, during the process of joint flexing, has many 
different solutions that give a realistic visual appearance to the human body. The skeleton can be surrounded 
by surfaces of planar or curved patches, or the skin can be modeled by elementary volumes. All the methods 
have been created to give a realistic appearance to hands and bodies with no concern for the force information 
exchanged during contact. In Figure 6, we show the successive steps of finger flexing whose last position 
can be compared with a JLD result. The starting position was the neutral rest position and the following 
procedure was applied: For each time t i corresponding to link displacement angle less than 10 de~rees, 
do: be~in 1 Move links and joints using some "classical" method (parametric, kinematic or dynamic), and 
calculate new position of prescribed DOF on bones, 2 from preceding position at time ti. 1 calculate 
prescribed DOF displacement U k on bones 3 calculate stiffness K, erase R k and solve relation (5) to 
obtain tissue displacements U u, 4 update position of tissue points end In our calculations, an updated 
Lagrangian formulation in small strains [32] was used. We also used a classical engineering stress measure 
(Cauchy stress) and a linear constitutive law for flesh tissue. This formulation is simple, but it gives 
good visual results, without requiring long calculations. For the displacement of finger links, a variation 
angle of 10 degrees seems to be a maximum to ensure a small displacement and rotation condition.  L,t~SIGGRAPH 
'89, Boston, 31 July-4 August, 1989 Therefore, 30 degrees displacement of the first phalanx and 50 degrees 
of the second phalanx as shown in Figure 6, needs at least height position calculations corresponding 
to displacements of 10, 20 and 30 degrees for the first phalanx and displacement of 10, 20, 30, 40 and 
50 degrees for the second phalanx; or any combination of these displacements. b F C F d Figure 6 -Successive 
steps of finger flexing without contact; a. rest position; b. particular bones; c. finger flexing based 
on FEM deformation d. finger flexing based on Joint-dependent Local deformation (JLD) It must be noted, 
however that the final position could be obtained directly from test position using another formulation 
which takes into account large displacements and rotations in small strains. In this case, the formulation 
would be based on the use of a Piola-Kirchhoff stress instead of Cauchy stress, and would requ~e an iterative 
computation. However, this scheme does not seem very interesting in hand animation because inbetween 
positions are indispensable for realistic movement decomposition. If more realism, or incompressible 
material modeling, are desired, increased computation time will be required for material non-linear calculations. 
When material non-linearities exist, a Newton-Raphson iterative method must be added in step 3 of the 
procedure for each time t i. The use of a linear material allows us to obtain inflation of flesh without 
an iterative calculation and requires less than 1 minute per frame on a VAX 780. But this procedure works 
only with the particular shape of bones shown in Figure 6. More realistic bones require incompressible 
material and this increases the computation time. 28 Although we proved that the calculations described 
here give realistic deformations of fingers during flexion, in the HUMAN FACTORY system we use a hybrid 
formulation based on JLD operators when there is no contact, and on FEM calculation when a contact is 
detected. In a complete grasping task, this method saves CPU time during the reach phase of the task 
when the hand comes closer to the object. ANIMATION CONTROL In this section, we briefly discuss how 
animation of deformable objects and human bodies has been introduced into the HUMAN FACTORY system. For 
animation of rigid objects, the HUMAN FACTORY system already contains animation procedures for simple 
physical movements applied to material points. Examples are movement of pendula, circular movement with 
acceleration, projectile with initial velocity and so on. It also contains basic animation laws like 
the Catmull laws (see [20], p.49). These physical or empirical laws are applied to animated variables 
or state variables. In this way, during the specified interval, state variables are automatically updated 
to the next value according to the law [21]. Moreover these state variables drive actor transformations. 
Combining state variables and actor transformations allows a complex animation of actors. Animation of 
a physically deformable object can be simply supported in the HUMAN FACTORY system by defining prescribed 
displacements called U k in the preceding sections as new state variables. When the three degrees of 
freedom of some point are prescribed, state variables of VECTOR type are sufficient for defining the 
movement of prescribed points. When less than three degrees of freedom are displacement prescribed, a 
new type of state variable has been defined. With this approach deformable bodies are processed as actors. 
Object points are not only submitted to translations and rotations, but automatically follow the prescribed 
degrees of freedom according to constitutive laws and other potential constraints such as body forces 
and surface forces. It should be noted that the use of state variables is not always required and can 
often be omitted. For example the problem of free fall of a deformable object is implicitly defined and 
does not require an extra physical law and prescribed degrees of freedom. We have already discussed the 
problem of hand animation in the preceding sections. In the system, skeleton animation is based on joint 
angle definition. A realistic skeleton is linked to animated skeleton segments, and prescribed displacements 
are fixed on bones surfaces. We use displacement-based degrees of freedom because displacement transducers 
(such as mouse, rolling bowl and so on) are more common in computer animation than force transducers 
(such as remote manipulators in robotics). The procedure based on prescribed displacements is easy to 
implement in parametric animation systems and can pass information to dynamic animation systems. Force 
prescribed systems will be effective when forces transducers are intensively introduced in computer animation. 
In this case, the animator will be fully engaged in the scene during creation and it will be possible 
to define a new TYPE OF ACTOR called animator. CONCLUSION In this paper we have simulated objects and 
skin hand deformations in a grasping task. To this end, a finite element module has been developed for 
modelling both object and synthetic human flesh deformations and their contacts. The method gives information 
about the synthetic environment of the human. It may be compared to the robot tactile sensor or to the 
human sense of touch. This information provides a significant contribution to automatic motion control 
in 3D character animation. We believe that it can be used to improve the behavior of synthetic human 
grasp and more generally to improve the synthetic human behavior in the synthetic environment. These 
problems cannot be solved using only geometric solutions, or only force solutions implying gravity and 
muscular forces based on a single point of contact. In an artist oriented system, the finite element 
model can be used to define objects in the same way as a sculptor molds his shapes. The object and human 
data base contain not only envelope coordinates but also volume point coordinates and information about 
physical material, tissue characteristics and force threshold. In this way, we take advantage of the 
intrinsic properties of the numerical method, based on composition-decomposition of elements, for computer 
animation purposes. ACKNOWLEDGMENTS The authors would like to thank Richard Laperri~re and Ross Racine 
for their contribution in producing the images. They are also grateful to referees for their comments 
and suggestions. The research was supported by the Natural Sciences and Engineering Council of Canada, 
the FCAR foundation, le Fonds National Suisse pour la Recherche Scientifique and the Institut National 
de la Recherche en Informatique et Automatique (France). REFERENCES [1] Armstrong WW and Green MW. The 
dynamics of articulated rigid bodies for purpose of animation. The Visual Computer, Vol 1, 1985, pp 231-240 
[21 Badler NI and Morris MA. Modeling flexible articulated objects. Proc. Comp. Graphics '82, Online 
conf., 1982, pp 305-314. [3] Badler NI and Smoliar SW. Digital representation of human movement. Computing 
Surveys, Vol 11, No 1, 1979, pp 19-38 [4] Badler NI. Design of a human movement representation incorporating 
dynamics. Tech. rep., Dept. of computer and infor.science, Univ. of Pennsylvania, Philadelphia 1984 [5] 
Barr AH. Global and local deformations of solid primitives. Proc. SIGGRAPH '84, pp 21-30 [6] Bathe KI. 
Finite element procedures in engineering analysis. Prentice Hall, 1982 [7] Blinn JF. A generalization 
of algebraic surface drawing. ACM Trans. on graphics, Vol 1 No 3, 1982, pp 235- 256 [8] Bohm J. A comparison 
of different contact algorithms with applications. Comp.Struc., Vol 26 N 1-2, 1987, pp 207-221 [9] Calvert 
TW, Chapman J, and Patla A. Aspects of the kinematic simulation of human movement. IEEE Computer Graphics 
and applications, nov 1982, pp 41-52 [10] Catmull E. A System for Computer-generated Movies. Proc. ACM 
Annual Conference, Vol. 1, 1972, pp.422- 431. [11] Chaudary AB and Bathe KJ. A solution method for static 
and dynamic analysis of three dimensional contact problems with friction. Comp.Struc. Vol 24 N 6, 1986, 
pp 855-873 [12] Cutkosky MR. Robotic grasping and fine manipulation. Kluwer Academic Publ., 1985 [13] 
Gourret JP. Modeling 3D contacts and Deformations using finite element theory in synthetic human tactile 
perception, in: D. Thalmarm et al., SIGGRAPH '88 course notes on synthetic actors, 1988, pp 222-230 [14] 
Hollerbach JM. A recursive Lagrangian formulation of manipulator dynamics and a comparative study of 
dynamics formulation. IEEE Trans. on systems, man and cyber., SMC-10 No 11, 1980, pp 730-736 [15] Isaacs 
PM and Cohen MF. Controling Dynamic simulation with kinematic constraints, behavior functions and inverse 
dynamics. Proe. SIGGRAPH' 87, pp 215-224 [16] Jacobsen SC, McCammon ID, Biggers KB and Phillips RP. Design 
of tactile sensing systems for dextrous manipulators. IEEE Control Systems Magazine, Vol 8, N 1, 1988, 
pp 3-13 [17] Komatsu K. Human skin model capable of natural shape variation. The Visual Computer, No 
3, 1988, pp 265- 271 [18] Lee CSG, Gonzales RC and Fu KS. Tutorial on robotics. IEEE Comp. Soc. Press, 
1983 [19] Luciani A. Un outil inforrnatique de cr6ation d'images anim6es: modules d'objets, langage, 
controle gestuel en temps r6el. Le syst~me ANIMA. These Docteur-Ing. INP Grenoble 1985 [20] Magnenat-Thalmann 
N and Thalmann D. Computer animation: Theory and Practice. Springer, Tokyo, 1985 [21] Magnenat-Thalmann 
N and Thalmarm D. 3D Computer Animation: More an Evolution Problem than a Motion Problem, IEEE Computer 
Graphics and Applications, Vol. 5, No 10, 1985, pp.47-57. [22] Magnenat-Thalmann N and Thalmann D. Image 
Synthesis: Theory and practice. Springer, Tokyo, 1987 [23] Magnenat-Thalmann N and Thalmarm D. The direction 
of synthetic actors in the film Rendez-vous ~t Montreal. IEEE Computer Graphics &#38; applications, Vol 
7, No 12, 1987, pp 7-19 [24] Magnenat-Thalmann N, Laperri~re R and Thalmarm D. Joint-Dependent Local 
Deformations for hand animation and object grasping, Proc. Graphics Interface '88, Edmonton [25] Moore 
M and Wilhelms J. Collision detection and response for computer animation. Proc.SIGGRAPH '88, pp 289-298 
[26] Paul RP. Robot manipulators: mathematics, programming and control. The M1T Press, Cambridge, Mass., 
1981 [27] Platt JC and Barr AH. Constraint method for flexible models. Proc. SIGGRAPH '88, pp 279-288 
[28] Pugh A(ed.). Robot sensors. Vol 2. Tactile and non-vision. IFS publications Ltd (Bedford) and Springer 
Verlag, 1986 ~.I~ SIGGRAPH'89, Boston, 31 July-4 August, 1989 [29] Slotine JJE and Asada H. Robot analysis 
and control. Wiley, 1986 [30] Terzopoulos D, Platt J, Barr A and Fleischer K. Elastically deformable 
models. Proe.SIGGRAPH '87, pp 205-214 [31] Thomson DE, Buford WL, Myers LM, Giurintano DJ and Brewer 
III JA. A hand biomechanics workstation. Proc. SIGGRAPH '88, pp 335-343 [32] Timoshenko S and Goodier 
JN. Theory of elasticity. 3rd.ed., McGraw-Hill, NY, 1970 [33] Wilhelms J. Toward automatic motion control. 
IEEE Computer Graphics and applications, Vol 7, No 4, 1987, pp 11-22 [34] Wit.kin A and Kass M. Spacetime 
Constraints. Proc. SIGGRAPH '88, pp. 159-168 [35] Wyvill G, McPheeters C, Wyvill B. Data structure for 
soft objects. The Visual Computer, No 2, 1986, pp 227-234 [36] Zienkiewiez OC. The finite element method. 
Third edition, McGraw-Hill, London, 1977  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74336</article_id>
		<sort_key>31</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Combinatorial analysis of ramified patterns and computer imagery of trees]]></title>
		<page_from>31</page_from>
		<page_to>40</page_to>
		<doi_number>10.1145/74333.74336</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74336</url>
		<abstract>
			<par><![CDATA[Herein is presented a new procedural method for generating images of trees. Many other algorithms have already been proposed in the last few years focusing on particle systems, fractals, graftals and L-systems or realistic botanical models. Usually the final visual aspect of the tree depends on the development process leading to this form. Our approach differs from all the previous ones. We begin by defining a certain "measure" of the form of a tree or a branching pattern. This is done by introducing the new concept of ramification matrix of a tree. Then we give an algorithm for generating a random tree having as ramification matrix a given arbitrary stochastic triangular matrix. The geometry of the tree is defined from the combinatorial parameters implied in the analysis of the forms of trees. We obtain a method with powerful control of the final form, simple enough to produce quick designs of trees without loosing in the variety and rendering of the images. We also introduce a new rapid drawing of the leaves. The underlying combinatorics constitute a refinment of some work introduced in hydrogeology in the morphological study of river networks. The concept of ramification matrix has been used very recently in physics in the study of fractal ramified patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P301517</person_id>
				<author_profile_id><![CDATA[81100054298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[X.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Viennot]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LABRI, D&#233;partement d'Inforrnatique, Universit&#233; de Bordeaux I, FRANCE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P89612</person_id>
				<author_profile_id><![CDATA[81100461917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eyrolles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LABRI, D&#233;partement d'Inforrnatique, Universit&#233; de Bordeaux I, FRANCE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P205015</person_id>
				<author_profile_id><![CDATA[81100011235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Janey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LIB, D&#233;partement d'Inforrnatique, Universit&#233; de Franche-Comt&#233;, FRANCE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P52005</person_id>
				<author_profile_id><![CDATA[81332488435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arqu&#233;s]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LIB, D&#233;partement d'Inforrnatique, Universit&#233; de Franche-Comt&#233;, FRANCE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aono M., and Kunii T.L. Botanical tree image generation, IEEE Computer Graphics &amp; Apphcations 4,5 (1984),I0-34.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Ball, R.C. DLA in the real world, in On growth and form: fractal and non-fractal patterns in Physics, Stanley, H.E., and Ostrowski, N., eds., Martinus Nijhoff, Boston (1986) 69-78.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Beyer, T., and Friedel. M. Generative scene modelling. Proceeding of EUROGRAPHICS '87 (1987),151-158 &amp; 571.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325249</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BloomenthaI, J. Modeling the Mighty Maple. Proceedings of SIGGRAPH '85 (San Francisco, CA, July 22-26, 1985). In Computer Graphics 19, 3 (1985), 305-311,]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cole, V,C. The artistic anatomy of trees. Dover Publication, N-Y (1965) (orginally Seely Servi &amp; Co., Load., 19 I5).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D'Arcy Thompson, W. On growth and form. University Press, Cambridge, 2rid ed., (1952).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325245</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Demko, S., Hodges, L., and Naylor, B. Construction offractal objects with iterated function systems. Proceedings of SIGGRAPH '85 (San Francisco, CA, July 22-26, 1985). In Computer Graphics 19, 3 (I985), 271-278.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378505</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[De Reffye, P., Edelin, C., Franqon, J., Jaeger, M., Puech, C. Plant Models Faithful to Botanical Structure and Development. Proceedings SIGGRAPH '88 (Atlanta, August 1-15, 1988). Computer Graphics 22, 4(1988),151-158,]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Eyrolles G. Synth~se d'images figuratives d'arbres par des rndthodes combinatoires. Ph.D. Thesis, Un. Bordeaux I 1986]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Flajolet, P., Raoult, J.C., and Vuillemin, J. The number of registers required for evaluating arithmetic expressions. Theor. Computer Science 9 (1979) 99-125.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808572</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gardner, G., Simulation of natural scenes using textured quadric surfaces. Computer Graphics 18, 3 (1984).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617445</ref_obj_id>
				<ref_obj_pid>616002</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Green, M., and Sun, H. A 1engage and system for procedural modeling and motion. IEEE Comp. Graph. &amp; Ap. , (1988) 52-64.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hail6 F., Oldeman R., and Tomlinson P. Tropical trees and forests: an architectural analysis. Springer Berlin 1978,]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Honda, H. Description of the form of trees by the parameters of the tree-like body: effects of the branching angle and the branch length of the shape of the tree-like body, J. Theor. Biol. 31 (1971), 331-338.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Horton, R.E. Erosioned development of systems and their drainage basins, hydrophysical approach to quantitative morphology. Bull. Geol. Soc. America 56 (1945), 275-370.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801284</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kawaguchi, Y. A morphological study of the form of nature. Proceedings of SIGGRAPH '82 (July 1982). In Computer Graphics 16, 3 (1982), 223-232.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Kemp, R. The average number of registers needed to evaluate a binary tree optimally. Acta Infor. 11 (1979), 363-372.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>280635</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Knuth, D.E. The Art of Computer Programming. col. 3, Addison-Wesley, Reading (1973).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Leopold, L.B. Trees and streams: the efficency of branching patterns, J. Theor. Biol. 31 (1971), 339-354.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Lienhardt, P. Moddlisation et gvolution de surfaces libres. Ph.D. Thesis, Univ. Louis Pasteur, Strasbourg (1987).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Lienhardt P. &amp; Franqon J.Vegetal leaves synthesis. Proc. COGNITIVA'87 (Paris La Villette,May 18-22,1987)212-18.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[MacMahon, T.A. The mechanical design of trees. Scientific American 233 (1975), 92-102.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, B, The fractal geometry of nature. Freeman &amp; Co., San Francisco (1982).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807485</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Marshall, R., Wilson, R., and Carlson, W. Procedure models for generating three-dimensional terrain. SIGGRAPH '80, Computer Graphics 14, 3 (July 1980), 154-162.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Meier A., Moon J.W. &amp; Pounder J.R. On the order of random channel networks. SIAM J. Alg. Disc. Mat. 1 (I 980) 25-33.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Mendes-France M., De l'arbre de Leonardo da Vinci d la thdorie de la dimension. Rev. du Palais de la D6couverte, Paris, 10 (1981), 52-60.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Naudin, J.J., and Prud'homme, R, Mdthodes d'analyse morphologiques et morphostructurales d'interprdtation des topogra.phies et des bathymdtries dans les domaines continentaux matins. Bull. de l'Inst, de Gdologie du Bassin D'Aquitaine 10 (1971) 111-114]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Niemeyer, L., Pietronero, L., and Wiesmann, A.J. Fractal structure of dielectric breakdown patterns. Phys. Rev. Letters 52 (1984) 1033.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Nittmann, J,, Daccord, G., and Stanley, H.E. Fractal growth of viscous fingers. Nature 314 (1985) 141-144.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>12859</ref_obj_id>
				<ref_obj_pid>12858</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Niklas, K.J,, Computer-simulated plant evolution. Scientific American (1986) 78-86.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer, P. Real time design and animation of-f rectal plants and trees. Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1985). In Computer Graph. 20, 4 (1986), 55-64.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Penaud, J.G. The ramification matrix of random binary trees. Research report, LABRI n~ 8832 , D6partement d'Informatique, Universit6 de Bordeaux I (1988).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Percheron, G., Principles and methods of the graph theoretical analysis of natural binary arborescences. J. Theor. Biology 99 (1982) 509-552.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Prud'homme, R., and Vigneaux, M. Mdthodes rnorphologiques et morphostructurales appliquies d l'dtude des rdseau.x hydrographiques du Bordelais. Revue gfographique des Pyr~n6es du Sud-Ouest 41 (t970), 5-14.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16608</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz P.Graphical applications of L-systems. Proc. of Graphics Interface '86-Vision Interface'86 (1986),247-53]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378503</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, P., Lindenmayer, A., and Hanan, J. Developmental models of herbaceous plants for computer imagery purposes. Proceedings of SIGGRAPH '88 (Atlanta, August 1-15, 1988).In Computer Graph. 22, 4(1988), 141-150.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Reeves, W.T. &amp; Blau, R.Approximate and probabilistic algorithms for shading and rendering structured particle systems Proceedings of SIGGRAPH '85 (San Francisco, CA, july 22-26, 1985).In Computer Graphics 19, 3 (1985), 313-322.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Sawada, Y., Dougherty, A., and Gollub, J.P. Dentritic and fractal patterns in electrolytic metal deposits. Phys. Review Letters 56 (I 986) 1260-t263.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Smith, A.R., Plants, fractals, and formal languages. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). Computer Graphics 18, 3 (1984), 1-10.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Stevens, P.S. Patterns in Nature. Little, Brown &amp; Co., Boston (1974).]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Strahler, A.N.Hypsometric (area-altitude) analysis of erosional topology. Bull. Geol. Soc. Amer. 63 (1952) 1117-42.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[VanDamme, H., Obrecht, F., Levitz, P., Gatineau, L., Laroche, C. Nature 320 (1986), 73 I.]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Vannimenus, J., On the shape of trees: tools to describe ramified patterns. Proc. sum. school in Theor. Physics, Les Houches (1987).]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Vannimenus, J., and Viennot, X.G. Combinatorial Tools for the Analysis of Ramified Patterns. J. Star. Physics, 54 (I989) 1529-1538.]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Vauchaussade de Chaumortt, M., artd Viennot X.G. Enumeration of RNAs secondary structures by complexity, in Mathematics in Medecine and Biology, Lecture Notes in Biomathematies n~57, Capasgo, V., Grosso, E., and Paven- Fontana, S.L., eds., Springer-Verlag, Berlin (1985), 360-365.]]></ref_text>
				<ref_id>45</ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Witten, T.A., and Sanders, L.M. Phys. Rev. 47 (1981) 1400.]]></ref_text>
				<ref_id>46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Woldenberg, M.J. A structural taxonomy of spatial hierarchies, in Colston papers,v. 22,Butterworth Sci. Publ., London (1970) 147-175.]]></ref_text>
				<ref_id>47</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 Combinatorial Analysis of Ramified Patterns and 
Computer Imagery of Trees Xavier Gdrard Viennot 1, Georges Eyrolles 1, Nicolas Janey 2, Didier Arquds 
2 1. LABRI, D6partement ffInforrnatique, Universit6 de Bordeaux I, FRANCE (U.A. CNRS 0726) 2. LIB, D~partement 
d'Informatique, Universit~ de Franche-Comt~, FRANCE (U.A CNRS 0822) Abstract Herein is presented a new 
procedural method for generating images of trees. Many other algorithms have already been proposed in 
the last few years focusing on particle systems, fractals, graftals and L-systems or realistic botanical 
models. Usually the final visual aspect of the tree depends on the development process leading to this 
form. Our approach differs from all the previous ones, We begin by defining a certain "measure" of the 
form of a tree or a branching pattern. This is done by introducing the new concept of ramification matrix 
of a tree. Then we give an algorithm for generating a random tree having as ramification matrix a given 
arbitrary stochastic triangular matrix. The geometry of the tree is defined from the combinatorial parameters 
implied in the analysis of the forms of trees. We obtain a method with powerful control of the final 
form, simple enough to produce quick designs of trees without loosing in the variety and rendering of 
the images. We also introduce a new rapid drawing of the leaves. The underlying combinatorics constitute 
a refinment of some work introduced in hydrogeology in the morphological study of river net-works. The 
concept of ramification matrix has been used very recently in physics in the study of fractal ramified 
patterns, CR Categories and Subject Descriptors : 1.3.5 [Computer Graphics]: Computational Geometry and 
Object Modeling. L3.7.[Computer Graphics]: Three-Dimensional Graphics and Realisms. J.3 [Life and Medical 
Sciences]: Biology. J.5 [Arts and Humanities]: Arts, fine and performing. General terms: Trees, plants, 
algorithms, realistic image synthesis, figurative image synthesis Additional keywords and phrases: branching 
patterns in physics, stochastic modeling, analysis of form, fractals, self-similarity, combinatorics, 
ramification matrix 1. Introduction Computer Image Synthesis generation of trees and plants has been 
the subject of many papers in the past few years. Let us mention for example : Marshall, Wilson, Carlson 
[24], Kawaguchi [16], Reeves, Blau [37], Gardner [11], Aono, Kunii [1], Smith [39], Bloomenthal [4], 
Niklas [30], Demko, 1. LABRI, D6partement d'Informatique, Universit6 de Bordeaux I, 33405 Talence, FRANCE 
- T61.: (33) 56 84 60 85 2. LIB, d6partement d'Informatique, Universit6 de Franche-comt6, 25030 Besan~on, 
FRANCE - T61.: (33) 81 66 64 63  Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. Hodges, Naylor [7], Oppenheimer [31], Prusinkiewicz [35], Beyer et Friedel [3], 
Prusinkiewicz, Lindertmayer et Hanan [36], De Reffye, Edelin, Franqon, Jaeger, Puech [8]. In these works, 
tree generation was mainly made at two levels. The first one is the generation of the topological (combinatorial) 
tree underlying the real tree. In general, this topological tree is binary or ternary. The second level 
is the generation of the geometrical tree. Each method applies a more or less sophisticated geometrical 
model to the topological tree. The minimum geometry consists in a 2D-drawing of trees, with width and 
length choices for each branch and angle choices for each branching node. A more sophisticated geometry 
consists in a 3D visualization to which are added vegetal elements (leaves, flowers), bark texture on 
branches and outside constraints such as light, wind or gravity. In all previous mentioned works, these 
two topological and geometrical levels are more or less separated during the gene- ration. These methods 
can be roughly classified as follows : -Fixed topology methods, like the ones of Kawaguchi [16], Aono 
&#38; Kunii [1] which only generate perfect trees. Due to the lack of variation of topology, geometry 
is of great importance in order to create a large diversity of forms. -Generation methods by development 
models which include a real growth strategy of trees. For example : generation by fractals of Mandelbrot, 
Oppenheimer [31], or by stochastic and recursive growth of branching nodes, Niklas [30]; generation by 
rewriting rules using L-systems theory developed by Lindenmayer, Smith [39], Prusinkiewicz [35], Prusinkiewicz, 
Lindenmayer, Hanan [36]; generation by a botanical development model De Reffye, Edelin, Fran~on, Jaeger, 
Pueeh [8], Papers [16],[I],[37],[4], [31] essentially focus on geometry, while papers [3], [8], [35], 
[36], [39] are mainly interested in the development of topology. These various methods use geometry in 
order to obtain the final shape (or form) of the tree. The aim is to realize realistic drawings of plants 
and trees. All above mentioned methods focus mostly on the parameters involved in the development process, 
rather than on the direct control of the final shape. The fact that the shape is implicitly contained 
in its history, is a well known concept : D'Arcy Thompson [6], Hall~, Oldeman and Tomlinson [13]. In 
this paper a new approach, different from previous ones, is proposed, separating shape from deve- lopment. 
In order to obtain better control of the final shape, we first stress on the necessity of defining numerical 
para- meters which allow a certain measure of shape of the tree, i.e. allowing the numerical evaluation 
of features as thorny, dense, slender, well built or bushy. Herein, the shape of tree is measured by 
introducing the new notion of ramification matrix. This matrix is a triangular &#38;#169;1989 ACM-0-89791-312-4/89/007/0031 
$00.75 31  ,'.,,~~SIGGRAP H '89, Boston, 31 July-4 August, 1989 stochastic one, associated with each 
tree or ramified structure. Depending only on the underlying topological tree, this matrix is defined 
from the combinatorial notions of branch order and branching node biorder. These notions constitute a 
refinement of some concepts introduced by the hydrogeolo- gists Horton [15] and Strahler [41] in the 
morphological study of river networks. Our study shows that many visual characte- ristics connected with 
the shape of the tree, are reflected in the associated matrix. Very recently, this notion has been used 
in physical study of' fraetal ramified structures, Vannimenus, Viennot [43], [44]. Our method consists 
in the choice of a ramification matrix and then random generation of a combinatorial tree whose ramification 
matrix is the one chosen (or very similar). At last an elementary 2D geometry is defined. The main idea 
is to con- trol the width and length of branches, the angles of branching nodes by linear, polynomial 
or exponential laws in terms of the order mad biorder parameters. The advantage is in a better control 
of the shape. The method is simple and fast while keeping a great variety of possible forms. Although 
this theo- retical model moves away from the botanical ones, a realistic rendering can be obtained. For 
this purpose, we introduce a fast leaf drawing algorithm. Our method also seems well adapted for obtaining 
figurative trees as could be painted by artists. 2. Horton-Strahler analysis for binary trees 2.1. Binary 
trees and botanical trees In order to avoid confusion between botanical tree, topological tree or geometrical 
tree, we recall a few concepts from theoretical computer science, see for example Knuth [18]. A binary 
tree is defined by a set of vertices or nodes, joined by edges. There are two kinds of vertices : the 
internal nodes (or branching nodes) and the external nodes (or terminal nodes). Each internal node has 
two sons : a left and a right son, the external nodes having no sons. An internal node is called the 
father of its sons. The edges join a father with each of its sons. The root of the tree is the unique 
node with no father. It will be convenient to add an extra edge from this root, called the root edge 
(see Figure 1). To each natural branching pattern, one can associate an underlying topological tree. 
Generally, this tree can be considered as a binary tree. In botany, the binary tree edges are referred 
to as branch segments. 2.2. Order and segments The vertices of a binary tree are labeled by the following 
recursive procedure. The terminal nodes are labeled 1. If the two sons of a node v are labeled i and 
j, then the label of the node v is ord(v) = max(i,j) if ~j ; = i+l if i=j. The label ord(e) of an edge 
e going from the vertex v to one of its sons y is the label of y. The label of a node (resp. edge) is 
called the order of this node (resp. edge) (Figure 1). ___.___-: External or \1 / ~ terminal nodes 1 
1 ~ \1 J~ Internal or . 7~ / ~ branching nodes  Root ~ I~Root e~So Figure 1. Order and Strahler number 
in a binary tree. The order of the root edge (that is the order of the root) is called the Strahler 
number of the tree. A segment of order k is a maximal sequence of consecutive edges having order k. The 
notions of order and segment have been introduced in hydro- geology by Horton [15] (in a slightly different 
form), and by Strahler [41]. Observe that this concept of order is different from the one usually introduced 
in the botanical study of trees. In [8] the notion of order is defined from the development history of 
the tree. When this history is unknown, for each node the distinction between the so-called "straight 
edge" and "lateral edge", as in [36], is arbitrary. Herein neither deve- lopment history nor arbitrary 
convention are required. 2,3. Horton-Strahler analysis in hydrogeology and other sciences. A river network 
is supposed to be without islands and triple (or multiple) junction points. Thus, the underlying topologi- 
cal tree is a binary tree. Many studies have been carried out in hydrogeology in order to examine river 
network morphology. In particular, the concept of bifurcation ratio 1~, of order k has been introduced. 
If b k is the number of order k segments, then 13 k is the ratio bk.1/bk. For example, the binary tree 
in Figure 1 has bifurcation ratios 1~z=8/2=4, B3=2/1=2. These ratios give certain information about the 
"shape" of the binary tree. For example the trees in Figures 2, 3 are two extreme cases. The perfect 
tree of height 3 (each terminal node has the same height, Fig. 2) has all segments reduced to the edges: 
each bifurcation ratio is equal to 2 (this is the minimum possible value). For the very thin tree (Fig. 
3) there is one segment of order 2, each terminal edge is a segment of order 1, the bifurcation ratio 
of order 2 is equal to the number of terminal nodes and can be arbitrarily large. Figure 2. Perfect tree 
Figure 3. "Very thin" tree. Geologists have observed that bifurcation ratios are usually between 3 and 
5. We define a random binary tree as a binary tree chosen at random with uniform probability among the 
C n = (2n!)/n!/(n+l)! binary trees with n branching nodes. In particular, it is known that all the bifurcation 
ratios of a random binary tree approach 4 as the number of nodes becomes larger, Meier &#38; Moon [25]. 
Similar studies have been made for other branching patterns in nature as in botany, MacMahon [221 or 
in anatomy, Wotdenberg [47] mad neurophysiology, Percheron [33]. Prud'homme and Vigneaux [34] have shown 
that there exist some correlations between the Horton-Strahler analysis of river networks and the tectonic 
structure of the subsoil. This analysis has also been made for the valley networks of submarine mountains, 
Naudin &#38; Prud'homme [27]. Quite unexpectedly, the Strahler number of a tree has also appeared in 
theoretical computer science in the study of the minimum number of registers required to compute an arithmetical 
expression, Flajolet et al. [10], Kemp [17], and in molecular biology in the study of the "complexity" 
of the form and in energy computation of nucleic acids secondary structures (RNA), Vaucbaussade de Chaumont 
&#38; Viennot [45]. 3. A new model for tree topology : the ramifica-tion matrix. 3.1. Biorder of a branching 
node. Consider a branching node of order k in a binary ~ree, having two sons with order i and j. The 
biorder of this node is the pair (k,i) if j=k and i<k, if not we have i=j=k-1 and the biorder is (k-l,k-1), 
Fig. 4. k>i Fork biorder (k,i) biorder (k-l,k-1) Figure 4. Biorder of order k branching node 3.2. Ramification 
matrix of a binary tree. For a binary tree T, we define successively the following quantities : - for 
k~_2, a k is the number of order k branching nodes - for l_<i<k, bk, i is the number of nodes of biorder 
(k,i) - for k.~_2, bk. k is the number of nodes of biorder (k-l,k-1)    ~ Computer Graphics, Volume 
23, Number 3, July 1989 -for l_<j_<k, l~j = bkj / ak. The number l:h~j is then the probability for a 
branching node of order k to have biorder (k,j). The ramification matrix ram(T) of the binary tree T 
with Strahler number s is the (s-1)xs stochastic matrix whose (k,j) term (l<_j<_k_<s,2_<k_<s) is Pkj- 
Adding the entry Pl: =1, this matrix would be a square lower triangular stochastic matrix. The ramification 
matrix of the binary tree displayed on Figure 1 is : u2 0 i/zz Table 1 The ramification matrix of a real 
tree is the one of the underlying binary tree associated to it. 3.3. Examples of ramification matrices 
3.3.1. Perfect tree 0 0 1 The ramification matrix is 0 0 0 1 Table 2 0 0 0 0 1 3.3.2. Random binary 
tree Experimental studies have shown that, as the number of nodes tends to infinity, the ramification 
matrix of a random binary tree (see definition in  2.3) approaches the matrix of Table 3. This fact 
has been rigorously proved by Penaud [32]. 1~ ~ ~ Table 3 1/2 1/4 ~ 1/16 1/16 3.3.3. Random Increasing 
binary tree One can generate binary trees randomly by the following procedure. Starting from T 1 = ~/, 
the tree having only one branching node and two terminal nodes, we generate a sequence T n of binary 
trees by the following iterative process: choose with uniform probability one of the i+1 terminal nodes 
of T~, then Tn. 1 is obtained by replacing the chosen node by T 1. Each tree T n has n internal nodes, 
but such a tree is not at all a random binary tree. It is in fact a random increasing binary tree. Such 
a tree is obtained by labelling the internal nodes in the order of substitution. The internal nodes are 
labelled 1,2 ..... n such that the label of the sons are bigger than the label of the father. The number 
of such trees is in fact n!. Observe that a random increasing binary tree is the same thing as the binary 
search tree associated to a random permutation. Experimental studies using Monte-Carlo tests show that 
the ramification matrix for large random increasing binary trees approach the matrix of Table 4 : 0.40.2 
0.60.3 0.5 1 0.1 o.2 o.3 o.a Table 4 0.05 o.1 0.2 0.3 0.35 0.025 0.05 0.1 0.2 0.3 0.325 3.3.4. Self-similar 
fern Figure 5 shows the generation of a self-similar fern. At each step of the iteration, each terminal 
edge is replaced by the elementary self-similar fern obtained after the first iteration, that is by adding 
p=6 edges to the primitive edges. For an arbitrary number p, and an arbitrary number of iterations, the 
ramification matrix has the remarkable form : 0 1-1~ 1,~, 0 0 1-1/r, lip Table 5 o o o l-lip up Figure 
5. A self-similar fem 3.4. Self-similarity In the former examples 3.3.1-4, the ramification matrix 
presents a certain property of self-similarity. By this, we mean that the variation curve of the biorder 
probability of the k th row looks the same for all the rows. In other words, if we visualize this variation 
by a curve extralx~lating the points (J,Pkd) for l<_j_<k, all the curves corresponding to each row are 
statistically correlated. We will say that the binary tree is (statistically) self-similar (for the ramification 
matrix). Note that this notion is different, although related, to the one introduced by Mandelbrot [23]. 
Ramification matrix of such a statistically self-similar tree can be visualized by a curve. Such curves 
are displayed on Figure 6. Perfect t /~ trees Viscous 0.75 ..~ Self-similar digitation ~ fern ~ = 6) 
(Phyd.csmd DLA model) 0.5 Random 0.~ Increasing Random / Binary ~ees binary trees 1 2 3 ~ Figure 6. Self-similar 
ramification matrices 3.5. Ramification matrices in physics Many studies have recently been made in 
physics concer-ning tree-like structures occuring in nature. We will quote for example electric breakdowns, 
Niemeyer, Pietronero, Wiesman [28], electrolytic metal deposit, Sawada, Dougherty, Gollub [38], tile 
so-called viscous fingers, Nittmann, Daccord, Stanley [29], VanDamme et al. [42] or the well-known Diffusion 
Aggregation Process (DLA) of Witten and Sanders [46],and Ball [2] for a survey. The patterns are (or 
approximated by) branching fractal structures. The visual aspect of these patterns is usually measured 
by physicists with a single number: the fractal mass dimension (see Mandelbrot [23]). Very recently, 
the branching structures of these patterns have been taken into account by applying the ramification 
matrix model, Vannimenus [43], Vannimenus, Viennot [44]. The viscous fingers, the 2D DLA model and the 
so-called 2D branching Eden model have been studied. The ramification matrices are again self-similar. 
The corresponding curves are close to the one corresponding to random binary trees (see Figure 6). It 
is known that, in high dimension, these models should behave as random increasing binary trees. The difference 
between the two curves (associated to random binary and random increasing binary trees) of Figure 6 shows 
the strong influence of the planarity constraint. 4. Generation and visualization of trees using ramification 
matrices 4.1. Generation of the topological tree A stochastic triangular (s-1)xs matrix R is given, together 
 with a number S_<s. The algorithm generates randomly a binary tree T having Strahter numbcI S and whose 
ramification matrix is (almost) the same as the one obtained by taking the rows 2 to S of R. This randomness 
insures a more natural aspect to the final image. The generation starts with a tree T 1 reduced to a 
single edge (its root edge) labelled S. Then, iteratively, a sequence T n of labelled binary trees will 
be constructed. The tree Tn 1 is obtained from T n by choosing one terminal edge of T a labelled k~l, 
and by dividing this edge into two edges labelled respec- tively k and i<k or both k-1. The choice (k,i) 
or (k-l,k-1) is made from a random selection according to the biorder distribution probability given 
by the k t~ row of the matrix R. The algorithm stops when all the terminal edges are labelled 1. ~t~SIGGRAPH 
'89, Boston, 31 July-4 August, 1989 Experiments show that the ramification matrix of the final tree 
T is close to the given matrix R, especially for the first rows (corresponding to the small orders) and 
when the size of the tree is sufficiently large (more than a few hundred nodes). The control of the size 
of the tree is made by choosing the Strahler number S. In the pictures below, the Strahler number is 
chosen between 5 and 10, with a size of the tree varying from a few hundred branctting nodes to several 
thousand. 4.2. Orientation of the structure In the algorithm described in 4.1, in the case of a biorder 
(k,i) with i<k, we have not completely described which edge (left or right son) receives the label k 
(this edge will be called the main edge of the branching). The second step of the method is to make this 
choice explicit. There are essentially four options in the program. The first is to make this choice 
randomly (usually with probability 1/2). The second option is to make this choice such that the main 
edges alternate (left and right) when moving along a segment of the tree. The third option is to fix 
the choice such that the main edge is always on the same side; this may give a simulation of a wind effect 
in the final image of the tree. The last option is to choose the orientation such that the main edge 
is closer to the vertical direction than the other edge. This choice cannot be decided until the coordinates 
of the branching nodes on a 2D or 3D image are computed (see below 4.3). 4.3. Generation of the geometrical 
tree The third step of our method is the application of an elementary geometry, once the topological 
tree has been obtained, by determining the position in the space of each node of the tree. By elementary 
geometry, we mean the choices (Figure 7): - for each edge e, a width W(e) and a length L(e), - for each 
branching node v, two angles 01(v ) and 02(v), -in the case of a 3D drawing, a third angle 03(v ) is 
  necessary, corresponding to the so-called phyllotaxy botani-cal phenomenon. w~wt Width r I \ I Figure 
7. The 2D geometry : width, length and two branching angles. One of the main ideas of our method is to 
make the width and length of an edge depend only on the order k of that edge, and the two angles 01 and 
02 relative to a branching node depend only on the biorder of that node. We have chosen certain arbitrary 
laws for these four parameters, corresponding to a certain aesthetic effect of the image of the tree, 
together with a certain realism from the botany; for a more precise study, see Honda [14], Leopold [19], 
Mendes-France[26], Stevens]40]. Usually, for botanical trees, as for many other natural branching patterns, 
the width of the branches decreases when moving from the root to the terminal nodes. In general, it is 
the same for the length of the branches, although the decrease is less important. Thus, it is natural 
to choose the laws of width and length as non-decreasing functions W(k) and L(k) of the order k. In the 
pictures presented below, the laws are linear or quadratic for L(k) and polynomial or exponential for 
W(k) : L(k) = c I * k or L(k) = c 1 * k 2 ; W(k) = c z * k s or W(k) = c 2 * [3 k with c 1, c 2, ~ and 
13 some numerical constants. For the choice of a, good visual aspects are obtained with a such that W(k) 
= c3 * L(k)S/2, that is a=S or S/2 in the quadratic or linear cases for the length. We also have chosen 
analog aesthetic effects and a certain amount of realism for the choice of the angle laws 0 t and 02. 
The principal idea is that the main branches should have a smaller deviation with respect to their n~tother 
branches than the less important branches of the tree. In our model, the importance of a branch is measured 
by its order. We have thus used the following laws : For a branching node with biorder (k-l,k-1), that 
is a fork, the two resulting branches have the same importance, and we set 01=02=0f, a real constant. 
For a branching node with biorder (k,i), i<k, then the respec- tive deviation angles 0rn and 07 of the 
main and secon-dary branches with their mother branch (see Figure 8) are given by 0m(k,i ) = cm*i/(k-1 
), 0,(k,i) = c,*(k-i)/(k-l) where c~ and c, are some numerical constants. k ~ ..' ..." //V k-I y, biorder 
(k-l,k-1) biorder (k,i), k<i Figure 8. Angles Of, O m, 0 s as functions of the biorder.  Good visual 
effects can be obtained with c and 0e equal 30  and c m equal 10% Of course it is possible to adopt 
any other kind of parameterization, depending on the final visual effects one desires. For 2D drawing, 
these definitions are sufficient for defining the (elementary) geometry of the tree. The coordinates 
of each node of the tree can be computed using length and angle parameterizations. As most of our pictures 
are given in 2D, we do not insist in the choice of the phyllotaxy angle 03. There are no natural reasons 
to make this angle depend on the order of the mother branch. 4.4. 21) -drawing For the purpose of quicker 
drawing, and also for a better understanding of the influence of the choice of the ramification matrix, 
we have simplified the drawing algorithm. Once the coordinates of each node have been computed, each 
edge of the underlying binary tree is represented by a line segment. This edge is visualized on the screen 
by a rectangle. The junction between the rectangles corresponding to a branching node is organized as 
shown in Fig 9. First fillingj g triangle left edge Figure 9. Jonction between branches represented by 
rectangles. In the drawing of Figure 10 (end of the paper), some rectangles have not been filled up. 
This is to show that, when the length or width of some edges is very small (a few pixels or under the 
size of a pixel) the tree may have many more branching nodes than those visualized on the screen (more 
than 1000 for the binary tree related to this figxare). Figures 10, 20 give examples of two different 
geometric laws for the width of the branches: exponential and polynomial. 5. Relationship between form 
and ramification matrix The ramification matrix is relative to the topological binary tree underlying 
the geometrical tree. The "shape" or "form" of ~ this topological tree, without any geometrical consideration, 
is obviously a purely abstract concept. The study of the relationship between the ramification matrices 
and the tree shape cart only be made with geometrical trees. It is one of the reasons for which a very 
simplified geometry (2D geometry, each edge being visualized by a rectangle) has been defined, in order 
to avoid a too important influence from this geometry upon the relationship'study between shapes and 
matrices. The parameters and geometrical laws chosen for the photos of the trees in this section, are 
always the same. 5.1. Self-similar matrices Two typical matrices leading to very different visual results 
are those given by above given Tables 3 &#38; 4, i.e. the ramifica-tion matrices of random binary trees 
and of random increasing binary trees. In the first case (Figure 11) we obtain rather airy trees with 
a slender or bushy shape, with a few long segments where many thorns are settled, i.e. branching nodes 
of biorder (k,1) (these thorns are too small to be seen in the photo in Fig. 11). The thorns and the 
small subtrees associated to the biorder (k,2) concentrate 75% of the biorder probabi-lities. The second 
matrix gives rise to a family of trees which contains many more important branches and are more well 
balanced (Fig. 12). In this matrix, 60% to 70% of biorder pro-babilities are concentrated on the 2 last 
values (diagonal and sub-diagonal).The "well-balanced" aspect is due to the high probability of the biorder 
(k-l,k-1) giving rise to many forks (however without reaching the totally well-balanced aspect of the 
perfect tree). Very few thorns or small subtrees appear on high order branches. The matrix of Table 6 
is similar to the one of random increasing binary trees, except for the biorders (k-l,k-1) whose probability 
has mainly been reduced, while maintaining a high probability for the biorders (k,k-1). This matrix looks 
like a self-similar one (at least for the orders >_4). This leads to quite well-balanced trees (Fig. 
13), with few forks and then long segments of constant order (and then of constant thickness). These 
long segments appear at all levels of the tree (for all the orders). F0.25 0.5 0.5 0.25 1 0.125 0.25 
0.5 0.125 Table 6, /0.0625 0.125 0.25 0.5 0.0625 / /0.0313 0.0625 0.125 0.25 0.5 0.0312 / L0.0t56 0.0313 
0.0625 0.125 0.25 0.5 0.0156 0.1 0.1 0.8 0.1 0.1 0.1 0.7 Table 7 0.1 0.1 0.1 0.6 0.1 0.1 0.1 0.1 0.1 
0.5 0.1 0.10.l 0.i 0.I O.l 0.4 0.I 5.2. Operations on ramification matrices  Two types of operations 
can be applied to ramification matrices : the shuffle and the linear combination of several matrices. 
The shuffle consists of forming a matrix whose it first lines are the i1 first lines of a ramification 
matrix R1; then whose i2 following lines are the lines i1+1.....i~+i2 of a ramification matrix R2; and 
so on for the following lines with matrices R3, .... Rm. Generally, the matrices R1..... Rm are chosen 
autosimilar. The shuffle operation allows the generation of non (statistically) autosimilar trees ( 
3.4). An example is given in Figure 14. This tree is generated from a matrix which is the shuffle of 
three matrices. The lines of order 2, 3, 4 are issued from the perfect tree matrix (Table 2), the lines 
5,6 from the random binary tree matrix (Table 3), the lines 7,8 from the random increasing binary tree 
matrix (Table 4). The generated tree inherits (statistically) features of the three corresponding families 
of trees, each one at a different level : the important ComputerGraphics,Volume23, Number3, July 1989 
branches, i.e. of high order, are bushy as in a random increasing binary tree (Figure 12), then the intermediary 
bran-ches become slender as in a random binary tree, simulating regrowth on old branches (Figure 11), 
finally the terminal branches become small perfect trees simulating inflorescen-cos. Note that these 
perfect trees have a random order (2,3 or 4) and that they replace the "thorns" which exist in great 
quantity on a random binary tree. The matrix in Table 7 is a shuffle of a matrix similar to the matrix 
of the tree in Figure 13 and a matrix similar to the one of a perfect tree. Figure 15 shows a tree generated 
by this matrix, with long main branches, on which grow many almost perfect trees making a bunch effect. 
The tree in Figure 16 is generated by the random increasing binary tree matrix of order 6, to which is 
added the line of order 7 : (0.8;0;0;0;0;0;0.2). This shuffle implies the appearance of many thorns on 
the trunk (i.e. the segment of highest order). The algorithm applying the length branch law, leads to 
a length increasing effect of the trunk. If the geometrical size of order one branches is under the pixel 
size, we shall only see the increase of the trunk, without the introduced thorns. Obviously, this effect 
can be introduced at every branch level in the tree. A second possible operation on ramification matrices 
is the linear combination. In practice, we limit ourselves to two matrices R and M. If k and i.t are 
positive reals such as k+la=l, we introduce the (triangular stochastic) matrix kR+gM. By continuously 
varying k from 0 to 1, we can progressively go from the family of trees associated to the matrix M to 
the one associated with R. 5.3. Alternative tree generation : constraints related to segments Most photos 
in this paper are obtained by the random generation algorithm (cf section 4.1) guided by the given ramification 
matrix. The final shape results from the combina-tion of two components : the stochastic growth and the 
start parameters. It is possible to minimize the importance of the stochastic component, and then to 
obtain greater control of some parts of the tree. Such an alternative of our generation method is called 
constraint by segment : instead of generating the tree, cf 4.1, by random selection (according to the 
given matrix proba-bilities Pk.i or Ilk.k),of the biorder (k,i) or (k-l,k-1) of a mother edge labelled 
k>l, we impose a number of branching nodes on the order k segment associated with this edge. This number 
is also called length of the segment. One rule is to take the average value of this length as. the integer 
part of the inverse of the fork probability Pk,k. The selection can be exact or gaussian around this 
average value. The biorders of branching nodes different from the end branching node of the order k segment 
are randomly chosen, as in section 4.1, with the help of probabilities Pk,i (i<k). The ramification matrix 
of the generated tree will be quite near the one given initially, but visual effect will be different. 
More regular structures will appear. An example is given in Figure 17 : the tree contains only one very 
long segment of order 3, to which join segments of order 2. In fact these segments are themselves composed 
of a multitude of small line segments representing the edges of the binary tree. The edges of order 1 
are too small and do not appear on the screen. This gives the "aerial" effect of floating filaments, 
although we have not changed geometric laws. Another strategy consists in choosing segment lengths independently 
from the ramification matrix. A possible rule is to choose little order segments with lengths equal to 
1, i.e. as if fork probability Pk.k was equal to 1. This introduces perfect :'L~r~SIGG RAPH '89, Boston, 
31 July-4 August, 1989 trees at the branch tips. Obviously, with this method, the ramification matrix 
of the generated tree could be more different than the one given. An example is visuallsed in Figure 
18 which seems to simulate an herbaceous plant. 6. The leaf model In order to obtain realistic drawings 
(Figures 22 to 27), we describe herein a model for drawing leaves. Such an efficient and fast algorithm 
is primordial to draw trees with hundreds of branches and then thousands of leaves. 6.1 The leaf drawing 
model As shown in Figure 19, a leaf is made of an arborescence of "veins" immersed in the limb (body 
of the leaf once we have removed the veins). In a first approximation, the leaf is supposed to be flat 
and the underlying arborescence is a ternary tree except at the leafstalk (or petiole) where the aritty 
can take any odd value. Below, we call main vein a sequence of central edges issued from the petiole, 
and secondary vein, an edge issued from a main vein. We consider in the following that there is no deeper 
veins than secondary ones. A lobe is then constituted of a main vein, its secondary veins and the border 
surrounding the part of the limb associated to this main vein (border whose geometry is not specified 
at this level : polygonal, smoothed, far from or near the terminal nodes). The topological leaf structure 
is defined by : 1) The number of lobes; 2) The "size" of the leaf, given by the number n of nodes on 
the central main vein. The number of nodes on each other main vein issued from the petiole being a simple 
function (usually decreasing) of n and of the "distance" between this vein and the central one. The geometrical 
leaf structure is then obtained by defining: 1) The positions of nodes with the help of 3 parameters 
: two angles A and 6 and a length law L for arborescence edges. A is the angle between two successive 
main veins, and 6 is the angle between a secondary nervure and its main vein. The length L(d) of an edge 
is an increasing function of the "depth" d of the edge (d is the distance between the initial vertex 
of the edge and the final vertex of the main vein of the lobe). Three laws have been tested (the last 
one giving the best results) : (1) L(d) = Cte, (2) L(d) = A*d + B, (3) L(d) = A'Log(1 + d)+ B. If two 
veins cross, one of the end segments is deleted. 2) The border of each lobe as a polygon joining the 
root and points in the continuation of the veins determined from the terminal nodes by a multiplicative 
factor. The limb border is then the polygon obtained by joining parts of each lobe border belonging to 
this limb border (see Figure 19). This polygonal representation is sufficient when the leaves are drawn 
with a little size on the tree (seen from far, see Figures 22 to 25), allowing a fast drawing algorithm 
of a tree with its foliage. In the foliage of a tree, leaves being mixed, it is necessary to distinguish 
them by various colors. A very realistic aspect is obtained by gradation of colors (see Figure 21). To 
this aim, each lobe color gradation is obtained by two operations : (1) an affinity whose axis is the 
lobe main vein, whose direction is the one of the secondary veins and whose ratio varying between 0 and 
1 gives the color gradation by a function ; (2) an homothety whose center is the root of the arborescence. 
When we need to represent a realistic leaf, the limb border must be smoothed. This is done by interpolation 
with the help of cubics of each lobe border polygonal segment (each seg- ment is replaced by a cubic 
which is given by its two extre- mities and two associated tangent vectors, see Figures 19,21). Such 
a method for modeling leaves using an underlying tree has already been introduced by Prusinkiewicz et 
A1. [36]. They use L-systems. As in our method for generating trees, our leaf drawing algorithm separates 
growth and topology, the 36 topology being the dominant feature from which is issued the geometry. Our 
model differs from the one of P. Lienhardt [21] by using simple combinatorial tree structures instead 
of planar maps. This allows a faster drawing algorithm issued from an easy leaf topological modeling 
while obtaining a large diversity of forms (see Figure 21). The method proposed by Bloomenthal [4] allows 
the visualization and the positioning of a digitalized leaf (the maple leaf) with the help of an added 
polygonal structure for a 3D aspect simulation. The method is quite different from ours : his aim is 
not to propose a general leaf model. Other fraetal approaches appear, given in Oppenheimer [31], in which 
the external boundary shape of the leaf is the limit of the recursi~e fractal growth of the internal 
veins, and in Dernko et al. [7] who generates leaves as fractal sets, using iterated function systems. 
CentralMain Main veins vein Limb Petiole - " Figure 19. Leaf geometry. 6.2 Spot models A faster algorithm 
can be obtained by replacing real leaves by spots. These spots can merely constitute a cloud of color 
points (two side background trees in Figure 27), or polygonal spots instead of points (the two foreground 
trees in Figure 27). 7. Realistic rendering The visualization in two dimensions allows some realism by 
generating trees with a sufficiently great size if leaves are drawn with a 3D arrangement, see figures 
22 to 27. The leaves are settled on the tree with a rule dependant upon the branch order. They are disposed 
stochastically with a great density for little order branches and a null density for high order branches. 
Of course, it is not possible to generate a diffe- rent leaf each time. The geometrical representation 
of the wanted leaf is kept in memory and modified by two types of transformations before being drawn 
in the tree according to the above rule. These two transformations preceding the drawing of a leaf are 
an homothety of the whole leaf, the final size being chosen along a stochastic law, and a rotation of 
the leaf in the three dimensions, with possible respect to a certain law (in order to obtain special 
effects, such as wind or gravity). The bark texture on the branches in Figures 12, 13, 22 and 24 is obtained 
by drawing random dotted vector lines of a different color along the direction of the branch. Irregularities 
(as dead branches, growth, abnormality, pruned tree effect) can also be simulated, if we stop the generation 
algorithm in section 4.1 before reaching order one branches, while keeping the geometric laws of 4.3 
in the tree geometric drawing (the order k being replaced by the label of the branch which can be different 
in that case). Color photos are made on IBM PSI2 8580, screen 8514A, resolution 1024x768 (256 colors). 
On this computer, the generation time for the topology and the geometry of the tree of Fig. 22 (with 
1500 internal nodes) is below one second; the execution time for drawing this tree without foliage is 
about 20 seconds, with about 3000 polygonal spots is one minute. A simplified version (without foliage) 
has been implemented on Apple Macintosh by Yves Chiricota (UQAM, Montrgal). 8. Conclusion Topology is 
essential in the herein given method which allows the analysis of a ramified structure, independently 
from @ ~ Computer Graphics, Volume 23, Number 3, July 1989 its history. This leads to a ramification 
matrix which is the expression of the main features of the ramified structure form. As shown, this matrix 
allows one a powerful control of the final form and is a tool for image synthesis of ramified structures 
with such characteristics. This association between image analysis and image synthesis is one of the 
interesting points of this method. The association of a geometry depending only on the combinatorial 
parameters order and biorder, with art easy and fast leaf drawing algorithm, is a good compromise between 
speed and final rendering, while keeping a great diversity of possible forms. Such an easy and fast method 
is of practical interest in order to implement an interactive environment for tree creation and animation, 
in various domains (Botany, arts, architecture,...). The scientific significance occurs then in analysis 
and synthesis of tree-like structures which are not necessarily botanical ones, for example in physics 
(electric breakdowns, viscous fingers, DLA,...) and in molecular biolo- gy (RNA secondary structures). 
In particular, the ramification matrix model has been applied recently in physics to branching fractal 
structures [43] [44]. Further research : -Development of an interpreter for ramified structure modeling 
(see [12]). Our method clearly separating the different structure levels (sections 4.1, 4.2, 4.3, 4.4, 
5) is well adapted to this aim. -We could animate the growth algorithm by keeping up to date the orders 
and biorders of the tree under construction (at each random choice of the biorder of a terminal node, 
the order changing edges are necessarily on the unique tree-path leading from the root to this node). 
-This method seems to be promising for figurative tree drawing with a certain artistic quality. -Generalization 
to any arity (e.g. ternary) tree (this is already done in the combinatorial situation by Vauchaussade 
de Chaumont &#38; Viennot [45]). Work Partially supported by PRC Mathrmatiques et Informatique References 
 [1] Aono M., and Kunii T.L. Botanical tree image generation, IEEE Computer Graphics &#38; Applications 
4,5 (1984),10-34. [2] Ball, R.C. DLA in the real world, in On growth and form: fractal and non-fractal 
patterns in Physics, Stanley, H.E., and Ostrowski, N., eds., Martinus Nijhoff, Boston (1986) 69-78. [3] 
Beyer, T., and Friedel. M. Generative scene modelling. Proceeding of EUROGRAPHICS '87 (1987),151-158 
&#38; 571. [4] Bloomenthal, J. Modeling the Mighty Maple. Proceedings of SIGGRAPH '85 (San Francisco, 
CA, July 22-26, 1985). In Computer Graphics 19, 3 (1985), 3054311. [5] Cole, V,C. The artistic anatomy 
of trees. Dover Publication, N-Y (1965) (orginaUy Seely Servi &#38; Co., Lond., 1915). [6] D'Arcy Thompson, 
W. On growth and form. University Press, Cambridge, 2rid ed., (1952). [7] Demko, S., Hodges, L., and 
Naylor, B. Construction offractal objects with iterated function systems. Proceedings of SIGGRAPH '85 
(San Francisco, CA, July 22-26, 1985). In Computer Graphics 19, 3 (I985), 271-278. [8] De Reffye, P., 
Edelin, C., Franqon, J., Jaeger, M., Puech, C. Plant Models Faithful to Botanical Structure and Development. 
Proceedings SIGGRAPH '88 (Atlanta, August 1-15, 1988). Computer Graphics 22, 4(1988),151-158, [9] Eyrolles 
G. Synth~se d'images figuratives d'arbres par des mdthodes combinatoires. Ph.D. Thesis, Un. Bordeaux 
I 1986 /10] Flajolet, P., Raouh, J.C., and Vuillemin, J. The number of registers required for evaluating 
arithmetic expressions. Theor. Computer Science 9 (1979) 99-125. [11] Gardner, G., Simulation of natural 
scenes using textured quadric surfaces. Computer Graphics 18, 3 (1984). [12] Green, M., and Sun, H. A 
langage and system for procedural modeling and motion. IEEE Comp. Graph. &#38; Ap. , (1988) 52-64. [13] 
Hall6 F., Oldeman R., and Tomlinson P. Tropical trees and forests: an architectural analysis. Springer 
Berlin 1978. [14] Honda, H. Description of the form of trees by the parameters of the tree-like body: 
effects of the branching angle and the branch length of the shape of the tree-like body, J. Theor. Biol. 
31 (1971), 331-338. [15] Horton, R.E. Erosioned development of systems and their drainage basins, hydrophysical 
approach to quantitative morphology. Bull. Geol. Soc. America 56 (1945), 275-370. [16] Kawaguchi, Y. 
A morphological study of the form of nature. Proceedings of SIGGRAPH '82 (July 1982). In Computer Graphics 
16, 3 (1982), 223-232. [17] Kemp, R. The average number of registers needed to evaluate a binary tree 
optimally. Acta Infor. 11 (1979), 363-372. [18] Knuth, D.E. The Art of Computer Programming. col. 3, 
Addison-Wesley, Reading (1973). [19] Leopold, L.B. Trees and streams: the efficency of branching patterns, 
J. Theor. Biol. 31 (1971), 339-354. [20] Lienhardt, P. Moddlisation et gvolution de surfaces libres. 
Ph.D. Thesis, Univ. Louis Pasteur, Strasbourg (1987). [21] Lienhardt P. &#38; Franqon J.Vegetal leaves 
synthesis. Proc. COGNITIVA'87 (Paris La Villette,May 18-22,1987)212-18. [22] MacMahon, T.A. The mechanical 
design of trees. Scientific American 233 (1975), 92-102. [23] Mandelbrot, B. The fractal geometry of 
nature. Freeman &#38; Co., San Francisco (1982). [24] MarshaR, R., Wilson, R., and Carlson, W. Procedure 
models for generating three-dimensional terrain. SIGGRAPH '80, Computer Graphics 14, 3 (July 1980), 154-162. 
[25] Meier A., Moon J.W. &#38; Pounder J.R. On the order of random channel networks. SIAM J. Alg. Disc. 
Mat. 1 (1980) 25-33. [26] Mendes-France M., De l~rbre de Leonardo da Vinci d la thdorie de la dimension. 
Rev. du Palais de la Drcouverte, Paris, 10 (1981), 52-60. [27] Naudin, J.J., and Prud'homme, R, Mdthodes 
d'analyse morphologiques et morphostructurales d'interprdtation des topogra.phies et des bathymgtries 
dans les domaines continentaux matins. Bull. de l'Inst, de Gdologie du Bassin D'Aquitaine 10 (1971) 111-114 
[28] Niemeyer, L., Pietronero, L., and Wiesmann, A.J. Fractal structure of dielectric breakdown patterns. 
Phys. Rev. Letters 52 (1984) 1033. [29] Nittmann, J,, Daccord, G., and Stanley, H.E. Fractal growth of 
viscous fingers. Nature 314 (1985) 141-144. [30] Niklas, K.J,, Computer-simulated plant evolution. Scientific 
American (1986) 78-86. [31] Oppenheimer, P. Real time design and animation offractal plants and trees. 
Proceedings o:f SIGGRAPH '86 (Dallas, Texas, August 18-22, 1985). In Computer Graph. 20, 4 (1986), 55-64. 
[32] Penaud, J.G. The ramification matrix of random binary trees. Research report, LABRI n  8832 , Drpartement 
d'Informatique, Universit~ de Bordeaux I (1988). [33] Percheron, G., Principles and methods of the graph 
theoretical analysis of natural binary arborescences. J. Theor. Biology 99 (1982) 509-552. [34] Pmd'homme, 
R., and Vigneaux, M. Mdthodes rnorphologiques et morphostructurales appliquies d l'dtude des rdseaux 
hydragraphiques du Bordelais. Revue grographique des Pyr~nres du Sud-Ouest 41 (t970), 5-14. [35] Pmsinkiewicz 
P.Graphical applications of L-systems. Proc. of Graphics Interface '86-Vision Interface'86 (1986),247-53 
[36] Prusinkiewicz, P., Lindenmayer, A., and Hanan, J. Developmental models of herbaceous plants for 
computer imagery purposes. Proceedings of SIGGRAPH '88 (Atlanta, August 1-15, 1988).In Computer Graph. 
22, 4(1988), 141-150. [37] Reeves, W.T. &#38; Blau, R.Approximate and probabilistic algorithms for shading 
and rendering structured particle systems Proceedings of SIGGRAPH '85 (San Francisco, CA, july 22-26, 
1985).Jn Computer Graphics 19, 3 (1985), 313-322. [38] Sawada, Y., Dougherty, A., and Gollub, J.P. Dentritic 
and fractal patterns in electrolytic metal deposits. Phys. Review Letters 56 (1986) 1260-t263. 37  
    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74337</article_id>
		<sort_key>41</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[The synthesis and rendering of eroded fractal terrains]]></title>
		<page_from>41</page_from>
		<page_to>50</page_to>
		<doi_number>10.1145/74333.74337</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74337</url>
		<abstract>
			<par><![CDATA[In standard fractal terrain models based on fractional Brownian motion the statistical character of the surface is, by design, the same everywhere. A new approach to the synthesis of fractal terrain height fields is presented which, in contrast to previous techniques, features locally independent control of the frequencies composing the surface, and thus local control of fractal dimension and other statistical characteristics. The new technique, termed <i>noise synthesis</i>, is intermediate in difficulty of implementation, between simple stochastic subdivision and Fourier filtering or generalized stochastic subdivision, and does not suffer the drawbacks of creases or periodicity. Varying the local crossover scale of fractal character or the fractal dimension with altitude or other functions yields more realistic first approximations to eroded landscapes. A simple physical erosion model is then suggested which simulates hydraulic and thermal erosion processes to create gloabl stream/valley networks and talus slopes. Finally, an efficient ray tracing algorithm for general height fields, of which most fractal terrains are a subset, is presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39053292</person_id>
				<author_profile_id><![CDATA[81100233090]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Musgrave]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yale University Department of Mathematics, Box 2155 Yale Station, New Haven, Connecticut]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P37153</person_id>
				<author_profile_id><![CDATA[81100640935]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Kolb]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yale University Department of Mathematics, Box 2155 Yale Station, New Haven, Connecticut]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P233956</person_id>
				<author_profile_id><![CDATA[81100138521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Mace]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics, Inc., 2011 N. Shoreline Boulevard, Mountain View, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>19647</ref_obj_id>
				<ref_obj_pid>19644</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ahuja, S., N. Carriero, and D. Gelerenter, "Linda and Friends," IEEE Computer, August, 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325176</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bouville, Christian, "Bounding Ellipsoids for Ray-Fractal Intersection," Computer Graphics, vol. 19, no. 3, pp. 45-52, July 1985.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., "Shade Trees," Computer Graphics, vol. 18, no. 3, pp. 223-230, July, 1984.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fournier, Alain, D. Fussell, and L. Carpenter, "Computer Rendering of Stochastic Models," Communications of the ACM, vol. 25, pp. 371-384, 1982.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, A., T. Tanaka, and K. lwata, "ARTS: Accelerated Ray Tracing System," 1EEE Computer Graphics and Applications, vol. 6, no. 4, pp. 16-26, April, 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gardner, Geoffrey Y., "Visual Simulation of Clouds," Computer Graphics, vol. 19, no. 3, pp. 297-303, July, 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gardner, Geoffrey Y., Functional Modelling (SIGGRAPH course notes), Atlanta, 1988.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Jurgens, H., Dietmar Saupe (eds.), and Dietmar Saupe, "Point Evaluation of Multi-Variable Random Fractals," Visualisierung in Mathematik und Naturissenschaft - Bremer Computergraphik Tage 1988, Springer-Verlag, Heidelberg, 1989.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801137</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "New Techniques for Ray Tracing Procedurally Defined Objects," Computer" Graphics, vol. 17, no. 3, July, 1983.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357324</ref_obj_id>
				<ref_obj_pid>357323</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "New Techniques for Ray Tracing Procedurally Defined Objects," Transactions on Graphics, vol. 2, no. 3, pp. 161 - 181, July, 1983.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378519</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kelley, Alex D., M. C. Malin, and G. M. Nielson, "Terrain Simulation Using a Model of Stream Erosion," Computer Graphics, vol. 22, no. 4, pp. 263-268, August, 1988.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lewis, J. P., "Generalized Stochastic Subdivision," ACM Transactions on Graphics, vol. 6, no. 3, pp. 167-190, July, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit B. and J. R. Wallis, "Some Long- Run Properties of the Geophysical Records," Water Resources Research 5, pp. 321-340, 1969.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit B., "Stochastic Models for the Earth's Relief, the Shape and the Fractal Dimension of the Coastlines, and the Number-Area Rule for Islands," Proceedings of the National Academy of Sciences (USA), vol. 72, pp. 3825-3828, 1975.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit B., The Fractal Geometry of Nature, W. H. Freeman and Co., New York, 1982.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>383446</ref_obj_id>
				<ref_obj_pid>358589</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit B., "Comment on Computer Rendering of Stochastic Models," Communications of the ACM, vol. 25, no. 8, pp. 581-583, 1982.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, Benoit B., personal communications, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30658</ref_obj_id>
				<ref_obj_pid>30657</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Mastin, Gary A., P. A. Watterberg, and J. F. Mareda, "Fourier Synthesis of Ocean Waves," IEEE Computer Graphics and Applications, vol. 7, no. 3, pp. 16-23, March, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15890</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Miller, Gavin S. P., "The Definition and Rendering of Terrain Maps," Computer Graphics, vol. 20, no. 4, pp. 39-48, 1986.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Miller, Gavin S. P., personal communications, 1988.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Musgrave, F. Kenton, Craig E. Kolb, and B. B. Mandelbrot, A Survey of Terrain Synthesis Techniques, to appear.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Musgrave, F. Kenton, "Grid Tracing: Fast Ray Tracing for Height Fields," Yale Dept. of Computer Science Research Report RR-639, July 1988.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Musgrave, F. Kenton and B. B. Mandelbrot, "About the Cover," IEEE Computer Graphics and Applications, vol. 9, no. 1, January, 1989.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Musgrave, F. Kenton, "Prisms and Rainbows: a Dispersion Model for Computer Graphics," Proceedings of the Graphics Interface '89 - Vision interface '89, London, Canada, June, 1989.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61153</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Peitgen, H. O, and Dietmar Saupe (eds.), The Science of Fractal Images. Springer-Verlag, New York, 1988.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Perlin, Ken, "An Image Synthesizer," Computer Graphic's, vol. 19, no. 3, pp. 287-296, July, 1985.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Rogers, D. F., Procedural Elements for Computer Graphics, Me Graw Hill, New York, 1985.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Voss, Richard F., Random Fractal Forgeries, Springer- Verlag, Berlin, 1985. (in Fundamental Algorithms for Computer Graphics, R. A. Earnshaw, ed.)]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ ~)" Computer Graphics, Volume 23, Number 3, July 1989 i The Synthesis and Rendering of Eroded Fractal 
Terrains F. Kenton Musgravet, Craig E. Kolb? and Robert S. Mace~: tYale University Department of Mathematics 
Box 2155 Yale Station New Haven, Connecticut 06520 ~Silicon Graphics, Inc. 2011 N. Shoreline Boulevard 
Mountain View, California 94039 Abstract In standard fractal terrain models based on fractional Brownian 
motion the statistical character of the surface is, by design, the same everywhere. A new approach to 
the synthesis of fractal terrain height fields is presented which, in contrast to previous techniques, 
features locally independent control of the frequencies composing the surface, and thus local control 
of fractal dimension and other statistical characteristics. The new technique, termed noise synthesis, 
is intermediate in difficulty of implementation, between simple stochastic subdivision and Fourier filtering 
or generalized stochastic subdivision, and does not suffer the drawbacks of creases or periodicity. Varying 
the local crossover scale of fractal character or the fractal dimension with altitude or other functions 
yields more realistic first approx- imations to eroded landscapes. A simple physical erosion model is 
then suggested which simulates hydraulic and thermal erosion processes to create global stream/valley 
networks and talus slopes. Finally, an efficient ray tracing algorithm for gen- eral height fields, of 
which most fractal terrains are a subset, is presented. CR Categories and Subject Descriptors: 1.3.3 
[Computer Graphics]: Picture/Image Generation, 1.3,7 [Computer Graph-ics]: Three-Dimensional Graphics 
and Realism General Terms: Algorithms, Graphics Additional Keywords and Phrases: Fractal, terrain models, 
sto-chastic subdivision, fractional Brownian motion, fractal dimen- sion, lacunarity, crossover scale, 
erosion models, height fields, ray tracing. 1. INTRODUCTION At first glance, fractal terrains are convincing 
forgeries of natural mountain terrains. Closer scrutiny, however, reveals an unnatural character in these 
surfaces as representations of nature. One problem is the fact that if one turns the average "fractal 
mountain" upside-down and looks at the other side of the surface, it looks (statistically) identical 
to the "top" side. This is almost never the case in nature, where depressions in the landscape fill up 
with all manner of detritus, thus acquiring smoother surfaces over the ages of geologic time. The origin 
of fractal landscapes in computer graphics is this: some time ago, B. B. Mandelbrot perceived an analogy 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. between a record 
of Brownian motion over time, and the skyline of jagged mountain peaks. 15 He reasoned that if this process 
were extended to two dimensions the resulting "Brownian sur-face" might provide a visual approximation 
to mountains in nature. He then found it necessary to generalize from Brownian motion to a fractional 
Brownian surface. Some of Mandelbrot's earliest computer graphics images were of such surfaces. 14 Woss 
later used Mandelbrot's fractional Brownian surfaces to create some very convincing forgeries of nature. 
28 New terrain syn-thesis methods have since been proposed by Foumier et al., 4 Miller, 19 and Lewis. 
t2 Most fractal terrain surfaces are related to fractional Brownian motion (/Bin), and can be called 
more loosely 1If 13 surfaces. Fractal terrains in general have no global erosion features inherently 
due to isotropy and stationarity, and practi-cally due to the difficulty in implementation and computation 
of such global processes, which require global communication. In this paper, we present a flexible approach 
to the gen- eration of fractal terrain models of varying smoothness and asymmetry in a first-pass surface 
specification stage, and suggest a second-pass global, physical erosion process for height fields which 
generates both local and global erosion features through a simplified simulation of natural erosion processes. 
The terrain generation method features arbitrary local control of fractal dimension and crossover scale, 
neither of which was sought in previous methods. It also features arbitrary lacunarity*, which is not 
available in common subdivision algorithms. Terrain patches can be compactly represented as height fields; 
we will also describe a very efficient algorithm for ray tracing regular** height fields. This rendering 
algorithm can be characterized as the definition of height fields as a new type of primitive (thus joining 
spheres, planes, polygons, etc.) in the ray tracing para- digm. 2. OTHER WORK Creating synthetic images 
of fractal terrains usually involves two distinct procedures: modelling and rendering. It is well-known 
that rendering fractal terrains is generally more time-consuming than modelling them, especially if one 
chooses to ray trace the scene. In our scheme for imaging eroded syn-thetic terrains, we subdivide modelling 
into two steps: terrain generation and erosion simulation, As the latter step is an attempt to simulate 
the actions of the elements on the landscape over geologic time, it is not surprising to find that it 
competes with rendering, in the time required to create realistic results. * Crossover scale and lacunarity 
will be defined in section 3.1. ** We define a regular height field as a two-dimensional array of altitude 
values where the distance is constant between all rows and between all columns of altitude values. &#38;#169;1989 
ACM -0-89791-312-4/89/007/0041 $00.75 41  S,GGRAP. '89, Boston, 31 July-4 August, 1989 As all three 
steps are essential to creating realistic images, we present new results in each area. First let us review 
work by other researchers in the fields of fractal terrain synthesis, erosion modelling, and ray tracing 
of terrain models. 2.1. Fractal Terrain Modelling Most fractal terrain models have been based on one 
of five approaches: Poisson faulting,15.28 Fourier filtering,15,28, 18 midpoint displacement, 4, 12.19,25 
successive random additions, 28 and summing band-limited noises. 7,8, t9 The approach presented here 
is of the last type, which we will refer to as the noise syn- thesis method. We will now briefly review 
these techniques (for a more detailed review, see Voss and SaupJ 5 or Musgrave, Kolb, and Mandelbrot 
21 ). The original terrain generation technique employed by Mandelbrot 15 was generation of fBm using 
Poisson faulting. The Poisson faulting technique involves applying Gaussian ran- dom displacements (faults, 
or step functions) to a plane or sphere at Poisson distributed intervals. The net result is a Brownian 
surface. This approach has been employed by Man- delbrot to create fractal coastlines and Voss to create 
fractat planets) s It has the advantage of being suitable for use on spheres for creation of planetoids. 
Its primary drawback is the O (n 3) time complexity of the algorithm. Midpoint displacement methods are 
standard in fractal geometry, and were introduced as a fast terrain generation tech- nique by Foumier, 
Fussell, and Carpenter. 4 We classify the vari- ous midpoint displacement techniques by locality of reference: 
wireframe midpoint displacement, tile midpoint displacement, generalized stochastic subdivision, and 
unnested* subdivision. Wireframe subdivision is used only in the well-known triangle subdivision scheme 
4 and involves the interpolation between two points in the subdivision process. Tile midpoint displacement 
involves the interpolation of three or more non-collinear points; it is used in the "diamond-square" 
scheme of Miller, 19 the square scheme of Foumier et al., 4 and the hexagon subdivision of Mandelbrot 
and Musgrave. 25 Generalized stochastic subdivi- sion 12 interpolates several local points, constrained 
by an auto- correlation function. Miller 19 also proposed an unnested "square-square" subdivision, which 
is not strictly a midpoint subdivision scheme. Wireframe and tile midpoint displacement methods are generally 
efficient and easy to implernem, but have fixed lacunarity and are nonstationary due to nesting (for 
illustrations of the resulting artifacts, see Miller 19 ). Generalized stochastic subdivision and unnested 
subdivision schemes are stationary; the former is flexible but not particularly easy to implement, while 
the latter features fixed lacunarity and is very simple to imple- ment. Note that all midpoint displacement 
techniques produce true fractal surfaces 23 but simply have an incorrect statistical character to qualify 
as fractional Brownian motion. 16 Successive random additions is a flexible unnested subdi- vision scheme. 
If points determined in previous stages of subdi- vision are re-used, they are first displaced by addition 
of a ran- dom variable with an appropriate distribution. Previous points need not be re-used; new grid 
points to be displaced can be determined from the previous level of subdivision by linear or nonlinear 
interpolation. Successive random additions features continuously variable level of detail, which is useful 
for zooms in animation, and arbitrary lacunarity. The lacunarity ~ depends on the change of resolution 
at successive generations; time com- plexity of the algorithm is a function of ~ and the final resolu- 
* Unnested here means that successive levels of subdivision retain no points from previous levels. tion 
R. The successive random additions algorithm is easy to implement. Fourier filtering generates fBm by 
taking the Fourier transform of a two-dimensional Gaussian white noise, multiply-ing it in frequency 
space with an appropriate filter, and inter- preting the inverse Fourier transform of the product as 
a height fietd. 28 Alternatively, one can simply choose the coefficients of the discrete Fourier transform, 
subject to the proper constraints, and interpret the inverse Fourier transform as above, z5 Advan- tages 
of this approach include the availability of arbitrary lacunarity and precise control of global frequency 
content. Disadvantages include periodicity of the final surface, which can require that substantial portions 
of the computed height field patch be discarded, the O (n log n) time complexity of the FFT algorithm, 
the level of complexity of implementation, and lack of local control of detail. What we call noise synthesis 
can be described as the iterative addition of signals with tightly band-limited frequen- cies, each of 
which has a randomly varying, or noisy, amplitude. Noise synthetic surfaces have been used by Miller, 
19 Gardner 7 and Saupe. 8 Miller has used Perlin's procedural "l/f noise ''2 (which is actually 1If 
3 noise) as a displacement map 3 to add detail to the (otherwise straight) edges of polygons tessellating 
a Brownian surface of similar spectral content. Gardner has intro- duced a noise function, based on a 
"poor man's Fourier series ''6 (a variation of the Mandelbrot-Weierstrass function) and inter- preted 
it as a height field. The quantization of altitude values of the height field yields terraced land, such 
as mesas. Our approach differs from Gardner's in that we exercise local con- trol over frequency content 
based on the amplitude of existing signal and other functions. The Perlin noise function is notably more 
isotropic than Gardner's noise function, and is not periodic; Gardner's terrains and textures suffer 
visible artifacts due to these factors. In addition, the use of Gardner's noise function requires that 
one subjectively determine critical values for a number of constants. Driven by table lookups, the Gardner 
noise function is much faster than the Perlin function. Noise synthesis is a functional-based modelling 
tech-nique. Each point is determined procedurally, independently of its neighbors; no global computation 
is required. Point-evaluation is a distinguishing property of the noise synthesis method for generating 
random fractals. Recently, a parallel and independent research effort by Saupe has developed an approach 
to noise synthesis similar to that presented here. Saupe's work features an emphasis on mathematical 
foundations, while the authors' emphasizes appli- cations. For a thorough mathematical treatment of the 
issues of noise synthesis which is complimentary to this work, see Saupe. 8 2.2. Erosion Models The issue 
of the symmetry of fBm has been addressed by Mandelbrot arid Voss t5,28 through the use of non-linear 
scaling in a post-processing step, and by Mandelbrot 25 through the use of random variables with non-Gaussian 
distributions in the dis- placement process. These approaches yield peaks which are more jagged and valleys 
which are smoother, but still lack glo- bal erosion features. A global river system, created algorithmi- 
cally at terrain-generation time, has been demonstrated by Man- delbrot and Musgrave, 25 with less-than-satisfactory 
results (see plate 10). Kelley et al. II have used hydrology data to derive a sys- tem for the generation 
of stream network drainage patterns which are subsequently used to determine the topography of a terrain 
surface. This approach features, by its construction, the global dependence necessary for realistic hydraulic 
erosion pat- terns, and has a strong basis in measurements of real physical  ~ Computer Graphics, Volume 
23, Number 3, July 1989 systems. This approach to modelling hydraulic erosion is rela- tively efficient; 
what it lacks is the detail of a fractal surface. While the stream network may be fractal, the "surface 
under tension" used for the terrain surface is not, and cannot be readily made so without disturbing 
the drainage basins and stream paths. A simple hydraulic erosion simulation is proposed here in which 
water is dropped on each vertex in a fractal height field and allowed to run off the landscape, eroding 
and depositing material at different locations as a function of the sediment load of water passing over 
each vertex. It features the global com-munication necessary to create global features, but is slow despite 
the O(n) time complexity. We also present a global model for simulation of what we refer to as thermal 
weathering. While hydraulic erosion creates valleys and drainage networks, thermal weathering wears down 
steep slopes and creates talus slopes at their feet. The thermal weathering simulation can create realistic 
results in much less computing time than the hydraulic erosion simulation, and is also O (n) in time 
complex- ity. Both models are discussed in section 4. 2.3. Ray Tracing Fraclal Terrains Efficient ray 
tracing of fractal terrains has been addressed by Kajiya, 9.1 Bouville,2 Miller,19 and Mastin et al. 
18 Kajiya and Miller propose procedural fractal terrain models to save memory and achieve adaptive level 
of detail; Miller proposes a parallel scheme for rendering terrains which is not specific to ray tracing. 
Mastin et al. propose a quadtree spatial decomposi- tion for the ray tracing of height fields. The ray 
tracing schemes of Kajiya and Bouville rely on invariance of the horizontal position of computed vertices 
of the terrain height field under subsequent iteration of the midpoint subdivision process used to generate 
the surface, in order to ensure that the surface is within predictable bounds for ray/surface intersection 
test culling. This requires that the sub- division scheme nests, else the bounding volumes become ill-defined. 
(Note that nested subdivision schemes suffer most from the creasing problem.) The nesting requirement 
cannot always be met in iterative subdivision schemes, as when subdi- viding non-nesting polygons such 
as hexagons (see Mandel-brot 25 ). Such limitations led the authors to develop an efficient ray tracing 
scheme which is not necessarily procedural but is general to all regular height fields. This new method 
can be implemented hierarchically as an n 2 tree, and in that is similar to the quadtree approach of 
Mastin et al. It uses a DDA to traverse a spatial subdivision data structure, and in that is remin- iscent 
of the 3DDDA ARTS algorithm of Fujimoto. 5 Our "grid tracing ''22 scheme will be described in section 
5. 3. TERRAIN SYNTHESIS 3.1. Fractal Dimension, Fractional Brownian Motion, Cross- over Scale, and Lacunarity 
We now give a very brief description of some of the mathematical terminology associated with the generation 
of frac- tal terrains. For greater depth, see Peitgen and Saupe. 25 For this discussion, we define Df 
as the fractal dimension of the surface, DE as the Euclidean dimension of the surface, and H as the Holder 
exponent. (Note that previous authors have sometimes erroneously referred to H as the fractal dimension.) 
For terrain models DE=2 and Df=3-H. The fractal dimension Dr, Euclidean dimension De, Holder exponent 
H, and the spectral exponent ~ of l/f 13noise and of fBm are related by Df = DE+I-H = DE+ 3-[3 (1) 2 
It follows that 13 = l+2H and H = (~- 1)/2. Since DE = 2, for our purposes, Df = 3-H = (7-~)/2. H is 
constrained to the interval [0,1] and 13 to [1,3]; outside this range we do not have formally fractal 
behavior. Fractional Brownian motion in one dimension is a sto-chastic process X (t ) with a power spectrum* 
S (f ) scaling with f as S~f) -l/f ~ where ~ again is in the interval [I,3]. FBm is itself not a sta-tionary 
process, but its increments 1 (t, At) = X(t + At)-X (t) are; that is, the expected value of l(t, At) 
is zero for all t and At and the variance ~2 of 1 (t, At) does not depend on t. In the special case of 
Brownian motion, H = 0.5 and ~2 varies as At TM. Thus for H = 0.5 increments are uncorrelated; for H 
>0.5 (as in fractal terrains, where H is approximately equal to 0.8) increments are positively correlated; 
for H<0.5 they are nega-tively correlated (corresponding to a very rough surface). In more than one dimension 
fBm is a random field X(x,y,...) with X on any straight line being a Ill ~ noise. Discretized fractional 
Brownian motion is a stochastic process X(t) with a discrete power spectrum such that each spectral line 
has the energy Lf i ]f S(f)df where X is the logarithmic spacing of the lines. Many fBm sur-faces used 
in computer graphics are discretized fBm's. A fractal surface changes in character depending on whether 
it is observed from nearby or from far away. From far away it appears fiat or smooth (as the Earth seen 
from space). The transition from "nearby" to "far away" appearances occurs at the crossover scale which 
is the scale where vertical and hor- izontal displacements are equal. Thus, for a mountain range ris- 
ing within one kilometer from sea level to peaks which are, one kilometer high, the crossover scale is 
one kilometer. The cross- over scale is not to be confused with the upper and lower fre- quency cutoffs 
for a band-limited fBm. Lacunarity generally refers to gaps in fractals; 15 in this instance it refers 
to the gap between frequencies composing the discretized fBm of the ffactal terrain. Thus when iteratively 
adding the frequencies composing the discretized fBm, if the frequency fi added at stage i is a multiple 
~. of fi-l, fi = ~Lfi-l, is the spatial tacunarity of the fBm. While spatial lacunarity affects the texture 
of the fBm, this effect is usually only notice- able for k > 2. Therefore we usually let = 2, as lower 
values involve more computation for a given frequency range of fBm and higher values effect the surface 
appearance. 3.2. Noise Function Noise synthetic terrain generation is accomplished by the addition of 
successive frequencies of tightly band-limited noises. The source of the noise we use is a version of 
the Perlin 26 noise function. The ideal noise function for our purposes would be monochromatic (i.e., 
single-frequency), stationary (invariant under translation), and isotropic (invariant under rotation). 
The Perlin function supplies a band-limited signal of random ampli-tude variation. It is stationary and 
nearly isotropic.** * The power spectrum Sf3") is the power P(f ) of the signal at frequency f, or the 
the mean squared power over interval Af centered at f, divided by Af: S(f) = p(f)2/&#38;f. ** It is geometrically 
impossible to reconcile the three criteria of mono- ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 
The Perlin noise function N:R"--~R is implemented as a set of random gradient values defined at integer 
points of a lat-tice or grid in space (of dimension n = 1, 2, or 3) which are interpolated by a cubic 
function. At lattice points in space (points in space with integer coordinates), the value of the func- 
tion is zero (a zero crossing) and its rate of change is the gra- dient value associated with that lattice 
point. The first deriva- tive of the function is interpolated at non-integer points using the cubic function 
3x ~-2x 3, which features second derivative continuity and zero rate of change at the end points, where 
x =0 and x=l. Since the gradient might be, for instance, increasing at two consecutive lattice points 
i and i + 1, there may also be a zero crossing at a point between i and i + 1 (see figure 1). This gives 
rise to frequencies in the noise function higher than the primary frequency, which is defined by the 
spacing of the integer lattice. Figure 1 One-dimensional trace of noise function. The noise function 
can be modified to have an arbitrary, non-zero value at the lattice points. This increases the variance 
of the function, but adds low frequency components to the sig- nal which cannot be controlled or subsequently 
removed. 12 For an analysis of the spectral characteristics of such a noise func- tion see Saupe. s The 
Perlin noise function N (if) outputs a signal with a fixed lower frequency f. To generate a signal of 
lowest fre-quency u f, one can perform a scalar multiplication uff of the coordinate vectors supplied 
to N. This has the effect of moving the reference points in the noise lattice, producing the desired 
frequency shift in the output of N. We will see this practice used below. 3.3. Frequency Control Given 
the noise function, how do we use it to generate more realistic terrains? Subjective observation of natural 
landscapes reveals that in certain types of mountain ranges there is a marked change in the statistics 
of the surface as one moves from the foothills to higher peaks. The foothills are more rounded, while 
the higher mountains are more jagged. Some-times, as in the eastern slope of the Sierra Nevada, the entire 
mountain range rises in a relatively short distance from a nearly flat plain. This change of character 
can be characterized as a change of fractal dimension Df, crossover scale, or both. Using the noise synthesis 
technique we can easily devise terrain models with such features by modulating the power spec- trum of 
the surface as a function of horizontal position and/or vertical altitude. We give some examples below. 
Given a (Perlin) noise function N:R".----~R with Gaussian distribution in the interval [-i,1], we can 
generate fBm as fo1- chromaticity, s.tationarity, and ~so.tropy in a rnulltldirnenslona| Per|in noise 
function. If the primary (lowest) frequency of an n-dimensional Perlin function is f along the axes of 
the grid upon which it is defined, then the frequency is ~'f~f along the diagonal of that grid. lows: 
For our lowest frequency offset a0 we have a0 = N(F~) where if0 is the initial object space coordinate 
vector of the height field position being calculated. Iterating (discretized) fBm at lacunarity ~>1 requires 
that, at iteration n, the frequency added is proportional to (f0L")-51k Setting the lowest fre-quency 
f0=l gives a frequency increment at iteration n of L-0.513,,. Thus for higher frequencies added at iteration 
i>0 we have ai = N~--l~Jco i where co = X -'5~ (a constant) and /~/ =/ff/-iX. Note that for a two-dimensional 
noise function N:RL--~R, we have ~-=if oBJ. For N:R3----~R, we may have/~- ffo~ i due to vertical displace- 
ment. For the purposes of terrain modelling we will introduce a number of parameters to the formulae 
for fBm. We may wish to translate N by a constant c, so that it is, for instance, always or nearly always 
positive. We may also wish to scale N by a factor cs to reduce or expand its range. In the patches shown 
in plates 3 and i 1, we insert the lowest frequency first: ao = (N(Fo) + c,) c~. + Co where a0 is the 
initial height of a point in the height field and Co is an offset constant which determines the zero 
value or "sea level" of the terrain. We have for the altitude ai at stage i>0: ai = ai-i + ai-i (N (I~ 
) + G) cs col The procedure used in plates 3 and 1 1 generates a surface in which the power of the high 
frequencies is linearly propor- tional to the (previous) altitude of the surface. This amounts to modulating 
crossover scale with altitude. In plates 3 and 11, as in the other illustrations of noise-synthetic terrain 
patches, we set k = 2. (The rainbow in plate 1 1 is from Musgrave. 24 ) In plate 4 the crossover scale 
varies with altitude and horizontal position. Here we have ao = F(x) (N(ffo) + c,) cs + Co with F (x) 
= min(2x,2 -2x), assuming that x varies from 0 to I. To give the ridge a more natural path than that 
of a straight line, we add some l/f 3 noise to x before calculating F(x). The contribution of higher 
frequencies is again scaled as ai = ai-l + ai-l (N (t~ ) + c, ) cs cO i Fractal dimension can be modulated 
as easily as the crossover scale by scaling [3 or H in successive generations. Plate 5 shows a patch 
which is planar on the left, to space filling on the right (modulo the upper and lower frequency cutoffs, 
which are approximately at 7 and 1/128 times the patch size, respectively). In this case, we have 13= 
l/x (correspond-ing to H = 1/x-3/2), and x in the interval (0,1]. In plate 6, we linearly change fractal 
dimension Df from 2 (H=l, 13=3) to 3 (H=0, 13=1) on the right. Note that this is not the same as going 
from planar (l/f ~) to filling all of 3 space (I/f 0), as in plate 5. It is interesting to note that 
experience indicates that modulation of crossover scale is more effective than modulation of fractal 
dimension for modelling realistic looking terrain. That changing crossover scale alone should have such 
a dramatic effect is not surprising, for as B. B. Mandelbrot has pointed out, 17 the fractal dimension 
of the Himalayas is approxi- mately the same as that of the runway at the JFK airport; what is true is 
simply that the crossover scale of the latter is on the ~ Computer Graphics, Volume 23, Number 3, July 
1989 order of millimeters while that of the former is on the order of kilometers. It is readily apparent 
that the global lacunarity X is sub- ject to precise user control in the noise synthesis scheme. Com-putational 
cost for a surface is a function of the number of fre- quencies used. Thus surfaces generated with small 
lacunarity will be more expensive to compute than those with large lacunarity. Cost can be reduced by 
omitting high frequencies when their contribution drops below an arbitrary threshold. With the noise 
synthesis method, one may exercise local control over lacunarity. This can be accomplished by displacing 
the initial coordinate P0 supplied to the noise function by a vec- tor valued noise function /~ (e. g., 
Perlin's .....Dnolse0 26). The effects of such local change of lacanarity are shown in plate lb, where 
we modulate intensity on the image plane as intensity = N (fro + l~(lYo)). (Plate la shows the similarly 
interpreted output of noise N(/~o).) Note that local change of lacunarity interferes with the precise 
local control of frequency. While it is not obvious that this local modulation of lacunarity is particularly 
useful for terrain synthesis, it may prove useful for the synthesis of other textures, such as clouds, 
smoke, or flames. Plates 11 and 12 are details of 100 x 100 patches similar to that in plate 3. Note 
that the triangles, which are obscured by bump mapping, are quite large in comparison with the overall 
image. By including only relatively low frequencies in the terrain and leaving high-frequency details 
to a texture map, we can achieve realistic results using very small height fields. 4. PHYSICAL EROSION 
MODEL We have divided erosive processes into two categories: hydraulic erosion and thermal weathering. 
Hydraulic erosion is that caused by running water. What we term "thermal weather- ing" subsumes the non-hydraulic 
processes which cause rock to flake off steep inclines and form talus slopes at the base. In this section 
we will illuminate the two erosion simulation algo-rithms. 4.1. Hydraulic Erosion The hydraulic erosion 
model involves depositing water ("rain") on vertices of the height field and allowing the water and sediment 
suspended in the water to move to any lower neighboring vertices. The erosive power of a given amount 
of water is a function of its volume and the amount of sediment already carried in the water. The hydraulic 
erosion model is implemented by associat- ing with each vertex v at time t an altitude at", a volume 
of water w~', and an amount of sediment st" suspended in the water. At each timestep, we pass excess 
water and suspended sediment from v to each neighboring vertex u. The amount of water passed, Aw, is 
defined as: Aw = rain (w)', (wf + a~')- (w7 + aT)) If Aw is less than or equal to zero, we simply allow 
a fraction of the sediment suspended in the water at v to be deposited at V: a;~-l = a:' + Kas;' s;'+ 
l = ( 1 -Kd)s:' Otherwise, we set w:'+l = w,'-Aw wLl = w~ + Aw Here, c~ is the sediment capacity of Aw. 
When passing sedi-ment from v to u, we remove at most this amount of sediment from s;' and add it to 
s:'+l If cs is greater than st", a fraction of the difference is subtracted from a[ and is added to 
s]'+~, which constitutes the erosion of soil from v, Finally, we allow a frac- tion of the sediment remaining 
at v to be deposited as above. Thus, if sf ?_ cs, we set s,~.~ = s, ~ + c~ all = a;' + K~(s;' -c~ ) s)'l 
= (I Kd)(S," --cs) - Otherwise, s:'+l = s7 + s:' + K~ (c~ -s:") a:'+~ = a;' -K~(c, -s:') sf+l = 0 The 
constants K,, Ka, and Ks are, respectively, the sediment capacity constant, the deposition constant and 
the soil softness constant. K,. specifies the maximum amount of sediment which may be suspended in a 
unit of water. Ks specifies the softness of the soil and is used to control the rate at which soil is 
con-vetted to sediment. Ka specifies the rate at which suspended sediment settles out of a unit of water 
and is added to the alti- tude of a vertex. Through the above process, water and, more importantly, soil 
from higher points on the landscape are transported to and deposited in lower areas. This movement constitutes 
the com-munication necessary for modelling the global process of ero-sion. In a full two-dimensional 
implementation, one must take care to distribute water and sediment to all neighboring lower vertices 
in amounts proportional to their respective differences in overall elevation. Although this model is 
ad hoc, the resulting landscapes bear reasonable resemblance to natural erosion patterns. Further research 
will concentrate on constructing a more sophisticated, physically accurate model. Plates 2 and 9 show 
a terrain patch before and after 2000 time steps of hydraulic and thermal erosion. The erosion simu- 
lation required approximately 4 hours of CPU time on a Silicon Graphics Iris 4D/70 workstation. The uneroded 
patch shows a good first approximation to an eroded landscape with a central stream bed. The uneroded 
patch was created by weighting the addition of always positive noise values by the distance d of the 
point from the diagonal of the patch, which diagonal is also "higher" at the far end. The stream bed 
is made non-linear by the addition of 1/f 3 noise to the distance d. In this simulation, K, = 5.0, Kj 
= 0.1, and Ks = 0.3. Note the gullys, confluences, and alluvial fans that have appeared in the eroded 
patch, which is rendered as a dry wash, i.e., without water present. The distribution of rainfall on 
landscapes in nature is strongly influenced by adiabatics, or the behavior of moisture- laden air as 
it rises and descends in the atmosphere. As air rises, it cools and the relative humidity rises. When 
the relative humidity exceeds one hundred percent, clouds form; when the clouds become dense, precipitation 
occurs. Wind blowing over mountains raises air as it passes over the mountains, thus pre-cipitation is 
much greater at the top and downwind of, mountain peaks. It is easy to include a rough approximation 
of adiabatic effects in our erosion model by making precipitation a linear function of altitude. This 
has a significant effect on the erosion patterns produced. In our use of the hydraulic erosion model, 
we have sim- ply allowed a fixed amount of rain (approximately one one thousandth of the height of the 
vertex) to fall at regular intervals (approximately every sixty to one hundred time steps). Mandel- 
"~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 brot and Wallis 13 have pointed out that records of 
flooding of the Nile river show a l/f noise distribution, i.e., large floods happen with low frequency. 
Such a noisy distribution in the rainfall would constitute a more realistic simulation of nature; it 
is probable that it would have a long-term effect on the erosion features created. This is an idea yet 
to be explored. 4.2. Thermal Weathering The other erosion process we model is thermal weather- ing, which 
is a catch-all term for any process that knocks material loose, which material then falls down to pile 
up at the bottom of an incline. The thermal weathering process creates talus slopes of uniform angle. 
Thermal weathering is a kind of relaxation process and is both simple to implement and fast. At each 
time step t+l, we compare the difference between the alti- tude &#38; at the previous time step t of 
each vertex v and its neighbors u to the (global) constant talus angle T. If the com- puted slope is 
greater than the talus angle, we then move some fixed percentage c, of the difference onto the neighbor. 
4 &#38;'-af > T: a~ + G(af-a,"-T) af+j = [a~-af < T aJ' With care taken to assure the equitable distribution 
of talus material to all neighboring vertices, the slope to the neighboring vertices asymptotically approaches 
the talus angle. Plates 7 and 8 show a patch created with non-uniform lacunarity before and after slumping 
or thermal weathering. This process has created a rough approximation of sand dunes. 4.3. Discussion 
of Erosion Models An interesting extension would be to account for the differing hardnesses of bedrock, 
silt, and talus. This can be accomplished by adding appropriate fields to the vertex data structure and 
making the simplifying assumption that silt lies on top of talus, which in turn lies on top of bedrock. 
Another sim- ple extension will be to add strata of differing hardnesses to the bedrock, as is commonly 
seen in sedimentary rock. This can be accomplished through the use of a Perlin texture (as in Plate 13) 
or more efficiently by table lookup of a vertically perturbed one-dimensional array of hardnesses. Finally, 
it would be desir- able to render the water flowing on the landscape. To do this realistically represents 
a major challenge and will be the aim of future research. 5. RAY TRACING HEIGHT FIELDS Having created 
eroded fractal height fields, we now need to render them quickly and realistically. We present a fast 
ray tracing technique for height fields, termed grid tracing, 22 The basic idea is this: A two-dimensional 
array of alti- tude values is traversed in an arbitrary direction by a ray, through the use of a modified 
DDA (Digital Differential Analyzer) algorithm. The array is thought of as composing a grid of small square 
cells eorresponding to the pixels being illuminated by a DDA algorithm. Each cell has associated with 
it the height field altitudes at the four corners of the cell. As the ray traverses the array of cells, 
the altitude of the ray at each cell is compared to the four altitudes associated with the cell. Ray/surface 
intersection tests need only be performed when the altitude span of the ray over the extent of the cell 
intersects the interval of altitudes defined by the lowest and highest of the four altitudes associated 
with the cell. For a ray traveling above the surface, the condition can be stated: rain (ray:,,ea,,ray(f,,.) 
< max (hi.j, h i j+l hil,j, hi+l.j+l) (2) where ray:l,,,,, fu,.l represents the altitudes of the end 
points of the ray segment within the cell and the hm., represent the alti- tudes of the height field 
H at the four comers of the i,j th cell. As the surface of the terrain within a cell can be represented 
by exactly two triangles which split the square diagonally, the ray/surface intersection test consists 
of two ray/triangle intersec- tion tests. These tests are greatly simplified by the shape and orientation 
of the triangles. Only rays grazing past the surface will fail the intersection tests; most rays will 
incline directly into the surface at the first cell where surface intersection is tested. Note that the 
calculation in expression (2) can be simplified by creating an auxiliary array of values for each cell 
which are equal to the right hand side of (2). Advantages of this algorithm are manifold. First, only 
the height field need be calculated and stored as the model. The actual polygon descriptions (i.e., the 
plane equations of the tri- angles) need only be calculated when an intersection test is per- formed. 
This can save both time and space in the creation of the terrain model, as polygons which are not visible 
in the rendering are never fully described. Second, the grid traversal can be accomplished with the use 
of a modified Bresenham DDA 27 algorithm. The Bresenham algorithm is a highly optim- ized, fast algorithm 
which uses only floating point addition* in determining the height of the ray and the next cell along 
the path of the ray. Third, the algorithm is general. Any two-dimensional array of scalar data (i.e., 
an image) may be inter- preted as a height field and ray traced with this algorithm. Fourth, the algorithm 
performs ray/object intersections in O (4k-) time with a small constant multiplier, where k is the number 
of cells in the grid. Furthermore, the grid tracing algorithm can be made hierarchical and, for fractal 
terrains which are not post-processed as by an erosion simulation, procedural. The hierar- chy is created 
by having each cell contain another grid rather than two triangles. Each altitude associated with the 
cell is then equal to the height of the bounding box of the subgrid. Hierarchical decomposition is desirable 
for ray tracing large grids, as implementation as a hierarchy of n x n grids (an n 2 tree) reduces the 
time complexity to O(log,4k-). In renderings of a portion of a 1217 x 1217 grid, grid traversal time 
was reduced by approximately 50% with a 162 tree implementation. Plate 10 is such a rendering, and at 
one ray per pixel at 1280 x 1024 resolution, it required less than one half of an hour of CPU time times 
eight CPUs using a parallel ray tracing scheme 22 on an Encore Muhimax computer, under the C-Linda parallel 
programming language.l Grid tracing of procedural terrain models enables adap-tive level of detail and 
efficient memory usage in that no unnecessary height field values need be computed. In the pro= cedural 
implementation, height field values are calculated and stored when a cell is first traversed by a ray. 
Measuring diver- gence of primary (first-generation) rays at the far end of a cell determines whether 
a cell needs to be decomposed into a subgrid; such divergence is a linear function of the distance the 
ray has traveled. This simple metric breaks down in the face of the bane of ray tracing: rays reflected 
and refracted by curved or bump-mapped surfaces. Grid tracing is a memory-bound algorithm. While the 
grid can be traversed at great speed, page faults generated when a grid is too large to fit imo main 
memory severely compromise the speed of a grid tracing program. A 1000 x 1000 grid corn- * The best-known 
Bresenham DDA is an integer algorithm. The version used for our purposes is not the integer Bresenham 
DDA, but rather a slightly less optimal floating point version. A simpter alternate scheme could use 
an ordinary integer DDA for the traversal, bu! would need to check one eetl to either side of the ray 
path for possible intersections due to imprecision in tracking that path. ~ posed of two byte integer 
altitude values comprises two mega- bytes of memory. If one elects to store the plane equation data for 
triangles when it is calculated for ray/surface intersection tests, the memory usage increases steadily 
as the image is ren- dered unless active memory management is implemented. We have found it beneficial 
to store a small number of triangles in a cache organized as a linked list of triangle data stored in 
most- recently-used-first order. Note that height fields tessellated by equilateral triangles, as opposed 
to right triangles, can be ray traced just as efficiently. A right triangle can be transformed into an 
equila- teral triangle with a skewing and a scaling transformation such as x =x +y/2 and y =y',/3/2. 
The inverse of the product of these transformations can be applied to the ray, whereupon the ray can 
traverse a rectilinear grid in "grid space". This is useful because an equilateral triangle tessellation 
of a surface requires less stored data per unit area of surface and is, upon rendering, often more aesthetically 
appealing than a right triangle tessella- tion. 6. CONCLUSION We have demonstrated a new method for creating 
fractal terrains which gives a first approximation to erosion features, at terrain generation time. As 
opposed to previous methods, noise synthesis allows local control over frequencies comprising the surface. 
We have also suggested two effective erosion algo- rithms which simulate hydraulic erosion by flowing 
water and thermal weathering, which chips away steep inclines and forms talus slopes. The hydraulic erosion 
simulation requires a significant amount of computer time to create extensive, deep drainage systems, 
while the thermal weathering can be quite fast. Finally, we have described a ray tracing algorithm for 
height fields which is efficient enough to allow the ray tracing of detailed terrains in a reasonable 
amount of computer time. Acknowledgements The work of Ken Musgrave and Craig Kolb was accom- plished 
in Benoit Mandelbrot's project at Yale University as a part of our ongoing quest for more beautiful and 
realistic for- geries of nature, using the latest results in fractal geometry. We are deeply grateful 
to Benoit Mandelbrot, and to Dietmar Saupe, for their comments, corrections, and inspiration in this 
endeavor. The work at Yale was funded, in part, through the Office of Na- val Research contract N00014-88-K-0217, 
and development was carried out with the invaluable assistance of Nick Carriero, Rob Bjornson, and David 
Gelerenter of the Yale Computer Science Department, using C-Linda 1 on the Encore Multimax. That sys- 
tem is supported, in part, by NSF grants DCR-8601920 and DCR-8657615. All the authors, particularly Rob 
Mace, are in-debted to Silicon Graphics, Inc. for their generous support. References 1. Ahuja, S., N. 
Carriero, and D. Gelerenter, "Linda and Friends," IEEE Computer, August, 1986. 2. Bouville, Christian, 
"Bounding Ellipsoids for Ray-Fractal Intersection," Computer Graphics, vol. 19, no. 3, pp. 45-52, July 
1985. 3. Cook, Robert L., "Shade Trees," Computer Graphics, vol. 18, no. 3, pp. 223-230, July, 1984. 
 4. Fournier, Alain, D. Fussell, and L. Carpenter, "Computer Rendering of Stochastic Models," Communications 
of the ACM, vol. 25, pp. 371-384, 1982. 5. Fujimoto, A., T. Tanaka, and K, lwata, "ARTS: Accelerated 
Ray Tracing System," IEEE Computer Graphics and Applications, vol. 6, no. 4, pp. 16-26, April, 1986. 
 Computer Graphics, Volume 23, Number 3, July 1989 6. Gardner, Geoffrey Y., "Visual Simulation of Clouds," 
Computer Graphics, vol. 19, no. 3, pp. 297-303, July, 1985. 7. Gardner, Geoffrey Y., Functional Modelling 
(SIGGRAPH course notes), Atlanta, 1988. 8. Jurgens, H., Dietmar Saupe (eds.), and Dietmar Saupe, "Point 
Evaluation of Multi-Variable Random Fractals," Visualisierung in Mathematik und Naturissenschaft - Bre- 
mer Computergraphik Tage 1988, Springer-Verlag, Heidelberg, 1989. 9. Kajiya, James T,, "New Techniques 
for Ray Tracing Procedurally Defined Objects," Computer" Graphics, vol. 17, no. 3, July, 1983. 10. Kajiya, 
James T., "New Techniques for Ray Tracing Procedurally Defined Objects," Transactions on Graph-ics, vol. 
2, no. 3, pp. 161-181, July, 1983. 11. Kelley, Alex D., M. C. Malin, and G. M. Nielson, "Ter- rain Simulation 
Using a Model of Stream Erosion," Computer Graphics, vol. 22, no. 4, pp. 263-268, August,  1988. 12. 
Lewis, J. P., "Generalized Stochastic Subdivision," ACM Transactions on Graphics, vol. 6, no. 3, pp. 
167-190, July, 1987. 13. Mandelbrot, Benoit B. and J. R. Wallis, "Some Long-Run Properties of the Geophysical 
Records," Water Resoutz'es Research 5, pp. 321-340, 1969. 14. Mandelbrot, Benoit B., "Stochastic Models 
for the Earth's Relief, the Shape and the Fractal Dimension of the Coastlines, and the Number-Area Rule 
for Islands,"  Proceedings of the National Academy of Sciences (USA), vol. 72, pp. 3825-3828, 1975. 
15. Mandelbrot, Benoit B., The Fractal Geometry of Nature, W. H. Freeman and Co., New York, 1982. 16. 
Mandelbrot, Benoit B., "Comment on Computer Render- ing of Stochastic Models," Communications of the 
ACM, vol. 25, no. 8, pp. 581-583, 1982. 17. Mandelbrot, Benoit B., personal communications, 1988. 18. 
Mastin, Gary A., P. A. Watterberg, and J. F. Mareda, "Fourier Synthesis of Ocean Waves," IEEE Computer 
Graphics and Applications, vol. 7, no. 3, pp. 16-23, March, 1987. 19. Miller, Gavin S. P., "The Definition 
and Rendering of Terrain Maps," Computer Graphics, vol. 20, no. 4, pp. 39-48, 1986. 20. Miller, Gavin 
S. P., personal communications, 1988. 21. Musgrave, F. Kenton, Craig E. Kolb, and B. B. Mandel- brot, 
A Survey of Terrain Synthesis Techniques, to appear. 22. Musgrave, F. Kenton, "Grid Tracing: Fast Ray 
Tracing for Height Fields," Yale Dept. of Computer Science Research Report RR-639, July 1988. 23. Musgrave, 
F. Kenton and B. B. Mandelbrot, "About the Cover," IEEE Computer Graphics and Applications, vol. 9, no. 
1, January, 1989. 24. Musgrave, F. Kenton, "Prisms and Rainbows: a Disper- sion Model for Computer Graphics," 
Proceedings of the Graphics Interface '89 -Vision Interface '89, London, Canada, June, 1989. 25. Peitgen, 
H. O, and Dietmar Saupe (eds.), The Science of Fractal Images. Springer-Verlag, New York, 1988. 26. 
Perlin, Ken, "An Image Synthesizer," Computer Graph- ic's, vol. 19, no. 3, pp. 287-296, July, 1985. 
     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74338</article_id>
		<sort_key>51</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[From splines to fractals]]></title>
		<page_from>51</page_from>
		<page_to>60</page_to>
		<doi_number>10.1145/74333.74338</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74338</url>
		<abstract>
			<par><![CDATA[Deterministic splines and stochastic fractals are complementary techniques for generating free-form shapes. Splines are easily constrained and well suited to modeling smooth, man-made objects. Fractals, while difficult to constrain, are suitable for generating various irregular shapes found in nature. This paper develops <i>constrained fractals</i>, a hybrid of splines and fractals which intimately combines their complementary features. This novel shape synthesis technique stems from a formal connection between fractals and generalized energy-minimizing splines which may be derived through Fourier analysis. A physical interpretation of constrained fractal generation is to drive a spline subject to constraints with modulated white noise, letting the spline diffuse the noise into the desired fractal spectrum as it settles into equilibrium. We use constrained fractals to synthesize realistic terrain models from sparse elevation data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.1</cat_node>
				<descriptor>Spline and piecewise polynomial interpolation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Spline and piecewise polynomial approximation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39079906</person_id>
				<author_profile_id><![CDATA[81100122769]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szeliski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corp., Cambridge Research Lab, One Kendall Square, Bldg. 700, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40037147</person_id>
				<author_profile_id><![CDATA[81100294834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Terzopoulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Laboratory for Computer Science, P.O. Box 200015, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. H. Ahlberg, E. N. Nilson, and J. L. Walsh. The Theory of Sptines and their Applications. Academic Press, New York, 1967.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35072</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. H. Baxtets, J. C. Beatty, and B. A. Barsky. An Introductior, to Splines for use in Computer Graphics and Geometric Modeling. Morgan Kau~mann, Los Altos~ CA, 1987.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27626</ref_obj_id>
				<ref_obj_pid>27625</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. A. Foley. Weighted bicubic spline interpolation to rapidly varying data. A CM Transactions on Graphics, 6(1):1-18, January 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Fournier, D. Fussel, and L. Caxpenter. Computer rendering of stochastic models. Communications of the A CM, 25(6):371-384, 1982.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs, Z. M. Kedem, and S. P. Uselton. Optimal surface reconstruction from planar contours. Communications of the A CM, 20(10):693-702, October 1977.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13489</ref_obj_id>
				<ref_obj_pid>13482</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Geman and Hwang C.-K. Diffusions for global optimization. SIAM Journal o/ Control and Optimization, 24(5):1031-1043, September 1986.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Geman and D. Geman. Stochastic relaxation, Gibbs distribution, and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-6(6):7'21-'/41, November 1984.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5603</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. K. P. Horn. Robot Vision. MIT Press, Cambridge, Massachusetts, 1986.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[3. P. Lewis. Generalized stochastic subdivision. A CM Transactions on Graphics, 6(3):167-190, July 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B. B. Mandelbrot. The Fractal Geometry of Nature. W. H. Freeman, San Fzancisco, 1982.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. G. Schweikezt. An interpolation curve using spline in tension. J. Math. and Physics, 45:312-317, 1966.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>914552</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Szeliski. Bayesian Modeling of Uncertainty in Low- Level Vision. PhD thesis, Carnegie Mellon University, August 1988.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1856805</ref_obj_id>
				<ref_obj_pid>1856740</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Szellski. Regutarization uses fractal priors. ~'.u AAAI- 87: Sixth National Conference on Artificial 2~telligence, pages 749-154, Morgan Kaufmann Publishers, Seattle, Washington, July 198"/.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Szeliski and D. Terzopoulos. Constrained fractals using stochastic relaxation. Submitted to A CM Transactions on Graphics, 1989.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos. Multilevel computational processes for visual surface reconstruction. Computer Visiont Graphics, and Image Processing, 24:52-96, 1983.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5994</ref_obj_id>
				<ref_obj_pid>5979</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos. ltegularization of inverse visual problems involving discontinuities. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAML8(4):413-424, July 1986.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Fleischer. Deformable models. The Visual Computer, 4(6):306-331, December, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos, J. Platt, A. Burr, and K. Fleischer. Elastically deformable models. Computer Graphics (SIG- GRAPH'87), 21(4):205-214, July 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[It. F. Voss. Random fractal forgeries, in R. A. Earnshaw, editor, Fundamental Algorithms for Computer Graphics, Springer-Verlag, Berlin, 1985.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 From Splines to Fractals Richard Szeliskit and Demetri Terzopoulos~ t Digital Equipment Corp., Cambridge 
Research Lab, One Kendall Square, Bldg. 700, Cambridge, MA 02139 ~Schlumberger Laboratory for Computer 
Science, P.O. Box 200015, Austin, TX 78720 Abstract Deterministic splines and stochastic fractals are 
complementary techniques for generating free-form shapes. Splines are easily constrained and well suited 
to modeling smooth, man-made ob- jects. Fractals, while difficult to constrain, are suitable for gen- 
erating various irregular shapes found in nature. This paper develops constrained #actals, a hybrid of 
splines and fractals which intimately combines their complementary features. This novel shape synthesis 
technique stems from a formal connec- ti-on between fractals and generalized energy-minimizing splines 
which may be derived through Fourier analysis. A physical in- terpretation of constrained fraetal generation 
is to drive a spllne subject to constraints with modulated white noise, letting the spline diffuse the 
noise into the desired fractal spectrum as it settles into equilibrium. We use constrained fractals to 
synthe- size realistic terrain models from sparse elevation data. Keywords: Fractals, Splines, Constraints, 
Scattered Data In- terpolation, Digital Terrain Models, Physically Based Model- ing, Deformable Models 
CR Categories: L3.5--Object Modeling (Curve, surface, solid, and object representations); L3.7--Three-Dimensional 
Graphics and Realism; G.l.l--Interpolation (Spline interpo- lation); G.1.2--Approximation (Spline approximation) 
 1 Introduction Over the years, computer graphics researchers have devel- oped numerous mathematical 
models capable of generat- ing free-form shapes. Such models come in two varieties-- deterministic and 
stochastic. Spline models, which are de- terministic, have established themselves as a convenient and 
powerful technique for modeling smooth, man-made shapes, such as teapots [2]. By contrast, fractal models 
have become popular for recreating a wide variety of the shapes found in nature [10]. Most fractal models 
feature a stochastic component, making them well suited to gen- erating nonsmooth, irregular shapes, 
such as mountainous terrain [4]. In this paper, we develop a model of shape which combines deterministic 
splines and stochastic frac- tals to inherit their complementary features. Permission .to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. 1.1 Constraints versus Natural 
Detail Splines typically offer precise shape control but they lack natural looking detail. In this paper, 
we employ a class of variational splines whose positions, slopes, and curvatures are locally controllable 
though external shape constraints. Furthermore, these variational models cart become piece- wise smooth, 
producing local discontinuities such as frac- tures and creases. However, these splines provide no mech- 
anism for modeling the fine-scale texture of many natural shapes. By contrast, stochastic fractals provide 
realistic detail for modeling a wide variety of complex natural phenomena, but they offer little control 
over shape. This deficiency is most acute in the Fourier based methods [10] which can produce shapes 
with true fractal distributions but cannot be controlled locally. A common approach for obtaining some 
control is to first triangulate a given set of points, then add fractal texture by recursively subdividing 
and randomly perturbing the subtriangles [4]. Unfortunately, this approach produces annoying visual artifacts 
because the spatial statistics are nonstationary across the original triangle boundaries. Moreover, it 
makes difficult the im- position of more complicated constraints. Conventional free-form shape synthesis 
techniques are therefore inadequate for many graphics applications--splines provide insufficient detail, 
while fractals provide insufficient shape control. This paper proposes constrained fractals, a new shape 
modeling technique which simultane- ously provides both detail and control. 1.2 Overview Section 2 gives 
an intuitive explanation of the constrained fractal technique, and discusses fractal terrain generation 
which serves as our main application area. Section 3 presents the controlled-continuity splines which 
form the deterministic component of constrained fractals. The main text develops these variational splines 
in a single variable, and multivariate extensions are relegated to an appendix. We describe how to discretize 
the spline energy expres- sions using finite elements, and present examples of spline surfaces constrained 
by scattered data. Section 4 explains how to associate a probability distribution with variational splines 
through the Boltzmann distribution, and shows that samples from this distribution have fractal statistics. 
Section 5 introduces a multiresolution stochastic relaxation &#38;#169;1989 ACM-0-89791-312-4)89/007/0051 
$00.75   -~,,,~[~SIGG RAP H '89, Boston, 31 July-4 August, 1989 algorithm for sampling the Boltzmann 
distribution to ob- tain constrained fractals. Because of length limitations, we present a full description 
of our algorithm in a companion paper [14]. In Section 6 we demonstrate the application of this algorithm, 
showing how to include local control over smoothness. Finally, Section 7 closes with some conclu-sions 
about our work. 2 The Constrained Fractal Approach 2.1 Deterministic Component A constrained fractal 
is a physically-based model which makes use of the energy minimization principles underly- ing variational 
splines [1]. 1 These principles characterize spline curves and surfaces as the "smoothest" shapes con- 
sistent with the given constraints; this gives rise to an in- teresting relationship connecting variational 
splines to spa- tial smoothing filters (see [16,13,12]). What is surprising, however, is that "spline 
smoothing filters" can provide the spatial frequency characteristics of fractal fields [13]. To exploit 
the filtering property of variational splines ~in generating constrained fractals, we employ a gen-eral 
class of multivariate spline models called controlled- continuity splines [16]. These splines allow us 
to create the desired shape by applying local constraints (say, on posi- tion and/or orientation) at 
arbitrary points. Physically, the constraints are interpretable as external forces which shape the spline 
[15]. Controlled-continuity splines also afford local control over smoothness, which permits us to introduce 
jump or crease discontinuities at arbitrary points on the spline to yield a piecewise smooth shape. 2.2 
Stochastic Component To introduce fractal detail into the shape, we go one step further. As it minimizes 
its deformation energy under the influence of constraint forces, we subject the controlled- continuity 
spline to white noise. Visualize this physically as continually bombarding the spline shape with point 
masses impacting at random velocities. The impulses im- parted by these projectiles randomly perturb 
the spline as it "relaxes" into a stochastic equilibrium (characterized by minimal time-averaged energy 
under the random per- turbations). During relaxation the spline diffuses the ef- fects of the perturbations 
spatially, eventually shaping the flat spectrum of the perturbations into the desired fractal spectrum. 
2  2.3 Bayesian Interpretation We can also motivate our approach by making use of an- other interesting 
relationship, first developed in statistical mechanics, which connects energy functionals to random 1Vaxiational 
splines are simple instances of "deformable models" (see [18,17]); hence, the constrained fractal technique 
extends to this general class of physically-b~ed models a8 well. 2 As Lewis [9] has argued, the spectrum 
of the random process need not be truly fractal in order to provide realistic detail. We use the term 
"fractal" to describe a random function who6e spectrum we can control. 52 fields via the Boltzmann probability 
distribution [7]. The relaxing controlled-continuity spline can therefore be inter- preted as a "Gibbs 
Sampler" which draws sample shapes from a Boltzmann distributed ensemble that has ffractal statistics 
due to the spline's internal energy [13]. The con- strained fractal is thus a typical sample from the 
posterior distribution, i.e., a random fractal sample consistent with the observations which are provided 
by the constraints.  2.4 Algorithmic Features The stochastic equilibrium of the spline is computable 
by a stochastic relaxation algorithm implemented as a local, iterative, numerical process. We obtain 
such an a~go-rithm by locally discretizing the continuous sphne energy functionals using regular finite 
difference or finite element grids. 3 Each relaxation step replaces the values of nodal vari- ables on 
the grid by a noise-perturbed weighted combina- tion of neighboring variable values, thereby propagating 
information from node to node across the grid. Because of the loced nature of the communication, a large 
number of iterationsmay be necessary for the stochastic relaxation process to converge on large, fine 
grids. If the variational spline problem is discretized on a sequence of successively coarser grids, 
however, the convergence rates improve dra- matically [151. In this paper we propose a multiresolution 
stochastic relaxation process which computes the interpo- lated fractal shape efficiently. The multi.resolution 
process is readily parallelizable, and is therefore suitable for mas- sively parallel computers. 2.5 
Fractal Terrain Generation As an application of our constrained fractal technique, we concentrate on 
the problem of terrain generation for the synthesis of realistic outdoor scenes. Fractal terrain generation 
[10] has traditionally been approached using a variety of stochastic subdivision tech- niques. Fournier 
et al. [4] employ a technique called ran- dom midpoint displacement which creates a tessellated sur- 
face by recursively subdividing triangles. The height of each newly created interior point is randomly 
perturbed away from its original interpolated value, and the mag-nitude of each perturbation is related 
to the level of the subdivision. Varying this relationship results in ffractals of arbitrary degree. 
Voss [19] uses successive random addi- tions, which differs in that all of the points are randomly perturbed 
at each subdivision step (not just the newly ere- SRegular ("fine-grained") grich are independent of 
the spatial or- ganization of the data and lead to algorithms that are readily im- plementable on massively 
parallel computational strttctures. These properties account for the prevalent ttse of regular grids 
in the com~ purer vision cormntmity, as does the massive paralleellsm of the early human visual system 
[8]. Our use of regular grids st~ in contrast to conventional tee.h.n.iques for interpolating sparse 
data in eorapute~r graphics applications. The latter usually involve irregularly triangu- lating the 
doraain in a data dependent fashion [5] (techniques have also been developed for the simpler case of 
interpolating "gridded"  data [31). ated ones). Lewis [9] proposes generalized stochastic sub- division, 
a refinement of random midpoint displacement. Instead of displacing each midpoint independently, he adds 
correlated Gaussian noise, which alleviates the artifacts due to spatially nonstationary statistics across 
triangles that are sometimes evident with the preceeding methods. Unlike the above methods, our multiresolution 
stochastic relaxation algorithm can easily accommodate arbitrary constraints as additional terms in its 
energy min- imization principle. The solution is guaranteed to have spatially stationary statistics, 
so long as we perform a suf- ficient number of iterations on the fine level (in practice, this number 
proves to be quite low). To apply our constrained fractal technique to terrain modeling, we may begin 
either with synthetic elevation landmarks selected by a user or with true elevation data ac- quired in 
surveys or through aerial photogrammetry. The first step is to create the terrain model from these typi- 
cally sparse elevation data (e.g., isoelavation contours) by interpolating a dense digital elevation 
map in the form of a gridded, single-valued surface ](u, v). To do so, we supply these data to our algorithm 
as elevation constraints d~, let- ting the controlled-continuity spline serve as an interpolant whose 
parameters afford local control over the continuity of the surface and the tightness of fit to the data. 
At the same time, the stochastic mechanism invents fractal de- tail that enhances the realism of the 
interpolated terrain model. Thus our technique solves the surface fitting and detail generation problems 
simultaneously. 3 Variational Splines Variational splines are characterized by the minima of en- ergy 
functionals. To construct a variational spline, we first define a deformation energy functional E over 
a suit- able class of functions, and then compute a function which minimizes g. In the univariate case, 
the minimizing func- tions approximate the steady-state deformations of elastic strings and beams subjected 
to applied forces. Suppose that we stretch an elastic string horizontally along the z axis. Let z = u 
denote the coordinate along the string and let y = f(u) give the shape of the string as a function of 
u. The (linearized) deformation energy associated with f is given by 1 /" 2 E(/) = j where f,, indicates 
differentiation with respect to u. Next, suppose that f(u) gives the shape of an elastic beam. The (linearized) 
deformation energy of the beam is 1 /" 2 (ff) = ~ J f~, du, where fun denotes the second derivative. 
Note that the minimum of this expression characterizes the common cu- bic spline [1]. Because the string 
has tension, it defines a continuous curve f. Since the beam resists bending, it defines a smoother curve 
f that is not merely continuous in position but also in tangent.  3.1 Controlled-Contlnulty Spllnes 
 We can blend the above energies to create a model that combines the properties of the string and beam. 
Introduc- ing nonnegative rigidity p(u) and tension [1 - v_(u)] param- eter functions that take values 
between 0 and 1 inclusively, the hybrid energy functional is  ep(II) = -+ (1) Note, that if we restrict 
p(u) = p and r(u) ~- r to be global constants independent of u, the above spline reduces to the globally 
continuous ~spline under tension" proposed by Schweikert [11]. As functions of u, however, p(u) and r(u) 
provide local control over the continuity of the curve. Consequently, the function f which minimizes 
(1) is a controlled-continuity spline [16]. In regions of u where p(u) > 0 and r(u) > 0, the spline is 
continuous in both position and tangent, tend- ing towards the string as v(u) ~ 0 and towards the beam 
as r(u) ~ 1. In regions where r(u) = 0, the spline is free to have discontinuous tangents (creases), 
and in regions where p(u) = 0, the spline is free to have discontinuous positions (fractures). The univariate 
controlled-continuity splines general- ize to any number of variables, to any embedding space dimensionality, 
and to arbitrary order of continuity (see Appendix A), thereby providing a unified treatment of curves, 
surfaces, solids, or higher-dimensional models (in spacetime) [16]. Since in this paper we concentrate 
on ter- rain modeling applications, we make use of the bivariate case--surfaces. Appendix A defines controlled-continuity 
surface splines based on the membrane and plate, the nat- ural bivariate analogues of the string and 
beam. 3.2 Fitting Data To formulate the spline fitting problem, we combine the energy functional of the 
controlled-continuity spline with a data compatibility constraint. In the univariate case, the data is 
a collection of values {Pi} = {(ul,d~)}. A simple data compatibility constraint measures the squared 
(weighted Euclidean) distance between the data and the spline f(u) using the constraint functional 1 
6(f; {w}) = c, -d,) (2) i where the weights ci are inversely related to the variance of the uncertainty 
(noise) in the data (ci = a[2). 4 To find the approximating spline, the functionals (1) and (2) are combined 
to form the energy functional E(f) -~ ~ep(f) '4- ed(f; {Pi}), (3) where A is known as a regularization 
parameter. This con- tinuous formulation of the variational spline fitting prob- 4We can handle orientation 
(slope) data ol by adding the term 1 ~ C', (/~(u~) -o~) 2 to (2) [161.   r~~SIGGRAPH '89, Boston, 
31 July-4 August, 1989 ~  Figure 1 Sphne approxlmatmn lem in terms of a functional applies to arbitrarily 
struc- tured constraint data, whether gridded, contoured, or scat- tered. Figure 1 illustrates a physical 
interpretation of (3) in the univariate case. The first term defines the energy of the spline curve. 
The second term corresponds to the en- ergy of a collection of zero-length ideal springs (with spring 
constants cl) connecting the spline to the data points. The springs apply forces which deflect the spline 
such that it ap- proximates the data (infinitely stiff springs result in strict interpolation). When 
(3) is at a minimum, the physical system is at equilibrium, such that the forces exerted by the springs 
balance the reluctance of the spline to deform. 3.3 Finite Element Discretization To minimize (3), we 
apply the finite element method, which provides a systematic approach to the discretiza- tion and solution 
of variational spline problems [15]. We discretize f(u) on a regular "fine grained" mesh of nodal variables 
(see Footnote 1). When finite element analysis is applied to quadratic functionals such as (1), 5 we 
obtain a discrete energy func- tion expressible as a quadratic form: .Ep(X) ~- --lxTApx (4) 2 where 
x is the vector of nodal variables. 8 The prior model matrix Ap is sparse, having at most 13 entries 
per row (see [15,12] for details). Similarly, the discrete data constraint in (2) can be written as 1 
d)TAd(x d), (5)Ed(X , d) = ~(x -- SActually, (1) is quadratic only if p(u) and ~r(u) are fixed functions. 
 For example, in the mdvariate case X = [/(0) ..... f(jh) ..... y((M -1)h)]', where h is the spacing 
of a linear M-node mesh. 54 Figure 2: Sparse data points where a is a zero-padded vector of data values, 
and the di- agonal matrix Ad has entries w~ where data points coincide with nodal variables and zeros 
elsewhere. Using (4) and (5), we write the combined energy (3) in discrete form as E(X) = ~xT Ax-- xrb 
+ k (e) where k is a constant, while A=AAp+Ad and b=Ad~t. , This energy function has a minimum at x 
= x*, the solu- tion to the linear system of algebraic equations Ax = b. (7) In principle, the solution 
to (7) can be found using ei- ther direct or iterative numerical methods. Direct methods are impractical 
for solving large systems associated with fine meshes because of excessive storage requ~ements. Al-ternatively, 
simple iterative schemes such as Gauss-Seidel relaxation requ~e relatively little storage but can be 
very slow to converge. We resolve the difficulty using multigrid relaxation, which accelerates convergence 
by solving the problem at multiple resolution levels [15]. 3.4 A Surface Fitting Example To better visualize 
the fitting of variational spline models to scattered data, let us consider a small example involv- ing 
the bivariate controlled-continuity spline model given in Appendix A. Figure 2 shows nine data points. 
The in- terpolated thin plate (v --1) solution on the finite element mesh is shown in Figure 3. Note 
that a jump discontinuity (p = 0) has been introduced along the left edge and an orientation discontinuity 
(r = 0) along the right edge. Figure 3: Interpolated piecewise continuous solution 4 Converting Energies 
into Probabilities The controlled-continuity splines presented in the previ- ous section give us a powerful 
approach to interpolating (or approximating) data with differing amounts of smooth-ness. For many graphics 
applications, however, the result- ing shapes have insufficient detail or random texture to look natural. 
We will now show how to convert our spline energy functions into probability distributions from which 
we can draw random samples having fractal textures. The idea of converting an energy function into a 
prob- ability distribution comes from statistical mechanics. In many stochastic physical systems, the 
probability of a particular configuration is inversely related to its energy. Many different equations 
for transforming energies to prob-. abilities are possible. For our application, we will use the Boltzmann 
distribution, where the energy of a state E(x) is related to its probability p(x) through a negative 
expo- nential: p(x) = ~ 1 exp (-Ep(x)/T) (S) (the partition function Z is used to normalize the dis-tribution). 
The temperature parameter T controls how "peaked" the distribution is with respect to its low-energy 
states. The Boltzmann distribution has properties which make it useful for modeling random fields [7]. 
For our pur- poses, the most important of these is that multiplicative interactions between probability 
distributions can be con- verted into additive interactions between energies. This becomes particularly 
useful when we look at fractal gener- ation as sampling from a constrained (conditional) distri- bution 
using the Gibbs Sampler algorithm to be presented in the next section. Figure 4:-Sample from posterior 
distribution Interestingly, we can use the energy of the controUed- continuity spline model to define 
a Boltzmann distribution with a fractal spectrum. A Fourier analysis of this prior model reveals that 
the resulting distribution is correlated Gaussian noise with a fractal spectrum (i.e., self-affine over 
scale) for the membrane or string (v = 0) and for the thin plate or beam (r = 1) [13] (see Appendix B). 
When data d constrain the fractal shape, we may obtain it by sampling from the conditional distribution 
p(xld ). This posterior distribution can be calculated using Bayes' rule  v(dfx) p(x) (9) P(xld) = p(d) 
where the distribution p(d) is a normalization factor. The conditional distribution p(dlx ) can be derived 
from a mea- surement model which describes how the data d was ac-- quired from a sample shape x [12]. 
For a linear measurement model, the negative loga- rithm of the posterior distribution p(xld ) can be 
written as the sum of two energy functions -logp(xld) = g(x; d) = Ep(x) + Ed(X, d); (10) i.e., the posterior 
distribution is itself a Boltzmann dis- tribution. We thus have a correspondence between our Bayesian 
models and the constraints used in the previ- ous section to fit the generalized spline. The measurement 
model p(dlx) corresponds to the constraint data. The prior model p(x) corresponds to the controlled-continuity 
spline. As Shown in Appendix B, we can control the spectrum of this prior model through our choice of 
the order of the spline. The posterior distribution p(x[d) thus defines a class of random shapes which 
are drawn from a family of fractais '89, Boston, 31 July-4 August, 1989 and which are also consistent 
with given shape constraints (observations). The most likely sample from this distribu- tion, the Mazimum 
a Posteriori (MAP) estimate, corre-sponds to the minimum energy solution of (7), as shown in Figure 3. 
A ~ypical sample from this distribution is shown in Figure 4. Devising an efficient method for generating 
such a random sample is the subject of the next section. Multiresolution Stochastic Relaxation The explicit 
evaluation of the Boltzmann distribution given in (8) is very difficult because the computation of the 
partition function Z requires a summation over all possi- ble states. Fortunately, we can generate random 
samples from this distribution using a simple algorithm known as the Gibbs Sampler [7]. At each step 
of this iterative algo- rithm, a new random state is chosen from the Boltzmann distribution corresponding 
to the local energy function of the variable being updated. This updating rule is guaran- teed to convergence 
to a random sample from the overall distribution (the ensemble is then said to be at thermal equilibrium). 
For our quadratic energy function (6), the local energy function for the node zi (with all other nodes 
fixed) is E(=~) = [a,=~ + a~jzj -b~ =~ + k, (11) i where a 0 are the entries of A, and Ni expresses 
the fact that the aij are nonzero only for certain neighbors of node i (see [14] for details). When using 
Gauss-Seidel relaxation, we choose the new node value which minimizes this local energy = -a,j j (12) 
aii (for pure interpolation, we set x/+ = di at points coincident with data). We can thus rewrite the 
local energy as i k'.  (13)  For the Gibbs Sampler algorithm, we choose the new value for :el from 
the local Boltzmann distribution -=~)2) (14) p(zi) oc exp(-E(xi)/T) (x exp 2 T/aii which is a Gaussian 
with mean equal to the deterministic update value z/+ and a variance equal to T/aii. Thus, the Gibbs 
Sampler is equivalent to the usual relaxation algo- rithm wish the addition of some locally controlled 
Gaussian noise at each step. For instance, the sample surface in Fig- ure 4 exhibits the rough (wrinkled) 
look of fractals. The amount of roughness can be controlled with the "temper- ature" parameter T. 5.1 
Multiresolution Acceleration Although the above iterative algorithm will eventually achieve stochastic 
equilibrium, the convergence may be un- acceptably slow in practice. To accelerate conyergence, we use 
coarse-to-fine relaxation on a multiresolution pyramid. The problem is first solved on a coarser mesh, 
and the solution is used as an initial condition for the next finer level. The coarse-to-fine technique 
is thus similar to re-cursive subdivision and successive addition techniques [4,19,9]. Unlike these approaches, 
however, we do not just add random detail as the resolution is increased. Instead, we use the coarse 
(low resolution) solution as an initial con- dition for the stochastic relaxation algorithm. The itera. 
tire nature of this algorithm removes the nonstationarities that are present in the interpolated initial 
condition, and it also allows us to impose constraints at finer resolutions. The disadvantage of this 
approach is that the coarse level sample may no longer look like a subsampled version of the fine level 
sample. This lack of "internal consistency" becomes a problem when we wish to generate renderings at 
a variety of scales [4]. We can avoid this discrepancy either by limiting the number of iterations at 
the finer levels, or by "freezing" the points derived from the coarse level and only iterat- ing on the 
new points (which resembles random mid-point displacement). The second approach is usuMly preferable, 
since it allows the fine level shape to relax sufficiently so that "creases" or other artifacts are not 
visible. However, if this freezing procedure occurs at a resolution much coarser than that of the data, 
the resulting shape will not fit the data as well as it could. A strategy which allows full relax- ation 
until the data resolution is reached and then freezes coarse level points as more detail is added works 
well in practice. In [14] we present examples of this approach ap- plied to the generation of "zoom sequences" 
over fractal terrain. Using a multiresolution pyramid also gives us addi- tional control over the spectrum 
of the fraetal shape, When we use a membrane (string) or thin plate (beam) model in our stochastic relaxation 
algorithm, the resulting spectrum is fractal, but it is limited to the form ss( ) which corresponds 
to fractal fls of 2 and 4 respectively (Appendix B). The simplest way to approximate an inter- mediate 
fractal degree is to use the controlled-continuity spline. If we choose wl = wgw2 in (18), we obtain 
a power spectrum which behaves as S,, oc ]~]-3 in the vicinity of coo. At lower frequencies, the model 
behaves as a mem- brane, while at higher frequencies it behaves like a thin plate. We can extend the 
range of intermediate fractal be- havior by modifying the coarse-to-fine Gibbs Sampler. In- stead of 
implementing the same energy equation at each level, we modify the Mgorithm so that a different blend 
of  Figure 12: Constrained fractal with spatially varying frac- tal degree and variance tically detailed 
shapes that interpolate data or match pre- scribed shape constraints. The deterministic component of 
our technique employs variational splines which can gen- erate piecewise continuous shapes that satisfy 
sparse, ir- regular position and orientation constraints. The stochas- tic component of constrained fractals 
injects noise into the spline energy minimization procedure in order to imbue the shapes with fractal 
characteristics. Using the constrained fractal model, we can locally control the continuity of the underlying 
shape and the amount of random detail added. Such controllability makes our approach extremely flexible. 
The constrained fractal computation is performed on a regular, fine-grained mesh using stochastic relaxation; 
hence, it is amenable to massively parallel implementa- tion. We use a multiresolution pyramid to accelerate 
the convergence of the relaxation process. This coarse-to-fine procedure bears some similarity to existing 
recursive sub-- division schemes. Unlike these other schemes, however, constrained fractals avoid the 
artifacts that are introduced during the subdivision process, and they can assimilate constraints at 
any resolution (instead of merely refining a coarse map). The ideas developed in this paper are applicable 
to other deformation energy based models, such as those de- veloped in [18,17]. By augmenting these dynamic 
models with a closely related method for fractal detailing, we can synthesize a greater variety of realistic, 
three-dimensional shapes and motions which, in principle, can be readily con- trolled and constrained. 
The generality of our approach makes it suitable for a wide range of modeling and com- puter graphics 
applications. Acknowledgements This research was carried out in part while the authors were at Schlumberger 
Palo Alto Research, Palo Alto, CA, and while Richard Szeliski was at SRI International, Menlo Park, CA. 
The digital elevation data was provided courtesy of Jeff l:todriguez of the University of Texas at Austin. 
The color images were rendered using a modeling testbed system implemented by Kurt Fleischer on Symbolics 
Lisp Machines. A Multivariate Spline Interpolation There exist natural multivariate extensions to the 
defor- mation energy functionals given in Section 3 [16]. The bivariate extension of (1) is the "thin 
plate under tension" ep(f) = 5 0(u, v){[1 -+ + r(u, v)(fu2u + 2f~2,, + f~,,)} dudv, (16) where, the 
(f,~ + f~) gives the stretching energy density of a membrane, while the (f,~,, + 2f,~,, + f~,,) term 
gives the bending energy density of a thin plate. As in the univari- ate case, the rigidity and tension 
functions can be used to introduce discontinuities in position and orientation. The bivariate extension 
of the data compatibility constraint (2) is 1 (17) ~d(f; {Pi}) : 5 i The functional (16) is a second-order 
instance of the general d-variate, p-order controlled-continuity spline model ep(.f) =  p w.,(u)~ j,!'''jd! 
Ou l''..Ou~" du -j~+...+j4=m (18) where u is the d-dimensional domain of f. This more general formulation 
allows us to specify interpolators of arbitrary smoothness. A generalized version of the data compatibility 
term is  ed = 7 (u)lI(u) -a( )l du (19) where d(u) and c(u) are now continuous functions. B Fractal 
Nature of Prior Model By taking the Fourier transform of the function f(u) and expressing the energy 
equations in the frequency domain, we can analyze the filtering behavior and the spectral char- acteristics 
of the spline model. Using Rayleigh'~]energy theorem we can rewrite p(f) in terms of the Fourier transform 
F(~) = .T{.f(u)} to obtain the new energy function EL(F). Using the gen- erai form in (18) with the simplifying 
assumption that the '89, Boston, 31 July-4 August, 1989   S GGRAPH weighting functions are constant, 
w~ (u) = wm,r we obtain E (F) _- 7 ,/ (20) where P IG(~)I ~ = ~ w,~l~l 2m. (21) m----O For the membrane 
interpolator, IG(~)I 2 cx [~l 2 and for the thin plate model, IG(~)I ~ ~ I~,14, We note that since the 
Fourier transform is a lin-ear operation, if f(u) is a random variable with a Boltzmann distribution 
with energy Ep(f), then F(~) is a random variable with a Boltzmann distribution with energy ~(F). Thus, 
p(F) is proportional to exp (-~f IG(w)lZlF(w)lZd~) from which we see that the probability distribution 
at any frequency ~ is Therefore, F(e) is a random Gaussian variable with vari- ance IG(~,)I -~, and the 
signal f(u) is correlated Gaussian noise with a spectral distribution Sy(w) = IG(~,)1-2. (22) From this 
analysis, we can conclude that using a controlled-continuity spline is equivalent to using a cor-related 
Gaussian field as the Bayesian prior. The spectral characteristics of this Gaussian field are determined 
by the choice of spline parameters. For the membrane and the thin plate models, we have Smembrame(~) 
O( I.,I -~ (23) and S'~hln-pl.,,(,~) o: I~l -'. (24) These equations are interesting because they correspond 
in form to the spectra of Brownian fractals, which can be characterized by the power law  ) (25) This 
spectral density characterizes a fractal Brownian function vH(u) with 2H = ~ -E, whose fractal dimen- 
sion is D = E + 1 - H (where E is the dimension of the Euclidean space) [19]. Comparing (23) or (24) 
to (25), we can conclude that a random sample drawn from a Boltz-mann distribution constructed using 
the energy model of a membrane or a thin plate is indeed fractal [13]. rWhile this a~suraption does not 
strictly apply to general piece- wise continuo'txs interpolation, it provides art approxirrtatiort to 
its local behavior away from boundaries and discontinuities. References [1] J. H. Ahlberg, E. N. Nilson, 
and J. L. Walsh. The Theory of Splines and their Applications. Academic Press, New York, 1967. [2] R. 
H. Bartels, J. C. Beatty, and B. A. Barsky. An I~ troduction to Splinea for use in Computer Graphics 
and Geometric Modeling. Morgan Kaufmann, Los Altos, CA, 1987. [31 T. A. Foley. Weighted bicubic spline 
interpolation to rapidly varying data. A CM Transactions on Graphics, 6(1):1-18, January 1987. [4] A. 
Fournler, D. Fussel, and L. Carpenter. Computer ren- dering of stochastic models. Communications of the 
A CM, 25(6):371-384, 1982. [5] H. Fuchs, Z. M. Kedem, and S. P. Oselton. Optimal surface reconstruction 
from planar contours. Communications of the ACM, 20(10):693-702, October 1977. [6] D. Geman and Hwang 
C.-I~. Diffusions for global op- timization. SIAM Journal o/ Control and Optimization, 24(5):1031-1043, 
September 1986. [7] S. Geman and D. Geman. Stochastic relaxation, Gibbs dis- tribution, and the Bayesian 
restoratioa of images. IEEE Transactions on Pattern Analysis and Machine Intelli-gence, PAMI-6(6):721-741, 
November 1984. [8] B. K. P. Horn. Robot Vision. MIT Press, Cambridge, Massachusetts, 1986. [9] 3. P. 
Lewis. Generalized stochastic subdivision. ACM Transactions on Graphics, 6(3):167-190, July 1987. [10] 
B. B. Mandelbrot. The Fractal Geometry of Nature. W. H. Freeman, San Francisco, 1982. [11] D. G. Schweikert. 
An interpolation curve using spline in tension. J. Math. and Physics, 45:312-317, 1966. [12] R. Szeliski. 
Bayesian Modeling of Uncertainty in Low- Level Vision. PhD thesis, Carnegie Mellon University, Au- gust 
1988. [13] R. Szellski. Regularization uses fractal priors. Y.u AAAI- 87: Sixth National Conference on 
Artificial 2ntellig~nce, pages 749-154, Morgan Kanfmann Publishers, Seattle, Washington, July 1987. 
[14] R. Szeliski and D. Terzopoulos. Constrained fraetals using stochastic relaxation. Submitted to A 
CM Transactions on Graphics, 1989. [15] D. Terzopoulos. Multilevel computational processes for visual 
surface reconstruction. Computer Vision, Graphics, and Image Process,he, 24:52-96, 1983. [16] D. Terzopoulos. 
Regularization of inverse visual problems involving discontinuities. IEEE Transactions on Pattern Analysis 
and Machine Intelligence, PAML8(4):413-424, July 1986. [17] D. Terzopoulos and K. Fleischer. Deformable 
models. The Visual Computer, 4(6):306-331, December, 1988. [18] D. Terzopoulos, J. Platt, A. Burr, and 
K. Fleischer. Elas- tically deformable models. Computer Graphics (SIG-GRAPH'87), 21(4):205-214, July 
1987. [19] R. F. Voss. Random fractal forgeries. In R. A. Earnshaw, editor, Fundamental Algorithms for 
Computer Graphics, Springer-Verlag, Berlin, 1985. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74339</article_id>
		<sort_key>61</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Hardware acceleration for Window systems]]></title>
		<page_from>61</page_from>
		<page_to>67</page_to>
		<doi_number>10.1145/74333.74339</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74339</url>
		<abstract>
			<par><![CDATA[Graphics pipelines are quickly evolving to support multitasking workstations. The driving force behind this evolution is the window system, which must provide high performance graphics within multiple windows, while maintaining interactivity. The virtual graphics system presented by [7] provides a clean solution to the problem of context switching graphics hardware between processes, but does not solve all the problems associated with sharing graphics pipelines.The primary difficulty in context switching a graphics accelerator is the pipeline latency encountered during a pipeline flush. This latency removes the responsiveness and interactivity of the graphics system. As primitives become more complex and pipelines become longer, pipeline latency grows. Hardware solutions are described which further accelerate the window system by eliminating the need for pipeline flushing and resynchronization. An overview of the entire system is presented, highlighting the hardware mechanisms which contribute to window acceleration.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P55936</person_id>
				<author_profile_id><![CDATA[81100386243]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rhoden]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hewlett-Packard Company, Graphics Technology Division, Fort Collins, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P39439</person_id>
				<author_profile_id><![CDATA[81332535809]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wilcox]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hewlett-Packard Company, Graphics Technology Division, Fort Collins, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akeley, Kurt and Jermotuk, Tom. High-Performance Polygon Rendering. Proceedings of SIGGRAPH'88 (Atlanta, Georgia, August 1-5, 1988). In Computer Graphics 22,4 (August 1988), 239-246.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Foley, James and Van Dam, Andries. Fundamentals qf Interactive Computer Graphics Addison-Wesley, Reading, Massachusetts, 1982]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Newman, William and Sproull, Robert. Principles of Interactive Computer Graphics. McGraw-Hill, New York, New York, 2cnd edition, 1979]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>24053</ref_obj_id>
				<ref_obj_pid>22949</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Scheifler, Robert and Gettys, Jim. The X-Window System. ACM Transactions on Graphics 5,2 (April 1986), 79-109.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger and Thayer, Larry. A Fast Shaded-Polygon Renderer. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20,4 (August 1986), 95-101.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37426</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Torborg, John. A Parallel Processor Architecture for Graphics Arithmetic Operations. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics 21,4 (July 1987), 197-204.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378517</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Voorhies, Douglas, Kirk, David, and Lathrop, Olin. Virtual Graphics. Proceedings of SIGGRAPH'88 (Atlanta, Georgia, August 1-5, 1988). In Computer Graphics 22,4 (August 1988), 247-253.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 HARDWARE ACCELERATION for WINDOW SYSTEMS Desi Rhoden 
Chris Wilcox Hewlett-Packard Company Graphics Technology Division Fort Collins, Colorado, 80525 ABSTRACT 
Graphics pipelines are quickly evolving to support multi- tasking workstations. The driving force behind 
this evolution is the window system, which must provide high performance graphics within multiple windows, 
while maintaining inter- activity. The virtual graphics system presented by [7] provides a clean solution 
to the problem of context switching graphics hardware between processes, but does not solve all the problems 
associated with sharing graphics pipelines. The primary difficulty in context switching a graphics ac- 
celerator is the pipeline latency encountered during a pipeline flush. This latency removes the responsiveness 
and interactivity of the graphics system. As primitives become more complex and pipelines become longer, 
pipeline latency grows. Hardware solutions are described which further ac- celerate the window system 
by eliminating the need for pipeline flushing and resynchronization. An overview of the entire system 
is presented, highlighting the hardware mechanisms which contribute to window acceleration. CR Category: 
1.3.1 [Computer Graphics]: Hardware Ar- chitecture - Raster Display Devices. 1. INTRODUCTION Workstations 
communicate with their users through an in- terface that allows the user to create and manipulate windows. 
The primary function of a window system is to provide the user with simultaneous access to multiple processes 
on the workstation. Each process provides an in- terface to the user through its own area on the display. 
The result is increased productivity since the user can manage more than one task at a time. An emerging 
standard for window systems is the X window system [4] developed at MIT. The implementation described 
in this paper is based on X windows, but the discussion is applicable to any win- dow system. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery:; To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 
ACM-O-89791-312-4/89/O07/O061 $0o.75 Each process associated with a window views the workstation resources 
as if it were the sole owner. This means that resour- ces such as the processing unit, memory, peripherals, 
and graphics hardware must be shared between these processes in a manner which prevents conflicts. Efficient 
methods for transparent sharing between processes already exist for con- ventional computing resources; 
good examples are time-sliced processors and virtual memory systems. Similar schemes allow processes 
to share graphics hardware such as framebuffers and graphics accelerators. The goal of our system is 
to provide a virtual graphics device to each process requesting graphics [7]. Actual implementation of 
virtual graphics requires extensive hardware support within the graphics system. Many of the difficulties 
that exist with virtual implementations are a result of the pipeline architec- ture common to most graphics 
devices. Sharing the graphics accelerator has traditionally required pipeline flushing and resynchronization 
to maintain the illusion of a virtual device. Unfortunately, these operations are costly and can impact 
user interactivity, especially when multiple windows are active and context swapping occurs between the 
host and graphics device. The problem is similar to a virtual memory system thrashing when a majority 
of CPU time is spent swap- ping pages. To further compound the problem, the current trend of our graphics 
pipelines is towards higher level, more complex primitives. The complexity of these primitives re- quires 
more processing time in the pipeline, which increases the penalty for a pipeline flush. Our systems currently 
sup- port spline primitives that can require several seconds to render, and pipelines can typically contain 
hundreds of these primitives. Considering the trends toward more complex primitives and longer pipelines, 
it is clear that alternatives to pipeline flushing are necessary for good system perfor- mance. Allowing 
the window system to freeze while rendering proceeds can no longer be considered a viable op- tion. Software 
solutions exist for many of these problems, but are not fast enough. To provide interactivity for a sig- 
nificant number of windows requires hardware solutions, especially when those windows require the graphics 
ac- celerator.   '~Lq~SIGGRAPH '89, Boston, 31 July-4 August, 1989 The goal of the hardware described 
in this paper is to create a graphics device that can be shared between multiple win- dows in an efficient 
manner. Graphics operations within a window should not unduly influence the performance of graphics inside 
of other windows. To achieve this goal for an unlimited number of windows would require an uncon- strained 
amount of hardware. Since hardware is costly, our solution is to provide acceleration for a reasonable 
number of windows with a limited amount of resources. The system described in this paper is currently 
under development. However, many of these features have already been imple- mented in currently available 
systems. Each feature will be discussed in detail in the following sections. The key hardware resources 
provided to accelerate the window sys- tem are listed below: 1. MULTIPLE GRAPHICS CONTEXTS. 2. PIPELINE 
SYNCHRONIZATION. 3. PIPELINE BYPASS AND VALVE. 4. PIPELINE MARKER CIRCUITRY. 5. WINDOW RELATIVE RENDERING. 
 6. WINDOW BLOCK MOVER. 7. WINDOW BURST TRANSFER. 8. WINDOW COMPARE CIRCUITRY. 9. WINDOW CLIPPING 
PLANES. 10. WINDOW DISPLAY MODE PLANES. 11. WINDOW OVERLAY PLANES. 12. WINDOW OFFSCREEN PLANES. 13. 
MULTIPLE HARDWARE DISPLAY MODES. 14. MULTIPLE HARDWARE COLOR MAPS. 15. HARDWARE CURSOR SUPPORT  Tho 
ideal graphics hardware would provide a separate resource for each window, obviously not a practical 
solution. Instead, enough resources for a reasonable number of win- dows are added to the system, and 
these resources are shared in the most efficient manner possible. Window support is integrated into the 
pipeline at the correct location to mini- mize interaction of the window system software with graphics 
rendering. Quick access to window control cir- cuitry is required to allow fast switching, providing 
the appearance of an unlimited resource. In the sections that follow, the major blocks of our graphics 
accelerator are presented, with the accompanying modifications for window support. 2 HARDWARE SUPPORT 
2.1 System Overview Support for window acceleration exists in all functional areas of the graphics hardware. 
Figure 1 shows the graphics ac- celerator with window support added. The placement of the window support 
circuitry within the pipeline is especially significant. A majority of the window support circuitry is 
placed after the rendering hardware and before the framebuffer. This is the logical location for the 
window relative and window com- pare operations, described in a later section. Both of these operations 
help eliminate the need for pipeline flushing. Another important component is the pipeline bypass, which 
provides the window system with direct access to various components of the system, including the frarnebuffer. 
 2.2 Transform Processor The transform processor is the core of the accelerated graphics system. On our 
workstations, the transform proces- sor block is implemented with parallel floating point processors. 
The transform processors perform many tasks, including graphics context management, matrix transforma- 
tion calculations, spline tessellation, and lighting model computations. The transform processors also 
control vector and polygon rendering hardware, implemented with VLSI components as described in [5]. 
2.2.1 Multiple Graphics Contexts To accelerate multiple processes the pipeline must be capable of handling 
multiple contexts [7]. A graphics context con- sists of the current set of attributes, matrix stack, 
light sources, shading control, spline basis matrices, and other hardware state information. Our early 
products supported only a single hardware context, and required the host software to perform all context 
switching. Software context switching required the host to store context for each active process in virtual 
memory, writing the context to the device when the process was active, and reading the context back afterwards. 
Figure 2 shows software context switching.   Trantf~rm| Host Computer Figure 1 - System Overview Our 
current systems store multiple contexts, eliminating the need to constantly pass contexts between the 
host and graphics device. Our implementation of hardware context switching is shown in Figure 3. The 
only limitation to the number of contexts stored is the size of memory associated with the transform 
processor. Our current products, includ- ing the system described in this paper, support up to 32 contexts. 
When all of the hardware contexts are allocated, the least recently used context can be swapped out by 
the software, using software context switching. Storing contexts in hardware provides high performance 
context switching, an important step in allowing multiple windows to render simultaneously without degrading 
performance. Context switches are performed without flushing the pipeline, or in- terrupting the flow 
of commands to the device. The hardware context does not contain the window offset, a key factor in the 
elimination of pipeline flushing. ~ Computer Graphics, Volume 23, Number 3, July 1989 2.2.2 Pipeline 
Synchronization Another area of window support within the graphics pipeline is synchronization hardware. 
Our system increases the pipeline throughput by using a parallel implementation which contains multiple 
transform processors. Incoming primitives are divided up and sent to individual transform processors. 
Load balancing is performed by determining the Host J Graphics Frame Computer Pipeline Buffer Context 
0 Currerlt Conlext I Context 1 Context 2 I Screen Relative Coordinates I Context n --~ Contexl with Window 
Offset I Figure 2 - Software Context Switching least busy processor, then handing it the current primitive. 
When a primitive is handed to a transform processor, a se- quence marker is stored in the sequence manager. 
The sequence manager is a circuit that keeps track of the order of primitives, so that the outputs from 
the transform proces- sors can be restored to their original order before rendering. Large primitives 
such as polylines, polygon meshes, and splines are split up into segments and sent to separate trans- 
form processors to achieve optimum performance from the parallel architecture. Because the sequence manager 
ensures that these segments are returned to their proper order, results which are order dependent will 
be consistent [6] and repeatable. This would not be assured if ordering were not maintained. Pipeline 
synchronization is necessary in the window system environment to assure that primitives from competing 
processes are rendered in the order requested. 2.2.3 Pipeline Bypass and Valve Although the pipeline 
provides good throughput for render- ing primitives, it creates some problems for interactive window 
performance. The primary problem is that complex primitives can require significant processing time, 
blocking other primitives until they are completely rendered. This means that window operations, which 
should be interactive, can end up waiting. Another problem that reduces interac- tivity of the window 
system is pipeline latency. Pipeline latency is defined as the time required for a single primitive to 
traverse the pipeline. A pipeline that provides excellent throughput can exhibit a very large latency 
time. Host Graphics ~ Window ~ Frame Computer Pipe|ine Circuitry Buffer Context 1 I I~ Context 2 I__ 
__ I .Ser~.e~n nelalive Coordinates I co.,ext o --I C_~ ~~ ....... ,.o coo,~ ..... I Ii_ ____~ Conlr~x:l 
Wilhout W~.dow O('[set~ Figure 3 - Hardware Context Switching Our solution to this problem is to provide 
a separate path for window primitives that do not require the pipeline. The implementation is via a pipeline 
bypass, which allows the window system direct access to the framebuffer. The pipeline bypass supports 
block move, block read, and block write operations in hardware, which will be described later. The pipeline 
bypass is also used to directly render X window system primitives. The philosophy behind the pipeline 
bypass is that window systems often require fast access for operations that are comparatively simple. 
By offering a bypass we can avoid the overhead of the graphics pipeline, while providing the simple services 
required by the window system. The pipeline offers high performance rendering and other advanced features, 
while the bypass offers fast block operations and direct framebuffer access. The net result is a system 
which provides good window system interaction, even in the middle of a complex rendering operation. Because 
separate paths are available to the framebuffer, some form of synchronization must be supplied. The system 
provides explicit control over pipeline access to the framebuffer with a pipeline valve. The pipeline 
valve turns off data coming from the rendering hardware into the framebuffer. When the pipeline output 
is stopped, the win- dow system is free to access the framebuffer. The pipeline valve does not stop the 
transform processors, which continue processing primitives until the entire pipeline backs up. Since 
the pipeline stages are buffered with FIFOs, significant processing will proceed before the pipeline 
fills up. While the pipeline valve is closed the window system may move, resize, or otherwise manipulate 
the windows on the display without regard to the contents of the pipeline, when the pipeline valve is 
opened, rendering will continue to the modified window structure. The primitives being rendered will 
appear in the correct location, because they are window relative. Since the window offset is applied 
after the pipeline valve, window offsets may be changed anytime, even in the middle of drawing a primitive. 
 "L,,I~~SIGG RA PH '89, Boston, 31 July-4 August, 1989 2.2.4 Pipeline Marker Circuitry Another enhancement 
to the pipeline for window support is the pipeline marker. The pipeline marker is a register that the 
window system can access via the pipeline bypass without closing the pipeline valve. It is used to keep 
track of which contexts have primitives still being processed in the pipeline. The purpose is to prevent 
unnecessary pipeline flushing when changing contexts. A context change often requires swapping of system 
resources such as window clip- ping planes or window display mode planes. These must sometimes be swapped 
during a context switch because they are a limited resource, and are shared between multiple processes. 
Window system software needs to ensure that all primitives from the context being swapped out are rendered 
before any swapping is performed. One method for this is to flush the pipeline, which we wish to avoid. 
A pipeline marker register provides a better method for verifying that the least recently used context 
is finished rendering, without flushing the pipeline. With enough window clipping planes and display 
mode planes, it is very unlikely that the least recently used context still has anything in the pipeline, 
since all windows in the system are rarely active simultaneously. The mechanism for keeping track of 
currently active contexts is to send a marker down the pipeline between each context switch. The marker 
value is incremented each time and a table of contexts currently in the pipeline is maintained. This 
table shows the context number, window clipping id, and marker number for each active context. As the 
contexts are processed through the pipeline, the pipeline marker register is automatically updated 'each 
time the marker reaches the end of the pipeline. When a context switch oc- curs, the window system can 
read the marker register and refer to its table to determine which contexts are still in the pipeline. 
If the context being swapped is not in the pipeline, the context switch and clipping plane changes can 
occur im- mediately. If not, the window system must wait until the marker register indicates that the 
context has been processed. Under no condition is it necessary to stop the pipeline, or prevent processes 
from continuing to place com- mands and data into the pipeline. 2.3 Window Circuitry Window support 
circuitry is placed after the rendering hardware and before the framebuffer. The window hardware consists 
of window relative circuitry, window block mover, window burst transfer, and window compare circuitry. 
2.3. I Window Relative Rendering Any graphics application will run faster when it views itself as the 
sole owner of the graphics device. When an applica- tion requests a window, the corresponding framebuffer 
memory is allocated to that application for graphics output. The ideal environment would allow the process 
to treat the window as a stand alone graphics device. Most systems, however, require the process to be 
modified to run inside a window. In other words the application needs to be window smart and post process 
the output of the application to con- form to the window environment, by adding window offsets or clipping 
to window boundaries. Any software that per- forms this processing will reduce overall system performance 
considerably. For this reason we have chosen to implement these functions in hardware. In our system, 
primitives in the pipeline are specified relative to the window origin. Trans-lation to screen relative 
coordinates occurs after scan conversion, before framebuffer access. This lets the applica- tion treat 
the window as a full screen virtual device. Of course, the above operations can be included in the trans- 
formation matrix. However, if the window offset is included in the matrix stack, the pipeline must be 
flushed every time the window is moved or changed. After flushing the pipeline, the new window offset 
is added to the transformation matrix, then the pipeline must be filled up again. This causes a major 
performance degradation. A better solution is to let the application access the device as if it owned 
the entire screen, then provide hardware to offset all primitives into the window associated with that 
process. We have imple- mented this by rendering primitives in window relative coordinates, and performing 
the window relative to screen relative conversion downstream from the rendering hardware. The window 
translation is therefore completely transparent to the application. Because the offset is per- formed 
in parallel with bther pipeline operations, no performance penalty exists. Figure 4 shows a block diagram 
of the window support circuitry, The window relative circuitry consists of a table of offsets with an 
entry for each window. The window offset is applied to each primitive at the framebuffer, allowing all 
primitives within the graphics pipeline to remain window relative. Window offsets can be updated asynchronously 
via the pipeline bypass. This permits windows to be moved or shuf- fled during rendering by closing the 
pipeline valve, moving the window, and modifying the window offset entry. When the pipeline valve is 
opened, rendering will proceed correctly at the new location! This can occur whenever the window system 
moves or otherwise modifies a window. Applications can therefore run without explicit knowledge of their 
window location. 2.3.2 Window Block Mover Block move operations are important for window system per- 
formance. These operations support basic window primitives including raster text, icons, and sprites. 
Window moves, shuffles, and resizes also take advantage of block moves. Block moves can be particularly 
difficult to handle in the window environment, because window offsets need to be included into an operation 
that is typically implemented as screen relative. Block move operations inside a window must be window 
relative, however, forcing all block moves to be window relative is not a good solution. The reason is 
that many objects such as fonts are stored in offscreen memory, and these objects are identified by screen 
relative coordinates. The ideal block mover hardware should there- fore be able to handle several different 
kinds of operations. Our implementation of the block mover includes a register with a bit for each operand 
that. specifies whether the operand is window or screen relative. Block moves can be window relative, 
screen relative, or any combination thereof.  '89, Boston, 31 July-4 August, 1989 ', S,GGRAPH 2.4.1 
Window Clipping Planes Window clipping planes contain an id number for the win- dow that currently controls 
each pixei. When primitives are drawn, the window circuitry compares the window id of the pixei in the 
framebuffer to the window id of the pixel cur- rently being drawn. If the values match, the primitive 
lies inside the window, and the pixel is drawn. If the values are different, the primitive must be clipped, 
so the pixel is dis- carded [1]. Four window clipping planes provide up to sixteen independent windows, 
although one value must usually be reserved as a keep out value. ~ Depth B,Jf~ex Window 4 Clippings 
ID,S Video Circuitry Generator Figure 6 - Framebuffer Organization 2.4.2 Window Display Mode Planes 
Window display mode planes work in a similar fashion [7]. The framebuffer values for each pixel are sent 
in a stream to the video circuitry. At the same time the window display id is also sent. A display processor 
checks all values simul- taneously and reformats the framebuffer data according to the display mode for 
each pixel. This method allows one window to display from 8 planes, another from 24 planes, another in 
12:12 double buffer mode, and so on. Windows which are rendering us ing double buffering can swap buffers 
asynchronously, a necessity to allow independent processes to render smoothly. Four window display mode 
planes pro- vide up to sixteen independent display modes. The color map for each window is also chosen 
based on the display id. Display modes and color lookup tables are discussed in the section on the video 
generator. 2.4.3 Window Overlay Planes Another resource that is useful for a window system is over- 
lay planes. These are framebuffer planes that are merged into the display in front of the image planes, 
allowing win- dows to coexist with rendered images. Since the actual contents of the framebuffer image 
planes are not destroyed by overlay data, our system allows rendering to image win- dows occluded by 
overlay windows. 2.4.4 Window Offscreen Planes Offscreen memory is also a valuable resource for window 
systems. Since many windows use predominantly raster text, raster fonts can be stored in an area of the 
framebuffer that is not displayed. The advantage is that characters from these fonts can be block moved 
into the window, a framebuffer to framebuffer copy, faster than they can be written from the host, a 
system memory to framebuffer copy. The importance of offscreen memory for font storage is reduced if 
accelera- tion is available for the system memory to framebuffer path. Our current systems display 1280 
by 1024 pixels out of the 2048 by 1024 framebuffer, which provides an offscreen area of 768 by 1024 pixels. 
 2.5 Video Generator The video circuitry processes data from the framebuffer and sends it to the raster 
display. The data is formatted according to the current display mode, mapped through a color lookup table, 
and converted from digital values to an analog signal. The window support provided by the video generator 
in- cludes multiple display modes, multiple color maps, and hardware cursors. 2.5.1 Multiple Display 
Modes Window support within the video generator is shown in Fig- ure 7. Multiple display modes are provided 
by the video generator to allow each window to define a unique display mode. The id stored in the window 
display mode planes in the framebuffer is used as an index into the display mode table, which determines 
the display mode for all pixels inside the corresponding window. Valid display modes include full 24-bit 
rgb, 8-bit index, 12-bit index, and many more. Since the display mode selects which framebuffer planes 
are dis- played, double buffering is controlled independently for each window. The display mode id also 
determines the color lookup table and other attributes such as blending for each pixel. The four planes 
for display modes allow for up to 16 different display modes on the display at any one time. Figure 8 
shows multiple display modes within separate windows. l HardwareCursor I ; Lookl /1 Dis ta bode 1 ModeDisplay~ 
Display Control Table Figure 7 - Video Generator   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74340</article_id>
		<sort_key>69</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[The pixel machine: a parallel image computer]]></title>
		<page_from>69</page_from>
		<page_to>78</page_to>
		<doi_number>10.1145/74333.74340</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74340</url>
		<abstract>
			<par><![CDATA[We describe the system architecture and the programming environment of the Pixel Machine - a parallel image computer with a distributed frame buffer.The architecture of the computer is based on an array of asynchronous MIMD nodes with parallel access to a large frame buffer. The machine consists of a pipeline of <i>pipe nodes</i> which execute sequential algorithms and an array of <i>m</i> &amp;times; <i>n</i> pixel nodes which execute parallel algorithms. A <i>pixel node</i> directly accesses every <i>m</i>-th pixel on every <i>n</i>-th scan line of an interleaved frame buffer. Each processing node is based on a high-speed, floating-point programmable processor.The programmability of the computer allows all algorithms to be implemented in software. We present the mappings of a number of geometry and image-computing algorithms onto the machine and analyze their performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>D.4.2</cat_node>
				<descriptor>Distributed memories</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.4.2</cat_node>
				<descriptor>Virtual memory</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor>Image displays</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Parallel processors**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010949.10010950.10010955</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Operating systems->Memory management->Distributed memory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010949.10010950.10010951</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Operating systems->Memory management->Virtual memory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14194891</person_id>
				<author_profile_id><![CDATA[81100561593]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Potmesil]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Holmdel, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P78163</person_id>
				<author_profile_id><![CDATA[81538031556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Hoffert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Holmdel, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[[1] AT&T Pixel Machines, "The Pixel Machine System Architecture," A Technical Report, Holmdel, NJ, November 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[[2] Clark, J. H., "The Geometry Engine: A VLSI Geometry System for Graphics," <i>ACM Computer Graphics</i>, <b>16</b>, (3), July 1982, 127-133.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[[3] DeBenedictis, E. P., <i>The Bell Laboratories' Hypercube</i>, personal communication, April 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356573</ref_obj_id>
				<ref_obj_pid>356571</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[[4] Denning, P. J., "Virtual Memory," <i>Computing Surveys</i>, <b>2</b>, (3), September 1970, 153-189.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808592</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[[5] Dipp, M., and Swensen, J., "An Adaptive Subdivision Algorithm and Parallel Architecture for Realistic Image Synthesis," <i>ACM Computer Graphics</i>, <b>18</b>, (3), July 1984, 149-158.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>810237</ref_obj_id>
				<ref_obj_pid>800179</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[[6] Fuchs, H., "Distributing a Visible Surface Algorithm Over Multiple Processors," <i>Proceedings of ACM 1977</i>, Seattle, WA, October 1977, 449-451.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[[7] Fuchs, H., et. al., "Fast Spheres, Shadows, Textures, Transparencies, and Image Enhancements in Pixel-Planes," <i>ACM Computer Graphics</i>, <b>19</b>, (3), July 1985, 111-120.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>366805</ref_obj_id>
				<ref_obj_pid>366786</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[[8] Heising, W. P., and Larner, R. A., "A Semi-Automatic Storage Allocation System at Loading Time," <i>Communications of the ACM</i>, <b>4</b>, (10), October 1961, 446-449.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>64121</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[[9] Hillis, W. D., <i>The Connection Machine</i>, The MIT Press, Cambridge, MA, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[[10] Kershaw, R. N., et. al., "A Programmable Digital Signal Processor with 32-bit Floating Point Arithmetic," <i>Proceedings of IEEE International Solid-State Circuits Conference</i>, February 1985, 92-93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808581</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[[11] Levinthal, A., and Porter, T., "Chap - A SIMD Graphics Processor," <i>ACM Computer Graphics</i>, <b>18</b>, (3), July 1984, 77-82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[[12] Levoy, M., "Volume Rendering: Display of Surface from Volume Data," <i>IEEE Computer Graphics and Applications </i>, <b>8</b>, (3), May 1988, 29-36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[[13] McCormick, B. H., DeFanti T. A., and Brown, M. D., "Visualization in Scientific Computing," <i>ACM Computer Graphics</i>, <b>21</b>, (6), November 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807467</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[[14] Parke, F. I., "Simulation and Expected Performance Analysis of Multiple Processor Z-Buffer Systems," <i>ACM Computer Graphics</i>, <b>14</b>, (3), July 1980, 48-56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37413</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[[15] Potmesil, M., and Hoffert, E. M., "FRAMES: Software Tools for Modeling, Rendering and Animation of 3D Scenes," <i>ACM Computer Graphics</i>, <b>21</b>, (4), July 1987, 85-93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[[16] Potmesil, M., McMillan, L., Hoffert, E. M., Inman, J. F., Farah, R. L., and Howard, M., "A Parallel Image Computer with a Distributed Frame Buffer: System Architecture and Programming," <i>Proceedings of Eurographics '89</i>, Hamburg, Federal Republic of Germany, September 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2467</ref_obj_id>
				<ref_obj_pid>2465</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[[17] Seitz, C. L., "The Cosmic Cube," <i>Communication of the ACM</i>, <b>28</b>, (1), January 1985, 22-33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325196</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[[18] Sato, H., et. al., "Fast Image Generation of Constructive Solid Geometry Using a Cellular Array Processor," <i>ACM Computer Graphics</i>, <b>19</b>, (3), July 1985, 95-102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[[19] Whitton, M. C., England, N., and DeMonico C., "Manage Design Trade-Offs in High-End Graphics Board," <i>Electronic Design</i>, <b>36</b>, (6), March 1988, 77-84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Pixel Machine: A Parallel Image Computer Michael Potmesil and Eric M. Hoffert AT&#38; T Bell Laboratories 
Holmdel, New Jersey Abstract We describe the system architecture and the programming environment of 
the Pixel Machine -a parallel image computer with a distributed frame buffer. The architecture of the 
computer is based on an array of asyn- chronous MIMD nodes with parallel access to a large frame buffer. 
The machine consists of a pipeline of pipe nodes which execute sequential algorithms and an array of 
m x n pixel nodes which execute parallel algorithms. A pixel node directly accesses every m-th pixel 
on every n-th scan line of an interleaved frame buffer. Each processing node is based on a high-speed, 
floating-point programmable processor. The programmability of the computer allows all algorithms to be 
implemented in software. We present the mappings of a number of geometry and image-computing algorithms 
onto the machine and analyze their performance. CR Categories and Subject Descriptors: C.1.2 [Processor 
Architectures]: Multiprocessors -MIMD processors -parallel processors -pipeline processors; D.4.2 [Operating 
Systems]: Storage Management -distributed memories -virtual memory; 1.3.1 [Computer Graphics]: Hardware 
Architecture -raster display devices; 1.3.3 [Computer Graphics]: Picture/Image Generation -display algorithms; 
1.3.7 [Computer Graphics]: Three Dimensional Graphics and Realism -animation -visible line/sulface algorithms; 
1.4.0 [Image Processing]: General -image displays. General Terms: Parallel, Pipeline, Architecture, Algorithms, 
Geometry and Image Computing, Shared Memory, Distributed Memory, Interleaved Memory, Virtual Memory, 
Message Pass- ing. Additional Key Words and Phrases: Active server, passive server, virtual node, virtual 
shared memory, virtual display lists, virtual volumes, virtual textures, parallel paging. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 
ACM -0- 89791-312-4/89/007/0069 $00.75 1. Introduction As computing technology progressed, it became 
apparent that even the most powerful computers available, built on principles devised by John von Neumann 
in the early 1940s, are reaching the limits of their speed imposed by the constraints of physical laws. 
The single-processor model executing only at most one instruction in every machine cycle is beginning 
to outlive its usefulness. There is no inherent reason why many calculations cannot be performed simultaneously. 
Computer graphics is a perfect example of such an application area. Pixels can be read, written and processed 
simultaneously; in fact, most graphics algorithms impose few limits on the amount of paral- lelism achievable 
for pixel processing. With a parallel architecture, a designer hopes that, instead of the typical linear 
improvement in performance that is inherent in technology evolution, a quantum leap in performadce can 
be obtained. Such a quantum leap has been demanded by the various communities using image computing. 
The recent report Visualization in Scientific Computing [13] stresses the need for innovative high-speed 
architectures to meet the needs of interpreting large amounts of scientific data. Animators require photorealistic 
rendering of high scene complexity and image quality with quick turnaround times. Doctors and radiologists 
must see a 3D reconstruction from an NMR or CT device in seconds. For image computing to he a practical 
tool in these and other areas, it is not feasible to wait for evolution- ary improvements in technology. 
Instead, a break from tradi-tional architectures must occur and be built. In this paper, we describe 
such an architecture; what motivated its development, how it works and what it portends for the future 
of image computing. The design of the Pixel Machine was inspired and influenced by: speed -the advent 
of fast RISC-style digital signal proces- sors that offer a large amount of the functionality found in 
a microprocessor with an integrated floating-point unit at a fraction of the price [ 10].  parallelism 
-parallel architectures, in which processing is performed in parallel by nodes on the contents of their 
local  Authors' addresses: Michael Potmesil, AT&#38;T Bell Laboratories, Room 4F-625, Holmdel, NJ 07733; 
Telephone: (201) 949-4826; Email: mp@vax135.att.com Eric M. Hoffert, Apple Computer Inc., 20525 Mar[ani 
Avenue, Mail Stop 60V, Cupertino, CA 95014; Telephone: (408) 974-0493; Email: emh@apple.com '89, Boston, 
31 July-4 August, 1989  'c(~SIGGRAPH memories and messages can be exchanged between proces- sors [17,3,9] 
and local memories can be part of a video frame buffer [7,18]. interleaving -the notion of an interleaved 
frame buffer, dis- tributed among the processors of a parallel image-computing system, to achieve load 
balancing as originally developed in [6,14}.  programmability -the concept of a programmable graphics 
machine attached to a host computer as introduced in the lkonas frame buffer and graphics processor and 
later also used by Pixar [11] and TAAC-1 [19].  pipelining -pipelined operations as applied in the Geometry 
Engine [2] to geometry computing.  flexibility -the value of a rendering and modeling program- ming 
environment, such as FRAMES [15], where different computing modules following the old software adage 
"small is beautiful," can be interconnected in different ways to achieve diverse modeling and rendering 
functions.  partitioning -image-space or object-space partitioning of data among 2D or 3D arrays of 
asynchronous, independent processing elements as described in [5].  2. System Architecture The Pixol 
Machine was designed as a programmable computer with pipeline and parallel processing closely coupled 
to a display system [16,1]. The Pixel Machine consists of four major building blocks [Figure 1]: (a) 
a pipeline of pipe nodes, (b) an array of m x n parallel pixel nodes with a distributed frame buffer, 
(c) a pixel funnel, and (d) a video processor. The pipeline and pixel-array modules can be incrementally 
added to a system to build a more powerful computer. The Pixel Machine functions as an attached processor. 
In the current configuration the host computer is a high-end worksta- tion, but in principle diverse 
hosts could be supported, ranging from personal computers to supercomputers. 2.1 Computations The CPU 
of the computing nodes is a DSP32 digital-signal processor with an integrated floating-point unit [I0]. 
It con-sists of a 16-bit integer section and a 32-bit floating point sec- tion. The integer section with 
21 registers is mainly used to generate memory addresses while the floating-point section with four 40-bit 
accumulators is used to process geometry and image data. The DSP32 has a RISC-style instruction set and 
instruction decoding. Unlike a RISC processor which operates only on data in registers and uses load/store 
register-memory accesses, the DSP32 uses register pointers to point to arrays of data in memory. The 
pointers are usually post-incremented during the same instruction. In a typical operation, the DSP32 
can read two operands from memory and one from an accumulator, per- form a multiply-accumulate operation 
and write the result to an accumulator and to memory. The DSP32 has a 16-bit addressing capability, allowing 
it to address directly only* 64 Kbytes of memory. There are 4 Kbytes of RAM memory on board of the chip. 
Each pixel and * It should be noted that the next generation of this processor has a 24-bit addressing 
space allowing it to address directly 16 Mbytes of memory. pipe node has additional 32 Kbytes of fast 
static RAM memory. These 36 Kbytes are used for program and scratch data storage. Pixel nodes also contain 
a distributed frame buffer and z-buffer. In each pixel node, there are 512 Kbytes of video RAM memory 
organized as two banks of 256  256 32-bit rgb~ pixels and 256 Kbytes of general-purpose dynamic RAM 
memory which can be organized as a 256 x 256 32-bit floating-point z-buffer. These additional 3/4 Mbytes 
of memory are addressed via a memory management unit. The nodes are running at 5 Mips or 10 Mflops which 
must really be interpreted as 5 million multiply-accumulate opera- tions per second. In typical applications, 
programmed in C, the overhead of invoking functions, computing data pointers, etc. can reduce the floating-point 
operations to about 10-25% of the peak rate. 2.2 Communications and Connections There are a number of 
different communication paths in the system. Each pixel and pipe node is connected to the VMEbus via 
a DMA port (host-to-node connection). This port can be used by the host to access all memory-mapped locations 
in a node and for handshaking and synchronization activities by the node. Pipe nodes are connected with 
fifes into nine-node pipelines (downstream pipe node-to-node connection). The fifo input to the first 
node is written by the host via the VMEbus, the fifo output of the last node is either broadcast -via 
a broadcast bus -to all the pixel nodes (pipe-node to pixel-node connection) or written to a fifo read 
back -via the VMEbus -by the host. The pipe nodes in a pipeline are also connected via a unidirec- tional 
serial asynchronous link in the direction opposite to the fifes (upstream pipe node-to-node connection). 
Two pipelines can be placed in a system and configured as two parallel pipes or one long serial pipe. 
Pixel nodes are connected to their four nearest neighbors, in a closed-toms network, via serial bidirectional 
asynchronous links (pixel node-to-node connection). These pathways allow flexibility for data movement 
needed in different algorithms. Some pixel-node operations, such as changing display buffers or exchanging 
messages with adjacent nodes, require all the nodes to be synchronized: they have to wait for the last 
node to complete its previous computations. There are two hardware semaphores, shared by all the pixel 
nodes, which allow global synchronization. Pixel nodes can also be syn-chronized with vertical and horizontal 
video retrace periods. 2.3 Pixel Mapping and Display The frame buffer in the Pixel Machine is distributed 
into the array of the m x n pixel nodes. The frame buffer is divided into two or more display buffers. 
One of these buffers is always displayed by the video system, at the selected size and speed, on the 
screen. When in double-buffered mode, a second buffer is used to draw the next image. Additional buffers 
may contain other pixel-oriented data such as texture maps. Pixels in the displayed buffer are read by 
the video pro- cessor and mapped on the video screen. This mapping is determined by the position of each 
pixel node within the array and is fixed. Each pixel node contains the size of the pixel- node array 
(re,n) and its position within the array (p,q) where 0 <_ p < m and 0 <_ q < n. The position (p ,q) also 
serves as a unique identification number of each node. Pixel node (p,q) then displays every m-th pixel 
starting with pixel p on every n-th scanline starting with scanline q, i.e., a processor-space VMEbus 
I , , , I I I Broadcast._ Bus I I'.terleave<lP,xe, Video Video ~ Funnel Processor i.ae o Pipe-Node Pipeline 
PixeI-Node Array with Distributed Frame Buffer Figure t A block diagram of the Pixei Machine. pixel 
(i,j) is mapped into a screen-space pixel (x,y) by: x=mi+p y=n j +q (1)  This format requires the display 
subsystem to collect all of the distributed frame-buffer pixels and assemble them into a con-tiguous 
screen image. The device that performs this function is called the video pixel funnel. The interleaved 
format of the frame buffer provides load balancing for image-computing algorithms and matches well the 
speed limitations of video RAM memories with the speed requirements of a high-resolution display*. The 
architecture of the pixel nodes is scalable, using between 16 and 64 nodes [Table 1]. The video processor 
can be pro- grammed to display two high-resolution formats as well as NTSC and PAL. To aid in the development 
of uniform software for all the pixel-node configurations and to allow hardware modularity, the concept 
of virtual pixel nodes was utilized. A virtual node renders into a subset of a buffer, called a virtual 
screen, all within a physical node. The virtual nodes and their virtual screens are also interleaved 
in an m'  n" pattern - just as the physical nodes -with each virtual node having a unique screen position 
(p',q'). The mappings in equation (1) also apply to the virtual nodes. All software is written for one 
virtual node and is invoked one or more times, depending on the system size, by a physical node. The 
physical and virtual pixel-node configurations of the Pixel Machine are shown in Table 1. 3. Software 
Architecture Software developed to run on the Pixel Machine is always divided into two major conceptual 
areas: host software and node software. The latter category is further subdivided into pipe-node software 
and pixel-node software. Host software controls interaction with the Pixel Machine, pipe-node software 
executes sequential-type algorithms and finally pixel- node software executes parallel algorithms. A 
pixel is shifted out of a video memory in =40 ns while it is displayed on a 1280 1024 pixel screen in 
=9 ns. Therefore, at least 5 parallel banks of video memories are required to shift out 5 pixels in :40 
ns. 3.1 Host Software Each node in the Pixel Machine is a small autonomous com-puter, albeit with a 
number of limitations. The current proces- sor used in each node does not support interrupts and has 
lim- ited addressing capabilities. These limitations forced the software designers of the Pixel Machine 
to come up with a number of creative solutions to difficult problems typically not encountered on a conventional 
computer. A programming environment had to be developed that simulates much of the functionality taken 
for granted in a standard operating system. There are two different types of processes which can run 
on the host computer and interact with or control the Pixel Machine: passive server This process functions 
as a data-base server for the Pixel Machine. In this capacity, interaction takes place in a linear fashion: 
the host sends a stream of commands and data to the Pixel Machine, and the Pixel Machine performs vari- 
ous operations on the received data. There is no interaction initiated by the Pixel Machine, it responds 
only when it is explicitly requested to do so (e.g., to a command to return the current transformation 
matrix). This server is employed almost exclusively for traditional polygon rendering, where databases 
and commands are generated by the host and sent to the machine. In this mode the Pixel Machine acts as 
slave and the host computer as master. active server This process is responsible for responding to all 
requests for resources that are made by the Pixel Machine. It polls a user-defined set of nodes (pipe 
or pixel) for messages. When a message is received, the active server initiates a host function that 
supplies needed resources to the requesting node. We have found this to be a very powerful paradigm for 
host/Pixel Machine interaction. The host needs the Pixel Machine for certain demanding geometry and image 
computing, and the Pixel Machine needs the host for con- tiguous large blocks of memory and for access 
to a file sys- tem (among a number of other potential needs). In this mode the Pixel Machine acts as 
master and the host com-puter as slave.  ~L~r~. ~SIGGRAPH '89, Boston, 31 July-4 August, 1989 Physical 
Virtual V/P nodes m x n pixels/node nodes m'  n" pixels/node Ratio 16 4 x 4 256  256* 64 8  8 128 
 128 20 5  4 256  256** 80 10  8 128  128 32 8  4 128  256* 64 8  8 128 x 128 40 10 x 4 128  
256** 80 10  8 128 x 128 64 8  8 128  128" 64 8  8 128  128 160  128"* 160 x 128 Table 1 Physical 
and virtual pixel-node configurations. * Display screen size: 1024 x 1024 pixels. ** Display screen 
size: t280  1024 pixels. The host process has complete control over all nodes. It can access all memory 
in each node including program memory and frame-buffer memory in pixel nodes. Such accesses take place, 
via DMA, even when the nodes are running. The host software is also responsible for halting, initializing 
and starting each node as well as for downloading programs into them. It also configures 1he video processor 
and accesses the video lookup tables. 3.2 PixeI-Machine Software Software that runs on the Pixe[ Machine 
is quite distinct from software that runs on yon Neumann machines, The important distinction from the 
single-processor approach is that software is mapped to different architectural components, each of which 
has a different character and number of nodes. The pipeline (where each pipe node typically contains 
a distinct program) executes sequential algorithms and the pixel-node array (where each pixel node typically 
contains the same program*) exe-cutes parallel algorithms. In some cases, our algorithm is entirely sequential; 
such an algorithm would run only in the pipe nodes. Analogously, we have algorithms that are entirely 
parallel in nature; such an pipeline at all. We have components that map onto array. 3.3 Pipe-Node Software 
application might not utilize the found that most applications have both the pipeline and pixel-node 
 Pipe nodes are employed for operations that are intrinsically sequential in nature. Such operations 
are those that constrain the efficiency of a parallel algorithm. The use of a pipeline is an attempt 
to remove as much sequential style processing from the parallel pixel-node array as possible. Pipe-node 
software requires algorithm partitioning. Each pipe node acts as a distinct computational element in 
a pipeline. A separate program runs in each node and messages -commands and data -are passed down a pipeline. 
The last node in a * However, there is no reason why each pixel node cannot execute a different program. 
pipeline has the ability to broadcast messages to all the nodes in a pixel-node array or to return them 
back to the host. The FRAMESsystem [15] contains methods for experimenting with pipeline partitioning 
and how to achieve maximum flexi-bility in such a scheme. The same philosophy is employed here. Our experience 
shows that special care must be taken to ensure that software in the pipeline does not become I/O bound. 
Pipe-node software can be written to allow the same program to reside in several consecutive nodes and 
to operate on alter-nating input messages (e.g., each instance of an n-node transformation program transforms 
only every n-th polygon). This allows the same software to run efficiently in longer pipe- lines and 
to eliminate or reduce bottlenecks by repeating the slowest program in more than one node. 3.4 Pixel-Node 
Software This section describes (a) what actions a pixel node performs as a computational element and 
(b) the general mechanisms available for increasing the amount of data that a pixel node can directly 
access. There are two approaches to the issue of memory limitation, The first approach is that of message-passing, 
where nodes exchange portions of distributed data. This approach exploits the ability of a machine to 
shuffle large amounts of data among its nodes. The second approach util-izes the memory of the host computer, 
letting it serve as an adjunct memory device for individual nodes. Support software in the pixel nodes 
comprises several categories: screen-space to processor-space coordinate map-ping, frame-buffer and z-buffer 
access to pixel-oriented data, display-list access, and optimized mathematical functions. Mapping functions 
transfer coordinates from the (x,y) display screen space to the (i',j') virtual screen space of a virtual 
pixel node (p',q') by: , p, i'= x-p 1 --X m" m' m" j, _ y-q' = 1 q" n" n" Y n  where the scale multiplication 
is the same for all the pixel nodes and therefore is actually computed by a pipe node and the offset 
subtraction is computed individually by each pixel node. There are four basic mapping functions, used 
in all image-computing algorithms, which transform screen coordinates to processor coordinates. Function 
ilo(x) returns the smallest integer i" such that m'i' + p" _> x: ilo(x) = x ~n 7 0.5 1  Function ihi(x) 
returns the largest integer i' such that m'i' + p' _< x: ihi(x) = tx -Ira' p' + 0"5 Similarly, function 
rio(y) returns the smallest integer j' such that n'j' + q' _> y, and function jhi (y) returns the largest 
j' such that n'j" + q' _< y. The mapping from the screen space to the processor space is not one-to-one: 
there are more pixels in screen space than in processor space. To be certain that processor-space pixel 
(i',j') is actually screen-space pixel (x,y), these two conditions must be true: ilo(x) = ihi(x), and 
jlo(y) = jhi(y) Each node can independently read or write the contents of its individual frame buffer 
and z-buffer. Access to these memories is in row and column addressing modes using virtual screens. A 
32-bit pixel can be accessed in four instruction cycles (one cycle to read each color component) and 
a 32-bit z-buffer value in one cycle. Mathematical functions include routines for frequently used operations 
in geometry and image computing such as square root (ray-sphere intersection), vector normalization (shading), 
and dot product (back-face removal). These highly-optimized functions efficiently utilize the floating-point 
capability of the DSP32 at each node, since many of the operations involve multiply/accumulate instructions. 
 3.5 Interleave/De-Interleave Each node in the pixel-node array has a four-way serial I/O switch. This 
allows a node to communicate directly with its four nearest neighbors. Communications between two nodes 
occur over a half-duplex serial channel. All nodes must syn- chronize to exchange data, and message-passing 
occurs in lock- step fashion, with all nodes sending data in the same direction at the same time. This 
type of communication scheme is well-suited to problems that map onto a grid or torus architec- ture. 
There are times when it is undesirable to compute on pixels in an interleaved format. Using the current 
Pixel Machine, this is not possible through hardware due to constraints imposed by video memory access 
requirements. At this point, the old hardware adage "do it in software!" is employed. Software can take 
the interleaved frame-buffer format, and using serial I/O message-passing, reconfigure the frame buffer 
so that each node has a contiguous block of pixels. We call this process de-interleaving. Analogously, 
it is possible to take a frame buffer configured as contiguous blocks and again employing serial I/O 
message-passing, distribute the pixels so that they are in their correct interleaved position for display. 
We call this method interleaving. 3.6 Virtual Memory Photorealistic rendering requires large amounts 
of data. This data is typically geometry information, but can also consist of texture maps, environment 
maps, etc. Other rendering tech- niques, such as volume rendering, can also require significant amounts 
of data storage. We have also found that an efficiently coded implementation of a rendering program (ray 
or volume tracers, for example) can be very small, in terms of code space. Hence it became apparent that 
we could develop schemes for virtual memory [4] which would be used only for data. Each node has a page 
table in its memory along with a set of associated pages. When a memory access is required for data that 
does not reside in the available pages, a parallel page-fault is generated, causing a node to make a 
request to the host to deliver the required page of memory. The page is broadcast to all nodes in the 
pixel array from the last node in the pipeline, At this point, the page table in each node is updated, 
deleting a page based on a page-replacement policy and adding the newly requested page to the table. 
We call it parallel paging, since typically nodes may request pages from the host concurrently. The parallel 
paging scheme is employed for virtual display lists in the ray-tracing software implemented on the PJxoI 
Machine. Figure 2 shows a ray-traced image with 17,000 polygons. Each polygon uses 100 bytes, giving 
a database size of 1.7 Mbytes, substantially more than can fit in one pixel node's local memory. Figure 
3 also shows a ray-traced image generated using virtual display lists. This scene contains over 50,000 
polygons, area-light sources and is antialiased at 16 samples per pixel. The active server can store 
multiple texture maps or volume databases in host's memory. When an individual pixel or voxel is requested 
by an arbitrary node, the host retrieves a page of adjacent data and routes it to the requesting node. 
This scheme is especially suitable for either (a) applications with memory requirements that far exceed 
the collective memory capacity of the pixel nodes, or (b) applications where distribution of memory over 
the pixel nodes would require an overly complex and/or inefficient algorithm. Because all pixel nodes 
have access to this memory, we call it virtual shared memory. Figure 4 shows a ray-traced image that 
uses virtual texture maps. There are 13 virtual texture maps requiring a total of 4 Mbytes of texture 
map data. The scene also contains approxi- mately 2,000 polygons. Figure 5 shows a volume rendering of 
a nuclear magnetic resonance (NMR) angiography study that uses virtual volumes. The size of the data 
is 256 x 256 x 160 voxels or approximately 10 Mbytes. 3.7 Program Overlays A node can directly address 
64 Kbytes of memory. This con- straint coupled with the cost and size of fast static RAM memories dictated 
the size of program memory at 36 Kbytes in the current Pixel Machine. The solution to this problem of 
small program size is a classic one, first seen in the early days of computing. If a node does not have 
enough program or local data memory available for a required function or message processing, we use program 
overlays [8]. A program is manually divided into a static instruction and data segment which resides 
in a node at all times and several dynamic segments which are swapped-in, one at a time from the host. 
The host server keeps track of the overlay segments loaded into any of the nodes and ensures that the 
correct 73  map virtual shared memory requests respectively. The pipe- line is used to compute bounding 
volumes, tessellate geometric primitives and to transform the display list before rendering begins. The 
floating-point capability of each node is exercised to its maximum for the ray-object intersection tests. 
Antialiasing is performed by stochastic sampling in multiple passes, volume rendering Rays are marched 
in parallel [12] by the pixel nodes inside volume data. Each node processes its set of interleaved pix- 
els in the image. At each pixel, a ray is cast into the volume and ray-marching incrementally steps along 
the direction of the ray, sampling the signal inside. The sam-pled values of a ray are then converted 
into image intensity according to the application: thresholding, finding maximum, translucency accumulation 
and integration can be selected. The volume is stored on the host computer, with each pixel node requesting 
voxel packets that contain voxels along the path of a marching ray. This procedure is accomplished using 
virtual shared memory via the active server. The pipe- line is not utilized in this mapping. Antialiasing 
is accom- plished by sampling very finely along each ray and by inter- polating voxel values adjacent 
to an intersection point. image processing An image is processed by the pixel nodes in parallel, with 
each pixel node-computing its set of interleaved pixels. If the image is too large to fit in the local 
pixel-node memory, it can be distributed over the collective memory of all the nodes in contiguous block 
fashion and redistributed into interleaved format for a final display using the interleave/de-interleave 
strategy. The pipeline can be used for run-length decoding and other sequential image functions as an 
image is being sent to the pixel nodes.  5. Performance Analysis In this section we attempt to analyze 
the theoretical perfor- mance of the Pixel Machine architecture and then look at some of our actual results. 
5.1 Theoretical Performance Analysis The classic recurrence equation for the divide-conquer-marry paradigm 
is as follows: T(n) = g(n) + M T(n/M) + h(n) where g(n) is the cost of dividing up a problem into M 
sub-problems (divide), T(n/M) is the cost of running the subprob- lem (conquer), h (n) is the cost of 
combining the results of the subproblems into a final solution (marry) and n is the number of data elements. 
This generic equation is typically applied to a sequential implementation of a recursive algorithm. Interest-ingly 
enough, the equation can also be applied to the analysis of algorithms on parallel machines. In this 
case, the multipli- cative term M would drop out, since the divided problems or subproblems are being 
solved concurrently. The modified equation becomes: T(n) = g(n) + T(n/M) + h(n) The ideal parallel algorithm 
will have minimal g(n) and h (n) terms; these are the parallel overhead costs. The algorithm development 
efforts for parallel architecture are primarily con- cerned with ensuring that the T(n/M) term will predominate 
in the expression above. This ensures that adding more proces-sors to a problem yields a linear improvement 
in performance. A term that has recently entered into the parlance of parallel processing is Non von 
Neumann bottleneck. This refers to the costs g(n) and h(n), which are considered bottlenecks if they 
predominate in the expression above. The salient difference between the Pixel Machine and other parallel 
machines is that there is no h (n) term for displaying or animating the image computed by the pixel nodes. 
This immediately obviates a large amount of the usual parallel over- head. This term is eliminated because 
the interleaved frame buffer is assembled into a contiguous scan image by the pixel funnel. Only if we 
read back the computed image from the frame buffer to the host computer does the h (n) term reappear. 
The g(n) term represents the cost associated with the screen space to processor space conversion. As 
an example of how this term affects efficiency, consider the case of rasterizing a geometric primitive 
in a pixel node. A simple equation describing the rasterization is as follows: T(p) = g(x) + p l(x) 
where p is the number of pixels rasterized, T(p) is the time required to rasterize these pixels, I(x) 
is the cost per pixel of rasterization for an arbitrary algorithm x and g(x) is the paral- lel overhead 
for that algorithm. Let us also define rl, the efficiency of a parallel algorithm implementation, to 
be the slope of the graph of normalized inverted execution time vs. number of pixel nodes. A unity value 
of rl implies exactly linear improvement in performance for linear increases in the number of pixel nodes. 
This is what we aspire to for all implementations. Values less than unity indicate sublinear improvement 
for pixel-node increases. If p is small and g (x) is large so that g(x)>p l(x), then the parallel overhead 
predominates and q ~ 1. Conversely, ifp is large and g(x) is small so that g(x) < p l(x), then the parallel 
overhead is small or negligible and rl = 1. The optimal algorithms for the Pixel Machine are those that 
require a g(n) term only once per image as opposed to once per object. An example of the former is ray-tracing 
and of the latter is vector drawing. It is much easier to amortize the cost g (n) once per image than 
once per object, since there may be many objects in an image. 5.2 Measured Performance Analysis We have 
tested the actual efficiency of the machine on a number of different image-computing algorithms: raster 
operations A basic pixet-node function is to modify rectangular regions on the screen in various ways. 
The pixel-node organization allows m'n" pixels to be processed in parallel by m' n' virtual nodes during 
each iteration. Figure 6 illustrates per- formance of the machine performing raster operations on 1282, 
2562, 5122, and 10242 pixel regions. The execution times are plotted as solid lines and the normalized 
efficiency is shown as dotted lines. The efficiency of the machine, as the slopes of the dotted lines 
indicate, is very high with almost linear improvement and increases as the size of the region increases. 
point rasterizing A pixel node maps a point into its screen space and then tests if the point actually 
belongs there and should be drawn. Each pixel node maps and tests all the points but typically draws 
only 1/m'n" of them, giving a very low figure of merit. The graphs in Figure 7 indicate that the sequential 
part of the algorithm dominates: the bottleneck is a pipe node which converts the host floating-point 
and integer   :L~.~SIGG RAPH '89, Boston, 31 July-4 August, 1989 10242 60 -- efficiency. :: k 5122 
2562 .:... .:.., 1282 10242~ .:::."" " ...'* 40-- :i:::" " Time [ms] ...~.,IZ~,1~2I 20 -- . ...' t~ 
:~':: ~ 512:~ 2562. 16 32 64 Nodes Figure 6 Parallel performance: raster operations.  &#38; 60--1pipe 
 40--Time   2 pipes [ms] .................. e-ffici.eg~-Y... 2 pipes 20-- ,.,t-'" ................................ 
1 pipe I I 16 32 64 Nodes Figure 7 Parallel performance: points. formats to the DSP32 floating-point 
format. There is not any speed improvement above 20 pixel nodes when a single pipeline is used. In a 
system with two parallel pipelines the improvement stops at 32 pixel nodes. Two parallel pipelines improve 
the speed of this algorithm by about 70% for 32 or more pixel nodes. vector rasterizing A parallel version 
of the Bresenham algorithm rasterizes one-pixel wide aliased vectors. In an m' x n" array of vir- tual 
pixel nodes, the algorithm writes rain (m',n') pixels dur- ing one iteration. The figure of merit for 
this algorithm is only min(m',n')/m'n'. Line drawing, which is essentially a one dimensional process, 
cannot be very efficiently imple- mented on this architecture. Performance for randomly-oriented 2, 16, 
128 and 1024 pixel-long vectors is shown in Figure 8. Actual times are again plotted as solid lines while 
the efficiency of the algorithm is plotted as dotted lines. As expected, the slope of these lines illustrates 
the low efficiency. For very short vectors the overhead becomes dominant and there is almost no improvement 
in speed as the number of processors increases Antialiased vectors are drawn by a modified version of 
the above algorithm which computes pixel intensity based on 1024 1024 60-- 40-- Time .... [ms] .: :~.!.!.:..! 
16 (1 pipe) 20-- ~ ............. ~ ~ (1(2 pipeS)pipe) 16 k--~----,..___ -  I I I 16 32 64 Nodes Figure 
8 Parallel performance: aliased vectors.  60- 1024 1024 128 16 (2 pipes) 16 (1 pipe) 40- .. Time [ms] 
2 (2 pipes) 2 {1 pipe) l~! ,t - I I I 16 32 64 Nodes Figure 9 Parallel performance: antialiased vectors. 
distance from the vector and blends the intensity with the background Figure 9 shows the relative performance 
of this algorithm for the same randomly-oriented vectors as in Fig- ure 8. On absolute time scale, aliased 
vectors are about twice as fast as antialiased vectors. However, because more processors do more useful 
work per pixel and per iteration, the antialiased algorithm is more efficiently implemented in this architecture 
than the aliased algorithm. In both algo- rithms, a small speed improvement is obtained for short vec- 
tors when two parallel pipelines are used. polygon rasterizing A pipe node converts polygons into triangles, 
sorts their ver- tices in y and computes the slopes of the three edges. The pixel nodes transform the 
slopes into their processor spaces, compute forward difference in y along the edges and scan-convert 
the triangle by stepping in y along two active edges and filling the span in x between them. Performance 
for random triangles within 82 , 162 , 642 , 2562 and 10242 bound- ing squares is given in Figure 10. 
For large triangles the performance is similar to raster operations. As the size of the triangles decreases 
the sequential part (executing in the pipe nodes) and the parallel overhead of the rasterizing algo- 
rithm dominates and decreases the efficiency of the architec- ture. 1024 z 60-- efficiency., ~ 2562 ..~"., 
642 ... ~ '.", h d 40-- il Time [ms] 20-- 2562 642 ~ 16 32 64 Nodes Figure 10 Parallel performance: 
Gouraud-shaded z-buffered polygons. 256 60--256 efficiency .:I ~6 ,'::!!! [!!!!![!!!!:'" 4 40-- ,D'.'." 
Time [ms] 20-- i-' i 3 16 32 64 Nodes Figure 11 Parallel performance: Phong-shaded z-buffered spheres. 
 sphere rasterizing Phong-shaded z-buffered spheres are rasterized using the approximations described 
in [7]. Because many computa-tions have to be done at each pixel to evaluate the inside/outside equation, 
depth, normal vector, and finally the color, the efficiency of this algorithm is high even for small 
spheres [Figure 11]. Note that the implementation of this algorithm is more efficient then, for example, 
Gouraud-shaded z-buffered rasterizing of polygons of similar size.  ray tracing  Our first objective 
was to see if the performance would improve linearly with increases in the number of processing nodes 
for the case where the object database resides entirely in a node's memory. In these tests, the database 
size is kept constant while the number of pixel nodes in a system is increased. As can be seen from the 
dotted graph in Figure 12, our objective of linear improvement was met, and we have had similar experiences 
with many other object data- bases. In addition, the actual rendering times for the image are plotted 
(solid graph) and they are two to three orders of magnitude faster than on typical workstations. 60- 
Time 40-- [sl 20- I I I 16 32 64 Nodes Figure 12 Parallel performance: ray tracing. 15 -- --60 10--40 
PageTime Faults[103 s] [106] 5---20 1 - . . ~ : . ~y!~ed. _ 4 .... i--7 i 10 20 30 40 50 Objects [1031 
 Figure 13 Ray tracing: scene complexity vs. time (solid) and parallel paging (dotted) using virtual 
data memory. Our second objective was to examine what happens to the performance when the parallel paging 
is used for virtual display lists. This test was run keeping the number of pixel nodes in the system 
constant, while increasing the number of objects in a scene. It can be seen from the graph in Figure 
13 that the paging begins at about 5,000 objects in the display list. The performance degrades exponentially 
when the paging begins but becomes again linear above 10,000 objects. The dotted graph labeled "requested" 
shows the number of page faults generated by all the nodes. Since many nodes request the same page at 
the same time, the dot- ted graph labeled "serviced" shows that only about one tenth of the generated 
page faults had to be serviced. The speed of the algorithm when paging a display list is about five times 
slower than when all of a display list is in the pixel- node memory. The measured performance confirms 
our analysis: the architec- ture of the machine is best suited for image-computing algo- rithms which 
require a parallel overhead only once per image (e.g., ray tracing, fractals, 213 and 3D solid textures) 
and degenerates as the overhead increases and the number of use- fully employed pixel nodes decreases 
(e.g., line and point rasterizing). ' S,GaRAP. '89, Boston, 31 July-4 August, 1989 6. Summary and Conclusions 
We have described a parallel image computer designed for fast geometry and image computing. The computer 
contains a large distributed frame buffer which allows many computing elements, capable of floating-point 
operations, to access pixel-oriented data in parallel. We have developed software for standard 3D polygonal 
graphics, 3D volume display and ray tracing, all based on a common programming environment. To overcome 
the problems inherent to the architecture of the machine and its current implementation -particularly 
the lim- ited amounts of program and data memories in each node -we resorted to using established software 
techniques found in trad- itional computers such as program overlays for instructions and virtual memory 
for data. We also found a method to remove the restrictions of the interleaved frame-buffer design using 
interprocessor communication capabilities. To simplify the development of software for our scalable parallel 
architecture we have developed a concept of physical and virtual nodes which makes the size of the machine 
transparent to the pro- grammer. We have also used the Pixel Machine for real-time playback of compressed 
audio and video data and as a general-purpose parallel computer. Acknowledgements and Credits We would 
like to thank Bill Ninke, Kicha Ganapathy and Jim Boddie for providing a fertile environment that allowed 
the exchange of ideas between people involved in graphics, paral- lel processing and digital signal processing. 
Leonard McMillan contributed major ideas to both the software and hardware architecture and should be 
identified as one of the principal architects of the system. Bob Farah should be credited with the design 
of the pipeline card and for handling enormous numbers of odds and ends. Marc Howard should be thanked 
for bringing to life very high-quality, reliable video at 2 A.M. on a Friday night. Jennifer Inman should 
be thanked for writ- ing a great deal of the pipe and pixel-node software. Pete Segal must be credited 
with much work on the ray tracer. Jon Leech pulled his hair on message-passing and the interleave/de-interleave 
code. John Spicer and Tom Rosenfeld contributed towards a nice parallel-programming environment. Miss 
Piggy was an immense help in the early days when everything great was done at around 4 A.M. and common 
sense prevailed. Spouses and lovers are most importantly thanked for being understanding at the worst 
of times. The controversial ghost-writer Tango A. Scampers wrote the origi- nal version of this paper. 
We would also like to thank NASA for generating the image in Figure 2 and for providing the database 
for testing purposes. Kamran Manoocheri must be thanked for creating the image A Museum Room in Figure 
4 and Leonard McMillan for A Tea Room in Figure 3. References [1] AT&#38;T Pixel Machines, "The Pixel 
Machine System Architecture," A Technical Report, Holmdel, N J, November 1988 [2] Clark, J. H., "The 
Geometry Engine: A VLSI Geometry System for Graphics," ACM Computer Graphics, 16, (3), July 1982, 127-133 
[3] DeBenedictis, E. P., The Bell Laboratories' Hypercube, personal communication, April 1986 [4] Denning, 
P. J., "Virtual Memory," Computing Surveys, 2, (3), September 1970, 153-189 [5] Dippr, M., and Swensen, 
J., "An Adaptive Subdivision Algorithm and Parallel Architecture for Realistic Image Synthesis," ACM 
Computer Graphics, 18, (3), July 1984, 149-158 [6] Fuchs, H., "Distributing a Visible Surface Algorithm 
Over Multiple Processors," Proceedings of ACM 1977, Seattle, WA, October 1977, 449-451 [7] Fuchs, H., 
et. al., "Fast Spheres, Sh~tdows, Textures, Transparencies, and Image Enhancements in Pixel-Planes," 
ACM Computer Graphics, 19, (3), July 1985, 111-120 [8] Heising, W. P., and Lamer, R. A., "A Semi-Automatic 
Storage Allocation System at Loading Time," Communi-cations of the ACM, 4, (10), October 1961, 446-449 
[9] Hillis, W. D., The Connection Machine, The MIT Press, Cambridge, MA, 1985 [10] Kershaw, R. N., et. 
al., "A Programmable Digital Signal Processor with 32-bit Floating Point Arithmetic," Proceedings of 
IEEE International Solid-State Circuits Conference, February 1985, 92-93 [11] Levinthal, A., and Porter, 
T., "Chap -A SIMD Graphics Processor," ACM Computer Graphics, 18, (3), July 1984, 77-82 [12] Levoy, M., 
"Volume Rendering: Display of Surface from Volume Data," IEEE Computer Graphics and Applica- tions, 8, 
(3), May 1988, 29-36 [13] McCormick, B. H., DeFanti T. A., and Brown, M. D., "Visualization in Scientific 
Computing," ACM Computer Graphics, 21, (6), November 1987 [14] Parke, F. I., "Simulation and Expected 
Performance Analysis of Multiple Processor Z-Buffer Systems," ACM Computer Graphics, 14, (3), July 1980, 
48-56 [15] Potmesil, M., and Hoffert, E. M., "FRAMES: Software Tools for Modeling, Rendering and Animation 
of 3D Scenes," ACM Computer Graphics, 21, (4), July 1987, 85-93 [16] Potmesil, M., McMillan, L., Hoffert, 
E. M., Inman, J. F., Farah, R. L., and Howard, M., "A Parallel Image Com- puter with a Distributed Frame 
Buffer: System Architec- ture and Programming," Proceedings of Eurographics '89, Hamburg, Federal Republic 
of Germany, September 1989 [17] Seitz, C. L., "The Cosmic Cube," Communication of the ACM, 28, (1), January 
1985, 22-33 [18] Sato, H., et. al., "Fast Image Generation of Constructive Solid Geometry Using a Cellular 
Array Processor," ACM Computer Graphics, 19, (3), July 1985, 95-102 [19] Whitton, M. C., England, N., 
and DeMonico C., "Manage Design Trade-Offs in High-End Graphics Board," Electronic Design, 36, (6), March 
1988, 77-84 Pixaris a registered trademark of Pixar. TAAC-1 is a trademark of Sun Mierosystems, Inc. 
Geometry Engine is a trademark of Silicon Graphics, Inc. VmEbus is a registered trademark of the VMEManufacturers 
Group. Miss Piggy is a registered trademark of Jim Henson Productions.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74341</article_id>
		<sort_key>79</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Pixel-planes 5: a heterogeneous multiprocessor graphics system using processor-enhanced memories]]></title>
		<page_from>79</page_from>
		<page_to>88</page_to>
		<doi_number>10.1145/74333.74341</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74341</url>
		<abstract>
			<par><![CDATA[This paper introduces the architecture and initial algorithms for Pixel-Planes 5, a heterogeneous multi-computer designed both for high-speed polygon and sphere rendering (1M Phong-shaded triangles/second) and for supporting algorithm and application research in interactive 3D graphics. Techniques are described for volume rendering at multiple frames per second, font generation directly from conic spline descriptions, and rapid calculation of radiosity form-factors. The hardware consists of up to 32 math-oriented processors, up to 16 rendering units, and a conventional 1280 &amp;times; 1024-pixel frame buffer, interconnected by a 5 gigabit ring network. Each rendering unit consists of a 128 &amp;times; 128-pixel array of processors-with-memory with parallel quadratic expression evaluation for every pixel. Implemented on 1.6 micron CMOS chips designed to run at 40MHz, this array has 208 bits/pixel on-chip and is connected to a video RAM memory system that provides 4,096 bits of off-chip memory. Rendering units can be independently reasigned to any part of the screen or to non-screen-oriented computation. As of April 1989, both hardware and software are still under construction, with initial system operation scheduled for fall 1989.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Parallel processors**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.2.1</cat_node>
				<descriptor>Parallel</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600.10010615</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits->Logic circuits</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43124435</person_id>
				<author_profile_id><![CDATA[81339500019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fuchs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14093769</person_id>
				<author_profile_id><![CDATA[81100243410]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Poulton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31077567</person_id>
				<author_profile_id><![CDATA[81332497960]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eyles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31078142</person_id>
				<author_profile_id><![CDATA[81332501972]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Trey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P130500</person_id>
				<author_profile_id><![CDATA[81100076381]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goldfeather]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Mathematics, Carleton College, Northfield, MN.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39042088</person_id>
				<author_profile_id><![CDATA[81100423073]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ellsworth]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39080691</person_id>
				<author_profile_id><![CDATA[81332516521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Molnar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39084730</person_id>
				<author_profile_id><![CDATA[81100457973]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P33122</person_id>
				<author_profile_id><![CDATA[81100207990]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Brice]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tebbs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P169062</person_id>
				<author_profile_id><![CDATA[81332506192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Laura]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Israel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Airey, J. and M. Ouh-young, "Two Adaptive Techniques Let Progressive Radiosity Outperform the Traditional Radiosity Algorithm," University of North Carolina Department of Computer Science Technical Report TR89-020.]]></ref_text>
				<ref_id>Airey 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Akeley, Kurt and T. Jermoluk, "High-Performance Polygon Rendering," Computer Graphics, 22(4), (Proceedings of SIGGRAPH '88), pp 239-246.]]></ref_text>
				<ref_id>Akeley 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378518</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Apgar, B., B. Bersack, A. Mammen, "A Display System for the Stellar Graphics Supercomputer Model GS 1000," Computer Graphics, 22(4), (Proceedings of SIGGRAPH "88), pp 255-262.]]></ref_text>
				<ref_id>Apgar 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15897</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bishop, Gary and David M. Wiemer, "Fast Phong Shading," Comptaer Graphics, 20(4), (Proceedings of SIGGRAPH '86), pp. 103-106.]]></ref_text>
				<ref_id>Bishop 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Clark, J. and M. Hannah, "Distributed Processing in a High-Performance Smart Image Memory," LAMBDA (VLSI Design), Q4, 1980, pp 40-45.]]></ref_text>
				<ref_id>Clark 80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Clark, J. July, 1982. "The Geometry Engine: A VLSI Geometry System for Graphics," Computer Graphics, 16(3), ~Proceedings of SIGGRAPH '82), pp 127-133.]]></ref_text>
				<ref_id>Clark 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., and Donald P. Greenberg, "The Hemi-cube: A Radiosity Solution for Complex Environments," Computer Graphics, 19(3), (Proceedings of SIGGRAPH '85), pp~ 31-40.]]></ref_text>
				<ref_id>Cohen 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Shenchang Eric Chen, John R. Wallace, and Donald P. Greenberg, "A Progressive Refinemerit Approach to Fast Radiostiy Image Generation," Computer Graphics, 22(4), (Proceedings of SIGGRAPH '88), pp. 75-84.]]></ref_text>
				<ref_id>Cohen 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Crow, F, "Summed-Area Tables for Texture Mapping," Computer Graphics. 18(4), (Proceedings of SIGGRAPH '84), pp. 207-212.]]></ref_text>
				<ref_id>Crow 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378468</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Deering, M., S. Winner, B. Schediwy, C. Duffy, N. Hunt, "The Triangle Processor and Normal Vector Shader: A VLSI System for High Performance Graphics," Computer Graphics, 22(4), (Proceedings of SIGGRAPH '88), pp 21-30.]]></ref_text>
				<ref_id>Deering 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Demetrescu, S., "High Speed Image Rasterization Using Scan Line Access Memories," Proceedings of the 1985 Chapel Hilt Conference on VLSI, Rockville, MD, Computer Science Press, pp 221-243.]]></ref_text>
				<ref_id>Demetrescu 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>48468</ref_obj_id>
				<ref_obj_pid>48467</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Diede, T., C. Hagenmaier, G. Miranker, J. Rubenstein, W. Worley, "The Titan Graphics Supercomputer Architecture," Computer, 21(9), pp 13-30.]]></ref_text>
				<ref_id>Diede 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Etlsworth, David, "Pixel-Planes 5 Rendering Control," University of North Carolina Department of Computer Science Tcchnical Report TR89-003.]]></ref_text>
				<ref_id>Ellsworth 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>57405</ref_obj_id>
				<ref_obj_pid>57392</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Eyles, J., J. Austin, H. Fuchs, T. Greer, J. Poulton,"Pixelplanes 4: A Summary," Advances in Computer Graphics Hardware H, Eurographics Seminars, 1988, pp 183-208.]]></ref_text>
				<ref_id>Eyles 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>810237</ref_obj_id>
				<ref_obj_pid>800179</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry, "Distributing a Visible Surface Algorithm over Multiple Processors," Proceedings of the ACM Annual Conference, 449-451.]]></ref_text>
				<ref_id>Fuchs 77</ref_id>
			</ref>
			<ref>
				<ref_obj_id>802893</ref_obj_id>
				<ref_obj_pid>800090</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., B, Johnson, "An Expandable Multiprocessor Architecture for Video Graphics," Proceedings of the 6th ACM- IEEE Symposium on Computer Architecture, April t 979, pp 58- 67.]]></ref_text>
				<ref_id>Fuchs 79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H. and J. Poulton, "Pixel-planes: A VLSI- Oriemed Design for a Raster Graphics Engine," VLSI Design, 3rd Quarter, 1981., 2(3),.pp 20-28.]]></ref_text>
				<ref_id>Fuchs 81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., J. Poulton, A. Paeth, and A. Bell, "Developing Pixel Planes, A Smart Memory-Based Raster Graphics System," Proceedings of the 1982 MIT Conference on Advanced Research in VLSI, Dedham, MA, Artech House, pp 137-146.]]></ref_text>
				<ref_id>Fuchs 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., J. GoldFeathcr, J.P. Huhquist, S. Spach, J. Austin, F.P. Brooks, Jr., J. Eyles, and J. Poulton, "Fast Spheres, Textures, Transparencies, and Image Enhancements in Pixel- Planes," ComputerGraphics, 19(3), (Proceedings of SIGGRAPH '85), pp. 111 - 120.]]></ref_text>
				<ref_id>Fuchs 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gardner, G., "Functional Modeling of Natural Scenes, Functional Based Modeling," MGGRAPH Courxe Notes, vol. 28, 1988, pp. 44-76.]]></ref_text>
				<ref_id>Gardner 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378474</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gharachorloo, Nader, S. Gupta, E. Hokenek, P. Balasubramanian, B. Bogholtz,C. Mathieu, C. Zoulas,"Subnanosecond Pixel Rendering with Million Transistor Chips, " Computer Graphics, 22(4), (Proceedings of SIGGRAPH '88), pp 41- 49.]]></ref_text>
				<ref_id>Gharachorloo 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13054</ref_obj_id>
				<ref_obj_pid>13050</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Goldfeather, Jack and Henry Fuchs, "Quadratic Surface Rendering on a Logic-Enhanced Frame-Buffer Memory System," IEEE Computer Graphics and Applications, 6(1 ), pp 48-59.]]></ref_text>
				<ref_id>Goldfeather 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Goldfeather, Jack, S. Molnar, G. Turk, and H. Fuchs, "Near Real-Time CSG Rendering using Tree Normalization and Geometric Pruning," University of North Carolina Deparlment of Computer Science Technical Report TR88-006. To appear in CG&amp;A, 1989.]]></ref_text>
				<ref_id>Goldfeather 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Goldfeather, Jack, "Progressive Radiosily Using Hemispheres," University of North Carolina Department of Computer Science Technical Report TR89-002.]]></ref_text>
				<ref_id>Goldfeather 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg and Bennett Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics, 18(3), (Proceedings of SIGGRAPH '84), pp. 213-222.]]></ref_text>
				<ref_id>Goral 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Immel, D., M. Cohen, and D. Greenberg, "A Radiosity Method for Non-Diffuse Environments," Computer Graphics, 20(4), (Proceedings of SIGGRAPH '86), pp. 133-142.]]></ref_text>
				<ref_id>Immel 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Jansen, F. and R. Sutherland, "Display of Solid Models with a Multi-processor System," Proceedings of Eurographics "87, Efseviers Science Publications, 1987, pp 377-387.]]></ref_text>
				<ref_id>Jansen 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>87842</ref_obj_id>
				<ref_obj_pid>87839</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Levoy, Marc, "Volume Rendering by Adaptive Refinement," The Visual Computer, 5(3), June, 1989 (to appear).]]></ref_text>
				<ref_id>Levoy 89a</ref_id>
			</ref>
			<ref>
				<ref_obj_id>329375</ref_obj_id>
				<ref_obj_pid>329129</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Levoy, Marc, "Design for a Real-Time High-Quality Volume Rendering Workstation," Chapel Hill Workshop on Volume Visualization, Chapel Hill, North Carolina, May 1989 (to appear)]]></ref_text>
				<ref_id>Levoy 89b</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801252</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Norton, Alan, "Clamping: A Method of Antialiasing Textured Surfaces by Bandwidth Limiting in Object Space," ComputerGraphics, 16{3), (Proceedings of SIGGRAPH ' 82), pp 1-8.]]></ref_text>
				<ref_id>Norton 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357315</ref_obj_id>
				<ref_obj_pid>357314</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T., "Curve Filting with Conic Splines,"ACM Transactions on Graphics, 2(1), January 1983.]]></ref_text>
				<ref_id>Pavlidis 83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Pcrlin, K., "An Image Synthesizer," Computer Graphics, 19(3), (Proceedings of SIGGRAPH '85), pp. 151-159.]]></ref_text>
				<ref_id>Perlin 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906584</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Pl~ong, B.T., "illumination for Computer-Generated Pictures," Ph.D. Dissertation, University of Utah, Salt Lake City, 1973.]]></ref_text>
				<ref_id>Phong 73</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Poulton, J., H. Fuchs, J.D. Austin, J.G. Eyles, J. Heinecke, C-H Hsieh, J. Goldfeather, J.P. Hultquist, and S. Spach, "PIXEL-PLANES: Building a VLSI-Based Graphic System," Proceedings of the 1985 Chapel Hill Conference on VLSI, Rockville, MD, Computer Science Press, pp 35-60.]]></ref_text>
				<ref_id>Poulton 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Poulton, J., H. Fuchs, J. Austin, J. Eyles, T. Greer. "Building a 512x512 Pixcl-planes System," Proceedings of the 1987 Stanford Conference on Advanced Research in VLSI, MIT Press, pp 57-71.]]></ref_text>
				<ref_id>Poulton 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325225</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Pratt, V., "Techniques for Conic Splines," Camp, let Graphics, 19(3), (Proceedings of SIGGRAPH '85), pp. 151-159.]]></ref_text>
				<ref_id>Pratt 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295889</ref_obj_id>
				<ref_obj_pid>13028</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Rossignac, J., A. Requicha, "Depth Buffering Display Techniques for Constructive Solid Geometry," IEEE Computer Graphics and Applications, 6(9), pp 29-39.]]></ref_text>
				<ref_id>Rossignac 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Runyon, S., "AT&amp;T Goes to 'Warp Speed' with its Graphics Engine," Electronics Magazine, July 23, 1987, pp 54- 56.]]></ref_text>
				<ref_id>Runyon 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Swanson, R., L. Thayer, "A Fast Shaded-Polygon Renderer," Computer Graphics, 20(4), (Proceedings of SIGGRAPH '86), pp 95-t01.]]></ref_text>
				<ref_id>Swanson 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357348</ref_obj_id>
				<ref_obj_pid>357346</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Tar, S. and A. Middleditch, "'Convex Decomposition of Simple Polygons," ACM Transactions on Graphics, 3(4), October 1984, pp 244-265.]]></ref_text>
				<ref_id>Tor 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37426</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Torberg, J., "A Parallel Processor Architecture for Graphics Arithmetic Operations," Computer Graphics, 21(4), (Proceedings of SIGGRAPH '87), pp 197-204.]]></ref_text>
				<ref_id>Torberg 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>51684</ref_obj_id>
				<ref_obj_pid>51683</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[van Dam, A., Chairman, PHIGS+ Committee, "PHIGS+ Functional Description, Revision 3.0," Computer Graphics, 22(3), July, 1988, pp 125-218.]]></ref_text>
				<ref_id>van Dam 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Wallace, J., M. Cohen, and D. Greenberg, "A Two- Pass Solution to the Rendering Equations: A Synthesis of Ray- Tracing and Radisoity Methods," Computer Graphics, 21(4) (Proceedings of SIGGRAPH '87), pp. 311-320.]]></ref_text>
				<ref_id>Wallace 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Watkins, G., "A Real-Time Visible Surface Algorithm, " University of Utah Computer Science Department, UTEC-CSc-70-101, June t 970, NTIS AD-762 004.]]></ref_text>
				<ref_id>Watkins 70</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Whitton, Mary., "Memory Design for Raster Graphics Displays," IEEE Computer Graphics and Applications, 4(3), March 1984, pp 48-65.]]></ref_text>
				<ref_id>Whitton 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance, "Pyramidal Parametrics," Cam-. puter Graphics 17(3) (Proceedings of SIGGRAPH '83), pp. 1- 11.]]></ref_text>
				<ref_id>Williams 83</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 Pixel-Planes 5: A Heterogeneous Multiprocessor Graphics 
System Using Processor-Enhanced Memories 1 Henry Fuchs, John Poulton, John Eyles, Trey Greer, Jack Goldfeather 
2, David Ellsworth, Steve Molnar, Greg Turk, Brice Tebbs, Laura Israel Department of Computer Science 
University of North Carolina Chapel Hill, NC 27599-3175 Abstract This paper introduces the architecture 
and initial algorithms for Pixel-Planes 5, a heterogeneous multi-computer designed both for high-speed 
polygon and sphere rendering (1M Phong-shaded tri- angles/second) and for supporting algorithm and application 
re- search in interactive 3D graphics. Techniques are described for volume rendering at multiple frames 
per second, font generation directly from conic spline descriptions, and rapid calculation of radiosity 
form-factors. The hardware consists of up to 32 math-oriented processors, up to 16 rendering units, and 
a conventional 1280x1024-pixel frame buffer, interconnected by a 5 gigabit ring network. Each rendering 
unit consists of a 128x 128-pixel array of processors-with-memory with parallel quadratic expression 
evalu- ation for every pixel. Implemented on 1.6 micron CMOS chips designed to run at 40MHz, this array 
has 208 bits/pixel on-chip and is connected to a video RAM memory system that provides 4,096 bits of 
off-chip memory. Rendering units can be independently reas- signed to any part of the screen or to non-screen-oriented 
computa- tion. As of April 1989, both hardware and software are still under construction, with initial 
system operation scheduled for fall 1989. CR Categories and Subject Descriptors: B.2.1 [Arithmetic and 
Logic Structures]: Design Styles - parallel; C. 1.2 [Processor Archi- tectures]: Multiprocessors -parallel 
processors; 1.3.1 [Computer Graphics]: Hardware Architecture -raster display devices; 1.3.3 [Computer 
Graphics]: Picture/Image generation- display algorithms; 1.3.7 [Computer Graphics[: 3D Graphics and Realism 
- color, shad- ing and texture, visible surface algorithms. Additional Key Words and Phrases: logic-enhanced 
memory, ring network, polygon scan-conversion i This work supported by the Defense Advanced Research 
Projects Agency, DARPA ISTO Order No. 6090, the National Science Foundation, Grant No. DCI-8601152, the 
Office of Naval Research, Contract No. N0014-86-K-0680, and U.S. Air Force Systems Command, Contract 
No. F33615-88-C- 1848. 2 Department of Mathematics, Carleton College, Northfield, MN. Permissionto copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. 1. Introduction Many computer 
applications seek to create an illusion of interaction with a virtual world. Vehicle simulation, geometric 
modeling and scientific visualization, for example, all require rapid display of computer-generated imagery 
that changes dynamically according to the user's wishes. Much progress has been made in developing high- 
speed rendering hardware over the past several years, but even the current generation of graphics systems 
can render only modest scenes at interactive rates, For many years our research goal has been the pursuit 
of truly interactive graphics systems. To achieve the necessary rendering speeds and to provide a platform 
for real-time algorithm research, we have been developing a massively parallel image generation archi- 
tecture called Pixel-Planes [Fuchs 81, 82, 85, Poulton 85]. We briefly describe the basic ideas in the 
architecture: Each pixel is provided with a minimal, though general, processor, together with local memory 
to store pixel color, z-depth, and other pixel information. Each processor receives a distinct value 
of a linear expression in screen-space, Ax + By + C, where A,B,C are data inputs and x,y is the pixel 
address in screen-space. These expressions are generated in a parallel linear expression evaluator, composed 
of a binary tree of tiny multiply-accumulator nodes. A custom VLSlchip contains pixel memory, together 
with the relatively compact pixel processors and the linear expression evaluator, both implemented in 
bit-serial circuitry. An array of these chips forms a "smart" frame buffer, a 2D computing surface that 
receives descriptions of graphics primitives in the form of coefficients (A,B,C) with instructions and 
locally performs all pixel-level rendering computations. Since instructions, memory addresses, and A,B,C 
coefficients are broad- cast to all processors, the smart frame buffer forms a Single-lnstruction-Multiple-Datastream 
computer, and has a very simple connection topology. Instructions (including memory addresses and A,B,C's) 
are generated in a conventional graphics transformation engine, with the relatively minor additional 
task of converting screen-space polygon vertices and colors into the form of linear expressions and instructions. 
In 1986 we completed a full-scale prototype Pixel-Planes system, Pixel-Planes 4 (Pxpl4) [Poulton 87, 
Eyles 88], which renders 39,000 Gouraud-shaded, z-buffered polygons per second (13,000 smooth- shaded 
interpenetrating spheres/second, 11,000 shadowed poly- gons/second) on a 512x512 pixel full-color display, 
While this system was a successful research vehicle and is extremely useful in our department's computer 
graphics laboratory, it is too large and expensive to be practical outside of a research setting. Its 
main limitations are: &#38;#169;i989 ACM-0-89791- 312-4/89/007/0079 $00.75  :t~-~$1GGRAPH '89, Boston, 
31 July-4 August, 1989  large amount of hardware, often utilized poorly (particularly when rendering 
small primitives)  hard limit on the memory available at each pixel (72 bits)  no access to pixel 
data by the transformation unit or host computer  insufficient front-end computation power  This paper 
describes its successor, Pixel-Planes 5 (Pxpl5). Pxpl5 uses screen subdivision and multiple small rendering 
units in a modular, expandable architecture to address the problem of proces- sor utilization. A full-size 
system is designed to render in excess of one million Phong-shaded triangles per second. Sufficient "front 
end" power for this level of performance is provided by a MIMD array of general-purpose math-oriented 
processors. The machine's multiple processors communicate over a high-speed network. Its organization 
is sufficiently general that it can efficiently render curved surfaces, volume-defined data and CSG-defined 
objects. In addition it can rapidly perform various image-processing algorithms. Pxpl5' s rendering units 
each are 5 times faster than Pxpl4 and contain more memory per pixel, distributed in a memory hierarchy: 
208 bits of fast local storage on its processor-enhanced memory chips, 4K bits of memory per pixel processor 
in a conventional VRAM "backing store", and a separate frame buffer that refreshes normal and stereo 
images on a 1280x1024 72Hz display. 2. Background Raster graphics systems generally contain two distinct 
parts: a graphics transformation engine that transforms and lights the geo- metric description of a scene 
in accordance with the user's viewpoint and a Renderer that paints the transformed scene onto a screen. 
Designs for fast transformation units have often cast the series of discrete steps in the transformation 
process onto a pipeline of processing elements, each of which does one of the steps [Clark 82]. As performance 
requirements increase, however, simple pipelines begin to experience communication bottlenecks, so designers 
have turned to multiple pipelines [Runyon 87] or have spread the work at some stages of the pipe across 
multiple processors [Akeley 88]. Vector organizations offer a simple and effective way to harness the 
power of multiple processors, and have been used in the fastest current graphics workstations [Apgar 
88, Diede 88]. Wide vector organizations may have difficulty with data structures of arbitrary size, 
such as those that implement the PHIGS+ standard, so at least one commercial offering divides the work 
across multiple processors operating in MIMD fashion [Torberg 87]. The rendering problem has generally 
been much more difficult to solve because it requires, in principal, computations for every pixel of 
every primitive in a scene. To achieve interactive speeds on workstation-class machines, parallel rendering 
engines have become the rule. These designs must all deal with the memory bandwidth bottleneck at araster 
system's frame buffer. Three basic strategies for solving this problem are: Rendering Pipelines. The 
rendering problem can also be pipelined over multiple processors. The Hewlett-Packard SRX graphics system 
[Swanson 86], for example, uses a pipeline of processors implemented in custom VLSI that simultaneously 
perform 6-axis interpolations for visibility and shading, operating on data in a pixel cache, The frame 
buffer bandwidth bottleneck can be ameliorated by writing to the frame buffer only the final colors of 
the visible pixels. This can only be achieved if all the primitives that may affect a pixel are known 
and considered before that pixel is written. Sorting primitives by screen position minimizes the number 
that have to be 8O considered for any one pixel. Sorting first by Y, then by X achieves a scan-line order 
that has been popular since the late 1960's and is the basis for several types of real-time systems [Watkins 
70]. The basic strategy has been updated by several groups recently. The SAGE design [Gharachorloo 88] 
contained a processor for every pixel on a scan-line. Data for primitives active on a scan-line pass 
by this array, and visible pixel colors are emitted at video rates; no separate frame buffer is required. 
Researchers at Schlumberger [Deering 88] recently proposed a system in which visibility and Phong-shading 
processors in a pipeline are assigned to the objects to be rendered on the current scan line. The latter 
two projects promise future commer- cial offerings that can render on the order of 1M triangles per second 
with remarkably little hardware, though designs for the front ends of these systems have yet to be published. 
These machines have each cast one particular rendering algorithm into hardware, enabling a lower-cost 
solution but one not intended for internal programming by users. New algorithms cannot easily be mapped 
onto hardware for scan-line ordered pipelines. Finally, a difficulty with these designs is ensuring graceful 
performance degradation for scenes with excep- tional numbers of primitives crossing a given scan-line. 
Interlaced Processors. As first suggested a decade ago [Fuchs 77, 79, Clark 80], the frame buffer memory 
can be divided into groups of memory chips, each with its own rendering processor, in an interlaced fashion 
(each processor-with-memory handles every nth pixel on every mth row). The rendering task is distributed 
evenly across the multiple processors, so the effective bandwidth into the frame buffer increases by 
a factor of m.n. This idea is the basis of several of the most effective current raster graphics systems 
[Akeley 88, Apgar 88]. Some of these systems, however, are again becoming limited by the bandwidth of 
commercial DRAMs [Whitton 84]. With increasing numbers of processors operating in SIMD fashion, proc- 
essor utilization begins to suffer because fewer processors are able to operate on visible pixels, the 
"write efficiency" problem discussed in [Deering 88]. Raising the performance of interlaced processors 
by an order of magnitude will probably require more complex organi- zations or new memory devices, Processor-Enhanced 
Memories. Much higher memory bandwidth can be obtained by combining some processing circuitry on the 
same chip with dense memory circuits. The most widely used example of a"smart" memory is the Video RAM 
(VRAM), introduced by Texas Instruments. Its only enhancement is a second, serial-access port into the 
frame buffer memory; nevertheless these parts have had a great impact on graphics system design. The 
SLAM system, described some years ago in [Demetrescu 85], combines a 2D frame buffer memory with an on-chip 
parallel 1D span computation unit; it appears to offer excellent performance for some 2D applications 
but requires external processing to divide incoming primitives into scan- line slices. Recently NEC announced 
a commercial version of an enhanced VRAM that performs many common functions needed in 2D windowing systems. 
This approach has been the focus of our work since 1980; in the Pixel-Planes architecture we have attempted 
to remove the memory bottleneck by performing essentially all pixel- oriented rendering tasks within 
the frame buffer memory system itself. The architecture we will describe below employs a MIMD array of 
processors in its transformation unit and seeks to make more effec- tive use of the processor-enhanced 
memory approach.  3. Project Goals We wanted Pixel-Planes 5 to be a platform for research in graphics 
algorithms, applications and architectures, and a testbed for refine- ments that would enhance the cost 
effectiveness of the approach. To this end, we adopted the following goals:  ~ Computer Graphics, Volume 
23, Number 3, July 1989 Fast Polygon Rendering. Despite all the interest in higher- order primitives 
and rendering techniques, faster polygon ren-dering is still the most often expressed need for many applica- 
tions: 3D medical imaging, scientific visualization, 'virtual worlds' research. We therefore set a goal 
of rendering 1 million z-buffered Phong-shaded triangles per second, assuming the average triangle's 
area is 100 pixels and that it is embedded in a triangle strip. We wanted to achieve this rate without 
using any special structures for rendering just triangles --we wanted a system for much more than triangles. 
Generality. For the system to be an effective base for algorithm development, it needed to have a simple, 
general structure whose power was readily accessible to the algorithm developer programming in a high-level 
language. We wanted it to have sufficient generality for rendering curved surfaces, volume data, objects 
described with Constructive Solid Geome- try, for rendering scenes using the radiosity lighting model, 
and (we hoped) for a variety of other 3D graphics tasks that we have not yet considered. It was essential 
that the system support a PH1GS+ -like environment for application programmers not interested in the 
system's low-level details. Further, the hard- ware platform should be flexible to allow experiments 
in hardware architectures. Packaging. A high-performance configuration that met our primary performance 
goals should fit within a workstation cabinet with no unusual power requirements. We also wanted a system 
that could be modularly built and flexibly configured to trade cost for performance. The system should 
drive a 1280x1024 display at >60Hz, and be able to update full scene images at >20 frames/second. 4. 
Parallel Rendering by Screen-space Subdivision We now describe the scheme we use in Pxpl5to attain high 
levels of performance in a compact, modular, expandable machine. Our previous work has depended on a 
single, large computing surface of SIMD parallel processors operating on the entire screen space. In 
the new architecture, we instead have one or more small SIMD engines, called Renderers, that operate 
on small, separate 128x128-pixel patches in a virtual pixel space. Virtual patches can be assigned on 
the fly to any actual patch of the display screen. The system achieves considerable speedup by simultaneously 
processing graphics primi- tives that fall entirely within different patches on the screen. The principal 
cost of this screen-space subdivision scheme is that the primitives handled in the transformation engine 
must be sorted into "bins" corresponding to each patch-sized region of the screen space. Primitives that 
fall into more than one region are placed into the bins for all such regions. The simplest (though expensive) 
way to support these bins is to provide additional storage in the transformation engine for the entire, 
sorted list of output primitives. Once trans- formed, sorted, and stored, a new scene is rendered by 
assigning all available Renderers to patches on the screen and dispatching to these Renderers primitives 
from their corresponding bins. When a Ren- derer completes a patch, it can discard its z-buffer and all 
other pixel values besides colors; pixel color values are transferred from on-chip pixel memory to the 
secondary storage system, or "backing store", described below. The Renderer is then assigned to the next 
patch to be processed. This process is illustrated in Figure 1 for a system configured with only four 
Renderers. The general idea of multiple independent groups ofpixel processors operating on disjoint parts 
of the display screen was described in several of our earlier publications as "buffered" Pixel-Planes. 
What al [J, ~1 d,la,ld b e 2C3 " b'3  a 3 d I) I) typical I / 128x128 ~pixel patch 1024 pixels 1280 
pixels Figure 1: Rendering process for a Pxpl5 system with 4 Renderers. 1280x1024 screen is divided into 
80 128x128 patches. Patches are processed in raster order. Renderers a-d are assigned initially to the 
first four patches. Renderer a completes first, and is assigned to the next available patch. Next Renderer 
d completes its first patch and is assigned to the next available patch, and so forth. is new about this 
implementation is the idea of flexibly mapping small virtual pixel spaces onto the screen space. It allows 
useful systems to be built with any number of small rendering units, permits cost/performance to be traded 
nearly linearly, and can render into a window of arbitrary size with only linear time penalty. The virtual 
pixel approach is supported in the Pxpl5implementation by a memory hierarchy, whose elements are: (I) 
208 bits of fast SRAM associated on-chip with each pixel processor; (2) a "backing store" built from 
VRAMs, tightly linked to the custom logic-en-hanced memory chips; (3) a conventional VRAM frame buffer. 
The backing store consists f an array of VRAMs, each connected via its video port to one of our custom 
memory chips; IMB VRAMs provide 4Kbits of storage per pixel. The backing store memory is available through 
the VRAM random I/O port to the rest of the system, which can read and write pixel values in the conventional 
way. A Renderer uses this memory to save and retrieve pixel values, effectively allowing "context switches" 
when the Renderer ceases operations on one patch and moves to another. A typical context switch takes 
about 0.4 msec, the time to render a hundred or so primitives, and can be fully overlapped withpixel 
processing. In the simple multi-Renderer scheme described above, the backing store is used to store pixel 
color values for patches of the screen as the Renderer completes them. When the entire image has been 
rendered, each of these regions is transferred in a t~lock to the (double-buffered) display memory in 
the Frame Buffer, from which the display is refreshed.   5. Architectural Overview The major elements 
of Pxpl5 are: Graphics Processors (GPs), floating point engines, each with considerable local code and 
data storage.  Renderers, each a small SIMD array of pixel processors with its own controller.  Frame 
Buffer, double-buffered, built from conventional Video RAMs, from which the video display is refreshed. 
 ~(~SlGGRAPH '89, Boston, 31 July-4 August, 1989 pOrtl o,, :, ,_ : , C~l~,<to, r --+ , I +~.i_. , 'r 
I Rin+ ~-..~ .c'ilGi i L-C-r.~L_~r.~I t ] ! Network Workstation Figure 2:Pxpl5 block diagram. Host Interface, 
which supports communications to/from a UNIX workstation. Ring Network to interconnect the various processors 
in a flexible way. 5.1 Ring Network Pxpl5's multi-processor architecture, motivated by the desire to 
support a variety of graphics tasks, requires a capable communica- tions network. Rather than build several 
specialized communica- tions busses to support different types of traffic between system elements, we 
instead provide a single, flexible, very high perform- ance network connecting all parts of the system. 
At rendering rates of IM primitives per second, moving object descriptions from the GPs to the Renderers 
requires up to 40 million 32-bit words/second (40 MW/sec), even for relatively simple render- ing algorithms. 
Simultaneously, pixel values must be moved from the Renderers to the Frame Buffer at rates up to 40 MW/sec, 
for real- time interactive applications. At the suggestion of J. William Poduska of Stellar Computer, 
Inc., we explored technology and protocols for fast ring networks, and eventually settled on a multi- 
channel token ring. Ring networks have many advantages over busses in high-speed digital systems. They 
require only point-to- point communication, thus reducing signal propagation and power consumption problems, 
while allowing a relatively simple commu- nication protocol. Their major disadvantage, long latency, 
is not acceptable for many computing systems, but is okay here. Our network can support eight simultaneous 
messages, each at 20 MW/sec for a total bandwidth of 160 MW/sec. To avoid deadlock, each transmitting 
device gains exclusive access first to its intended receiver, then to one of the 8 data channels, before 
it transmits its data packet. Each Ring Node is a circuit composed of commercial MSI bus-oriented data 
parts and field-programmable controllers. (At the expense of an expensive development cycle, the Ring 
Network could be reduced to one or a few ASICs.) The controllers operate at 20MHz, while data is moved 
at 40MHz (to save wires). Each client processor in the system has one or more of these Nodes, which provides 
to the client a 20 MW/sec port onto the Ring network. We have developed a low-level message-passing operating 
system for the ring devices called the Ring Operating System (ROS). It provides device control routines 
as well as hardware independent communication. In addition, ROS controls the loading and initializa- 
tion of programs and data. 5.2 Graphics Processors The performance goals we have set require sustained 
computation rates in the "front end" of several hundred MFlops, feasible today only in parallel or vector 
architectures. We elected to build a M1MD transformation unit; this organization handles PH1GS+ -like 
variable data structures better than would a vector unit, and supports the "bins" needed for our screen 
subdivision multi-Renderer. Much of the system's complexity is hidden by ROS; the program- ming model 
is therefore relatively simple. Load sharing is accom- plished by dividing a database across the GPs, 
generally with each GP running the same code. Since the GPs are programmable in the C language, users 
have access to the machine's full capability without needing to write microcode. 5.3 Renderer Section 
4 describes the essentials of the Renderer design, whose block diagram is shown in Figure 3. It is based 
on a logic-enhanced memory chip built using 1.6 micron CMOS technology and operat- ing at 40MHz bit-serial 
instruction rates. In addition to 256 pixel processing elements, each with 208 bits of static memory, 
the chip contains a quadratic expression evaluator (QEE) that produces the value Ax+By+C+DxZ+Exy+Fy 2 
simultaneously at each pixel x,y from global inputs A,B,C,D,E,F [Goldfeather 86]. Quadratic expres- sions, 
while not essential for polygon rendering, are very useful for rendering curved surfaces and for computing 
a spherical radiosity lighting model (see Section 7.6). A major design issue for the Renderer was choosing 
the size of the processor array. The effectiveness of the screen-space subdivision scheme for parallel 
rendering is determined in part by the frequency with which primitives must be processed in more than 
one region, and this in turn depends on the size of the Renderer's patch. On one band, economy of use 
of the fairly expensive custom chips of the processor array and the need to leverage performance by dividing 
the rendering work across as many processors as possible argue for smaller Renderer patches. A large 
Renderer patch, on the other hand, reduces the likelihood that primitives wilt need to be processed more 
than once. We elected a 128x128 Renderer size; it is fairly efficient for small primitives, and its hardware 
conveniently fits on a reason- able size printed circuit board. Custom Memory Chips ' m ~. ~ lx2280~i~r?:]] 
i \ Renderer Board "-,,q-,r-t~ II ] ~ Backing Store Controller [ pnnnnnnq Back ng ] G __LJ ~8!~ P~ixAe~ray 
] ~ e~n~ ~n Store . , on,;ii:;I Pro<essors JI B / L___~ .._.___J [M~[~[~[~t~2 ~ (4K bits/pixel) Figure 
3: Block diagram of a Pxpl5 Renderer. Pixel processor array implemented in 64 custom chips, each with 
2 columns of 128 pixel processors-with-memory and a quadratic expression evaluator. ~ Computer Graphics, 
Volume 23, Number 3, July 1989 5.4 Frame Buffer and Host Interface The Frame Buffer is built in a fairly 
conventional way using Video RAMs. It supports a 1280x1024-pixel, 72Hz refresh-rate display, 24-bit true 
color and a color lookup table. Display modes include stereo (alternating frames) and a hardware 2x zoom. 
The Frame Buffer is accessed through two Ring Nodes, to provide an aggregate bandwidth of 40 MW/sec into 
the buffer, allowing up to 24Hz updates for full-size images. Pxpl5is hosted by a Sun 4 workstation. 
Host communication is via programmed I/O, providing up to 4 MBytes/sec bandwidth between Pxpl5 and its 
host. 5.5 Performance Since the transformation engine in Pxpl5 is based on the same processor used in 
Pxpl4,we estimate, based on the earlier machine's performance, that a GP can process on the order of 
30,000 Phong- shaded triangles per second; 32 GPs are therefore required to meet our performance goal. 
A single Renderer has a raw performance of about 150,000 Phong-shaded triangles per second; actual perform- 
ance is reduced somewhat by inefficiencies resulting from primitives that must be processed in more than 
one patch. Simulations predict an actual performance of around 100,000 triangles/sec, so a configu- ration 
to meet the performance goals will require 8-10 Renderers. 6. PPHIGS Graphics Library Pxpl5 may be programmed 
at various levels. We anticipate users ranging from application programmers, who simply desire a fast 
rendering platform with a PHIGS+ -style interface [van Dam 88], to algorithm prototypers, who need access 
to the Renderer's low-level pixel operations and may depart from the PHIGS+ paradigm. To meet these disparate 
needs, several layers of support software are required. Program initialization and message passing between 
processors are handled by the Ring Operating System (ROS). A local variation of PHIGS+ (PixeI-Planes 
PHIGS or PPHIGS)provides a high-level interface for users desiring portable code. This section describes 
PPHIGS. PPHIGS makes the hardware appear to the "high-level" graphics programmer very much like any other 
graphics system: the programmer's code (running on the host) makes calls to the graphics system to build 
and modify a hierarchical data structure. This structure is traversed by the PPHIGS system to create 
the image on the screen. 6.1 Database Distribution Since the applications programming library is based 
on PHIGS, it allows the programmer to create a display list that is a directed acyclic graph of structures. 
These structures contain elements that are either graphics primitives, state-changing commands, or calls 
to execute other structures. To take advantage of the multiple graphics proces- sors in Pxpl5, we must 
distribute the database structure graph across the graphics processors in a way that balances the computational 
load, even in the presence of editing and changes in view. In order to achieve this we must balance the 
load across GPs for each structure. When a structure is created, some of the primitives are placed on 
each GP. If the object goes out of view or a new instance is created, the load will remain balanced. 
In PHIGS, as in most structured display list systems, child structures inherit information from their 
parents such as transformation matri- ces and colors. These state-changing commands as well as structure 
execution calls must be replicated on each GP since each structure is distributed across multiple GPs. 
This replication should not be a problem, since we expect the majority of structure elements to be graphics 
primitives and not state-changing ones. We have devised other distribution schemes for applications that 
violate this assump- tion. 6.2 The Rendering Process The rendering process is controlled by a designated 
graphics proces- sor, the master GP, or MGP. By exchanging messages with other GPs and sending commands 
to other modules when necessary, the MGP synchronizes operations throughout the system. Before discussing 
the steps in the rendering process, we first want to emphasize the distinction between pixel operations 
that take place on a per primitive basis, such as z comparison and storage, and those that can be deferred 
until the end of all primitive processing or end-of- frame. Shading calculations from intermediate values 
stored at the pixels, for instance, need only be performed once per pixel, rather than once per primitive 
(assuming there is sufficient pixel storage to hold the intermediate values until end-of-frame). During 
end-of- frame the final colors can be computed in parallel from the stored values of the visible portions 
of every polygon that falls within the 128x128 pixel region. For expensive lighting and shading models, 
such as Phong shading and textures, this speedup is dramatic. The major steps in the rendering process 
are: 1. The application program running on the host edits the database using PPHIGS library routines 
and transmits these changes to the GPs. 2. Application requests anew frame. Host sends this request 
to the MGP, which relays it to the other GPs. 3. The GPs interpret the database, generating Renderer 
commands for each graphics primitive. These commands are placed into the local bins corresponding to 
the screen regions where the primitivelies. EachGPhas abin forevery 128x128pixelregion in the window 
being rendered. 4. The GPs send bins containing commands to Renderers. The Renderers execute commands 
and compute intermediate re-suits. 5. The GP sending the final bin to a Renderer also sends end-of- 
frame commands for the region. The Renderers execute these commands and compute final pixel values from 
the intermedi- ate results. 6. The Renderers send computed pixels to the frame buffer. 7. When all 
regions have been received, the frame buffer swaps banks and displays the newly-computed frame.  The 
MGP assigns Renderers to screen regions while the frame is being rendered. It communicates a Renderer 
assignment to the GPs by sending a message to one GP, which sends its associated bin, and then forwards 
the message to the next GP, which does the same. At the end, the message is sent back to the MGP, indicating 
that all the bins have been processed. This method ensures that at most one GP attempts to transmit to 
a Renderer at a given time. This prevents blocked transmissions, which would slow throughput. The steps 
of the rendering process can be overlapped in several ways; at maximum throughput, several frames may 
bein progress at once. This requires that the bin memory be double buffered. If a GP runs out of bin 
memory it must send some of its bin data to a Renderer to free up memory. The MGP handles synchronization 
to keep the frames properly separated [Ellsworth 89]. 7. Rendering Algorithms We now discuss various 
rendering algorithms in turn. Some of these have been published before, in which case, we review their 
applica-    '89, Boston, 31 July-4 August, 1989 [Fuchs 81] Fuchs, H. and J. Poulton, "Pixel-planes: 
A VLSI- Oriented Design for a Raster Graphics Engine," VLSI Design, 3rd Quarter, 1981., 2(3),.pp 20-28. 
[Fuchs 82] Fuchs, H., J. Poulton, A. Paeth, and A. Bell, "Developing Pixel Planes, A Smart Memory-Based 
Raster Graphics System," Proceedings of the 1982 M1T Conference on Advanced Research in VLSI, Dedham, 
MA, Artech House, pp 137-146. [Fuchs 85] Fuchs, H., J. GoldFeather, J.P. Hultquist, S. Spach, J. Austin, 
F.P. Brooks, Jr., J. Eyles, and J. Poulton, "Fast Spheres, Textures, Transparencies, and Image Enhancements 
in Pixel- Planes," Computer Graphics, 19(3), (Proceedings of SIGGRAPH '85), pp. 111-120. [Gardner 88] 
Gardner, G., "Functional Modeling of Natural Scenes, Functional Based Modeling," SIGGRAPH Course Notes, 
vol. 28, 1988, pp. 44-76. [Gharachorloo 88] Gharachorloo, Nader, S. Gupta, E. Hokenek, P. Balasubramanian, 
B. Bogholtz, C. Mathieu, C. Zoulas,"Subnanos- econd Pixel Rendering with Million Transistor Chips, " 
Com-puter Graphics, 22(4), (Proceedings of SIGGRAPH '88), pp 41 - 49. [Goldfeather 86] Goldfeather, 
Jack and Henry Fuchs, "Quadratic Surface Rendering on a Logic-Enhanced Frame-Buffer Memory System," IEEE 
Computer Graphics and Applications, 6(1), pp 48-59. [Goldfeather 88[ Goldfeather, Jack, S. Molnar, G. 
Turk, and H. Fuchs, "Near Real-Time CSG Rendering using Tree Normaliza- tion and Geometric Pruning," 
University of North Carolina Department of Computer Science Technical Report TR88-006. To appear in CG&#38;A, 
1989. [Goldfeather 89] Goldfeather, Jack, "Progressive Radiosity Using Hemispheres," University of North 
Carolina Department of Computer Science Technical Report TR89-002. [Goral 84] Goral, Cindy M., Kenneth 
E. Torrance, Donald P. Greenberg and Bennett Battaile, "Modeling the Interaction of Light Between Diffuse 
Surfaces," Computer Graphics, 18(3), (Proceedings of SIGGRAPH '84), pp. 213-222. [Immel 86] lmmel, D., 
M. Cohen, and D. Greenberg, "A Radiosity Method for Non-Diffuse Environments," Computer Graphics, 20(4), 
(Proceedings of SIGGRAPH '86), pp. 133-142. [Jansen 87] Jansen, F. and R. Sutherland, "Display of Solid 
Models with a Multi-processor System," Proceedings of Eurographics "87, Elseviers Science Publications, 
1987, pp 377-387. [Levoy 89a] Levoy, Marc, "Volume Rendering by Adaptive Refinement," The Visual Computer, 
5(3), June, 1989 (to appear). [Levoy 89b] Levoy, Marc, "Design for a Real-Time High-Quality Volume Rendering 
Workstation," Chapel Hill Workshop on Volume Visualization, Chapel Hill, North Carolina, May 1989 (to 
appear) [Norton 82] Norton, Alan, "Clamping: A Method of Antialiasing Textured Surfaces by Bandwidth 
Limiting in Object Space," Computer Graphics, 16(3), (Proceedings of SIGGRAPH ' 82), pp 1-8. [Pavlidis 
83] Pavlidis, T., "Curve Fitting with Conic Splines,"ACM Transactions on Graphics, 2(1), January 1983. 
[Perlin 85] Perlin, K., "An Image Synthesizer," Computer Graphics, 19(3), (Proceedings of SIGGRAPH '85), 
pp. 151-159. [Phong 73] Phong, B.T., "Illumination for Computer-Generated Pictures," Ph.D. Dissertation, 
University of Utah, Salt Lake City, 1973. [Poulton 85] Poulton, J., H. Fuchs, J.D. Austin, J.G. Eyles, 
J. Heinecke, C-H Hsieh, J. Goldfeather, J.P. Hultquist, and S. Spach, "PIXEL-PLANES: Building a VLSI-Based 
Graphic System," Proceedings of the 1985 Chapel Hill Conference on VLSI, Rockville, MD, Computer Science 
Press, pp 35-60. [Poulton 87] Poulton, J., H. Fuchs, J. Austin, J. Eyles, T. Greer. "Building a 512x512 
Pixel-planes System," Proceedings of the 1987 Stanford Conference on Advanced Research in VLS1, MIT Press, 
pp 57-71. [Pratt 85] Pratt, V., "Techniques for Conic Splines," Computer Graphics, 19(3), (Proceedings 
of SIGGRAPH '85), pp. 151-159. [Rossignac 86] Rossignac, J., A. Requicha, "Depth Buffering Display Techniques 
for Constructive Solid Geometry," IEEE Computer Graphics and Applications, 6(9), pp 29-39. [Runyon 87] 
Runyon, S., "AT&#38;T Goes to 'Warp Speed' with its Graphics Engine," Electronics Magazine, July 23, 
1987, pp 54- 56. [Swanson 86] Swanson, R., L. Thayer, "A Fast Shaded-Polygon Renderer," Computer Graphics, 
20(4), (Proceedings of SIGGRAPH '86), pp 95-101. [Tor 84] Tor, S. and A. Middleditch, "Convex Decomposition 
of Simple Polygons," ACM Transactions on Graphics, 3(4), Octo- ber 1984, pp 244-265. [Torberg 87] Torberg, 
J., "A Parallel Processor Architecture for Graphics Arithmetic Operations," Computer Graphics, 21(4), 
(Proceedings of SIGGRAPH '87), pp 197-204. [van Dam 88] van Dam, A., Chairman, PHIGS+ Committee, "PHIGS+ 
Functional Description, Revision 3.0," Computer Graphics, 22(3), July, 1988, pp 125-218. [Wallace 87] 
Wallace, J., M. Cohen, and D. Greenberg, "A Two- Pass Solution to the Rendering Equations: A Synthesis 
of Ray- Tracing and Radisoity Methods," Computer Graphics, 21(4) (Proceedings of SIGGRAPH '87), pp. 311-320. 
[Watkins 70] Watkins, G., "A Real-Time Visible Surface Algo- rithm, " University of Utah Computer Science 
Department, UTEC-CSc-70-101, June 1970, NTIS AD-762 004. [Whitton 84] Whitton, Mary., "Memory Design 
for Raster Graphics Displays," IEEE Computer Graphics and Applications, 4(3), March 1984, pp 48-65. [Williams 
83] Williams, Lance, "Pyramidal Parametrics," Corn-. puter Graphics 17(3) (Proceedings of SIGGRAPH '83), 
pp. 1- 11.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74342</article_id>
		<sort_key>89</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Illumination networks: fast realistic rendering with general reflectance functions]]></title>
		<page_from>89</page_from>
		<page_to>98</page_to>
		<doi_number>10.1145/74333.74342</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74342</url>
		<abstract>
			<par><![CDATA[We present a technique for modeling global illumination which allows a wide variety of reflectance functions. Scene coherence is exploited in a preprocessing step in which the geometry is analyzed using iterative techniques. Memory is traded for speed, in anticipation of the high memory capacities of workstations of the future. The algorithm operates well over a wide range of time and image quality constraints: realistic results may be produced very quickly while very accurate results require more time and space. The method can be extended for animation and parallelization.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P45942</person_id>
				<author_profile_id><![CDATA[81100097043]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Buchalew]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Sciences, The University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68425</person_id>
				<author_profile_id><![CDATA[81100584372]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fussell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Sciences, The University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[[1] Arvo, James, Backward Ray Tracing, Developments in Ray Tracing (SIGGRAPH '86 Course Notes), Vol. 12, August 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37409</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[[2] Arvo, James and David Kirk, Fast Ray Tracing by Ray Classification, <i>Computer Graphics</i> (SIGGRAPH '87 Proceedings), Vol. 21, No. 4, July 1987, pp. 55-64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[[3] Cohen, Michael F., Donald P. Greenberg, A Radiosity Solution for Complex Environments, <i>Computer Graphics </i> (SIGGRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 31-40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[[4] Cohen, Michael F., Shenchang Chen, John Wallace, Donald P. Greenberg, A Progressive Refinement Approach to Fast Radiosity Image Generation, <i>Computer Graphics</i> (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 1988, pp. 75-84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[[5] Cook, Robert L., Thomas Porter, Loren Carpenter, Distributed Ray Tracing, <i>Computer Graphics</i> (SIGGRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 111-120.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[[6] Immel, David S., Michael F. Cohen, Donald P. Greenberg, A Radiosity Method for Non-Diffuse Environments, <i>Computer Graphics</i> (SIGGRAPH '86 Proceedings), Vol. 20, No. 4, August 1986, pp. 133-142.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[[7] Kajiya, James T., Anisotropic Reflection Models, <i>Computer Graphics</i> (SIGGRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 15-21.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[[8] Kajiya, James T., The Rendering Equation, <i>Computer Graphics</i> (SIGGRAPH '86 Proceedings), Vol. 20, No. 4, August 1986, pp. 143-150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[[9] Mitchell, Don P., Generating Antialiased Images at Low Sampling Densities, <i>Computer Graphics</i> (SIGGRAPH '87 Proceedings), Vol. 21, No. 4, July 1987, pp. 65-72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[[10] Nashita, Tomoyuki and Eihachiro Nakamae, Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection, <i>Computer Graphics</i> (SIGGRAPH 85 Proceedings), Vol. 19, No. 3, July 1985, pp. 22-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>30319</ref_obj_id>
				<ref_obj_pid>30300</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[[11] Ohta, Masataka and Mamoru Maekawa, Ray Coherence Theorem and Constant Time Ray Tracing Algorithm, <i>Computer Graphics 1987</i> (Proceedings of CG International '87), ed. T. L. Kunii, pp. 303-314.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[[12] Wallace, John R., Michael F. Cohen, Donald P. Greenberg, A Two-pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radiosity Methods, <i>Computer Graphics</i> (SIGGRAPH '87 Proceedings), Vol. 21, No. 4, July 1987, pp. 311-320.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[[13] Ward, Gregory J., Frances M. Rubinstein, Robert D. Clear, A Ray Tracing Solution for Diffuse Interreflection, <i>Computer Graphics</i> (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 1988, pp. 85-92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[[14] Whitted, Turner, An Improved Illumination Model for Shaded Display, <i>Communications of the ACM</i>, Vol. 23, No. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 Illumination Networks: Fast Realistic Rendering 
with General Reflectance Functions Chris Buckalew Donald Fussell Department of Computer Sciences The 
University of Texas at Austin Austin, TX ABSTRACT We present a technique for modeling global illumination 
which allows a wide variety of reflectance functions. Scene coherence is exploited in a preprocessing 
step in which the geometry is analyzed using iterative techniques. Memory is traded for speed, in anticipation 
of the high memory capac- ities of workstations of the future. The algorithm operates well over a wide 
range of time and image quality constraints: realistic results may be produced very quickly while very 
ac- curate results require more time and space. The method can be extended for animation and parallelization. 
CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation-Display algorithms. 
1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. General Terms: Algorithms Additional 
Key Words and Phrases: global illumination, radiosity, ray tracing, memory, specular, diffuse, data struc- 
ture, incremental, ray space. 1. INTRODUCTION Most techniques used to model global illumination are well- 
suited to particular surface reflectance functions. Ray trac- ing methods built on [14] have been designed 
to render spec- ular reflection from surfaces, and relatively efficient algo- rithms for thi s purpose 
have been developed [2]. Radiosity methods such as [3] and [10] have been designed to handle diffuse 
reflection from surfaces, and recent advances have led to relatively efficient algorithms of this type 
as well [4]. Generalizations of ray tracing techniques to handle diffuse Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0089 
$00.75 78712 reflectance functions ([1] [5] [8] [13]) and of radiosity tech- niques to handle specular 
reflectance functions ([6]) have been significantly slower. This has led to the development of hybrid 
methods which capitalize on the strengths of both techniques ([12]) to efficiently render scenes containing 
both diffuse and specular surfaces. We have developed a fast algorithm for rendering scenes containing 
both diffuse and non-diffuse surfaces. The method can produce illumination of arbitrary accuracy, with 
very realistic results produced in a very short time. The algorithm has been designed to exploit a space-time 
trade- off, in which the use of large data structures allows a less computatlon-intensive approach to 
be used than might oth- erwise have been possible. In spite of this, the memory re- quirements of this 
method are much smaller than the virtual memory capacities of most of today's workstations and well within 
the real memory capacities of tomorrow's machines. The algorithm can be extended to allow fast animation 
that saves information between frames, and it can be efficiently parallelized. 2. THE PATCH-LINK MODEL 
In diffuse reflection, a surface element interacts with most of the other elements that are visible from 
its front surface. The usual technique for computing global illumination for diffuse surfaces based on 
their radiosity solves this problem with virtual frame buffers called hemicubes that represent the scene 
from each of the elements' points of view [3]. Un- fortunately, the hemicubes must be stored at huge 
memory cost or recalculated frequently, and they represent only that directional information which contributes 
to the computa- tion of form-factors, or percentage of the energy emitted from each surface element which 
actually arrives at a given surface element. For non-diffuse reflection, light incident on each surface 
element reflects in a particular direction, so de- tailed directional information must be used in modeling 
this type of reflection. In [6], the hemi-cube approach was gen- eralized to include such information 
by replacing locally ori- '89, Boston, 31 July-4 August, 1989 SIGGRAPH ented hemicubes associated with 
each surface element with a cube oriented along the coordinate axes for each element. Thus a directionally 
varying radiosity from any element can be distributed to other elements within the context of a sin- 
gle, global coordinate system providing directional referents. Unfortunately, this method required that 
an e  e sparse ma- trix be replaced by an ed  ed matrix in solving for the energy balance of the environment, 
where e surface elements and d directions are being used. In practice, this required on the order of 
1.5 to 8 days of CPU time on a small supereomputer to produce images of simple scenes [6]. Ray tracing 
methods control the high computational cost of global directional illumination by calculating rays from 
one surface element to another only as they are needed. In specular environments relatively few rays 
are needed, so the high cost of computing them individually is worthwhile. However, ray tracing diffuse 
environments requires far more rays to sample the many elements of the scene providing diffuse illumination 
of each element, and the expense of the ray-object intersection calculations may become significant. 
Our algorithm has some of the characteristics of dis- tributed ray tracing and of radiosity techniques. 
It is based on a data structure called an illumination network (I-net). This data structure implements 
a model of light and surface interaction which we call the patch-link model. Surfaces in the scene are 
intersected with a set of rays distributed in orientation and location throughout the scene. Any time 
a pair of facing surfaces is intersected by a common ray, a "link" between these surfaces is formed. 
The surfaces are then treated as sets of "patches," each of which is a small neighborhood of links. Light 
can travel through the scene only by means of these links. The reflectance function associ- ated with 
each patch consists of a mapping from "incoming" links to "outgoing" links; that is, the input to the 
function is a collection of incoming light intensities over the set of links, which the function maps 
to a collection of outgoing light intensities over the same set of links. The set of links associated 
with each patch connect it to much of its environment, thus fulfilling the function of hemicubes or the 
global cubes of [6]. In addition, the links encode the directional relationships of the patches they 
con- nect, serving the function of rays in ray tracing methods. The high cost of computing the large 
number of links nec- essary is reduced and scene coherence is exploited by calcu- lating all the links 
incrementally in a preprocessing step. The collection of links represents a finite subset of all the 
light rays which pass through the scene. An extreme ap-proach is to select at least one ray which connects 
each pair of patches and add it to the collection of links. If there are N patches this process will 
result in at least N 2 links. Another approach is that of [6], in which the projection of a patch onto 
a global cube element forms a link. Our approach is to choose an "evenly distributed" and geometrically 
uniform set of rays which intersect the scene. Any of the rays ill this set which intersect two objects 
will become links. Proper choice of this set of rays will allow fast incremental ray-patch intersection 
computatiotts as a preprocessing step. The patch-llnk model clearly works well in the limit, where patch 
size approaches zero and the number of links approaches infinity, and clearly works poorly where patch 
size is very large and number of links very small. The cor-rect choice for these sizes depends very much 
on the re-flectance functions of the objects in the scene and the de- sired resolution and accuracy of 
the image. Shiny objects and sharp shadows, for instance, require smaller patch sizes, and greater accuracy 
requires more links. 3. AN OVERVIEW OF THE ALGORITHM The algorithm consists of three main parts. The 
first is a preprocessing step in which the objects in the scene are divided into patches and the links 
between patches in the scene are established. Reflectance functions are set up at this time as well: 
the reflectance function for a patch is described by an NxN matrix, where the (i,j)th element of the 
matrix gives the fraction of the light arriving on llnk i that will leave on link j. The reflectance 
function, then, is determined by the coefficients of this matrix. For a completely diffuse patch, all 
the coefficients of the matrix would be equal, with the sums of each of the rows equal to one. In reality 
a surface will absorb some of the incident radiation, so the sums of each of the rows will actually be 
less than one-if this were not the case convergence might not be achievable. For a perfect mirror, each 
row would have one coefficient of I with the rest 0, because all the light coming in over link i will 
leave by the link associated with the reflectance angle of link i. The second part of the algorithm is 
the distribution pro- cess. Light travels outward over the links associated with the light-emitting patches 
and arrives at the patches on the other end of these links. For each of these patches, the incoming light 
is passed through the patch's reflectance function, and the result is passed outward along the patch's 
links to the patches on the other end of the links, some of which will be the original emitting patches. 
This process continues until there is no more light incoming to any patch, which occurs when all the 
light has been reflected out of the scene or ab- sorbed. This strategy resembles the light shooting technique 
used in the progressive refinement approach to hemi-cube based radiosity computation in [4]. Following 
convergence, the scene must be rendered; the algorithm gives view-independent results, so viewing param- 
eters are set up and light falling on the screen is determined. The preprocess and the distribution process 
are cleanly sep- arated, so that once the I-net is set up in the preprocess, it may be reused by multiple 
passes of the distribution process. Objects' reflectance functions and light source strengths may be 
changed between passes; the preprocess merely encodes the geometry of the scene into an I-net. @ ~ Computer 
Graphics, Volume 23, Number 3, July 1989 4. LINKS Links are implemented as pointers; if a ray intersects 
two patches which face each other, each patch will have a pointer for that link, pointing to the other 
patch. The geometry thus becomes implicit: the pointer indicates the patch that is hit if light leaves 
the patch in a certain direction. In our implementation the direction in 3-space associated with a pointer 
is determined by its location in the patch's array of such pointers. Some ray-tracing techniques, such 
as [2] and [11], have used a finite set of rays to partition all the rays intersect- ing the scene into 
areas of interest, but our method uses only a predetermined finite set of rays for all light transport 
throughout the scene. We would like this set to be uniform so that it lends itself to incremental ray-object 
intersection calculations. To achieve this end we chose a formulation of ray space similar in some respects 
to that of [2]. The ray space of [2] is 5-dimensional; a ray is represented by a 3-D origin and a 2-D 
direction. We use a different, 4-dimensional formulation. Rays are represented by lines, each described 
by two slopes and a two-dimensional inter- cept. The 2-D intercept gives the line's intersection with 
an intercept plane (one of x -y, x -z, or y -z planes) and the slope of the line in each of the intercept 
plane's two di- mensions. There is no ray origin or ray direction as with [2]; origins are built into 
the data structure (the ray-object intersection points serve as origins) and the ray's direction along 
the line (plus or minus) is implied by the direction that the object faces. This formulation of ray space 
may be visualized more easily by considering the analogous formulation for two-dimensional scenes. In 
2-space, lines are described by one intercept (on the z-axis or on the y-axis) and one slope in the appropriate 
dimension (dy/dx if intercept is on the y-axis or dx/dy if the intercept is on the x-axis). Thus this 
ray space for 2-D scenes is two-dimensional. However, some rays cannot be described by a y-intercept 
and y-slope, just as some rays cannot be described by an x-intercept and an x-slope. To solve this problem 
we par- tition ray space into two regions, one for rays whose y-slope is between -1 and +1, the other 
for rays whose x-slope is between -1 and +1. If we restrict our scene to the first quadrant of the unit 
square (in 3-space, the first octant of the unit cube); then we can put boundaries on the range of the 
x-and y-intercepts. If y--slopes must be less than one, then the lowest possible y-intercept is -1. Similarly 
if y-slopes must be greater than -1, the highest possible y-intercept is 2. The 2-dimensional version 
of this situation is shown in Figure 1. All the rays passing through the first quadrant of the unit square 
are contained in two areas of ray space, one for each dimension, limited by -1 and +1 on the slope axis 
and -1 and +2 on the intercept axis. These areas, and some sample rays, are shown in Figure 2. Our selection 
of rays that will %, 2 "'"",,slope = -1 %%1 i t- ~p ad te ,,,' slope = +1 Figure 1: slope and intercept 
bounds on first quadrant of the unit square become links is simply a sampling of points in the ray space 
we have formulated. We choose appropriate intervals for the slope and intercept axes, set up a grid with 
these intervals, and generate a ray for each grid point. In 3-space the process is exactly analogous. 
We have three volumes of ray space, one for each intercept plane, each re-gion bounded by -1 and +1 on 
the slope axes and -1 and +2 on the intercept axes. Our finite set of rays is chosen by a uniform point 
sample in this four-dimensional ray space, just as in the 2-space case. Two things to note: not all the 
rays inside these limits actually pass through the scene, and the rays are uniform in terms of slopes 
and intercepts. They are not uniform in other ways. For example, con-sider all the rays of this sampling 
that pass through the ori- gin. The spatial density of the rays decreases as the slopes approach zero. 
This is shown in the 2-dimensional example in Figure 3. We correct for this error by associating a weight- 
ing factor with each slope which is applied to all light travel- ing along any link having that slope. 
Each slope accounts for a certain portion of a sphere around the origin of the ray, and the weighting 
factor is associated with the size of the angle which subtends that portion. For the k-th ray counterclock- 
wise from the horizontal about the ray origin, the subtended angle 8k = arctan((k + 0.5)~Xy) -arctan((k 
-0.5)~y) and the weight associated with that ray is therefore c]Skfor some constant c. Another nonuniformity 
is in the distances between rays with common slopes. Rays orthogonal to their intercept plane are spaced 
at a distance ~r apart in each of two coor- dinate directions. Then rays at an angle ~b with respect 
to these rays (likewise with respect to the intercept plane nor-mal) are at a distance &#38;r cos apart 
(see Figure 4). This nonuniformity in spacing would cause errors if left uncor-rected, so an attenuation 
factor of cos $ is associated with all rays at angle  with respect to their intercept plane nor- mal. 
 '89, Boston, 31 July-4 August, 1989 five rays in 2-space y-intercept x-intfrcept .... ' :~: 112 i ~ 
:~:i:~;:: ...... ' , (~)'~!i!:ii: ii:: "~ i ::: O: ::::~: :1 '~ope -~ ::. i!~ :: ;:o s~ope ....: ;!/:::.:... 
: :: ... : i :Q J -1 _t I the same rays in ray space Figure 2: scene space and ray space Y  (k+ 1/2)Ay 
(k-1/2)Ay X 0 Figure 3: spatial density varies with slope ~r COS ~r Figure 4: nonuniform spacing correction 
 Note that this correction allows Lambert's cosine law for diffuse reflection to be modeled by the intersection 
densities of rays at various angles to a surface. Given the ray distance correction factor noted above, 
the density of energy trans-mitted by a given size set of rays is constant regardless of the slope of 
the rays. In terms of energy density, this has the same effect as rays with uniform spacing at all slopes 
with no correction factor. For evenly spaced rays, the density of intersections with rays at angle c~ 
with respect to the surface normal varies as cos o~ and provides the desired attenuation, therefore our 
correction for the energy density also provides proper distribution of the incoming energy for Lambertian 
reflection. As a result, it is not necessary to include this cos o~ term in the reflectance functions 
for surfaces if enough links are involved in the calculation of the intensity at a pixel. In the current 
implementation, objects are limited to pla- nar polygons. It is very easy to calculate ray-object intersec- 
tions incrementally with this set of rays. Once we calculate the intersection point of a given ray and 
a given object, it is a simple matter to determine the intersection point of the same object and the 
"next" ray. The planar geometry of the object and the geometry of the relationship of one ray to the 
next result in very simple incremental calculations, which are described more fully in a later section. 
5. PATCHES Given a uniform set of rays which will become links, the scene is divided into patches. If 
the patch size is too small, it will not intersect very many rays, and thus will not have very many links. 
If a patch is too large, one ray for each slope must be chosen as a link out of perhaps many such rays. 
A bad choice for the link might cause errors. We deal with this problem by dividing each object into 
rectangular areas each of which is small enough that it can intersect no more than one ray for each slope. 
This is accomplished by sizing the rectangular areas such that when projected onto the intercept planes 
the sides of the projected rectangles are equal to the intercept interval. The I-net data structure is 
simple. Each patch has an array of pointers, one for each slope, and with each pointer is associated 
a buffer for incoming light called the in-buffer. Each pointer represents a link, and it points to the 
patch on the other end of the link. The in-buffer accumulates unprocessed light that has come in over 
the link, but that has not yet been sent through the reflectance function. The size of the array and 
the total number of patches depends on the resolution required. For patches that have only a diffuse 
component to the re- flectance function, the direction of incoming light is not im- portant since it 
will be evenly distributed. For these patches, then, a great deal of memory may be saved by eliminating 
their in-buffers and substituting a global in-buffer which re- ceives all the light arriving at the patch, 
regardless of direc- tion. @ ~ Computer Graphics, Volume 23, Number 3, July ~989 6. REFLECTANCE FUNCTIONS 
Conceptually, the reflectance function of a patch is described by an N  5/" matrix, where N is the number 
of links con- nected to the patch. N is usually a large number, so the resulting matrix is very large. 
For a totally diffuse reflection function, all elements of the matrix are identical, so it may be represented 
by a scalar constant. In the case of a specular reflectance function, the matrix is very sparse, with 
entries in each row clustered about the column associated with the reflection direction for that row. 
For these reflectance func- tions it is cheaper to store for each llnk the location of the reflecting 
link and a small matrix which describes how the light will be distributed around the reflecting link. 
Usually this small matrix will be the same not only for every link connected to the patch, but for every 
link connected to the 2 entire object. In this way storage costs are reduced and ex-ecution speeds are 
improved. Thus diffuse and specular reflectance functions can be stored at modest cost. Other interesting 
reflectance func- tions may be stored in this way as well. If the generality of the full matrix representation 
of a reflectance function is desired, the large matrix need be stored only once for each object (instead 
of for each patch), since objects are planar. 7. BUILDING THE I-NET STRUCTURE The preprocess utilizes 
the slope-intercept format of rays: a ray will intersect an object if its intercept lles inside a poly- 
gon formed by projecting the object onto the intercept plane along the ray's slope. This is illustrated 
in a 3-D example in 2 Figure 5. Basically, then, for each slope S, we project each 0 object onto the 
intercept plane along S and run a standard scan-conversion algorithm on the resulting polygon. All rays 
with slope S whose intercepts lie within the polygon intersect the object and those intersection points 
can be calculated in- crementally. The incremental calculation of ray-object intersections is 0 the key 
to the speed of the preprocess. Given an object and two slopes, the intercepts are easily determined 
by scan- -1 converting, as described above. However, we must also de- -1 termine the coordinates of 
the ray-object intersections that project to these intercepts in order to find which patches the ray-object 
intersections are in. Suppose that the plane equation of an object is Ax + By + Cz + D = 0 and we wish 
Figure 5: some rays associated with a given slope to find the intersection points of all the rays intersecting 
the y -z plane with slopes yslope and zslope. If the intercept of a particular ray is (yint, zint), then 
the coordinates of the point (x, y, z) where the ray intersects the object are determined as follows: 
Ax + By+Cz+ D= 0 Ax + B(yslope x + yint) + C(zslope x + zint) + D = 0 Ax + B, yslope, x + C zslope* 
x = -D -B, yint- C, zint  ,, S GGRAPH '89, Boston, 31 July-4 August, 1989 Figure 6: a ray and the links 
it generates (-D -B * yint -C * zint) X~ (A + B * yslope + C * zslope) This is the result for the x-coordinate; 
y and z are deter- mined from x. If the denominator is zero, then the y- and z-slopes are both parallel 
to the object's plane, and if there is a solution, it will not be unique. This calculation is not at 
all fast, and it may be made faster by noticing that the denominator need be calculated only once for 
each pair of slopes. It is then combined with the numerator coefficients so that D' = D/(A + B yslope 
+ C zslope) B' = B/(A -F B * yslope + C * zslope) C' = C/(A + B * yslope + C * zslope) The calculation 
is now x = -D ~ - B ~ yint -C p zint which is certainly faster, but if we take advantage of the fact 
that we are using a scan-conversion algorithm to determine yint and zint, it may be made faster yet. 
Since zint remains constant throughout each scan and at each step of the scan conversion yint is incremented 
by 2xy, then x0 = -D t -B ~ * yint -C ~ * zint at the start of the scan, and xi+a = xi --B I * Ay thereafter. 
Also, B I * Ay is fixed throughout the scan conversion, so each step costs only an addition. The other 
two coordinates are determined as before. These intersection points are stored until all intersections 
have been found for S. At this point each ray with slope S is examined for intersections; links are set 
up between any pair of patches which have consecutive intersections on the ray and which face each other, 
as shown in Figure 6. Note that many links may be set up for a single ray if there are multiple pairs 
of objects facing each other along the ray. The regularity of the geometry of the patches and links can 
cause noticeable aliasing. To attenuate the effects of this problem the ray-object intersection points 
are jittered by a random fraction of the intercept interval amount. This procedure results in a small 
perturbation in the slope rep- resented by each link. This loss of regularity is achieved very cheaply, 
and the resultant noise reduces the effect of the aliasing artifacts. The general problem of aliasing 
due to uniform point sampling and methods of dealing with it are discussed in [9]. 8. THE DISTRIBUTION 
PROCESS This part of the algorithm distributes the light throughout the scene until convergence is achieved. 
Light is first "shot" from the light sources, which have patches and links llke any other objects. This 
light is sent into the scene via the light sources' links, and is accumulated in the recipient patches' 
in-buffers. Following the light sources' depletion, each patch in the scene is sequentially examined 
for any unprocessed light in the patch's in-buffers. If any is found, the contents of each of the patch's 
in-buffers is run through the reflectance function and the result is sent outward over the patch's links 
into other patches' in-buffers. This process is continued until no patch's in-buffer contains an amount 
of light larger than a given small threshold value. The reflectance function calculations consume most 
of the time used in this process. In the general case, the reflectance function multiplies the array 
of in-buffers by a matrix of co- efficients and the result is mapped back out to the array of links. 
As mentioned above, we may short-circuit this proce- dure in the case of diffuse or specular reflectance 
functions (or a function which is a combination of the two) with a resultant memory savings. For example, 
if a surface reflects 60~ of incoming light in a tight specular pattern and 40~ in a diffuse pattern, 
then 40~ of the incoming light will be summed into a global buffer and distributed evenly while the remainder 
will be distributed around the reflected direction according to a small matrix which describes how the 
light spreads around the reflected direction. When the patch is totally diffuse only the global buffer 
need be maintained, and incoming light is processed very rapidly. 9. RENDERING The algorithm is view-independent; 
no eyerays need be cal- culated prior to rendering. Given the standard viewing pa- rameters, eyerays 
are shot from the eyepoint through each pixel of the image plane. Each eyeray is matched to the "closest" 
link (in terms of slope and intercept), and the eye- ray's intersection point with the nearest object 
(found with a standard Z-buffer algorithm) determines the patch it hits. The amount of light that the 
pixel sees is given by the to- tal amount of light reflected from that patch over that link, which has 
been accumulated in an out-buffer associated with the link. This procedure is not sufficient to produce 
good results, however. Sudden jumps in intensity may occur as the eyer- ~ a C  ""q j Figure 7: non-diffuse 
rendering ays move from patch to patch, or the slope that the eyeray is coerced to changes. To avoid 
these problems, the light assigned to an eyeray is interpolated in two different ways: the light intensities 
associated with the rays surrounding the eyeray are interpolated for patches in the intersected patch's 
8-neighborhood, and then these values are themselves inter- polated. This process is illustrated in Figure 
7. A given ey- eray is associated with the four slopes that surround it-the x - z slopes immediately 
to the left and right of the eyeray's x -z slope, and the x --y slopes immediately above and below the 
eyeray's x - y slope-these are called the bounding slopes. The out-buffers associated with these four 
slopes are evaluated for each of the patches in the intersected patch's 8-neighborhood. For each of the 
four patches in each %or- net" of the 8-neighborhood, the value associated with the eyeray's slope is 
biliuearly interpolated from the values of the bounding slopes (a). These four resulting amounts are 
averaged to get a value for the center of the corner areas (b). This procedure results in four values, 
one at each corner of the intersected patch. The value for the intersection point is then bilinearly 
interpolated from these four corner points (c). A great deal of memory may be saved at the cost of view 
independence if viewing parameters are determined dur-ing the preprocess and out-buffers allocated for 
only those patches and links that are actually utilized in rendering. For the special case of totally 
diffuse surfaces, all the out-buffers for a given patch will contain the same value. In this case more 
memory may be saved by substituting a global out- buffer for each patch, and time may be saved by skipping 
the first interpolation step. 10. ANALYSIS OF RESULTS The algorithm was implemented in C on a single 
processor of an Ardent Titan and on an HP9000 series 300. All time figures are given for the Ardent; 
the HP workstation figures Computer Graphics, Volume 23, Number 3, July 1989 were about 5 times slower. 
Times were measured using the gprof utility in UNIX. All images are 500x500 pixels. Figure 8 demonstrates 
the diffuse reflection performance of the algorithm. The light sources are red, green and blue vertical 
rectangles, which are reflected by a totally diffuse floor. Figure 9 shows the same scene with a specular 
floor. The irregularities of the reflections are the result of the slight jittering of the ray-object 
intersections, while the spread of the reflections is a function of the degree of specularity of the 
floor. Figures 10 and 11 show the obligatory office scene. This scene was rendered at low resolution, 
with 2834 patches and 1201 links at each patch. 1.8 million ray-object intersections were calculated 
in the preprocess, which required 98 seconds for each image. Light sources are the pole lamps, the sky- 
light, the monitor screen, and the tiny lights on the fronts of the machines. In Figure 10, all the surfaces 
are diffuse. Memory for the I-net was 15 Mbytes. The distribution process required 24 seconds, and initialization, 
eyeray calculation, and ren-dering took 44 seconds. Note the light reflecting from the desk diffusing 
onto the wall at low center and onto the chair pedestal. The green from the carpet also diffuses onto 
the lower wall. In Figure 11, the carpet has been given a heavy coat of wax. The I-net took 18.5 Mbytes. 
The distribution process jumped to 97 seconds. Initialization, eyeray calculation, and rendering took 
69 seconds due to the additional time needed for the non-diffuse rendering. Note the reflections from 
the light areas of the back wall on the floor foreground and the reflections from the side of the desk 
on the floor background. The desk front also reflects on the floor, and on the far left the light wall 
reflects in the floor. 11. EVALUATION OF THE ALGORITHM While we have only tested diffuse and specular 
reflectance functions, the method may be used for less ordinary re-flectance functions; one example is 
the reflectance function of an anisotropic surface [7]. Another example is very care- ful treatment of 
reflection where different wavelength bands reflect in slightly different directions. This would be im- 
plemented with a different reflectance matrix for each color channel. The method will also handle transparent 
objects with no modification: instead of a reflectance function, the object's matrix will represent its 
refractance function. Translucent objects such as frosted glass may be modeled by jittering the outgoing 
light direction from the incoming direction by an amount determined by the degree of translucence. This 
algorithm may be used on other than planar ob-jects with no loss of speed in the distribution process, 
since the geometry of the scene has been built into the I-net at  ~  12. FUTURE WORK Although this 
technique correctly models both diffuse and non-diffuse interreflections in a scene (to some degree of 
res- olution), often the patch size may be large enough that ex-tremely specular reflections look poor 
to the eye. Figure 9 shows this well; the floor is almost a mirror, yet the patch size is large enough 
that "holes" appear near the edge of the reflections where adjacent patches reflect significantly dif- 
ferent amounts of light due to discretization. This problem may be fixed in the current implementation 
by reducing the patch size down to sub-pixel resolution, an expensive solu- tion if the scene has much 
surface area. A better approach might be to allow different patch sizes and link densities in different 
parts of the scene. Very small or highly specular objects will be more accurately rendered if they have 
been divided into smaller patches, whereas very small patches might result in much unnecessary computa-tion 
in the case of, for example, a large stretch of blank wall. Sharp shadow boundaries also may require 
smaller patches. Object size ~nd specularity are known at preprocess time, and objects with appropriate 
characteristics may be divided into more patches than they would otherwise. Shadows can be detected by 
noticing when two adjacent links associated with a light-emitting patch are connected to different ob- 
jects; in this case more links are needed between the two original links. Another solution is to use 
ray tracing for the rendering stage of the algorithm. Eyerays are cast into the I-net, and unless the 
ray hits a specular object, the intensity at the ray- patch intersection is evaluated using bilinear 
interpolation of the intensities of the patch and its neighbors. If an eyeray hits a specular object, 
a reflected ray is cast, and a final intensity calculation for that ray performed unless it hits a specular 
surface. This process continues until the reflected ray hits a diffuse object, a light source, is reflected 
out of the scene, or a threshold is reached. Of course, if the environment is completely specular, this 
process degenerates into standard ray tracing, and the I-net is redundant. What separates this from [1] 
and two-pass methods ([12]) is that all the illumination of the environ- ment, including both diffuse 
and nondiffuse interreflection, has been completed at the rendering stage, and the ray trac- ing merely 
provides some additional resolution where it mat- ters most. In fact, one can consider this technique 
to be a form of distributed raytracing, with the I-nets providing a fast way of evaluating the non-specular 
rays. Since most of the rays will be eyerays whose intersections must be calcu- lated in any case, this 
procedure will result in little addi- tional work if much of the scene is diffuse. Since the geometry 
of a scene is built into a data structure, an interesting extension of this work involves animation. 
If for each link an accumulator keeps a total of the amount of light that has passed over the link (out-buffers 
corresponding to the in-buffers mentioned previously) then we can save Computer Graphics, Volume 23, 
Number 3, July 1989 information between frames. When an object moves between two frames, we determine 
the links that are affected and negate the light that has traveled over the links; that is, light that 
previously traveled over the links will be negated and sent down the same links. This "negative light" 
will be run through the reflectance functions at each patch, and the resulting (smaller) amounts of negative 
light are dispatched onto the links. This process continues until convergence. At this point the scene 
is exactly as it would have looked had the affected links never been there. The links are then removed 
and new links are established which reflect the ge- ometry of the updated scene. The same light that 
was negated is now released down these new links and distributed until convergence and the scene is rendered. 
Note that if the vast majority of the links were unaffected by the change, most of the work done for 
the first frame will have been saved. Another area for exploration is the parallelization poten- tial 
of this algorithm. In the preprocess, the incremental ray- object intersection calculations are both 
slope-independent and object-independent; slope-object pairs may be taken from a queue by idle processors. 
In the distribution process, each patch can have its own processor which periodically ex- amines the 
patch's in-buffers and processes any light it finds there and sends the results out over the patch's 
links. Hardware assistance may be useful for the scan-conversion portion of the preprocessing step and 
the rendering, in the manner of [4]. ACKNOWLEDGMENTS Our thanks to Emilia Villarreal, A.T. Campbell, 
and K.R. Subramanlan for many helpful technical discussions and sug- gestions. We would also like to 
thank the folks at the Univer- sity of Texas System Center for High Performance Comput- ing, in particular 
Jesse Driver and Dan Reynolds, for their assistance and the use of their machines. REFERENCES [1] Arvo, 
James, Backward Ray Tracing, Developments in Ray Tracing (SIGGRAPH '86 Course Notes), Vol. 12, August 
1986. [2] Arvo, James and David Kirk, Fast Ray Tracing by Ray Classification, Computer Graphics (SIGGRAPH 
'87 Proceedings), Vol. 21, No. 4, July 1987, pp. 55-64. [3] Cohen, Michael F., Donald P. Greenberg, A 
Radiosity Solution for Complex Environments, Computer Graph- ics (SIGGRAPH '85 Proceedings), Vol. 19, 
No. 3, July 1985, pp. 31-40. [4] Cohen, Michael F., Shenchang Chen, John Wallace, Donald P. Greenberg, 
A Progressive Refinement Ap-proach to Fast Radiosity Image Generation, Computer   ~~SIGG RAPH'89, Boston, 
31 July-4 August, 1989 Graphics (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 1988, pp. 75-84. 
[5] Cook, Robert L., Thomas Porter, Loren Carpenter, Distributed Ray Tracing, Computer Graphics (SIG-GRAPH 
'85 Proceedings), Vol. 19, No. 3, July 1985, pp. 111-120. [6] Immel, David S., Michael F. Cohen, Donald 
P. Green- berg, A Radiosity Method for Non-Diffuse Environ- ments, Computer Graphics (SIGGRAPH '86 Proceed- 
ings), Vol. 20, No. 4, August 1986, pp. 133-142. [7] Kajiya, James T., Anisotropic Reflection Models, 
Com-puter Graphics (SIGGRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 15-21. [8] Kajiya, James 
T., The Rendering Equation, Computer Graphics (SIGGRAPtt '86 Proceedings), Vol. 20, No. 4, August 1986, 
pp. 143-150. [9] Mitchell, Don P., Generating Antialiased Images at Low Sampling Densities, Computer 
Graphics (SIGGRAPtt '87 Proceedings), Vol. 21, No. 4, July 1987, pp. 65-72. [10] Nashita, Tomoyuki and 
Eihachiro Nakamae, Continu- ous Tone Representation of Three-Dimensional Objects Taking Account of Shadows 
and Interreflection, Com-puter Graphics (SIGGRAPH 85 Proceedings), Vol. 19, No. 3, July 1985, pp. 22-30. 
[11] Ohta, Masataka and Mamoru Maekawa, Ray Coherence Theorem and Constant Time Ray Tracing Algorithm, 
Computer Graphics t987 (Proceedings of CG Interna- tional '87), ed. T. L. Kunii, pp. 303-314. [12] Wallace, 
John R., Michael F. Cohen, Donald P. Green- berg, A Two-pass Solution to the Rendering Equa-tion: A Synthesis 
of Ray Tracing and Radiosity Meth- ods, Computer Graphics (SIGGRAPH '87 Proceed-ings), Vol. 21, No. 4, 
July 1987, pp. 311-320. [13] Ward, Gregory J., Frances M. Rubinstein, Robert D. Clear, A Ray Tracing 
Solution for Diffuse Interreflec- tion, Computer Graphics (SIGGRAPH '88 Proceed-ings), Vol. 22, No. 4, 
August 1988, pp. 85-92. [14] Whitted, Turner, Art Improved Illumination Model for Shaded Display, Communications 
of the ACM, Vol. 23, No. 6, June 1980, pp. 343-349.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74343</article_id>
		<sort_key>99</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Near real-time shadow generation using BSP trees]]></title>
		<page_from>99</page_from>
		<page_to>106</page_to>
		<doi_number>10.1145/74333.74343</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74343</url>
		<abstract>
			<par><![CDATA[This paper describes an object-space shadow generation algorithm for static polygonal environments illuminated by movable point light sources. The algorithm can be easily implemented on any graphics system that provides fast polygon scan-conversion and achieves near real-time performance for environments of modest size. It combines elements of two kinds of current shadow generation algorithms: two-pass object-space approaches and shadow volume approaches. For each light source a Binary Space Partitioning (BSP) tree is constructed that represents the shadow volume of the polygons facing it. As each polygon's contribution to a light source's shadow volume is determined, the polygon's shadowed and lit fragments are computed by filtering it down the shadow volume BSP tree. The polygonal scene with its computed shadows can be rendered with any polygon-based visible-surface algorithm. Since the shadow volumes and shadows are computed in object space, they can be used for further analysis of the scene. Pseudocode is provided, along with pictures and timings from an interactive implementation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P210186</person_id>
				<author_profile_id><![CDATA[81100655026]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Norman]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39042315</person_id>
				<author_profile_id><![CDATA[81100427474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A. "Some Techniques for Shading Machine Renderings of Solids." AFIPS SJCC 68, 32, 1968, 37-45.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807403</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Atherton, P., Weiler, K., and Greenberg, D. "Polygon Shadow Generation." Proc. S1GGRAPH '78. In Computer Graphics, 12:3, July 1978, 275-281.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bergeron, P. "A General Version of Crow's Shadow Volumes." IEEE CG&amp;A, 6:9, September 1986, 17-28.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44111</ref_obj_id>
				<ref_obj_pid>44102</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. "Jim Blinn's Corner: Me and My (Fake) Shadow." IEEE CG&amp;A, 8:1, January 1988, 82-86.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brotman, L.S., and Badler, N. "Generating Soft Shadows with a Depth Buffer Algorithm." IEEE CG&amp;A, 4:10, October 1984, 5-12.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chin, N. "Shadow Generation Using BSP Trees." M.S. Thesis, Dept. of Computer Science, Columbia University New York (forthcoming), 1989.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. and Greenberg, D. "The Hemi-Cube: A Radiosity Solution for Complex Environments." Proc. SIGGRAPH ' 85. In Computer Graphics, 19:3, July 1985, 31-40.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Crow, F. "Shadow Algorithms for Computer Graphics." Proc. S{GGRAFH '77. In Computer Graphics, 11:3, July 1977, 242-248.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42460</ref_obj_id>
				<ref_obj_pid>42458</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Foumier, A, and FusselI, D. "On the Power of the Frame Buffer.'" ACM Trans. on Graphics, 7:2, April 1988, 103- 128.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, A., and Naylor, B. "On Visible Surface Generation by A Priori Tree Structures." Prec. SIGGRAPH "80. In Computer Graphics, 14:3, July t980, 124-I33.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801134</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Abram, G., and Grant, E. "Near Real-Time Shaded Display of Rigid Objects." Proc. SIGGRAPH '83. In Computer Graphics, 17:3, July 1983, 65-72.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Goldfeather, J'., Hultquist, J'., Spach, S., Austin, J., Brooks, Jr., F., Eyles, J., and Poulton, J. "Fast Spheres, Shadows, Textures, Transparencies, and image Enhancements in PixeI Planes." Proc. SIGGRAPH '85. In Computer Graphics, 19:3, July 1985, 111-120.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Haines, E. "A Proposal for Standard Graphics Environments." IEEE CG&amp;A, 7:11, November 1987, 3- 5.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15899</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Max, N. "Atmospheric Illumination and Shadows." Proc. SIGGRAPH ' 86, In Computer Graphics, 20:4, August 1986, 117-124.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nishita, T. and Nakamae, E. "Half-Tone Representation of 3-D Objects Illuminated by Area Sources or Polyhedron Sources." IEEE COMPSAC, November 1983, 237-242.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nishita, T., Okamura, I., Nakamae, E., "Shading Models for Point and Linear Light Sources." ACM Trans. on Graphics, 4:2, April 1985, 124-146.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Nishita, T. and Nakamae, E. "'Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection." Proc. SIGGRAPH '85. In Computer Graphics, 19:3, July 1985, 23-30.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Schumacker, R., Brand, B., Gilliland, M., and Sharp, W. "'Study for Applying Computer-Generated Images to Visual Simulation." AFHRL-TR-69-14, USAF Human Resources laboratory, September 1969.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I., Sproull, R., and Schumacker, R. "A Characterization of Ten Hidden-Surface Algorithms." ACM Comp. Surv., 6:1, March 1974, 1-55.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37421</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Thibault, W. and Naylor, B. "Set Operations on Polyhedra Using Binary Space Partitioning Trees." Proc. SIGGRAPH "87. In Computer Graphics, 21:4, July 1987, 153-162.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801127</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Warn, D. "Lighting Controls for Synthetic Images." Proc. SIGGRAPH ' 83. In Computer Graphics, 17:3, July 1983, 13-21.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Weiler, K. and Atherton, P. "Hidden Surface Removal Using Polygon Area Sorting." Proc. SIGGRAPH '77. In Computer Graphics, 11:2, July 1977, 214-222.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807462</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Weiler. K. "Polygon Comparison using a Graph Representation." Proc. SIGGRAPH '80. In Computer Graphics, 14:3, July 1980, 10-18.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. "Art Improved Illumination Model for Shaded Display." CACM, 23:6, June 1980, 343-349.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Williams, L. "Casting Curved Shadows on Curved Surfaces." Proc. SIGGRAPH'78. In Computer Graphics, 12:3, August 1978, 270-274.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Near Real-Time Shadow Generation Using BSP Trees Norman Chin Steven Feiner Department of Computer Science 
Columbia University New York, NY Abstract This paper describes an object-space shadow generation algorithm 
for static polygonal environments illuminated by movable point light sources. The algorithm can be easily 
implemented on any graphics system that provides fast polygon scan-conversion and achieves near real-time 
performance for environments of modest size. It combines elements of two kinds of current shadow generation 
algorithms: two-pass object-space approaches and shadow volume approaches. For each light source a Binary 
Space Partitioning (BSP) tree is constructed that represents the shadow volume of the polygons facing 
it. As each polygon's contribution to a light source's shadow volume is determined, the polygon's shadowed 
and lit fragments are computed by filtering it down the shadow volume BSP tree. The polygonal scene with 
its computed shadows can be rendered with any polygon-based visible-surface algorithm. Since the shadow 
volumes and shadows are computed in object space, they can be used for further analysis of the scene. 
Pseudocode is provided, along with pictures and timings from an interactive implementation. CR Categories 
and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation--Display algorithms; 1.3.5 
[Computer Graphics]: Computational Geometry and Object Modeling---Curve, surface, solid, and object representations; 
1.3.7 [Computer Graphics]: Three- Dimensional Graphics and Realism--Color, shading, shadowing, and texture 
General Terms: Algorithms Additional Keywords and Phrases: shadows, shadow volumes, BSP, binary space 
partitioning Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. &#38;#169;1989 AC M-O-89791- 312-4 / 89 /O07 /O099 $06.75 10027 1 Introduction One classic 
problem in 3D computer graphics is that of shadow generation. Areas in shadow are those that are not 
visible from a light source. The presence of shadows in an image helps viewers to better understand the 
spatial relationships between objects, is vital for applications such as architectural planning, and, 
in general, increases the appearance of reality that a picture provides. Unfortunately, current shadow 
generation algorithms do not run fast enough for interactive performance, except on special hardware 
[12]. Real-time alternatives to full shadow generation typically involve tricks for transforming polygons 
to create polygon shadows that are mapped onto one or more infinite planes [4]. These "fake" shadows 
are not properly clipped to the surfaces that they shadow and are not blocked by intervening surfaces. 
We present a shadow algorithm that achieves interactive performance for polygonal environments of modest 
size when implemented on a graphics system that provides fast polygon scan conversion. After reviewing 
current shadow algorithms, we describe how the new algorithm is related to them. Next, we provide an 
overview of previous work on the BSP tree data structure and algorithms on which the shadow algorithm 
is based, and present a detailed description of how the new algorithm works. 2 Previous Shadow Algorithms 
Crow's classic paper on shadow generation [8] describes three basic approaches: scanline shadow computation, 
the two-pass object-space approach, and shadow volumes. Since Crow's survey appeared, the taxonomy of 
shadow algorithms has been broadened to include three more basic methods: a two-pass z- buffer method 
[25], ray tracing [1, 24], and radiosity approaches [7, 17]. Because the algorithm discussed here combines 
the two-pass object-space approach with the shadow-volume approach, we provide a brief introduction :o 
both. The two-pass object-space approach, developed by Atherton, Weiler, and Greenberg [2] for arbitrary 
polygonal environments, applies two passes of an object-space visible- surface algorithm. The first pass, 
executed from the point of view of the light source, splits polygons into pieces that are visible from 
the light source (lit) and ones that are invisible from the light source (shadowed). This is accomplished 
by  ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 transforming the polygons from the point of view 
of the light source and clipping those polygons that are further away against the clip window of those 
that are closer. Any part of a polygon that lies within a closer polygon, as seen from the light source, 
is in shadow. Lit polygon fragments are transformed back into their original orientation and attached 
to the original polygons as surface detail polygons. A second pass through the visible-surface algorithm 
is then performed from the point of view of the camera. The shadow-volume approach involves the construction 
of a "shadow volume" for each object facing the light source. The shadow volume of an object is that 
volume bounded by the object and a set of invisible "shadow polygons," all of which face outward from 
the volume. A shadow polygon is created by connecting two vectors emanating from the point light source 
with the two vertices of one of the object's edges. The polygon is bounded by the edge, and the pieces 
of the two light source vectors that begin at the edge and continue away frem the light source. The entire 
shadow volume is clipped against the view volume to yield a finite volume. Any part of a polygon within 
another polygon's shadow volume is shadowed. Whether a visible point on a scene polygon is in shadow 
can be determined by computing the relative number of shadow polygons between it and the eyepoint that 
are front- facing or back-facing. A number of shadow aigorithms have been developed that create shadow 
volumes as a preprocessing step before rendering with a scan-line or z-buffer visible- surface algorithm 
[15, 5, 16, 3, 14, 9]. The technique described here combines elements of both these approaches, with 
some important differences [6]. In the two- pass object-space approach, the scene must be wholly within 
the light source's view volume and must be transformed by the light source's perspective transformation. 
While the algorithm described here does clip scene polygons into shadowed and fit parts, it does not 
require that polygons be transformed in the shadow generation process. The basis of the Atherton, Weiler, 
and Greenberg algorithm--the Weiler-Atherton polygon clipper [22] (or its more robust descendant [23])--contains 
a number of implementation subtleties. In contrast, our algorithm uses a simpler clipping algorithm that 
always clips a polygon against a plane, rather than against another polygon. The new algorithm's second 
(visible-surface) pass may be conveniently accomplished in image-space. Alternatively, the algorithm 
may also be used to perform object-space visible-surface determination by placing the light source at 
the eyepoint and returning the list of the non-overlapping lit (visible) polygon fragments that are computed. 
Although the new algorithm generates a shadow volume, the volume does not have to be closed (e.g., by 
clipping it agaiast the view volume) and does not include the actual scene polygons. Shadow-volume algorithms 
typically use the shadow volume to compute shadows in the course of performing visible-surface determination. 
The algorithm described here clips the scene polygons against the shadow volume in object space in the 
spirit of [16], creating the shadow volume as it proceeds. Our algorithm benefits from the divide-and-conquer 
power of the Binary Space Partitioning (BSP) tree [10, 11] and its generalization to modeling polyhedra 
[20]. It is relatively simple and straightforward to implement and efficient enough to provide interactive 
performance. In order to understand how the algorithm works it is necessary to review some BSP fundamentals. 
3 BSP Fundamentals The BSP visible-surface algorithm, developed by Fuchs, Kedem, and Naylor, provides 
an extremely elegant and simple way to determine visibility priority among polygons in a scene independent 
of the eyepoint [10, 11]. A BSPIree represents a recursive partitioning of n-dimensional space, inspired 
by the early work of Schumacker [18, 19]. In 3D, the BSP tree's root is a polygon selected from those 
in the scene. The root polygon is used to partition object space into two half-spaces. One half-space 
contains all remaining polygons in front of the root polygon, relative to its plane equation, and the 
other contains all polygons behind it. Any polygon that lies on both sides of the root polygon's plane 
is split by the plane and its front and back pieces are assigned to the appropriate half- space. One 
polygon each from the root polygon's front and back half-space become its front and back children. Each 
child is recursively used to divide the remaining polygons in its half-space in the same fashion. The 
tree is complete when each leaf node contains only a single polygon whose two half- spaces are empty, 
A modified inorder traversal of this tree provides for O(n) back-to-front ordering from an arbitrary 
viewpoint. Thibault and Naylor [20] introduced the concept of using a BSP tree to represent polyhedral 
solids. They associate an "in" or "out" value with each empty region at the leaves. Assuming that a polyhedron's 
normals point outward, then an "in" region con-esponds to the half-space on a polygon's back side, and 
an "out" region corresponds to the half-space on a polygon's front side. Each internal node defines a 
plane and has a list of polygons embedded in the plane. The "in" and "out" regions form a convex polyhedral 
tessellation of space. Thus, a BSP tree can represent an arbitrary (possibly concave) solid with holes 
as a union of convex "in" regions. Thibault and Naylor show how to produee a BSP tree from a polygonal 
boundary representation of a solid and how to perform Boolean set operations on two boundary representations 
or on a BSP tree and a boundary representation to yield a new BSP tree. 4 The SVBSP Algorithm The Shadow 
Volume BSP (SVBSP) tree is a modified version of the BSP tree used by Thibault and Naylor. Each internal 
node is associated with a "shadow plane" defined by a point light source and an edge of a polygon facing 
the light source. (If a directional light is used, then the shadow plane is defined by the light source's 
direction vector and the polygon edge.) This is one of the "shadow polygons" that Crow refers to as bounding 
the shadow volume [8]. The direction of the plane's normal is used to determine the half-space in which 
an object is located. At the leaves are the "in" and "out" cells indicating whether or not a region is 
interior to the shadow volume. There axe two basic steps to the Shadow Volume BSP algorithm whose execution 
is interleaved for each polygon facing the light source: Determining shadows. The polygon is filtered 
down the SVBSP tree to determine those parts that are shadowed and those that are lit.  Enlarging the 
SVBSP tree. The shadow volume for each of the polygon's lit parts is created and added to the SVBSP tree. 
 The most straightforward approach to checking whether a polygon is in shadow would be to compare it 
with the shadow volumes of all other polygons. Polygons that are further from the light source than the 
polygon being tested cannot, however, cast a shadow on it. Therefore, if we process the polygons in front-to-back 
order relative to the light source, then each polygon would only have to be compared with the shadow 
volumes of those polygons that have already been processed and which are closer to the light source than 
it. The front-to- back ordering can be determined by building a regular BSP tree from the original scene 
polygons and traversing it from the point of view of the light source. Note, that this BSP tree needs 
to be created only once at the outset. It must be recomputed only if the scene's polygons change, not 
if a light source is moved. Rather than check if a polygon is in each of the individual shadow volumes 
of all polygons in front of it, it is more efficient to keep one current merged shadow volume that is 
enlarged by unioning it with the shadow volume of each new polygon as the polygons are processed in front-to-back 
order. Since a polygon is compared only with polygons that are closer to the light than it, there is 
no need to check it against those planes of the merged shadow volume that would have been defined by 
these closer polygons. Therefore, these planes may be left out. (If complete shadow volumes are needed 
for subsequent computation, however, the scene polygon planes must be included.) The resulting merged 
shadow volume is a set of semi-infinite pyramids radiating outward from a single apex at the point light 
source. Figure 1 (a) shows a merged SVBSP shadow volume in 2D for a set of lines seen from a point, while 
Figure 1 (b) shows the shadow volume with the lines (planes in 3D) actually included. While Nishita et 
al. [16] compare the shadow volumes of two convex polyhedra, BSP trees make it relatively easy to compare 
the shadow volume of one polygon with a typically concave union of shadow volumes. The union operation 
is a version of the Boolean set union for polyhedra described in [20]. The determination of which areas 
of a polygon are in shadow is performed by filtering the polygon down the SVBSP tree, (a) (b) Figure 
1 SVBSP volume in 2D. Light Initial state: out Add ab: a bAout in out Add cd: a/N Add ef: a/N b out b 
out in c in c A d out /"--..d g in out in out f out in out Figure 2 Building an SVBSP volume in 2D. 
splitting it whenever it lies in both half-spaces of a node's plane. Fragments that reach the "in" leaves 
are in shadow, while fragments that reach the "out" leaves are lit. Since the SVBSP tree is built incrementally, 
each polygon is compared only with that part of the tree in existence when it is processed. Note that 
it is not necessary to filter any polygon that doesn't face the light source, since it is already entirely 
in shadow. Such polygons include any polygon whose plane embeds the light source. The SVBSP tree must 
be augmented m include each lit fragment's shadow volume. This is accomplished by creating a set of shadow 
planes for the fragment's edges and constructing an SVBSP tree for them, using the algorithm for building 
BSP trees presented in [20]. An SVBSP tree node consists of the shadow plane alone, since the shadow 
plane edge is no longer needed. Figure 2 shows the steps in the construction of an SVBSP tree in 2D. 
Initially, the tree contains a single "out" cell. Lines ab and cd (which would be polygons in 3D) are 
both filtered down the SVBSP tree without any splitting. When line efis filtered down the tree, it is 
split into eg and gfby the shadow plane through b. Line eg is wholly inside an "in" cell (the left branch 
ofb in Figure 2); I01  S'GGRAPH '89, Boston, 31 July-4 August, 1989 therefore its shadow planes are 
not inserted. Since each fragment that reaches an "out" cell is lit, it casts a shadow that might fall 
on fragments added later. Therefore, shadow planes for each edge of a lit polygon fragment are computed 
and the volume that they define is added to the SVBSP tree, replacing the ' 'out" cell in which the fragment 
landed. Figure 3 shows pseudocode for shadowGenerator, the top- level shadow generation loop for the 
scene polygons. Each scene polygon is processed by the recursive procedure delermineShadow (Figure 4), 
which filters the polygon down the SVBSP tree, splits it when necessary, and augments the SVBSP tree 
with the shadow volumes of lit fragments. The pseudocode shown here assumes convex polygons and a single 
light source. 5 Multiple Light Sources The SVBSP algorithm described above can be easily modified to 
generate shadows cast by multiple light sources. This can be accomplished by building a separate SVBSP 
tree for each light source. All processing for one light source is performed before considering the next. 
Therefore, only one SVBSP tr~e need be kept in memory at any time. Polygons are processed in front-to-back 
order with respect to the current light source. Each polygon fragment must keep track of the light sources 
by which it is lit. If a fragment falls into an SVBSP tree "out" cell, it is marked as lit. If it falls 
into an "in" cell, it is marked as shadowed. In both cases, the polygon fragment is attached to the regular 
BSP tree node of the unfragmented polygon with which it is associated. After all the polygons have been 
; shadowGenerator determines shadow fragments that ; are attached to the appropriate node in the BSP 
; tree for subsequent rendering. Alternatively, ; fragments could be written to a file. procedure shadowGenerator 
(PLS, BSPtree) ; Initialize the SVBSP tree to an OUT cell SVBSPtree := OUT ; Process all polygons facing 
light source PLS in ; front-to-back order by BSP tree traversal in O(n). for each scene polygon p, in 
front-to-back order relative to PLS if p is facing PLS ; Determine areas of p that are shadowed. ; BSPnode 
is p's node in BSPtree SVBSPtree := deterrnineShadow (p, SVBSPtree, PLS, BSPnode) else ; p is not facing 
PLS or PLS is in p's plane mark p as shadowed endif  endfor discard SVBSPtree endproc Figure 3 Pseudocode 
for shadowGenerator. ; determineShadow filters p down SVBSPtree to ; determine shadowed fragments and 
reattaches shadowed ; fragments to BSPnode. procedure determineShadow (p, SVBSPnode, PLS, BSPnode) returns 
SVBSPnode ill (SVBSPnode is an IN cell) attach p to BSPnode as a shadowed fragment else it (SVBSPnode 
is an OUT cell) attach p to BSPnode as a lit fragment ; create shadow volume for p and ; append it to 
the SVBSP free shadowPlanes := planes that form the shadow volume of p with PLS SVBSPnode := buildSVBSPtree 
(SVBSPnode, shadowPlanes) else ; Split p by SVBSPnode.plane, creating ; negPart and posPart. splitPolygon 
(p, SVBSPnode.plane, negPart, posPart) if (negPart is not null) SVBSPnode.negNode := determineShadow 
(negPart, SVBSPnode.negNode, PLS, BSPnode) if (posPart is not null) SVBSPnode.posNode := determineShadow 
(posPad, SVBSPnode.posNode, PLS, BSPnode) endif endproc Figure 4 Pseudocode for determineShadow. processed 
in front-to-back order with respect to the current light source, the current SVBSP tree can be discarded 
and a new one initialized. The polygon fragments created by filtering the scene through the previous 
SVBSP tree are filtered through the next SVBSP tree in front-to-back order relative to the new light 
source. Note that the front-to-back order is established by traversing the original BSP tree, which has 
not gained any nodes due to SVBSP polygon fragmentation. Shading calculations can be done after the entire 
scene has been processed for each light source, since each polygon fragment that has passed through the 
last light source's SVBSP tree is now associated with information indicating which light sources illuminate 
it. This is ideal for graphics systems that offer hardware shading support for multiple light sources. 
Alternatively, shading calculations could be performed incrementally as each light source's visibility 
from a fragment is determined. 6 Discussion It is highly desirable to keep an SVBSP tree well-balanced, 
even at the expense of increased size, as is the case when using BSP trees to model polyhedra. This would 
help in unioning and filtering since each polygon must be filtered down to the tree's leaves. Controlling 
tree size is also important, however. One major way to accomplish this is to consider only the silhouette 
edges of the objects of which the polygons are part--a standard shadow algorithm optimization. As well, 
the edges created by splitting a polygon as it is filtered down the i original BSP tree need not be counted, 
Another way to reduce the size of the tree is to create shadow planes only for polygons that the user 
marks as being able to cast shadows. In the special case of one light source, the shadowed fragments 
may be kept and the lit fragments thrown away, rather than keeping both. In this case, a polygon would 
be rendered by drawing its shadowed fragments on top of the original unfragmented polygon, as in [2]. 
There are some cases in which shadows may be known to fall only within a specified region, for example 
when a light source is defined with cones or flaps [21]. In these cases, the scene can first be clipped 
to a view volume containing only the region of interest for further processing. This could also be accomplished 
using a BSP tree. The fragments produced by filtering down one light's SVBSP tree are pipelined to the 
next SVBSP tree. Therefore, in processing multiple point light sources, it better to proceed in the order 
that results in the least amount of polygon fragmentation. One heuristic is to process the light sources 
in increasing order of the number of polygons facing them. Alternatively, the light sources can be processed 
in increasing order of the likelihood with which their position will change. If copies of the intermediate 
fragments produced by each SVBSP tree for each polygon are maintained, then a change in the position 
of the t~ light source will only require sending the fragments from the i-1 th SVBSP tree through the 
remaining trees. Therefore, those light sources whose position will change most often can be computed 
last. Although a light source's SVBSP tree may be augmented with the shadow volumes of the lit polygon 
fragments that reach its leaves, these lit portions have already been fragmented by previous SVBSP trees. 
A smaller tree will result if the SVBSP tree is instead augmented by shadow volumes created from the 
more coherent lit fragments that result from filtering the original scene polygon down the current SVBSP 
tree alone. These more coherent fragments cannot be used for multiple light source rendering since they 
only record the effect of the current light source. They may, however, be used to render the effects 
of that light source by itself. As Thibault and Naylor point out, fragmentation could also be reduced 
if edges were merged when it has been determined that adjacent fragments are both in "in" or "out" regions. 
As a special case, if all fragments of the polygon are lit or all are shadowed, then the fragments may 
be discarded and a copy of the original polygon used, marked accordingly.  7 Implementation This algorithm 
has been implemented in C on a HP 9000 350 TurboSRX graphics workstation under HP-UX using the Starbase 
Graphics Library. To simplify the implementation only convex polygons are handled and polygons are processed 
individually, so no advantage is taken of the connectivity of polygons in polyhedra to identify silhouette 
edges. As well, no distinction is made between the original edges of a polygon and those generated by 
splitting it during creation of the original BSP tree or the SVBSP trees. A bit mask is used to keep 
track of which light sources illuminate each polygon fragment. Our implementation is able to take advantage 
of the hardware shading capabilities provided by the graphics system when rendering the figures. Since 
the original scene is already represented as a BSP tree, the scene may be rendered with either the BSP 
visible-surface algorithm (as done in the figures included here) or the hardware z-buffer. Timings for 
the figures are presented in Table 1 and include only the time needed to generate polygon shadows. Rendering 
time was an additional fraction of a second. Figures 5-8 show a scene illuminated by three light sources, 
shown individually and together. Two versions of the scene are shown in each figure. The first version 
is shaded using the light sources. The second, fragmented version shows how the scene polygons are split 
by both the scene BSP tree and the light source SVBSP trees: shadowed fragments are shown in three levels 
of gey, depending on the number of light sources that illuminate them, while colored fragments are lit 
by all light sources. Figure 9 shows another scene with only the shadowed fragments outlined. Figures 
10 and 11 show additional scenes rendered with the algorithm. It is important to note that care must 
be taken to avoid problems posed by limited floating point precision. For example, as polygon fragments 
get progressively smaller due to fragmentation, the plane equation that would be calculated for each 
will also get progressively more inaccurate. We currently compute a plane equation for each original 
scene polygon and assign it to each polygon fragment generated from it. This not only saves computation, 
but assures that all fragments of the original polygon remain coplanar with each other. A similar approach 
can preserve the collinearity of edges that are formed by splitting an original scene edge.  8 Conclusions 
and Future Work The algorithm that we have presented generates shadows in object space in near real-time 
for a modest number of polygons. It is simple to implement, and because it generates a set of polygons 
as output, it may be used as a preprocess to any polygon-based visible-surface algorithm. Since the input 
and output formats are the same, a pipelined approach for modeling shadows from multiple light sources 
is easy to implement. No restrictions are placed on the locations of the point light sources and viewer, 
no transformations are required before visible-surface determination. Our implementation relies on the 
use of a BSP tree representation of the scene to determine a front-to-back ordering of the scene polygons 
for each light source in time linear in the number of scene polygons. The algorithm may be easily modified 
to support a full shadow volume that includes the scene polygons, in which case the scene BSP tree is 
not necessary. We have recently learned that Naylor (personal communication, 1989) has independently 
proposed a similar algorithm. BSP trees not only present a unified framework for visible- surface determination, 
point classification, and set operations on polyhedra, but, as we have shown, also make possible interactive 
shadow generation on modem graphics workstations. In addition to pursuing some of the performance improvements 
mentioned previously, we are also investigating a natural extension to the SVBSP algorithm to support 
object- space shadow generation for linear and area light sources [6].  :L~,~~SIGGRAPH '89, Boston, 
31 July-4 August, 1989 Figure Secs Lights Input Front-facing Front-facing SVBSP Fragments polygons polygons 
edges nodes 5 .62 1 27 12 49 144 122 6 .68 1 27 15 61 140 108 7 .23 I 27 15 61 31 49 8 5.33 3 27 12,15,15 
49,61,61 144,140,32 475 9 1.96 1 126 61 227 88 537 I0 4.97 2 65 33,32 132,128 210,169 523 I1 7.99 2 
106 49,53 196,212 415,191 813  Tetra256 4.15 1 258 130 390 577 723 Tctra1024 25.44 1 1026 514 1542 2894 
3345 Table 1 Timings for figures. Figures Tetra256 and Tetra1024 (not shown) are recursive tetrahedra 
[13] with 256 and 1024 polygons, respectively, casting shadows on themselves and a ground plane. Acknowledgements 
This work is supported in part by the Defense Advanced Research Projects Agency under Contract N00039-84-C-0165, 
an equipment grant from the Hewlett-Packard Company AI University Grants Program, and the New York State 
Center for Advanced Technology under Contract NYSSTF-CAT(88)-5. The recursive tetrahedron in Figure 9 
was generated using Eric Haines's Standard Procedural Database [13]. References 1. Appel, A. "Some Techniques 
for Shading Machine Renderings of Solids." AFIPS SJCC 68, 32, 1968, 37-45. 2. Atherton, P., Weiler, 
K., and Greenberg, D. "Polygon Shadow Generation." Proc. SIGGRAPH '78. In Computer Graphics, 12:3, July 
1978, 275-281. 3. Bergeron, P. "A General Version of Crow's Shadow Volumes." IEEE CG&#38;A, 6:9, September 
1986, 17-28. 4. Blinn, J. "Jim Blinn's Comer: Me and My (Fake) Shadow." 1EEE CG&#38;A, 8:1, January 
1988, 82-86. 5. Brotman, L.S., and Badler, N. "Generating Soft Shadows with a Depth Buffer Algorithm." 
IEEE CG&#38;A, 4:10, October 1984, 5-12. 6. Chin, N. "Shadow Generation Using BSP Trees." M.S. Thesis, 
Dept. of Computer Science, Columbia University New York (forthcoming), 1989. 7. Cohen, M. and Greenberg, 
D. "The Hemi-Cube: A Radiosity Solution for Complex Environments." Proc. SIGGRAPH '85. In Computer Graphics, 
19:3, July 1985, 31-40. 8. Crow, F. "Shadow Algorithms for Computer Graphics." Proc. SIGGRAPH ' 77. 
In Computer Graphics, 11:3, July 1977, 242-248. 9. Foumier, A. and Fussell, D. "On the Power of the 
Frame Buffer." ACM Trans. on Graphics, 7:2, April 1988, 103- 128. 10. Fuchs, H., Kedem, A., and Naylor, 
B. "On Visible Surface Generation by A Priori Tree Structures." Prrc. SIGGRAPH "80. In Computer Graphics, 
14:3, July 1980, 124-133. 11. Fuchs, H., Abram, G., and Grant, E. "Near Real-Time Shaded Display of 
Rigid Objects." Proc. SIGGRAPH '83. In Computer Graphics, 17:3, July 1983, 65-72. 12. Fuchs, H., Goldfeather, 
J., Hultquist, J., Spach, S., Austin, J., Brooks, Jr., F., Eyles, J., and Poulton, J. "Fast  Spheres, 
Shadows, Textures, Transparencies, and Image Enhancements in Pixel-Planes." Proc. SIGGRAPH '85. In Computer 
Graphics, 19:3, July 1985, 111-120. 13. Haines, E. "A Proposal for Standard Graphics Environments." IEEE 
CG&#38;A, 7:11, November 1987, 3- 5. 14. Max, N. "Atmospheric Illumination and Shadows." Proc. SIGGRAPH 
"86. In Computer Graphics, 20:4, August 1986, 117-124. 15. Nishita, T. and Nakamae, E. "Half-Tone Representation 
of 3-D Objects Illuminated by Area Sources or Polyhedron Sources." IEEE COMPSAC, November 1983, 237-242. 
 16. Nishita, T., Okamura, I., Nakamae, E., "Shading Models for Point and Linear Light Sources." ACM 
Trans. on Graphics, 4:2, April 1985, 124-146. 17. Nishita, T. and Nakamae, E. "Continuous Tone Representation 
of Three-Dimensional Objects Taking Account of Shadows and Interreflection." Proc. SIGGRAPH '85. In Computer 
Graphics, 19:3, July 1985, 23-30. 18. Schumacker, R., Brand, B., Gilliland, M., and Sharp, W. "Study 
for Applying Computer-Generated Images to Visual Simulation." AFHRL-TR-69-14, USAF Human Resources laboratory, 
September 1969. 19. Sutherland, I., Sproull, R., and Schumacker, R. "A Characterization of Ten Hidden-Surface 
Algorithms." ACM Comp. Surv., 6:1, March 1974, 1-55. 20. Thibault, W. and Naylor, B. "Set Operations 
on Polyhedra Using Binary Space Partitioning Trees." Proc. SIGGRAPH '87. In Computer Graphics, 21:4, 
July 1987, 153-162. 21. Warn, D. "Lighting Controls for Synthetic Images." Proc. SIGGRAPH '83. In Computer 
Graphics, 17:3, July 1983, 13-21. 22. Weiler, K. and Atherton, P. "Hidden Surface Removal Using Polygon 
Area Sorting." Proc. SIGGRAPH '77. In Computer Graphics, 11:2, July 1977, 214-222. 23. Weiler, K. "Polygon 
Comparison using a Graph Representation." Proc. SIGGRAPH '80. In Computer Graphics, 14:3, July 1980, 
10-18. 24. Whitted, T. "An Improved Illumination Model for Shaded Display." CACM, 23:6, June 1980, 343-349. 
 25. Williams, L. "Casting Curved Shadows on Curved Surfaces." Proc. S1GGRAPH "78. In Computer Graphics, 
12:3, August 1978, 270-274.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74344</article_id>
		<sort_key>107</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Real-time rendering of trimmed surfaces]]></title>
		<page_from>107</page_from>
		<page_to>116</page_to>
		<doi_number>10.1145/74333.74344</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74344</url>
		<abstract>
			<par><![CDATA[Rational tensor product surfaces, (B&amp;eacute;zier, NURBS, Hermite, polynomial, etc.) are rendered in real-time by uniform faceting. The described methods are modular and can be balanced for optimal implementation on different hardware platforms. Discretization anomalies such as angularities, Mach banding, cracking etc. are avoided by tessellating the surface patches and segmenting the trimming curves based on the view.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.5</cat_node>
				<descriptor>Iterative methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003739</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Nonlinear equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P15780</person_id>
				<author_profile_id><![CDATA[81100334998]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alyn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rockwood]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P163782</person_id>
				<author_profile_id><![CDATA[81332503346]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heaton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35031962</person_id>
				<author_profile_id><![CDATA[81100600964]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Davis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akeley, K. and Jermoluk, T. High-Performance Polygon Rendering. Proceedings of S IGG RAPH '88 (A tl anta, August 1-5, 1988). In Computer Graphics 22, 4 (August 1988), 239-240.]]></ref_text>
				<ref_id>Ake88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378518</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Apgar, B., Bersack, B, and Mammen, A. A Display System for the Stellar Graphics Supercomputer Model GS1000. Proceedings of SIGGRAPH'88 (Atlanta, August 1-5, 1988). In Computer Graphics 22, 4 (August 1988), 255-262.]]></ref_text>
				<ref_id>Apg88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>3651</ref_obj_id>
				<ref_obj_pid>3650</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Boehm, W., Farin, G.E. and Kahmann, J. A Survey of Curve and Surface Methods in CAGD. In Computer Aidid Geometric Design 1 (1984) 1-60.]]></ref_text>
				<ref_id>Boe84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Catmull,E. ASubdivisionAlgorithmforComputerDisplay of Curved Surfaces, doctoral dissertation, Univ. of Utah, Salt Lake City (1974).]]></ref_text>
				<ref_id>Cat74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807440</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Clark, J.H. A Fast Algorithm for Rendering Parametric Surfaces. Supplement, proceedings of SIGGRAPH'79. In Computer Graphics 13, 2 (L979), 289-299.]]></ref_text>
				<ref_id>Cla79</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378468</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Deering, M, et, al. The Triangle Processor and Normal Vector Shader: A VLSI System for High Performance Graphics. Proceedings of SIGGRAPH'88 (Atlanta, August -5, 1988). In Computer Graphics 22,4 (August 1988), 21- 30.]]></ref_text>
				<ref_id>Dee88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[DeRose, A.D. and Holman, T.j. The Triangle: A Multiprocessor Architecture for Fast Curve and Surface Generation. In TR 87-08-07 University of Washington, Seattle, WA (August 1987).]]></ref_text>
				<ref_id>DeR87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Farouki, R. Concise Piecewise-Linear Approximation. Internal IBM Research Document, Yorktown Heights, NY.]]></ref_text>
				<ref_id>Faro</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61954</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Farin, G.E. Curves and Surfaces for Computer Aided Design. Academic Press, Inc., Boston (1988).]]></ref_text>
				<ref_id>Far88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Foley, J. and Van Dam, A. Fundamentals of Interactive Computer Graphics. Addison-Wesley Publishers, 1982.]]></ref_text>
				<ref_id>Fol82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807453</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. On the Rendering of Surfaces. In Computer Graphics 13, 2 (August 1979), 253-259.]]></ref_text>
				<ref_id>For79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Garey, M., Johnson, D.S., Preparata, F. P. and Tarjan, R. E. Triangulating a Simple Polygon. lnlnfo.Proc.Lett. 7,4, (1978), 175-180.]]></ref_text>
				<ref_id>Gar78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378474</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gharachorloo, N. et. aI. Subnanosecond Pixel Rendering with Million Transistor Chips. Proceedings of SIGGRAPH'86 (Atlanta, August 1-5, 1986). In Computer Graphics 22, 4 (August 1988), 41-49,]]></ref_text>
				<ref_id>Gha88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801287</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J.T. Ray Tracing Parametric Patches. Proceedings of SIGGRAPH'82. In Computer Graphics 16, 3 (1982), 245-254.]]></ref_text>
				<ref_id>Kaj82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358815</ref_obj_id>
				<ref_obj_pid>358808</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Lane, J.M., et, al. Scan Line Methods for Displaying Parametrically Defined Surfaces. Comm. In ACM 23, 1 (1980) 23-34.]]></ref_text>
				<ref_id>Lan80</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lane, J. and Riesenfeld, R.F. Bounds On Polynomials. In BIT21 (1981) 112-117.]]></ref_text>
				<ref_id>Lan81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30665</ref_obj_id>
				<ref_obj_pid>30663</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Rockwood, A.P. A Generalized Scanning Technique for Display of Parametrically Defined Surfaces. In IEEE Computer Graphics and its Applications 7, 8 (August t 987), 15-26.]]></ref_text>
				<ref_id>Roc87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. Private communication (1988).]]></ref_text>
				<ref_id>Sed88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. and Wang, X. Rational Hodographs. In CAGD 4 (1987), 333-335.]]></ref_text>
				<ref_id>Sed87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378510</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Shantz, M. and Chang, S. Renderiag Trimmed NURBS with Adaptive Forward Differencing. Proceedings of SIGGRAPH'88 (Atlanta, August I-5, 1988). In Computer Graphics 22, 4 (August 1988), 189-198.]]></ref_text>
				<ref_id>Sha88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37425</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Shantz, M, and Lien, S. Shading B icubic Patche's. Proceedings of SIGGRAPH'87 (Anaheim, July 27-31, 1987). In Computer Graphics 21,4 (July 1987), 189-196.]]></ref_text>
				<ref_id>Sha87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sweeney, A.J. and Barrels, R.H. Ray Tracing Free-Form B-Spline Surfaces. In IEEE Computer Graphics and its Applications 6, 2 (February 1986) 41-49.]]></ref_text>
				<ref_id>Swe86</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Real-Time Rendering of Trimmed Surfaces Alyn Rockwood Kurt Heaton Tom Davis Silicon Graphics Computer 
Systems Mountain View, CA Abstract Rational tensor product surfaces, (B~zier, NURBS, Hermite, polynomial, 
etc.) are rendered in real-time by uniform faceting. The described methods are modular and can be balanced 
for optimal implementation on different hardware plaOrorms. Discretization anomalies such as angularities, 
Math banding, cracking etc. are avoided by tessellating the surface patches and segmenting the trimming 
curves based on the view. CR Categories and Subject Descriptors: G.I,5 [Mathematics of Computing/: RootsofNonlinearEquations-lterativemethods; 
1.3,3 [Computer Graphics]: Picture/Image Generation- Display algorithms; 1.3.5 [Computer Graphics]: Computational 
Geometry and Object Modeling - Curve, surface, solid and object representations. Additional Key Words 
and Phrases: Trimmed NURBS and Bdzier surfaces, faceting, roots of nonlinear equations, view-driven tessellation 
and graphics systems. 1. Introduction State of the art, 3D graphics systems render over one hundred 
thousand transformed, lighted and z-buffered polygons per second tAke88, Apg88]. We expect systems capable 
of rendering over a million polygons to be available in the future/Dee88, Gha88]. These machines accentuate 
the need for methods which facet free-form surfaces efficiently for rendering. The display of surfaces 
such as NURBS (non-uniform rational B-splines), Brzier and polynomial tensor product surfaces is increasingly 
important in CAD/CAM, animation and scientific visualization. This paper describes a modular approach 
to render trimmed surfaces in real-time by a uniform view-driven tessellation per patch. Methods are 
described to avoid anomalies due to the faceting. The following goals served as guidelines. Real-time 
performance: The surfaces must be trimmed, faceted, transformed, lighted, smooth shaded and z-buffered 
in real- time. Permissionto copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. High quality images: Discretization anomalies must be minimized regardless of view or motion. 
Adjacent facets should abut without cracking or overlapping. Portability: The algorithms must easily 
port to different graphics systems. Tasks should be efficiently distributed between CPUs and specialized 
graphics processors. Previous algorithms for rendering surfaces/Cat74, C1a79, For79, Kaj82, Lang0, Roc87, 
Shag8, Sweg6] did not fully satisfy our needs. Some methods such as ray-tracing and point sampling do 
not take advantage of existing polygon rendering abilities. Other methods do not account for trimming 
or they exhibit too many unwanted visual artifacts. Others are algorithmically too complex. A new method 
which satisfies our goals is previewed in Section 2. We discuss in detail each step in Sections 3 through 
9. An implementation on an Silicon Graphics GTX Workstation is disc ussed in Section 10.  2. A Preview 
We refer to object space as the 3D coordinate system in which the surface is defined. Viewing transformations 
map object space to image space, and screen space is the 2D coordinate system defined by projecting image 
space onto the xy-plane. Surfaces are defined as a deformation of a (u,v) axis aligned rectangle into 
object space. The rectangle is calledparameter space. A surface can be trimmed by restricting the domain 
to a subset of parameter space called the trimming region. The trimming region is defined as the area 
enclosed by a set of closed loops of directed curves called trimming curves. A region is monotone with 
respect ~o an axis if any line perpendicular to that axis has a convex intersection with the region. 
We refer to a region which is monotone with respect to both the u and the v axes as uv-monotone. Our 
method converts all surfaces into individual B~zier patches bounded by trimming curves. The patches can 
be processed in any order or in parallel. The trimming region of each patch is subdivided into uv-monotone 
regions. Each uv-monotone region is tessellated in parameter space into a grid of rectangular tiles trimmed 
by triangular coving along curve boundaries as shown in Figure 1. The tile size is computed on a per 
patch basis by transforming the control mesh of the patch into screen space. Step sizes in the u and 
v directions are determined that guarantee the size of the tiles, when projected to screen space, will 
be smaller than a user specified tolerance. &#38;#169;1989 ACM-O-89791-312-4/89/O07/OI07 $00.75 107 
 k~SIGGRAPH '89, Boston, 31 July-4 August, 1989 /\/\ Figure 1. Coving and tiling a trimmed surface 
patch in parameter space. Each trimming curve is segmented in parameter space by evaluating points 
on the curve based on a coving step size which is derived from the tile step size. Triangles are formed 
between points on the curve and points on the grid. This technique allows the interior of each patch 
to be tessellated with different size tiles without cracking between edges of abutting patches. Boundary 
curves of two adjacent patches will generate identical faceting along the edge when rendered, preventing 
cracking. The desire for portability led us to organize the method in a modular, tool kit fashion. We 
decomposed the rendering process into steps with well defined interfaces between them. For many steps 
we developed competing algorithms, each with different strengths and weaknesses depending upon the implementation 
chosen, i.e. hardware, software, microcode, VLSI, etc. This enables us to select the best algorithms 
to distribute processing and balance bandwidth capacities for each system. As a side benefit, code is 
easier to develop and more maintainable. The Method Convert to B6zier: All trimmed surfaces are converted 
into individual B6zier patches with trimming regions defined by closed loops of Bdzier or piecewise linear 
curves. Calculate Step Sizes: Step sizes are calculated in parameter space for each curve and surface 
which guarantee the size of facets in screen space will not exceed a user specified tolerance. Find Extrema: 
All points on the trimming curves where the tangents are parallel to the u or v axes are discovered, 
i.e. the local minima and maxima. Divide into uv-Monotone Regions: Using extrema, the trimming region 
of the patch is divided into uv-monotone regions. Each region is defined by a closed loop of curves. 
Cove and Tile: Using the calculated step sizes, each uv-monotone region is uniformly tessellated into 
a grid of rectangles connected by triangles to points evaluated along the curves. Evaluate Surface Functions: 
The polygons defined in (u,v) parameter space are transformed into facets in object space by evaluating 
their vertices with the surface functions. Surface normals are also calculated. Render Facets: Each facet 
is transformed to screen space, clipped, lighted, smooth shaded and z-buffered using standard 3D graphics 
hardware. The previous steps do not imply a rigid ordering. Specific implementations may change the sequence 
of steps. In the following sections we discuss the steps in detail.  3, Converting To Trimmed Rational 
Bezier Patches Prevalent surfaces in the design of complex sculptured objects are NURBS surfaces or collections 
of B6zier, polynomial or Hermite patches which are pieced together. A trimmed surface is obtained by 
restricting the surface domain to the interior of a region defined by closed loops of directed curves 
joined end to end. These trimming curves may be either rational or polynomial, and may be NURBS, Bdzier 
etc., or in piecewise linear form. We convert all trimmed surfaces into a set of trimmed B6zier patches 
with B~zier or piecewise linear trimming curves. Non-NURBS curves and surfaces can be converted to Bdzier 
form using a change of basis [Far881; NURBS surfaces and curves are converted to B6zier form by knot 
insertion [Boe83] and change of basis. A NURBS domain is divided into a set of rectangles which corresponds 
to domains of B6zier patches. The trimming region must be subdivided along patch boundaries. After conversion, 
the trimmed B6zier patches may be processed in any order or in parallel. We discuss the NURBS to B6zier 
conversion in more detail below. The shape of each NURBS curve or surface depends on a set of control 
points and on knot vectors (non-decreasing arrays of real numbers). For a NURBS curve or surface of order 
n, the special case where the first and last knots have mul!iplicity n and the interior knots have multiplicity 
n- 1 defines a set of Bdzier curves or surfaces. The Boehm knot insertion algorithm [Boe83] inserts a 
knot, then adds and adjusts control points to yield a new description for the same curve or surface. 
For example, to convert a NURBS curve of degree 4 with the knot sequence t 0, 0, 0, 0, 0, 1,2, 2, 3, 
3, 3, 3, 3 } to B6zier form, add five knots with values 1, 1, 1, 2 and 2. The result will be the same 
curve described as three B6zier curve segments. Closely spaced knots can cause numerical problems. We 
allow the user to specify a tolerance ( 1.0E-6 works well); any knots closer than this are coerced to 
the same value before knot insertion. The NURBS trimming region is split into patches as illustrated 
in Figure 2. Trimming curves are split at patch boundaries with additional curves added along patch boundaries 
to restrict the trim region to individual patches. Piecewise linear curves are split by interpolation. 
B6zier curves can either be converted to piecewise linear form and split as above, or the root finder 
algorithm described in Section 5 can be used. ................. r ................... -r ................ 
I i i . . . . . . . . . . . . . i . ......... i i......................... , ................................................. 
i  Figure 2. Splitting a NURBS trimming region into patches. It may be advantageous to further subdivide 
some B6zier patches, especially those with control points having widely differing weights, or those that 
come near the eye in a perspective view. Step size calculations explained in Section 4 can be used to 
determine whether further subdivision is necessary, and if so, the patches can be split [Far88]. Because 
the B~zier form is our internal representation and is also critical to many of our algorithms, we define 
it explicitly. A rational Bdzierpatch of degree n in u and degree m in v is defined by R: [0,1]X[0,1]---~ 
R 3 and n m   ZZw..r..B.~(u)B.m(v) lJ IJ I J R(u,v) = i=o j=o , (1) n m i=0 j=O where w.. are the weights, 
r. are the controlpoints and the B" are the Bemstei~ polynomials [Fa~88]. A trimming curve of degree 
s is defined in the parameter space of a patch by C: [0,1 ]---~ R 2 and S ZwiciB~(') C(t) = i=O , (2) 
S i=0 where ci = (u i , v i ) are the control points; thus C(t) = (u(t), v(t)), u(t) and v(t) are the 
component functions. If the weights in (1) and (2) are equal to 1 then the denominator disappears (becomes 
equal to 1 ) and the patch and curve are just the polynomial B6zier forms. 4. Calculating The Step Sizes 
Based On View For each patch, we compute step sizes based on the viewing transformation to ensure the 
size of facets on the display do not exceed a user specified tolerance. Step sizes for both the u and 
v directions, as well as step sizes for each trimming curve, are computed. In the eauations below the 
control points r.. and weights w.. are t ' IJ tal mapped by viewing and perspective transformations to 
(~. Xi., W.. Y. W.Z.., W. ) in homogeneous coordinates Let R. = (J~.. ~'.. t I ' l] I ij lJ I ' iJ , 
Z: ) be the 3b control point after the perspective division. Let ]'OL be"the user specified tolerance 
in screen coordinates and n 3 be the projection from image space to screen space. Then the number of 
steps in the respective u and v directions (between 0 and 1) which guarantee sample points on the patch 
closer in screen space than TOL are obtained from: n, = n ~2 max( II W y rt 3 R 0 -Wifj rt~ R.l J. 
II )/(TOL*min(W 0. )), for l<i<n-1 and l<j<_m, and (3) n. = m {2 max( Jl W j x3 Rij -Wj .t x3 R~j :~1 
JJ )/(TOL*min(Wij )), forl<i<n and l<j<m-l. The formulas in (3) are modifications of those found in [Roc871 
(We appreciate one of the referees noting the simple extension to include perspective). The step sizes 
in parameter space which result in screen space steps less than TOL are given by STEP=I/n and STEP =1/ 
n v . The number of steps which partitions a trimming curve of degree s into segments that are smaller 
in screen space than STEP, or STEP, respectively, can be obtained from: n, = s max( [1wic i -w i ~1%1 
I[)/(STEP, *min(w)), (4) for l<i<s-1, or  "t~SIGGRAPH '89, Boston, 31 July-4 August, 1989 n, = s max( 
II wic i - w i +1 ci+t II )/(STEP,. *min(wi)), (5) for 1< i <s-l. A trimming curve that is either vertical 
or horizontal should use (4) if it increments in u or (5) if it increments in v. If the curve is a boundary 
curve, i.e. u=0, v=0, u=l or v=l, then STEP u in (4) or STEP in (5) is derived by using only the control 
points of the t" associated boundary edge in (3). Other trimming curves should use the maximum of (4) 
or (5). The curve step sizes in parameter space which result in screen space steps less than TOL are 
given by STEP,= 1/n Note that if the ratio of any two weights is either very large or very small, the 
formulas will result in wasteful oversarnpling (oversampling does not produce visible artifacts, but 
is inefficient). Prior subdivision of the patches or trimming curves can ameliorate this problem. As 
a rule, weights used for conics or quadric surfaces need not deviate much from 1. If all weights are 
1 the formulas simplify to the non-rational form. 5. Finding The Maxima And Minima Of The Trimming Curves 
In this section we present a method for finding the intersections of a curve with lines of constant parameter. 
It is also useful for finding extrema of trimming curves. Local maxima and minima are needed to divide 
the trimming region of the patch into uv-monotone regions. There are several options to do this. Option 
1 : If the trimming curves are in piecewise linear form, then finding the relative extrema is easily 
accomplished by inspection. Option 2: Curves in the B6zier form can be evaluated in increments of STEP 
to form piecewise linear curves. Option 3: A third option is to use a "'root finder" to find the extrema 
directly. It is equivalent to finding points at which the derivatives of the component functions are 
zero, that is in (2) find all t such that u'(t)=0 or v'(t)=O. This option has the advantage that the 
extrema need only be found when the trimming curve is modified. The other options must find the extrema 
based on view. If the trimming curves are non-rational, then the derivative is straightforward [Far88]. 
If they are rational, the non-rational numerator of B6zier curve of the derivative is used. The conversion 
from original control points to derivative form is found in [Sed87]. In all instances, one obtains an 
explicit function f(t) =~f~ B (t) in B6zier form for which roots are desired (note, the fi are scalars). 
We now describe the root finder algorithm. A reasonable estimate of the smallest root off(t) is the value 
of t where the control polygon first crosses the t axis. This is found by testing, in increasing order, 
successive pairs off i for a sign change. If f, is the smallest value such that fi fi + n < 0, then the 
estimate of the root is fi t = + i/n (6) n(fi -fi+l ) If i=0 or i=n-l, then the estimate is exactly 
the same as in Newton's method. This follows since the B6zier control polygon is tangent to the curve 
at t=0 and t= 1 [Far88]. In the other cases, the polygon is typically closer to the curve than the tangent 
and is usually a better estimate of the root. If all control points are above or below the axis, i.e. 
there is no sign change in adjacent pairs, then there are no roots of the polynomial in the interval 
[0,1]. The root finder iterates by subdividing the component curve at the estimate, using the de Casteljau 
formula [Far88]. The de Casteljau formula for evaluating (2) at a point t is given recursively by f i 
j = (l-t) f iJ-l+ t f i~-I 1 (7) forj = 1 ...... ~ and i = 1 ..... s-j, where fi  = f. The value f~ 
is f(t). The formula also subdivides the curve at the point t into two curves which are identical to 
the original curve. The root finder uses the de Casteljau formula to generate two new sets of control 
points for the left and right curves, denoted below by Li's and Ri's respectively. The left curve is 
investigated for roots by checking the signs of adjacent pairs of values. If there is no root, the right 
curve is investigated. Convergence is assumed when the function is less in absofute value than a given 
resolution, RES. To track the root in the original parameter space it is necessary to compute an actual 
root, ActRoot, and a current root, CurRoot. The latter is relative to the current subdivision. Scale 
is the scale factor which relates the current subdivision to the original curve. Our approach resembles 
one described by Lane and Riesenfeld [Lan8 ! ] who begin with binary subdivision and switch to the estimate 
(6) after a root is isolated. We do not use binary subdivision, but perform a special subdivision whenever 
the estimate approaches a given tolerance e. The special subdivision is used because (6) loses precision 
when CurRoot is small. The special guess avoids the precision problem and usually results in a subdivision 
which significantly contracts the curve and allows greater precision for (6). The precision problem is 
particularly pronounced when converging to a multiple root. The root finder algorithm is illustrated 
in Figure 3 and outlined below. Root Finder Algorithm: Finds the smallest value oft in the interval [0,1 
] such that the function f(t) = 0. 1. Initialize: L +-- fi' Ri <'-'- 1 for i = 0,1 ..... n. ActRoot <-- 
CurRoot <--- Scale <-- OldCRoot +-- 1.  2. Test convergence: If IR01 < RES, then output Act Root and 
End.  3. Find crossing: Find k such that L~L~ ~<0 for k = 0,1 ,..,n- 1. If no such k is found then go 
to step 7.  4. Guess: CurRoot ~--k/n + L~/(n( L~ - L~+ = ))" 5. Special guess: If Lk/(n( L~ - Lk+ n 
)) < ~, then CurRoot <---- k/ n+ ~.  6. de Casteljau: Evaluate L~ 's with (7) at CurRoot; new Lk's 
and R~'s are generated. Scale <-- Scale*OldCRoot, ActRoot <--- ActRoot -Scale* ( 1 -Cur Root). Go to 
step 2. 7. Find crossing: Find k such that RkR~+~<0 for k = 0,1 ,,.,n- 1. If no such k is found, then 
output "no root" and End.  8. Guess: CurRoot 6- k/n + R~/(n( R~ - Rk+ i ))" 9. Special guess: If Rk/(n 
( R~ - R~+ I )) < ~, then CurRoot <---- k/n+ s.  10. de Casteljau: Evaluate Rk's with (7) at CurRoot; 
new Lk's and R,'s are generated. Scale ~-- Scale*(l- OldCRoot), ActRoot <--- ActRoot +Scale* CurRoot. 
Go to step 2. 0 4 J 1 2 0 \ 3 a) Beginning curve. b) First iteration. 3 jf / 4 ~ c) Special subdivision. 
 Figure 3. Four iterations of the root finder algorithm. Farouki lFaro] notes two deficiencies with the 
Lane-Riesenfeld algorithm: first, it requires O(d) subdivision stages, each with cost O(n 2) operations 
for convergence to d binary digits; and second, successive subdivision compounds errors in the coefficients 
of the successively generated polynomials. It is better to compute roots with a procedure that refers 
only to the original specification of the polynomial. As noted before, our root finder converges quadratically 
as with Newton's method, i.e. O(log2d). This behavior has been confirmed by experience on curves up to 
degree fifteen; iteration to 32 bits usually occurs in six to seven steps. The occasional special subdivision 
does not change the overall rate of convergence. The only case experienced in which convergence is less 
than quadratic is when the root is highly multiple. The time-critical computation is the evaluation of 
the function and the subdivision of the curve using the de Casteljau algorithm (7). It is an O(n 2) algorithm, 
it can be adapted as an O(n) algorithm by computing each row of the array in parallel. One such implementation 
is described by DeRose [DeR87], for instance. With regard to Farouki's second criticism, the quadratic 
convergence of the routine minimizes the impact of successive subdivisions "slipping" coefficients. Finally, 
after convergence, the original curve can be evaluated at ActRoot to test for any slippage and "purified" 
by another call to the root finder for the appropriate part of the subdivided curve. t3 d) Fourth iteration. 
 The guesses are indicated by horizontal marks. To find the next largest root, the original curve must 
be subdivided at the discovered root (ActRoot) and then the algorithm is applied again in the interval 
[0,1 ] for the righthand curve. Repeated application generates an ascending sequence of real roots. Other 
options: Sederberg, Zundel and de Boor, and Farouki are considering other approaches to the problem of 
finding roots of polynomial curves [Sed88]. 6. Dividing The Trimming Region Into UV-Monotone Regions 
The trimming region of a patch is specified by closed loops of trimming curves. Tiling and coving a patch 
is facilitated if its trimming region is divided into uv-monotone regions with a single closed loop of 
cu~es enclosing each region. In Option I of this section we discuss a simple technique for generating 
uv-monotone regions. The algorithm is simple but inefficient in that it creates regions that could be 
combined. As a second option, we present a more complicated algorithm which generates fewer regions. 
Option 1: Regions bounded on the left and right by monotone curves and on the top and bottom by horizontal 
straight lines are uv-monotone. As shown in Figure 4, a patch can be decomposed into u v- monotone regions 
by casting a line of constant v through curve endpoints and extremal points. The algorithm is outlined 
below.  S,GGRAPH '89, Boston, 31 July-4 August, 1989 1 region a C2 ~ f i 3 l 3.t i, jC1 region d VT~4 
1 11 Figure 4. Atrimming region divided into uv-monotone regions using Option 1. Find intersection points: 
Remove trimming curves parallel to the u axis if they exist. Cast a line of constant v through each extremal 
point and through the first point and last point of each curve. Find all points on all curves intersected 
by these lines using either the Root Finder algorithm described in Section 5 or by interpolation. Create 
lists and sort: Create a list of points for each trimming curve containing the end points, extremal points 
entered twice and intersection points entered twice. Sort each list with respect to parameter t where 
C(t) defines the curve. Divide into curves: Divide each list into a collection of pairs of consecutive 
points. Sort these pairs with respect to v. The two points in a pair are the end points of a curve which 
is monotone in both u and v. Merge sort into regions: Create monotone regions by sorting the first point 
in each pair with the first point in all other pairs with respect to v then u. If the first elements 
of two pairs have the same u value, determine priority by further sorting with respect to u of the second 
element. After sorting, each two consecutive pairs define a region. Reinsert any horizontal curves removed 
in the first step. Close each region by inserting additional horizontal curves on the top and bottom 
of each region as required. Note that region b and region d can be combined into a single uv-monotone 
region. These regions can be discovered and combined to reduce overhead if desired. However, the cost 
of creating extra regions may be significant for more complex examples as shown in Figure 5. Option 1 
generates nineteen regions from this patch; below we describe an improved algorithm that generates only 
seven regions. 112 C B H Figure 5. A trimming region divided in uv-monotone regions using Option 2. 
Option 2: We refer to a point on a trimming curve as v-critical if it is a local maximum and the trimming 
region lies above it or if it is a local minimum and the trimming region lies below. The u-critical points 
are similarly defined. If the region is split vertically at each v- critical point and horizontally at 
the u-critical points, the resulting pieces will be uv-monotone. In Figure 5, points D, I, M, and K are 
v-critical and points F, L, and J are u-critical. To create uv-monotone regions, first we split the trimming 
region vertically through D, I, M and K. Then we split the resulting trimming regions horizontally through 
F, L and J. The lines which split the trimming region only extended to the nearest arc rather than across 
the entire patch. The algorithm is outlined below. Find v-critical points: Find the subset of end points 
and extremal points that are v-critical. Divide vertically: Through each v-critical point, extend a line 
up or down through the interior of the region until it meets another trimming boundary. Split the region 
along this segment. Find u-critical points: Find the u-critical points in each region generated by the 
previous step. Divide horizontally: Through each u-critical point, extend a line left or right through 
the interior of the region until it meets another trimming boundary. Split the region along this segment. 
 Both options discussed above can be implemented using the same data structure for input and output. 
We use a list of circular lists of curve segments. Regions are divided and curves inserted in the same 
fashion that trimming regions are divided at patch boundaries in Section 3, preserving the data structure. 
The final result is a list of circular lists of curves, where each circular list surrounds a uv-monotone 
region. Care must be taken in dividing curves to ensure that the new curves segment into exactly the 
same set of points or cracking may result. Once generated, the uv-monotone regions are independent of 
each other and can be processed in any order or in parallel. 7. Covering And Tiling: Creating Uniform 
Tessellations That Don't Crack Coving and tiling tessellates each uv-monotone region into three-or four-sided 
polygons that are defined in (u,v) parameter space and that have edges small enough to satisfy the screen 
space tolerance. This is done by superimposing a lattice of points a distance STEP and STEP apart over 
the uv-monotone region as shown in Figure 6. Trimming curves are segmented into points by evaluating 
them in increments of STEP. All lattice points that lie within the region and all points on the curves 
are interconnected to form a mesh of polygons. Two algorithms for generating this mesh of polygons are 
discussed in this section. The first algorithm is general purpose and is guaranteed to handle any uv-monotone 
region. The second is more restricted but is faster. \ ~ v step size  'T i "u u step size Figure 6. 
A lattice of points is superimposed on the uv-monotone trimming region. Option 1: We refer to horizontal 
lines through lattice points as v-lattice lines and similar vertical lines as u-lattice lines. First, 
the uv-monotone regions are divided along v-lattice lines into horizontal slices STEP v high as outlined 
below. Tessellate trimming curves: If not done previously, segment each trimming curve by evaluating 
iteratively by STEP. Subdivide slice boundaries: Intersect v lattice lines with trimming curves by interpolating 
between two evaluated points. Output a degenerate coving triangle whose vertices are the two evaluated 
points and the interpolant to avoid cracking. Create slices: Create each slice by grouping the interpolated 
points, the evaluated points on the curve between them and any points between the curves on the v-lattice 
lines. Monotone curves on the left and right edge and horizontal curves top and bottom define each slice. 
Each horizontal slice is then decomposed into triangles using a general purpose monotone polygon triangulation 
algorithm such as one described in [Gar78]. Triangulate slices: Each slice is triangulated using a monotone 
polygon triangulation algorithm, Option 2: A more efficient algorithm exists for any horizontal slice 
that contains two points that lie on a u-lattice line. The algorithm chops out the rectangular center 
section of the slice, generating a strip of tiles. The two regions remaining on the left and right ends 
are triangulated. An algorithm for triangulating end regions is described below. End Regions are bounded 
by a u-lattice line, a v-lattice line and points of a monotone curve. The curve may be increasing or 
decreasing and may be to the left or right of the u-lattice line. Without loss of generality, assume 
the end region is oriented as shown in Figure 7. Points B, C, D and the points between C and D are lattice 
points. Points A, E and the points between them lie on a trimming curve. Assume the points are organized 
into two lists: TopPoint = { B, A- E} and BottomPoint = {C-D, E}. Next(TopPoint) and Next(BottomPoint) 
refers to the next point in the top or bottom list respectively. CoveTriangle(p I, p2, p3) means that 
the points p 1, p2, and p3 are output as the vertices of a coving triangle. Ifp is a point, p.u is the 
u coordinate of p. The coving algorithm follows: 1. Top = B; Bottom = C; NextTop = Next(TopPoint); NextBottom 
= Next(BottomPoint). 2, If NextTop = E and NextBottom = E, then CoveTriangle(Top, Bottom, E) and End. 
3. If NextTop.u > NextBottom.u then go to 7. 4. CoveTriangle(Top, Bottom, NextTop) 5. If NextTop = 
E then go to 2. 6. Top = NextTop; NextTop = Next(TopPoint); go to 2.  7. CoveTriangle(Top, Bottom, 
NextBottom). 8. If NextBottom = E then go to 2. 9. Bottom = NextBottom; NextBottom = Next(Bottom); go 
to 2.  B A ~E C D Figure 7. A example of coving an end region of a horizontal slice. The complete algorithm 
for coving and tiling a uv-monotone regions using Option 2 is summarized below: Divide into slices: 
Dividing into horizontal slices as described in the Option 1 above.  Test for lattice points: Check 
the slice to see if it has two points which lie on a u-lattice line. If not, use the general purpose 
triangulation algorithm and end.   :L~SIGGRAPH '89, Boston, 31 July-4 August, 1989 Generate tiles: 
Output lattice points within the interior of the horizontal slice as a strip of rectangles. Cove left 
end: Using the coving algorithm described above, generate a strip of three-side polygons along the left 
trimming curve. Cove right end: Using the coving algorithm described above, generate a strip of three-side 
polygons along the right trimming curve. 8. Generating Surface Facets From Parameter Space Polygons 
To generate facets, object space coordinates (x,y,z) and normal vectors (n,n,n) are calculated from (u,v)coordinates 
of the polygons. The (x,y,z) coordinates are calculated using a polynomial expansion of the B6zier coefficients, 
or using the de Casteljau algorithm. We compute the normal vector by evaluating the partial derivatives 
of the surface in the u and v directions, taking their cross product and normalizing the result. A less 
expensive way to generate surface normals is first to approximate the surface normals with another patch. 
This patch interpolates to given analytic surface normals on the original patch. Second, the "surface 
normals" patch is evaluated exactly as the original patch. This approach requires less computation than 
forming the cross product from partial derivatives and then normalizing, but it assumes the original 
patch has no high frequency components. See [Roc87, Sha87] for more details. 9. Rendering Facets By Traditional 
Techniques Option 1: The facets are transformed, lighted, smooth shaded and z-buffered using standard 
3D polygon rendering techniques [Fo182]. Option 2: A more efficient, but less general way is to derive 
the facets from the transformed Bdzier control mesh instead of transfornling each vertex of each facet. 
The facets are then lighted, smooth shaded and z-buffered using standard techniques. However, this technique 
requires the surface normals patch approach since the analytic surface normals would otherwise be transformed. 
Furthermore, distance related local lighting is excluded with this scheme. The important attribute of 
Option 1 is that the facets can be treated as standard 3D polygon primitives by the graphics systems. 
No special handling is required. There is a significant computational savings in Option 2 in transforming 
the control mesh. However, this benefit may not be as significant if the target graphic system has large 
rendering capacities in hardware. 10. Implementation Details The method was successfully implemented 
on a Silicon Graphics IRIS-4D GTX Workstation. Its architecture comprises multiple RISe-based CPU's interfaced 
to a high-performance Graphics Subsystem [Ake881. The Graphics Subsystem contains five identical 20 Mflop 
processors (Geometry Engines ) which are microcodable. A user interface was added to the IRIS Graphics 
Library TM that accepts either NUR BS or Bdzier surfaces as primitives. The first five steps of the method 
were programmed in C code to execute on the host CPUs. The algorithmically simple but computationally 
intensive step of surface evaluation was programmed in microcode and executes on the first Geometry Engine. 
The microcode evaluates either a single coving triangle, a mesh of coving triangles or a horizontal strip 
of tiles. Facets are rendered the same as other 3D polygons by the Graphics Subsystem. We discovered 
many opportunities to simplify the implementation initially and then improve performance later. For example, 
the initial implementation used only the general purpose polygon triangulation algorithm [Gar78] and 
simple microcode that evaluated triangles individually. Adding algorithms to generate and evaluate strips 
of tiles improved performance substantially. Our current implementation immediately discretizes the trimming 
curves and saves the points for use later in coving and tiling. With a complete list of points, finding 
the local maxima and minima and subdivision into monotone curves becomes trivial. However, since curve 
tessellation is view dependent, monotone subdivision must be performed each frame. A Root Finder is being 
added so that monotone subdivision is performed only when a trimming curve is changed. It is difficult 
to give meaningful performance values since suitable benchmarks do not exist. Measures such as "surfaces 
per second" are of little use. The shape of the trimming regions and the perspective viewing parameters 
can have a substantial effect on the ratio of triangles to rectangles in our method. However, it is not 
too unreasonable to consider each rectangle to be two triangles and measure triangles per second. We 
included in our measurement all steps of the method including the conversion from NURBS to internal B6zier 
form, conversion to monotone regions, coving, tiling and the rendering of the facets. Using this measure, 
moderately to extremely complicated trimmed surfaces as shown in Figures 8 and 9 render at about 15,000 
triangles per second. Simply trimmed and untrimmed NURB S surfaces as in Figure 10 render up to 60,000 
triangles per second. We have observed that coving and tiling is the current bottleneck and is therefore 
a candidate for microcode in the future. Also, we have yet to take advantage of the multiple CPU's. As 
a demonstration of portability, the IRIS-4D GTX implementation was ported to a Silicon Graphics Personal 
IRIS TM workstation. Although the internal architecture of this machine is significantly different, the 
port was successfully completed in only two days.  11. Conclusion We have presented a method that renders 
trimmed rational tensor product surfaces by view-driven faceting without anomalies. Alternative algorithms 
were presented for many of the steps to show a method that can be tailored to satisfy the requirements 
of different graphics sy stems. A real-time implementation on a high-performance workstation was described. 
One feature of the method is that users can readily choose between image quality and rendering speed 
by specifying a tolerance for on-screen facet size. The speed of the method is due mainly to the fact 
that we adapt uniform faceting on a per patch basis. The modular architecture of the method makes it 
quick to implement, portable, maintainable and amenable to incremental improvements. A notable feature 
is that trimmed surfaces are decomposed into intermediate forms that are ideally suited for implementation 
with parallel architectures. With judicious use of hardware, future implementations are feasible which 
fully utilize the rendering capacities of modem graphics systems.   ,x~~SIGGRAPH '89, Boston, 31 July-4 
August, 1989 Acknowledgements Special thanks to Derrick Bums, Rosemary Chang, Carl Korobkin, Reuel Nash, 
Ann Sydeman and Vince Uttley for their contributions to the design of the method and its implementation. 
References lAke88] Akeley, K. and Jermoluk, T. High-Performance Polygon Rendering. Proceedings of SIGGRAPH'88 
(Atlanta, August 1-5, 1988). In Computer Graphics 22, 4 (August 1988), 239-240. [Apg88] Apgar, B., Bersack, 
B, and Mammen, A. A Display System for the Stellar Graphics Supercomputer Model GS 1000. Proceedings 
of SIGGRAPH'88 (Atlanta, August 1-5, 1988). In Computer Graphics 22, 4 (August 1988), 255-262. [Boe84] 
Boehm, W., Farin, G.E. and Kahmann, J. A Survey of Curve and Surface Methods in CAGD. In ComputerAidid 
Geometric Design 1 (1984) 1-60. [Cat74] Catmull, E. A Subdivision Algorithm for Computer Display of Curved 
Surfaces, doctoral dissertation, Univ. of Utah, Salt Lake City (1974). [C1a79] Clark, J.H. A Fast Algorithm 
for Rendering Parametric Surfaces. Supplement, proceedings of SIGGRAPH'79. In Computer Graphics l 3, 
2 (1979), 289-299. [Dee88] Deering, M, et, al. The Triangle Processor and Normal Vector Shader: A VLSI 
System for High Performance Graphics. Proceedings of SIGGRAPH'88 (Atlanta, August 1-5, 1988). InComputerGraphics22,4(August 
1988),21- 30. [DeR87] DeRose, A.D. and Holman, T.J. The Triangle: A Multiprocessor Architecture for 
Fast Curve and Surface Generation. In TR 87-08-07 University of Washington, SeattLe, WA (August 1987). 
[Faro] Farouki, R. Concise Piecewise-Linear Approximation. Internal IBM Research Document, Yorktown Heights, 
NY. [Far88] Farin, G.E. Curves and Surfaces for Computer Aided Design. Academic Press, Inc., Boston 
(1988). [Fo182] Foley, J. and Van Dam, A. Fundamentals of Interactive Computer Graphics. Addison-Wesley 
Publishers, 1982. [For79] Forrest, A.R. On the Rendering of Surfaces. In Computer Graphics 13, 2 (August 
1979), 253-259. We also thank Mark Compton, Paul Haeberli and Monica Schulze for their help in preparing 
the camera-ready copy and the color images. [Gar78] Garey, M., Johnson, D.S., Preparata, F. P. and Tarjan, 
R. E. Triangulating a Simple Polygon. In lnfb. Proc. Lett. 7,4, (1978), 175-180. [Gha88] Gharachorloo, 
N. et. al. Subnanosecond Pixel Rendering with Million Transistor Chips. Proceedings of SIGGRAPH'86 (Atlanta, 
August 1-5, 1986). In Computer Graphics 22, 4 (August 1988), 41-49, [Kaj82] Kajiya, J.T. Ray Tracing 
Parametric Patches. Proceedings of SIGGRAPH'82. In Computer Graphics 16, 3 (1982), 245-254. [Lan80] Lane, 
J.M., et, al. Scan Line Methods for Displaying Parametrically Defined Surfaces. Comm. In ACM 23, 1 (1980) 
23-34. [Lan81 ] Lane, J. and Riesenfeld, R.F. Bounds On Polynomials. In BIT21 (1981) 112-117. [Roc87] 
Rockwood, A.P. A Generalized Scanning Technique for Display of Parametrically Defined Surfaces. In IEEE 
Computer Graphics and its Applications 7, 8 (August t987), 15-26. [Sed881 Sederberg, T. Private communication 
(1988). [Sed87] Sederberg, T. and Wang, X. Rational Hodographs. In CAGD 4 (1987), 333-335. [Sha881 Shantz, 
M. and Chang, S. RenderiNg Trimmed NURBS with Adaptive Forward Differencing. Proceedings of SIGGRAPH'88 
(Atlanta, August 1-5, 1988). In Computer Graphics 22, 4 (August 1988), 189-198. [Sha87] Shantz, M, and 
Lien, S. Shading Bicubic Patche's. Proceedings of SIGGRAPH'87 (Anaheim, July 27-31, 1987). In Computer 
Graphics 21,4 (July 1987), 189-196. [Swe86] Sweeney, A.J. and Barrels, R.H. Ray Tracing Free-Form B-Spline 
Surfaces. In 1EEE Computer Graphics and its Applications 6, 2 (February 1986) 41-49. Geometry Engine 
is a registered trademark of Silicon Graphics Computer Systems, Inc. Graphic" Library and Personal IRIS 
are trademarks of Silicon Graphics Computer Systems, Inc'.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74345</article_id>
		<sort_key>117</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Accurate color reproduction for computer graphics applications]]></title>
		<page_from>117</page_from>
		<page_to>126</page_to>
		<doi_number>10.1145/74333.74345</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74345</url>
		<abstract>
			<par><![CDATA[A method is presented for accurate color reproduction among a wide variety of display devices. The method is very general, in that it may be applied to virtually any color display device. Its generality has been demonstrated by application to color monitors, film recorders, electronic pre-press systems and color hardcopy devices. The algorithm has been used to accurately translate between device dependent and device independent color specifications and to translate from one device dependent color specification to another.The method separates the color reproduction process into two distinct components: <i>device characterization</i>, which accounts for the colorimetric properties of each class of display device, and <i>device calibration</i>, which accounts for local variations from one instance of a device to another.A <i>companded</i> RGB color space is introduced, which is used with trivariate parametric polynomial volumes (i.e. hyperpatches) to perform accurate color transformations.A color separation algorithm is presented which converts companded RGB to and from the subtractive printing colors (cyan, magenta, yellow, black) using gray component replacement.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Device independence**</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P33561</person_id>
				<author_profile_id><![CDATA[81100583113]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Lindbloom]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Crosfield Dicomed, Inc., Minneapolis, MN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>576984</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Conrac Corporation, Raster Graphics Handbook, Second Edition, Van Nostrand Reinhold Company, 1985.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Texas Instruments, Digital Signal Processing Applications with the TMS820 Family, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Forman S. Acton, Numerical Methods That Work, Harper &amp; Row, 1970.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807417</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Edwin Catmull, "A Tutorial on Compensation Tables," Computer Graphics, vol. 13, no. 2, Association for Computing Machinery, August 1979.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Michael F. Cohen and Donald P. Greenberg, "The Hemi-cube, A Radiosity Solution for Complex Environments," Computer Graphics, vol. 19, no. 3, Association for Computing Machinery, July 1985.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, Thomas Porter, and Lores Carpenter, "Distributed Ray Tracing," Computer Graphics, vol. 18, no. 3, Association for Computing Machinery, July 1984.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Tom N. Cornsweet, Visual Perception, Academic Press, 1970.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[James D. Foley and Andries Van Dam, Fundamentals of Interactive Computer Graphics, Addison Wesley Publishing Company, 1982.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Roy A. Hall and Donald P. Greenberg, "A Testbed for Realistic Image Synthesis," Computer Graphics and Applications, vol. 3, no. 8, IEEE Computer Society, November 1983.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801294</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Paul Heckbert, "Color Image Quantization for Frame Buffer Display," Computer Graphics~ vol. 16~ no. 3, Association for Computing Machinery, July 1982.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801287</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya, "Ray Tracing Parametric Patches," Computer Graphics, vol. 16, no. 3, Association for Computing Machinery, July 1982.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Irving Pobboravsky and Milton Pearson, "Computation of Dot Areas Required to Match A Colorimetrically Specified Color Using the Modified Neugebauer Equations," 150, Graphic Arts Research Center, Rochester Institute of Technology.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Anthony Ralston and Philip Rabiaowitz, A First Course in Numerical Analysisp McGraw Hill Book Company, 1978.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617433</ref_obj_id>
				<ref_obj_pid>616001</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Philip K. Robertson, "Visualizing Color Gamuts: A User Interface for the Effective Use of Perceptual Color Spaces in Data Displays," Computer Graphics and Applications, vol. 8, no. 5, IEEE Computer Society, Sew tember 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Miles F. Southworth, Color Separation Techniques, Second Edition, Graphic Arts Publishing, 1979.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>48045</ref_obj_id>
				<ref_obj_pid>46165</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Maureen C. Stone, William B. Cowan, and John C. Beatty, "Color Gamut Mapping and the Printing of Digital Color Images," A CM Transactions on Graphics, vol. 7, no. 3, Association for Computing Machinery, October 1988.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325233</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Daniel L. Toth, "On Ray Tracing Parametric Surfaces," Computer Graphics, vol. 19, no. 3, Association for Computing Machinery, July 1985.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Turner Whitted, "An Improved Illumination Model for Shaded Display," Communications of the ACM, vol. 23, no. 6, Association for Computing Machinery, June 1980.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gunter Wyszecki and Deane B. Judd, Color in Business, S~ience and Industry, John Wiley gc Sons, 1975.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gunter Wyszecki and W. S. Stiles, Color Science, Concepts and Methods, Quantitative Data and Formulae, Second Edition, John Wiley ~ Sons, 1982.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. A. C. Yule, Principles of Color Reproduction, John Wiley &amp; Sons, 1967.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 Accurate Color Reproduction for Computer Graphics 
Applications Bruce J. Lindbloom Crosfield Dicomed, Inc. Minneapolis, MN Abstract A method is presented 
for accurate color reproduction among a wide variety of display devices. The method is very general, 
in that it may be applied to virtually any color display device. Its generality has been demonstrated 
by application to color monitors, fihn recorders, electronic pre-press systems and color hardcopy devices. 
The algorithm has been used to accurately translate between device dependent and device independent color 
specifications and to translate from one device dependent color specification to another. The method 
separates the color reproduction process into two distinct com- ponents: device characterization, which 
accounts for the colorimetric proper- ties of each class of display device, and device calibration, which 
accounts for local variations from one instance of a device to another. A companded RGB color space is 
introduced, which is used with trivariate parametric polynomial volumes (i.e. hyperpatches) to perform 
accurate color transformations. A color separation algorithm is presented which converts companded RGB 
to and from the subtractive printing colors (cyan, magenta, yellow, black) using gray component replacement. 
CR Categories and Subject Descriptors: 1.3.6 [Computer Graphics] Methodol- ogy and Techniques -Device 
independence, 1.3.7 [Computer Graphics] Three-Dimensional Graphics and Realism -Color, shading, shadowing 
and texture. General Terms: Algorithms. Additional Key Words and Phrases: color correction, color reproduction, 
color separation, companding 1. Introduction Color is becoming increasingly common and available on all 
computer graph- ics systems. Once considered a luxury, today even low end PCs are equipped with color 
and are serving very sophisticated color applications. Why is accurate color reproduction important? 
There are many reasons why color fidelity is of interest to designers and users of systems employing 
computer graphics as well as researchers in the field. Observation of industry trends indicates a continuing 
migration toward higher quality, photorealistic imagery. Sophisticated rendering techniques such as radiosity[5] 
and ray tracing[18, 9, 6] approximate physical and optical properties with increasing accuracy. However, 
these images only exist in digi- tal form within the computer until they take on visual meaning by way 
of display on a display device. This display process must approximate the intended colors with the same 
degree of accuracy used in the rendering pro- tesS. Many commercial applications of computer graphics 
require consistent and accurate display of color among multiple display devices. Clients often proof 
a design based on a facsimile of the final output. Most users of computer graphics systems are aware 
of the oftentimes gross disparities between hard- copy images and screen images. Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct cornmereial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. The interest in accurate 
color reproduction is further fueled by the plethora of high quality color output devices employing a 
wide variety of technologies such as dye sublimation, ink jet and thermal transfer. In order to take 
advantage of these rapid developments, a method is needed which allows accurate color reproduction on 
new devices without requiring detailed knowledge and expertise of the physics and chemistry of each new 
display technology. Finally, there is a growing interest in the integration of device independent color 
standards with graphics exchange standards, two examples being the ISO 8613 Colour Addendum and the ANSI 
IT8. Methods are needed to accu- rately translate between these color standards and display devices. 
The algorithms presented here were initially developed in 1984 and were incorporated into successful 
commercial applications shortly thereafter. They have proven to be very useful in meeting the needs described 
above. 2. Design Goals For a color reproduction algorithm to be general purpose and useful, it should 
possess certain characteristics set forth as design goals. The following list describes some of the more 
important goals: a) It must be able to convert from a device independent color specification to a device 
dependent color specification. b) It must be reversible, allowing the conversion from a device dependent 
color specification to a device independent color specification. c) The processor and memory requirements 
must be low enough for imple- mentation in commercial equipment in a high volume, production environment, 
using general purpose computers including PCs. d) Colors which lie outside of the color gamut of a device 
must be handled gracefully and meaningfully. e) A single method must be applicable to virtually any type 
of color display device. The operation of this conversion function must be controlled by a relatively 
small set of characterization parameters for each class of dev- ice. f) It must be applicable to non-RCB 
color systems such as print (cyan, magenta, yellow and black printers). g) It must be applicable to color 
mapped as well as full color raster applica- tions. h) It must be visually continuous in the sense that 
no artificial visual discontinuities or anomalies are introduced. i) It must work with continuous tone 
devices as well as devices that simu- late continuous tones by screening or dithering. j) It must correctly 
compensate for imperfect color producing agents, for example 'dye crosstalk' in photographic films caused 
by unwanted spec- tral absorption of non-ideal dyes in the processed emulsion and 'addi-tivity failure'[21] 
that occurs in printing inks. 3. Constraints Any color reproduction system is faced with many constraints, 
over which it has little or no control. Among these are: a) The human visual system is extremely complex. 
Many volumes have been written on this subject alone, and suffice it to say that phenomena such as chromatic 
adaptation, size and location of visual field, color defective vision, simultaneous contrast and many, 
many others contri-bute to the enormous complexity of color perception[7]. b) Display devices require 
periodic calibration to account for long term drift. In practice, the responsibility of timely and methodical 
calibration is often neglected. &#38;#169;1989 ACM-0-89791-312-4/89/007/0117 $00.75 117   :~.~j~~SIGG 
RAPH '89, Boston, 31 July-4 August, 1989 Reason 3: Companding provides a useful convergence criterion. 
As we shall see in 6.2, the approximate uniform nature of companded RGB space provides a convenient 
error measure for the termination of the numeri- cal iteration loop in the (L*, u*, v*) to RGB conversion 
process. 5.3. Device Color Coordinates The third and final color space is that of the physical display 
device. It is dependent, not only on the class of device, but also on each instance of each class. This 
is the lowest level of color binding. For a film recorder it may be 8 to 12 bit exposure codes for RGB; 
for an electronic pre-press system it may be dot percentages of the four process color inks; for a thermal 
transfer printer it may simply be ones and zeros, indicating print or no-print. 6. Algorithm Description 
 Figure 5 is an overview of the color conversion process. The three color sys- tems described in 5 
are depicted by the three boxes. The arrows indicate the algorithms used to convert between color systems. 
Colors are completely device independent on the far left and become progressively more device dependent 
toward the right. Device I Cla.ss Binding % n s t .... Bindin~ Independent DeviceInstance Color Ctv, 
sS Unb~ndinfl s%~Rce Uabindi (L*, u*, v*) i ClassIndependent, ClassDependent. ClassDependent, Instancelndependent 
Instancelndependent Instance Dependent Color Color Color Figure 5: Device dependent binding levels 
Class Conversions Instance Conversions r Instance #1 Device Instance ~2 Cla~s 'A' (r, s, b) Instance 
~3 Instance ~1 Device Device Independent Instance #2 Class'n' Color (~, ~, b) Instance #1 Device Class 
'C' (L*, u,, v*) (r, ~, b) v w In an environment with multiple display devices, transformations occur 
as illustrated in Figure 6. In this diagram, the double arrow pairs of Figure 5 are replaced with single, 
double headed arrows for simplification purposes. As shown, the conversion from one device class to another 
involves the device independent (L*, u*, v*) color space as a temporary intermediate, through which the 
exchange is made. Class Independent, Cl~s Dependent, Class Dependent, Instance Independent Instance 
Independent Instance Dependent Color Color Color Figure fl: Color conversion among multiple devices 120 
 The color transformations indieated by the four arrows in Figure 5 will each be described in 6.1 through 
fi.4. 6.1. RGB to L*, u*, v* Transformation The transformation between companded RGB and (L*, u*, v*) 
is done using trivariate parametric hyperpatches. The degree of the polynomials is arbitrary, with higher 
degrees providing more accurate color matching at the expense of a longer computation time and a greater 
effort during the charac- terization process, in the following discussion, the tricubic case will be 
used as an example, with the hope that application to other degrees will be obvi- ous. Experience has 
shown that there is little gained in going beyond degree three, and for many applications triquadratic 
or even tr]lincar hyperpatches are adequate. The process of transforming companded RGB space into (L*, 
u*, v*) space involves using the companded RGB components (0 ~ r, g, b _~ 1) as the parameters for the 
polynomials. The hyperpatch therefore applies a free form deformation to the RGB cube, transforming it 
into (L*, a*, v*) space. This is illustrated in Figure 7, which is an RGB cube in the companded RGB space 
of a particular class of device, and Figure 8, which shows the cube after transformation to (L*, u*, 
v~ ) space. Figure 7: Oompanded RGB cube in companded RGB space Figure 8: Companded RGB cube in L*, 
u*, v* space The mathematical formulation of the tricubic hyperpatch is shown here for the L* component. 
The u* and v* components are similar. [/+(~ b where '~ ~ Computer Graphics, Volume 23, Number 3, July 
1989 with similar equations for f l(g, b ) through f 3(g, b ), and  r .0] ho(,)= [,3 ,] t ,3J with 
similar equations for h l(b ) through h ls(b ). In these equations, (L~., u~., v~.) are control points 
derived from spectro- photometric measuremen~ taken during the device characterization process. These 
control points are interpolated using the basis function, [B~3 ]. This basis function is derived from 
the polynomial f(t)~ a t3+b t2+c t + d whose coefficients a, b, c and d we wish to express in terms of 
control points in (L*, u*, v*) space (Pc through P3), which the function will inter- polate. We choose 
the following four conditions: f (0) = P0 f (1/3) = P1 f (2/3) = P2 / (1) = P~ Combining these equations 
yields 27 9 3 P1 8 4 2 ~ P2 27 9 3 Pa 1 1 1 which leads to the cubic interpolation basis ~7 1 1 -9 27 
-27 9 r '1 9 ~ 1 18-45 36 - [ JBxa = 8 4 2 = -2 11 18-9 T 0 0 1 1 1 Following similar proeess, the quadratic 
and linear bases are found to be 1 0 Bxl 1 For polynomials of degree N, (N + 1) 3 control points are 
needed. These control points are measured with a spectrophotometer or spectroradiometer from sample colors 
made on a calibrated output device (calibration is described in 6.3). The colors to be measured are 
those resulting from all combinations of r, g, b taken from the set {i/N}, with i =0,1, "'' ,N. The hyperpateh 
exactly interpolates the control points, therefore higher degree polynomials have more control points 
which are more closely spaced, resulting in a better representation of the actual device properties. 
It is noteworthy that not only is the shape of the deformed RGB cube impor- tant, but also the locations 
of the isoparametrie curves on its surface and the isoparametrie bivariate patches in its interior. One 
portion of color spane that is particularly sensitive to even small errors is the gray scale. Any hue 
in an achromatic color is easily perceived. In terms of the color spaces defined here, all colors with 
equal r, g, b values must map onto the L* axis. Since there are only N + 1 control points with this property, 
the entire gray scale is not guaranteed to map properly. This phenomenon is easily remedied by applying 
a reparameterization to aH r, g, b values prior to substitution into the hyperpatch equations. The effect 
of this may be seen by comparing Figure 9, which is a transformed gamut without reparameterization, with 
Figure 8, for which reparameteriza- tion was used. This process does not change the shape of the gamut, 
it only redistributes the isoparametric patches within the gamut such that all r ~ g ~ b map onto the 
L* axis. This redistribution is slight, and in fact no change whatever occurs at any of the control points. 
This i'eparameterization may be implemented using three look up tables, each containing 256 entries. 
These tables are created once for each class of device by interpolating the N + 1 achromatic control 
points with a parametric polynomial using the [BXN } basis. 256 equal steps in the curve parameter generate 
256 (L*, u*, v*) gray scale values, each of which is transformed to RGB parameters using the transformation 
described in 6.2. Normally, the (L*, u*, v a) values generated this way will be 256 even steps in L*, 
with u* ~ v* ~ 0. The resulting 256 RGB triplets become the values of the reparameterization look up 
tables. The reparameterized hyperpatch now interpolates the measured control points with precise gray 
scale reproduction. Figure 9: Color gamut without reparmeterization The information required to characterize 
a device is a) the polynomial degree, N, to be used for interpolation, b) an ordered set of (N + 1) 3 
control points in (L*, u*, v*) and c) three reparameterization look up tables, one for each RGB component. 
All of this information is measured and computed once for each class of dev- ice and is used thereafter 
for all color conversions between companded RGB and (L* , u* , v* ). To summarize the transformation 
from RGB to (L*, u*, v*), the com-panded RGB values are first passed through the reparameterlzation look 
up tables and then substitutod into the hyperpatch equations, producing a dev- ice independent (L* , 
u* , v*) color. 6.2. L*~ u*, v* to RGB Transformation This transformation is the inverse of the process 
just described in the previ- ous section. We start with a device independent (L*, u*, v*) color and con- 
vert it to a device class dependent, companded RGB color. There is no closed form solution to the inverse 
of the hyperpatch equations, so a numerical solution must be employed. Newton's method[3, 13] is used 
here to transform the color (L* I , u* t , v* I ) into companded RGB values. The iteration process obtains 
guess n +1 from guess n as follows: rn+ l ~ r n + Ar n gn+l ~ gn + Agn (4) bn+ 1 ~ b n + Ab n where far 
n Ag n /Xb~ ] = [AL*n AU* n Av*n ] [j]-i AL*, = L*' -Ls, ~XU~ n ~ US t -Ugxn and [J] is the Jacobian 
OL* Ou* Ov* ] or ~ -~- [j] = OL* On* Or* where the partial derivatives are evaluated at (rn, an, bn)" 
The (r, #, b) parameters must always be clamped to the range [0, 1]. As a bit of an historical aside, 
the first effort in the development of these color reproduction algorithms used a hyperpatch to map the 
RGB intensity cube to (X, Y, Z) space. This transformed color cube is shown in Figure 10 for a color 
film recorder (obviously a non-linear transform, as discussed in  4). The irregular spacing of the RGB 
intensity points results in very large variations in the partial derivatives, which seriously impairs 
the stability of the Newton iteration, causing it to take giant steps into oblivion, on its way toward 
far away roots. Despite considerable effort, this scheme could never be made to work reliably. A comparison 
of Figure 10 with Figure 8 clearly shows the improvements realized by mapping companded ROB into (L*, 
u*, v a) space, where the iteration is very well behaved. Furthermore, the use of companded RGB and (L*, 
u*, v* ) gives much better control over perceptual errors than (X, Y, Z) which is very perceptually non-uniform. 
The use of Newton's method has three requirements: a sufficiently good ini- tial guess must be available, 
the functions must be differentiable and some convergence criteria must be available to terminate the 
iteration process.  '89, Boston, 31 July-4 August, 1989 Z  Figure 10: RGB intensity cube in X, Y, Z 
space Newton's method has quadratic convergence in the neighborhood of a root, and therefore a good initial 
guess will be very beneficial in finding a rapid solution. Experimentation has shown the following equation 
to be easily computed as well as providing an excellent initial guess, shown here for red: Pi ~i di 
We ro~ 1 ~i di +e where the summations occur over all control points, Pi is the red parameter value 
at control point i, d i is the square of the distance between (L* t , u* ~ , u t ) and control point 
i and e is a small constant to prevent divide by zero failures, Initial guesses for the green and blue 
parameters are similarly computed. These initial guesses are weighted averages of the parameter values 
associated with the control points based on their distances. The partial derivatives needed for the Jacobian 
are easily computed since polynomial functions are used for the interpolation. There are several criteria 
which are useful for terminating the iteration pro- cess. Since we are iterating in (La, u*, v*) space, 
a perceptual color difference may be used to detect convergence[20] : However, since we are using compandcd 
RGB, a much more convenient and efficient method is available. We can terminate the iteration when maximum(l~r 
], I&#38;g l, I&#38;b l) -< 1/256. A maximum iteration count must also be defined. If convergence is 
not attained after this prescribed number of iterations (say five), the (L* ~ , u* ~ , v* ~ ) color is 
outside the color gamut of the device, and there- fore cannot be accurately displayed. These eases of 
out of range colors are quite common and may be illustrated by comparing the gamut of Figure 8 (a film 
recorder with color transparency fihn) with that of Figure 11 (a press proof from an electronic pre-press 
sys- tem). These two gamuts are quite different, and divide color space into four regions: colors that 
are only in one gamut, colors that are only in the other gamut, colors that, are in both gamuts and colors 
that are in neither gamut. These regions are easier to visualize by examining Figure 12, which shows 
the intersecting gamuts. Figure 1_1: Color gamut for print in L*, u*, v* spice Figure 12: Intersecting 
gamuts of two devices This leads to the very complex issue of handling colors which are outside the gamut 
of the display deviee[16 , 14]. The difficulty arises more from definition than from implementation. 
The definition of the desired course of action appears to be very dependent on the application context. 
Mapping to the closest displayable color can result in hue shifts and can introduce discon- tinuities 
in a smooth sequence of out of range colors. A method which seems to suit many applications is to treat 
hue as being more important than saturation, which in turn is more important than lightness. In this 
case, hue is always maintained. The saturation is altered only if it is greater than 100% in which ease 
it is clamped to lfiO%. Finally, the lightness is set to 100% only if it is greater than 100%. This requires 
ray tracing the outer surfaces of the hyperpatch. These sur-faces are bivariate parametric patches for 
which numerous ray -patch inter- section solutions have been devised[U, 17, 18]. However, in this use, 
there are certain properties of the hyperpatches which make this computation easier than intersecting 
a ray with an arbitrary patch. First, it has been found that the three surfaces of the companded RGB 
cube containing black are always nearly planar after transformation to (La, u*, u*) space for all device 
types tested. As an approximation, we may force the (L*, u*, v*) control points to be located on planes 
fitted through them as part of the characterization process. This reduces the saturation clamping to 
process to a trivial ray -plane intersection, with the ray orl-ginating at (La t , u* t , v* t ) and 
pointing towards (L* t , O, 0). However, the same scheme will not work for the lightness clamping because 
the three surfaces of the companded RGB cube containing white are typically highly curved. Therefore, 
lightness clamping must be done by ray tracing these three patches. The ray originates at the point (La 
I , ua t , va t ) and points toward (0, 0, 0). It will intersect the patch at most only once because 
these patches are not folded over or grossly distorted (no multiple roots within the parameter range 
and no silhouette edges). The intersection calcu- lation may be simplified by applying a rotation to 
the ray (rotating about the (L*, u*, v*) origin) such that the ray lies on the +L* axis. The patch may 
then be transformed by this same transformation and projected onto the u,v* plane. The 313 ray tracing 
problem now becomes the 2D problem of intersecting the point (0, 0) with a well behaved 2D bivariate 
patch. This may be solved by using a simplified version of the Newton's method described earlier. Alternatively, 
a subdivision scheme may be used by con-~'erting from [B~N ] basis control points ([GGx]) to Bdzier basis 
[BB] control points ([G B ]):  [GB ] = [BB ]-' [B ] [a ] [B ] r [BB ] -'r In many applications, 
a relative gamut mapping is desired so that no damp- ing is applied. In such cases, a colorimetric match 
is not obtained, but rather, pure red for one class of device is mapped onto pure red for a different 
class of device, green to green, blue to blue, and so on. For exam-ple, if colors in the gamut of device 
Class 'A' (refer to Figure 6) are to be mapped to a Class 'B' device by applying a relative gamut mapping, 
the (L*, u*, v*) colors are converted to Class 'B' colors using the device charac- terization information 
for Class 'A'. The instance mapping that follows uses a Class 'B' instance conversion. In fact, since 
the transformation is based on free form hyperpatches, arbi-trary mappings may be created by altering 
the locations of the control points. This allows color gamut mappings based on preference rather than 
colorimetrie principles. After companded RGB values are determined, they must be reparameterized by the 
inverse of the function described in 6.1. To summarize the transformation from (L~, a*, v*) to companded 
RGB, the input color is first subjected to saturation clamping (if needed) and then passed into the iterative 
process of Equations 4. If no solution is found, the color must be subjected to lightness clamping. In 
any event, the resulting parameters are passed backwards through the reparamcterization table to arrive 
at the final companded RGB values. While this seems rather involved, some application examples will be 
examined in 7 which demonstrate imple- mentation details. ~ Computer Graphics, Volume 23, Number 3, 
July 1989 6.3. RGB to Device Color Coordinate Transformation The eompanded RGB values are generated for 
a class of display device. In this context, all instances of this class are identical. Therefore identical 
RGB data imaged on two different devices of the same class will produce identical results. This is accomplished 
by processing the RGB data with a local cali- bration function as part of conversion to device specific 
coordinates. This calibration process accounts for local variations in a particular instance of a device 
(e.g. long term drift, new film emulsion batch, new roll of printer rib- bon, etc.) as well as differences 
among devices within the same class. As we saw in fi.1, the characterization process requires the use 
of a spectro- photometer or spectroradiometer, which is a very expensive instrument, requiring a skilled 
operator. However, characterization need only be per-formed once for each class of device, with the resulting 
measurements apply-ing forever after to all instances of that class. Calibration, on the other hand, 
must be performed at regular intervals by the end user of each instance of the display device, and therefore 
this process should be simple, requiring less expensive and less sophisticated measurement equipment. 
In many applications, the end user may have no technical incli- nation whatever. The simplicity of calibration 
must be based on this prem- ise. The method used here is a variant of Catmull's method[4], which used 
b-splines to establish a linear relationship between log2i and density. One deviation from this scheme 
is the use of three separate look up tables, one each for red, green and blue. This technique allows 
gray colors (equal r, g, b values) to be displayed as gray, even on devices which do not exhibit gray 
tracking properties, such as film recorders and print. The second deviation from Catmull's method is 
the linearization of com-panded RGB values with L*, rather than the log of intensity with density. This 
is in line with our definition of companded RGB and its relationship with the CIE uniform perceptual 
lightness scale, Equation (1). The conver-sion from density (D) to L* is done by using intensities (I): 
Itohit ~ 10"O*h~u Ibtac k ~ 10 -D*~.,* [i = lO-o~ where D i is the density to convert. Relative luminances 
are then computed as.. rl = I~ -tbl,~k rn = "[while -[black which are then substituted into Equation 
(1) to produce L*. While the device characterization information is common to all instances of each class 
of device, the calibration information is unique to each device instance. It is refined periodically 
at whatever interval seems appropriate. With suitable software support, this calibration prueess can 
be made simple enough for non-technical people to perform using relatively inexpensive equip- ment sueh 
as a densitometer. This calibration process involves imaging a stepwedge, measuring the densities of 
the steps, and using these measure- ments to refine the eMibration tables. This process may be further 
simplified by using a densitometer with a serial interface. After the companded RGB values are passed 
through their respective look np tables, they are transformed into physical device coordinates. This 
process is, of course, very device specific and may be as simple as scaling the range of the RGB values. 
Other applications may require conversion to the subtractive printers (CMYK) and possibly screening or 
dithering. 6.4. Device Color Coordinate to RGB Transformation This final transformation involves inverting 
the device specific transformation function to produce RGB components, which are then passed backwards 
through their look up tables to produce eompanded RGB values. 7. Application Examples In this section 
different types of application examples will be examined. Each example has been chosen to demonstrate 
a different use of the methods presented in this paper. 7.1. Color Mapped Applications In a typical color 
mapped application the user interacts with simple 2D graphics such as lines and polygons. The geometric 
objects are colored by number, using a color look up table to define the appearance of the relatively 
small (typically < 256) set of colors. These colors are stored in the graphics file as (L*, u*, v*), 
although the user interface software presents the user with more useful controls such as companded RGB 
(using the methods of 6.1 and 6.2) and possibly HSV and HSL[81, which are derivations of RGB. Colors 
may he mixed specifically for any display device by using the appropriate device characterization parameters 
during the conversion to and from (L*, u*, v*). When the design session is over, a device independent 
color table is stored. Note that the colors in the color table may easily be checked against any device 
gamut to detect out of range colors. This out of range information is available from the (L*, u*, v*) 
to RGB conversion process, as any color to which saturation clamping or lightness clamping has been applied 
can be so flagged. When this file is to be displayed on a device, the (L*, u*, v*) to RGB pro- cess is 
applied, using the characterization parameters for the particular display device class, followed by the 
transformation to the physical device coordinates using local calibration information. The computation 
time for this small set of colors is acceptable for nmst commonly used computing plat- forms in use today. 
7.2. Full Color Raster Applications The computation needed for translation to and from (L*, u*, v*) is 
too great for use on images with many colors, such as full color raster images. It is suggested here 
that such images be stored in companded RG/3 for a certain device class. The conversion of this raster 
image to the RGB space of a different class of device must use an approximate solution to the processes 
described in 6.1 and 6.2. One method of doing this is by tessellating the source RGB space into a large, 
three dimensional array of points. Each of the source colors associated with these points is transformed 
to (L*, u*, v*) using the source device class, and then to companded RGB using the destination device 
class. This process generates a 3D look up table which may be used to transform all colors in the source 
image, using table look up combined with trilinear inter- polation. The size of the look up table is 
arbitrary. Larger tables will reduce the Mach banding effects discussed earlier, but will require more 
storage. This trade-off may be changed at will by tessellating at finer or coarser reso- lutions, thereby 
allowing optimization for individual applications. Note that the risk of Maeh banding is relatively small 
since continuous functions are being tessellated at points that are approximately uniformly distributed 
in a perceptual sense. The compute requirements needed to generate large look up tables suggests that 
it may be useful to create them off-line for repeated use at later times. When not needed, the look up 
tables may be discarded, as they may always be exactly recreated at any time and at any resolution from 
the small set of device characterization information. 7.3. Print Applications For print applications, 
companded RGB must be converted to the four pro- cess colors: cyan, magent% yellow and black (CMYK). 
This process is called color separation[15]. The four dimensional CMYK space has an extra degree of freedom 
which is typically used to control the way in which the black printer is used. Although there is much 
effort ia applying scientific methods to this, there is still a healthy dose of art and craft involved. 
One way the extra degree of freedom may be used is in the control of the gray component replacement (GCR), 
which governs the amount of the gray component of a CMY color that is replaced by the black printer. 
In this simplified ease, the specification of a GCR value locks in the extra degree of freedom and establishes 
a one to one mapping from RGB to CMYK. This implies that different calibration information is needed 
for every possible GCR value. In practice, it has been found that it is sufficient to calibrate at a 
few GCR levels and to interpolate this calibration data for other CCR valnes. The calibration process 
is exactly as described in 6.3, with density measure-ments being taken from a press proof. This correctly 
compensates for the lack of gray scale tracking in the printing proeess. An algorithm is presented here 
which converts from companded RGB (r, g, b in th .... ge [0, 11) to CI~YK ( .... y, k in the range [0, 
11): c p =l-r m I ~l-g yr ~l-b Vmi n~min(c' , m' , y' ) Vma ~ ~ max(c' , m' , y' ) v.~ = vm,~a~{1-(Vm.-V,~J} 
~ (5) c = c t _ Vrem m ~ m ! -Vre m y =y' -V,~,~ k ~ VminG In these equations, G is the GCR value in 
the range [0, 1]. The constant a is used to control the relationship between the black printer and the 
CMY printers as a function of GCR. Examination of several standard references to good 'blacks'[21, 15] 
leads to a value for c~ of about 5. The constant fl is used to give further control of the K to CMY relatlonsbip 
as a function of satura- tion. The value for fl is somewhat subjective, bat 2 is a good starting point. 
   :~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 The (c, m, V, k ) values are generic in the same 
sense the (r, g, b ) values are, and we may think of them as companded CMYK. These values are cali- brated 
for specific output by using the calibration tables: md~,,~ ~ 1 - .fg(l -m) Ydevice = 1 - fb(l -y) where 
fr, fa and fb are the calibration look up tables, and lava is an average of them. Equation (5) may be 
implemented as a triangular, two dimensional look up table indexed by Vmm and Vma x. One reason such 
a simple color separation algorithm works is that the com-plex non-linearities and erosstalk effects 
have already been accounted for by the (L*, u*, v*) to RGB transformation described in  6.2. This color 
separation algorithm may be inverted: Vmi n : min(c , m, y ) Vine ~ = max(c, m, y) Vr~,,, = t: a "-~ 
(~ (v.,,= -v.,,.,,)) ~ (fi) - V~e,~ = min(V~,~, 1 - Vm~) r ~ 1-c -V,.,m b ~-1 -y V,.,, m Equation (6) 
may be implemented as a rectangular, two dimensional look up table, indexed by k and (Vrnax-Vmin)" Figure 
13 shows the effect of gray component replacement on the color separation process, using the algorithm 
presented above. This demonstrates that as the black increases linearly with GCR, color is removed from 
the CMY in a non-linear fashion. i GCR value in the range 0.6 to 0.8 produces a black with the highest 
den- sity, and therefore offers the greatest dynamic range. Although the max-imum GCR value of 1.0 provides 
the best economy of the more expensive colored printing inks, the resulting printed images suffer from 
reduced sha- dow density and increased sensitivity to registration errors between the black and colored 
printers, causing light outlines to appear on dark picture ele-ments. Figures 4a, 4b and 13 of this paper 
were made using this color separation algorithm. Color separation films were made by processing the CMYK 
out-put through an electronic pre-press system. 8. Future Work Some work has begun in applying these 
techniques to the calibration of color raster scanners. The approach taken involves scanning a monochrome 
test pattern containing known levels of L*. By applying the technique described in 6.3 in reverse, look 
up tables may be created that map RGB device coor- dinates from the scanner into companded RGB. This 
method correctly per- forms gray scale tracking over the dynamic range of the scanner. However, a method 
needs to be devised to characterize the scanner gamut in device independent terms. Preliminary work has 
also begun on implementing the RGB to CM-YK color separation process, combined with optional halftone 
generation, on a set of four parallel digital signal processors. 9. Conclusions This paper describes 
a general framework for device independent color repro- duction. Introduced is a companded RGB color 
space which serves as an important intermediate between physical device color coordinates and device 
independent color systems. The important issue of color quantization is addressed as part of the development 
of companded RGB. The device characterization process is described which generates a relatively small 
set of parameters used to control the single, general purpose transfor- mation function between companded 
RGB and (L~, uS, v*) for any type of display device. This transformation function automatically accounts 
for non-linearities and color crosstalk effects exhibited by various display devices, as well as providing 
exact gray scale reproduction. The calibration process is described which is used to map generic, companded 
 RGB values to physical device color coordinates. These methods have been in use for several years and, 
although not perfect, have been found to be quite effective in addressing the ambitious design goals 
set forth in 2. 10. Acknowledgements In the academic community, the motto is often 'publish or perish'. 
In the highly competitive industrial segment, a different Boolean function is often used: 'publish and 
perish'. The au%hor mould therefore like to express his ~ppreeimtion to George Walker and Trevor Haworth 
of Grosfield Dicomed, Inc. and to Brian Jordan of Crosfield Electronics, Ltd. for allowing this information 
to be made public. Thanks is also due to Gerry Baiei, Tom Buck and Jim Dillon for their impor- tant liaison 
roles between research and product development, and to Carey Carlson for his tireless testing, film recorder 
expertise and many helpful suggestions. Finally, the author wishes to express sincere gratitude to John 
Grimaldi for establishing a creative work environment and for his dedicated support of this and other 
research work. Appendix Color Qunntization and Companding Five informal discussions about quantization 
are presented to support the use of a companded RGB space. Admittedly there is room for more rigor in 
some of the discussions. However, empirical evidence strongly supports the conclusions drawn. Discussion 
1: Sampling 3D Color Space Although there is some disagreement among experts as to the exact number, 
there are approximately ten million deteetably different colors[19]. Since color space is three dimensional, 
this suggests that 215 samples (cube root of ten million) would be sufficient to avoid visible quantization 
errors, provided the coordinate system axes carried equal perceptual weight and the samples were carefully 
selected along each axis. Conclusion l: It should be possible to define a color system such that three 
 channels of eight bits each should be sufficient to guarantee no perceptible color quantization anomalies. 
 Discussion 2: Experience with the Companding Function The companding method described in this paper 
has been used for many, many pictures. Color quantization problems have never been observed as a result 
of the companding and quantization processes. Obviously, contours will be visible on display devices 
lacking adequate color control, but this is a deficiency of the device, not the quantization method. 
 Companded RGB has three channels of eight bits each, therefore the claim is made that it meets the 
criteria of Discussion 1. We can make this claim a little more believable by factoring in two addi- tional 
safety margins. First, we will use 256 samples per axis rather than 215 to make better use of a binary 
representation and, second, we realize that no display device is capable of displaying all of the ten 
million perceivable colors. Therefore, we have over 16 million samples to cover fewer than ten million 
detectably different displayable colors. Conclusion 2: Eight bit channels of companded RGB are sufficient 
to guaran- tee no perceptible color quantization problems. Discussion 3: Examination of the Companding 
Function If we differentiate Equation (3), we find that the part of the function with the minimum slope 
is V c < ~/100, where the slope is 1/a. If we assume that 256 levels are sufficient to avoid quantization 
errors (Conclusions 1 and 2), the minimum intensity step needed is 1/(256 X to), which in turn means 
that approximately 2312 evenly spaced intensity r~levelsare required. Therefore, twelve bits of intensity 
precision are needed (/]og2(2312) ~ = 12). Conclusion 3: Twelve bit channels of intensity should be 
sufficient to guaran- tee no perceptible color quantization anomalies. Discussion 4: A Look Up Table 
Experiment An experiment was performed using a high quality film recorder with twelve bit exposure control. 
A look up table was carefully constructed such that 256 equally spaced levels of L* were displayed. Examination 
of this look up table indicated a minimum slope of about one part in 2793. Conclusion 4: Same as Conclusion 
3. ([1og2(2793) / = 12). Discussion 5: RGB Interpolation Experiment A.nother experiment was performed 
using the same film recorder. This exper- iment displayed the 28 unique interpolation paths between all 
possible pairs of the eight corner colors of the RGB cube. The images were plotted several times, with 
progressive masking of the least significant bits of the look up table. This simulated display devices 
with limited control of intensities (12 bit, 11 bit, 10 bit, etc.). The resulting film showed obvious 
visual quantiza- tion breaks in the eight bit simulation, and the discriminating eye could detect subtle 
breaks even in the 11 bit simulation. No visual quantization defects could be seen on the 12 bit image. 
Conclusion 5: Same as Conclusion 3. Therefore, if RGB channel values are quantized to eight bits in the 
intensity domain, color quantization defects may be visible. If this is to be avoided, the intensity 
channels must be quantized to at least 12 bits, resulting in a storage/transmission increase of fifty 
percent. On the other hand, companding gives the best of both worlds by guarantee- ing no visual quantization 
problems while maintaining eight bit color chan- nels. Furthermore, referring to Figure 2b, the compression 
function of Equa- tion (2) combined with the quantization operation may be implemented as a 4096 X 8 
bit look up table, and the scaling operation combined with the expansion function of Equation (3) may 
be implemented as a 256 X 12 bit look up table. Therefore, companding becomes a very inexpensive operation. 
   ~..4~ SIGGRAPH'89, Boston, 31 July-4 August, 1989 References 1. Conrac Corporation, Raster Graphics 
Handbook, Second Edition, Van Nostrand Reinhold Company, 1985. 2. Texas Instruments, Digital Signal Processing 
Applications with the TMSSeO Family, 1986. 3. Forman S. Actou, Numerical Methods That Work, Harper &#38; 
Row, 1970. 4. Edwin Catmull, "A Tutorial on Compensation Tables," Computer Graphics, vol. 13, no. 2, 
Association for Computing Machinery, August 1979.  Michael F. Cohen and Donald P. Greenberg, "The Hemi-cube, 
A Radios- ity Solution for Complex Environments," Computer Graphics, val. 19, no. 3, Association for 
Computing Machinery, July 1985. Robert L. Cook, Thomas Porter, and Loren Carpenter, "Distributed Ray 
Tracing," Computer Graphics, yah 18, no. 3, Association for Computing Machinery, July 1984. Tom N. Cornsweet, 
Visual Perception, Academic Press, 1970. James D. Foley and Andries Van Dam, Fundamentals of Interactive 
Com- puter Graphics, Addison Wesley Publishing Company, 1982. Roy A. Hall and Donald P. Greenberg, "A 
Testbed for Realistic Image Synthesis," Computer Graphics and Applications, vol. 3, so. 8, IEEE Computer 
Society, November 1983. 10. Paul Heekbert, "Color Image Quantization for Frame Buffer Display," Computer 
Graphics, voh 16, no. 3, Association for Computing Machinery, July 1982. 11. James T. Kajiya, "Ray Tracing 
Parametric Patches," Computer Graph- ics, vol. 16, no. 3, Association for Computing Machinery, July 1982. 
 12. Irving Pobbaravsky and Milton Pearson, "Computation of Dot Areas Required to Match A Colorimetrieally 
Specified Color Using the Modified Neugebauer Equations," 150, Graphic Arts Research Center, Rochester 
Institute of Technology. 13. Anthony Ralston and Philip Rabiaowitz, A First Course in Numerical Analysis, 
McGraw Hill Book Company, 1978. 14. Philip K. Robertsou, "Visualizing Color Gamuts: A User Interface 
for the E~eetive Use of Perceptual Color Spaces in Data Displays," Computer Graphics and Applications, 
vol. 8, no. 5, IEEE Computer Society, Se W t.ember 1988. 15. Miles F. Southworth, Color Separation Techniques, 
Second Edition, Graphic .Arts Publlshing, 1979. 16. Maureen C. Stone, William B. Cowan, and John C. 
Beatty, "Color Gamut Mapping and the Printing of Digital Color Images," ACM Tran- sactions on Graphics, 
vol. 7, no. 3, Association for Computing Machinery, October 1988. 17. Daniel L. Toth, "On Ray Tracing 
Parametric Surfaces," Computer Graphics, vol. 19, no. 3, Association for Computing Machinery, July 1985. 
 18. Turner Whitted, "An Improved Illumination Model for Shaded Display," Communications of the ACM, 
vol. 23, no. 6, Association for Computing Machinery, June 1980. 19. Gunter Wyszecki and Deane B. Judd, 
Color in Business, Science and Industry, John Wiley &#38; Sons, 1975.  20. Gunter Wyszecki and W. S. 
Stiles, Color Science, Concepts and Methods, Quantitative Data and Formulae, Second Edition, John Wiley 
&#38; Sons, 1982. 21. J. A. C. Yule, Principles of Color Reproduction, John Wiley &#38; Sons, 1967. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74346</article_id>
		<sort_key>127</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Metamouse: specifying graphical procedures by example]]></title>
		<page_from>127</page_from>
		<page_to>136</page_to>
		<doi_number>10.1145/74333.74346</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74346</url>
		<abstract>
			<par><![CDATA[Metamouse is a device enabling the user of a drawing program to specify graphical procedures by supplying example execution traces. The user manipulates objects directly on the screen, creating graphical tools where necessary to help make constraints explicit; the system records the sequence of actions and induces a procedure. Generalization is used both to identify the key features of individual program steps, disregarding coincidental events; and to connect the steps into a program graph, creating loops and conditional branches as appropriate. Metamouse operates within a 2D click-and-drag drafting package, and incorporates a strong model of the relative importance of different types of graphical constraint. Close attention is paid to user interface aspects, and Metamouse helps the user by predicting and performing actions, thus reducing the tedium of repetitive graphical editing tasks.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.5</cat_node>
				<descriptor>Polynomials, methods for</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003739</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Nonlinear equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P62816</person_id>
				<author_profile_id><![CDATA[81100340093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Maulsby]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Knowledge Sciences Laboratory, Department of Computer Science, The University of Calgary, 2500 University Drive NW, Calgary, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42050684</person_id>
				<author_profile_id><![CDATA[81100252005]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Witten]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Knowledge Sciences Laboratory, Department of Computer Science, The University of Calgary, 2500 University Drive NW, Calgary, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P160151</person_id>
				<author_profile_id><![CDATA[81430611778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kenneth]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Kittlitz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Knowledge Sciences Laboratory, Department of Computer Science, The University of Calgary, 2500 University Drive NW, Calgary, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abbott, Edwin A. Flatland m A Romance of Many Dimensions. Signet Classics edition. New York. 1984.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Andreae, Peter. "Justified generalization: acquiring procedures from examples.'" PhD thesis. Department of Electrical Engineering and Computer Science, MIT. January 1985.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356918</ref_obj_id>
				<ref_obj_pid>356914</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Angluin, Dana and Smith, C. H. "Inductive inference: theory and methods." Computing Surveys 3 (15), pp. 237-269. September 1983.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15912</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bier, Eric A. and Stone, Maureen C. "Snap-dragging." Proc. ACM SIGGRAPH '86 (Dallas, August 18-22, 1986), in Computer Graphics 20, 4, pp. 233-240.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>22362</ref_obj_id>
				<ref_obj_pid>22627</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Borning, Alan. "Defining constraints graphically." Human Factors in Computing Systems: Proc. ACM SIGCH1 '86. Boston. April 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dennett, Daniel C. The intentional Stance. MIT Press. Cambridge MA. 1987.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fuller, Norma and Prusinkiewicz, P. "L.E.G.O.--an interactive graphics system for teaching geometry and computer graphics." Proc. CIPS Edmonton 1986.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fuller, Norma and Prusinkiewicz, P. "Geometric modeling with Euclidean constructions," in {231, pp. 379-391.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Halbert, Dan. "Programming by example." Research Report OSD-T8402. Xerox PARC. Palo Alto CA. December 1984,]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378495</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kurlander, David and Bier, Eric A. "Graphical search and replace." Proc. ACM SIGGRAPH '88 (Atlanta GA, August 1-5, 1988), in Computer Graphics 22, 4, pp. 113-120.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[MacDonald, Bruce A. and Witten, Ion H. "Programming computer controlled systems by non-experts.'" Proc. IEEE Systems, Man and Cybernetics Annual Conference. Alexandria VA. October 1987.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cutter, Mark, Halpem, B., Spiegel, J. MacDraw. Apple Computer Inc. 1985, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Maulsby, David. "Inducing procedures interactively." MSc thesis. Department of Computer Science, University of Calgary. December 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>67463</ref_obj_id>
				<ref_obj_pid>67449</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Maulsby, David and Witten, Ian H. "Inducing procedures in a direct-manipulation environment." Proc. ACM SIGCHI '89 (in press).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Maulsby, David, Kittlitz, Ken and Witten, Ian H. "Constraint-solving in interactive graphicsma user-friendly approach." Proc. Computer Graphics International 1989 (in press).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>43392</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Myers, Brad. Creating User Interfaces by Demonstration. Academic Press. San Diego. 1988.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Noma, T., Kunii, T. L., Kin, N., Enomoto, H., Aso, E. and Yamamoto, T. Y. "Drawing input through geometrical constructions: specification and applications," in {23}, pp. 403-415.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Papert, Seymour. Mindstorms. Basic Books. New York. 1980.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Preparata, Franco P. and Shamos, Michael I. Computational Geometry. Springer-Verlag. New York. 1985.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>53589</ref_obj_id>
				<ref_obj_pid>53588</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Rich, Charles and Waters, Richard. "'The programmer's apprentice: a research overview." IEEE Computer 21 (11), pp. 11-25. November 1988.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Smith, David C. "Pygmalion: a creative programming environment." Report STAN-CS-75-499. Stanford U. 1975.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan E. "Sketchpad: a man-machine graphical communication system." Proc. AFIPS Spring Joint Computer Conference, vol. 23, pp. 329-246. 1963.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann, Nadia and Thalmann, Daniel, eds. New Trends in Computer Graphics: Proc. CG International '88. Geneva. June 1988.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Tempo. Affinity MicroSystems Ltd. Boulder CO. 1986.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[van Lehn, Kurt. "Felicity conditions for human skill acquisition: validating an Al-based theory." Research Report CIS-21. Xerox PARC. Palo Alto CA. 1983.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[van Sommers, Peter. Drawing and Cognition. Cambridge Univ. Press. Cambridge UK. 1984.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[White, R. M. "Applying direct manipulation to geometric construction systems." in {23}, pp. 446-455.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ - - - @* Computer Graphics, Volume 23, Number 3, July 1989  a. The scene is set. b. Planned path. 
c. Alternative path. d. Constructions for procedure. 0 e. Move row-line R 8 f. Move teapot up / g. 
Move pot to first / h. Move potto near up to first row. to near end of R. cup; pour. end of row-line. 
 pot up to R. along 2nd row. to near end of R.  / 0 m. End of row n. No more rows; remove R. marker. 
Figure 3. The tea-party animation procedure. The power of a system like Metamouse lies in its ability 
to isolate constraints and predict actions. The user performs only a few steps of the tea-party task. 
Once Metamouse detects repetition, it predicts subsequent actions until it cannot meet the constraints 
or until the user objects. It observes the teapot move to the second cup and predicts all actions for 
the rest of row 1. When it fails to find a fourth cup, it asks the user to take over. The user moves 
the row-line; Metamouse recognizes this action and hence predicts the move-and-pour sequences for the 
second and third rows. 3 Background and Related Work Automation of graphical editing tasks has followed 
two streams of development: interactive tools to help users with constraints; and graphics-oriented programming 
systems. Interactive help began with Sketchpad [22], which used iterative numerical relaxation to resolve 
several types of constraint among object parameters. A similar approach is adopted in [27], which lets 
users compose constraints based on least-squares relaxation. Recent research has also produced a system 
that automatically selects and applies appropriate construction tools [4]. These systems offer simple, 
appealing interfaces to a restricted set of constraint-satisfaction methods. End-user programming is 
one way to support repetitive, customized editing operations and the invention of arbitrary constraint 
systems. Given that most users are non-programmers, research has focussed on graphical methods, often 
based on geometric construction [5, 7, 8, 171. With their graphical interfaces and use of examples, these 
systems greatly simplify program construction, but users must still work with abstractions. When programming 
with L.E.G.O. or a macro facility such as [24], the user declares loops and conditional branches, albeit 
by menu selection. Users of ThingLab must conceive an algebraic model of constraints in order to produce 
equational networks that define them [5]. An alternative is to observe the user at work and infer loops 
and branches, constants and variables. A number of systems for programming by demonstration have been 
produced [2, 9, I 1, 16, 211. Programs are constructed incrementally from several execution traces. Only 
Noddy, a robot teaching system, relies completely on automatic generalization [2], but it performs an 
exponentially complex induction of functions and is incapable of coping with errors. SmallStar [9] operates 
in a very general desktop domain but requires the user to identify variables and their type and value 
range. Peridot [16] infers value ranges and certain spatial relations (such as centered within box ), 
but not loops or branches. 129 ~ ~ _ ~ ~ i i i ~ ! i ~ i : ~i i ii i~ i~ ~ ~ ! ~ ~ ! ii ~ ! ii i ~ ~ 
~ ! ii i~ ~ ~ ~ i ~ i~ ili ~ l i  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74347</article_id>
		<sort_key>137</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[A two-view approach to constructing user interfaces]]></title>
		<page_from>137</page_from>
		<page_to>146</page_to>
		<doi_number>10.1145/74333.74347</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74347</url>
		<abstract>
			<par><![CDATA[This paper describes a system for constructing graphical user interfaces following a two-view paradigm: one view contains a textual representation of the interface in a special-purpose, "little" language, and the other view contains a direct manipulation, interactive editor for the user interface. The user interface can be edited in either view, and the changes are reflected in the other view. The language allows dialog boxes to be expressed in a simple and natural way, and has a well-defined mapping into the interactive editor. A base set of interactors is currently available, but the system can be easily extended with more interactors. We believe this approach to building user interfaces combines the advantages of the direct manipulation, WYSIWYG approach with the advantages of the textual, descriptive approach, and does not suffer from the limitations of either approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Software support</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>User interfaces</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011074</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011069</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Integrated and visual development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P97448</person_id>
				<author_profile_id><![CDATA[81100367729]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gideon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Avrahami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DEC Systems Research Center, 130 Lytton Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P159945</person_id>
				<author_profile_id><![CDATA[81100076721]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kenneth]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Brooks]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DEC Systems Research Center, 130 Lytton Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39069778</person_id>
				<author_profile_id><![CDATA[81332491195]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Brown]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DEC Systems Research Center, 130 Lytton Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Interface Builder. NEXT, Inc., Palo Alto, CA.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Proto~per. SmetherBarnes, Portland, OR.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>59743</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Paul J. Asente. Editing Graphical Objects Using Procedural Representations. PhD thesis, Dept. of Computer Science, Stanford University, Stanford, CA, 1987. Also available as Research Report #87/6 from DEC Western Research Laboratory, 100 Hamilton Avenue, Palo Alto, CA 94301.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>315691</ref_obj_id>
				<ref_obj_pid>6424</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jon Bentley. Little Languages. Communications o.fthe ACM, 29(8):711-721, August 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>914474</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kenneth P. Brooks. A Two-view Document Editor with Userdefinable Document Structure. PhD thesis, Dept. of Computer Science, Stanford University, Stanford, CA, 1988. Also available as Research Report #33 from DEC Systems Research Center, t30 Lytton Avenue, Palo Alto, CA 94301.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>62428</ref_obj_id>
				<ref_obj_pid>62402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Luca Cardelli. Building User Interfaces by Direct Manipulation. In Proc. ACM SIGGRAPH Syrup. on User lntelface Software, pages 152-166, October 17-19 1988.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>62031</ref_obj_id>
				<ref_obj_pid>62029</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Rex Hartson and Deborah Hix. Human-Computer Interface Development: Concepts and Systems. ACM Computing Sup'veys, 21 ( 1 ):5-92, March 1989.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359467</ref_obj_id>
				<ref_obj_pid>359460</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Paul HeckeI. A Technique for Isolating Differences Between Files. Communications of the ACM, 21(4):264-268, April 1978.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63219</ref_obj_id>
				<ref_obj_pid>63218</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mark A. Linton, John M. Vlissides, and Paul R. Calder. Composing User Interfaces with InterViews. IEEE Computer, 22(2):8-22, February 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Mark S. Manasse and C. Greg Nelson. A Performance Analysis of a Multiprocessor Window System. Technical Report, DEC Systems Research Center, Palo Alto, CA, (to appear).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Paul R. McJones and Garret F. Swart. Evolving the UNIX System Interface to Support Multithreaded Programs. In Proc. Winter 1989 USENIX Technical Conference, pages 393--404, USENIX Association, Berkeley, CA, 1989.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>624789</ref_obj_id>
				<ref_obj_pid>624573</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Brad A. Myers. User-lnterface Tools: Introduction and Suvery. IEEE Software, 6( 1): 15-23, January 1989.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325241</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Greg Nelson. Juno, a constraint-based graphics system. Computer Graphics, 19(3):235-243, July 1985.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Paul Rovner. Extending Modula-2 To Build Large, Integrated Systems. IEEE Software, 3(6):46--57, November 1986.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>317489</ref_obj_id>
				<ref_obj_pid>317456</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Andrew J. Schulert, George T. Rogers, and James A. Hamilton. ADM - A Dialog Manager. In Proc. ACM SIGCHI "85 Conf. on Human Factors in Computing Systems, pages 177- 183, April 1985.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>48708</ref_obj_id>
				<ref_obj_pid>48706</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Charles P. Thacker, Lawrence C. Stewart, and Edwin H. Satterthwaite Jr. Firefly: A Multiprocessor Workstation. IEEE Transactions on Computers, 37(8):909-920, August 1988.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 A Two-View Approach to Constructing User Interfaces 
Gideon Avrahami Kenneth P. Brooks Marc H. Brown DEC Systems Research Center 130 Lytton Avenue Palo Alto, 
CA 94301 Abstract This paper describes a system for constructing graphical user in-terfaces following 
a two-view paradigm: one view contains a tex- tual representation of the interface in a special-purpose, 
"little" lan- guage, and the other view contains a direct manipulation, interac- tive editor for the 
user interface. The user interface can be edited in either view, and the changes are reflected in the 
other view. The language allows dialog boxes to be expressed in a simple and natu- ral way, and has a 
well-defined mapping into the interactive editor. A base set of interactors is currently available, but 
the system can be easily extended with more interactors. We believe this approach to building user interfaces 
combines the advantages of the direct ma- nipulation, WYSIWYG approach with the advantages of the tex- 
tual, descriptive approach, and does not suffer from the limitations of either approach. CR Categories 
and Subject Descriptions: D.2.2 [Software] Tools and Techniques -user intelfaces; 1.3.4 [Computer Graph- 
ics] Graphics Utilities-software support; 1.3.6 [Computer Graph- ics] Methodology and Techniques -interactive 
techniques General Terms: User Interface Management Systems (UIMS) Additional Keywords and Phrases: TEX, 
Multiple Views 1 Preliminaries Tools for constructing interactive graphical user interfaces are be- coming 
increasingly important as more and more applications ex- hibit such interfaces. Indeed, most contemporary 
workstation and personal computer software environments provide such a tool, typi- cally called a user 
interface management system, a dialog manager, or an interface builder. While these tools share the goal 
of mak- ing it easier for programmers to create user interfaces, they differ significantly in the model 
and facilities they offer 17, 12]. The oldest approach to building graphical user interfaces (and one 
that is still in common use) is to provide a library, or toolkit, of routines to be called from within 
the application [9]. Although pro- gramming languages are inherently expressive, they are not very Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 
ACM -0-89791-312-4/89/007/0137 $00.75 well tuned to the task of specifying and modifying graphical ele- 
ments and arrangements. There are systems that provide a special-purpose descriptive lan- guage for specifying 
the user interface [151. They provide a con- cise description of the interface, and also separate an 
application's source code from its user interface description. However, they still share with the programming 
approach the disadvantage that the in- terface designer cannot see the effects of changes to the interface 
immediately. A growing trend is to use a direct manipulation editor for con- structing user interfaces 
[ 1,2, 6]. The direct manipulation approach has the nice feature that the designer always sees what the 
interface will look like and can readily change its properties. It has the dis- advantage that it is 
typically difficult to make consistent changes throughout a large collection of interface objects. Recent 
research in related areas suggests that the best aspects of a descriptive language and an interactive 
editor can be combined in a "two-view" editor that provides access to both representations simultaneously. 
Such editors have been built for documents [5] and for illustration graphics [3, 13]. This paper describes 
FormsVBT, a system we are implementing that supports a two-view approach to constructing user interfaces 
from an extensible library of interactor objects. One view contains ari interactive editor and the other 
view contains a textual descrip- tion of the user interface in a special-purpose "little" language [4]. 
The interface designer can edit the user interface in either view, and the effects of the editing are 
displayed in the other view as well. A third, non-editable view shows exactly how the interface will 
ap- pear at runtime, with proper sizing characteristics. Figure 1 shows the system in action. Our approach 
for constructing user interfaces combines the virtues of the interactive approach with those of the textual 
description approach, but without suffering the limitations of either. (FormsVBT also allows user interfaces 
to be constructed by direct programming, but that is not a focus of this paper.) The next section presents 
an overview of the entire FormsVBT system. Actually, there are two parts to the system: a textual language 
with its runtime support library, and a two-view editor, FormsEdit, for building interface descriptions 
in this language. Sec- tion 3 presents the language. Section 4 describes the runtime as-pects of using 
the system, that is, how a user interface description is "interpreted" into calls on the underlying workstation 
environment, and how application code communicates with the runtime library. Sections 5 and 6 are devoted 
to describing the two-view editor for constructing user interfaces: we first describe how an interface 
de- signer uses the two-view editor, and then we give an overview of how the editor is actually implemented. 
The final sections outline some future directions and offer some concluding remarks.   ~,~SIGGRAPH 
'89, Boston, 31 July-4 August, 1989 Bitmap A bitmap image. Border A border of a specified thickness 
and texture around some other component. Passive Text A line of text. Optionally, multiple lines of 
text with built-in scrollbars. Elements Texture A textured rectangle. Browser A list of items, specified 
at runtime, from which the user can make a selection. Generic A place-holder in which the application 
program can take control. For example, a generic would be used as the main window of a graphics editor. 
Glue Blank space. Basic Null A placeholder (displayed while editing as a rectangle textured with "chickenwire"). 
 lnteractors Numeric An editable integer value. ScrotlBar A horizontal or vertical scrollbar. TypeIn 
An editable text field. Optionally, multiple lines of editable text with built-in scrollbars. Boolean 
A binary state variable with visual feedback (usually a checkbox, which can be empty or checked). Button 
Generates an event when it is clicked. Options are available for Guarded, Repeating, UpClick, and DownClick 
styles of buttons. Choice One of a collection of binary state variables within a Radio group of which, 
like pushbuttons on old Interactive car radios, only one can be on at a time. Visual feedback is usually 
a round circle, which can be either Modifiers empty or filled. Menu Displays its first child normally, 
and its second child when it is clicked and the mouse button stay down. The two children may be any component 
of any complexity. Menus belonging to the same MenuBax group will pass the activation along as the mouse 
rolls from one to the next. Menultem The basic component of menus. Highlights when the mouse roils into 
it with the button down; gen- erates an event if the mouse button is released while inside it. MenuBar 
Defines a group for descendants that are of class Menu. Grouping Radio Defines a group for descendants 
that are of class Choice. The value of this interactor is the name of its member that is currently set. 
HBox A horizontal arrangement of subordinate components, Layout VBox A vertical arrangement of subordinate 
components. Figure 3: Standard FormsVBT components. 3.2 A Larger Example (Border (BgColor "LightGrey") 
Figure 4 shows a dialog from a color editor whose textual descrip- (PenSize 8) (PenPat "White") tion 
appears at the right. This dialog allows the user to specify a (VBox color by adjusting each color component 
by the appropriate scroll- (HBox (HBox (Width 60) "Red") (Scrollbar %red)) bar. The high, medium, or 
low quality options determine how many (HBox (HBox (Width 60) "Green")(Scrollbar %grn)) colors are dithered 
together to form the desired color. The dialog (HBox (HBox (Width 60) "Blue") (Scrollba~ %blu)) components 
are specified so that all components are aligned nicely, (Glue 10) and behave reasonably when stretched. 
(HBox (Width 200 + Infty) (Height 75 + 200) Note that the Generic component whose name is colorArea is 
(Radio %quality =med taken over at runtime by the application, which controls its appear- (VBox Fill 
ance and its interactive behavior, if any. The medium quality option (Choice %high "High") (Glue I0) 
will be selected when the dialog first appears, unless changed by the (Choice %med "Medium") (Glue I0) 
application. Also, the scrollbars will have default values and ranges (Choice %low "Low") Fill)) unless 
the application specifies otherwise at runtime. (Generic %colorArea)) (Glue 10) (HBox Fill (Button %okay 
(Border (Width 60) "OK")) Fill (Button %cancel (Border (Width 60) "Cancel")) Fill)))  '89, Boston, 
31 July-4 August, 1989  "L,i[~SIGGRAPH VBTs respond to user actions by calling the runtime package to 
generate events. The exact nature of the actions reported is part of the definition of each interactor 
class. The current set of interactors report the following events: Clicking on a Button, Boolean, or 
Choice interactor.  Hitting the return key in a TypeIn interactor.  Clicking the plus or the minus 
buttons on Numeric interactor, or hitting the return key while typing into it.  Clicking in a Scrollbax. 
 Clicking on an item in a Browser. A procedure is attached to an event by calling AttachProc:  PROCEDUBE 
Art achProc (v : VBT ; name:Text; p:Proc; arg:REFANY); TYPE Proc = PROCEDURE(VBT, Text, REFANY, Time); 
 AttachProc binds a procedure to a named interactor within the specified top-level VBT. It takes an 
extra argument, a REFANY (a generic pointer), which is later passed as the last argument when the attached 
procedure is called. This argument may be used by the application for any purpose, and provides a means 
of approximating object-oriented programming in a Modula environment. Once a procedure is attached to 
an interactor, it will be called whenever a reportable event occurs within that interactor. The ar- guments 
to an attached procedure are the top-level VBT, the name of the interactor, the KEFANY argument passed 
to AttachProc, and the time (for synchronized action in a concurrent environment). 4.2 Communication 
 Communication between a dialog and its application may be initi- ated by either of them. In generating 
events, the dialog takes the initiative. The application, however, can also initiate communica- tion 
to examine and change the values of interactors. The following procedures provide access to interactors 
of various types: PROCEDURE GetText (v:VBT; name:Text) :Text PROCEDURE Get Integer (v : VBT ; name : 
Text) : INTEGER PROCEDURE GetBoolean (v : VBT ; name : Text) : BOOLEAN PROCEDURE GetChoice (v:VBT; 
name:Text) :Text PROCEDURE PutText (v:VBT; name:Text; text:Text) PROCEDURE PutIateger(v:VBT; name:Text; 
hum:INTEGER) PROCEDURE PutBoolean(v:VBT; name:Text; value:B00LEAN) PROCEDURE PutChoice (v:VBT; groupName: 
Text; choiceName:Text)  The different classes of interactors handle only the calls that ap- ply to them. 
For instance, GetBoolean and PutBoolean apply to Boolean and Choice interactors, while GetText and PutText 
ap-ply to Text, TypeIn and Text interactors. For convenience, we ex- pect text interactors to handle 
GetInteger and PutInteger, too, by performing the conversion to and from string representation. Our underlying 
window manager provides routines to control the appearance, position, and disappearance of dialogs. 
4.3 Snapshot The FormsVBT runtime library can return to the application pro- grammer an s-expression 
containing the current values of all value- containing, named interactors, and can restore the interactor 
values from an s-expression. For example, the s-expression of values for the color editor ex- ample from 
Section 3.2 is as follows: (CurrentValues (quality med) (red 70) (grn 23) (blu 0)) The value of the 
Radio component (quality is the symbolic name of the Choice component that is currently selected. The 
other named components in the example dialog are each of the three scrollbars. Note that the named interactors 
without values, colorArea, okay, and cancel, are not saved. The Choice interac- tors are not recorded 
since their grouping Radio interactor records their values implicitly. The ability to "snapshot" and 
"restore" a dialog has turned out to be quite handy as a way of maintaining state between invocations 
of an application and storing configuration files for applications. In the latter case, it is desirable 
that the snapshot be a textual file so that system administrators can use familiar text-based tools for 
system management. 5 Two-View Editor: User Interface Figure 1 shows a typical screen during two-view 
editing with FormsEdit. There are two editable views of the user interface: the Text view at the left 
and the Graphics view at the upper right. The Text view uses a standard text editor to display and edit 
s-expressions. The Graphics view shows the user interface, with its internal structure completely visible. 
There are also two columns of buttons. A third view, the Result view, is located in the lower right. 
The user does not edit in this view, but sees how the dialog will actually look, stretch, and to some 
extent, interact. Editing in the Text view is straightforward. The Result and Graphics views are not 
updated after each keystroke, but only when the user issues the Reparse command to the editor. The time 
neces- sary for updating the graphical views depends on how drastic were the changes to the Text view. 
By and large, changes that do not involve creating new components happen almost instantaneously, whereas 
complex editing involving the creation of new components may take several seconds for large dialogs. 
Selecting an item in the Graphics view is done in the obvious way: click on an object. Mouse commands 
exist for traversing the hierarchical structure of the Graphics, either to change the selected object, 
or to extend or contract the selection. In particular, it is pos- sible (and useful) to select objects 
without selecting their children. For example, one might select (in order to delete or replace) a box 
or the border of an object. The simplest and most common type of editing in the Graphics view is to modify 
the properties of an existing component. One does this by double-clicking on the component. This causes 
a dialog to be popped up showing all the properties of that component. Figure 5 shows the dialog for 
editing the properties of a Numeric interactor.   "~..~SIGG RAPH '89, Boston, 31 July-4 August, 1989 
 Border VBox~j HBox Glue Glue H ox Boolean G ue HBox /\ 1 /1\ Fill Text Fill VBOX Fill Radio Text Fill 
HBox Fill Button Fill Bu~on Fill 1 /\ I I HBox HBox Fill VBox Text Border Glue Border Border /l\ /1\ 
1 I l HBox Text Fill Text Fill Numeric HBox Choice Choice Typeln Text Text /1\ /\ 1 1 Text Fill Numeric 
Text Fill HBox HBox  /\ /\ Text Bitrnap rext Bitfnap Figure 7: Parse tree corresponding to the Mail 
Configuration dialog box of Figures 1, 2, and 5. 6.1 The Text View The text view module is designed 
to make use of an external edi- tor running as a separate process. It can also be configured to use an 
internal editor, built from the text-editing tools in our toolkit, but users generally prefer to edit 
text with the editor they normally use. So we connect to an external text editor, using pipes or any 
other inter-process communication mechanism that may be avail- able. This editor must provide us at least 
the ability to read and to change the current contents of its buffer, and to add a user com- mand, Reparse, 
which will notify the two-view editor process when it is invoked. It is highly desirable that we also 
have access to the "modified" flag, so dialog-view edits can be locked out when the text is in a modified 
state. The use of an external editor has significant consequences for our design. To reparse the full 
text, and thus fully rebuild the contents of the other views, would be too slow to be acceptable. What 
we want is to translate textual changes into the smallest possible changes to the parse tree, which in 
turn will lead to the smallest disruption in the other views. This task would be much easier if we could 
find out, at the time of a Reparse, what regions of the text have been modified since the last Reparse. 
However, many editors, including the one we use in our working environment, do not maintain such information 
or do not make it available to clients. Our approach is to take the entire modified text and compare 
it with the old version, computing the differences. For an application with huge volumes of data, such 
as a document editor, this strategy would be prohibitively time-consuming. However, because there seems 
to be a natural limit to the useful size and complexity of di- alogs (roughly 5K, in our description 
language), full-text compari- son is feasible. The strategy is centered around the use of a character 
array con- taining the text and a token stream describing it. Our lexical ana- lyzer makes a complete 
pass through the text, discovering tokens and storing them in an array. Each token contains three indices 
into the character buffer describing the beginning of whitespaee prior to the token, the beginning of 
the token itself, and the end of the token, 144 as well as other information useful to the parser. The 
parse tree, in turn, contains information linking it to the token stream. Each node contains a count 
of all the tokens in the expression describing it and its children. It is thus a simple tree-walking 
computation to find a node from a token index, or a token index from a node. A character buffer and token 
stream corresponding to the cur- rent parse tree are stored at all times. When a Reparse command is given, 
a new character buffer and token stream are created corre- sponding to the new text. (We refer to a token 
stream together with its character buffer as a generation.) Then we compare the two to- ken streams, 
using a modified form of Heckel's algorithm [8]. This algorithm finds an island of certainty of matching 
wherever it finds a token that occurs exactly once in each view. These islands are expanded forward and 
backward as long as corresponding adjacent neighbors continue to match. We end up with each token in 
the old and new generations marked as Matched or Probable, with an in- dex linking it to the corresponding 
token in the other generation, or marked as Unmatched. Groups of adjacent Unmatched tokens are noted 
as cores of difference. The next phase of the algorithm examines each core of differ- ence in turn to 
see what change it represents. The simple regu- larity of s-expressions serves us very well here--it 
is easy to ex- pand a core to include a complete expression (or several neighbor- ing subexpressions) 
by looking for a surrounding pair of matching parentheses. During this expansion we determine the actual 
status of Probable tokens in that vicinity. The cross-link fields of adjacent Matched or Probable tokens 
allow us to find the corresponding point or region in the other token stream. Given this we can compute, 
a tree-transforming operation. The core in the old generation can be mapped to one or more nodes in the 
parse tree. The core in the new generation is parsed (a much smaller task than a full-text parse) to 
generate one or more new nodes. Thus we have the specification for an add, delete, or replace operation 
on the parse tree. When all differences have been translated into parse tree operations, we then perform 
them, yielding an updated parse tree and updated Graphics and Result views.  ~1 ~ Computer Graphics, 
Volume 23, Number 3, July 1989 Responding to edits in the Graphics view, we must translate changes in 
the other direction. The parse tree module calls the Text view, describing the change in terms of parse 
tree nodes. Using the token count information, we can map from a node to a sequence of tokens in the 
current token stream. Using the character indices stored in tokens, we can determine the number of characters 
in each token, and thus determine the group of characters in the text view that will need to be replaced. 
For newly introduced nodes, we tra- verse each node and its descendants and synthesize new tokens and 
text to correspond to them. New tokens are inserted at the appropri- ate point in the token array; new 
text is added at the end of the char- acter buffer, for simplicity. White space is generated by a simple 
algorithm. Once the new text is available, we perform a replace- ment of the relevant region of text 
in the editor buffer, to produce an updated text view. The strategy for comparing token streams interacts 
well with prettyprinting. Although newly generated text is unformatted and quite difficult to read, the 
user can invoke a prettyprinter or clean it up as desired. And since tokens are compared based on their 
con- tent and not on the associated white space, an ensuing Reparse will generate no updates at all to 
the parse tree. 6.2 The Result View The Result view displays the dialog as it would actually appear 
at runtime, with the proper size and stretchability characteristics. No editing is supported; instead, 
the interactors respond to mouse ac- tions with the same interactive feedback they would give at run- 
time. (Of course, nothing further happens because no application code is invoked.) The Result view changes 
in response to parse tree changes initiated by the other views. The Result view is closely associated 
with the parse tree. For each node in the parse tree, there is a VBT in the Result view. A field of the 
node points to the VBT, and to each VBT we attach a pointer to the corresponding node. When a parse tree 
transforma- tion takes place, it is reported to all the views in terms of nodes; the pointers allow us 
to find the VBTs involved. Where a new node has been introduced (having no associated Result view VBT), 
we cre- ate the corresponding VBT structure using the same method used to initialize a dialog at runtime, 
and then add it as a new child of the appropriate parent VBT. 6.3 The Graphics View The Graphics view 
resembles the Result view in its implementation, but with some added complications. Where the Result 
view trans- lates the parse tree directly into a tree of VBTs, the Graphics view adds a border around 
each VBT, thus making all levels of structure explicitly visible and accessible. The Graphics view also 
intercepts all mouse actions and translates them into editing operations, rather than allowing them to 
be received by the interactors. The Graphics view editor uses the parse tree as its underlying data structure. 
All selections are represented in terms of nodes in the parse tree, and all editing actions are executed 
directly as trans- formations on that tree. User actions, expressed by clicking and dragging with the 
mouse, are mapped to the indicated VBTs; these are translated into nodes using pointers that were stored 
when the VBTs were created. Editing actions lead to tree transformations, such as direct re-placement 
of a node (a flew object is dragged onto an interactor), adding a child to a node (a new object is dragged 
into an HBox or 7Box), inserting a level into the tree (an existing object is given a Border, for example), 
or deleting one or more levels (a Border is deleted). After the tree transformation has taken place, 
the parse tree module notifies each of the views, including the Graphics view itself. The Graphics view 
updates its appearance in response to this notification, just as it would if the change had been initiated 
from the Text view. The updating process is the same as for the Result view, except that new VBTs are 
given borders. 7 Future Work A feature we intend to add is a restricted form of macros. Cur-rently our 
extensibility mechanism allows one to add new interac- tors by programming, but macros could provide 
a way to create new component classes derived from existing classes, simply by writing a definition within 
the FormsVBT language. For example, if one frequently uses black-bordered buttons 60 pixels wide, one 
might write: (Define (Button60 name label) (Border (Width 60) (Button ~name (Text label)))) It is tempting 
to replace the FormsVBT descriptive "little" lan- guage with a general-purpose programming language (LISP 
is an obvious choice), but the additional expressiveness beyond the macros we do plan to implement does 
not seem warranted for di- alog layout. Also, using a general-purpose programming language would complicate 
two-view editing significantly. Another goal is to add dynamic loading to FormsEdit. At present, the 
language is extensible, but FormsEdit can handle only those components whose implementations have been 
linked into it. To handle extensions, it must be relinked. However, if it is told what object modules 
are needed to implement the extensions (perhaps by a preamble to the dialog description), then with dynamic 
loading it could bring in those modules, whose initialization procedures will add the necessary definitions 
to the language. By this mechanism, in fact, simple applications could be entirely loaded into the editor 
and tested, using the Result view as a rapid prototyping testbed.  8 Conclusions The work we have described 
here was initiated by our desire to make it as easy to get graphical input within a dialog framework 
as it is to get textual input today (say, by using scanf in C). And indeed, the programming interface 
to FormsVBT has led to surpris- ingly simple programs. For simple types of interactions (integers, reals, 
strings, choices, booleans), the application is only slightly more complicated than it would be if written 
using ~ca.nf, and it has a much nicer user interface with much better typechecking of the input. The 
FormsVBT language has proven to be expressive and well suited to dialog construction. Even before the 
Graphics view was functional, we were usually able to construct user interfaces more rapidly with ForrnsVBT 
than with a pure direct-manipulation ed- itor we had been using. Its advantages were particularly striking 
whenever modifications were needed to a large collection of inter- ators, and wherever regular sizing, 
spacing, or alignment of several related components was desired. By using a layout model similar to TEX, 
it is easy to describe complex tiling configurations without '89, Boston, 31 July-4 August, 1989  
 c~SIGGRAPH getting bogged down in the details, and with simple and predictable positioning and stretching 
properties. Being based on symbolic expressions, the language is simple to learn and can be easily extended 
to accommodate new build- ing blocks. Not only the language, but also the two-view editor, is entirely 
independent of the specific set of building blocks pro- vided (except the few that the Graphics view 
uses in its own user interface), and would merely require relinking to support new con- tributions to 
the set. Because the language provides a level of separation between the application and the actual building 
blocks used, it would be straight- forward to provide a different set of building blocks, accessed by 
the same syntax but based upon an entirely different window sys- tem (or different toolkit in the same 
window system. Thus it can be a tool for enhancing portability of applications, and particularly of their 
user interfaces. (As with most UIMS, FormsVBT can also be viewed a mechanism to both give a single application 
multi- ple "looks and feels" as well as to provide a single "look and feel" across multiple applications.) 
The ability to store and retrieve a dialog's values provides an at- tractive alternative to many existing 
"'configuration'-type files (now stored either as a binary version of a data structure, or in an arbitrary 
text file). It removes entirely the need for the programmer to design and support a special file format. 
When we set out, it was open to question whether a two-view editor for'building user interfaces might 
combine the disadvan- tages of the two editing approaches rather than the advantages. Now, even with 
only preliminary experience, we are no longer wor- ried: FormsVBT appears to combine the advantages of 
the two approaches while eliminating the disadvantages of each approach. With more experience and with 
some understanding of why users prefer which view for what purposes, we hope to learn just how much of 
an advantage the multi-view editing paradigm provides, and gain some insight as to what other domains 
may benefit from this approach. Acknowledgements Many of the interactors we use were developed by Luca 
Cardelli as part of his DialogEditor project here at SRC, Thanks to Greg Nelson and Mark Manasse, who, 
unknowingly, made our implementation job much easier than it would have been had we been using any other 
window system with which we're familiar. Thanks also to Luca, Paul McJones, and John Hershberger for 
feedback on earlier drafts of this paper. References [1] Interface Builder. NEXT, Inc., Palo Alto, CA. 
[2] Prototyper. SmetherBarnes, Portland, OR. [3] Paul J. Asente. Editing Graphical Objects Using Procedu- 
ral Representations. PhD thesis, Dept. of Computer Science, Stanford University, Stanford, CA, 1987. 
Also available as Research Report #87/6 from DEC Western Research Labora- tory, 100 Hamilton Avenue, 
Palo Alto, CA 94301. [4] Jon Bentley. Little Languages. Communications of the ACM, 29(8):711-721, August 
1986. [5] Kenneth P. Brooks. A Two-view Document Editor with User- definable Document Structure. PhDthesis, 
Dept. of Computer Science, Stanford University, Stanford, CA, 1988. Also avail- able as Research Report 
#33 from DEC Systems Research Center, t 30 Lytton Avenue, Palo Alto, CA 94301. [6] Luca Cardelli. Building 
User Interfaces by Direct Manipu- lation. In Proc. ACM SIGGRAPH Syrup. on User lntelface Software, pages 
152-166, October 17-19 1988. [7] H. Rex Hartson and Deborah Hix. Human-Computer Inter- face Development: 
Concepts and Systems. ACM Computing Surveys, 21(1):5-92, March 1989. [8] Paul Heckel. A Technique for 
Isolating Differences Between Files. Communications of the ACM, 21(4):264-268, April 1978. [9] Mark A. 
Linton, John M. Vlissides, and Paul R. Calder. Com- posing User Interfaces with InterViews. IEEE Computer, 
22(2):8-22, February 1989. [10] Mark S. Manasse and C. Greg Nelson. A Performance Anal- ysis of a Multiprocessor 
Window System. Technical Report, DEC Systems Research Center, Palo Alto, CA, (to appear). [11] Paul R. 
McJones and Garret F. Swart. Evolving the UNIX System Interface to Support Multithreaded Pro-grams. In 
Proc. Winter 1989 USENIX Technical Conference, pages 393--404, USENIX Association, Berkeley, CA, 1989. 
[12] Brad A. Myers. User-Interface Tools: Introduction and Su- very. IEEE Software, 6( 1): 15-23, January 
1989. [13] Greg Nelson. Juno, a constraint-based graphics system. Com-puter Graphics, 19(3):235-243, 
July 1985. [141 Paul Rovner. Extending Modula-2 To Build Large, Inte- grated Systems. IEEE Software, 
3(6):46--57, November 1986. [15] Andrew J. Schulert, George T. Rogers, and James A. Hamil- ton. ADM -A 
Dialog Manager. In Proc. ACM S1GCHI "85 Conf. on Human Factors in Computing Systems, pages 177- 183, 
April 1985. [16] Charles P. Thacker, Lawrence C. Stewart, and Edwin H. Sat- terthwaite Jr. Firefly: A 
Multiprocessor Workstation. IEEE Transactions on Computers, 37(8):909-920, August 1988. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74348</article_id>
		<sort_key>147</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Scan line display of algebraic surfaces]]></title>
		<page_from>147</page_from>
		<page_to>156</page_to>
		<doi_number>10.1145/74333.74348</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74348</url>
		<abstract>
			<par><![CDATA[A robust algorithm is presented for scan line display of algebraic surfaces of arbitrary degree and topology. The algorithm correctly displays singularities of any complexity, even those missed by ray tracing or polygonization, and (for surfaces of degree less than eight) offers a significant speed improvement over ray tracing. Antialiasing can generally be accomplished very quickly. In addition to its typical function of shaded raster display, the algorithm is particularly adept at quickly plotting silhouette and intersection curves. A practical use for the algorithm is to display boolean combinations of algebraic half spaces, including blend surfaces.A new polynomial basis is introduced, referred to as the Bernstein pyramid polynomial basis, which enhances numerical stability and which simplifies several computations such as scan planesurface intersection and silhouette detection.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.5</cat_node>
				<descriptor>Polynomials, methods for</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003739</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Nonlinear equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P281616</person_id>
				<author_profile_id><![CDATA[81100400673]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Sederberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Engineering Computer Graphics Lab, Brigham Young University, Provo UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P12914</person_id>
				<author_profile_id><![CDATA[81100036550]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Zundel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Engineering Computer Graphics Lab, Brigham Young University, Provo UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801152</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arnon, D.S., Topologically reliable display of algebraic curves, Computer Graphics, 17, 1983, 219-228.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arnon, D.S. and Rauen, J., On the display of cell decompositions of algebraic surfaces, XEROX Technical Report, 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J., Polygonization of implicit surfaces, Computer Aided Geometric Design, 5, 1988, 341-355.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bradshaw, C.B., Surfaces of functions of three variables, M.S. Thesis, Department of Civil Engineering, Brigham Young University, 1982.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>19624</ref_obj_id>
				<ref_obj_pid>19619</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Farouki, R.T., The characterization of parametric surface sections, Computer Vision, Graphics and Image Processing, 1986, 33, 209-236.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>43650</ref_obj_id>
				<ref_obj_pid>43647</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Farouki, R.T. and Rajan, V.T., On the numerical condition of polynomials in Bernstein form, Computer Aided Geometric Design, 4, 1987, 191-216.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>47425</ref_obj_id>
				<ref_obj_pid>47424</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Farouki, R.T. and Rajan, V.T., Algorithms for polynomials in Bernstein form, Computer Aided Geometric Design, 1988, 5, 1-26.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61954</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Farin, G., Curves and Surfaces for Computer Aided Geometric Design, Academic Press, 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Goldman, R.N., Sederberg, T.W. and Anderson, D.C., Vector elimination: A technique for the implicitization, inversion, and intersection of planar parametric rational polynomial curves, Computer Aided Geometric Design, 1, 1984, 327-356.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hall, M. and Warren, J., Adaptive tessellation of implicitly defined surfaces, Rice COMP TR88-84, 1988, Rice University.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801136</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., Ray tracing algebraic surfaces, Computer Graphics, 17, 3, 1983, 83-90.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hoffmann, C.M. and Hopcroft, I.E., Automatic surface generation in computer aided design, The Visual Con~outer, 1, 1985, 95-100.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lane, J.M. and Riesenfeld, R.F., Bounds on a polynomial, B/T, 21, 1, 1981, 112-117.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mahl, R., Visible surface algorithms for quadric patches, IEEE Transactions on Computers, C.21, 1, 1972, 1-4.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325231</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Middleditch, A.E. and Sears, K., Blend surfaces for set theoretic volume modeling systems, Computer Graphics, 19, 1985, 161-170.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Owen, J.C. and Rockwood, A.P., Intersection of general implicit surfaces. In Geometric Modeling: Algorithms and New Trends, G. Farin, editor, SIAM, Philadelphia, 1987, 335-346.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Patrikalakis, N.M. and Kriezis, G.A., Piecewise continuous algebraic surfaces in terms of B-splines, MITSG 88-5, Massachusetts Institute of Technology, August 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Petersen, C.S., Adaptive contouring of three-dimensional surfaces, Computer Aided Geometric Design, 1, 1984, 61-74.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Rockwood, A.P. and Owen, J.C., Blending surfaces in solid modeling. In Geometrk: Modeling: Algorithms and New Trends, G. Farin, editor, SIAM, Philadelphia, 1987, 335-346.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Salmon, G. Analytic Geometry of Three Dimensions, Longmarts, Green and Co., 1912.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T.W., Piecewise algebraic surface patches, Computer Aided Geometric Design, 2, 1985, 53-59.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>18559</ref_obj_id>
				<ref_obj_pid>18548</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T.W. and Parry, S.R., Comparison of three curve intersection algorithms, Computer-Aided Design, 18, 1, (1986), 58-63.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>69179</ref_obj_id>
				<ref_obj_pid>69177</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T.W., An algorithm for algebraic curve intersection, to appear in, Computer-Aided Design.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T.W., Spencer, M.R. and de Boor, C., Real root approximation of polynomials in Bernstein form, in preparation.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>66827</ref_obj_id>
				<ref_obj_pid>62847</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Tindle, G.L., Tetrahedral triangulation, in, R.R. Martin, ed., The Mathematics of Surfaces H, Clarendon Press, Oxford, 1987, 387-394.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15253</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Warren, J.D., On algebraic surfaces meeting with geometric continuity, Ph.D. Thesis, Cornell University, 1986.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321330</ref_obj_id>
				<ref_obj_pid>321328</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Weiss, R.A., BE VISION, A package of IBM 7090 FOR- TRAN programs to draw orthographic views of combinations of plane and quadric surfaces, JACM, 13, 2, 1966, 194-204.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Zundel, A.K., Scan line rendering of algebraic surfaces and half spaces, M.S. Thesis, Department of Civil Engineering, Brigham Young University, 1989.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Scan Line Display of Algebraic Surfaces Thomas W. Sederberg Alan K. Zundel Engineering Computer Graphics 
Lab Brigham Young University Provo UT 84602 Abstract A robust algorithm is presented for scan line display 
of algebraic surfaces of arbitrary degree and topology. The algorithm correctly displays singularities 
of arty complexity, even those missed by ray tracing or polygonization, and (for surfaces of degree less 
than eight) offers a significant speed improvement over ray tracing. An- tialiasing can generally be 
accomplished very quickly. In addi- tion to its typical function of shaded raster display, the algorithm 
is particularly adept at quickly plotting silhouette and intersection curves. A practical use for the 
algorithm is to display boolean com- binations of algebraic half spaces, including blend surfaces. A 
new polynomial basis is introduced, referred to as the Bern- stein pyramid polynomial basis, which enhances 
numerical stabil- ity and which simplifies several computations such as scan plane- surface intersection 
and silhouette detection, CR Categories and Subject Descriptors: G.1.5 [Numerical Analysis]: Roots of 
Nonlinear Equations - Polynomials, methods for; 1.3.3 [Computer Graphics]: Picture/Image Generation - 
Dis-play algorithms; J.6 [Computer-Aided Engineering]: Computer- aided design. Additional Key Words and 
Phrases: Algebraic surfaces, blend surfaces.  INTRODUCTION An algebraic surface is one which is given 
by an implicit equa- tion f(x, y,z) = 0 where f(x, y, z) is a polynomial. Interest is growing in the 
use of algebraic surfaces for geometric modeling. Notable examples include the use of algebraic surfaces 
for blend- ing between other algebraic surfaces [12, 15, 19,26] and schemes for modeling free-form objects 
directly with algebraic surfaces [17,21]. This trend motivates the need for robust solutions to the problem 
of computer graphics display of algebraic surfaces. The topology of a general algebraic surface can be 
very difficult to analyze. Indeed, no current algorithm can robustly display Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. all singularities and topological 
components of a general algebraic surface. (Arnon's algorithm [2] under current development is an exception.) 
Even ray tracing can miss components such as double lines 1 . This paper presents a robust scan line 
algorithm for displaying algebraic surfaces. It works directly from the implicit equation of the surface, 
without splitting it into polygons. The algorithm gains its robustness by relying on the algebraic tools 
of resultants and dis- eriminants, reducing all questions of visibility, topology and singu- larity to 
univariate polynomials in the Bernstein basis. The algo- rithm is equally robust in its display of boolean 
combinations of algebraic half spaces. An early version of this algorithm was used to create the pic- 
tures of cubic algebraic surfaces in reference [21]. No discussion of the rendering algorithm was made 
in [21] because power basis polynomials were involved and problems with numerical accuracy were experienced 
for quartic (and higher degree) surfaces, espe- cially in the presence of singularities. These floating 
point prob- lems were remedied by basing the algorithm entirely on Bernstein polynomials, which are much 
more numerically stable than power basis polynomials. The remarkable numerical stability of polynomials 
in Bernstein form has been thoroughly discussed by Farouki and Rajan [6,7]. It was also documented in 
[22] that in computing the intersection points of planar curves using algebraic methods, cases occurred 
in which the intersection algorithm produced zero digits of accuracy when analyzing two degree five curves 
expressed in power basis polynomials. The same problem expressed in the Bernstein basis yielded ten digits 
of accuracy. This paper assumes a basic familiarity with B~zier curves and surfaces. An excellent review 
is [8]. 1.1 Previous work Previous publications on the general problem of rendering alge- braic surfaces 
take three basic approaches: Direct computation of silhouette points using discriminants, ray tracing, 
and polygoniza- tion. The earliest algorithm for computer graphics display of alge- braic surfaces, Weiss' 
BE VISION, appeared over two decades ago [27]. BE VISION plotted the silhouette and intersection curves 
for a boolean eornbinatlon of quadrie surfaces and planes, computing these curves directly using discriminants 
and resultants. Mahl used 1See, for example, lhe Steiner surface in Figure 6 with its three double lines 
which avoid detection by ray tracing &#38;#169;1989 ACM-0-89791-312-4/89/007/0147 $00.75 147  ~~SIGGRAPH 
'89, Boston, 31 July-4 August, 1989 similar techniques in developing a scan line algorithm for shaded 
images of quadrie surfaces [14]. Owen and Rockwood have used a related approach, but instead of finding 
silhouette points by com- puting discriminants (a univariate polynomial problem), they in- tersect the 
surface with its polar surface (see section 4 herein) at each scan plane by solving two polynomials in 
two unknowns [16]. They had good success with this method, although for algebraic surfaces of unknown 
topology it would be difficult to assure that all silhouette points had been computed. Hanrahan showed 
that algebraic surfaces lend themselves well to ray tracing [ 11 ]. The ray-surfac#intersection equation 
is reduced to a univariate polynomial of the same degree as the surface. Draw- backs include speed and 
difficulty in displaying some singularities. Polygonization algorithms approximate an algebraic surface 
with a set of polygons, which can then be rendered using tradi- tional methods. An early such algorithm 
is described in [4], and has been included in the MOVIE.BYU software since 1983. It samples f(:r, y, 
z) function values over a three dimensional rect- angular grid of points and linearly interpolates polygons 
in regions where the function values change sign. Figures 11-13 in this paper were created using this 
algorithm. More recently, Tindle [25] based a similar polygonization algo- rithm on a tetrahedral subdivision 
of space. Nice improvements are discussed by Bloomenthal [3] and Hall and Warren [10] involving an adaptively 
refined sample grid to generate more polygons in re- gions of greater surface complexity. These algorithms 
are excellent for most cases, but can miss singularities and small, unwanted com- ponents. Petersen takes 
advantage of special polynomial properties in his adaptive polygonization scheme for algebraic surfaces 
[18]. Arnon [2] is addressing the singularity problem by applying the cylindrical algebraic decomposition 
algorithm [ 1] to obtain a poly- gonization which does not have gaps at singularities and which is topologically 
correct. A virtue of polygonization algorithms is that they work on any implicit surface, not just on 
algebraic ones. Also, they interface well with existing polygon rendering systems. A current limitation 
is that none of the existing papers address the polygonization of boolean combinations of algebraic half 
spaces. This is akin to the singularity problem, because tangent discontinuity occurs where surfaces 
intersect. 1.2 Paper Outline The major steps in our algorithm are surveyed in section 2. We mentioned 
that the Bernstein polynomial basis is essential for ro- bust computation of silhouette points for surfaces 
of degree greater than three. A problem of trivariate polynomials in Bernstein form is that they can 
be very awkward and expensive to manipulate. This problem is addressed in section 3, wherein a new variation 
of trivariate Bernstein polynomials is introduced, dubbed Bernstein pyramid polynomials, which lend themselves 
ideally to the ren- dering problem. Silhouette computation is described in section 4. Section 5 discusses 
how to convert from power polynomial basis to Bemstein pyramid basis. Implementation details are provided 
in section 6, and section 7 gives some examples and makes timing comparisons with ray tracing. 2 ALGORITHM 
OVERVIEW We here provide a brief overview of our scan line algorithm. De- tails follow in subsequent 
sections. 148 A key feature of our algorithm is its robust, numerically sta- ble capability of quickly 
computing critical points. Critical points along a scan line consist of the x coordinates of all silhouette 
points and surface intersection points. Surface intersection points can be generated by two surfaces 
involved in a boolean operation, by a sur- face and a z clipping plane, or by a surface intersecting 
itself. The importance of critical points is that they define changes in visibility: between two critical 
points, the same surface is continuously visi- ble. This enables our scan line algorithm to operate several 
times faster than a ray tracing algorithm. Figure 7 shows a partially painted sphere along with the silhou- 
ette points of the unpainted portion, and Figure 9 shows the sphere within its viewing pyramid (ignore 
the control points for now). On the next scan line to be painted, there are two critical points (in ad- 
dition to x = 0 and x = 1, which are always critical points). The intersectioncurve between the scan 
plane and the sphere is shown in Figure 1. The critical points are marked with a symbol V. The shading 
for that entire scan line can be determined by performing a small number of ray-surface intersections 
-three, in this case. Be- tween each pair of critical points, an "exploratory" ray is cast (see Figure 
2). If no surface is intersected (as in rays 1 and 3 in Fig- ure 2), all pixels in the interval between 
those two critical points are painted with background color. If a surface is intersected (as in ray 2), 
then rays are cast every ten or twenty pixels within that interval (see Figure 3) to determine shading 
values, and the color of intermediate pixels is assigned by interpolation. This underscores the need 
for numerical stability: Ifa single crit- ical point is overlooked, an entire interval of pixels will 
be in er- ror. Using power basis polynomials, it is possible for the silhouette computation to be completely 
wrong (zero digits of accuracy) for surfaces of degree as low as five. Furthermore, some algebraic surfaces 
have extremely compli- cated critical points. Consider the Steiner surface in Figure 6. This surface 
has three double lines, one along each of the Cartesian co- ordinate axes. Since a double line has no 
thickness, each scan plane that intersects a double line creates two coincident critical points. By using 
the Bernstein polynomial forms described below, our al- gorithm can robustly (and more quickly than ray 
tracing) display the Steiner surface, double lines and all. It should be noted that [11] rendered the 
same Steiner surface with ray tracing, but failed to detect the double lines. 3 BERNSTEIN PYRAMID BASIS 
Most commonly, the equation of an algebraic surface is given in power basis with Cartesian coordinates: 
f(X,Y,Z) = E xiYYZ~co~ =0 (1) i+j+k_<n As will be shown, there are compelling advantages for our ap- 
plication to instead express the equation of an algebraic surface in terms of a new variation of trivariate 
Bernstein polynomials which we will refer to as the Bemstein Pyramid'Polynomial (BPP) basis. The BPP 
(x,y,z) coordinate system might be referred to as apro-jective eye coordinate system. It is actually 
defined by the viewing pyramid. The z coordinate of the viewing plane is zero and the z coordinate of 
the eye is one. The ( z, y) coordinates range from (0,0) in the lower left comer to (1,1) in the upper 
right comer. All points on any line going through the eye position have the same (x, y) coordinates, 
except the ( z, y) coordinates of the eye are not defined. Formulae for converting from BPP coordinates 
to Carte- sian coordinates are given in equations 16 -18. Notation: We will use upper case (X,Y,Z) for 
Cartesian coordi- nates and lower case (x,y,z) for BPP coordinates. A degree npolynomial in BPP form 
is defined: f(z,y,z) 1=0 i=0 (1 -- z)'~--k z~( 1 -- y)n-~-i yi ( 1 -- x)n-~-i xi fqk Two pieces of information 
are required to define a surface in BPP form: The Cartesian coordinates of the pyramid vertices P000, 
Pn0o, P0n0, P00n (see Figure 4) and the scalar coefficient values fiik (see Figure 5). Unlike the coefficients 
of power basis implicit equations, the BPP coefficients fi;k can be thought of as control point values 
positioned in a regular lattice about the pyramid as shown in Figure 5. The position of coefficient fij~ 
is denoted Pii~ where Pil~ = n-i -j -k P000+ 2_pn0  +~-Po~0 + k-P00~; i+j+k < n 'rl. "r/, (3) Figure 
9 shows a sphere in BPP form. Parenthetical point of Interest: Unlike the power basis, the BPP coefficients 
fqk assume some geometric meaning Each con- trol point fiik influences the function f( x, y, z) most 
heavily in its immediate neighborhood. Thus, there is some amount of geometric intuition connected with 
these control points, making it possible to anticipate the shape of simple BPP surfaces by considering 
the val- ues of the control points. This property is reminiscent of piecewise algebraic surfaces, a discussion 
of which can be found in [21[. 3.1 Degree and Redundancy Section 5 discusses how to convert the power 
basis equation of an algebraic surface into BPP form. A degree n surface in power basis converts to a 
degree nBPP equation. However, there is some redundancy in the BPP equation. A degree npower basis equation 
has (n + 1)(n + 2)(n + 3)/6 terms, whereas a degree n BPP equation has (n+ 1)(n+ 2)(2n+ 3)/6 terms The 
redundancy is due to the fact the a general BPP equation of degree n converts to a very special case 
of a power basis equation which is degree 3n. However, if a degree n power basis equation is converted 
to BPP form, the terms in the BPP equation of degree higher than n would cancel out if the equation were 
converted back to power form. This redundancy actually facilitates the quick set up critical point equations. 
We investigated all existing forms of trivariate Bern- stein polynomials (such as the tetrahedral "pure 
degree" case used in [21], which does not involve redundancy) and discovered that the silhouette equations 
are tremendously awkward and expensive to set up using those existing forms. That awkwardness motivated 
the development of BPP form.  4 SILHOUETTE DETECTION with respect to the eye position [20]. A sphere 
and its polar sur- face are shown in Figure 8, along with the viewing pyramid. For a degree n surface 
defined in homogeneous power basis: F(X,Y,Z,W) = ~ x~yiz~wIFijkl = 0 (4) i+ j+ k+ l=n its polar surface 
P(f) is degree n --1 and is given by: P(f) = Xev,fx + Y, vcfr + gcv,fz + Wcvefw. (5) Recall that the 
homogeneous coordinates (.X, Y, Z, W) are equivalent to the Cartesian coordinates (X/W, Y/W, Z/W). Therefore, 
Were = 0 for orthographic views (eye at o) and 1 oth- erwise. It turns out that the polar of a degree 
n BPP surface is trivial to compute 2 . Figure 9 shows the control points for the sphere, and Figure 
10 shows the control points for its polar. Note that the con- trol points for the polar are identical 
to the control points of the sphere, except the first plane of control points is discarded. It is simply 
a BPP surface of degree n -1 which is obtained by dis- carding the first plane of control points (the 
white control points). Figures 11-13 show a torus with its polar surface, the control points for the 
toms and the control points for its polar. We could not label all of the control point values, but emphasize 
that the polar of any algebraic surface in BPP form has the same control point values as the surface 
itself except that all control points lying on the viewing plane are discarded. Thus, in the case of 
the torus, its polar is obtained by eliminating the plane of light blue control points.  4.1 Discriminants 
and Resultants The intersection curve of two surfaces f( x, y, z) = 0 (degree n) and g(x, y, z) = 0 (degree 
m) can be projected to the plane z = 0 by computing the resultant of the two surfaces Essentially, the 
re- sultant eliminates the variable z from the two equations f(x, y, z) and g(x, y, z), creating a two 
dimensional curve h(x, y) = 0 of degree tara Any point (x, y, z) which lies on the intersection of the 
two surfaces projects to a point (x, y, 0) on the z = 0 plane which lies on the curve h(x, y) = 0. The 
resultant of a surface and its polar is called the discriminant of the surface. For our purposes, the 
discriminant is a curve in the viewing plane (that is, the z = 0 plane) which contains all of the silhouette 
points. The two most commonly used resultants are Bezout's and Sylvester's. Bezout's is most efficient. 
Here we spell out the details of Bezout's resultant for surfaces up to degree four. Don't despair of 
the following cold equations; there is an example in section 4.3. For a thorough discussion on how to 
apply Bezout's resultant to polynomials in Bernstein form of higher degree, see [7,9] In order to form 
the resultant, we must group the terms of the BPP equations such that f(x, y, z) and g(x, y, z) are univariate 
polynomials in z with coefficients that are polynomials in x and y. Thus, write A fundamental task in 
our display algorithm is to compute the sil- n f( z,y,z) = ~( 1 - z)~i z~ fd z, y) (6) houette points 
of the surface This is a job for which BPP form is i=o perfectly suited. Classical analytic geometry 
teaches that silhouette points can be 2 The complete derivation of the polar of a BPP surface fills 
a couple of pages. computed as the intersection of the surface and its polar surface It is accomplished 
by expanding equation 5 in BPP form. '89, Boston, 31 July-4 August, 1989   ' , S,GGRAPH wh~e lid z, 
y) ( 1 -- x)~i-i xj( 1 -- y)~i-* Y*fi~i and 171 9(x, y, z) = E( 1 - z)'~-izigi(x, y) (7) i=O where 
0 )EE( ifrn<i<n ra-i m--i  (, ,)(.) 1=o k=o (1--x)~-i-i~/(1--y)m-i-ky~Ojki ifO <i<m Note that .,~(x, 
y) is a tensor product polynomial in Bemstein form whose coefficients are simply the coefficients of 
the i th plane of control points in its pyramid, scaled by (~.) (and likewise for gi(x, y)). Adopting 
Salmon's shorthand for a 2 x 2 determinant: (i, j) = Aoj -/jg,, the resultant of f and 9 (which we denote 
R(f,g)) for degrees n= 1,2,3,4 are as follows. n=l: R(f,g) = (1,0) (8) n=2: R(f,g) = ] (2,1)(2,0) [ 
(2,0) (1,0) (9) n=3: (3,2) (3, 1) (3,0) R(f,g)= (3,1) (3,0)+(2,1) (2,0) (lO)  (3,0) (2,0) (1,0) n=4: 
(4,3) (4,2) (4,1) (4,0) (4,2) (4,1)+(3,2) (4,0)+(3,1) (3,0) (11) (4,1) (4,0)+(3,1) (3,0)+(2,1) (2,0) 
(4,0) (3,0) (2,0) (1,0) R(f, 0) is a tensor product polynomial in Bemstein form, as in equation 12. 
4.2 Bernstein Polynomial Arithmetic For the sake of completeness, we include a brief discussion of Bernstein 
polynomial multiplication, needed to compute resultants and diserirninants. A more thorough treatment 
can be found in [7] (along with much other relevant material). Addition of two polynomials in Bernstein 
form of the same de- gree (the only case we encounter) is done by simply adding like coefficients. One 
Variable: Given two univariate polynomials in Bernstein form, i=0 9(0 = ( 1 - t)"-'t'9~ i=O 150 the 
coefficients hi of their product h(t) =f(t) xg(t) = ~ (1 i=0 can be found using the algorithm: h(i) 
= O; i=0,...,m+n. (?)(7/ h(i+j) = h(i+j) +-7~-f(i)O(J); (,+j) i = O,...,n; j = 0,...,m. Two Variables: 
Given two bivariate polynomials in tensor product Bernstein form, f(x,y)=~(:)(~.)(1--x)~ix'(1-V)~iV'f,y 
(12) i=o 1=o g(x'Y)= ~i--~o (7) the coefficients hli of their product o+--'-)( ) h(z,y) = i J x i=0 
1=0 ( 1 -- x) rn+n--ixi( 1 --y)m+~/yihQ.  can be found using the algorithm: h( i,j) = 0; i,j = 0,..., 
m + n. h(i+j,k+l) = h(i+j,k+l)+ (:) (9 (i+j (T++~) f( i,j)g( k, 1); i,k=O,...,rg ],l=O,...,m. BPP: While 
we're at it, here's how to multiply two trivariate poly- nomials in BPP form (as in equation 2). This 
is used in section 5. Given two polynomials in BPP form, f(x, y, z) (degree n, with coefficients fqt0 
and g(x, y, z) (degree m, with coefficients gq~), their product h(x, y, z) is a BPP of degree m + n with 
coefficients hiik computed as follows: h(i,y,k) = 0; k = 0,...,re+n; i,j = O,...,m+n-k. h(il + i2,jl 
+ j2,kl + k2) = h(il + i2,jl + j2,kl + k2) + ('~)( Jl )( q )(n )( J~ )(  _.w=.~,l_,2~C.._h_~ '2 )r 
j,Q,jl,kl)g(i2,j2,k2) XkI+~/X J1"12 /X flt2 / kl =O,...,n; il,jl = 0,...,n--kl; k2 = 0,...,m; i2,j2 
= 0,..., m-k2. 4.3 Example To illustrate how straightforward and algorithmic the resultant computation 
is, we demonstrate by computing the discriminant of a sphere whose implicit equation is -x 2 -y2 _ z 
2 + 1 = 0 (our convention is that points inside a half space have positive func- tion values). This example 
is simple enough that you can follow it through with by hand. We will use the sphere shown in Figure 
9 and its polar shown in Figure 10. Denote the equation of the sphere by f( x, y, z) and the equation 
of its polar by g(x, y, z). Then, using the definition of fi and gi from section 4.1, fo = [ y2 2y(1--y) 
(l--y) 2 ] --6 19 --6  --31 --6 --31 2x( 1 -- .~) ; (13) 2;2 (:) [ 14 14 ] ( 1--Z } fl = [ y (l--y) 
] 14 14 x f2 = --16 and for the polar, we have go = [ Y (l--Y) ] 14 14 x gt =-16; g2 =0. Substituting 
these equations for fi and gi into equation 9, and using the multiplication algorithm in section 4.2, 
the resultant R(f, g) = h(x, y) (which in this case is the discriminant of the sphere) is .R(f,g) = 25600 
x [ y2 2y(l --y) (I __y) 2 ] X 1 5 1 2x(1 --x) (15) --3 1 --3 ~2 There is a useful geometric interpretation 
of equation 15. It can be viewed as a biquadratic B~zier surface patch z = h(x, y). The intersection 
of this surface patch with the plane z = 0 is the dis- criminant (that is, silhouette) curve h(x, y) 
= 0. Figure 14 shows the surface z = h(x,y) (scaled by 1/25600), interpreted as abi- quadratic tensor 
product B6zier surface patch. POWER TO BPP CONVERSION Most algebraic surfaces in use in the computer 
aided geometric de- sign world are expressed in power basis (equation 1). A preprocess is required in 
our display algorithm to convert power basis equa- tions to BPP basis. The BPP equation is "view dependent" 
-it changes as the viewing pyramid changes. Pyramid to Cartesian Coordinate Conversion. We must first 
observe how to convert from pyramid coordinates (x, y, z) to ho- mogeneous Cartesian coordinates (X, 
Y, Z, W). We apologize for the slight complication of introducing the homogeneous variable W, but it 
really pays off shortly. We can simply set it to one and ignore it, except we will need to compute the 
partial derivative of F with respect to W. If the comers of the pyramid have the homogeneous Carte- sian 
coordinates P0oo = (Xo00, Yo0o, Z000,1), P,00 = (Xmo, Yloo, Zloo, 1), Po.o = (.Xom, Yore, Zorn, 1), P,,~.,o 
= (Xlm, YllO, Zi it, 1), Pot. = (Xool, Yool, Zool, l ), where P,.,o = P.oo + Po.o - Pooo, then 1--k l--k 
X(x,y,z) = EEE (1-z)l-kz~(1 _y)l-~-iyj k=o ]=o i=o ( 1 -- x) 1-k-ixiXqk (16) 1 1-k 1-k ( 1 z)l-~zk( 1 
--y)l-~-jyi k=O j=O i=O ( 1 x) l-'~-ixiY~j~ (17) 1 1-k 1--k : EEE ( 1 - z)l-~z~( 1 - y) 1-k-iyi k=0 j=O 
i=0 ( 1 - x) 1-~-ixiZo.k (18) W(x,y,z) = 1 (19) Note that X(x,y,z), Y(x,y,z) and Z(x,y,z) are degree 
one polynomials in BPP form that return Cartesian coordinates as func- tions of BPP coordinates (x, Y, 
z). Conversion algorithm. A succinct "high level" trick for con- verting fxom power basis to BPP basis 
(or to any other basis) can be derived from Euler's law for homogeneous polynomials as follows. F(X, 
Y, Z) (a power basis equation in Cartesian coordinates) can be converted to BPP form f( x, y, z) using 
the following recursive algorithm: f(z,y,z) = C2B(0,0,0,0) where the function C2B returns a polynomial 
in BPP form and is defined: FUNCTION C2B(i,), k, l) IFi+j + k+ 1= n, THEN t C2B = itjtktttFqh ELSE ~t 
C2B = [X(x,y,z) x C2B(i + 1,j,k,l) +Y(x,y,z) x C2B(i,j + 1, k3l ) + Z(x,y,z) x C2B(i,j, k + 1,l)+ C2B(i,j,k,l+ 
1)]/(n-i-j-k-l) ENDIF END C2B Some explanation is in order for statements I" and $. Recall that for/+./+ 
k+ l= n, O"F axiaYiOZ~OW l = i!j! k ! l! Fok. In C2B, the arguments i,j, k, l indicate how many times 
the func- tion F has undergone partial differentiation with respect to X, Y, Z and W respectively. We 
actually don't differentiate F at all, ex- cept to keep track that if it has been differentiated n times, 
it's equal to the constant i! j ! k ! l! Fqk; hence, statement t. Statement $ is where Euler's law comes 
in. Euler's law states that for a degree n homogeneous polynomial, X xFx+ Y xFr+ Z x Fz+ W xFw F(X,Y,Z,W) 
= where Fx, etc., indicates partial differentiation. Statement :~ is sim- ply the implementation of Euler's 
law: The  operator is BPP mul- tiply andX ( x, y, z), Y( x, y, z), Z( x, y, z) are the degree one BPP 
functions in equations 16-19. This conversion algorithm is not the most efficient, but it is easily implemented. 
151 ~~SIGG RAPH '89, Boston, 31 July-4 August, 1989 6 IMPLEMENTATION DETAILS 6.1 Critical Point Computation 
As a preprocess, the discriminant of each surface is computed. If boolean operations are performed, the 
resultant of each pair of in- tersecting surfaces is also computed. Recall that discriminants and resultants 
are tensor product poly- nomials of the form h(x,V)=~(~)(;)(1--x)n-lx'(1--V)"-.JV'h,/. (20) i=o i=o 
For each scan line V = Vs, each discriminant and resultant is eval- uated at V = Ya, producing in each 
case a univariate polynomial in Bernstein form. All roots of such a polynomial in the [ 0, 1] in- terval 
are critical points, and all critical points are roots of such an equation. Thus, the robustness of this 
rendering algorithm is due primarily to the robustness ofpolynomlal root finders. 6.2 Polynomial Root 
Finding The Bernstein polynomial basis is ideally suited to polynomial root finding [6]. lndeed, our 
rendering algorithm has proven to be an excellent test bed for the robustness of a root finder in Bemstein 
basis. We have refined a root finder which follows the lines suggested by Lane and Riesenfeld [13]. First, 
roots are isolated, using the variation diminishing property as a test for isolation. Isolated roots 
are refined using the modified regula falsi method. Additional en- hancements to handle multiple roots 
are discussed in [24]. In most cases, this root finder is much faster than global root finders such as 
the Jenkins-Traub algorithm. The root finder finds all roots in the unit interval, and none oth- ers. 
The roots are found in ascending order, and the root finder can optionally stop after finding the first 
root- ideal for r ay tracing. Co- herence is harnessed by using roots from preceding polynomials as starting 
points for Newton iteration. Robustness is then checked using the variation diminishing property. A good 
example of the robustness of our root finder is the Steiner surface in Figure 6. The critical points 
for this surface require the solution of a degree 12 polynomial at each scan line, each having three 
double roots and four single roots. 6.2.1 Degree limitations The degree of the discriminant grows quadratically 
with the degree of the surface. A degree 6 surface has a degree 30 discriminant. This is probably the 
practical limit for the solution of critical points using discriminants and univariate polynomials. For 
degree higher than 6, the answer is to use an algorithm for ro- bustly computing roots of two Bernstein 
form polynomials in two unknowns. Thus, silhouette points are found by evaluating the sur- face BPP equation 
and its polar BPP equation at V = V, (creating two Bernstein form polynomials in the unknowns x and z) 
and find- ing all solutions in the unit interval. Again, robustness is required, and again the Bernstein 
form comes to the rescue. The first author recently developed an algorithm for dealing with just that 
problem [23], and the algorithm does robustly find allsolutions and should in theory work for surfaces 
at least of degree 25. However, speed suffers dramatically as the degree rises. After about degree 8, 
raw ray tracing becomes just as fast, although we repeat that ray tracing can miss singularities which 
our algorithm won't. 152 6.3 Shading The reason our algorithm is generally much faster than ray tracing 
is that we don't need to fire a ray at each pixel. To get smooth shading, we have found it generally 
sufficient to fire rays every 15 pixels. Surface normals and shading values are obtained basically as 
in [11]. If there are no highlights, we simply interpolate colors between sample pixels. Otherwise, we 
interpolate the normals. The ray-surface intersection equation reduces to a univariate polynomial in 
Bernstein form whose roots are easily found using our Bernstein root finder. 6.4 Antialiasing Our algorithm 
can usually reduce aliasing to an acceptable level with little expense. Critical points are computed 
to floating point accuracy, and the slope of the silhouette curve is easily obtained. This makes it possible 
to obtain a good first order approximation to the percent of a pixel being filled by the silhouetting 
surface. Col- oring such a pixel using ratios so determined has worked nicely. All edges but those sloping 
less than about 5 degrees from the hor- izontal require no further antialiasing. 6.5 Boolean Operations 
The algorithm handles boolean operations efficiently. Figures 18- 20 show two intersecting tori. All 
of the critical points -silhou-ette (in yellow and blue) and intersection (in black) -are shown in Figure 
20. Figure 19 shows a partial picture of the boolean dif- ference of the toil, along with the remaining 
visiblecritical points. Note that the visible critical points are ultimately the only impor- tant ones. 
In between each pair of visible critical points, the same surface is visible. 7 EXAMPLES ANDTIMINGS Figure 
15 shows how our algorithm rendered a cone-cone blend due to Middleditch and Sears [15]. Figure 16 shows 
a degree 4 blend between two elliptical cylinders, from a paper by Hoffmann and Hopcroft [12], and Figure 
17 shows a cubic blend (that's right, it's not a torus) between two circular cylinders, devised by Joe 
Warren [26]. Figures 16 and 17 actually required several boolean opera- tions to trim away unwanted portions 
of surfaces. Figures 22 and 23 are degree four Kummer surfaces. We implemented our algorithm on a Macintosh 
II using Light- speed C version 2.15, from which all of our photographs were taken. We also ran the algorithm 
on a VAX 8600 to obtain timings. The VAX typcially ran five times faster than the Macintosh. We didn't 
have a state-of-the-art ray tracing program to race against. To be objective in comparing our algorithm 
with ray tracing, we devised a ray tracing algorithm by setting our scan line algorithm to fires a ray 
at every non-background pixel. In other words, we provided critical point information to the ray tracer 
so that it knew, to the pixel, where to trace. We felt that no spatial indexing scheme could improve 
on that. We ran time tests on five examples: 1. a sphere (Figure 7) - 60.4 % background pixels  2. 
the Steiner surface (Figure 6) - 77.1% background 3. the degree four blend (Figure 15) - 89.7% background 
 4. a torus (as in Figure 12) - 62.1% background 5. Torus-torus boolean difference (Figure 19) 84.3% 
background  Images were computedboth at 128 x 128 resolution and512 x512 resolution. We collected times 
for silhouette plot (as in Figure 21), shaded image using our algorithm, and ray tracing. Times are in 
VAX 8600 cpu seconds, with the times for 128 x 128 resolution and 512 x 512 resolution seperated by a 
slash. Surface Number 112131415 Silhouette 1/4 7/27 4/16 3/14 11/44 Shaded 4 45 18/82 9/40 10/67 29/136 
Ray Trace 18/25i 36/372 15/137 38/461 49/482 Our algorithm provides images that are pretty well antialiased. 
For equivalent quality, a ray tracer probably needs to fire four rays per pixel. Note that execution 
times do not grow quadratically with the res- olution. The critical point computation grows roughly linearly 
with resolution. CONCLUSIONS Our primary goal in developing this algorithm was robustness, and we are 
confident that we have met that goal. Also, for as little time as we have spent optimizing our code, 
we think that the algorithm is very competitive in execution speed. We have tried to condense the most 
essential information into this paper. More detail can be found in [28]. Acknowledgements: This work 
was supported in part by the Na- tional Science Foundation under grant number DMC-8657057. We are appreciative 
of valuable discussions with Alyn Rockwood and Dennis Arnon. References 1. Amon, D.S., Topologically 
reliable display of algebraic curves, Computer Graphics, 17, 1983, 219-228. 2. Arnon, D.S. and Rauen, 
J., On the display of cell decomposi- tions of algebraic surfaces, XEROX Technical Report, 1988. 3. 
Bloomenthal, J., Polygonization of implicit surfaces, Com-puter Aided Geometric Design, 5, 1988, 341-355. 
 4. Bradshaw, C.B., Surfaces of functions of three variables, M.S. Thesis, Department of Civil Engineering, 
Brigham Young University, 1982. 5. Farouki, R.T., The characterization of parametric surface sec- tions, 
Computer Vision, Graphics and Image Processing, 1986, 33, 209-236. 6. Farouki, R.T. and Rajan, V.T., 
On the numerical condition of polynomials in Bernstein form, Computer Aided Geometric Design, 4, 1987, 
191-216. 7. Farouki, R.T. and Rajan, V.T., Algorithms for polynomials in Bernstein form, Computer Aided 
Geometric Design, 1988, 5, 1-26.  8. Farin, G., Curves and Surfaces for Cornputer Aided Geometric Design, 
Academic Press, 1988. 9. Goldman, R.N., Sederberg, T.W. and Anderson, D.C., Vec- tor elimination: A technique 
for the implicitization, inver- sion, and intersection of planar parametric rational polynomial curves, 
Computer Aided GeornetricDesigrg 1, 1984, 327-356. 10. Hall, M. and Warren, J., Adaptive tessellation 
of implicitly de- fined surfaces, Rice COMP TR88-84, 1988, Rice University. 11. Hanrahan, P., Ray tracing 
algebraic surfaces, Computer Graphics, 17, 3, 1983, 83-90. 12. Hoffmann, C.M. and Hopcroft, LE., Automatic 
surface gener- ation in computer aided design, The Visual Computer, 1, 1985, 95-100. 13. Lane, J.M. 
and Riesenfeld, R.F., Bounds on a polynomial, B/T, 21, 1, 1981, 112-117. 14. Mahl, R., Visible surface 
algorithms for quadric patches, IEEE Transactions on Computers, C-21, 1, 1972, 1-4. 15. Middleditch, 
A.E. and Sears, K., Blend surfaces for set the- oretic volume modeling systems, Computer Graphics, 19, 
1985, 161-170. 16. Owen, J.C. and Rockwood, A.P., Intersection of general im- plicit surfaces. In Geometric 
Modeling: Algorithms and New Trends, G. Farin, editor, SIAM, Philadelphia, 1987, 335-346. 17. Patrikalakis, 
N.M. and Kriezis, G.A., Piecewise continuous algebraic surfaces in terms of B-splines, MITSG 88-5, Mass- 
achusetts Institute of Technology, August 1988. 18. Petersen, C.S., Adaptive contouring of three-dimensional 
sur- faces, Computer Aided Geometric Design, 1, 1984, 61-74. 19. Rockwood, A.P. and Owen, J.C., Blending 
surfaces in solid modeling. In Geometric Modeling: Algorithms and New Trends, G. Farin, editor, SIAM, 
Philadelphia, 1987, 335-346. 20. Salmon, G. Analytic Geometry of Three Dimensions, Long-mans, Green 
and Co., 1912. 21. Sederberg, T.W., Piecewise algebraic surface patches, Com-puter Aided Geometric Design, 
2, 1985, 53-59. 22. Sederberg, T.W. and Parry, S.R., Comparison of three curve intersection algorithms, 
Computer-Aided Design, 18, 1, (1986), 58-63. 23. Sederberg, T.W., An algorithm for algebraic curve intersec- 
tion, to appear in, Computer-Aided Design. 24. Sederberg, T.W., Spencer, M.R. and de Boor, C., Real 
root ap- proximation of polynomials in Bernstein form, in preparation. 25. Tindle, G.L., Tetrahedral 
triangulation, in, R.R. Martin, ed., The Mathematics of Surfaces H, Clarendon Press, Oxford, 1987, 387-394. 
 26. Warren, J.D., On algebraic surfaces meeting with geometric continuity, Ph.D. Thesis, Cornell University, 
1986. 27. Weiss, R.A., BE VISION, A package of IBM 7090 FOR- TRAN programs to draw orthographic views 
of combinations of plane and quadric surfaces, JACM, 13, 2, 1966, 194-204. 28. Zundel, A.K., Scan line 
rendering of algebraic surfaces and half spaces, M.S. Thesis, Department of Civil Engineering, Brigham 
Young University, 1989.  '89, Boston, 31 July-4 August, 1989 "~~SIGGRAPH v v v v Y Figure 3. Shading 
rays. Figure 2. Exploratory rays. Figure 1. Critical points. I Y fo2o PortO 20 f22o PnnO z=O z=l c~ 
foo2 b f210 POOr~ Pno0 f2oo Figure 4. Pyramid vertices. Figure 5. BPP coefficients. 154   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74349</article_id>
		<sort_key>157</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Rendering cubic curves and surfaces with integer adaptive forward differencing]]></title>
		<page_from>157</page_from>
		<page_to>166</page_to>
		<doi_number>10.1145/74333.74349</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74349</url>
		<abstract>
			<par><![CDATA[For most compute environments, adaptive forward differencing is much more efficient when performed using integer arithmetic than when using floating point. Previously low precision integer methods suffered from serious precision problems due to the error accumulation inherent to forward differencing techniques. This paper proposes several different techniques for implementing adaptive forward differencing using integer arithmetic, and provides an error analysis of forward differencing which is useful as a guide for integer AFD implementation. The proposed technique using 32 bit integer values is capable of rendering curves having more than 4K forward steps with an accumulated error of less than one pixel and no overflow problems. A hybrid algorithm employing integer AFD is proposed for rendering antialiased, texture-mapped bicubic surfaces.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39070040</person_id>
				<author_profile_id><![CDATA[81408601942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[S.-L.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., 2500 Garcia Avenue, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P183192</person_id>
				<author_profile_id><![CDATA[81100325653]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[S. R.]]></middle_name>
				<last_name><![CDATA[Rocchetti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., 2500 Garcia Avenue, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Salim Abi-Ezzi, '~The Graphical Processing of NURB Surfaces," Industrial Associate Review Summary, November 1988. Rensselaer Design Research Center, Rensselaer Polytechnic Institute]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282943</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Jerry Van Aken and Mark Novak, "Curve-Drawing Algorithms for Raster Displays," ACM Transactions on Graphics, vol. 4, no. 2, pp. 147-169, April 1985.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35072</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Richard Barrels, John Beatty, and Brian Barsky, An Introduction to Splines for use in Computer Graphics &amp; Geometric Modeling, pp. 400-406, Morgan Kaufmann Publishers, 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Edwin Catmull, A Subdivision Algorithm for Computer Display of Curved Surfaces, Thesis in Computer Science, of Utah, UTEC-CSc-74-133, 1974.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[George M. Chaikin, "An Algorithm for High Speed Curve Generation," Computer Graphics and Image Processing, vol. 3, pp. 346-349, 1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Robert Cook, Patch Work, Tech. Memo 118, Computer Div., Lucasfilm Ltd., June 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Robert Cook, Loren Carpenter, and Edwin Catmull, "The Reyes Image Rendering Architecture," Proceedings of SIGGRAPH '87, Computer Graphics, vol. 21, 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[James Foley and Andries Van Dam, "Fundamentals of Interactive Computer Graphics," Addison-Wesley Publishers, p. 533, 1982.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99906</ref_obj_id>
				<ref_obj_pid>99902</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Victor Klassen, "Drawing Antialiased Cubic Spline Curves Using Adaptive Forward Differencing," ACM Transactions on Graphics, under revision, 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>108364</ref_obj_id>
				<ref_obj_pid>108360</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Victor Klassen, "Integer Forward Differencing of Cubic Polynomials: Analysis and Algorithms," ACM Transactions on Graphics, under revision, 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jeffrey M. Lane and Richard F. Riesenfeld, "A Theoretical Development for the Computer Generation of Piecewise Polynomial Surfaces," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. PAMI-2, pp. 35-46, 1980.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37416</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sheue-Ling Lien, Michael Shantz, and Vaughan Pratt, "Adaptive Forward Differencing for Rendering Curves and Surfaces," Proceedings of SIGGRAPH '87, Computer Graphics, vol. 21, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M.L.V. Pitteway, "Algorithm for drawing ellipses or hyperbolae with a digital plotter," Computer Journal, vol. 10, no. 3, pp. 282-289, Nov. 1967.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325225</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Vaughan Pratt, "Techniques for Conic Splines," Proceedings of SIGGRAPH '87, Computer Graphics, vol. 19, 1985.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30665</ref_obj_id>
				<ref_obj_pid>30663</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Alyn Rockwood, A Generalized Scanning Technique for Display of Parametrically Defined Surfaces, 7, IEEE Computer Graphics and Applications, August 1987.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37425</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Michael Shantz and Sheue-Ling Lien, "Shading Bicubic Patches," Proceedings of SIGGRAPH '87, Computer Graphics, vol. 21, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378510</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Michael Shamz and Sheue-Ling Chang, "Rendering Trimmed NURBS with Adaptive Forward Differencing," Proceedings of SIGGRAPH '88, Computer Graphics, vol. 22, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '(~ Computer Graphics, Volume 23, Number 3, July 1989 Rendering Cubic Curves and Surfaces with Integer 
Adaptive Forward Differencing Sheue-Ling Chang, Michael Shantz and Robert Rocchetti Sun Microsystems, 
Inc. 2500 Garcia Avenue Mountain View, CA 94043 Abstract For most compute environments, adaptive forward 
differencing is much more efficient when performed using integer arithmetic than when using floating 
point. Previously low precision integer methods suffered from serious precision problems due to the error 
accumulation inherent to forward differencing techniques. This paper proposes several different techniques 
for implement- ing adaptive forward differencing using integer arithmetic, and provides an error analysis 
of forward differencing which is use- ful as a guide for integer AFD implementation. The proposed technique 
using 32 bit integer values is capable of rendering curves having more than 4K forward steps with an 
accumulated error of less than one pixel and no overflow problems. A hybrid algorithm employing integer 
AFD is proposed for rendering antialiased, texture-mapped bicubic surfaces. CR Categories and Subject 
Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation - Display algorithms; 1.3.5 [Computer 
Graphics]: Computational Geometry and Ob-ject Modelling - Curve, surface, and Geometric algorithms. Additional 
Key Words and Phrases: adaptive forward differenc-ing, parametric curve, and texture. Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advamage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0157 
500.75 Introduction Much progress has been made in recent years on techniques for computer aided geometrical 
design. Parametric curves and sur-faces including non-uniform rational B-splines are commonly used to 
describe surfaces of objects being designed. Such objects have typically been rendered by tesselating 
to bilinear quadrilaterals or triangles which are then rendered using widely available special purpose 
hardware for polygons. Alternatively, isoparametric curves across the surface are rendered by tesselat- 
ing to polylines which are rendered using special purpose hardware. These simple piecewise linear approximations 
are also used to drive numerically controlled milling machines. Research has focused largely on subdivision 
methods for render- ing and modelling [4, l l]. Less progress has been made on hardware techniques for 
direct rendering of higher order curves and surfaces. Recursive subdivision is expensive for hardware 
implementation due to the high speed stack memory require-ments and the computational complexity increase 
over polygon rendering methods. Incremental solutions of the implicit equa- tions have been developed 
for conics [2,5, 13, 14], and a few hardware curve generators have been built. Adaptive forward difference 
(AFD) is an incremental technique proposed previously for rendering parametric curves and surfaces [12, 
17]. Abi-Ezzi [1] adapted the AFFD technique to a new basis which has a convex hull property yet retains 
much of the efficiency of the forward difference basis. AFD is an extension of forward differencing and 
is similar to adaptive subdivision in its dynamic step size adjustment. AFD differs from recursive subdivision 
or ordinary forward differencing by generating points sequentially along the curve while adjusting the 
parametric incre- ment to give pixel sized steps. AFD allows a surprisingly simple hardware implementation, 
and is compatible with frame buffer memory interleaving for high performance. With special pur-pose hardware 
for rendering these curves and surfaces directly, the overhead of subdivision and stack memory is eliminated 
and the quality of the rendered surface is as good. AFD in software, with its high speed and low cost, 
is also attrac- tive for parametric curve and surface rendering. Various imple- mentation methods for 
integer adaptive forward differencing are discussed in this paper. One 32-bit scheme is proposed which 
offers advantages in performance, precision, and output format.  ~~SIGGRAPH '89, Boston, 31 July-4 
August, 1989 The error accumulation in forward differencing is analyzed, including a comparison of the 
error accumulation in different integer AFD schemes. Integer AFD may also be used for fast rendering 
of antialiased texture-mapped bicubic surfaces. Integer Adaptive Forward Differencing A parametric curve 
can be tesselated into n segments using equal parametric increments at l/n spacing (assuming that the 
parameter of the function ranges from 0.0 to 1.0). This is done by first converting a polynomial function 
into the forward difference basis [8]. The points along the curve can then be gen- erated incrementally 
with three additions per cycle in the case of a cubic. The authors described three operators in adaptive 
forward differencing in the previous paper. Adjust-down is an operator for reducing the parametric increment 
by half and reducing the step size to approximately one pixel per step when the x,y screen step size 
is more than one pixel. The adjust-up operation dou- bles the parametric increment to increase the change 
in x,y coor- dinates when the step size is less than 1/2 pixel. The two adjust- ment operations are performed 
by transforming the coefficients of the coordinate functions by the the adjust-up matrix [U ] or the 
adjust-down matrix [D ] : 1 0 0 0 "] / c'=(c<<l)+b; U = 0 2 1 0 J l b'--(a+b) <<2; 0044 0 0 0 8 a'=a<<3; 
 1 0 0 0 -] [ a' =a>>3; D = 0 1/2-1/8 1/16 J 1 b' a" 0 0 1/4 -l/8 =(b>>2)-; 0 0 0 1/8 c" = (c -b')>>l; 
where a, b, c, and d are the coefficients of the curve represented in forward difference basis. The notations 
"a<<3" and "a>>3" indicate a left or right shift of coefficient a by three bits. When the step size is 
within the desired range, the forward-step matrix IF ] is applied to move one step forward. output (d); 
  V,,oo 0110 d' = d+c; F = 0011 C" = c+b; 0001 b" = b+a; Adaptive forward differencing can be implemented 
in either floating point or fixed point arithmetic. Floating point imple- mentation offers more precision, 
but is usually more expensive. Higher performance can be achieved if AFD is performed using integer additions 
and shifts. There are two straight forward integer AFD implementations. The 64-bit integer AFD, with 
two 32-bit integers, provides adequate precision for most displays, but the computational cost is more 
than doubled over 32 bit integer operations due to the carry. The 32-bit integer AFD shown in Figure 
1 has an advantage in performance but a disadvantage in precision. It can handle only a very small number 
of forward steps. Subdivisions are required for large curves to avoid excessive error accumulation. In 
the error analysis section we show that this scheme can only handle cubic curves involving up to 100 
forward steps on a 1KxlK screen. The overflow protection bit is used here to avoid clipping a curve exactly 
to the display windown boundary which is quite expensive compared to vector clipping. a 12.20 b 12.20 
c 12.20 d 12.20 Figure 1. An integer forward difference implementation with a sign bit, an overflow-protection 
bit, 10 integer and 20 fractional bits. The approach in Figure 2 has the a, b, and c registers aligned 
and the d register in a 16.16 fract format. A forward step is per- formed by outputing (d>>16) where 
d'=d +(c>>8); c'=c +b; b'=b +a; Compared to the first method where all registers are aligned, this approach 
provides eight more fractional bits which increases the maximum number of forward steps to be 512, at 
a cost of one extra shift per forward step. , binary point I a, 4.28 b', 4.28 c, 4.28 [ d'~ 16.16 I 
Figure 2. An integer forward difference implementation with the a, b, and c registers aligned and the 
d register in 16.16 format. Register a has 28 fractional bits. Barrels etc. [3] discussed using successive 
guard bits in the for- ward difference registers to achieve higher precision with less bits. Each register 
except a contains n successive guard bits for processing up to 2 n forward steps, Figure 3. binary point 
a b [ c j~.. n ~  Id ~n ~n~ Figure 3. Forward difference registers with fl guard bits. A forward step 
operation is performed with n guard bits trun- cated before adding a register: output (d>>n); 1 2 -~ 
0 0 d' = d + (c>>n); 0 1 2 -~ 0 F i = 0 0 1 1 c'=c +(b>>n); 0 0 0 1 b' = b +a;  ~ Computer Graphics, 
Volume 23, Number 3, July 1989 The constant 2-" indicates a truncation of n guard bits. The use of guard 
bits significantly increases the number of forward steps allowable with 32-bit integer forward differencing. 
Register ini- tialization is also simpler with guard bits. A parametric curve f(t)=At3+ Bt2+Ct +D is 
converted to the forward difference basis with the following transformation where A, B, C, and D are 
the control points in polynomial basis, a, b, c, and d are the control points in forward difference basis, 
ga=l/n is the parametric increment: c 0 8 8 2 8 3 b = 0 0 282 683 B a 0 0 0 683 The forward difference 
basis functions are t(t-1)(t-2) B2 t(t-1) B3- ---, Bl=t, B0 = 1 6, 2 This transformation can be performed 
using integer additions and shifts if the tesselation number is a power of two, ie., the scaling factor 
8 = 2-" as follows: d=D c = (C + (B + (A >>n ))>>n )>>n b = (2B >>2n) + (6A >>3n) a = 6A >>3n With n 
successive guard bits in each register, the c coefficient is scaled by 2" and the a and b coefficients 
are scaled by 22" . The initialization is simplied as follows: f d=D d I1 O0 0 c =C +(B + (A >>n ))>>n 
c 01882 b = 00268 b =2B +(6A>>n) a 00068 A a = 6A >>n To utilize a forward difference register set with 
n successive guard bits in integer AFD the adjust-up [U] and adjust-down [D ] operators can be modified 
as follows 1 0 0 0 022-n 0 t c" =(c<<l)+(b>>n); b' = (a+b) <<2; Ui= 0 0 4 4 O0 0 8 a' = a <<3; a' = a 
>>3; Ii 0 0 0 1/2 -2-n/8 2-"//16 b' = (b>>2) -a'; Di = 0 1/4 -1/8 0 0 1/8 c' = (c -(b'>>n))>>l to reflect 
the alignment of the binary points of the registers. The factor 2-" indicates the existence of the guard 
bits. The number of guard bits remains unchanged throughout the process. Victor Klassen [9, 10] extended 
this pseudo floating concept to the integer AFD implementation. He modified the adjust-up and adjust-down 
operators [UK] and [DK] to incorporate the usage of guard bits in the AFD registers and thus to vary 
the number of guard bits following each adjustment operation. One guard bit is added before an adjust 
down and eliminated after an adjust up:   [ 000 i 000 1/2 2-" -2 0 2 -2-" 2-n-1 UK = 0 1/2 1//2 DK 
= 0 2 --1 0 0 1 0 0 1 When the registers acquire one extra guard bit after an adjust- down and lose one 
guard bit after an adjust-up, matrix [UK ] can be derived from [Ui] by scaling the first row of [Ui] 
by 1/2, the second row by 1/4, and the third and fourth rows by 1/8. Simi- larly, [DK] can be derived 
by scaling the first row of [D i] by 2, the second row by 4, and the third and fourth rows by 8. We notice 
that this technique keeps the a register constant and only shifts the contents of b, c and d registers 
during an adjustment. binary point I d I c a b I , I ~ ' "~" n-1 N  n-1 n-1 adjust up g / I d I c n 
 adjustdown fa ,b i I d : N * n+l n+l n+l Figure 4. The re-alignment of forward difference registers 
in Klassen's technique associated with an adjust-up or adjust-down operation. The contents of the a register 
remains constant dur- ing the entire process. There are different pseudo floating implementations for 
integer AFD depending on the application. Figure 5 illustrates the regis- ter format of our technique 
where the d register stays constant in an adjustment, and the a, b and c registers are shifted instead. 
The new adjust-up matrix [Uc ] is derived from [Ui I by scaling the first row of the matrix by 1, the 
second row by 1/2, and the third and fourth rows by 1/4. c' = c + (b>>(n+l)); 1 0 0 0 b' = b +a; 0 1 
2-"-10 g C = 0 0 1 1 a' = a<<l; O0 0 2 n' =n -1; The adjust-down matrix [Dc] is derived from [Di] by 
scaling the first row by l, the second row by 2, and the third and fourth rows by 4. a" = a>>l; 1 0 0 
0 b" Dc = 0 l -2 -n-2 2-n-3 = b -a'; 0 0 1 -1/2 c'=c-(b' >>(n +2)); 0 0 0 1/2 n" =n + l; '89, Boston, 
31 July-4 August, 1989 These transformations preserve the contents of the d register in an adjustment 
while eliminating one guard bit successively from the a, b and c registers during an adjust-up, and adding 
one guard bit successively to the a, b and c registers during an adjust-down. binary point i c  [ d 
[~ .2 n-I , 16 n-1 '~ ,g adjust up b Id , .~ n ~ n adjust down , I fl  ' .~. ~ n+ 1 I d ~ -~ n+l 
16 Figure 5. The re-alignment of the forward difference registers in our technique during an adjust-up 
or adjust-down operation. The binary point of the d register remains fixed. Pseudo floating point is 
very important in order to make the most effective use of fixed point arithmetic and fixed width registers. 
Both methods described above vary the number of guard bits in an adjustment thus giving the effect of 
a floating binary point. Since single float variables in computers contain only 24 bits of mantissa, 
these 32-bit pseudo floating point AFD implementa-tions could actually provide more precision than single 
precision float implementation when the registers are initialized with dou- ble precision floating point 
values. binary point a 26 6 b 26 6 I c 2_8. 4 I I d 30 21 a 12 20 b 12 20 c 14 18 d 16 16 Figure 6. 
A comparison of the register layout of the two methods. By comparing Figures 4 and 5, we can see that 
the difference between the two methods is that Klassen's method produces an output with a floating binary 
point while our method produces a fixed point t6.16 fract format output. The new method also offers several 
advantages including (1) an easier and less expensive initialization computation for fract format inputs 
and outputs, (2) fewer operations in the adjust up and down operations, (3) a 16.16 fract format output 
which better suits subsequent integer instructions, and (4) higher precision when the velocity of a 
curve decreases and  the parametric step size is adjusted severely upward. When the curve velocity is 
approximately 4.0 and the parametric increment is at 2 2 Klassen's registers are shifted so far to the 
left that only few fractional bits remain, whereas the registers in our technique always retain at least 
16 fractional bits even in regions of minimum curve velocity, as shown in Figure 6. Error Analysis on 
Forward Differencing While forward differencing has been a popular and inexpensive method for incrementally 
evaluating points along a parametric function, its rapid error accumulation has been a problem. The user 
must carefully analyze the error accumulation characteristics of the method to ensure accuracy. In this 
section the error accu-mulation properties of forward differencing are analyzed and guide lines are presented 
for evaluating the error bounds of vari- ous implementation schemes. 1. Error analysis on registers without 
guard bits For a cubic, the points on the curve can be computed incremen-tally using three additions 
per cycle. The contents accumulated in the registers at each cycle are shown in the table. We first assume 
that the registers are aligned as shown in Figure 1 and that each register has n fractional bits. cycle 
Contents of Forward Difference Register 0 a b c d 1 a a+b b+c c+d 2 a 2a+b a+2b+c b+2c+d 3 a 3a+b 3a+3b+c 
a+3b+3c+d 4 a 4a+b 6a+4b+c 4a+6b+4c+d 5 a 5a+b 10a+5b+c 10a+10b+5c+d 6 a 6a+b 15a+6b+c 20a+15b+6c+d 
k a ka+b ak(k- I)/2+ ak(k-l)(k-2)/6' + kb+c bk(k- I )/2 + kc+d The error accumulation problem can then 
be analyzed by exa-mining the data in the d register after k iterations: k(k-t)(k-2) k(k-l) d=a +b--+kc 
+d 6 2 The error accumulated in the d register is approximately ea = E~ k (k - 1)(k -2) + Eb k (k - 
1_______)_+ kE,. + Ed 6 2 which is dominated by the initial error in the a register. The initial errors 
in the registers are E a =E b =Ec =Ed =2 -'~. O ~ Computer Graphics, Volume 23, Number 3, July 1989 
The error accumulated in the d register after k cycles is approxi- mately e~ = E~, k(k-l)(k-2) + O(k2 
) 6 A rough estimation on the error accumulation for cubic functions with k=2 m forward steps is approximately 
3m-2 bits: 2m (2m--l)(2m--2) 23'' < -- 6 4 Therefore, the minimum number of fractional bits required 
for 2 m forward steps is n _> 3m-2. Based on this analysis, using 32-bit integer layout as shown in Figure 
! one can handle curves in a 1KxlK grid up to k=100 forward steps. This assumes that the 32 bits are 
used for one sign bit + one overflow bit + 10 integer bits + 20 fractional bits. The a register in this 
case con- tains only twenty fractional bits. Or it can handle curves on a 512x512 grid up to k=128 forward 
steps, by assuming one sign bit, one overflow bit, 9 integer bits and 21 fractional bits. 2. Error analysis 
on registers with guard bits With successive guard bits in the forward differencing registers as in Figure 
3, the error accumulation is similar to the previous analysis except that additional error is introduced 
through the truncation of the guard bits. Again we analyze the error problem by examining the forward 
difference process and the contents accumulated in the registers. Each register has a different number 
of fractional bits, i.e., the a and b registers each have 3n bits, the c register has 2n bits, and the 
d register has n bits. The initial errors in the registers are Ea = 2-", E c = 2 -2n and E a =E b =2 
-3n. The content of the d register shown in the table indicates that the error accumulated in the d register 
after k cycles is dominated by three terms: eel : Eb k(k-1)(k-2) + Ec k(k-l_____~) + k Eel + O(k 2) 6 
2 Contents of Forward Difference Register 0 b c d 1 a+b b+c+E,, c+d +Ed 2 2a+b a+2b+c+2E c b+2c+d +E,. 
+ 2E d 3 3a+b 3a+3b+c+3E c a +3b+3c+d+3E c +3E<l 4 4a+b 6a+4b+c+4E c 4a +6b+4c+d+6E c +4E d 5 5a+b 10a+5b+c+5E 
c 10a + 10b+5c+d+ 10E c +5E a 6 6a+b 15a+6b+c+6Ec 20a + 15b+6c+d+ 15Ec +6Ed k ka+b ak(k-1)/2+kb ak(k-l)(k-2)/6 
+ bk(k-1)/2 +c+k E c +kc+d+E c k(k- 1)/2+kEd * The a register column is not shown in this table. A rough 
estimate of the error accumulated with this method is approximately 3m+l bits for 2 m forward steps. 
In this case the minimum number of fractional bits required for 2 m forward steps is 3n _> 3rn+l. This 
method offers a dramatic improvement in precision han-dling when implemented in 32-bit integers even 
though addi-tional error is introduced through the truncation of guard bits. Using 32-bit integer layout 
as shown in Figure 7, a register con- tains up to forty two fractional bits. One can process curves in 
a 216x216 screen space up to 213 forward steps. This precision is more than adequate for the display 
screen sizes currently avail-able on the market. This is, therefore, a much more useful and powerful 
technique than the previous method which gives only 100 forward steps in a 1KxlK space. binary point 
a ~:~:::::::::::::::::: i b !!:::::::::::::::::: c 4 28 ::::::::.. v.v..v..~k~la~ / d 18 i::::::::::::::::::{ 
k~ 14 ~/ Figure 7. An integer forward difference implementation which can handle curves with up to 213 
forward steps. 3. Subpixel accuracy For rendering antialiased curves, two or three additional bits of 
subpixel accuracy are desirable. In this case error propagation can be controlled, and higher subpixel 
accuracy can be achieved by subdividing to reduce the total number of forward steps in the curve. Error 
accumulation can be analyzed, and the maximum number of forward steps can be estimated by scaling up 
both the screen space and the curve, and then rendering the curve in this larger screen space. For example, 
an antialiased curve rendered in a IKxlK screen with 3 bits of subpixel address accuracy, is equivalent 
to a curve scaled up by a factor of eight and rendered in an 8Kx8K screen. The three least significant 
bits of the x,y coordinates are used as the subpixel address. The guidelines provided above can thus 
be used to analyze the error accumula-tion for a given application requirement and to calculate the limi- 
tations of a specified implementation. 4. Estimating the number of forward steps  Rockwood [15] derived 
a formula for estimating the number of forward difference steps required for a given Bezier curve with 
a specified minimum step size: pmax = maximum Ipi+rpi I for 0 _< i _<n-1 If (t+8)-f (t)l _< n 8 pmax 
1 tesselation - -- n pmax where n is the degree and the Pi "s are the control points of the Bezier function. 
This formula is more intuitively clear by look- ing at the properties of Bezier functions: (1) the derivative 
of a Bezier function f (t) of degree n i=n Zpi n ! ti( l--t )'-i f (t) = i=0 i!(n -i)! is a degree n-1 
Bezier function f' (t) using the vectors of the original polygon as its control points. i =m m! ti(1-t) 
m-i , m=n-1;f' (t)= ~-'~ n (Pi+l-Pi) i !(m -i)! i=0   ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 
(2) the derivative f'(t) is the velocity of f (t), (3) the magni- tude of the derivative If" (t)l is 
bounded by the convex hull of its own control points, and is equal to maximum (In (Pi+l-Pi)l). When using 
forward differencing to render a curve with no miss- ing pixels, the step sizes in both the x and y directions 
should be no greater than one pixel step. Since the x and y coordinates of a Bezier curve are defined 
by two independent Bezier functions, the tesselation number can be computed in terms of the max-imum 
convexhull of the x coordinate and the y coordinate instead of the convexhull of the length of the polygon: 
xmax = maximum (Xi+ 1 --X i ) ymax = maximum (Yi+i -Yi ) pmax = maximum (xmax , ymax ). This tesselation 
number is less expensive to compute and is on the average 30% smaller than the number computed using 
vector length. However, it is big enough to ensure no x or y step size is more than one pixel. 2"(2"-1)(2n-2) 
2 -2" + + ) Ea ed (OFD) : ( 2"(2"-1) 2-" 2 n 6 2 In the case of AFD, there are only n-1 successive guard 
bits in the registers after an adjust-up operation is performed. Ordi-narily the initialization errors 
in registers with n-1 guard bits would be E d = 2 -16, E,, = 2 -n+l Ea and E h = 2 -2n+2 Ed. However, 
the initial errors in the a, b and c registers are magnified by two due to the adjust-up operation [Uc], 
which results in Ec : 2 -n +2 Ea and Eb : 2 -2n+3 Ed The error accumulated after one adjust-up operation 
followed by 2 "-1 forward steps is ed (AFD) : ( k(k-1)(k-2)2-2n+3 + k(k-1)2-~+2 + 2 n-l) Ed 6 2 where 
k = 2 n-l. The result shows that e(i(AFD)<ed(OFD), i.e. the error accumulated in AFD through an adjust 
up operation and 2 n-I forward steps is no greater than the error accumulated in OFD through 2 n forward 
steps. 5. Error bound on AFD without guard bits In a previous paper the authors observed that the error 
accumu-lated using OFD gives an upper bound on the error accumulated using AFD. OFD uses a fixed parametric 
increment sufficiently small so as to prevent missing pixels in the highest velocity region of the curve. 
AFD, on the other hand, increases its parametric increment whenever the step size is too small. The parametric 
step size used in AFD is always greater than or equal to that used in OFD. Thus, the total number of 
forward steps in AFD is considerably smaller than that in OFD if the velocity of the curve is not constant. 
In the case of OFD, 2k forward steps can accumulate an error of approximately ed (OFD ) : 2k(2k-l)(2k-2) 
6 With an adjust-up operation in AFD 2k forward steps is reduced to k forward steps which consequently 
introduces an error of approximately ed (AFD) : 23 k(k-l)(k-2) 6 The 23 factor is due to the left shift 
3-bits in an adjust-up opera- tion. The result shows that the error accumulated in AFD is always less 
than or equal to the error accumulated in OFD: 2k (2k- 1)(2k-2) > 23 k (k- 1 )(k-2) 6 6 6. Error bound 
on AFD with guard bits When using registers with successive guard bits, the error accu-mulated in the 
d register, as discussed previously, is dominated by three terms: Eb k(k-1)(k-2) k(k-1)+ Ec -- + kEa 
6 2 The initial errors in the registers with n guard bits are Ed = 2 -16, Ec = 2-nEa and Eh = 2-2nEd. 
The error accumu-lated in the d register after 2 n forward steps is 7. Overflow control The issues of 
precision control and estimation of the number of forward steps have been discussed above. Overflow is 
another issue of great concern when using integer AFD. The following section will analyze this issue 
using cubic Bezier curves and the convex hull property of Bezier functions. A cubic Bezier curve is defined 
by four control points, Pa, Pb, Pc, and Pd which reside in a screen size of 213x 213: Ipa I <213" Iph 
I <2 TM Ipc I <213' Ipa I <213 Three times the convexhull of the curve is bounded by 2" 31pa -Pb 1<2n, 
3 Ipb --Pc 1<2n, 3 Ipc -Pa 1<2" Here the notation "31pa --pb 1<2 n'' implies the x coordinate 3 I pa 
(x) -Ph (x) I <2 ~ and the y coordinate 3 I pa(y) -Ph (Y) I <2 n. The Bezier control points can be transformed 
into polynomial basis by D =Pd C =3(pc --pal) B = 3(pb -Pc) -3(pc -Pd) A = (Pc, - Pb) -2(pb -pc) + (Pc 
-Pa) The coefficients in polynomial basis are then converted into for- ward difference basis. Under the 
assumptions above, the polyno- mial coefficients A ,B ,C, and D are bounded by ID 1<2", IC1<2 n, 12B 
1<2 ~+2, 16A 1<2 "+3 . Using the register layout shown in Figure 7, the d register con- tains 18 integer 
bits and 14"fractional bits. The maximum value the registers can hold at initialization time is less 
than 217. If the Bezier control points satisfy the following constraints the max-imum number of forward 
steps required is 213 and there will be no overflow problem at the initialization stage. 3 Ipa -Ph I 
<213, 3 Ipb -Pc I <213, 3 Ipc -Pd I <213  ~ Computer Graphics, Volume 23, Number 3, July 1989 Next we 
look at the possibility of overflowing during the for- ward differencing process. We first extend a given 
curve f (t ) = t3 pa + 3t2(1--t )pb + 3t ( l--t )2p~ + (1--t )3pd by draw- ing an extension to the curve 
for the parameter range t=l.0 to t =2.0, as shown in Figure 8. t=to /~ t=O.~+to Figure 8. A segment of 
curve with the parameter ranging from t =to tot =l.0+to. At any instant during the process when the parameter 
is at t = to, the contents in the four registers, a, b, c, and d, are the forward difference coefficients 
of the portion of the extended curve with parameter ranging from t = to to t = 1.0 + t o and scaled by 
the current tesselation ~ : d =f(to) c =f'(to) +f"(to)~5 / 2 +f"(to)82 / 6 b =f'(to) +f"(to)~ a = f" 
(to)~5 The derivatives f" (t),f" (t) and f" (t) are lower order Bezier functions. f" (t) = 3[t2(pa 
-Pb) + 2t (1-t)(pb -Pc) + (1-t)2(pc -Pd)] f'(t) = 6[t(pa -- 2ph +Pc)] + (1--t)(pb --2pc +Pal)] f" (t) 
= 6[(pa -Ph ) -2(pb -Pc ) + (Pc -Pd )] The bound on the convex hull of functions If'(t)l is 213, on functions 
If"(t)l is 215, and on functions If'"(t)l is 216. Therefore, the magnitude of the derivatives satisfy 
the con-straints at any instant O.O<_to <_1.0 If(t)l, If'(t)l, If"(t)[, If"'(t)l<216 With the integer 
AFD implementation we proposed in Figure 5, the d register has 16 integer bits and 16 fractional bits. 
The maximum number of forward steps this scheme can handle is 212. In this case, the constraints on the 
convexhull of the control polygon is 3 Ip~ -Ph I < 212, 3 Ipb -Pc I < 212, 3 Ipc -Pd I < 212  Integer 
AFD for Surfaces AFD can be used to render shaded, textured, and trimmed sur-faces. Texture and imagery 
can be mapped onto a surface as a function of the parameters s and t. Shading and image mapping on a 
bicubic surface is performed by drawing many iso-parametric curves very close together so that no pixel 
gaps exist in between. Each isoparametric curve is a cubic function of parameter t defined by a constant 
s =si. The spacing 5s from one curve to the next is measured to decide whether the next curve should 
be drawn closer to or farther from the current curve. A polynomial bicubic function can be converted 
into forward difference basis by the transformation: 1 0 0 0 ~i ~2 ~3 flO fl! f12 ft3 0 0  ii0 0 0 0 
282 6~ 3 |f20 f2l f22 f23 0 6[33 0 0 61j 3 L f30 f3! f32 f33 where the fij "s are the control points 
in polynomial basis, and 5 and 13 are the parametric increments in the s and t directions, respectively. 
A surface can be tesselated using ordinary forward differencing into m*n four-sided polygons or m and 
n iso-parametric curves by choosing the scaling factors to be 8=l/m and [3=l/n. After basis conversion, 
a surface is described by three coordinate functions, f x (s ,t ), f y (s ,t ), and f z (s ,t ), each 
being a bicubic function of s and t. An isoparametric curve at a constant s = si is a cubic function 
f (s =si,t )=dB o(t )+cB l (t)+bB 2(t )+aB 3(t ) where the four coefficients a ,b ,c ,d can be computed 
from the surface matrix [A] using two dimensional AFD. These coefficients are stored in the first row 
of matrix [A ], i.e. ao0, a0l, ct02, and ao3. In the curve-to-curve outer loop, a forward- step [F] operation 
is applied to the surface matrix [A ] to pro- duce the coefficients of the next isoparametric curve : 
aoo+a 1o a01+a it aoe+a 12 a03+a 13 a 10+a e0 a l l+aet a 12+a z2 a 13+a e3 a20+a 30 a21+a31 a22+a32 
a23+a33 a30 a31 a32 a33 After a forward-step operation is applied, the first row of [A ], aoo+a 10, a01+a 
I1, a02+a 12, and a03+a 13 are the coefficients of the next isoparametric curve. These coefficients are 
then used in the pixel-to-pixel inner loop for computing the address of the pixets on the isoparametric 
curve. If the spacing between the current curve and the next curve is too small, an adjust-up opera- 
tion is )erformed to increase the spacing before a forward step takes Mace. If the spacing is too large, 
it is reduced with the [D ] o 9erator before [F ] is applied: t a oj aoj a oj aoj ~/i lj = [U ] a lj 
and a', lj = [D ] a lj a 2j a 2j a 2j a 2j t a 3j a 3j a 3j a 3j The two initial parametric increments 
of AFD can be estimated based on the initial velocity of a surface, i.e. ~=~f/~s (0,0), [~=~f/~t (0,0). 
By choosing these factors to be powers of two, ~= 2 -m and 13= 2 -n, the initialization can be greatly 
simplified. '89, Boston, 31 July-4 August, 1989 1. Hybrid integer AFD for surfaces AFD surface rendering 
technique can also be implemented in integer arithmetic as long as the precision limitation is carefully 
considered. When using forward differencing for surface render- ing, the error accumulates during both 
the curve-to-curve and pixel-to-pixel procedures. The curve-to-curve outer loop gen-erates the coefficients 
of the next isoparametric curve and the pixel-to-pixel inner loop computing the pixel addresses. If 2 
m forward steps are spent in the curve loop and 2 n steps in the pixel loop, the error in the a register 
is magnified by a factor of 2 m(2 m-1)(2"'-2)/6 in the curve outer loop and a factor of 2"(2"-1)(2"-2)/6 
in the pixel inner loop. The error can accu- mulate as much as 2 m+'l forward steps have accumulated. 
As shown in the analysis section, the 32-bit integer AFD is adequate for rendering curves in a 4Kx4K 
space up to 212 forward steps. Using 32-bit integer AFD for surface rendering, the maximum number of 
forward steps of the scheme is limited to m+n <_ 12, i.e. approximately 64 curves each no longer than 
64 pixels. Sur-faces requiring more than 64x64 forward steps must be subdi- vided. Alternatively, one 
can implement the curve outer loop in 64-bit AFD to compute the coefficients of the isoparametric curves 
and pixel inner loop in 32-bit AFD to compute the pixel addresses. This hybrid scheme provides more precision 
and uses proper operators in each loop, for example, [F], [U], and [D] in the outer loop and [F c ], 
[Uc ], and [Dc] in the inner loop. Matrix [Fc] is the same as [Fi] except that the d register is in 16.16 
fixed point format. A forward step in the curve outer loop can be performed with twelve 64-bit-integer 
additions (a 64-bit-integer is stored in two 32-bit integers). A forward step in the pixel inner loop 
can be done with three additions and two regis- ter shifts. The cost of register realignment before entering 
a pixel inner loop can be eliminated by properly scaling the coefficients of matrix [,4 ] in the t direction 
at the initialization time so that the first 32 bits of the coefficients aoo,aol,ao2, and a03 can be 
input directly to the 32-bit integer AFD pixel inner loop: fo0 foI f02 f03 Ii 0 0 0 i 0 620 0 6 83 flo 
fli f12 f13 1 0 0 0 282 683 2-" 2 0 .1"20 f21 f22 f23 0 0 683 2 -2" 62-" 62-" f30 f31 f32 f33 While 
rendering a surface, the decision to adjust up or down, or to forward step is made based on the distance 
between two adja- cent isoparametric curves, d (t) = If (s +Ss ,t ) -f (s ,t ) I. The distance is a cubic 
function of t. The maximum distance between the two curves can be estimated using the Bezier con- vex 
hull property if the distance function d(t) is converted into Bezier basis [6]. Converting d(t) into 
Bezier basis at every curve is quite expensive. Instead of converting d(t) at every curve, one can maintain 
a dual matrix IB ] to minimize this over- head. Matrix /7 is transformed into Bezier basis in the t direc- 
tion and forward difference basis in the s direction. Matrix B and the surface matrix A are operated 
on synchronously in the curve-to-curve outer loop. The first row of A stores the coefficients of the 
current isoparametric curve. The second row of B stores the distance to the next isoparametric curve. 
The Bezier convex hull property can be applied directly to the second row of B to find the maximum distance 
between two consecu- tive isoparametric curves. 2. Dicing with integer AFD An anti-aliasing technique 
[7] was proposed based on dicing to produce micropolygons followed by skittered subsampling and averaging 
for fast high-quality rendering of complex images. Micropolygons are the basic geometric unit of the 
technique. They are flat shaded quadrilaterals approximately 1/2 pixel on a side in screen space. Screen 
space derivatives of a surface are used to estimate how finely to dice, and subdivision and ordinary 
forward differencing are used to do the actual dicing. The algorithm presented by Cook for dicing, shading, 
clipping, and rendering micropolygons is as follows: Dice the primitive into a grid of micropolygons; 
Compute normals and tanget vectors for the micropolygons in the grid; Shade the micropolygons in the 
grid; Break the grid into micropolygons; For each micropolygon Bound the micropolygon in eye space; 
If the micropolygon is outside the hither-yon range, cull it; Convert the micropolygon to screen space; 
Bound the micropolygou in screen space; For each sample point inside the screen space bound If the sample 
point is inside the micropolygon Calculate the z of the micropolygon at the sample point by interpolation; 
If the z at the sample point is less than the z in the buffer Replace the sample in the buffer with this 
sample; Integer AFD can be a much more efficient method for dicing in screen space since the screen 
space step size is the threshold which controls adjust up, adjust down, or forward step. A similar algorithm 
is proposed here using integer AFD to dice a surface. AFD a primitive into strips of isoparametric curves; 
AFD an isoparametric curve into a sequence of points; Form a chain of micropolygons in between two consecutive 
isoparametric curves For each micropolygon Bound the micropolygon in eye space; Cull the micropolygon 
if outside the hither-yon range; Bound the micropolygon in screen space; Cull the micropolygon if outside 
the viewport range; For each sample point inside the screen space bound If the sample point is inside 
the the micropolygon Interpolate the z at the sample point; If the z at the sample point is less than 
the z in the buffer Shade the micropolygon if not yet done; Replace the sample in the buffer with this 
sample;  @ ~ Computer Graphics, Volume 23, Number 3, July 1989 A surface is first sliced into many 
strips of isoparametric curves using 64-bit integer AFD. Two consecutive isoparametric curves are no 
more than 1/2 pixel apart. Each isoparametric curve is then tesselated into a sequence of points using 
32-bit integer AFD with two consecutive points lying no more than 1/2 pixel ( apart. When the lesselation 
is done, lwo consecuUve iso-parametric curves form a chain of micropolygons. Each micro- polygon is a 
triangle with two vertices on one isoparametric curve and one vertex on the other isoparametric curve. 
Micropo-lygons are approximately 1/2 pixel on a side in screen space, and fiat shaded. Using synchronized 
AFD technique, different components of a surface can be computed in difference spaces. For example, the 
forward difference coefficients of the coordinate functions can be computed in the screen space while 
the shading functions are calculated in the eye space. / i I _ _ -) . . . . I ' i I ---4-------4- I 
I / I I / I I Figure 9. Dicing a bicubic surface into microtriangles with integer AFD in subpixel grid. 
The techniques proposed in the shading paper [16] can be used for calculating the shading function N,-, 
Ny, N=, N.L and N.H of a bicubic surface. Functions Nx, N~., and N- are the com-ponents of the normalized 
or un-normMized normal vector func- tions, and N.L and N.H are the inner products of the normal vector 
function with the light source vector L and the high light vector H N.L (s ,t ) = LxNx(s,t ) + LyNy(s 
,t ) + L=Nz(s ,t ) N.H (s ,t ) = HxN~ (s ,t ) + HyNy(s ,t ) + H=N=(s,t ) The coordinate functions and 
the shading functions are bicubic function of parameters s and t. These functions can be stepped along 
synchronously using integer AFD. The adjustment deci-sion is made based on the screen step size information. 
The coordinate functions are diced directly in screen space, thus, the overhead of dicing a primitive 
in eye space and transforming the micropolygons into screen space is eliminated. The shading functions 
are computed and then diced in the eye space. The normal vector of each micropolygon is generated by 
AFD instead of computed at every micropolygon. The overhead of computing the inner products N.L and N.H 
per micropolygon is also eliminated in this method at the cost of AFDing two bicubic functions. The shading 
value of a pixel is computed in the inner most loop after the z buffer depth comparison, thus, the no 
cost is spent on computing the shading of hidden pixels. For point light source, the un-normalized normal 
vector func-tions are used and two inner products and one normalization per pixet are required to calculate 
the sahding values N.L and N.H. Discussion The threshold for adjustment in AFD may be set to 0.5 and 
1.0, i.e. adjusting up when  and y steps are less than .5 pixel and adjusting down when x or y step 
is greater than 1 pixel. This ensures no missing pixels and reduces the pixel overpainting rate. Alternatively, 
one can use 1.0 and 2.0 as the thresholds, filling in a missing pixel whenever x or y takes a two-pixel 
step. The difflerence between the two is that in the former case redun-dant pixels are eliminated and 
in the latter, missing pixels are filled. The advantage of using a higher threshold, such as 10 to 20 
pixels, is to reduce the number of forward steps and to improve the performance by rendering a curve 
with a polyline. An adjust-down operation performed on a step size of greater than 1.0 can sometimes 
result in a step size of less than 0.5. To avoid getting into an infinite loop of adjust-ups and adjust-downs, 
it is helpful to enforce a forward step before an adjust-up in the implementation. The computational 
complexity of the two surface rendering algo- rithms described in the previous section may be compared 
by assuming that a bicubic surface is diced into n 2 vertices consti- tuting n 2 quadrilaterals or 2n 
2 triangles. It takes 16 multiplies and 12 additions to do a 4x4 point transformation. Computing the 
normal vectors of a quadrilateral takes 6 multiplies and 9 additions. The inner product computation for 
shading values N.L and N.H costs 6 multiplies and 4 additions per quadrila- teral. The overhead of dicing 
a primitive in eye space, comput- ing the shading values on every micropolygon, and transforming the 
micropolygons into screen space totals to 28 multiplies and 25 additions per quadrilateral. For a total 
of n 2 micropolygons, the overhead is 28n 2 multiplies and 25n 2 additions per surface. Using the synchronized 
AFD technique, a forward-step in the curve outer loop costs |2 additions (or 48 additions when using 
64-bit integer AFD) and a forward-step in the pixel inner loop costs 3 additions. Dicing a function into 
n isoparametric curves each with n vertices takes a total of 48n additions in the curve loop and 3n 2 
additions in the pixel loop. Computing five shad- ing functions N x, Ny, N z, N.L and and N.H costs a 
total of 15n :2 + 240n additions per surface. The AFD method costs a total of 18 n2+ 288tt additions. 
AFD has the overhead of computing the coefficients of the N.L (s ,t) and N.H (s ,t) shad-ing functions. 
AFD has the advantages that (1) primitives are diced in screen space with better control of the micropolygon 
size; (2) the shading values of hidden pixels are not computed, which may account for a large savings 
in computation when the depth order of the scene is not optimized; (3) the computational complexity is 
significantly lower.   ~,~SIGG RAPH '89, Boston, 31 July-4 August, 1989 Acknowledgements The authors 
are very grateful to Lewis Knapp for many helpful discussions and inputs to this project and for reviewing 
early drafts of this paper. Special thanks to John Recker for helping with the implementation and profiling. 
We thank Victor Klassen for several enlightening email conversations about his technique. References 
1. Salim Abi-Ezzi, "The Graphical Processing of NURB Surfaces," Industrial Associate Review Summary, 
November 1988. Rensselaer Design Research Center, Rensselaer Polytechnic Institute 2. Jerry Van Aken 
and Mark Novak, "Curve-Drawing Algo- rithms for Raster Displays," ACM Transactions on Graphics, vol. 
4, no. 2, pp. 147-169, April 1985. 3. Richard Barrels, John Beatty, and Brian Barsky, An Intro- duction 
to Splines for use in Computer Graphics &#38; Geometric Modeling, pp. 400-406, Morgan Kaufmann Publishers, 
1987. 4. Edwin Catmull, A Subdivision Algorithm for Computer Display of Curved Surfaces, Thesis in Computer 
Science, University of Utah, UTEC-CSc-74-133, 1974. 5. George M. Chaikin, "An Algorithm for High Speed 
Curve Generation," Computer Graphics and Image Pro- cessing, vol. 3, pp. 346-349, 1974. 6. Robert Cook, 
Patch Work, Tech. Memo 118, Computer Div., Lucasfilm Ltd., June 1985. 7. Robert Cook, Loren Carpenter, 
and Edwin Catmull, "The Reyes Image Rendering Architecture," Proceedings of SIGGRAPH '87, Computer Graphics, 
vol. 21, 1987. 8. James Foley and Andries Van Dam, "Fundamentals of Interactive Computer Graphics," 
Addison-Wesley Publish- ers, p. 533, 1982. 9. Victor Klassen, "Drawing Antialiased Cubic Spline Curves 
Using Adaptive Forward Differencing," ACM Transactions on Graphics, under revision, 1989. 10. Victor 
Klassen, "Integer Forward Differencing of Cubic Polynomials: Analysis and Algorithms," ACM Transac- tions 
on Graphics, under revision, 1989. 11. Jeffrey M. Lane and Richard F. Riesenfeld, "A Theoreti- cal Development 
for theComputer Generation of Piece- wise Polynomial Surfaces," IEEE Transactions on Pat-tern Analysis 
and Machine Intelligence, vol. PAM1-2, pp. 35-46, 1980. 12. Sheue-Ling Lien, Michael Shantz, and Vaughan 
Pratt, "Adaptive Forward Differencing for Rendering Curves and Surfaces," Proceedings of SIGGRAPH '87, 
Computer Graphics, vol. 21, 1987.  13. M.L.V. Pitteway, "Algorithm for drawing ellipses or hyperbolae 
with a digital plotter," Computer Journal, vol. 10, no. 3, pp. 282-289, Nov. 1967.  14. Vaughan Pratt, 
"Techniques for Conic Splines," Proceedings of SIGGRAPH '87, Computer Graphics, vol. 19, 1985.  15. 
Alyn Rockwood, A Generalized Scanning Technique for Display of Parametrically Defined Sulfaces, 7, 1EEE 
Computer Graphics and Applications, August 1987. 16. Michael Shantz and Sheue-Ling Lien, "Shading Bicubic 
Patches," Proceedings of SIGGRAPH '87, Computer Graphics, vol. 21, 1987. t7. Michael Shantz and Sheue-Ling 
Chang, "Rendering Trimmed NURBS with Adaptive Forward Differencing," Proceedings of SIGGRAPH '88, Computer 
Graphics, vol. 22, 1988.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74350</article_id>
		<sort_key>167</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Curve-to-curve associations in spline-based inbetweening and sweeping]]></title>
		<page_from>167</page_from>
		<page_to>174</page_to>
		<doi_number>10.1145/74333.74350</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74350</url>
		<abstract>
			<par><![CDATA[We are concerned in this paper with associations between spline curves that will hold at all inbetween positions when the control points of these curves are used as key points for animation or sweeping. It is established that any association between two spline curves that can be expressed as the equality of two linear mappings will hold throughout an inbetweening process provided the inbetweening trajectories are coordinated splines that uniquely interpolate the control-point key positions. Multiple associations are possible, so long as the basic requirements of linearity and coordination are observed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.1</cat_node>
				<descriptor>Spline and piecewise polynomial interpolation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P230541</person_id>
				<author_profile_id><![CDATA[81100508844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Bartel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Waterloo, Department of Computer Science, Computer Graphics Laboratory, Waterloo, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P232729</person_id>
				<author_profile_id><![CDATA[81100635015]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Hardock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Waterloo, Department of Computer Science, Computer Graphics Laboratory, Waterloo, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>35072</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[1. Bartels, Richard, Beatty, John, and Barsky, Brian. <i>An Introduction to Splines for Use in Computer Graphics and Geometric Modeling</i>. Morgan Kaufmann Publishers (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[2. Bartels, Richard and Hardtke, Ines. "Speed Adjustment for Key-Frame Interpolation." Proceedings of Graphics Interface '89. Morgan Kaufmann Publishers (1989) [to appear].]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[3. de Boor, Carl. <i>A Practical Guide to Splines</i>. Springer-Verlag (1978).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>61954</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[4. Farin, Gerald. <i>Curves and Surfaces for Computer Aided Geometric Design</i>. Academic Press (1988).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578659</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[5. Forsythe, George, Malcolm, Michael, and Moler, Cleve. <i>Computer Methods for Mathematical Computations</i>. Prentice-Hall (1977).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808575</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[6. Kochanek, Doris, and Bartels, Richard. "Interpolating Splines with Local Tension, Continuity and Bias Control." Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In <i>Computer Graphics 18</i>, 3 (July, 1984), 33-41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[7. Pegna, Joseph. <i>Variable Sweep Geometric Modeling</i>. PhD Thesis, Stanford University, Stanford, California 94305 (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>806814</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[8. Reeves, William. "Inbetweening for Computer Animation Utilizing Moving Point Constraints." Proceedings of SIGGRAPH'81 (Dallas, Texas, August 3-7, 1981). In <i>Computer Graphics 15</i>, 3 (August, 1981), 263-269.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325243</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[9. Steketee, Scott, and Badler, Norman. "Parametric Keyframe Interpolation Incorporating Kinetic Adjustment and Phrasing Control." Proceedings of SIGGRAPH'85 (San Francisco, California, July 22-26, 1985). In <i>Computer Graphics 19</i>, 3 (July 1985), 255- 262.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 Curve-to-Curve Associations in Spline-Based Inbetweening 
and Sweeping Richard H. Bartels and Ronald T. Hardock University of Waterloo Department of Computer 
Science Computer Graphics Laboratory Waterloo, Ontario Canada N2L 3GI  Abstract We are concerned in 
this paper with associations be-tween spline curves that will hold at all inbetween positions when the 
control points of these curves are used as key points for animation or sweeping. It is established that 
any associa- tion between two spline curves that can be expressed as the equality of two linear mappings 
will hold throughout an inbe- tweening process provided the inbetweening trajectories are coordinated 
splines that uniquely interpolate the contol-point key positions. Multiple associations are possible, 
so long as the basic requirements of linearity and coordination are ob-served.  Introduction This is 
not a paper about animation. It is about a prop- erty of splines that has applications in the fields 
of animation and computer-aided geometric design. The terminology of key-frame animation is convenient, 
however, and we will use it to present our results. We will give our results in terms of xy-curves with 
trajectories in t. Again, this is a presentational convenience. The observations we make can easily be 
ap- plied to higher dimensions, e.g. to the movement of spline surfaces through time or the sweeping 
of volume densities. We take the paper by Reeves [8] as a starting point. Reeves describes a means of 
controlling, throughout inbe-tweening, relationships that hold between curves in key-frames. He does 
this by introducing auxiliary curves, from key to key, that enforce the relationships in the temporal 
do- main. Reeves calls these temporal curves moving point con- straints. These were introduced to provide 
control over both position and dynamics in an animation, whereas we are con- cerned only with positional 
associations in this paper. Such things as the point contact of two curves, the tangency of two curves, 
the translational or angular orientation of one curve to another are the associations that interest us 
here. Since the creation of surfaces by sweeping and extrusion also corresponds to a process of the keyframing 
type, where the trajectories are in space rather than in time, what we learn here can be useful in computer-aided 
geometric design as well as in animation. (More precisely, the correspondence that can Research supported 
by Canada's NSERC Operating, Strategic, and Infrastructure programs, Province of Ontario's ITRC program, 
and grants from General Motors, Digital, and Silicon Graphics. Permission to copy without fee all or 
part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. be drawn is between keyframe inbetweening 
and generalized cylinders or non-rigid sweeps as surveyed by Pegna [7]. The difference between animation 
and sweeping is in the render- ing. In animation, curves are swept through trajectories along the t axis, 
and a sequence of cross sections of the resulting "surface" is presented as the inbetweens. In sweeping, 
the trajectory axis is z, and the interest is in the surface itself, rather than in cross sections of 
it.) While the mechanism of moving point constraints may be necessary to ensure that certain forms of 
association be- tween key curves are maintained throughout the temporal do- main, we felt that there 
ought to be some forms of useful as- sociation that would hold automatically throughout the inbe- tweening 
process without the complication of imposing con-straints. For animation a desirable situation would 
be one in which the positional and dynamic aspects of an animation were unbundled, with positional relationships 
on inbetween frames proceeding automatically from the key frames and with dynamics available for independent 
adjustment by such techniques as [9] or [2]. For computer-aided design dynamics play no role, and positional 
aspects are all that matter. A naive hope on our part was that we could express the curves in a key frame 
as spline curves in a desired association, and that inbetweening the control points would provide inbe- 
tween versions of the curves in the same state of association. This was put to the test. One spline curve, 
which we referred to as "Mickey's snout," was placed tangent to a another spline curve, which we referred 
to as "Mickey's nose," in a sequence of keyframes that could be loosely described as "Mickey nod- ding 
his head." The positions of each given control point of a curve in each keyframe were interpolated by 
the simplest method described in [6] to provide a trajectory for that control point. The inbetween curves 
were constructed from the inbe- tween positions of the control points. The result of doing this is sometimes 
acceptable and is sometimes not. The curve-to-curve association that exists within each keyframe may 
or may not be maintained throughout the inbe- tween frames. In particular, Mickey's nose may or may not 
separate from his snout. In Figure 1 we show two keyframes and an inbetween frame for which a curve-to-curve 
associa- tion is maintained. Figure 2 shows a similar situation for which the association is broken in 
the inbetween frame. Why some configurations showed difficulties while others did not came to be known 
among us as "the Mickey's nose problem." In this paper we present conditions ensuring that associ- ations 
will hold between spline curves under straightforward trajectory interpolation for their control points. 
The result will be that, if the trajectory interpolation satisfies a few &#38;#169;1989 ACM-0-89791-312-4/89/007/0167 
$00.75 167  :~.~~SIGG RAPH '89, Boston, 31 July-4 August, 1989 straightforward properties, and if the 
curve-to-curve associa- tion likewise satisfies a few properties, then the association will hold automatically 
throughout all inbetweens. No addi- tional constraints need be imposed. Admittedly, there will be many 
associations that will not satisfy the properties we set out. One of our fundamental requirements will 
involve linearity, and an association such as: "the arc length of curve R should be a certain multiple 
of the area enclosed by curve S," to give a wild example, would not fill the bill. However, as we will 
see, associations that relate a point or a derivative on one curve with a point or derivative on another, 
possibly through a modeling transformation, will satisfy our requirements. Representing Curves and Trajectories 
 Each curve under consideration is to be expressed para- metrically in control-point/basis-function format: 
R(u)= ~,~UiBi(u ). i We make no restrictions on the basis functions B i, so this format will equally 
well describe B-spline curves, B6zier curves, Beta-spline curves, Cardinal-spline curves, or NURBS among 
others ([1] and [4]). The chief item of interest is some form of association between one curve R (u) 
and a second curve S(v)=~v.c (v ). J J J The second curve is to be expressed in the same general for- 
mat, but there is no requirement that the basis functions C j be related in any way to the basis functions 
B i " Hence, we can study associations between B-spline curves and Cardinal curves, for example, or between 
B6zier curves of one degree and those of another. We will not be presenting a list of specific associations. 
Such a list is open ended. Instead, we will be establishing a set of conditions, and any association 
that conforms can be added to the list. However, we will give examples to show that contact, tangency, 
fixed separation, and angular orienta- tion are among the associations that can be established to hold 
throughout sweeping and inbetweening. The k th key of one of the curves, for example R (u), is formed 
when the control points U i of the curve are located in some chosen positions Ui, k for k = 0 ..... n, 
and the curve is defined relative to those positions. This gives us the k th instance of the curve R, 
which we denote by R k(u) : Rk (u )= ~Ui, k Bi(u). i A trajectory is formed for one of the control points 
U i when the sequence of positions U i, 0 ..... U i, ~ is interpolated by a parametric curve, also to 
be given in control-point/basis-func- tion format, Ui(t )= Y~Pl,iDt(t ). I The values t o ..... t n of 
the parameter t are those that provide the key positions of the control points U i for any i, that is 
Ui, k= Ui(t k )= ~Pl,iDl(tt ) I The basis functions D l are not required to be the same as the basis 
functions used to represent either of the curves R orS. To establish curve-to-curve coordination between 
R (u) and S (v), we first require conformity of trajectories. This means that a common interpolation 
scheme must be applied to all the control points of both curves. Consequently, the con- trol points of 
S (v) will satisfy equations of the form V.(t)= ~Q .Din(t) J m m, ) for the same basis functions D that 
were used for the control points U, and we will recover the key positions of V. as we J did for those 
of the U i ' Uj,k = Vj(tk)= ~Qm, jDm(t m This establishes the k th instance of the curve S, Sk(u)= ~Vj,kCj(u). 
J If we substitute the interpolation curves for U and V into the- definitions of R and S this provides 
us with swept versions of these curves that very in t as well as in their parametric vari- ables, R (u,t) 
= ~Ui(t)B i(u )= ~Pl, iDl (t)B i (u) i i t S(v,t)=]~V (t)C (v)= ~Q om(t)C.(v). j j m,j j j jm We can 
recover the k th instance of R or S from these swept versions by substituting the values of t given by 
t o ..... t n : R k(u)-- R(u,tk)=~Ui, k Bi(u) i Sk(v) = S(v,t k) =~V j, kC j(v). J In addition to the 
requirement of conformity of trajecto- ries, we will also require the interpolation process to be unique 
and linearly dependent on the data. By this we mean that all the trajectories derive from a nonsingular 
system of equations, for example ~ ~ ! = ~ . Do(tn) "'" D n(tn)JL P n i U n i This means that the coefficients 
P t, i and Q m, j that define the trajectories will be unique linear combinations of the con- trol points 
of the corresponding key curves Pl, i= ~-~dl, ,~Ui, X 2 and Qm.j = Y~dm. xVj,2 ' 2 where the coefficients 
d are the elements of the inverse of the matrix ~[- D a (t/3 )] of the trajectory system. Common methods 
of interpolation that are used to pro- vide trajectories in animation and computer-aided geometric design 
are, in fact, unique and linearly dependent on the data. ~ Computer Graphics, Volume 23, Number 3, July 
1989 Specific methods of this type worth mentioning are Catmull- Rom spline interpolation and some of 
its variations [6], natu- ral cubic spline interpolation [5], and trajectories in B-spline format [9] 
found by solving a system of interpolation equa- tions [3]. Key Associations that Hold for Inbetweens 
The result of the previ6us section is that the swept ver-sions of R and S can be given in the following 
forms: R(u,t)= ~dl, zUi.,~Di(t)B (u) il,~ and S (v,t)=~d m,,~Vj, 2Dm(t)Cj.(v). jmA The k th instance 
of each curve is given by R(u,tk )= ~dl,LUi,2Dl(tk)B (u) i l A and S (v,t k)=y~y~,dm,,~Vj,xDm(tk)C (v). 
j'm~, To finish our development, we will require that the asso- ciation that holds between R k (u) = 
R (u, t k ) and S k (v)= S (v ,t k) for each key k be expressible as a mapping equality, that is and 
that the maps F and G be linear, that is, i ' for any collection of scaler values c~ju. If this is the 
case, then using d l, k Dl(t) for a and / for/.1 with each fixed k and t gives us, on the left side of 
the mapping equality, ~'dt'kl Dt(t)F(~Ui" kBi(u) l = F(ENi, kDl(t)EUi,k B i(U)), \ l i and repeating 
the process with a = 1 and k used in place of/.1 gives ~'F(~ kDl(t)Y~Ui'ki Bi(u))   = (ZZd, kDt(t)ZUi 
k l i =F(R(u,t)) . Likewise, on the right side of the mapping equality, ~'Y~dmmk , k Dm(t)G(~'V'~j 
J,k Cj(v))  = G( n~k dm , kD m(t) j~Vj, kCj ( v )) =G(S(v,t)). This means that, if association F (or 
G) holds at key k for all k, it will also hold for all possible inbetween positions. To summarize, when 
the curves and trajectories under consideration are in control-point/basis-function format, when the 
trajectories conform and derive from a unique interpola- tion process that depends linearly on the data, 
and when the key associations are expressible as mapping equalities with linear maps, then the associations 
between curves that hold in the keys will hold throughout the trajectories. This is a general statement 
about inheritance. We em-phasize that it is unnecessary to know the details of any of the formulas. Constants 
like d which are not the normal m,] ~ output of the trajectory interpolation, do not have to be dealt 
with. The formulas we have given were used for the sake of advancing the presentation. Only the properties 
of our sum- mary, which are quite broadly stated, need to be verified. Inheritance proceeds automatically 
from format, conformity, and nonsingular-linear-system interpolation, and inheritance holds for all associations 
that can be expressed as linear map- ping equalities. This covers a great number of practical cases. 
We give some examples in the next section, but they do not, by any means, exhaust the possibilities. 
Examples One simple example of maps F and G that satisfy the re- quirements of linearity is given by 
evaluation at a point. Let F(f (u)) = f (u') for any function of u, and let   G( g(v))= g(v') for any 
function of v. It is easily verified that evaluation at a point is a linear map, and it corresponds to 
the key association that R k(U') = Sk(V' ) at all keys k for given, fixed parameter values u' and v' 
, as is shown in Figure 3. S(v) k R ~(.')=s (v) Figure 3. The association at key.k is.given by evalua- 
tion at a point. This will ensure that the point associa- tion shown will be maintained for all inbetweens. 
This is enough to keep Mickey's nose connected to his snout, but not enough to keep his nose from rotating 
around the point of contact. To prevent that, we need to control tangen- cy. Let F and G correspond to 
differentiation at a point, that is F(f (u))= ~uf(u') for any function of u and d G(g(v)) = --~Tv g(v') 
 :~~SIGG RAPH '89, Boston, 31 July-4 August, 1989 for any function of v. Differentiation at a point 
is also a linear map, and it corresponds to the key association that the tangent vector of R k(U) at 
u = u' corresponds to the tangent vector ofS k (v) at v = v'. In fact, nothing would be changed ifF and 
G were multiplied by any nonzero scaling constants. This would mean that, if the tangent vector of R 
k(u ) at u = u' were equal to a fixed multiple of the tangent vector of S k (v) at v = v' , then the 
same tangent-vector associa- tion would hold for all possible keys, as is indicated by Figure 4. Sk(v) 
 Figure 4. The association at key k is ~iven by differ- entiatiRn at a pqint. This means that tlS~ tgngept 
vec- tor to R at the chosen value oI u is parallel to the tan- ~ent vector to S at the chosen value of 
v. The orienta- tion of one tangent vector w!th respect the the other will depend upon the sign or the 
scaling constants. This is enough to keep Mickey's nose oriented consistently with the end of his snout, 
but it does not prevent the nose from floating free. We need one more observation to retire the problem 
of Mickey's nose. That observation is that several associations can hold simultaneously between R and 
S, so long as one association's formula is independent of the other. In brief, if F and F" are independent 
maps (that is, if F is not de- fined in terms of F, or conversely), if the same holds for G and G, and 
if ff(~Ui, kBi(u)l= a(j~. Vj,kCj(v) ) as well as F(t~.Ui, k Bi(u))= G(~V. J J, Cj( v)) , then #( n(u,t)) 
=G( S (v,t)) as well as F(R(u,t))= G(S(v,t)). An example of such independence would come by tak- ing 
F and G to be evaluation at the points u' and v' , re- spectively, and by taking/~ and (~ to be differentiation, 
also at the points u" and v' , respectively. Since the operation of taking a derivative value at a point 
is independent of the oper- ation of evaluating at a point, this is a valid example. This means that, 
at every key, if Mickey's nose touches his snout, and if his nose and snout have a common tangent direction 
at the point of contact, and if the point of contact occurs at the same parametric value u" and v' in 
all keys, then Mickey may move his head as he pleases and keep his features togeth- er. This was the 
pair of associations that made Figure 1 suc- cessful. A further example of a suitable mapping is given 
by any of the familiar modeling transformations applied to the results of evaluation or differentiation 
at a point. That is, we may let F correspond to the evaluation of R at a fixed value u = u' followed 
by a translation of the resulting point R k(u') by a fixed displacement A. This composition of mappings 
will be linear. We may let G correspond to the evaluation of S at a fixed value v = v'. Equating the 
result of F and G will amount to establishing the association between R and S that keeps a chosen point 
on R at a fixed offset from a known point on S. Figure 5 illustrates this association. ~ Rk(u) Figure 
5, "I~he po)nt evaluatiqn of R is ganslated to a fixed offset trom tne point evaluation or ~. If we 
change F to differentiation and the subsequent transformation to rotation by a fixed angle, and change 
G to differentiation, then the association that is produced is that of a fixed angular orientation between 
the tangent vector at a point on R with the tangent vector at a point on S, as is illus- trated by Figure 
6. ~ Computer Graphics, Volume 23, Number 3, July 1989 R k (U ) ~ S k (v ) Figure 6. At each key k the 
tangent to R at a cl2osen ppmt u is specified to. cpniorm to toe ta.ngent to ~ at a chosen point v rotated 
about a tixed angle. Finally, just as independent mappings can be used to hold a multiplicity of associations 
between two curves simul- taneously, it is possible to consider simultaneous associations between multiple 
curves as well. Thus, for example, we could arrange that R and S join at given u = u' and v = v", that 
curves S and T maintain a given angle between tangents at fixed v = v" and w = w',andthat Tkeep aspecified 
offset from M at a fixed w = w" and q = q" , all simulta- neously. A possible application of multiple 
associations to computer-aided design is that of filleting or smoothly blending between two swept surfaces, 
as is shown in Plate 2. Plates 1 through 4 show samples of some associations used to construct a variety 
of swept surfaces. References 1. Bartels, Richard, Beatty, John, and Barsky, Brian. An Introduction 
to Splines for Use in Computer Graphics and Geometric Modeling. Morgan Kaufmann Publishers (1987). 2. 
Bartels, Richard and Hardtke, Ines. "Speed Adjustment for Key-Frame Interpolation." Proceedings of Graphics 
Interface '89. Morgan Kaufmann Publishers (1989) [to appear]. 3. de Boor, Carl. A Practical Guide to 
Splines. Springer-Verlag (1978).  4. Farin, Gerald. Curves and Surfaces for Computer Aided Geometric 
Design. Academic Press (1988). 5. Forsythe, George, Malcolm, Michael, and Moler, Cleve. Computer Methods 
for Mathematical Computations. Prentice-Hall (1977). 6. Kochanek, Doris, and Bartels, Richard. "Interpolating 
Splines with Local Tension, Continuity and Bias Control." Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, 
July 23-27, 1984). In Computer Graphics 18, 3 (July, 1984), 33-41. 7. Pegna, Joseph. Variable Sweep Geometric 
Modeling. PhD Thesis, Stanford University, Stanford, California 94305 (1987). 8. Reeves, William. "Inbetweening 
for Computer Animation Utilizing Moving Point Constraints." Proceedings of SIGGRAPH'81 (Dallas, Texas, 
August 3-7, 1981). In Computer Graphics 15, 3 (August, 1981), 263-269. 9. Steketee, Scott, and Badler, 
Norman. "Parametric Keyframe Interpolation Incorporating Kinetic Adjustment and Phrasing Control." Proceedings 
of SIGGRAPH'85 (San Francisco, California, July 22-26, 1985). In Computer Graphics 19, 3 (July 1985), 
255-  262.    L _~SIGGRAPH '89, Boston, 31 July-4 August, 1989 7\ ,, .... -. m "w" w" "/ Figure 
1. Two spline curves whose key association (tangency at one point) is preserved. The key frames are the 
first and the last; the inbetween frame is in the middle. A trajectory was computed separately for each 
control vertex of each curve. Each such trajectory was formed by simple Catmull-Rom interpolation [Kochanek 
1984] by regarding each key to be doubled. This corresponds to setting the beginning and final tangent 
vector on the trajectory to half the chord between the initial and final key positions. The inbetween 
frame represents the parametric mid- point of the trajectory. f," ,," ",, m~ ..... I~ j ,~ , i / ',, 
7 "w" Figure 2. A two splines curves whose key association (tangency at one point) is not preserved 
on an inbetween frame. The inbetweening was done exactly as in Figure 1. The inbetween frame is, as in 
Figure 1, the parametric midpoint of the trajectory.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74351</article_id>
		<sort_key>175</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Voxel space automata: modeling with stochastic growth processes in voxel space]]></title>
		<page_from>175</page_from>
		<page_to>184</page_to>
		<doi_number>10.1145/74333.74351</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74351</url>
		<abstract>
			<par><![CDATA[A novel stochastic modeling technique is described which operates on a voxel data base in which objects are represented as collections of voxel records. Models are "grown" from predefined geometric elements according to rules based on simple relationships like intersection, proximity, and occlusion which can be evaluated more quickly and easily in voxel space than with analytic geometry. Growth is probabilistic: multiple trials are attempted in which an element's position and orientation are randomly perturbed, and the trial which best fits a set of rules is selected. The term <i>voxel space automata</i> is introduced to describe growth processes that sense and react to a voxel environment.Applications include simulation of plant growth, for which voxel representation facilitates sensing the environment. Illumination can be efficiently estimated at each plant "node" at each growth iteration by casting rays into the voxel environment, allowing accurate simulation of reaction to light including heliotropism.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14165310</person_id>
				<author_profile_id><![CDATA[81547350956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greene]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NYIT Computer Graphics Lab, Old Westbury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arvo, James, David Kirk, Modeling Plants with Environment- Sensitive Automata, Proceedings of Ausgraph '88, 27-33.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, Jules, Polygonization of Implicit Surfaces, Computer Aided Geometric Design, 5, 4 (,Nov. 1988), 341-355.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Shenchang E. Chen, John A. Wallace, Donald Greenberg, A Progressive Refinement Approach to Fast Radiosity Image Generation, Computer Graphics, 22, 4 (Aug. 1988), 75-84.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Stochastic Sampling in Computer Graphics, ACM Transactions on Graphics, 5, 1 (/an. 1986), 51-72.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Drebin, Robert A., Lurch Carpenter, Pat Hanrahan, Volume Rendering, Computer Graphics, 22, 4 (Aug. 1988), 65-74.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, Akira, Tanaka Takayuki, Kansei Iwata, ARTS: Accelerated Ray-Tracing System, IEEE Computer Graphics and Applications, 6, 4 (Apr. 1986), 16-26.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, Modeling the Interaction of Light Between Diffuse Surfaces, Computer Graphics, 18, 3 (July 1984), 119-128.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13023</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Greene, Ned, Environment Mapping and Other Applications of World Projections, 1EEE Computer Graphics and Applications, 6, 11 (Nov. 1986), 21-29.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Greene, Ned, Organic Architecture {videotape}, Siggraph Video Review 38, (Aug. 1988), ACM Siggraph, New York, segment 16.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Halton, J. H., A Retrospective and Prospective Survey of the Monte Carlo Method, SlAM Rev., 12, 1 (Jan. 1970), 1-63.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319126</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kaufman, Arie, 3D Scan Conversion Algorithms for Voxel-Based Graphics, Proceedings of 1986 Workshop on Interactive 3D Graphics, (Oct. 1986), 45-75.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Miller, Gene S., and C. Robert Hoffman, Illumination and Reflection Maps: Simulated Objects in Simulated and Real Environments, SIGGRAPH 84: Advanced Computer Animation Seminar Notes, (July 1984).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801263</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Norton, Alan, Generation and Display of Geometric Fractals in 3D, Computer Graphics, 16, 3 (July 1982), 61-67]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer, Peter, Real Time Design and Animation of Fractal Plants and Trees, Computer Graphics, 20, 4 (Aug. 1986), 56-64.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Preston, Kendall, and J. B. Duff, Modern cellular automata: theory and applications, Plenum, New York, 1984.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378503</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, Przemyslaw, Aristid Lindenmayer, James I-Ianan, Developmental Models of Herbaceous Plants for Computer Imagery Purposes, Computer Graphics, 22, 4 (Aug. 1988), 141-150.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801167</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Reeves, William T., Particle Systems - A Technique for Modeling a Class of Fuzzy Objects, Computer Graphics, 17, 3 (July 1983), 359- 376.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378505</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[de Reffye, Philippe, Claude Edelin, lean Francon, Marc laeger, Claude Puech, Plant Models Faithful to Botanical Structure and Development, Computer Graphics, 22, 4 (Aug. 1988), 151-158.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sabella, Paola, A Rendering Algorithm for Visualizing 3D Scalar Fields, Computer Graphics, 22, 4 (Aug. 1988), 51-58.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Smith, Airy Ray, Plants, Fractals, and Formal Languages, Computer Graphics, 18, 3 (July 1984), 1-10.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Upson, Craig, Michael Keeler, VBUFFER: Visible Volume Rendering, Computer Graphics, 22, 4 (Aug. 1988), 59-64.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Wyvill, Brian, Craig McPheeters, Geoff Wyvill, Data Structure for Soft Objects, The Visual Computer, 2, 4 (1986), 227-234.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~' Computer Graphics, Volume 23, Number 3, July 1989 VOXEL SPACE AUTOMATA: MODELING WITH STOCHASTIC 
GROWTH PROCESSES IN VOXEL SPACE Ned Greene NYIT Computer Graphics Lab'~ Old Westbury, New York Abstract 
A novel stochastic modeling technique is described which operates on a voxel data base in which objects 
are represented as collections of voxel records. Models are "grown" from predefined geometric elements 
according to rules based on simple relationships like intersection, proximity, and occlusion which can 
be evaluated more quickly and easily in voxel space than with analytic geometry. Growth is probabilistic: 
multiple trials are attempted in which an element's position and orienta- tion are randomly perturbed, 
and the trial which best fits a set of rules is selected. The term voxel space automata is intro- duced 
to describe growth processes that sense and react to a voxel environment. Applications include simulation 
of plant growth, for which voxel representation facilitates sensing the environment. Illumination can 
be effidently estimated at each plant "node" at each growth iteration by casting rays into the voxel 
environ- ment, allowing accurate simulation of reaction to light includ- ing heliotropism. CR Categories: 
1.3.5 [Computer Graphics]: Computational Geometry and Object Modeling -Curve, surface, solid and object 
representation. 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. 1.6 [Simulation and 
Modeling]: Applications. Additional Keywords and Phrases: Voxel, automata, stochastic processes, illumination, 
heliotropism, radiosity t Author's current address: Apple Computer, 20525 Mariani Ave., Cupertino, CA 
95014 Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
&#38;#169;1989 ACM-0-89791-312-4/89/007/0175 $00.75 1. Voxel Space By a voxel space we mean a region 
of three dimensional space partitioned into identical cubes (volume elements or vaxels), typically a 
region bounded by a rectangular solid so that it can be represented as an array or oetree of voxel records. 
Model-ing and rendering techniques which operate on a voxel space are the subject of increasingly active 
research. Various volume rendering techniques have been developed to visualize data produced by 3D medical 
imaging devices and computa- tional simulation [5], [19], [21]. In the synthesis domain, voxel spaces 
have been employed to create surfaces defined by implicit functions [2], [13], [22]. Alternatively, arbitrary 
three dimensional shapes can be represented in voxel space by marking the voxels that they intersect 
as "occupied" [11]. This representation is necessarily approximate, since it only indicates which voxels 
are inter-sected by the object, not the object's actual surface. Multiple objects can be distinguished 
from each other by assigning each a unique voxel value, so any collection of non-interseoting objects 
can be represented. Although partitioning space into voxels makes geometric calculations only approximate 
and puts a lower limit on the size of objects that can be distinguished, for many applications these 
disadvantages are outweighted by convenience and speed. Suppose we wish to initialize voxel space with 
an environment modeled as a collection of geometric primitives such as lines, polygons, and polyhedra. 
The process of identifying and labeling voxels that are intersected by a primitive object is referred 
to as tiling. Kaufman has outlined incremental tech- niques for tiling various primitives [11], although 
his criterion for tiling a voxel is somewhat different than the simple inter- section criterion employed 
herein: a voxel is tiled if the cube representing its extent is intersected. Figure 1 shows voxel representations 
of a line and a polygon. Voxel representation of an environment simplifies geometric operations such 
as intersection testing and measuring the relative proximity of objects. Whether an object intersects 
another object already represented in voxel space may be determined by testing each voxel that it intersects 
to see if it's already occupied. This method of sensing intersection is only approximate in the sense 
that two non-intersecting objects can  '89, Boston, 31 July-4 August, 1989  :~~SIGGRAPH intersect the 
same voxel, in which case intersection will be falsely detected. But it is faster and more convenient 
than the conventional method of intersecting one geometric element with all other elements in its vicinity 
using analytic geometry. The conventional approach can be difficult to implement, par- ticularly if a 
model is constructed from different surface types (polygons, quadric surfaces, patches, etc.). With the 
voxel method, riling is the only geometric operation which must be performed, and testing an element 
of one surface type against an element of another surface type only requires the ability to tile voxel 
space with each. In addition, performance is independent of scene complexity and does not depend on the 
number of nearby objects. Voxel representation also simplifies determining proximity relationships. Given 
a point in space we may identify the nearest object by scanning voxels in the neighborhood and comparing 
distances to occupied voxels encountered. Alterna. tively, the process may be facilitated by adding "boundary 
layers" of voxels to objects in the environment. According to this scheme, voxels adjacent to voxels 
which are part of object N are marked as being in boundary layer 1 of object N, voxels one additional 
layer removed from object N are marked as being in boundary layer 2, and so forth up to some specified 
number of boundary layers. If L boundary layers have been added to all objects, for any point in voxel 
spaee we may immediately determine whether it lies within L voxels of an object, and if so, the identity 
of the nearest object. As the discussion will show, voxel representation also facili- tates ray casting 
and a variety of other geometric operations. 2. Growth Systems The computer graphics literature includes 
a variety of approaches to simulating plant growth including particle sys- tems [17],[20], graftals [20], 
and fractals [14]. Recently, Prusinkiewicz etal. and de Reffye et al. have approached the problem with 
empirically based models of plant development, producing relatively realistic models of actual plant 
species [16], [18]. Less attention has been paid to the problem of simulating the effects of environmental 
factors on plant development, which are particularly important in complex environments where plants interact 
as they compete for space and light. To faith- fully mimic a natural growth process which senses and 
reacts to the environment, a simulated growth process must sense and react to the environment. In crude 
terms, growth is affected by conditions within the local environment: obstacles should be avoided, proximity 
to objects or other organisms may inhibit or promote growth, and growth is modulated by available light. 
At a minimum, simulated growth processes should be aware of these conditions. Arvo and Kirk have described 
growth processes capable of sensing the environment which they refer to as "environment- sensitive automata" 
[1]. Their method performs ray casting to test for intersection and proximity, and they have applied 
the technique to simulate clinging vines and patches of grass which avoid obstacles. They mention that 
the method could be extended to simulate heliotropism (sun seeking) and other effects. Their sole means 
of sensing the environment is ray- object intersection, which limits the type of information that can 
be obtained. This article argues that voxel representation simplifies sensing of the environment by growth 
processes. In particular, it is easier to obtain geometric information by scanning or sam-pling a voxel 
environment than by ray casting a conventional model. From any point in voxel space the size, shape, 
and proximity of neighboring objects can be determined by inspect- ing the records of nearby voxels. 
Voxel records may include information about material properties, making it straightfor- ward to confine 
growth to appropriate regions of the environ- ment. A variety of statistics about the local environment 
such as "center of mass" and "density" are readily obtained. Illumination, which depends on the global 
environment, can be estimated by sampling with ray casting. In this context, ray casting means tiling 
a ray in voxel space; a ray is occluded if it intersects an occupied voxel. While this means of estimating 
illumination isn't as accurate or general as ray tracing, it is suf- ficlent to estimate exposure to 
sunlight and "skylight" in an outdoor scene, and it can be performed very efficiently since it does not 
require ray-object intersection or any substantial aria- lyric geometry. Fujimoto etal. discuss incremental 
methods for tiling rays in the context of using uniform spatial subdivi- sion (like a coarse voxel space) 
to enhance ray tracing perfor- mance [6] . The efficiency of ray casting in voxel space makes it feasible 
to build an illumination table at each active plant "node" at each iteration, allowing accurate simulation 
of reac- tion to light including heliotropism. A paradigm for growth in voxel space may be outlined 
as Figure I. follows. The initial state of voxel space is specified, either "empty" or tiled with a three 
dimensional model of an environ- 176 An 8x8x8 voxel space with voxel representations of a polygon and 
a line ment. Beginning at specified seed points, models are grown from predefined geometric elements, 
added one by one to the model subject to satisfying a set of rules. Typically, rules con-  ~ Computer 
Graphics, Volume 23, Number 3, July 1989 sist of geometric constraints based on simple relationships 
like intersection, proximity, and occlusion which are evaluated by sensing the voxel representation of 
objects. Growth is proba- bilistic: multiple trials are attempted in which an element's position and 
orientation are randomly perturbed, and the trial which best fits the rule set (if any trial does) is 
selected. Vari-ous methods of propagation can be employed for choosing possible sites for new growth 
-tree-structured "random walk," "diffusion," etc. Experience has shown that a few simple rules are suffident 
to simulate some complex phenomena. The term voxel space automata will be applied to growth processes 
that sense and react to a voxel environment. The term automata is used informally here, and the approach 
presented in this article is only loosely related to the formal mathematical realm of cellular automata 
[15]. While both approaches are rule-based and operate on a matrix of cells, contrary to the spirit of 
cellular automata the implementation presented here is driven by geometry, and voxel representa- tion 
functions primarily to simplify geometric operations. Nevertheless, some of the methods described are 
formally developed in the cellular automata literature, for example rules based on inspection of neighborhoods. 
With respect to plant simulation, this paper is primarily con- cerned with environmental factors -obstacle 
avoidance, reac- tion to light, etc. The developmental model employed, a form of random walk subject 
to constraints, is not adequate for real- istic simulation of most plant species. In this sense, the 
exam- ples cited are more a detailed illustration of how voxel space automata work than a serious attempt 
to simulate plant growth. The latter objective requires a sophisticated model of plant development in 
addition to the ability to sense the environment, which suggests the possibility of combining the two 
in a voxel space automaton. 3. Geometric Operations in Voxel Space Constraints based on geometric rules 
such as intersection avoidance and proximity constraints provide a high level means of controlling growth. 
The skeleton of Figure 2 represents a tree-structured "random walk" through voxel space constrained by 
intersection avoidance. If growth in one randomly perturbed direction results in intersection with an 
occupied voxel, that trial is rejected and growth in another direction is attempted. Incidentally, the 
term "random walk" is used informally throughout this paper; segment directions are not chosen at random, 
but are generated by perturbing the direction of the last segment according to a parameterized dis- tribution 
function. Since we are generating and evaluating randomly perturbed trials, this approach to intersection 
avoidance may be con-sidered a "Monte Carlo" method [10]. In a sense, the growing model feels its way 
through voxel space by sensing the voxel representation of objects.  Figure 3 illustrates how growth 
can be controlled with simple biases and constraints. Panel A shows the initial state of voxel space 
in cross-section: a cylindrical column is surrounded by four boundary layers (records for voxels in this 
region include information about proximity to the column). Panel B shows growth with a slight bias to 
grow upward, implemented by interpolating trial segment directions with a vertical vector. Panel C shows 
growth with an upward bias and subject to a proximity constraint (on average, voxels intersected by a 
seg- ment must lie within two voxels of the column). Panel D shows growth with biases to grow upward 
and helically twist, subject to a proximity constraint. Growth rules can be based on any relationship 
that can be evaluated by reading voxel records. For a particular applica- tion, "center of mass" within 
a certain region or the "density" of a certain object within a certain radius may be of interest. The 
helical bias apparent in Figure 3D was imparted by per- turbing trial segment directions toward one side 
of a plane defined by the last segment and the local "center of mass." If information about a large 
region of voxel space is desired, sampling is an alternative to examining every voxel within the region. 
In evaluating relationships like illumination that depend on the global environment, sampling methods 
may be the only feasible approach. iiiiiii))11 iiiilll ,,,J,,i,,,,,iF lllllll)llllllllfl,,,,,,,,iJ,,,, 
llllllllllllllllll,l,,,,,Jl,,,,, Figure 2. Skeleton generated by tree-structured random walk through 
2D voxel space with intersection avoidance. Frame at left shows all attempts to place segments and 
voxels intersected by success- fully placed segments. Fan-shaped clusters represent unsuccessful trials. 
Skeleton generated is shown at right.   ~(~SIGGRAPH '89, Boston, 31 July-4 August, 1989 The vine 
model of Figure 5 illustrates how a complex model can be produced from a few simple rules. The vines 
were grown in 51 iterations in a 165x150x195 voxel space which was initialized by tiling with a polygonal 
model of the wail and ground plane and then adding four boundary layers. Figure 4 lists the growth rules 
which generated the vines. The proxim- ity constraint which held vine growth close to the wall has already 
been discussed. Illumination rules which confined vine growth to regions of the wall with substantial 
exposure to light are discussed in the following section. 4. Determining Available Light for Plant Shnulatlon 
 Light is one of the most important environmental factors to be considered in simulating growth of photosynthetic 
plants. For typical species, normal development requires illumination within a certain range, light intensity 
affects rate of growth, and shadowing within the local environment may affect direc- tion of growth. 
Since different parts of an organism may react differently to light, and shadowing changes from iteration 
to iteration, accurate simulation of reaction to light requires find- ing illumination at numerous sites 
on an organism at each iteration. For example, development of an individual tree limb is affected by 
illumination within the locai environment which changes over time as neighboring limbs develop. On a 
smaller scale, development of an individual leaf may depend on available illumination in its local environment. 
Ideally, we would like to be able to estimate illumination at each plant "node" at each growth iteration. 
The efficiency of sampling methods for estimating illumination in voxel space makes this feasible to 
do. In an outdoor scene, "direct" illumination comes from the sky hemisphere. To estimate exposure to 
the sky of an arbitrary point in voxel space we cast rays from the point toward points on the sky hemisphere. 
In this context, "casting a ray" means tiling a ray in voxel space; it is occluded if it intersects an 
occu- pied voxel. If we cast 100 rays from a point toward the sky and 40 of them are occluded, the point's 
exposure to sky is 0.6. In growth rules, this quantity will be called sky_exposure, which ranges in value 
between 0 (complete occlusion) and 1 (complete exposure). Similarly, to estimate exposure of an arbitrary 
point to direct sunlight, rays are cast towards points on a 180 degree arc representing the sun's trajectory 
and the fraction of occluded rays is determined. In growth rules, exposure to the sun's tra- jectory 
will be called sun_exposure, which ranges in value between 0 and 1. To confine growth of a plant species 
to regions of the environ- ment having the appropriate exposure to light we may specify minimum and maximum 
values for exposure expressed as a blend of sun_exposure and sky_exposure. For example, the illumination 
constraint from the growth rules for the vines of Figure 5 light { blend sun=0.8 sky=0.2 exposure rain=0.3 
max=l.0 boost 1.8 } confines growth to regions of the environment with between Figure 3. J // \ / 
</ / \ \ i ~78 A B C D  ~(~ Computer Graphics, Volume 23, Number 3, July 1989 30 and 100 percent of 
full exposure, and exposure is measured as an 80%/20% weighted average of sun_exposure and sky_exposure. 
The "blend" ratio is a way of specifying the relative importance of sun_exposure and sky_exposure which 
depends on mean climatic conditions (e.g., degree of cloud cover) and the illumination requirements of 
a particular species. In the scene of Figure 5 the sun's trajectory is inclined at 20 degrees from vertical, 
"behind" the wall with a window, so vine growth is confined to the brighter regions of the wall as expected. 
Figures 6A-6F were rendered from the voxel representation of the scene. Panels A and B, showing sun_exposure 
and sky_exposure respectively, were produced by estimating expo- sure at each occupied voxel by casting 
rays as previously described. Note that the image of sun_exposure is not a "sha-dow matte" corresponding 
to shadows cast by the sun in a fixed position, but rather a time exposure indicating average exposure 
to direct sunlight in the course of a day. Panel C shows the region of the environment above the illumination 
threshold for the vines, which corresponds nicely with the actual growth pattern. Of course growth processes 
don't need to know about illumi- nation in the whole environment; they determine illumination at spedfie 
sites in voxel space as needed to evaluate illumlna- tion constraints. For example, as the vines grew, 
sunexposure and sky_exposure were deterniined at one location for each growing tendril at each iteration, 
and growth at a particular tendril stopped whenever illumination fell below the threshold. The "boost" 
parameter in the constraint affects rate of growth, average number of leaves per segment, and leaf size. 
For example, a simple linear relationship between exposure and scale produced leaves having full exposure 
(1.0) that were 1.8 times the scale of leaves having the minimum exposure (0.3). Accordingly, leaves 
are larger and more numerous at the top of the wall where illumination is high than on the wall's verti- 
cal faces. Of course this crude intuitive model for modulating growth would benefit from empirical study. 
Figures 6A and 6B were created to show that the method for estimating illumination is accurate enough 
to evaluate illumina- tion constraints. They also suggest that estimating illumination in this manner 
may have application to surface shading. A detailed discussion of rendering issues is beyond the scope 
of this paper, but a few observations are in order. $. Estimating Diffuse Reflection Estimating illumination 
by ray casting on a voxel by voxel basis as previously described is essentially a radiosity approach 
which estimates diffuse reflection [7], and interreflection of light among objects in the environment 
can be simulated by making multiple passes through the voxel data. In producing Figures 6A and 6B a ray 
sample was black if the ray was occluded, otherwise white. On a second pass through the voxel data, occluded 
rays can be assigned the gray level of the intersected voxel (instead of black), improving accuracy, 
and subsequent passes further refine the image. The same strategy can be applied to color rendering if 
color information is stored at each voxel. A "first pass" color rendering of the scene (Panel F) has 
been simulated by blending a shadow matte (Panel D) with the image of sky exposure (Panel B) to approxi- 
mate overall illumination, and matting an image of surface color (Panel E) through this image. Figures 
6A-6F were produced with a conventional polygon renderer by drawing a cube for each occupied voxel in 
the scene. Alternatively, colors associated with occupied voxels can be applied to a polygonal model 
by dicing each polygon to the voxel grid and assigning each fragment the color of the corresponding voxel. 
Figures 5 and 9A were produced in this manner. Figure 4: Growth rules for vines of Figure 5 /* 17 seed 
locations (at base of walt, inside and outside the courtyard) */ seed 0.50 -0.89 0.56 seed 0.35 -0.89 
0.56 seed 0.56 -0.89 -0.60 /* skeleton parameters */ raadom_~ee { length 2.4/* limb length in "voxel 
wldr_hs" */ breach_ age_/ange 13/* 1, 2, or 3 iterations before branching (picked at random) */ branch..angle 
60/* (degrees) */ vertical_bias .08/* slight bias to grow upward */ no_of~:rials_max 300/* try 300 randomly 
perturbed trials before giving up *1 no_of~:rials_min 150 P try 150 trials before picking best proximity 
fit */ seekprox 1.5/* pick tr/al with avg. proximity closest to 1.5 "voxel widths" */ maxprox 3.0/* reject 
trials with avg. proximity greater than 3.0 "voxel widths" */ } /* illumination */ ught{ blend sunl0.8 
sky-0.2/* blend of sunexposur arid sky_exposure */ ~posure rain-0.3 m,ax-l.0/* nodes with less than 
30% expo. become inactive */ boost 1.8/* fuU exposure nodes grow 1.8 times faster than 30% exposure nodes 
*/ } /* leaf element */ dement { number of_triaLs 30/* attempt placement 30 times before giving up */ 
expected..frequency 1.5/* try to place 1.5 leaves per branch segment */ model {/* coordinates of 2 polygons 
in leaf model */ polygon (0,.32,.04),(-.23,.1..3,-.01),(..36,.4.4,-.11),(-.24,.76,-.11),(0,.99,-.06) 
polygon (0,.32,.04),(0,.99,-.06),(.28,.76,..1.3),(.41,.45,..13),(.25,.13:.02) } }     ~~SIGGRAPH 
'89, 8oston, 31 July-4 August, 1989 Primary and secondary rule sets were employed to track lines delineating 
the "railing" in the underlying model. To make the skeleton branch where lines in the underlying model 
forked and nowhere else, a primary rule set attempted to branch everywhere, subject to a proximity constraint, 
succeeding only in the neighborhood of a fork. When branching failed, a secondary rule set attempted 
to place a single limb segment subject to a proximity constraint, often succeeding, allowing growth to 
continue. This strategy produced full delineation of the railing tracery, as is apparent in Figure 9B. 
 The essential method of rule-based stochastic growth in voxel space is more general than the examples 
presented suggest. Mode of propagation need not be a random walk; alternatives include some form of "diffusion" 
-given successful placement of an element, new sites for potential growth in the neighbor- hood can be 
chosen according to a distribution function. The configuration of paving tiles in Figure 5 was produced 
from three primitive elements with this propagation mode, subject to constraints on proximity and intersection. 
This Monte Carlo approach to arranging primitive elements in close prox- imity while avoiding intersection 
may prove to have wide application in assembling complex models from randomly arranged elements. 8. Conclusion 
 At arbitrary locations in voxel space, the local environment can be easily and efficiently scanned and 
the global environ-ment can be easily and efficiently sampled. These properties make voxel representation 
useful for growth processes that sense and react to an environment. 9. Acknowledgements This paper is 
the core of a masters thesis submitted to the Computer Science Department of the Courant Institute of 
Mathematical Sciences, New York University. I would like to thank Prof. Ken Perlin for acting as my thesis 
advisor and most of all for encouraging me to enter the masters program at Courant. I would also like 
to thank Mike Gwilliam who very generously lent his time to help with image generation, producing Figures 
5 and 9A. Paul Heckbert and Jules Bloomenthal reviewed the manuscript and offered many help-ful suggestions, 
as did one of the anonymous reviewers. Pho-tographic work by Ariel Shaw, i0. References  1. Arvo, James, 
David Kirk, Modeling Plants with Environment- Sensitive Automata, Proceedings of Ausgraph '88, 27-33. 
 2. Bloomenthal, Jules, Polygonization of Implicit Surfaces, Computer Aided Geometric Design, 5, 4 (Nov. 
198~), 34.1-355.  3. Cohen, Michael F., Shenchang E. Chert, John A. Wallace, Donald Greenberg, A Progressive 
Refinement Approach to Fast Radiosity Image Generation, Computer Graphics, 22, 4 (Aug. 1988), 75-84. 
 4. Cook, Robert L., Stochastic Sampling in Computer Graphics, ACM Transactions on Graphics, 5, 1 (Jan. 
1986), 51-72. 5. Drebin, Robert A., Lurch Carpenter, Pat Hanrahan, Volume Rendering, Computer Graphics, 
22, 4 (Aug. 1988), 65-74. 6. Fujimoto, Akira, Tanaka Takayuki, Kansei Iwata, ARTS: Accelerated Ray-Tracing 
System, IEEE Computer Graphics and Applications, 6, 4 (Apr. 1986), 16-26. 7. Goral, Cindy M., Kenneth 
E. Torrance, Donald P. Greenberg, Modeling the Interaction of Light Between Diffuse Surfaces, Com-puter 
Graphics, 18, 3 (July 1984), 119-128. 8. Greene, Ned, Environment Mapping and Other Applications of 
World Pro jection s, 1EEE Cutup uter Grap hies and Applications, 6, 11 (Nov. 1986), 210.9. 9. Greene, 
Ned, Organic Architecture [videotape], Siggraph Video Review 38, (Aug. 1988), ACM Siggraph, New York, 
segment 16. 10. Hahon, J. H., A Retrospective and Prospective Survey of the Monte Carlo Method, SIAMRev., 
12, 1 (Jan. 1970), 1-63. 11. Kaufman, Arie, 3D Scan Conversion Algorithms for Voxel-Based Graphics, 
Proceedings of 1986 Workshop on Interactive 3D Graphics, (Oct. 1986), 45-75. 12. Miller, Gene S., and 
C. Robert Hoffman, Illumination and Reflec- tion Maps: Simulated Objects in Simulated and Real Environ- 
ments, SIGGRAPH 84: Advanced Comp uter Animation Seminar Notes, (July 1984). 13. Norton, Alan, Generation 
and Display of Geometric Fractals in 3D, Computer Graphics, 16, 3 (July 1982), 61-67 14. Oppenheimer, 
Peter, Real Time Design and Animation of Fractal Plants and Trees, Computer Graphics, 20, 4 (Aug. 1986), 
56-64. 15. Preston, Kendall, and J. B. Duff, Modern cellular automata: theory and applications, Plenum, 
New York, 1984. 16. Prusinkiewicz, Przemyslaw, Aristid Lindenmayer, James I-Ianan, Developmental Models 
of Herbaceous Plants for Computer Imagery Purposes, Computer Graphics, 22, 4 (Aug. 1988), 141-150. 17. 
Reeves, William T., Particle Systems - A Technique for Modeling a Class of Fuzzy Objects, Computer Graphics, 
17, 3 (July 1983), 359- 376. 18. de Reffye, Philippe, Claude Edelin, Jean Francon, Marc Jaeger, Claude 
Puech, Plant Models Faithful to Botanical Structure and Development, Computer Graphics, 22, 4 (Aug. 1988), 
151-158.  19. Sabella, Paola, A Rendering Algorithm for Visualizing 3D Scalar Fields, Computer Graphics, 
22, 4 (Aug. 1988), 51-58. 20. Smith, Alvy Ray, Plants, Fractals, and Formal Languages, Com-puter Graphics, 
18, 3 (July 1984), 1-10. 21. Upson, Craig, Michael Keeler, VBUFFER: Visible Volume Rendering, Computer 
Graphics, 22, 4 (Aug. 1988), 59-64. 22. Wyvill, Brian, Craig McPheeters, Geoff Wyvill, Data Structure 
for Soft Objects, The Visual Computer, 2, 4 (1986), 227-234.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74352</article_id>
		<sort_key>185</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[An efficient 3-D visualization technique for finite element models and other coarse volumes]]></title>
		<page_from>185</page_from>
		<page_to>194</page_to>
		<doi_number>10.1145/74333.74352</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74352</url>
		<abstract>
			<par><![CDATA[We have developed a technique that extends existing 3-D result visualization methods for use with discretized volumes such as finite element models, where result values are only available at coarsely spaced points throughout the volume. It represents results as smooth isosurfaces within the volume for one or more result values, using visually continuous, bi-cubic polynomials.At each of the points where results are available, result gradients are calculated by a finite difference procedure. The result values and result gradients are used to obtain the location of and the tangents to the isosurfaces on lines connecting the result points. Continuous doubly curved surfaces and surface normals are constructed separately between these discrete isosurface points using bi-cubic polynomials. The isosurfaces are rendered with standard light-source shading and optional levels of translucency, surrounded by translucent free faces of the structure.The method generates isosurfaces on an element-by-element basis, without reference at display time to the behavior of neighboring elements. It is intended for high speed display-time processing of either static or varying isosurface values.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P232248</person_id>
				<author_profile_id><![CDATA[81100068176]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Gallagher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hibbitt, Karlsson and Sorensen Inc., Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P125956</person_id>
				<author_profile_id><![CDATA[81100491058]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Nagtegaal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hibbitt, Karlsson and Sorensen Inc., Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ahmad, S., Irons, B.M., and Zienkiewicz, O.C., "Analysis of Thick and Thin Shell Structures by Curved Elements", Intl. Journal of Numerical Methods in Engineering, Vol. 2, pp. 419-451, 1970.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Akin, J.E. and Gray, W.H.," Contouring on Isoparametric Surfaces", Intl. Journal for Numerical Methods in Engineering, Vol. 11, pp. 1893-1897, 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807461</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Artzy, E., Frieder, G. and Herman, G., "The Theory, Design, Implementation and Evaluation of a Three- Dimensional Surface Detection Algorithm", Proceedings of SIGGRAPH '80, in Computer Graphics 14,3, July 1980.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807388</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H.N. and Sederberg, T.W., "Conversion of Complex Contour Line in Computer Graphics 12,3, August 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Drebin, R.A., Carpenter, L. and Hanrahan, P., "Volume Rendering", Proceedings of SIGGRAPIt '88, in Computer Graphics 22,4, August 1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dupuis, G. and (Joel, J.J., "A Curved Finite Element for Thin Elastic Shells", Intl. Journal of Solids and Structures, Vol. 6, pp. 987-996, 1970.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321225</ref_obj_id>
				<ref_obj_pid>321217</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ferguson, J.C., "Multivariate Curve Interpolation", Journal of the ACM, Vol. 11, pp. 221-228, 1964.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fraeijs de Veubeke, B., "A Conforming Finite Element for Plate Bending", Intl. Jounal for Solids and Structures, Vol. 4, pp 95-108, 1968.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gallagher, R.S., "Postprocessing Techniques for 3D Non-linear Structures", RPI Workshop on Geometric Modeling and FEM, Rensselaer Polytechnic Institute, May 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W.E. and Cliae, H.E., "Marching Cubes: A High Resolution 3-D Surface Construction Algorithm", Proceedings of SIGGRAPH '87, in Computer Graphics 21,4, July 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Levoy, M., "Display of Surfaces from Volume Data", IEEE Computer Graphics and Applications, May 1988.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Meek, J.L. and Beer, G., "Contour Plotting of Data Using Isoparametric Element Representation", Intl. Journal for Numerical Methods in Engineering, Vol. 10, pp. 954-957, 1976.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4159</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mortenson, M.E., GEOMETRIC MODELING, John Wiley &amp; Sons, 1985, pp. 151-164.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Murthy, S.S. and Gallagher, R.H., "Anisotropic Cylindrical Shell Element Based on Discrete Kirchoff Theory", Intl. Journal for Numerical Methods in Engineering, Vol. 19, pp. 1805-1823, 1983.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nagtegaal, J.C. and Slater, J.G., "A Simple Non- Compatible Thin-Shell Element Based on Discrete Kirchoff Theory", in Non-Linear Finite Element Analysis of Plates and Shells (T.J.R Hughes et al, eds.), AMD, Vol. 48, pp. 167-192, 1981.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[PATRAN II Users Manual, PDA Engineering, July 1987, Ch. 37 (Theory).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807390</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sunguruff, A. and Greenberg, D.P., "Computer Generated images for Medical Applications", Proceedings of SIGGRAPH '78, in Computer Graphics 12,3, August 1978.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Winger, J.M., "Advanced Graphics Hardware for Finite Element Results Display", Advanced Topics in Finite Element Analysis, (J.F. Cory, Jr. and J.L. Gordon, eds.), PVP Vol. 143, ASME, New York, 1988.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Efficient 3-D Visualization Technique for Finite Element Models and Other Coarse Volumes Richard 
S. Gallagher and Joop C. Nagtegaai Hibbitt, Karlsson and Sorensen Inc. Providence, RI 02906. Abstract 
We have developed a technique that extends existing 3-D result visualization methods for use with discretized 
volumes such as finite element models, where result values are only available at coarsely spaced points 
throughout the volume. It represents results as smooth isosurfaces within the volume for one or more 
result values, using visually continuous, bi-cubic polynomials. At each of the points where results are 
available, re- sult gradients are calculated by a finite difference proce- dure. The result values and 
result gradients are used to obtain the location of and the tangents to the isosurfaces on lines connecting 
the result points. Continuous dou- bly curved surfaces and surface normals are constructed separately 
between these discrete isosurface points us-ing bi-cubic polynomials. The isosurfaces are rendered with 
standard light-source shading and optional levels of translucency, surrounded by translucent free faces 
of the structure. The method generates isosurfaces on an element-by- element basis, without reference 
at display time to the behavior of neighboring elements. It is intended for high speed display-time processing 
of either static or varying isosurface values. CR Categories: 1.3.5 [Computer Graphics] Computa- tional 
Geometry and Object Modeling: Curve, surface, solid and object representation, 1.3.7 [Computer Graph- 
ics] Three Dimensional Graphics and Realism: Color, shading, shadowing and texture, Visible line/surface 
al- gorithms, 3.6 [Computer-Aided Engineering] Computer- aided design (GAD). Additional Keywords: Finite 
element analysis, isosnr- face, postprocessing, scientific visualization, volume ren- dering. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 
ACM-0-89791-312-4/89/007/0185 $OO.75 Introduction Computational mechanics techniques such as the fi- 
nite element method make it possible to calculate the values of important physical quantities inside 
a three-dimensional body. These methods produce results that are available at specific points inside 
and on the surface of the volume. Techniques to display these result values on exterior visible surfaces 
have been available for some time, and are used as a standard tool by finite element analysts. Examples 
of these are shown in Figure 1. However, a more complete understanding of the physical results can be 
obtained by a true three-dimensional visualization of the result values inside as well as on the surface 
of the volume. Although recent methods display such three- dimensional fields effectively, two key points 
must be ad- dressed to adapt these visualization techniques to results obtained by the finite element 
method or related analysis methods. First, the analysis methods do not yield a contin-uum of results 
within the volume. In the case of finite element analysis, the volume is subdivided into discrete polyhedral 
elements of arbitrary shape, with result val- ues generally computed at their vertices. Usually, the 
ele- ments are relatively large, and direct display of tile vertex results leads to images of insufficient 
resolution. Contin- uous values can be obtained to any resolution by inter- polation between the discrete 
result points, and can be used to display the physical behavior in form of threshold volumes or surfaces. 
However, this approach has a large computational cost and inhibits interactive rendering. This brings 
us to a second point, which is the need for clear, unambiguous representation of threshold sur-faces 
within the continuum. A designer carrying out a fi- nite element analysis often faces a binary decision--does 
the structure satisfy the design criteria or not. Being able to visualize the domain within a critical 
threshold value--and in the case of nonlinear or time-dependent behavior, the evolution of this domain--provides 
a key to understanding the behavior of the three-dimensional structure. The method presented here extends 
voxel-based techniques to the display of continuous higher-order intra-element behavior. The results 
are rendered with idea of using the binary "above or below" value of each node to construct a pointer 
into a lookup table with ta- bles for general element topologies. These include 4-node tetrahedra, f-node 
wedges, and 8-node bricks as shown in Figure 2. Figure 2. Linear finite element topologies. The lookup 
tables yield the element edges that inter- sect the isosurface, and the connectivity of the intersec- 
tion points on the isosurface segments. Another exten- sion used here is that the lookup tables generate 
4-corner polygons where possible, with 3-corner polygons gener- ated only as needed in a degenerate case 
(Figure 3). This quadrilateral-dominated subdivision improves the visual continuity of the resulting 
isosurfaces, as we will discuss in more detail below. Figure 3. qDiangle vs. quad-dominant edge intersections. 
Linear interpolation along the specified element edges is used to generate both values and gradient light 
source norma.ls at all corner points of the resulting isosur- face polygons. From the vertices and normals, 
one can generate bi-cubic result surface segment patches, herein referred to as RSS (Figure 4). One or 
more RSS are pro- duced for each element intersecting the result surface. Ideally, a surface segment 
should maintain slope con- tinuity with any neighboring surface segment sharing a common edge and corner 
normals. The search for ap- propriate functions describing such surface segments has been a major issue 
in the finite element literature in conjunction with the development of Cl-continuous dou- bly curved 
shell elements--see Dupuis [6] and Fraeijs de Veubeke [8]. When no satisfactory solution emerged, Ah- 
mad, Irons and Zienckiewicz [1] proposed shell elements in which the surface normals are interpolated 
separately from the surface geometry. This approach forms the ba- sis for most currently used doubly 
curved shell elements, such as the one formulated by Murthy and Gallagher [14]. We adopt a similar method 
to obtain visuMly slope continuous surface segments. First we use standard bi- cubic Hermite functions 
for the interpolation of the sur- face geometry. The surface patches thus obtained are slope-continuousat 
the vertices, but not necessarily along the complete edge of the patch. Thus, if the surface geom- etry 
is used to calculate the normal at each point, visual slope discontinuities may be produced along the 
interior of adjacent RSS edges (Figure 5). Instead, we generate unique gradients of the normals at each 
vertex, and again use the bi-cubie I-Iermite functions to interpolate the nor- mals between the vertices. 
This guarantees continuity of the normals across adjacent edges. There is still a potential for noticeable 
discrepancies between surface shape and light source shading near RSS boundaries. These effects tend 
to be small, with Figure 5 representing an fairly extreme gradient between two surface segments. It appears 
that the discrepancies are potentially the most pronounced at interior RSS transi- tions. For this reason 
we try to minimize the number of interior boundaries by using quadrilateral surface patches wherever 
possible. The RSS are polygonalized and displayed as they are generated at display time, with light source 
shading and an optional degree of translucency. One or more threshold values may be used to generate 
multiple result surfaces. To enhance the picture visually, the visible free faces of the solid are rendered 
as shaded polygons with a high degree of translucency from a predefined free face list. Currently, this 
is done in a separate pass. With proper flagging of element free faces, the faces could be rendered simultaneously 
with the element isosurfaces. d a: b Figure 4. RSS defined by corner points and normals. 187 // - /' 
 1. Determine which nodes are "in" (e.g. greater than the result value) and which nodes are "out" (less 
than the result value). If all nodes are in or all nodes are out, no isosurfaces intersect the element 
and pro- cessing of the element is complete. 2. If some nodes are "in" and others are "out", use a Marching 
Cubes-style lookup table to determine which edges intersect the isosurface of the thresh- old result 
value, and which result surface segments (RSS) result from these vertices. As discussed pre- vionsly, 
we use a variant of the lookup table which generates quadrilateral regions where possible. Since in finite 
element analysis the element topologies can vary (e.g. cubes, wedges, tetrahedra), differ-ent lookup 
tables are used for the various element topologies. Each result surface segment (RSS) will be either 
a four-noded or three-noded surface patch. 3. For each vertex of the result surface segment, linearly 
interpolate between the nodes of the associated ele- ment edge to determine the vertex coordinates and 
the result gradient at each vertex.  In finite element analysis, the dement edges do not have to be 
linear: finite elements with quadratic or even cubic edge geometry are not uncommon in analysis prac- 
tice. In principle, it would be possible to use actual el- ement shape functions to interpolate the vertex 
points along a curved edge. Since the output of this step pro- duces only corner points and result gradients, 
the curva- ture of the finite element faces is not taken into account in the creation of the result surface 
segments. Moreover, display speed considerations make it desirable to treat curved edges as if they were 
linear. Construction of Isosurface Segments At this point, we have entities defined by 3 or 4 coor- dinate 
points and corresponding result gradient vectors. The result gradient is, by definition, orthogonal to 
the result isosurface. Hence, it is conceivable to render the surface segments directly as Gouraud or 
Phong shaded polygons, effectively treating the elements as large vox- els, as is done by Lorensen and 
Cline and others. In this case the averaged normal values would produce a conti- nuity of light source 
shading values along adjacent tLSS edges. In large finite elements, however, this can lead to noticeable 
visual transitions as the shading reflects an averaged polygon angle across the adjacent RSS edges. Moreover, 
the coarse nature of the element mesh would result in a substantial visual loss of the result behavior 
within the element itself. A much improved visualization is obtained with a higher-order mapping for 
the geometry of the result surface segments. We selected the paramet- ric hi-cubic polynomial for two 
reasons: its high geomet- ric order, and the ease of surface definition based on the available data. 
The geometric representation of a parametric cubic surface involves a coefficient matrix that is applied 
to the Hermite functions for a cubic variation of a single parameter ~ between 0 and l: f~ = 2~ 3 -3~ 
2 +1 .h = -2~ 3 + 3~ 2 /~ = ~ _ 2~ + A = ~ -~ These Hermite functions multiplied with a coefficient 
matrix Bijt~ defines the shape of the result surface seg- ment ,(~1, ~) = ~/A6)B~jkYk(~) j,k The matrix 
of coefficients has the form: (a~i(0,0) x(0,1) 0~,(0,0)o~ 0~,(0.z)o~2 Bijk = | o=4q,o) o,4o,1 ) o=,~(0,0) 
0%~(o,I)[ o~ 0~1 o~t o~2 o~x 0~2 Ozi(1, O) Oil(l,1) ,O:tti(1,0) a~tZi(1,1) In this 4 by 4 by 3 matrix, 
the values in the up- per left-hand quadrant represent the Cartesian coordi-nate data at each of the 
four vertices. The values in the upper right-hand and lower left-hand quadrants represent the tangent 
vectors in the parametric directions ~2 and ~1 respectively. The values in the lower right hand corner 
represent the"twist" of the surface at the vertices. The twist is related to the isosurface curvature, 
which can in principle be obtained from the nodal results with use of a second order approximation. However, 
this will require considerable additional pre-processing, and it is not clear that the resulting images 
will be enhanced sig- nificantly. Hence, the coefficients in the lower right-hand corner of the matrix 
are set to zero, producing what is known as a Ferguson patch or F-patch [7,13]. This type of surface 
is completely determined by its four paramet- ric cubic edge curves, or alternatively by the 4 corner 
positions and the corner tangent vectors. Calculation of the RSS. Geometry Matrix The next step in the 
process is to calculate the co- efficients in the matrix described above. Obviously, the terms in the 
upper left-hand part of the matrix are di- rectly obtained as the coordinates of the points a, b, e and 
d shown in Figure 6. The lower left-hand and upper right- hand terms are equal to the tangent vectors 
in the para- metric directions, which are obtained on an edge by edge basis. An edge of a result surface 
segment can be consid- ered the line of intersection of the isosurface with another surface, which we 
call the intersection surface. It is not ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 necessary to 
obtain acomplete description of this surface; however, at each vertex we construct the normal si to the 
intersection surface. At the vertex, the edge of the RSS must then be orthogonal to both si and the normalized 
result gradient nl. d c G Figure 6. Parametric cubic surface conventions. If the edge of the RSS is 
on the surface of an element, the obvious choice is to select the element face as the intersection surface. 
With this choice, the boundaries of the isosurface will coincide exactly with element face if the face 
is planar, and will be a close approximation otherwise. For the edge a -b at vertex a, the element face 
is characterized by the coordinate ~ and x~ of the vertices of the RSS edge and by the coordinates m~+ 
and ~-of the end points the edge of the parent element. The normal to element face is hence readily obtained 
as the cross product of ~+ -z~-and zb~ -~: ,? = e,~,,(~ + --~-)(~ --.~) where eijk is the alternator 
symbol: el23 ~ e231 ~ e312 ~ 1, e321 ---- e213 = el3 2 ~ --I and all other eli k terms equal zero. If 
the edge of the RSS is in the interior of an element, we select an intersection surface that leads to 
simple ex- pressions for the tangent vectors and remains close to the straight line connecting the end 
points, thus nfinirniz- ing the chance that the edge will go outside the element. This surface is characterized 
by the coordinates of the end points and the normal to the isosurface at the end points. For the edge 
a -d in Figure 6 this thus yields: a a d Sl = eijknj(~k --~) Finally, one takes the vector product n~ 
and s~, yielding the tangent vector t~ in the parametric direc-tion of the edge: tt_~ e S a tt ti ij~ 
ink Similar formulae calculate the tangent vector t~ at vertex b. After the direction of the tangent 
vectors has been obtained, the length of the tangent vectors must be determined. Note that the vector 
specifies the derivative of the position with respect to ,f, with ~ changing from 0 to 1 along the edge. 
In order to get a smooth variation of the position as function of ~, we scale the length of the tangent 
vector to the straight line distance between the end points. This assures an even distribution of sub- 
polygons during the later rendering stage. The tangent directions are reversed if needed to be oriented 
in the positive parametric direction. The above expressions apply directly for quadrilat- eral result 
surface segments. Triangular segments are treated as collapsed quadrilaterals. It is assumed that the 
points (0,0) and (0, 1) in parametric space coincide in physical space, that is xi(0,0) = ~i(0, 1). It 
automat-ically follows that the tangent vectors ti along the edge vanish, and thus Dzi(O,O)/O~2 = Ozi(O, 
1)/0~2 = 0. Calculation of the RSS Normal Matrix For interpolation of the normal vectors, a similar procedure 
is used. First, the normalized gradient vectors are used in the upper left hand part of the coefficient 
matrix. For each edge, a surface is then constructed that contains the edge and is orthogonal to the 
RSS at the vertices. For edges in the interior of an element, this sur- face is the previously defined 
intersection surface. The construction of this surface makes it possible to calculate the parametric 
derivatives of the normal vectors. The results of tiffs calculation are presented below without derivation. 
For the edge a -b, the coordinate ~i b and ~, the tangent vectors t~ and t~ and the normal vectors n~ 
and nl b are used to compute the following coefficients: = --n i(4ti + --+ ~a -b a a 2 = eiikrtin j tk/~ 
~b b a b 2 ~- eijknlnjtk/g where t is the distance between the vertices a and b. If the surface segment 
is a triangle and the edge is collapsed we take the limit ~g ~ 0whichyieldsa ~ = cz b =13 ~ = ~b .~ 0. 
The parametric derivatives of the normals at each vertex can then be expressed as: al, zib/a~ b b b " 
b a = a t i +~ eij~njt k The parametric derivatives of the normal vectors are then used to form the upper 
right- and lower left-hand side of the coefficient matrix to be used with the cubic interpolation functions. 
Analogous to the geometry in- terpolation, it is assumed that the "twist" of the normal vectors is zero 
at the vertices: l o,~,(o,o) o~,(o,1) I o&#38; o~ 0 0 o~,0,o) o,~,0,1 ) Subdivision and Rendering After 
the parametric cubic RSS has been con-structed, it can be output directly for display prior to processing 
the next element. For shaded isosurfaces, this involves subdivision of the RSS into an appropriate poly- 
gon density for output to a display device. These coor-dinates of the sub-polygons are generated with 
the para- metric cubic shape functions and the geometry coefficient matrix described in the previous 
sections. The local surface normal is interpolated using the same functions, but now using the coefficient 
matrix for the normal vectors. Any other isosurface value depen- dent display attributes, such as a level 
of translucency, are applied at this point. The sub-polygons are then ren- dered, in this case using 
hardware-level Gouraud polygon shading. The composite final image would generally consist of one of more 
isosuffaces within a translucent outer sur- face. In our case, this outer surface consists of a previ- 
ously computed list of the exterior free faces of the ele- ments. With display hardware Z-buffering, 
isosurface and free face data can be output in any order. However, sort- ing and processing both free 
face and isosurface segments within each element can diminate the need for hardware Z-buffering in most 
cases, if elements are processed from back to front within the current view. Figure 7 shows the flow 
of principal stress in the X direction through the earlier two element test case, while Figure 8 shows 
isothermal surfaces through a solid cylinder head. Graphics Display Considerations This method, and particularly 
its processing of smooth, continuous surface segments one element at a time, was specifically designed 
to allow newer graphics device architectures to produce high-speed display of in- terior solid behavior 
in a 3-D real-time mode. As a result of increasing I/O bandwidth, many cur-rent graphics device architectures 
support real-time 3-D display by continuous re-transmission of display entities. In this case, software 
is designed around a tight, lower- level display loop of graphics entities. With the proper pre-calculation 
of data as outlined above, the processing of isosurfaces can be performed as part of a low level element-by-element 
display loop. This is not a fully optimal display situation -prac-tice within the current application 
program involves ini- tial decomposition of the solid element model into visible free faces, with the 
lowest level display loop being one through the visible free face list. For static or display-list imagery, 
the isosurface output of this method will need to be appended to the free face list. On the other hand, 
by maintaining an ass0ciativity between element and visible free face data, the display loop could be 
set up to incur minimal overhead by dis- carding those elements which contain neither visible free faces 
nor isosurface segments. Another advantage to having the finM isosurface cal- culation within a single 
display pass is that it allows real- time variation of the isosurface value within a static state of 
results. It also is well suited to display of multiple isosurface levels, as each value can be evaluated 
during the processing of each element within the display loop with a minimum of added overhead. Display 
of multiple isosurface regions with varying levels of translucency, as shown in Figure 9, and isosurface 
animation both repre- sent promising techniques for display of the overall result flow within a solid 
hody. The Issue of Result Smoothing Smooth isosurfaces generated from sparse data on a relatively coarse 
grid approximate the exact variation of the field variables in the finite element formulation, but are 
calculated from a finite element solution yielding discontinuous gradients across element boundaries. 
The process of smoothing therefore adds another level of ap- proximation to these results. It should 
be realized, however, that the fields calcu- lated by the finite element model are in itself an approxi- 
mation to the exact solution of the differential equations that describe the mathematical model. For 
example, it can be demonstrated that the exact solution to the heat transfer problem exhibits continuous 
temperature gradi- ents throughout the model. In that sense, the smoothed isosurfaces give a better impression 
of the nature of the solution of the mathematical problem. No general state- ment can be made that smoothing 
of discretized results gives a better or worse quantitative representation of the exact solution. In 
our experiences with finite elements, we have seen examples of both. Another issue is the. smoothing 
of results across known discontinuities of physical characteristics or result values - for example, 
when elements of materials such ds rubber and steel share common nodes. This is not an is- sue of the 
smoothing approach per se, but rather the raw input data provided to it. It occurs when element-based 
results are averaged to common corner nodes, without regard to such discontinuities. In the current applications 
program, we have the ability to associate more than one result with a single node when shared by elements 
with different physical properties or topology. Moreover, the averaging of gra- dient results at these 
nodes can be restricted to adjacent nodes values for like element types. This approach will yield discontinuous, 
separate isosurfaces across element  ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 type boundaries 
- which is exactly what one wants under the circumstances. The overriding benefit to properly applied 
smooth- ing techniques is the conceptual feel it can give to the nature of the 3D behavior. Particularly 
as one looks at multiple or complex results, the faceted nature of discrete result values can impede 
this visual level of understand- ing. Smooth three-dlmensional isosurfaces provide the analyst with a 
more easily understood representation of the result values in the structure or process. Conclusions The 
technique presented here accomplishes three goals in the visualization of 3-D behavior when results are 
available on a relatively coarse, non-uniform grid:  the generation of smooth, non-faceted result sur-faces; 
  the processing of single elements within a low-level display loop with minimal stored data;  visual 
representation of intra-element behavior.  Volume rendering techniques are starting to make an impact 
on the display of 3D structural behavior, as ev- idenced by applications such as Winger's [18] real-time 
implementation of a Marching Cubes approach for vi- sualizing finite element results. While the method 
we present here was developed with the finite element anal- ysis of solid objects in mind, however, its 
basic underlying principles are intended as a step towards the larger goal of reducing the computational 
and display bandwidth of general 3-D solid visualization problems. Acknowledgements Dr. James Winget 
of Silicon Graphics contributed valuable insights into this problem. Todd Gerhardt of Kohler Company 
furnished the cylinder head model. Tek- tronix, Inc. provided the 4336 display equipment on which the 
images were generated, with particular credit to the assistance of Dave Smith and Jerry Bouvisuto. David 
Berman and Godofredo Camacho of HKS devel- oped major portions of the display and rendering soft- ware. 
Finally, Dr. David Hibbitt deserves credit for his concepts of an interactive environment for finite 
element analysis, of which this work is a part. References 1. Ahmad, S., Irons, B.M., and Zienkiewlcz, 
O.C., "Analysis of Thick and Thin Shell Structures by Curved Elements", Intl. Journal of Numerical Methods 
in Engi- neering, Vol. 2, pp. 419-451, 1970. 2. Akin, J.E. and Gray, W.H.," Contouring on Isoparametric 
Surfaces", Intl. Journal for Numerical Methods in Engineering, Vol. 11, pp. 1893-1897, 1977.  3. Artzy, 
E., Frieder, G. and Herman, G., "The The- ory, Design, hnplementation and Evaluation of a Three- Dimensional 
Surface Detection Algorithm", Proceedings of SIGGRAPH '80, in Computer Graphics 14,3, July 1980. 4. 
Christiansen, H.N. and Sederberg, T.W., "Con-version of Complex Contour Line in Computer Graphics 12,3, 
August 1978. 5. Drebin, R.A., Carpenter, L. and Hanrahan, P., "Volume Rendering", Proceedings of SIGGRAPH 
'88, in Computer Graphics 22,4, August 1988. 6. Dupuis, G. and Goel, J.J., "A Curved Finite Ele- ment 
for Thin Elastic Shells", Intl. Journal of Solids and Structures, Vol. 6, pp. 987-996, 1970. 7. Ferguson, 
J.C., "Multivariate Curve Interpola- tion", Journal of the ACM, Vol. 11, pp. 221-228, 1964. 8. Fraeijs 
de Veubeke, B., "A Conforming Finite Element for Plate Bending", Intl. Jounal for Solids and Structures, 
Vol. 4, pp 95-108, 1968. 9. Gallagher, R.S., "Postprocessing Techniques for 3D Non-linear Structures", 
RPI Workshop on Geomet-ric Modeling and FEM, Rensselaer Polytechnic Institute, May 1987. 10. Lorensen, 
W.E. and Cline, H.E., "Marching Cubes: A High Resolution 3-D Surface Construction Al- gorithm", Proceedings 
of SIGGRAPH '87, in Computer Graphics 21,4, July 1987. 11. Levoy, M., "Display of Surfaces from Volume 
Data", IEEE Computer Graphics and Applications, May 1988. 12. Meek, J.L. and Beer, G., "Contour Plotting 
of Data Using Isoparametric Element Representation", Intl. Journal for Numerical Methods in Engineering, 
Vol. 10,  pp. 954-957, 1976. 13. Mortenson, M.E., GEOMETRIC MODELING, John Wiley &#38; Sons, 1985, pp. 
151-164. 14. Murthy, S.S. and Gallagher, R.H., "Anisotropic Cylindrical Shell Element Based on Discrete 
Kirchoff Theory", Intl. Journal for Numerical Methods in En-gineering, Vol. 19, pp. 1805-1823, 1983. 
 15. Nagtegaal, J.C. and Slater, J.G., "A Simple Non- Compatible Thin-Shell Element Based on Discrete 
Kir- choff Theory", in Non-Linear Finite Element Analysis of Plates and Shells (T.J.R Hughes et al, eds.), 
AMD, Vol. 48, pp. 167-192, 1981. 16. PATRAN II Users Manual, PDA Engineering, July 1987, Ch. 37 (Theory). 
 17. Sunguruff, A. and Greenberg, D.P., "Computer Generated Images for Medical Applications", Proceed- 
ings of SIGGRAPH '78, in Computer Graphics 12,3, Au- gust 1978. 18. Winger, J.M., "Advanced Graphics 
Hardware for Finite Element Results Display", Advanced Topics in Finite Element Analysis, (J.F. Cory, 
Jr. and J.L. Gordon, eds.), PVP Vol. 143, ASME, New York, 1988.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74353</article_id>
		<sort_key>195</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Computer graphics visualization for acoustic simulation]]></title>
		<page_from>195</page_from>
		<page_to>206</page_to>
		<doi_number>10.1145/74333.74353</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74353</url>
		<abstract>
			<par><![CDATA[Computer simulations can be used to generate the spatial and temporal data describing the acoustical behavior of performance halls, but typically the analytical results are difficult to assimilate and compare. By using computer graphics to display the multi-dimensional data, substantially greater amounts of information than that conveyed by standard techniques can be communicated to the designer. This allows designs of different acoustical spaces to be tested, evaluated, and compared.An example comparing the acoustical behavior of three different concert halls demonstrates these techniques and allows for the simultaneous assimilation of much of the information necessary to evaluate the acoustical nature of a space. The use of three-dimensional images, color, animation and abstract representation allows for the comprehension of the complex results of a scientific simulation. Specifically, the simultaneous display of particular icons familiar to the discipline enabled the simultaneous presentation of up to twelve parameters.From a more general point of view, the procedures demonstrate how computer graphics can be utilized for the portrayal of multi-dimensional time dependent data. The visualization techniques are potentially useful for the display of three-dimensional vector fields in many scientific and design applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P8531</person_id>
				<author_profile_id><![CDATA[81100381729]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stettner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39072544</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ailred and Newhouse, "Applications of the Monte Carlo Method to Architectural Acoustics," Journal Acoustic Society America, Vol. 30, No. I0, Oct 1958, pages 903-904.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barron M. and A. H. Marshall."Spatial Impression Due to Early Lateral Reflections in Concert Halls: The Derivation of a Physical Measure," Journal of Sound and Vibration, Vol. 77 No.2, 1981, pages 211-232.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Borish, J. "Extension of the Image Model to Arbitrary Polyhedra," Journal Acoustic Society America, Vol. 75, No.6, June 1984, pages 1827-1836.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bradley, J. S. "Experience With New Auditorium Acoustic Measurements," Journal Acoustic Society America, Vol. 73, No.6, June 1983, pages 2051-2058.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cremer, L. and H. A. Muller. Principles and Applications of Room Acoustics, Vol. 2, Applied Science, London, 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Edwards, N. A. "Music Performance Acoustics and Room Shape: An Investigation Employing an Images Model of Room Acoustics," Presented to the Acoustical Society of America Meeting, San Diego, Nov 1983.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Edwards, N. A. "Considering Concert Acoustics and the Shape of Rooms," Architectural Record, Vol. 172, No.9, Aug 1984, pages 133 - 138.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Haviland, J. K. and B. D. Thanedar. "Monte Carlo Applications to Acoustical Field Solutions," Journal Acoustic Society Ameiica, Vol. 54, No. 54, 1973.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hedeen, Robert A., Compendium of Materials For Noise Control, US Dep. HEW, NIOSH Technical Report, Washington, D.C. May 1980.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Jordan, V. L. Acoustical Design of Conceit Halls and Theatres, Applied Science, London, 1980.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Keller, J.B. "Geomelrical Theory of Diffraction," Journal Optitcal SocieO' America, Vol. 52, No. 2,1962, pages 116- 130.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kuttruff H. Room Acoustics, Wiley, New York, 1973]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Krokstad, A. and S, Strom and S. SOrsdal. "Calculating the Acoustical Room Response by the use of a Ray Tracing Technique," Journal Sound Vibration, Vol. 8 No. 1, 1968, pages 118-125.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[London, "The Determination of Reverberant Sound Absorption Coefficients from Acoustical Impedance Measurements," Journal Acoustic Society America, Vol. 22, 1950, pages 263-269.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Reichardt, W. and W. Schmidt. "Die Wahrnehmbarkeit der Ver~inderung yon Schallfeldparametern bei der Darbeitung yon Musik," Acoustica ,Vol. 18, 1967.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Reichardt, W. and U. Lehman. "Optimierung yon Raumeindruck und durchsichtigkeit yon musikdarbietungen durch auswertung yon impulshalltests," Acoustica ,Vol. 48, 1981~ pages 174-I85. o]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sabine, Wallace C. Collected Papers on Acoustics, Harvard University, Cambridge, MA 1927. Reprinted Dover 1964.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sekiguchi, K. and Sho Kimura and Tomoyuki Sugiyama, "Approximation of Impulse Response Through Computer Simulation Based on Finite Sound Ray Integration," Journal Acoustical Society Japan, Vol. 6, No. 2, 1985.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Schroeder, M. R. "Digital Simulation of Sound Transmission in Reverberant Spaces (Part 1)," Journal Acoustic Society America, Vol. 47, No. 2, 1970, pages 424- 431.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Stettner, A. S. Computer Graphics for Acoustic Simulation and Visualization, Master's thesis, Program of Computer Graphics Lab, Cornell University, Ithaca, NY, January 1989.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Walsh, J. P. "The Design of Godot: a System for Computer-aided Room Acoustic Modeling and Simulation," Proceedin~ l Oth International Congress on Acoustics, Sydney, 1980.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Wayman, J. L. and J. P. Vanyo. Computer Simulation of Sound Fields Using Ray Methods, PhD dissertation, University of California, Santa Barbara, July 1980.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~~SIGG RAPH'89, Boston, 31 July-4 August, 1989 simplify the problem. Wallace Sabine [17], considered 
the pioneer of modern acoustics, used ray theory around the turn of the 20th century in the formulation 
of his well known equation for the calculation of room reverberation time. In the late 1950's, Allred 
and Newhouse [l] first applied Monte Carlo Methods to calculate the mean-free paths of spaces by tracing 
rays on a computer. About a decade later, Krokstad, Strcm and Sorsdal [13] made the first attempt to 
use a computer to trace rays based on a simple geometric model to get an idea of the acoustical response 
of a hypothetical room. This was followed by Schroeder's digital simulation of simple reverberant spaces 
[19]. Haviland and Thanedar then extended earlier work with Monte Carlo methods in an attempt to obtain 
time histories of the pressure at a given point in a field [81. Wayman and Vanyo used these and similar 
techniques applied to more complex environments [22]. Walsh [21] conducted similar research in the development 
of the Godot System. Others have attempted to use another method similar to ray casting known as the 
image method to study the acoustical response of imaginary rooms. Interesting work has been done in this 
field, by Borish [3] and Edwards [6]. More recently, Sekiguchi, Kimura, Sugiyama have also been working 
on extending ray methods, using what is known as finite ray integration [18]. The ray method assumes 
that wave surfaces can be treated as rays normal to these surfaces and traveling in the direction of 
propagation in the medium. The behavior attributed to sound rays is similar to that of light rays in 
geometric optics, except for a few crucial differences. These differences stem from the sound ray's slower 
propagation speed, longer wavelength and higher rate of energy transfer to the surrounding environment. 
The most obvious distinction is the comparatively limited propagation speed of sound waves. Light propagates 
away from a source so quickly that the eye is unable to sense its temporal nature. The ear, on the other 
hand, is able to detect minute variations in sound pressure due to the longer time delays in a sound 
wave's propagation. Humans have the ability to perceive these variations even within small time scales 
of observation, on the order of 50 milliseconds. Another important difference of sound waves when compared 
to those of light results from the relatively long wavelengths of sound. When the wavelengths of the 
sound rays are comparable to the boundary and irregularity dimensions of an environment, the behavior 
of sound rays is not easily compared to simple reflections or refractions in geometric optics. While 
the acoustical data generated for the visualization did not include the effects of diffraction, the simulation 
process could be modified to do so using a geometric theory of diffraction [11]. The last major difference 
between light and sound rays results from the tendency of sound to easily transfer its energy to matter 
with which it interacts. Little energy is lost by a light ray when it passes through unobstructed air. 
The theoretical sound ray on the other hand will see considerable attenuation, especially at high frequencies, 
since a ray's energy vibrates air molecules which in turn dissipates energy in the form of thermal exchange. 
A surface's acoustical reflectivity is also strongly affected by variations in air pressure caused by 
rays incident on its surface. For this reason the sound absorption characteristics of a surface depend 
on the the ray's angle of incidence in ways which are unlike those of light. All of these characteristics 
combine to make the behavior of sound more difficult to predict and comprehend than the behavior of light, 
and new visualization methods are required to represent its appropriate measurements. The authors have 
used a modified specular and diffuse ray tracing algorithm combined with Monte Carlo techniques to simulate 
the time varying spatial distribution of sound. Unfortunately, within the space limitations of this paper, 
it is not possible to provide the details of this simulation procedure. This material is currently being 
submitted for publication. The interested reader is referred to Stettner's thesis [20] and to the general 
acoustic's literature [5] and [12]. Characterization of Sound Reverberation Time For a long time, reverberation 
time and other early sound energy decay measurements were considered the primary objective parameters 
in the acoustical design of sound spaces. Trying to characterize a hall's sound by using simple criteria, 
however, can be problematic. Recently, the inadequacy of using the reverberation quantity alone to predict 
the acoustics of a space has become widely realized [4] [10]. In response, a wide variety of relatively 
new acoustical measurements have been introduced. Three types of acoustical measurement now used characterize 
the clarity and definition, the spatial impression, and the overall strength of sound. Clarity and Definition 
The importance of early reflected sound energy to the intelligibility of speech sounds and to the clarity 
and definition of musical sounds is widely recognized [4]. If there is too much early reflected sound 
energy, the sounds of either music or speech will blend and lack definition. On the other hand if there 
is too little, the sound will be overwhelmed by the latter sound and clarity will be lost. One of the 
most popular measurements of early to late sound energy was proposed by Reichhardt. [16] Reichhart's 
measure of clarity incorporated an early energy time of 80 msec, which he believed to be appropriate 
for music. He defined this measurement, C80 , as the log of the early arriving sound (from 0 msec to 
80 msec after the direct sound) divided by the late sound energy arriving 80 msec and after the direct 
sound. Cso=lOlog f~ 2 p (t)dt where p2(t) represents the medial value of sound pressure varying through 
time. C80 is expressed in decibels (dBs). Spatial Impression The measurement of spatial impression quantifies 
to what extent the listener senses being immersed in the sound as opposed to just receiving it and relates 
to the listener's sense of envelopment in the sound field and perceived broadening of the sound source. 
The subjective degree of spatial impression has been found to correlate with the ratio of lateral to 
frontal energy at a listener's position [15]. One useful measurement, found to be linear with the degree 
of spatial impression, is the lateral energy fraction, Lf, defined as the ratio of early lateral reflected 
energy (over the first 80msec) to the total early energy including the direct energy [2]. Expressed in 
the following equation: Er Lf= t=sms /son, s / where q~ is the angle between the reflection path and 
the axis through the listener's ears, r is the reflection energy, which is dependent on time, and t = 
0 milliseconds is the time of the arrival of the direct sound energy. The numerator in the ~ Computer 
Graphics, Volume 23, Number 3, July 1989 equation of lateral fraction includes only reflected energy 
and the denominator includes both the direct and reflected sound energy. The closer the incident energy 
direction approaches this normal direction, the greater its contribution to the lateral fraction, and 
therefore toward a sense of spatial impression. (Figure 1 ) incident A sound /I J energy 0 /. normal 
[/ left ear Figure 1: Definition of Lateralization Overall Sound Strength A third type of measurement 
characterizes the overall strength of sound. Unfortunately, the sensation of the strength of sound is 
based on a number of psychoacoustic factors. Not only is the perception of loudness not linear with the 
amount of sound energy received, the temporal nature of incident sound also affects its perception. However, 
as a simple approximation, a measurement of the mC, erall energy at positions through time is useful 
in detecting possible sound strength problems. Areas where there are anomalies in sound strength can 
be caused by a number of different situations. In a hall there may be positions in which the sound field 
is significantly weaker, either at a particular time or on average, than the desired normal level. These 
deficient spots can result from an inability to receive direct or reflected sound energy due to room 
geometry, or from surface or air absorption of sound energy during propagation. Within the normal design 
process these problems can be very difficult to predict on a global level (at all points in an environment). 
In contrast to energy deficient areas, are those room positions of abnormally high energy on average 
or at particular instances of time. These acoustic phenomena result primarily from room geometry which 
directs energy toward specific areas. Most often these concentrations can be explained as the result 
of specular surface reflection. Some extreme examples of specular geometric concentration are whispering 
galleries, and dome focusing. In both of these situations, the walls in the rooms are shaped in manners 
which produce extremely consistent reflection from many positions all directed toward a singular area. 
Geometric situations in which specular focusing occurs can be very difficult to predict using contemporary 
design techniques, especially if the complexity of a room's shape is great. A third defect which relates 
to the measurement of the overall strength of sound through time is acoustic echo. Echos are simply reflections 
that come after the direct sound and are strong enough to be heard as distinct. A common example of distant 
echo in a hall is the reflected sound heard by musicians on stage, coming from a highly specularly reflective 
back wall.  Visualization Techniques The evaluation of the acoustical properties of a concert hall or 
auditorium is a difficult problem. But perhaps more difficult is the simultaneous assimilation of all 
of the information necessary to evaluate its acoustical nature. In addition to the three spatial parameters 
describing unique locations in space, one needs to be aware of the relative magnitudes and directions 
of the sound energy as well as its corresponding acoustical characteristics at different positions through 
time. Furthermore, this information needs to be viewed in its relationship to the reflection properties 
of the enclosed space, and its dependence on both time and wavelength. Efficient methods for representing 
these types of acoustical parameters in terms easily comprehended by the engineer/architect/designer 
have not yet been developed. Although analytical techniques for the simulation or measurement of the 
propagation of sound are available, the resulting information is lost using the crude measurements traditional 
in the practice today. Computer graphics visualization methods offer some potential opportunities for 
the display and understanding of this multi-dimensional information. Standard three-dimensional perspective 
image generation methods with diffuse shading can portray the physical space. Color can be effectively 
utilized to provide relative scalar values of engineering parameters, but care must be taken to maintain 
the correct perception of the physical space. The display speed of current graphics workstations allows 
images to be dynamically updated fast enough to animate time-dependent phenomena. Lastly, abstract symbols 
and representations can be utilized to depict a wide variety of additional parameters. These icons can 
be sized large enough to be seen within the global context of the simulation, but small enough as to 
not affect one's perception of the global behavior. Just displaying multi-dimensional information, however, 
is not necessarily going to give useful insight into a physical problem. The data presented must not 
overload the user's mind with o'Jerly specific and possibly insignificant information. It also must be 
displayed in ways which can be intuitively identified and easily understood. The visualization techniques 
presented for displaying acoustical measurements serve as new examples of computer graphics visualization 
techniques. Their capability for simultaneously displaying multi-dimensional information can help in 
the understanding of the acoustics of a concert hall. For comparison purposes, the acoustics of three 
particular hall designs are evaluated and compared. One model of a real hall was modeled and its design 
was varied to generate the data for the other two designs. The surfaces common between the models were 
assigned identical acoustical characteristics. Each test environment contained the same source description 
and relative position, and each contained a number of detailed listening devices known as "dummy-heads", 
positioned and oriented in identical positions with reference to the source. The acoustical characteristics 
of clarity and definition, spatial impression, and overall strength are depicted using icons and color. 
Although the simulation can be conducted using any particular wavelength of sound, the display of the 
frequency dependence of the simulation results is not addressed in the visualization examples following. 
The primary model used in the simulation was a simplified version of Boston Symphony Hall. (Figure 2a) 
The environment consisted of approximately 400 surfaces which when meshed amounted to approximately 6000 
polygons. The other two environments were based roughly on this model, with variations on the wall angles 
to produce a fan shaped and reverse fan shaped room when viewed in plan. (Figure 2b) The models remained 
identical in terms of ceiling and floor angles, but the stage size changed in accordance with the walls. 
The balconies in each of these rooms also conformed to its wall shape. The angle of slope of the balconies 
encircling the rooms was in each case equal to that shown in the hall section. The acoustical attributes 
of the surfaces within each model were varied to approximate the different reflectance characteristics 
of different parts of the room. [14119] The single source used in the tests of the simulation was chosen 
to t97 .~.~SIGGRAPH '89, Boston, 31 July-4 August, 1989 emit at a frequency of 1 kHz. Since a geometric 
approximation for diffraction was not implemented, only the absorption characteristics of surfaces and 
the air would be affected by a change in the frequency of the source. ~Seating Position Blocks ] Front 
Section View 0 10Meters I ''''I'''''''''', I Feet 0 10203040 __ Boston Symphony Hall '""'"] / .. Fan 
Variation Source" I ...... Reverse Fan Variation Posit!o_.n~, ,- ..................... [ Plan View Figure 
2a (top): Boston Symphony Hall in Section Figure 2b (bottom) Variations on Hall Design in Plan The source 
was positioned along the center axis of each hall, exactly 10 feet from the front of the stage and 4 
feet above the stage floor. The center direction of the source was directed at the center of the back 
wall of the first balcony. The source emission was weighted 65% in an isotropic spherical emission and 
35% in a cosine weighted emission in the center direction. This distribution was chosen to simulate a 
semi-directional sound source.  Visualization of Clarity and Definition The measure of early to late 
sound energy as expressed by the scalar measurement C80 serves as a good indicator of the clarity and 
definition of sound. This scalar measurement could be calculated for all receiver surfaces in an environment 
and displayed globally using a simple color scale. Then, each of the sample halls could be judged in 
terms of the absolute C80 levels at listener positions and by the variation in the C80 levels over many 
listener positions. If, however, one wants to easily see meaningful variations of the clarity level, 
and assimilate other acoustical information as well, an abstract icon can be cleverly used. One way of 
producing such an icon would be to split an abstract receiver surface horizontally into a upper and lower 
section. The lower section would represent the energy level reaching the surface within the first 80 
msec after the direct sound. The upper section would represent the energy level reaching the surface 
in the later tirne interval, spanning from 80 msec after the direct sound to infinity. Any energy level 
value could be chosen to be represented by the lower section of constant width. The upper section's width 
could then be sized as a fraction of that hypothetical level, so that the difference between the lower 
section in dBs and the upper section in dBs would equal the C80 value. In the test environments, each 
of the ear-like surfaces on the dummy-heads serve as icons for the visualization. The lower section of 
each icon represents an early energy level of approximately 20 dB, (Figures 3 and 7) 198 Late Interval 
 Early Interval 0 5 101520 Energy Level in Decibels C80 = Early Level - Late Level Figure 3: Early-to-Late 
Ratio Icon -For the desired minimum C80 of 0 dB , the icon would have a top portion equal in size to 
the bottom section. The maximum value of 8 dB would correspond to a top portion equal to 3/5 of the bottom. 
Icons with top sections larger than the bottom sections or smaller that 3/5 of the bottom's width fall 
outside the preferred range of values. Visualization of Spatial Impression Similarly, lateral fraction, 
Lf, serves as a good scalar measurement of spatial impression which can be calculated for any number 
of surfaces in an environment and displayed globally using a simple color scale. The lateral fraction 
is the ratio of the early lateral reflected energy (over the first 80msec) to the total early energy 
including the direct energy. By the term lateral, i1 is meant to the degree it is received along the 
direction of the normal to the ear. The closer the early incident energy directions approach this normal 
direction, the greater the lateral fraction, and therefore, the greater the sense of spatial impression. 
In this case an icon can be generated to portray a relative amount of spatial impression at each receiver 
surface. A cone originating on the surface of each receiver and whose wide side is directed out in the 
normal direction can be used to represent the relative degree of spatial impression. To coincide with 
the intuition of the user, the icon can be mar~ipulated so that the wider the cone angle, c~, the greater 
the degree of perceived spatial impression. (Figures 4 and 8) cone of d of spatial in normal receiver 
surface Figure 4: Spatial Impression Icon -The wider the cone angle, or, the greater the degree of perceived 
spatial impression. Unfortunately, the cause of.poor lateralization and thus deficient sound is not evident 
from the scalar value of lateral fraction. Lateralization depends on the complex reflective properties 
of the room, a combination of both geometry and surface attributes. Ray diagrams can allow the user to 
see the incident energy's relationship with the reflective properties of the room. There are two basic 
types of ray diagrams which are often used in the spatial design of a concert hall. Ray path diagrams 
show the paths followed by rays from the source to a ~ Computer Graphics, Volume 23, Number 3, July 
1989 given listener position. Ray source diagrams show the positions of real and virtual sources which 
would be apparent at a receiver position at a given time interval. A virtual source is an image of a 
real source whose position has shifted from the real source's position because its sound arrived through 
indirection. Ray path diagrams can be investigated and used for comparison with other positions in a 
hall or similar positions in another design. From examining the lateralization of the ray paths of the 
sound incident at two receiving surfaces representing ears during the critical first 50 milliseconds 
or so after the direct sound, one is able to see what room features contribute to that incident sound 
energy. (Figure 5a and 9) Ray source diagrams give a graphic representation of the envelopment and lateralization 
of the sound reaching a listener through time. For each ray which hits the surface or surfaces under 
scrutiny, a line is drawn in the direction opposite to the ray's incident direction, and is given a length 
equal to the total distance traveled by the ray on its journey from the source to the surface. (Figure 
5b and 9) While a ray diagram for a surface or receiver position may give directional incident energy 
information, it may not give an accurate description of the energy reaching a surface through a particular 
direction. Since many rays, each of which deposit their bundle of energy to a surface, may be traveling 
over the same or nearly the same path as seen in the visualization, the ray diagram will not accurately 
indicate the magnitude of the sound incident through particular directions, and thus may give an incorrect 
indication of lateralization. Furthermore, only the energy incident at one listener position can be analyzed 
at a time. receiver dummy-head receiver ~ pos~__~ dumm.YThead~ X- ~i ~ source position ~ position source 
position Plan View Figure 5a (left): Sample Ray Path Diagram: Figure 5b (right): Sample Ray Source Diagram: 
As an alternative to these diagrams, the rays incident within a chosen time interval can be sorted through 
subtended solid angles of equal size of the hemisphere over a receiver position, and representative rays 
can be drawn from the center of the hemisphere out through the center of each chunk of solid angle. (Figure 
6) The length of each ray indicates the strength of the incident energy within each solid angle and its 
direction indicates from which approximate direction that energy arrived. Furthermore, the color of each 
ray indicates its approximate sound strength in decibels referenced into a color scale. Known as a soundrose 
diagram, this three-dimensional incident energy distribution can show the time interval incident energy 
where direction is displayed using rays to indicate both the lateralization at the surface and the area 
of the room last responsible for its final reception. (Figure 10) The use of ray and soundrose diagrams 
in acoustical research is not new [7], yet their application within the context of computer graphics 
visualization techniques warrants their inclusion in this work. Figure 6: Sample Soundrose Construction 
Visualization of the Overall Strength of Sound The analysis of the overall strength of sound in a room 
can be approached in several ways. A certain amount of information can be determined simply using the 
geometric model of the space. More effectively, however, time interval flux or sound pressure levels, 
displayed at each surface in the environment using color can show global energy hot or cold spots. By 
displaying global sound pressure levels, global relative loudness levels can be estimated, and improper 
energy distributions can be recognized (Figure 11). Distinct acoustical aberrations which occur after 
the direct sound, such as low energy areas, echos or geometric concentrations, can be identified by visualizing 
the energy reaching the environment during short time intervals. Figures 12 to 23 are 12 frames each 
of 10 msec time interval, selected from an animation of the dynamic simulation of a sound energy impulse 
in the model hall. Unfortunately, the dynamic range with which the simulation began was so great that 
the low level resolution of the late acoustical energy is lost when the same color scale is used late 
in the simulation. For this reason, Figures 18 to 23 are displayed using a re-scaled color gradient. 
Using the global methods described, areas of interest can then be investigated in detail. Echograms, 
which are plots of the energy (flux) or sound level versus time incident at a position, can be generated 
for chosen surfaces. From these graphs acoustic spikes or holes can be seen. The echograms can then be 
analyzed to help identify different types of echos or geometric focusing. Energy levels at particular 
time intervals can be chosen and the paths between the source and surfaces of the rays contributing to 
those levels can be shown. This process can not only identify the existence of a problem but also its 
probable geometric cause. (Figures 24 and 25) Combined Visualization Many of the visualization tools 
described can be simultaneously displayed. In this way, general trends in a room's distribution of clarity, 
spatial impression, and sound energy strength, in relation to both the reflective nature of the space 
and the lime of propagation can be visualized. The combined visualization can take place on any number 
of dummy-heads made up of two surfaces which serve as abstractions of oversized ears. These ears can 
be sectioned to display their early to late ratio measurement of clarity in decibels. They can each have 
a protruding cone whose spread conveys a relative amount of lateral fraction and therefore the degree 
of perceived spatial impression. The relationship of the lateralization of received sound energy to the 
room's reflective properties can be visualized using soundrose diagrams superimposed on each ear surface. 
The length of a ray indicates its strength relative to other rays. A ray's color indicates its approximate 
sound strength in flux or decibels referenced into a color scale, and its direction indicates from which 
approximate direction that energy arrived. Overall sound strength received at each ear as well as at 
each surface in the environment if desired can be conveyed using the same color scale used to indicate 
the ray energy level in the soundrose diagrams. One is able to evaluate and compare some of the important 
acoustical characteristics of each of the three environments by comparing only the combined visualizations 
of their acoustical   L.,i~SIGGRAPH '89, Boston, 31 July-4 August, 1989 measurements. Figure 26 shows 
one such combined visualization. The combined visualization is important in a generic sense since it 
is capable of communicating many parameters simultaneously. Dummy-heads can be placed at any position 
specifying an x,y,z coordinate. Two ears representing a particular listening orientation specify two 
more dimensions. Upon each of the ear-like surfaces, the parameters of clarity, spatial impression (lateral 
fraction), and the direction and magnitudes of the cause of the resultant spatial impression can be conveyed. 
The overall strength of the sound energy reaching each ear is also shown. By also choosing to show the 
dynamic propagation of the energy through the environment over time, a dozen or more parameters can be 
simultaneously imparted to the viewer. In addition, although not shown, a two-dimensional echogram for 
any particular receiver position could be concurrently displayed in a separate window to show the time 
dependence of the energy received there. One could then choose time intervals within the echogram to 
simultaneously visualize the ray paths responsible for the energy level displayed. This would allow for 
further analysis into the relationship between the room's reflective characteristics and the sound at 
a particular position. Conclusions A visualization of acoustical measurements allows for the simultaneous 
assimilation of much of the information necessary to evaluate the acoustical nature of a space. The acoustical 
analysis of the three performance halls serves as a good example of the visualization of multi-dimensional 
information in a generic sense. The intuitive use of three- dimensional images, color, animation and 
abstract representation allows for the comprehension of the complex results of a scientific simulation. 
Specifically, the simultaneous display of particular icons familiar to the discipline enabled the simultaneous 
presentation of up to twelve parameters. From a more general point of view, the procedures demonstrate 
how computer graphics can be utilized for the portrayal of multi-dimensional time dependent data. Thus, 
the visualization techniques are potentially useful for the display of three-dimensional vector fields 
in many scientific and design applications. Acknowledgements The research was conducted under two National 
Science Foundation grants entitled, "Interactive Input and Display Techniques" (#DCR8203979) and "Visualization 
for Scientific Computing" (#ASC8715478). Simulation and displays were performed on equipment generously 
donated by Digital Equipment Corporation and Hewlett Packard Corporation. Special thanks to Holly Rushmeier, 
Roy Hall and Michael F. Cohen for their helpful discussions and input into this research and to Carl 
Rosenberg of Bolt Beranek and Newman for his contribution and encouragement. Lastly, thanks go to Ben 
Trumbore, Tim O'Conner, Filippo Tampieri, Rod Recker, David Baraff, Jim Ferwerda, Stuart Feldman, Eric 
Chen, Rich Eaton, Julie O'Brien, Ellen French, and Emil Ghinger for their general assistance. References 
1. Allred and Newhouse, "Applications of the Monte Carlo Method to Architectural Acoustics," Journal 
Acoustic Society America, Vol. 30, No. 10, Oct 1958, pages 903-904. 2. Barron M. and A. H. Marshall."Spatial 
Impression Due to Early Lateral Reflections in Concert Halls: The Derivation of a Physical Measure," 
Journal of Sound and Vibration, Vol. 77 No.2, 1981, pages 211-232.  2OO 3. Borish, J. "Extension of 
the hnage Model to Arbitrary Polyhedra," Journal Acoustic Society America, Vol. 75, No.6, June 1984, 
pages 1827-1836. 4. Bradley, J. S. "Experience With New Auditorium Acoustic Measurements," Journal Acoustic 
Society America, Vol. 73, No.6, June 1983, pages 2051-2058. 5. Cremer, L. and H. A. Muller. Principles 
and Applications of Room Acoustics, Vol. 2, Applied Science, London, 1978. 6. Edwards, N. A. "Music 
Performance Acoustics and Room Shape: An Investigation Employing an Images Model of Room Acoustics," 
Presented to the Acoustical Society of America Meeting, San Diego, Nov 1983. 7. Edwards, N. A. "Considering 
Concert Acoustics and the Shape of Rooms," Architectural Record, Vol. 172, No.9, Aug 1984, pages 133-138. 
 8. Haviland, J. K. and B. D. Thanedar. "Monte Carlo Applications to Acoustical Field Solutions," Journal 
Acoustic Society America, Vol. 54, No. 54, 1973. 9. Hedeen, Robert A., Compendium of Materials For Noise 
Control, US Dep. HEW, N1OSH Technical Report, Washington, D.C. May 1980. 10. Jordan, V. L. Acoustieal 
Design of Concert Halls and Theatres, Applied Science, London, 1980. 11. Keller, J.B. "Geometrical Theory 
of Diffraction," Journal Optitcal Society America, Vol. 52, No. 2,1962, pages 116- 130. 12. Kuttruff 
H. Room Acoustics, Wiley, New York, 1973 13. Krokstad, A. and S, Strum and S. Seirsdal. "Calculating 
the Acoustical Room Response by the use of a Ray Tracing Technique," Journal Sound Vibration, Vol. 8 
No. 1, 1968, pages 118-125. 14. London, "The Determination of Reverberant Sound Absorption Coefficients 
from Acoustical Impedance Measurements," Journal Acoustic Society America, Vol. 22, 1950, pages 263-269. 
 15. Reichardt, W. and W. Schmidt. "Die Wahrnehmbarkeit der Ver~inderung yon Schallfeldparametern bei 
der Darbeitung yon Musik," Acoustica ,Vol. 18, 1967. 16. Reichardt, W. and U. Lehman. "Optimierung von 
Raumeindruck und durchsichtigkeit yon musikdarbietungen durch auswertung yon impulshalltests," Acoustica 
,Vol. 48, 1981, pages 174-185. o 17. Sabine, Wallace C. Collected Papers on Acouslics, Harvard University, 
Cambridge, MA 1927. Reprinted Dover 1964. 18. Sekiguchi, K. and Sho Kimura and Tomoyuki Sugiyama, "Approximation 
of Impulse Response Through Computer Simulation Based on Finite Sound Ray Integration," Journal Aeoustieal 
Society Japan, Vol. 6, No. 2, 1985. 19. Schroeder, M. R. "Digital Simulation of Sound Transmission in 
Reverberant Spaces (Part 1)," Journal Acoustic Society America, Vol. 47, No. 2, 1970, pages 424- 431. 
 20. Stettner, A. S. Computer Graphics for Acoustic Simulation and Visualization, Master's thesis, Program 
of Computer Graphics Lab, Cornell University, Ithaca, NY, January 1989. 21. Walsh, J. P. "The Design 
of Godot: a System for Computer-aided Room Acoustic Modeling and Simulation,"  Proeeeding lOth International 
Congress on Acoustics, Sydney, 1980. 22. Wayman, J. L. and J. P. Vanyo. Computer Simulation of Sound 
Fields Using Ray Methods, PhD dissertation, University of California, Santa Barbara, July 1980.   
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74354</article_id>
		<sort_key>207</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Three dimensional Terrain modeling and display for environmental assessment]]></title>
		<page_from>207</page_from>
		<page_to>214</page_to>
		<doi_number>10.1145/74333.74354</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74354</url>
		<abstract>
			<par><![CDATA[A technique for compositing computer generated images of buildings and background images created from aerial photographs is described. The aerial photo data are mapped onto a terrain model based on cartographic data. The technique can be used to pre-evaluate visual impact of large scale construction by means of not only still images but also animations.The technique can be briefly described as follows: 1) an accurate, three-dimensional terrain model is created based on cartographic data. 2) a hierarchy of aerial photo data at various resolutions is mapped onto the terrain model as a texture. 3) the height of trees is taken into account in regions near the viewpoint. 4) allowing intersections of terrain models with constructions facilitates geometric adjustments and shadowing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31083821</person_id>
				<author_profile_id><![CDATA[81100412545]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaneda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima University, Saijo-cho, Higashi-hiroshima, 724 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14119449</person_id>
				<author_profile_id><![CDATA[81100330610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima University, Saijo-cho, Higashi-hiroshima, 724 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31090468</person_id>
				<author_profile_id><![CDATA[81100145250]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakamae]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima University, Saijo-cho, Higashi-hiroshima, 724 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31088636</person_id>
				<author_profile_id><![CDATA[81100539710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fukuyama University, Higashimura-cho, Fukuyama, 729-02 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14058008</person_id>
				<author_profile_id><![CDATA[81332531129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tanaka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tokyo Electric Power Co., Inc., 1-4-10 Irifune, Chuou-ku, Tokyo, 100 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P277684</person_id>
				<author_profile_id><![CDATA[81100252239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Takao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Noguchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tokyo Electric Power Co., Inc., 1-4-10 Irifune, Chuou-ku, Tokyo, 100 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agui, T., Miyata, K., and Nakajima, M. A Reconstructing Method of 3D Mountainous Shapes from Contours. Trans. IEICE J69-D, 12 (1986), 1905-1912, (in Japanese).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807388</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Christiansen, N. H. and Sederberg, T. W. Conversion of Complex Contour Line Definitions into Polygonal Element Mosaics. Computer Graphics 12, 3 (1978), 187- 192.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C. Shadow Algorithms for Computer Graphics. Computer Graphics 1I, 2 (1977), 242-247.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807507</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Feibush, E. A., Leroy, M., and Cook, R. L. Synthetic Texturing Using Digital Filters. Computer Graphics 14, 3 (1980), 294-301.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808572</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gardner, G.Y. Simulation of Natural Scenes Using Textured Quadric Surfaces. Computer Graphics 18, 3 (1984), tt-t9.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jet Propulsion Laboratory. Finale L. A.-- The Movie. SIGGRAPH '87 Film and Video Show (1987).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807485</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Marshall, R., Wilson, R., and Carlson, W. Procedure Models for Generating Three-Dimensional Terrain. Computer Graphics 14, 3 (1980), 154-162.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15890</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Miller, G. S. P. The Definition and Rendering of Terrain Maps. Computer Graphics 20, 4 (1986), 39-48.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15909</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Nakamae, E., Harada, K., Ishizaki, T., and Nishita, T. A Montage method: The Overlaying of the Computer Generated Images onto A Background Photograph. Computer Graphics 20, 4 (1986), 201-214.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617471</ref_obj_id>
				<ref_obj_pid>616004</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Nakamae, E., Ishizaki, T., Nishita, T., and Takita, S. Compositing 3D Images with Antialiasing and Various Shading Effects. IEEE Computer Graphics ~ Applications 9, 2 (1989), 21-29.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nishita, T., Okarnura, I., and Nakamae, E. Shading Models for Point and Linear Sources. A CM Transactions on Graphics 4, 2 (1985), 124-146.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27486</ref_obj_id>
				<ref_obj_pid>27485</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Petrie, G. and Kennie, T. J. M. Terrain Modeling in Surveying and Civil engineering. Computer Aided Design 19, 4 (1987), 171-187.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Porter, T. and Duff, T. Composing Digital Images. Computer Graphics 18, 3 (1984), 253-259.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rougelot, R. S. The General Electric Computed Color TV Display. Proceedings of the Second University of illinois Conference on Computer Graphics. in Part,neat Concepts in Computer Graphics. eds. Faiman, M. and Nievergelt, J. University of Illinois Press (1969), 261- 281.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807421</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Uno, S. and Matsuka, H. A General Purpose Graphic System for Computer Aided Design. Computer Graphics 13, 2 (:1.979), 25-232.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Williams, L. Pyramidal Par~metrics. Computer Graphics 17, 3 (1983), 1-11.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 Three Dimensional Terrain Modeling and Display for 
Environmental Assessment Kazufumi Kaneda, Fujiwa. Kato, Eihachiro N~kama~e, Hiroshima University Saijo-cho, 
Higashi-hiroshima, 724 Japan Hideo Tanaka, and Takao Noguchi Tokyo Electric Power Co., Inc. Tomoyuki 
Nishita, Fukuyama University Higashimura-cho Fukuyama, 729-02 Japan  1-4-10 Irifune, Chuou-ku, Tokyo, 
100 Japan Abstract A technique for compositing computer generated images of buildings and background 
images created from aerial pho- tographs is described. The aerial photo data are mapped onto a terrain 
model based on cartographic data. The tech- nique can be used to pre-evaluate visual impact of large 
scale construction by means of not only still images but also animations. The technique can be briefly 
described as follows: 1) an accurate, three-dimensional terrain model is created based on cartographic 
data. 2) a hierarchy of aerial photo data at various resolutions is mapped onto the terrain model as 
a texture. 3) the height of trees is taken into account in re-gions near the viewpoint. 4) allowing intersections 
of terrain models with constructions facilitates geometric adjustments and shadowing. CR Categories and 
Subject Descriptions: 1.3.3 [Computer Graphics]: Picture]Image Generation; 1.3.5 [Computer Graphics]: 
Computational Geometry and Object Modeling; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and 
Realism General Terms: Algorithms Additional Key Words and Phrases: Contour Line, Terrain Model, Visual 
Environment, Environmental Assess- ment, Texture Mapping  Introduction Pre-evaluation of visual impact 
of large construction projects, such as electric power plants, etc., has lately re- ceived a great deal 
of attention. Two methods have com- monly been used; one is to paint the proposed building onto a landscape 
photograph, the other is to build a three di- mensional scale model. The former method lacks objec- tivity 
as depending on an artist's ski]], and the number of views generated is restricted because each view 
must be sep- arately painted. Using a model case, the view point can be animated, but construction of 
the model is very time- consuming and expensive, camera angles may be restricted due to space limitations, 
and the resulting images are very Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. &#38;#169;1989 ACM-O-89791-312-4/89/O07/0207 $00.75 artificial looking. In order 
to overcome these disadvantages, S. Uno et al. [15] developed a graphic system which overlays com- puter 
generated images onto a background photograph, E. A. Peibush et M. [4] proposed an anti-aliasing method 
for montages using digital filtering, and T. Porter et al. [13] presented a method which composites complex 
3D images using an "a-channel". In [9], some of the authors of the present paper proposed a montage method, 
in which a computer generated image of the proposed construction is overlaid onto a background photograph 
with fog and shadow effects. However, with this method the viewpoint is restricted by available background 
photos, and cannot be animated. To address this problem, we here describe a new method, in which the 
construction is overlaid onto a background gen- erated by mapping aerial photo data as a texture onto 
a 3D terrain model generated from cartographic data. In this way still images with nearly unrestricted 
viewpoints, as well as animations, may be generated. The technique involves the following steps: 1) Input 
of contour lines from a topographical map. 2) Generation of a 3D terrain model from cartographic data. 
3) Adjusting the color of digitized aerial photographs. 4) Mapping aerial pho- tograph data as textures 
onto the terrain model. 5) Modifi- cation of model to take account of height of trees. 6) Over- laying 
computer graphic images of buildings etc. with their shadows onto the generated background. A number 
of methods of generating 3D terrain models from contour lines have been described. They can be sepa- 
rated into two classes [12]: filling the area between contour lines with a triangular mesh [2], [1], 
and with a rectangular mesh [7], [5], [8]. In both cases, the main aim has been to generate views for 
flight simulators; i.e., to display moun-tains at some distance, from a considerable height. Because 
the viewpoint is at high altitude, the range of distance from the viewpoint to various points on the 
landscape is not very great. Therefore, patches of constant size, independent of distance from viewpoint, 
are generally satisfactory. A bird's- eye animation for Los Angeles basin was made by JPL [6], for example. 
However, in environmental assessment images, the view- point will usually be very near the ground, i. 
e. at the level of the human eyes. In this case, small patch size results in very inefficient processing 
for regions distant from the viewpoint, while large patch size results in inadequate image quality in 
regions near the viewpoint (see Fig. 1). '89, Boston, 31 July-4 August, 1989 |m i Ill | I   ii ii 
 (a) (b) Figure 1: Terrain modeling. (a) Triangular mesh. (b) Rect- angular mesh. To overcome these problems, 
we use a radial mesh for the terrain model: the further from the viewpoint, the larger the patch size, 
resulting in a more even distribution of res- olution over the landscape. This method also leads to high 
speed hidden surface removal because the rows of the mesh are generated in order of distance between 
these rows and the view point. However, the mesh must be recalculated when the viewpoint changes. A local 
processing method, described below, is used to increase the efficiency of gener- ating the terrain model. 
In addition, the height of trees and the shadows of large constructions cast onto the background in regions 
near the viewpoint are taken into account. The height of trees close to the viewpoint cannot be neglected, 
particularly when the viewpoint is close to the ground. For example, if a road passes through a wood, 
the road should be obscured by the trees for most viewpoints, although it is not obscured in the aerial 
photo. And the shadows cast onto the background by constructions are important for making realistic images 
especially when their location is close to the viewpoint. In order to demonstrate the effectiveness of 
our method, we show some montages based on actual aerial photo data, with power substations, transmission 
towers, etc. overlaid. 2 Generation of Three Dimensional Terrain Model 2.1 Generation of Radial Mesh 
A radial mesh, as shown in Fig. 2, can be easily generated as follows. (1) A view volume (a square pyramid) 
is determined by the viewpoint, the view reference point~ and the view ~ngles. The b~.se of the view 
volume is divided into a rectangular mesh whose density depends upon the desired display accuracy. (2) 
The intersections of the lines which connect the view- point with each node in the rectangular mesh, 
and a  208 viewpoint ~ref~reace poia, view volume sampling point Y X Figure 2: Generation of a radial 
mesh. I I I 1 I I  ! (a) (b) Figure 3: A terrain model. (a) Before subdivision in depth direction. 
(b) After subdivision in depth direction. reference plane parallel to the ~y-plane, are calculated. These 
points are called sampling points in the discus- sion below. After perspective transformation, the sizes 
of patches of the terrain model are nearly constant in the horizontal direc- tion, but in the vertical 
direction, the size depends upon the gradient of the terrain; the steeper the terrain, the larger the 
vertical size of the perspective-transformed patch (see Fig. 3 (a)). To counter this problem, the radial 
mesh is recursively divided in the vertical direction until the vertical length of all patches satisfies 
the desired accuracy criterion. When the mesh is divided, a row of sampling points is inserted as shown 
in Fig. 4. In this way, the mesh size on a screen becomes nearly con- stant and gives homogeneous topographic 
images as shown in Fig. 3 (b) where accuracy of the terrain model, especially in the region of the skyline, 
is improved. Because the operation of this algorithm depends upon the location of the viewpoint, the 
terrain model must be regen- @ ~ Computer Graphics, Volume 23, Number 3, July 1989 / Input Pz and p~ 
6 rl~ ~ ttr~/io z ~y = IgW/pX  j~l 1) ,- j l', ~ j + l  [ ej.-l,~ "~ I P, ~ the following row h new 
row /~ is Sil = H(Kil) ( fori = 1,...,n= + 1 ) iastead midway 5:,b = H(Ki~) ( for i = 1,.-.,n~ + 1 ) 
between PI and P~ I. I y~s=G(S,t)(fori=l,...,n,+l) Y~b = G(S~,) ( for i = 1,,..,n. + 1 ) ag~t = y:~ -v;l 
(for/= l,-..,n,+l)  no ( d~,/<l~ ) (for all i ) yes Is processing of rows ~ no< j and j + I complete 
? / yes l i-~+J I J llO < j=,,,+l > (a) n~+l I P, S. j ............... ,....... ] ....... (D): , ~',j 
.......... 1 1 i 2 i+1 n=+l 1 2 i i+1 n,+l i. (b) (c) (d) px, P!t : the horizontal and vertical resolutions 
in pixel units r~z, n v : the number of horizontal and verticed divisions wx, w v : the width ~nd height 
of the screen  j : the index of the row of the mesh being processed PI, Pb : the indices pointing to 
the rows preceding and following the new row Si!, Si/, : the sampling points on the radical mesh corresponding 
to the intersections KiI and Kit, (see Fig. 4 (c)) Kit, Kib : the intersections on rows P and Pb (see 
Fig. 4 (b)) H(K) : the operation to calculate the sampling points on the radical mesh corresponding to 
the intersection .K on the rect- angular mesh. Y~, Y~b : Y components of the screen coordin&#38;tes 
of the sampling points Si! and Sib (see Fig. 4 (d)) G(S) : the operation to calculate y component of 
the screen co- ordinate of the sampling point S Figure 4: Method of subdividing a terrain model in the 
di-rection of depth. (a) Flow chart of subdividing a terrain model. (b) Rectangular mesh. (c) Radial 
mesh. (d) Per-spective view. sampling point contour line hid2 + h2dl hs -- dl + d2 h, : the height of 
the sampling point Ps hi, h2 : the height o{ the contours Cl and C2, respectively dl, d2 : the distance 
from the sampling point Ps to the con- tours Cl and C2, respectively Figure 5: Calculation of the height 
of a sampling point. block y c,   /\ el /~-I  JP, '---1 j C3 > X 0 (a) (b) Figure 6: Calculation of 
height using a local method. (a) Contour segments are recorded for each block. (b) Hier- archy of contour 
inclusion. erated every time the viewpoint is moved. However, through this disadvantageous process, hidden 
surface removal calcu- lations reduce because of the property that the rows of the mesh are lined up 
in order of distance from the viewpoint. In the next section we will discuss a method for efficiently 
calculating a terrain model. 2.2 Calculation of Height Using Local Process- ing The height of a sampling 
point is calculated by interpolat- ing between the closest contour segments on either side (see Fig. 
5). As a preprocessing step, the entire area is divided into a number of large blocks, and the contours 
running through each block are recorded as shown in Fig. 6 (a). For any sampling point (for instance, 
P1 or P2 in the figure), the nearest contour segment to its right within the same block is located (C2 
or C4 in the figure). Then the contour is examined to see if it contains the sampling point (Be-cause 
all contours are defined in counter clockwise order, the sense of the angle determined by the sampling 
point and two ordered points of the contour indicates whether the point is contained in the contour.) 
The other contour is lo- cated based on a separately memorized hierarchy of contour inclusion, as shown 
in Fig. 6 (b). For Pl, the contour C3 is immediately located, because it is the only contour directly 
contained by C2. For P2, the candidate contour pairs are either Cl and C2 or C1 and C~ because P~ located 
at a col. C2 is selected because it is closer to P2 than C4.  ~ Computer Graphics, Volume 23, Number 
3, July 1989 road horizon 2' 4 ~.~.i~;.i.j/.1.1..~rtate)i to they horizontal direction (a) nealy perpendicular 
patches N (b) Figure 10: Taking into account of the height of trees. (a) Height of trees ignored. (b) 
Height of trees included. in which a road and the horizon should be hidden by trees. The closer the 
camera position is to ground level, the more serious this problem becomes. We address this problem as 
follows. (1) The height of trees is added to the height obtained from topographical contour maps. Referring 
to the aerial photo, the regions covered by trees, the color of the trees, and the average height of 
the trees, are speci-fied. When a sampling point is located inside a region specified as tree covered, 
its color is compared to the tree color. If the color matches, the tree height for that region, modulated 
by a function, e.g. intensity of a tex- ture color, is added to the contour height. (2) Nearly perpendicular 
patches are generated at the boundary of tree covered regions. These patches have a very unnatural appearance, 
because of the enlarge-ment in the vertical direction of the applied texture (see Fig. 10 (b)).  This 
problem is countered, as shown in Fig. 11, by rotat- ing the boundary patches to lie horizontally, and 
mapping tree textures from near the boundary. However, the image still looks unnatural, particularly 
close to the viewpoint, be- cause the mapped texture is not a side view of trees. The quality can be 
further improved by mapping some actual photographs of side views of trees instead of the aerial photo 
data in these regions. In this way, the boundary between tree-covered and other regions is much more 
naturally displayed, and trees obscure roads, bases of towers, etc., as expected. i li~--'~ }tee-covered 
region i!i ) 0 , 4+  texture (aerial photograph) X Figure 11.: Mapping textures onto boundary patches 
of tree- covered regions. 3.3 Geometric Adjustment and Shadowing Allowing intersection of the base of 
constructions with a complex shape terrain model usually facilitates their geo-metric adjustment. Bases 
which may intersect with the ter- rain model are specified in the input data in order to make shadowing 
easy. Shadowing of constructions and terrain models is calcu- lated by using shadow volumes [3]. Shadow 
volumes for constructions are calculated by using the light source and the contour edges of the convex 
polyhedra which form the constructions (refer to [11]). While for a terrain model its back faces should 
be used for making shadow volumes be- cause these faces are fewer in number than front faces in environmental 
assessment views; the position of the sun is usually above the mountains. Therefore back faces are usu- 
ally a minority. 4 Examples Fig. 12 shows the effect of the terrain modeling techniques on the quality 
of generated images. Fig. 12 (a) shows sev- eral computer generated images, a power substation, several 
transmission towers, and a tank, compositing with a back- ground image created from the aerial photo. 
In order to composite each image taking account of hidden surface re- moval, the 3D image composition 
method [10] was employed. No special processing described in section 3.2 for example has been done for 
trees in this image; roads and tower base are visible although they should be partially obscured by trees, 
so the image seems unnatural. Fig. 12 (b) shows the effect of adding the tree height to the contour altitude; 
the image is improved a little. However, the boundaries of tree-covered regions look like cliffs because 
the resolution of the textures mapped onto these regions is very low and some triangular patches are 
clearly visible. Fig. 12 (c) shows the effect of mapping actual side views of trees, as discussed in 
section 3.2, to boundaries of tree- covered regions. The resulting image looks relatively natu- ral. 
Figures 12 (a) and (b) were generated on a 500 x 363 display; the horizontal sampling pitch which indicates 
the '89, Boston, 31 July-4 August, 1989   ~~SIGGRAPH horizontal size of the mesh on the screen is 
5.2 pixels. In Fig. 12 (c), the sampling pitch is set to 2 pixels, then the mountains are more accurately 
rendered. Fig. 12 (d) is a recent photograph of the same region. Some differences from the computer generated 
montages are apparent and are due to the passage of time since the aerial photograph was taken. In Fig. 
13, we examine the relation between the resolu- tion of the aerial photo data and the location of the 
view- point. Fig. 13 (a) was generated using aerial photographs with resolutions of 1/6000, 1/2000, and 
1/1000, with the viewpoint 40 meters from the ground (see Fig. 8). In (b), a proposed switching station 
is overlaid onto the image of (a). In (c), only one aerial photo, at scale 1/6000, is used. Fig. (d) 
shows that relatively high quality montages can be generated, even with viewpoints at fairly low altitudes 
(7 meters), if aerial photos of high enough resolution are used. It is important for the ultimate resolution 
of the overlaid image to match that of the generated background. Mapped trees, rice straw racks and poles 
close to the viewpoint make the image more realistic. In (e), the same aerial photos as (a) are used, 
with the altitude of the viewpoint reduced to 1.4 meters. Fig. (f) is a recent photograph from almost 
the same viewpoint as that of (e), in which rice straw racks were omitted to compare with (f). Fig. 14 
shows the same landscape as Fig. 13, viewed from the opposite side, Notice the shadows cast on the ground 
by the base and towers of the switching station. The horizontal sampling pitch used for Figures 13 and 
14 is 6.7 pixels and the display size, except for Fig. 13 (e), is 1000 x 666 pixels. Conclusions A new 
method for overlaying computer generated images onto background landscapes created by mapping aerial 
pho- tos onto terrain models based on cartographic data has been described. This method exhibits the 
following advantages. (1) The radial mesh results in approximately constant mesh density across the entire 
scene after perspective trans-formation. (2) A hierarchy of aerial photo textures at various resolu- 
tions is used to assure approximately constant resolu-tion of the texture maps after perspective transforma- 
tion. (4) Taking into account the height of trees, and mapping side views of trees at the boundaries 
of tree covered regions imparts a more natural appearance to the mon- tage.  To demonstrate the usefulness 
of the method, several montages for environmental assessment of the construction of power substations 
have been generated. Acknowledgment The authors wish to thank Bonnie Sullivan for her assistance with 
the English manuscript. We would also like to thank the reviewers for their helpful comments. References 
[1] Agui, T., Miyata, K., and Nakajima, M. A Recon-structing Method of 3D Mountainous Shapes from Con- 
tours. Trans. IEICE J69-D, 12 (1986), 1905-1912, (in Japanese). [2] Christiansen, N. H. and Sederberg, 
T. W. Conversion of Complex Contour Line Definitions into Polygonal Element Mosaics. Computer Graphics 
12, 3 (1978), 187- 192. [3] Crow, F. C. Shadow Algorithms for Computer Graph- ics. Computer Graphics 
1I, 2 (1977), 242-247. [41 Feibush, E. A., Leroy, M., and Cook, R. L. Synthetic Texturing Using Digital 
Filters. Computer Graphics 14, 3 (1980), 294-301. [5] Gardner, G.Y. Simulation of Natural Scenes Using 
Textured Quadric Surfaces. Computer Graphics 18, 3 (1984), 11-19. [6] Jet Propulsion Laboratory. Finale 
L. A. --The Movie. SIGGRAPH '87 Film and Video Show (1987). [7] Marshall, R., Wilson, R., and Carlson, 
W. Proce-dure Models for Generating Three-Dimensional Ter-rain. Computer Graphics 14, 3 (1980), 154-162. 
[8] Miller, G. S. P. The Definition and Rendering of Ter- rain Maps. Computer Graphics 20, 4 (1986), 
39-48. [9] Nakamae, E., Harada, K., Ishizaki, T., and Nishita, T. A Montage method: The Overlaying of 
the Computer Generated Images onto A Background Photograph. Computer Graphics ~0, 4 (1986), 201-214. 
[I0] Nakamae, E., Ishizaki, T., Nishita, T., and Takita, S. Compositing 3D Images with Antialiasing and 
Various Shading Effects. IEEE Computer Graphics ~ Applica. tions 9, 2 (1989), 21-29. [11] Nishita, T., 
Okamura, I., and Nakamae, E. Shading Models for Point and Linear Sources. ACM Transac-tions on Graphics 
4, 2 (1985), 124-146. [12] Petrie, G. and Kennie, T. J. M. Terrain Modeling in Surveying and Civil engineering. 
Computer Aided De- sign i9, 4 (1987), 171-187. [13] Porter, T. and Duff, T. Composing Digital Images. 
Computer Graphics 18, 3 (1984), 253-259. [14] Rougelot, 13.. S. The General Electric Computed Color TV 
Display. Proceedings of the Second University of Illinois Conference on Computer Graphics. In Pertinent 
Concepts in Computer Graphics. eds. Faiman, M. and Nievergelt, J. University of Illinois Press (1969), 
261- 281. [15] Uno, S. and Matsuka, H. A General Purpose Graphic System for Computer Aided Design. Computer 
Graph- ics 13, 2 (1979), 25-232. [16] Williams, L. Pyramidal Parametrics. Computer Graph- ics 17, 3 (1983), 
1-11.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74355</article_id>
		<sort_key>215</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Good vibrations: modal dynamics for graphics and animation]]></title>
		<page_from>215</page_from>
		<page_to>222</page_to>
		<doi_number>10.1145/74333.74355</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74355</url>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39081720</person_id>
				<author_profile_id><![CDATA[81452609331]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pentland]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vision Sciences Group, E15-410, The Media Lab, M.I.T., 20 Ames St., Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015212</person_id>
				<author_profile_id><![CDATA[81100006659]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vision Sciences Group, E15-410, The Media Lab, M.I.T., 20 Ames St., Cambridge MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[[1] Anderson, J. S., and Bratos-Anderson, M., (1987) Solving Problems in Vibrations, Longman Scientific and Technical Publ., Essex, England.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[[2] Barr, A., (1981) Superquadrics and angle-preserving transformations, <i>IEEE Computer Graphics and Application, 1</i> 1-20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[[3] Barr, A., (1984) Global and local deformations of solid primitives. Proceedings of SIGGRAPH '84, <i>Computer Graphics 18</i>, 3, 21-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[[4] Barzel, R., and Barr, A., (1988) A Modeling System Based On Dynamic Constraints, Proceedings of SIGGRAPH '88, <i>Computer Graphics</i>, Vol. 22, No. 4, pp. 179-188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[[5] Borning, A., (1979), Thinglab - a constraint-oriented simulation laboratory. SSL-79-3, Xerox PARC, Palo Alto, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[[6] Gardiner, M. (1965) The superellipse: a curve that lies between the ellipse and the rectangle, <i>Scientific American </i>, September 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[[7] Issacs, P., and Cohen, M., (1987) Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions, and Inverse Dynamics, Proceedings of SIGGRAPH '87, <i>Computer Graphics</i>, Vol. 21, No. 4, pp. 215-224.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37407</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[[8] Lasseter, J., (1987) Principles of Traditional Animation Applied to 3D Computer Animation, Proceedings of SIGGRAPH '87, <i>Computer Graphics 21</i>, 4, 35-44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[[9] Moore, M., and Wilhelms, J., (1988) Collision Detection and Response for Computer Animation, Proceedings of SIGGRAPH '88, <i>Computer Graphics 22</i>, 4, 289-298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>6066</ref_obj_id>
				<ref_obj_pid>6065</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[[10] Pentland, A. (1986) Perceptual Organization and the Representation of Natural Form, <i>Artificial Intelligence Journal</i>, Vol. 28, No. 2, pp. 1-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[[11] Pentland, A., (1987) Towards and Ideal 3-D CAD System, <i>SPIE conference on Machine Vision and the Man-Machine Interface</i>, Jan. 11-16, San Diego, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[[12] Pentland, A., and Williams, J. (1988) Virtual Construction, <i>Construction</i>, Vol. 3, No. 3, pp. 12-22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[[13] Sutherland, I., (1963), Sketchpad: A Man-Machine Graphical Communications System, in Interactive Computer Graphics, in <i>1963 Spring Joint Computer Conference</i>, reprinted in H. Freeman, ed., IEEE Comp. Soc., 1980, pp. 1-19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[[14] Terzopoulos, D., Platt, J., Barr, A., and Fleischer, K., (1987) Elastically deformable models, Proceedings of SIGGRAPH '87, <i>Computer Graphics</i>, Vol. 21, No. 4, pp. 205-214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[[15] Williams, J., Musto, G., and Hawking, G., (1987) The Theoretical Basis of the Discrete Element Method, <i>Numerical Methods in Engineering, Theory, and Application </i>, Rotterdam: Balkema Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[[16] Williams, J., and Musto, G. (1987) Modal Methods for the Analysis of Discrete Systems, <i>Computers and Geotechnics</i>, Vol. 4, pp. 1-19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[[17] Witkin, A., and Kass, M. (1988 Space-Time Constraints, Proceedings of SIGGRAPH '88, <i>Computer Graphics 22</i>, 4, 159-168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Modal  Good Vibrations: Dynamics for Graphics and Animation Alex Pentland and John Williams Vision 
Sciences Group, E15-410 The Media Lab, M.I.T. 20 Ames St., Cambridge MA 02138 Abstract Many of the problems 
of simulating and rendering complex systems of non-rigid objects can be min- imized by describing the 
geometry and dynamics separately, using representations optimized for ei- ther one or the other, and 
then coupling these rep- resentations together. We describe a system which uses polynomial deformation 
mappings to couple a vibration-mode ("modal") representation of ob- ject dynamics together with volumetric 
models of object geometry. By use of such a hybrid rep-resentation we have been able to gain up to two 
orders of magnitude in efficiency, control temporal aliasing, and obtain simple, closed-form solutions 
to common (non-rigid) inverse dynamics problems. Further, this approach to dynamic simulation nat- urally 
lends itself to the emphasis and exaggera- tion techniques used in traditional animation.  INTRODUCTION 
 The idea of using computers to provide interactive simula- tion of non-rigid object dynamics has been 
a major goal of computer graphics, starting with Sketchpad [13], Thinglab [5], and the recent profusion 
of new computer graphics work on non-rigid dynamics [4,7,14]. Our project, which we have named Thingworld 
[10,11,12], was conceived as direct de-scendant of Sketchpad and Thinglab: our goal is to use in- teractive 
dynamic simulation of multibody situations to aid in physical design. In common with all previous attempts 
at achieving this goal, we have been confronted with the problem that the huge computational expense 
of calculating dynamic, interactions prevents interactive simulation except for limited, toy situations. 
Furthermore, to be really useful to a designer, we must also be able to solve complex inverse dynamics 
problems, perform dynamic simulations for objects *This research was made possible by National Science 
Foundation Grant No. IRI-87-19920 and by ARO Grant No. DAAL03-87-K-0005 Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. defined by large spline surfaces 
or by constructive solid ge- ometry, and render objects without undue temporal aliasing --all of which 
are quite difficult with standard techniques and representations. In the Thingworld system we have been 
able to minimize each of these problems by describing the geometry and dy- namics separately, using representations 
optimized for either one or the other, and then coupling these representations together using deformation 
mappings. In our system dy- namic properties are described by modM anMysis, a method of breaking non-rigid 
dynamics down into the sum of in- dependent vibration modes. The advantage of the modal approach is that 
it breaks the dynamics problem into many small, independent problems. This allows us to achieve a level 
of control not possible with the massed equations nor-mally used in dynamic simulation. As a consequence 
many common inverse dynamics problems can be solved in closed form, and many traditional animation techniques 
can be eas- ily automated. Because formulations for describing non-rigid motion have been based on point-wise 
representations of shape, the de- tection and characterization of collisions has always been a major 
fraction of the computational cost in multibody sim- ulation systems. Further, analytic models of geometry 
(e.g., fl-splines) cannot be used because there has been no way to relate analytically-specified shape 
to object dynamics. Be-cause the Thingworld system describes non-rigid deforma- tion in terms of whole-body 
deformation modes, we can re-late object dynamics to object shape via global polynomial deformation mappings. 
This allows us to couple non-rigid object dynamics with analytic models of geometry (in our case superquadrics) 
so that we can more efficiently and ac-curately characterize the forces produced by collisions. The plan 
of this paper is to first present short description of the modal method for representing and calculating 
non- rigid object dynamics. We will then show how the modal representation can be modified to produce 
great gains in ef- ficiency, to reduce temporal aliasing, and to solve inverse dy- namics problems. We 
will then describe how the method can be generalized to arbitrary geometric representations, thus allowing 
more efficient and accurate detection and charac-terization of object collisions. Finally, we will discuss 
how this system can be adapted to automatically produce many of the effects used in traditional animation. 
&#38;#169;!989 ACM-0-89791-312-4/89/007/0215 $00.75  ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 
 2 MODAL DYNAMICS 2.1 Background: Finite Element Method The finite element method (FEM) is a technique 
for simu- lating the dynamic behavior of an object. In the FEM the continuous variation of displacements 
throughout an object is replaced by a finite number of displacements at so-called nodal points. Displacements 
between nodal points are in-terpolated using a smooth function. Energy equations (or functionals) can 
then be derived in terms of the nodal un-knowns and the resulting set of simultaneous equations can be 
iterated to solve for displacements as a function of im- pinging forces. In the dynamical case these 
equations may be written: M~ + DiL + Ku = f (1) where u is a an x 1 vector of the (x, y, z) displacements 
of the n nodal points relative to the objects' center of mass, M, D and K are an by 3n matrices describing 
the mass, damping, and material stiffness between each point within the body, and f is a 3n x 1 vector 
describing the (x, y, z) components of the forces acting on the nodes. This equation can be interpreted 
as assigning a certain mass to each nodal point and a certain material stiffness between nodal points, 
with damping being accounted for by dashpots attached between the nodal points. The damping matrix D 
is often taken to be equal to sM for some scalar s; this is called mass damping. To calculate the result 
of applying some force f to the ob- ject one discretizes the equations in time, picking an appro- priately 
small time step, solves this equation for the new u, and iterates until the system stabilizes. Direct 
(implicit) so- lution of the dynamic equations requires inversion the K ma-trix, and is thus computationally 
expensive. Consequently explicit Euler methods (which are less stable, but require no matrix inversion) 
are quite often applied. Even the explicit Euler methods are quite expensive, be- cause the matrices 
M, D, and K are quite large: for in- stance, the simplest 3-D parabolic element produces 60 x 60 matrices, 
corresponding to the 60 unknowns in the 20 nodal points (xl, yi, zi) which specify the element shape. 
In most situations M, D, and K are very much larger than 60 x 60, so that typically hundreds or thousands 
of very large ma- trix multiplications are required for each second of simulated time. For more details 
see references [4,7,14,15]. 2.2 Modal Analysis Because M, D and K are normally positive definite sym- 
metric, and M and D are assumed to be related by a scalar transformation, Equation 1 can be transformed 
into 3n inde- pendent differential equations by use of the whitening trans-form, which simultaneously 
diagonalizes M, D, and K. The whitening transform is the solution to the following eigen- value problem: 
)re = M -~ K (2) where A and  are the eigenvalues and eigenvectors of M-1K. Using the transformation 
u = &#38;ct we can re-write Equa- tion 1 as follows: rMeh + eTD~ + 6T I-(~t = eT f (3) 216 Figure 
1: (a) A cylinder, (b) a linear deformation mode in response to compression, (c) a linear deformation 
mode in re- sponse to acceleration, (d) a quadratic mode in response to a bending force, (e) superposition 
of both linear and quadratic modes in response to compression, (f) superposition of both linear and quadratic 
modes in response to acceleration. In this equation qbTMq~, qbTD, and eTKq5 are diagonal ma- trices, 
so that if we let M = eTM, _D -~ eTD, R = eTKqb, and f = qbTf then we can write Equation 3 as 3n indepen- 
dent equations: Mifii + Digi + ~'iRi = fi , (4) where/17//is the i th diagonal element of ]17/, and 
so forth. Be-cause the modal representation diagonalizes these matrices it may be viewed as preconditioning 
the mass and stiffness matrices, with the attendant advantages of better conver-gence and numerical accuracy. 
What Equation 4 describes is the time course of one of the object's vibration modes, hence the name modal 
analy-sis [16]. The constant 3~ri is the generalized mass of mode i, that is, it describes the inertia 
of this vibration mode. Sim-ilarly, Di, and/(i describe the damping and spring stiffness associated with 
mode i, and fi is the amount of force cou- pled with this vibration mode. The i th row of ~b describes 
the deformation the object experiences as a consequence of the force fi, and the eigenvMue hi is proportional 
to the natural resonance frequency of that vibration mode. Figure 1 illustrates the some of the first 
and second order modes of a cylinder. Figure l(a) shows the cylinder at rest, (b) shows the cylinder 
experiencing a linear deformation in response to a compressive force, (c) shows the cylinder expe- riencing 
a linear shear deformation in response to an accel-erating force, (d) shows a quadratic deformation in 
response to a centrally-applied (bending) force, and (el and (f) show how both the linear and second 
order deformations can be superimposed to produce a more accurate simulation of the object's response 
to the compressive and accelerating forces shown in (b) and (c). To obtain an accurate simulation of 
the dynamics of an object one simply uses linear superposition of these modes to determine how the object 
responds to a given force. Be-cause Equation 4 can be solved in closed form, we have the result that 
for objects composed of linearly-deforming ma- terials ~he non-rigid behavior ot" the object in response 
to an impulse force can be solved in dosed form for any time t. The solution is discussed in Section 
5.1. In environments with more complex forces, however, analytic solution be- comes cumbersome and so 
numerical solution is preferred. Either explicit or implicit solution techniques may be used to calculate 
how each mode varies with time. Non-linear materials may be modeled by summing the modes at the end of 
each time step to form the material stress state which can then be used to drive nonlinear plastic or 
viscous material behavior.  3 USING THE MODAL METHOD Although the simple modal method offers some benefits 
in terms of efficiency and stability, its main advantage is that it allows us to control the computation 
in ways that are ad- vantageous to various applications. In this section we detail some of the variations 
on the basic modal method that we have found to be particularly useful. 3.1 Increased Speed Modes associated 
with high resonance frequencies normally have little effect on object shape. This is because, for a fixed 
excitation energy, the displacement amplitude for each mode is inversely proportional to the square of 
the mode's resonance frequency. Thus a relatively accurate and more efficient simulation of an object's 
dynamics can be accom-plished by discarding the small-amplitude, high-frequency ]nodes, and superimposing 
only the large-amplitude, low- frequency modes. We can determine which modes to discard by examining 
their associated eigenvalue, which is propor- tional to the resonance frequency. The amount of error 
introduced by discarding high-frequency modes can be checked by occasionally substituting the displacements 
u produced by low-frequency modal anal- ysis into the full equations. When significant error is found 
additional modes can be added. Exactly which modes to add can be determined by a principal components 
analysis of the error residuals. One effect of discarding modes is, of course, to reduce the number of 
equations that must be considered within each time step. However, because the maximum allowable time 
step is inversely proportional to the highest resonance fre- quency in the system of equations, a more 
important effect of discarding high-frequency modes is that we can use much larger time steps. In typical 
situations we have found that the savings from fewer equations and larger times steps can reduce computation 
time by up to two orders of magnitude, while at the same time producing a reasonably accurate, realistic-looking 
animation. 3.1.1 Number of modes required For the sake of increased efficiency, our approach has been 
to model only as many modes as are required. In a quick- and-dirty analysis -- often sufficient during 
the initial phase of a design -- only rigid-body or rigid-body plus linear strain modes may be used, 
resulting in large computational savings. Later, more modes can be added to achieve any level of desired 
accuracy, although at greater cost. We have found that most commonplace multi-body inter- actions can 
be adequately modeled by use of only rigid-body, linear, and quadratic strain modes, as is shown in Figures 
1 and 2. Note that this is not true for bodies whose dimen- sions are quite disparate, however it is 
exactly these cases that can be adequately treated by either a one or two di- mensional analysis, and 
thus are cases where the standard FEM is quite efficient. 3.1.2 Recomputlng matrices and modes Normally, 
in either the finite element or modal methods, the mass, damping, and stiffness matrices are not recom-puted 
at each time step. The use of fixed M, D, and K (or, equivalently, fixed modes) is well-justified as 
long as the material displacements are small. The definition of "small," however, is quite different 
for different modes. Because the eigenvalue decomposition in Equation 2 performs a sort of principal-components 
analysis, it is the gross object shape (e.g., its low-order moments of inertia) determine the low- frequency 
modes, which as a consequence are quite stable. High-frequency modes are much less stable because they 
are determined by the fine features of the object's shape. In the standard finite element formulation 
the action of each mode is distributed across the entire set of equations, so that one must recompute 
the mass and stiffness matri- ces as often as required by the very highest-frequency vi- bration modes. 
When these high-frequency modes are dis-carded the mass, damping, and stiffness matrices need to be recomputed 
much less frequently --a large computational savings. We have found, for instance, that in most anima-tion 
sequences we can use a single, fixed set of low-frequency modes throughout the entire simulation. 3.1.3 
An example Figure 2 shows a example of computing non-rigid dynamic interaction: a ball colliding with 
a two-by-four. As can be seen, the interaction and resulting deformations look realistic despite the 
use of only first and second order modes. Perhaps the most impressive fact about this example, however, 
is the speed of computation: Using a Symbolics 3600 (with a speed of roughly one MIP), it requires only 
one CPU second to compute each second of simulated time!  3.2 Temporal Aliasing One important side effect 
of discarding high-frequency modes is reduction in temporal aliasing artifacts. A dy- namic simulation 
using the standard finite element method will produce very many small, high-temporal-frequency dis- placements. 
This is especially true for stiff materials. To avoid temporal aliasing artifacts these small displacements 
must be accurately tracked (requiring a small time step), and then averaged over time to produce each 
image. Ill modal analysis these high frequency displacements can be directly identified and discarded, 
thus reducing not only the number of time steps required, but also the need for time averaging in order 
to avoid temporal artifacts.  ~q,~SIGGRAPH '89, Boston, 31 July-4 August, 1989 &#38;#169; . 2. . . 
Figure 2: A ball colliding with a two-by-four (A) fil I ] I ~X\< ) \~X X i I lfl (B) (c)  Figure 
3: Low-order deformation modes are visually similar when objects have similar low-order moments of inertia. 
3.3 Use of Approximate Modes An object's low-order deformation modes can be thought of as the principal 
components of the object's repertoire of non-rigid behavior. These modes can be found by solving the 
eigenvalue problem of Equation 2, however for visualization purposes we have found that it is sufficient 
to use fixed, pre- computed deformation modes that are parameterized only by the object's low order moments 
of inertia. This is illustrated in Figure 3, which shows three objects colliding with a post after having 
been dropped from a few feet above the post. Figure 3(a) shows the original, unde- formed objects. Figure 
3(b) shows the collisions simulated using modes computed by solving Equation 2. In Figure 3(c) we have 
pJ:ecomputed the modes of a rectangular solid with approximately the same moments as the object to be 
ani- mated. These precomputed deformation modes were then used in place of the object's true modes in 
making the an-imation. Despite use of precomputed modes it can be seen that the collisions are visually 
very similar. A more accurate variation on this theme is to use 20 nodal points (i.e., a simple 3-D parabolic 
element) to approximate the shape of the object to be animated. Equation 2 can 218 be solved relatively 
quickly for this number of nodal points, and the resulting modes will produce a reasonably accurate simulation. 
Such shortcuts to finding an object's modes can produce an important savings in interactive simulation 
sys- tems such as Thingworld, where the user frequently changes each object's static geometry. 4 COMBINING 
DYNAMICS AND ANALYTIC GEOMETRY One problem with standard non-rigid dynamical techniques is that they 
are based on use of a point-wise representation of geometry, thus forcing the representation of geometry 
and dynamics to be identical. As a consequence one cannot, for instance, specify details of geometry 
without incurring large costs in calculating dynamic behavior, nor can one directly animate objects defined 
by, for example, large spline patches or constructive solid geometry. The fact that the same repre- sentation 
must be nsed for both geometry and dynamics thus has a large impact upon the efficiency and accuracy 
of multi- body simulations, where detailed specification of geometry is required to obtain accurate detection 
and characterization of collisions. We have been able to combine separate representations of dynamic 
behavior and geometric form in order to avoid these problems. We have accomplished this by describing 
each mode by an appropriate polynomial function, and then us-ing global deformation techniques [3] to 
establish the corre-spondence between dynamic state and geometric state. The result is an efficient scheme 
for simulating non-rigid dynam- ics that can be applied in a unified manner to objects whose geometry 
is defined using a wide range of techniques. To accomplish this, we must first realize that modes may 
be classified by the complexity of the associated deformation, e.g., as 0 th order (rigid body) modes, 
1 ~t order (linear defor- mation) modes, 2 nd order (quadratic deformation) modes, and so forth, as was 
illustrated by Figure 1. Thus we can describe the deformation associated with each mode by use of polynomial 
deformation mappings of the appropriate de- gree. This is accomplished by performing a linear regression 
of a polynomial with m terms in appropriate powers of x, y, and z, against the n triples of a, y and 
z coefficients that compose i, a 3n x 1 vector containing the elements of tile i th row of :  = (~)-~0~ 
, (5) where a is an m x 1 matrix of the coefficients of the desired deformation polynomial, ~ is an 3n 
x rn ma-trix whose first column contains the elements of u = (xl,ya, zi, x2, y2, z2, ...), and whose 
remaining columns con-sist of the modified versions of u where the x, y, and/or z components have been 
raised to the various powers, e.g., Xl Z~ Xl Xl ... ya yl y~ yl ... Zl Zl Zl Z~ ... z= ~ d x~ ~ ... (6) 
Y2 Ys Y~ Y2 ... Z 2 Z 2 Z 2 Z~ ... The question of which polynomial powers are the appro- priate for 
a particular column of  can be decided either by inspection (noting that the order of the deformation 
is related to the associated eigenvalue), or automatically by including all combinations of powers of 
x, Y, and z (up to some limit), performing the regression, and then discarding coefficients with negligible 
magnitude. The result is a polynomial model of the unit amplitude deformation associated with mode i. 
By simply scaling this polynomial deformation according to the mode's amplitude we can accurately copy 
the effects of this mode on the ob- ject's shape. By superimposing these deformations we ob- tain an 
accurate accounting of the object's non-rigid defor- mation. 4.1 Fast Collision Characterization In 
complex, multi-body simulations the ability to efficiently detect and characterize collisions is extremely 
important. Unfortunately, the point-wise representations used by the standard FEM are quite poor at this 
task. When using a polygon representation, for instance, the computational complexity of collision detection 
is O(nm) operations, where n is the number of polygons and m is the number of points to be considered 
after pruning via bounding box calculations [91. In contrast, one can perform collision detection relatively 
efficiently when employing volumetric representations (e.g., superquadrics [2,6,10]) by making use of 
their inside-outside function. In our system the basic volumetric primitive is a superquadric, which 
is mapped from its canonical reference frame 1 to its three-space position by an afflne transforma- tion 
T. The normalized inside-outside function D(x, y, z) for superquadrics is: D(x, y, z) = [((z/a~U ~ + 
(y/a2U ~' )'/~ + (z/an) ~I~] ~ (7) where the position (z, y, z) is relative to the object's canon- 
ical reference frame. The basic operation for collision detec- tion, then, is to take points (x, y, z) 
sampled from the tested object's surface, apply T -1 to convert them to the canonical 1The canonical 
reference frame is when the object has zero rotation, and is centered at (0, 0, 0) reference frame, and 
then substitute them into the inside- outside function. When the result is less than one the point is 
inside the surface, if greater then one the point is outside. Thus, the computational complexity is only 
O(m), rather than O(nm), where n and m are as before. As with other representations [9], to find the 
exact point in space-time at which contact between the two bodies occurred requires use of numerical 
minimization techniques, where both point po- sition, T and Equation 7 are expressed as functions of 
time. In the Thingworld system we have found that the ability to perform fast collision detection using 
volumetric representa- tions yields large computational savings. 4.2 Accuracy of Collision Characterization 
A more subtle but perhaps equally important advantage of being able to use analytic representations in 
dynamic simula- tions is the ability to characterize the collision surface more quickly and precisely. 
For instance, one difficult problem that arises when using any discrete time technique is that colliding 
bodies often interpenetrate during a time step. The depth, area and shape of this penetration determines 
tile re- pulsive force generated. With point-wise (polygon) representations it is difficult to determine 
the interpenetration region, so that most systems ignore the contact area's shape and simply find the 
single point (normally a polygon vertex) that first contacted the surface. As a consequence the calculated 
force is often seri- ously in error. When using analytic representations of geom- etry, however, both 
surface normal and principal curvatures are readily available so that good closed form approxima- tions 
to the depth, area and shape of the interpenetration region can be easily computed. 5 The Right Control 
Knobs One of the most important aspects of any simulation or ani- mation system is the ability to control 
the behavior of objects in a natural, intuitive, and convenient manner: in short, the system must have 
the right control knobs. In simulation sys- tems such as Thingworld, one often needs to be able to solve 
simple inverse dynamics problems: For instance, to make something jump from here to there and land softly. 
In ani- mation systems the same requirements arise, but in addition one needs to be able to produce pleasing 
but non-physically- realistic effects. In traditional animation some of the most important of these effects 
are called squash-and-stretch, an-ticipation, and exaggeration [8]. The control knobs for these sorts 
of things simply don't exist with standard approaches to dynamic simulation. Even simple inverse dynamics 
problems, for instance, require solv- ing huge numerical minimization problems because all of dy- namical 
equations are closely coupled together. Similarly, traditional animation effects such as squash-and-stretch 
can only be obtained by careful'ly jiggering material properties and external forces as a function of 
object position, velocity, and so forth. The situation is quite different when using modal analysis, 
because closed-form solutions exist for each mode's behav- ior as a function of time, and because the 
various modal behaviors are independent of each other so that they may '89, Boston, 31 July-4 August, 
1989 SIGGRAPH M t -(el2m~ R cos 1 ~t Figure 4: Damped vibration as a function of time. be treated separately. 
Further, the low-order modes of an object seem to closely mimic many of the effects used in traditional 
animation.  5.1 Inverse Dynamics The time behavior of each mode in response to an impinging force is 
given by Equation 4. The generic solution to this equation is ui = Ae rlt "t- Be ~2t, for D~-4h'i~7/i 
>0, rl,r2 <0 el = (A + Bt)e (Di/2~i)t, for D~ -4KiJfL = 0, (8) ai = e(Di/2~i)t(A cos/~t + B sin/zt), 
 for ~ = (4_~_~, -D~)I/~/2M~ > 0 for the overdamped, critically damped, and underdamped cases, where 
-D,  VD~ -4R, M, rl, r2 = 2M~ (9) and A and B depend on the initial conditions [1]. The third case, 
underdamped motion, occurs most commonly in me-chanical systems and is referred to as "damped vibration." 
To see this we let A = Rcos~ and B = Rsin8 in Equation 8 to obtain ~ = Re -(r<'/2~m cos(mr - 6) , (10) 
which is graphed in Figure 4. Thus, once we know the amplitude and derivative of a mode at time zero, 
we can predict its behavior for all future times --or at least until an external force adds or subtracts 
energy from the mode. In particular, given initial conditions fii(0) = X, ~i(0) = ~, and underdamped 
free oscillation, then I m \ 1/2  ~,(t) = x ~ + (~ + C ~x )~ e [<'~/~' cos(~t-~) (]]) 2Mi# ] where 
~ = tan -1 [(X/X + Dix/2tz]fIi)/X]. Using this relation we can achieve a desired object shape at some 
time h by adjusting initial modal amplitude and velocity at time to. Similarly, we can specify the desired 
object shape at times to and h, and then solve for the force required to achieve those 220 (A)  (B) 
  Figure 5: A time lapse illustration of a cylinder jumping and landing (a) with a hard thump, (b) softly. 
Time proceeds from left to right. constraints. Thus, Equation 11 can provide us with closed- form solutions 
to many common inverse dynamics problems. For closed-form solutions under other initial conditions see 
reference [1]. 5.1.1 Some Examples Imagine that we want a cylindrical solid to jump from point A to point 
B, landing either softly or with a hard "thump". Further, imagine that we wish to control the cylinder 
by changing only the characteristics of it's "mus-cles," i.e., by controlling the displacement and spring 
con-stant associated with each deformation mode. The inverse dynamics problem, then, is to make sure 
that the cylinder has the correct amount of extension or compression at the point of landing so that 
it can achieve the desired type of landing. The mathematics for calculating a trajectory that will take 
the cylinder from point A at time t = to to point B is well known. That calculation will also give us 
the time t = tl at which landing will occur, and the force vector finitial needed to achieve the jump. 
If we idealize the ge- ometry and time course of how the cylinder pushes against point A, then we can 
use standard kinematics to determine how much the cylinder must "crouch" and tense it's "mus- cles" (i.e., 
what initial modal displacements ~i (t0) and spring constants ffi(to) are required) in order to produce 
tile de- sired force vector. Producing a jump by use of the spring energies stored in the various modes 
will leave each of the modes in some state ~i(t0 + e) = Xi, ~i(t0 + e) = )~i as the cylinder leaves the 
surface. The inverse dynamics problem is then to set the spring constants /~i(t) (for to < t < tl) of 
the cylinder's ........ ~ -- " '~///'/'~ ' /t / I I "~..N.d J" V \ ~ I f 1-1/ ~ \ \ I 1 ~.st Figure 
6: (a) Physical squash-and-stretch in a collision. "muscles" so that the natural oscillation of the cylinder 
ex- erts the desired motion-canceling force ffm~z on point B at the appointed instant in time. To obtain 
ff~na* at t = tl we first determine what combi- nation of modal amplitudes will exert the desired final 
force by computing fti(Q) = fi/~ri(Q) , (12) where f = eTffi,~al, and the- "i(h) correspond to "tensing" 
the muscles for landing. We then solve Equation 11 with the  given values of * = h, M., D. ~,(t0) = 
X~, and 5~(*o) = 2~ in order to find a stiffness -h~i(~), to < t < tl, such that aai(~) has the desired 
value. 2 Thus Equation 11 provides a closed- form solution to such simple inverse dynamics problems --at 
least when we can idealize contact geometry, friction, etc. Examples of jumps computed in this manner 
are shown in Figure 5. In most situations of interest, unfortunately, the partic- ulars of geometry and 
friction are sufficiently complex and non-linear that there is no dosed-form solution, so that one must 
still employ the sort of constrained minimization de- scribed in [17] to obtain a solution. However, 
as these ex-amples illustrate, by using Equation 11 it appears that the problem can be reduced from several 
thousand free param- eters to only a few dozen free parameters. 5.2 Control of Animation The deformations 
caused by an object's low-order vibration modes correspond closely to the types of exaggeration and emphasis 
used in traditional animation. Thus, the amplitude of these low-order modes provides the control knobs 
needed for such animation. A simple version of squash-and-stretch in collisions is well modeled by straightforward 
application of non-rigid dy- namic simulation: things do squash and stretch during col- lisions, a shown 
in Figure 6. However, as applied in tradi- tional animation, this notion goes well beyond simply ob- 
taining physically-realistic deformations during a collision. It also occurs as a response to motion, 
to acceleration, and even in response to emotional states. By providing a "stretch/squash" control knob 
we can wire squashing-type 2The h'i(h) must of course be large enough that the modal displacements at 
~ = tl (which are no larger than the displacements at t = to) generate sufficient energy. Figure 7: Stretching/squashing 
tied to velocity @ 0  @ POSITION Figure 8: Stretching/squashing tied to speed minus acceler- ation; 
time proceeds from top to bottom. deformations directly to other parameters, both physical and non-physical, 
in order to obtain interesting visual effects. Examples of this are shown in Figures 7, 8 and 9, where 
we have wired the "stretch/squash" knob to various physi- ca] properties. Figure 7 shows three objects 
moving at dif- ferent speeds. In this figure the amplitude of the stretch- ing/squashing deformation 
is set equal the speed, so that as the object moves faster it becomes stretched out in the direction 
of motion. Figure 8 shows a time series where the stretch/squash deformation is equal to the speed minus 
the acceleration, so that an accelerating object "piles up" in anticipation as the motion begins, and 
stretches out as the motion reaches steady state. Finally, Figure 9 shows three mushrooms with both bend- 
ing and stretching/squashing deformations tied to image z position: as a consequence the mushrooms "wilt" 
from left to right. The same deformations could be tied to emotional state, for instance, thus providing 
physical illustration of a character's state of depression or elation.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74356</article_id>
		<sort_key>223</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Analytical methods for dynamic simulation of non-penetrating rigid bodies]]></title>
		<page_from>223</page_from>
		<page_to>232</page_to>
		<doi_number>10.1145/74333.74356</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74356</url>
		<abstract>
			<par><![CDATA[A method for analytically calculating the forces between systems of rigid bodies in resting (non-colliding) contact is presented. The systems of bodies may either be in motion or static equilibrium and adjacent bodies may touch at multiple points. The analytic formulation of the forces between bodies in non-colliding contact can be modified to deal with colliding bodies. Accordingly, an improved method for analytically calculating the forces between systems of rigid bodies in colliding contact is also presented. Both methods can be applied to systems with arbitrary holonomic geometric constraints, such as linked figures. The analytical formulations used treat both holonomic and non-holonomic constraints in a consistent manner.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Linear programming</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716.10011138.10010041</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization->Continuous optimization->Linear programming</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716.10011138.10010041</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization->Continuous optimization->Linear programming</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P52105</person_id>
				<author_profile_id><![CDATA[81100334025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baraff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Comell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barzel, R. and Barr, A.H., "Dynamic constraints," Topics in Pto'sically Based Modeling, course notes, vol. 16, SIG- GRAPH, 1987.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barzel, R. and Barr, A.H., "A modeling system based on dynamic constraints," Conlputep Graphics (Proc. SIG- GRAPH), vol. 22, pp. 179-188, 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Garey, M.R. and Johnson, D.S., Comlmters and Intractability. Freeman, New York, 1979.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gere, J.M. and Timoshenko, S.P., Me~'hani~'s of Materials. Wadsworth, Belmont, California, 1984.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Goldstein, H., Classical Mechanics, Addison-Wesley, Reading, Massachusets, 1983.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Golub, G. and Van Loan, C., Matrix Computations, John Hopkins University Press, Baltimore, 1983.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378530</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hahn, J.K., "Realistic animation of rigid bodies," Computer Graphics (Pro('. SIGGRAPH), vol. 22, pp. 299-308, 1988.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Isaacs, P.M. and Cohen, M.F., '~Controlling dynamic simulation with kinematic constraints," Comp,ter Graphits (Pro~'. SIGGRAPH), vol. 21, pp. 2t5-224, 1987.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kozlov, M.K., Tarasov, S.P., and Hacijan, L.G., "'Polynomial solvability of convex quadratic programming." Soviet Mathematics Doklady, vol. 20, no. 5, pp. 1108-1111, 1979.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Llewellyn, R.W., Linear Programming, Holt, Rinehart and Winston, 1964.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[MacMillan, W.D., Dynamics of Rigid Bodies, Dover, New York, 1960.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>355976</ref_obj_id>
				<ref_obj_pid>355972</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Marsten, R.E., "The design of the XMP linear programming library," ACM Transa~'tions on Mathematical Sofiw'are, vol. 7, no. 4, pp. 481-497, 198t.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Moore, M. and Wilhelms, J., "Collision detection and response for computer animation," Computer Graphics (Pro~'. SIGGRAPH), vol. 22, pp. 289-298, 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Murty, K.G., Linear Complementarity, Linear and Nonlinear Pro framming, Heldermann Verlag, Berlin, 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>39953</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Palmer, R.S., Computational Complexio' of Motion and Stability of Polygons, PhD Diss., Cornell University, January 1987.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Platt, J.C. and Barr, A.H., "Constraint methods for flexible models," Computer Graphics (Proc. SIGGRAPH), vol. 22, pp. 279-288, 1988.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Shampine, L.F. and Gordon, M.K., Computer Solution of Ordinary Differential Equations: The Initial Value Problem, Freeman, 1975.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Platt, J.C., and Barr, A.H., "'Elastically deformable models," Computer Graphics (Proc. SIG- GRAPH), vol. 21, pp. 205-214, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Analytical Methods for Dynamic Simulation of Non-penetrating Rigid Bodies David Baraff Program of Computer 
Graphics Comell University Ithaca, NY 14853 Abstract A method for analytically calculating the forces 
between systems of rigid bodies in resting (non-colliding) contact is presented. The systems of bodies 
may either be in motion or static equilibrium and adjacent bodies may touch at multiple points. The analytic 
formulation of the forces between bodies in non-colliding contact can be modified to deal with colliding 
bodies. Accordingly, an improved method for analytically calcu- lating the forces between systems of 
rigid bodies in colliding con- tact is also presented. Both methods can be applied to systems with arbitrary 
holonomic geometric constraints, such as linked figures. The analytical formulations used treat both 
holonomic and non-holonomic constraints in a consistent manner. Categories and Subject Descriptors: 1.3.5 
]Computer Graphics]: Computational Geometry and Object Modeling; 1.3.7 [Computer Graphics[: Three-Dimensional 
Graphics and Realism Additional Key Words and Phrases: dynamics, constraints, simu- lation 1. Introduction 
Recent work has focused on using the laws of Newtonian dynamics to simulate the motions of systems of 
rigid bodies. A realistic simulation of rigid bodies demands that no two bodies inter-penetrate. In order 
to enforce this constraint a simulator must first detect potential inter-penetration between two bodies 
and then act to prevent the two bodies from penetrating. However, in keeping with the laws of Newtonian 
dynamics, a realistic simula- tion should not prevent inter-penetration in an arbitrary manner. The simulator 
should calculate what forces would actually arise in nature to preverlt bodies from inter-penetrating 
and then use these forces to derive the actual motion of the bodies. In order to calcu- late these forces 
an explicit formulation is necessary. Traditional techniques from engineering and physics are not applicable 
to the problem of calculating forces between bodies in resting contact. These techniques assume that 
the systems of bodies being analyzed are in equilibrium. However, many of the simulations in computer 
graphics involve systems of bodies that are not in equilibrium. For example, the forces between the bricks 
in figure 1 cannot be calculated using traditional techniques. Permission to copy without fee all or 
part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permissionof the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. I--1 b  I I I I Figure 1. Overbalanced stack 
of bricks. This paper focuses on the following specific problem: given a number of non-colliding rigid 
polyhedral bodies, calculate the forces that would naturally arise to prevent bodies from inter- penetrating. 
The bodies may also be constrained to satisfy certain geometrical relationships such as those present 
in articulated figures[2, 8]. An analytical solution to the problem is presented that uses linear programming 
techniques to formulate and heurist- ically solve a system of inequality and equality constraints on 
the forces. The system of constraints guarantees that the contact forces will prevent inter-penetration 
and satisfy the laws of Newtonian dynamics. The solution is generalized to yield an improved algorithm 
for calculating forces between colliding sys- tems of rigid polyhedral bodies. 2. Previous Work Analytical 
methods for calculating the forces between col-liding rigid bodies have been presented by Moore and Wilhelms[13] 
and Hahn[7]. Both methods calculated the impulse between a single pair of bodies that collided at a single 
point. Moore and Wilhelms modeled simultaneous collisions as a slightly staggered series of single collisions 
and used non-analytical methods (below) to deal with bodies in resting contact. Hahn prevented bodies 
in resting contact from inter-penetrating by modeling their contact as a series of frequently occurring 
colli- sions. This model may be suitable for preventing inter-penetration in animation applications; 
however, it is not a valid analytical model of forces between bodies in resting contact. "Penalty" methods 
that introduce restoring forces when objects inter-penetrate have also been presented. Terzopolous et 
a/.[18] and Platt and Barr[16] produced highly realistic anima-tions of rigid and deformable non-penetrating 
bodies. Inter-penetration was prevented in both papers by introducing arbitrary penalty forces that acted 
to separate penetrating bodies; a natural solution method, since dynamical correctness of these forces 
was not a focus of either paper. Moore and Wilhelms[13] introduced spring forces (a penalty method) to 
prevent bodies in resting con- tact from penetrating. @1989 ACM -0-89791-312-4/89/007/0223 $OO.75  '89, 
Boston, 31 July-4 August, 1989 2.1 Penalty Methods vs. Analytical Methods Analytical methods offer several 
advantages over penalty methods. Penalty methods for rigid bodies are often computation- ally expensive, 
give only approximate results, and may require adjustments for different simulation conditions (figure 
2). heavy t spring  force t Figure 2. Differing amounts of inter-penetration from a penal- ty method. 
These undesirable behaviors arise from the attempt to model infinite quantities (infinite rigidity of 
bodies, infinitely hard sur- faces) with finite values. In particular, the differential equations that 
arise using penalty methods may be "stiff"' and require an excessive number of time-steps during simulation 
to obtain accu- rate results. Additionally, the correctness of the simulation under penalty methods is 
very difficult to verify. In their defense, penalty methods for rigid bodies are simple to implement 
and are easily extendible to non-rigid bodies. In contrast, analytical methods for rigid bodies give 
exact answers and produce differential equations that require far fewer time steps during simulation. 
The correctness of the simulation when using an analytical method is easily provable because analytical 
solutions are based directly on the laws of Newtonian dynamics. Analytical methods however are much more 
complex to derive and implement. 3. Simulation using Analytical Methods Simulations of rigid bodies employing 
analytical methods should treat collision forces and resting contact forces differently. Analytically, 
collision forces arc discontinuous impulsive forces in that they exist for a single instant of time and 
have the dimen- sions of mass times velocity (or equivalently force times time). Resting contact forces, 
or more simply, contact forces, are con- tinuous over some non-zero interval of time and have the dimen- 
sions of mass times acceleration. The effects of collision forces are independent of non-impulsive forces 
such as contact forces or gravity. Impulsive forces cause discontinuities in a body's velo- city; contact 
forces do not. Our simulator iterates through time (time steps) by solving a first order system of coupled 
ordinary differential equa-tions[I, 2]. Given the net force and torque on each body, the dif- ferential 
equations can be solved to yield the motion of the bodies. We adopt the usual method for solving the 
system of differential equations by using numerical integration procedures such as fourth order Runge-Kutta 
or Adams-Moulton[17] with adaptive time-step parameters. The integrator is given initial conditions in 
the form of the starting orientations, positions, and linear and angular velocities of all the bodies. 
As stated above, analytical methods introduce discontinuities in some of the velocities when collisions 
occur. It is unwise to blithely integrate over these colli- sion times. 1 INumerieal integrators assume 
that the functions they are integrating are continuous functions of time. If a function being integrated 
is discontinuous at some time to, the integrator must integrate up to to, stop, and then restart at t~, 
with new initial con- ditions. 224- Finding the time at which a collision occurs can be viewed as a root-finding 
problem. The collision time is found by using backtracking methods similar to those described by Moore 
and Wilhelms[13]. The collision time is bracketed by successively shorter time intervals until the colliding 
objects touch within a suitable tolerance. 2 Once the collision time has been calculated, the integrator 
is stopped (at the collision time) and collision forces are computed. Collision forces may be calculated 
using previous methods[7, 13] or by the improved collision method presented in section 8. The collision 
forces are used to compute the new velo- cities of the colliding bodies and then the integrator is restarted 
with new initial conditions. The new initial conditions are the positions and orientations at the time 
of the collision and the newly computed velocities. We call this series of steps resolving the collision. 
Since the computation of the new velocities (due to the collision forces) is independent of any contact 
forces, contact forces are not calculated until after collisions are resolved. Accordingly, the formulation 
of the resting contact problem impli- citly assumes that no bodies in contact are colliding i.e. collisions 
have been resolved. 4. Modeling Contact We will use the following terminology. Let two bodies A and 
B be in cofitact (colliding or resting) at some time to; A and B touch each other at some number of contact 
points. At time to, let p be the position of an arbitrary contact point in some world space. Define p~ 
and Pt, as the positions of the two points of A and B that satisfy p,,(t o) =p = pl,(to) (figure 3). 
(a) ~ ~ ^  ,~ (b}B A -F J l P hp~~~ (c) Figure 3, (a) Vertex-plane contact (side view). (b) Edge-edge 
contact. (c) Contact geometry. Pa and Ph are functions of time; they track the motion of two specific 
points of A and B that coincide at time to. Both pa and Ph vary according to the independent rigid body 
motions of A and B. The relative motion,/in(t0) -ph(t0), indicates whether A and B are colliding, resting, 
or separating at point p at time to. At each contact point there is a contact force F, (possibly zero) 
between A and B and a unit surface normal ~. For vertex- plane contact, the body whose vertex is the 
contact point is identified as body A. n is defined as the outwards unit surface 2We have found that 
using the relative displacements of inter-penetrating bodies to implement a regLda falsa method results 
in much faster convergence than the simpler bisection method. Our tolerance was chosen empirically. normal 
of B at Pb (figure 3a). For edge-edge contact, one body is identified as body A arbitrarily. ~ is defined 
as a unit vector mutu- ally perpendicular to the two contacting edges and directed away from B (figure 
3b). In the absence of friction, F is colinear with for both vertex-plane and vertex-edge contacts. Thus, 
we may write ff =f~ where f is the unknown magnitude of the contact force. From Newton's third law, if 
the force on A is 3% then the force on B will be -f~. Our goal is to calculate contact force mag- nitudes 
that prevent inter-penetration. 4.1 Degenerate Contact Points For yertex-vertex contacts, one body is 
identified as body A arbitrarily; for vertex-edge contacts, the body whose vertex is a contact point 
is identified as body A. Physically, vertex-vertex contacts (figure 4a) and vertex-edge contacts are 
indeterminate: the surface normal h is not well defined and the direction of the contact force between 
A and B cannot be determined. Conse-quently, the physically correct behavior of A and B may be indeterminate 
during the interval in which degenerate contact points occur. In the absence of degenerate contact points, 
the physically correct behavior of A and B is unique. A (a) (b) Figure 4. (a) Indeterminate vertex-vertex 
contact or vertex- edge contact (side view). (b) Removing indeterminacy by choosing n. Since the contact 
force direction is indeterminate, a direction for F must be chosen. To be consistent with our description 
of vertex-plane and edge-edge contacts we set ~t to be an arbitrary unit vector directed away from B. 
3 We then write F =fn, with f an unknown magnitude. The choice of h at degenerate contact points implicitly 
determines a particular behavior for A and B. Usually, indeterminate configurations exist only instantaneously, 
so the choice of ~ for indeterminate configurations has little effect on the simulation. However, if 
a configuration of bodies has degenerate con-tact points, calculating the correct contact force magnitudes 
is an NP-complete problem. This result follows directly from a theorem due to Pafmer[15]. The problem 
remains NP-complete even after a direction for F' is chosen. Solving NP-complete prob- lems currently 
requires exponential time and is considered intract- able. (See Palmer[15] and Garey and Johnson[3] for 
further dis- cussion). The NP-completeness may be avoided by converting indeterminate contacts to determinate 
contacts. Our system does this by imagining that B has been locally extended in a plane nor- mal to n 
as in figure 4b. This extension of B converts each indeterminate contact to the vertex-plane contact 
of figure 3a. Henceforth, indeterminate contact points are assumed to have been resolved in this manner. 
Contact Region Figure 5. The contact force is assumed to be zero except at points marked with o. line 
segment and polygon contact regions shown. For polygonal contact regions, the motion produced by any 
distribution of con- tact forces over the entire contact region can be produced by equivalent forces 
acting on only the vertices of the contact region; the same is true for line segment contact regions[15]. 
Interior points of contact regions are not considered as contact points. Thus, a configuration of bodies 
can be considered to have only finitely many contact points. Let n be the number of contact points; for 
1_< i _<n, the known surface normal and unknown force magnitude at the ith contact point are written 
h i and J~. The unknown f~'s are grouped into a single vector of scalar unknowns, F-For simplicity, we 
shall refer to f~ (the ith element off) as the contact force at point i, even though it is only the magnitude 
of the contact force. The actual force F i at contact point i is given by F; =jinl.  5. Calculating 
Dynamically Correct Contact Forces We can now place exact conditions on the contact forces we wish to 
calculate. A vector f~ of contact force magnitudes is correct if it satisfies the following conditions: 
(1) The contact forces do not allow the bodies to inter-penetrate. (2) The contact forces can "push" 
but not "pull". (3) The contact forces occur only at contact points; once two bodies have separated 
at a contact point, there is no force between them at that contact point. (4) Viewed as a function of 
time, contact forces are continuous.  Condition (4) is phrased somewhat informally, but the intuitive 
idea is that the force at a given contact point should vary smoothly over time (in the time interval 
between successive colli- sions). A correct vector of contact forces will produce motion that is dynamically 
correct. Note that more than one correct f may exist for a given configuration. Normally, the unique 
solu- tion of forces for an "overdetermined" structure is found using the equations of cornpatibility; 
the assumption of absolute rigidity precludes the use of these equations[4]. However, all correct vec- 
tors F result in the same (dynamically correct) motion. 5.1 Non-penetration Constraints To prevent inter-penetration 
it suffices to examine the rela- 4,2 Restricting Contact Points tive motions of bodies at each contact 
point. At time to, let the ith Figure 5 shows regions of contact points between contact- contact point 
be at position p between bodies A and B and let the ing bodies. In order to prevent inter-penetration, 
it is sufficient to functions Pc, and Pb be defined as in section 4. We would like to consider relative 
motion at only the endpoints and vertices of the characterize the geometrical relationship between A 
and B in the neighborhood of p at some (future) time I > t 0. Define a charac-3Our system chooses ~ by 
averaging nearby surface normals. teristiq function (of time) )~i(t) that indicates at time t whether 
A  ,,~~ ~"SIGGRAPH '89, Boston, 31 July-4 August, 1989 and B are: separate near p, touching near p, 
or inter-penetrating near p.4 For vertex-plane contact a characteristic function may be written as ~,(z) 
= ~(t)" (p,,(t) -p/,(t)). (1) This function (locally) characterizes vertex-plane contacts: Z,(t) is 
positive, zero, or negative according to whether p,(t) is outside, on, or inside B (ligure 6). The same 
function may be used for edge-edge contacts: Z~(t) is positive, zero, or negative according to whether 
the edge of A is outside, on, or inside B. In both cases, Z,(t) < 0 signals inter-penetration, and must 
be prevented. p,(t) X(t)>0 h(t) I / x ' (interior ot B) ~ p,(t) X(t)<O Figure 6. Characterization 
of three different positions of p,(t) relative to B at time t. At time In, A and B touch (p,(to) =pj,(t0)); 
therefore Xi(t~) = n(to)" (p,,(to) -pj,(to)) = 0. (2) Since Z,(t) < 0 signals inter-penetration, f' 
must guarantee that Z, is a non-decreasing function at time to; equivalently, f must not allow the relative 
displacement in the t] direction to decrease at time to. Appendix A gives a derivation for ~ and ~. ~ 
measures relative velocity in the n direction, while }{ is a measure of rela- tive acceleration. As such, 
the contact forces f' at time to deter- mine }{(teD); but X(t~) is independent of the contact forces 
that exist at time to. From the simulator's viewpoint, ;((displacement) and Z (relative velocity) are 
given at time to, while }{ depends on the contact forces at time to. What happens then if Zi(t0) < 0? 
This indicates that A and B are colliding (since Z,(t~) is decreasing). Since collisions are resolved 
before calculating contact forces, this will not occur. Conversely, if ZM0) > 0 then A and B are separating 
at contact point i. regardless ~( the contact forces at time to. Immediately after tn, this contact point 
will not exist and thus there will be no contact force here by condition (3) Contact forces vary continu- 
ously by condition (4) so the contact force, ~, must be zero at time to. 5 Thus, contact points with 
"~i(to) > 0 may be ignored since the force at these points is zero and Xi is increasing. We wit1 assume 
that these contact points are discarded by some preprocessing step and ignore their existence hereafter. 
The remaining case is: 6 ZAto) = 0. (3) If f' makes }{,(to)< 0, then p,, is accelerating into B and 
inter-penetration will immediately occur Formally, if 4The use of a characteristic function serves several 
purposes. First, it makes possi-ble simple correctness proofs for our methods. Second. it is extensible 
to contact between higher-order surfaces. Third. i1 allows a unified treatment of the different contact 
geometries. 5From calculus, if a continuous function g(t) satisfies g(t)=0 for t>t,, then g(t,,)= 0. 
~ln practice. ;~.(t.) is compared to zero within an empirically determined tolerance value ~. This applies 
to all similar numerical comparisons in this paper. Zi(to) = Zi(to) = 0 and Zi(to) < 0 then Zi is decreasing 
at time to, resulting in immediate inter-penetration. Thus, condition (l) may be written as ){,(to) -> 
0, (4) corresponding to our intuition that f' must not allow p,, to accelerate into B. Appendix A shows 
that the relative acceleration Hi at time t 0 is a linear function of the contact force S. To make this 
dependence clear, we will explicitly write }{, as a function of }~, Z/if >) with the lmphc]t understanding 
that this occurs at time to. Condition (1 in the form ,(/ ) _> 0 (5) is now a constraint on f~. Figure 
7 derives the constraints for a point mass resting on an inclined plane. (Refer to appendix A for a derivation 
of}{ when body B is at rest). Variables p,, contact point .]] force magnitude m mass of A F ~ total 
force _...4 g gravity vector ~ unit normal Relations F =mg +f]~} lJ,, = --^ ,+ I,~--+Icos0 m f~ Constraints 
~l=~.~i,=~. mg _+j] m(n.g )+l _>0 OF DI ?77 fl _>-m(n "~)=m I~ IcosO Figure 7. Constraint equations 
for a point mass A (with posi- tion p,,) resting on a fixed inclined plane B. Figure 8 derives constraints 
for the contact forces between a block (body A) and a (fixed) floor (body B). Barzel and Barr[2] derive 
p,,; note that centripetal acceleration terms are absent from figure 8 since the block is at rest. Derivations 
for the other relations in figure 8 are found in Goldstein[5]. 5.2 Matrix Formulations of Conditions 
(1) and (2) From the preceding section, Z(,F) is a linear function Thus condition ( 1 ) may be written 
as a linear inequality }{i(J~) = a, lf l + aizf 2 + ''' + a,,~, -b i _>0 (6) for 1 _< i _< n. Condition 
(2), that contact forces only push, may be written as the inequality f >_ 0 (7) for 1 < i < n. Conditions 
(1) and (2) can be written more con-cise[y using matrix notation: let A be the matrix ofaij's and b' 
the Variables ~ .z contact points t_.~1,2 body coordinates a linear acceleration c~ angular acceleration 
fl.2 force magnitudes g gravity vector ...+ F total force total torque m mass I moment of inertia Relations 
  F=my +.fib +f2a F=9~ xf~h +~2 xf, a --) F ~ F __> a=--C~=--pk2=a +O~Xr 1,2:---'}---XF)i,2 m 1 m 1 
 { mY' A lfl ~ lf2~ Constraints xl=n'fil=n mg+ +J2n + r~lxflh+F~2xf2~/l Xr~l 1 -> 0 ~2 =/9/ "#2 =--/~ 
mgt + __ +f2n -}-Ptxfln+P2xf2nl x~2 l -> 0 Figure 8. Constraint equations on the (unknown) contact force 
magnitudes f~,=, for a block (A) supported by a fixed floor (B). The block is at rest. vector of b~'s 
in equation (7) Then a21 a22 a2,, / b2 ~_ ) af-;: ] -= is) La,,, a,,, a;,,,j ,, IN,,(/)J Comparing the 
left- and right-hand sides componentwise, .. ---+ ___. xi(f ) = (Af )i - bi, (9) so condition ( 1 ) can 
be expressed concisely as   (10) or equivalently as AF>-;. 11) Condition (2) is stated as ~ > 0'. 7 
5.3 Linear Programming Finding a vector ~ that satisfies Mx-+ _>c~ (where M is a matrix and ~ is a vector) 
and minimizes a linear function z(~) is an example of the linear programming problem[10, 14]. In linear 
programming, the constraints between M~ and ~ may mix "=" constraints with "_>" constraints. A general 
lower bound of the form ~_> 0 ~ is optional. Systems for which an ,~ exists that satisfy all the constraints 
are feasible systems and each such ~ is For n-vectors x and y, x _> y means x, _> y, for I _< i _< n. 
a feasible solution. Otherwise, the system is infi, asible. Systems for which a feasible.2+ exists that 
minimizes z are bounded sys- tems and each such ~ is an optimal solution. Finding feasible (but not necessarily 
optimal) solutions is also a linear program- ming problem. An f' that satisfies conditions (I) and (2) 
can be expressed as a linear programming problem: choose f' subject to lhe con- straints Zy_>~ and .~_> 
~. (12) Linear programming is a polynomial time problem. A is typically sparse; thus linear programs 
involving A have expected O(n) solution times if a sparsity exploiting linear programming package is 
used[12]. Appendix B discusses some numerical issues con- cerning the matrix A.  5.3 Formulating Conditions 
(3) and (4) However, a feasible f with respect to equation (12) is not necessarily a correct Y. Intuitively, 
an T that satisfies conditions (1) and (2) may be an incorrect solution because it is "too strong". In 
figure 7, the only correct solution is f = (m I~ I cos0). How- -.-+ .__9 . . , . ever, f = (2m I g I 
cos0) is a feasible solunon (with respect to equation (12)) that prevents inter-penetration by incorrectly 
accelerating A away from B. Condition (3) will prevent this. Recall that ~ is a measure of relative acceleration. 
For the ith contact point, if Xi(7) > 0 (13) then X~ is strictly increasing (since X,. = 0 by assumption) 
and A and B are separating at this contact point. Call such a contact point a vanishing contact point 
and call all other contact points (where ~ i(T) = 0) non-vanishing contact points (figure 9). vanishing 
contact point t non-vanishing contact point Time: t o + dt Time: t o Figure 9. A vanishing contact point 
at lime t 0. The bodie separate at the point immediately after time to. From section 5. l, the contact 
force at a vanishing contact point is zero, by conditions (3) and (4). Condition (3) may be formulated 
as the statement fizi(f )=0 (14) because either contact_jgoint i is vanishing (fi = 0 and ~iU '~) > 0) 
or non-vanishing (E/U) = 0 and fi _> 0). Thus, the last constraint needed to guarantee correctness is 
equation (14), for 1_< i _<n. We can write all three constraints in the form n AF_>b, f~_>g and f-~i(f)=0 
(15) i=1 because ~ >_ 0 at-td ~df --~) >_ 0 forces each term .fi~,(f-~) in the sum- mation term of equation 
(15) to be non-negative, preventing can- .. ---+) cellation. Since ~,~Zi~ is non-negative, any correct 
solutionf ~ minimizes this sum. Equation (15) can also be written as Af--+_>~, f~_>~ and f~rA,f--f--+r~=o. 
(16) '89, Boston, 31 July-4 August, SIGGRAPH However, the term FrAT is quadratic in f; finding a correct 
f~ (a feasible solution to equation (16)) is an example of the quadratic programming problem. Quadratic 
programming, unlike linear programming, is an NP-hard problem in general[3]. For the (frictionless) contact 
model, A turns out to be positive semidefinite (PSD). Quadratic programs, when restricted to PSD matrices, 
can be theoretically solved in polynomial time[9], but no practical polynomial time algorithms are currently 
known[14]. Also, there is no reason to believe that A will remain PSD when friction is added to the model. 
For these reasons, we have not attempted to solve the problem of finding a correct f' by direct methods. 
We have developed a successful heuristic algorithm for this problem. The algorithm, like any heuristic 
algorithm, can be made to fail on certain pathological examples.  6. Heuristic Solution Methods A determinate 
configuration of bodies has only one physi-cally correct motion; any correct f~ produces this motion. 
Thus, the correct set V of vanishing contact points for any configuration is unique. Once we know V, 
a correct f~ can be found using linear programming. 6.1 Calculating f given V Suppose that we are given 
the (disjoint) index sets V and C: V = {j ] contact point j is vanishing}. C = { k [ contact point j 
is not vanishing }. (17) For any correct solution f, if je V then f~. = 0, and if ke C then ~Q~) = 0. 
Thus, given V, finding a correct 2~ may be phrased as: choose ~ subject to the constraints Vje V J and 
and Vke C -~ and . (18) t The constraints of this new system are all linear and conditions (1) and (2) 
are enforced. Condition (3) is also enforced since . ~ , . fZM" ) = 0 for lsVor l~C. The new system 
is formed from the original constraint A~ _> b ~. For each non-vanishing contact p~int, the "_>" constraint 
is changed to a "=" constraint since xk(f )=0 is equivalent to (AT)k = bk. For each vanishing contact 
point,.~ is set to zero and the "_>" constraint is retained. Additionally, the jth column of A may be 
set to zero (since ~ = 0) to exploit increased sparsity in A. Figure 10 shows a quadratic constraint 
system for four contact points, and the linear system formed when V={1,3} and C = {2,4}. However, we 
have no "oracle" that will provide us with the set V and we are currently unable to (efficiently) determine 
which contact points are vanishing. Finding V is easy for some configurations (figure 9), but not so 
for others. (As an example, try to determine the vanishing contact points of figure 1. Later frames from 
the simulation are given in figure 14). We can how- ever take a guess as to which contact points are 
vanishing and then use the new linear system to test the guess. If the guess is correct, the new linear 
system will be feasible. Any feasible solu- tion f found by a linear programming~ routine will be a correct 
solution. If the guess is incorrect, no f will satisfy the new sys-tem. The linear programming routine 
will report that the new sys- tem is infeasible, indicating the incorrectness of the guess. The obvious 
question is: how do we guess which contact points are vanishing and which are not? 228 1989 Original 
System a2t 022 a23 a24 / f2 > b2 a21 a22 a23 a24/ _ b3 and 3t a32 a33 a34J b4 ____~ f.(Af -b)i = 0 1 
_< i _< 4 (quadratic) New system V={1,3}, C={2,4} a22 0 a241 f2 2 b2 fl = 0 a22 0 a241 3 -> b3 and f3 
0 (linear) a,2 0 a.j lf4j = h4 Figure 10. Converting a quadratic system to a linear system, given V 
and C. 6.2 The Simplest Guess: V = ~3 To begin, note that a configuration that contains a vanish- ing 
contact point is, in a mathematical sense, singular. By this we mean to suggest that the existence of 
a vanishing contact point is a rare occurrence during a simulation. 8 A vanishing contact point occurs 
at a single instant of time t0, when the contact point is in transition from existence to non-existence. 
Before to, the contact point is not vanishing, and after to the contact point is non-existent and thus 
not considered. Thus vanishing contact points are only dealt with at an isolated instant of time to. 
With this in mind, the obvious first guess is to set V = O, that is, guess that no contact points are 
vanishing. The linear sys- tem constructed from V = ~3 is: choose f subject to the con-straints af ~ 
= b~ and J'~ > C. (19) Note that this problem cannot be solved using standard matrix techniques such 
as gaussian elimination, because of the inequality j"~ > 0 ~, but must be solved as a linear programming 
problem. We have found that the guess V = Q is correct for the vast majority of cases. 6.3 Predicting 
a Non-Empty V When a configuration with vanishing contact points is encountered, the initial guess V 
= O results in an infeasible linear system. Our method of guessing V in this situation is to find an 
approximate solution ~ that satisfies the constraints ~,(Q) _> 0 and ~ _> ~ (20) and use f~ to predict 
which contact points are vanishing. Given an approximate solution ~, define the residual vec-tor P as 
AI~ -ff = " = r~. (21) If f] is in fact a correct solution, then for all vanishing contact SA more precise 
statement is that vanishing contact points occur with measure zero. .... ~ . . . points 2, 1). = zj(f.) 
> 0 and for all non-vanishing contact points k .. ---> . . . . ' r~ =Xk(f.)=0. The hope ~s that an incorrect,yet 
approMmate solution f~ wall mdmate through its residual r which contact points are vanishing Contact 
point i is guessed to be vanishing if and only if ri > 0. The method of section 6.1 is then used to test 
the guess. 6.4 Finding Approximates The current heuristic used for finding an approximate solu- tion 
is: choose F. to minimize the objective function __) tl z(f.) = Y'f"i (22) i=1 subject to the constraints 
A g_>b and f~->0. (23) That is, we wish to find a minimum sum force solution that satisfies conditions 
(1) and (2) An optimal f~ can be found via linear programming since the objective function z is linear. 
Hope-fully, an f. that minimizes z will approximately minimize tt __.) ZLi2i(f.) (24) i-I and thus be 
a good approximate to a correct solution (Recall that a pelfect minimizer of equation (24) is a correct 
solution) The physical intuition behind this choice is that correct contact forces do no net work; therefore 
~ should be chosen to do as little net work as possible, Hopefully, the minimum force solu- tion ~,, 
will do little net work In practice we have found that the residuals formed using z are a good predictor 
of the vanishing contact points  6.5 Dealing with Incorrect Predictions The last question is what to 
do when there are vanishing contact points and ~,, does not predict them correctly. One could of course 
test all the possible guesses, but for n contact points, there are 2" different guesses, which would 
give an exponential algorithm. Our current implementation exploits the fact that configurations with 
vanishing contact points occur infrequently. When a correct solution F cannot be found, we use the approxi- 
mate ~ obtained from the minimum sum force solution. Since f~. is not correct, .faixi(f,,) > 0, (25) 
i-i and the contact force.~ adds energy to the system of bodies, pro- ducing incorrect results. The 
effect is mitigated by the fact that vanishing configurations are singular which means the incorrect 
f, is applied for only a short time. Shortly after applying the incorrect ~ the simulator reaches a configuration 
where a correct f-~ can be found. We have found that the short duration over which f~ is applied, coupled 
with the fact that f-~ is usually a good approximate of a correct solution produces satisfactory results. 
  7. Additional Constraints Holonomic constraints, which express equality constraints between bodies 
(e.g. articulated figures) can be added to the non- holonomic inter-penetration constraint in a consistent 
manner. Barzel and Barr[2] maintained holonomic constraints by introduc- ing constraint forces that had 
to satisfy a linear system af ~ = b. (26) This is consistent with our own formulation since linear programming 
allows equality constraints. Holonomic constraints are added to our system by imposing additional linear 
equality constraints on f~. Elements representing the holonomic constraint force are added to f; these 
elements are not subject to condition (2), the non-negativity constraint. The entire system of con-straints 
is solved as in section 6, except that the minimum sum force solution only takes into account the non-holonomic 
con-straint forces. This is justified since the net work done by the holonomic forces is zero if the 
holonomic constraint equations are satisfied[5]. If no contact occurs, only holonomic constraints remain 
and the system of equations is the same as in Barzel and Barr[2]. We use the sparse linear programming 
package to solve this linear system in O(n) time. Appendix B discusses some numerical issues involved 
with solving equation (26). 8. Simultaneous Collisions The linear programming formulation for resting 
contact can be used to improve the performance of existing collision methods for certain configurations. 
There are two analytical methods for resolving collisions involving multiple contact points and/or bodies: 
impulses at contact points can be calculated and applied one at a time or the impulses can be calculated 
and applied simultaneously for all contact points. We call the former view the propagation model of collisions 
and the latter the simul-taneous model of collisions; recent papers[7, 13] have used the propagation 
model for collisions. The two models are the same for collisions with a single contact point but may 
give give dif- ferent results for some multiple contact point collisions. Figure 11 shows a collision 
between three equal mass billiard balls with no loss of kinetic energy. V V Propagation v 1/3v 2/3v 2/3v 
  &#38;#169;CL3 &#38;#169;CL3 Simultaneous Figure 11. Propagation vs. simultaneous collisions. The 
propagation model results in the right ball moving away from the motionless left and center balls. The 
simultaneous model results in the right and center balls moving with equal velocity away from the leftmost 
ball. In other situations both models produce the same result, but the propagation model can require 
an excessive number of iterations to numerically converge. Figure 12 shows a ball of mass 9 colliding 
with a bali of mass 1, resting on an immovable floor. The collisions are totally inelastic; the propagation 
method iterates between calculating collision impulses between the two balls, and the smaller ball and 
the floor. After n iterations, the top ball will have .9" of its initial velocity v; a higher mass ratio 
would result in even slower convergence. In contrast, the simul- taneous model would produce the limiting 
result (both balls at rest) in one iteration, regardless of the mass ratio. :L~~SIGGRAPH '89, Boston, 
31 July-4 August, 1989   ~a 2+ .9v ;v ; * .gV t rest  ~,,,.w.J at rest Figure 12. Convergence behavior 
of the propagation model. The * indicates where the collision impulse is being applied. To calculate 
collision impulses for simultaneous collisions, we mimic the resting contact problem, At every contact 
point i, there is some impulse Ji : Ji~ti with Ji >- 0 the unknown magni-tude. The goal is to find a 
.~ that satisfies the laws of classical -..--) mechanics; given j , the final linear and angular velocities 
of the bodies (the ultimate goal) can be calculated[ 1 ! ]. For contact point i, let v7 be the relative 
approach velocity in the ~i direction (Xi from section 5) and v) be the (unknown) relative recession 
velo- city in the ni direction, v + is a linear function off*[l 1]. If v~- > 0, the bodies are separating. 
9 Otherwise, the bodies are in resting contact (v 7 = 0) or are colliding (v~- < 0). The coefficient 
of restitution, ~, is defined for single con-tact collisions as v + = -~iv,. (27) The definition of 
e does not readily extend to handle simultaneous collisions. The most that can be said is that if each 
ci = 1 then no kinetic energy is lost during the collision. We have chosen the following rules for simultaneous 
collisions. For each contact point in the collision, it is required that v~- _>-~ivT- (28) i.e. the 
recession velocity must be at least as much as would occur for a single contact coliision. The ">_" is 
needed since body A might be pushed away from body B by some third body C (figure 13). Paralleling the 
resting contact problem, Ji is assumed to be zero if v~ actually exceeds -eivT. A routine calculation 
shows that kinetic energy is conserved for multiple collisions when each ei = 1, and that for single 
contact point collisions, v] =-givi[5 ]. Since v7 is a linear function ofg, the constraints can be written 
as v+(F) + eiv7 > O, Ji > O, ji(v+O ~) + Eivi) = 0 (29) for 1 < i < n. This constraint system has the 
same form as the constraints of section 5, and the heuristic methods of section 6 can be used to solve 
forg. Note that for the case of two bodies col- liding at a single point without friction, the system 
reduces to one equation in one unknown. '~As in section 5.1, contact points with v, > 0 are discarded, 
since the bodies are separating at these contact points. This may immediately result in another round 
of collision resolution, but the excessive iterative behavior of figure 12 should not oc- cur. E__ AI 
 D o Figure 13. A is struck from below by C and pushed away from B. The impulse between A and B should 
be zero. The simultaneous collision method can also enforce holo- nomic constraints. Holonomic constraints 
are maintained by imposing additional linear equality constraints of the form vi ~/ )= v i . Components 
of f~ representing the holonomic con-straint impulses are not subject to the non-negativity constraint. 
For the case of two linked figures colliding at a single point, our method is equivalent to Moore and 
Wilhelms' method[13] except that our system of equation is one third the size of Moore and Wilhelms'. 
The reduction in size of the system is a consequence of regarding F as the only unknown in the problem; 
the final linear and angular momenta are expressed in terms ofF. 9. Conclusion We have presented an analytical 
method for finding forces between contacting polyhedral bodies, based on linear program- ming techniques. 
The solution algorithm currently used is heuris- tic. A generalization of the formulations presented 
yields an analytical method for finding simultaneous impulsive forces between colliding polyhedral bodies. 
Both methods allow holo- nomic geometric constraints to be maintained. A simulator has been constructed 
and a variety of simulations have been produced (figure 14). The major drawback of the current solution 
algorithm is the necessity of solving linear systems of inequalities. Linear programming software is 
considerably more complex than the software used to solve systems of linear equations; software for linear 
equations is also more readily available. Additionally, linear equations currently enjoy a much greater 
diversity of solu- tion techniques than linear programming[6]. The other major concern is that the heuristic 
algorithm used will occasionally fail and an approximate (but incorrect) solution will be used. This 
adds energy to the simulation but does not result in any unsatisfactory visual effects. We have not pur- 
sued the issue of error due to incorporating incorrect solutions into the simulator because we believe 
that such work would be premature. The addition of friction to the model would be likely to render such 
work inapplicable. Also, numerical techniques currently under investigation may preclude the need for 
any heuristic algorithms at all. Acknowledgements This research was conducted under two NSF grants entitled 
"Interactive Input and Display Techniques" (#DCR8203979) and "Visualization for Scientific Computing" 
(#ASC8715478) and an AT&#38;T Bell Laboratories PhD Fellowship. Simulation and displays were performed 
on equipment generously donated by Hewlett Packard Corporation and Digital Equipment Corporation. I thank 
Michael Cohen for preliminary discussions on this work, Jim Cremer for talking me out of some very wrong 
ideas, and Don Greenberg and Roy Hall for sound editorial advice and encouragement. Appendix A We derive 
expressions for Z and ~: Z(t) = n(t)"(p,(t)-ph(t)), (30) "2 (t) = ~(t)'(p,(t)-p~,(t))+ h(t). (p,,(t)-p~,(t)) 
and (31) (t) : ~(t)" (p,,(t) -p,,(t)) (32) + 2~n(t)'~,,(t) -f~,(t))+h(t)'~,,(t) -iJ~,(t)). At time to,p,(h~) 
= p~,(t0) so ~ (to) = h(to)'(p~(to)-f~l,(t,,)) (33) and 2 (t,~) = fi(t,,)'~,,(to) -}J~,(to))+ 2~(to)'(13,,(h,) 
-l~j,(to)). (34) Since fi(t0), ~(t0), l"~,,(to), and f~h(t~) are independent of J ~ and p,,(to) and )J,(h~) 
depend linearly on f[2, 51, ~(t0) is a linear func- tion off. For a vertex-plane contact with B fixed, 
~ =~, = 0 and 2 (t()) = h(n))'~,,(to). Appendix B The purely non-holonomic constraint equation  Af 
_ y>_o" and F'Af -)' b = 0 (35) often involves a singular matrix A, yielding multiple solutions. A is 
singular if the physical structure is overdetermined (such as a chair with more than three legs resting 
on a floor). Barzel and Barr[2] note that the purely holonomic constraint equation Af=/~ (36) is also 
often underconstrained or overconstrained. Underconstrained systems in both cases are easily handled 
by linear programming methods. Overconstrained systems that are feasible (admit a solution) are also 
handled by linear program- ming methods. However, infeasible overconstrained systems require special 
attention. Note that the infeasibilily arises from the holonomic constraint equations. We have encountered 
infeasible systems when using the techniques described by Barzel and Barr[2] to assemble models. We did 
not encounter infeasible constraints from assembled models with holonornic constraints. Barzel and Barr 
deal with infeasible holonomic constraints by selecting the least-squares solution. They find the least-squares 
solution by using singular-value decomposition (SVD), but note that this does not exploit sparsity and 
is relatively slow. SVD methods, however, cannot be used when there are non-holonomic constraints that 
must be maintained. One possibility is to use linear programming to find a solution that minimizes the 
1- norm (a~ opposed to the 2-norm) of the residual in equation (36): choose f such that liAr -~ lit (37) 
is minimi_-ed. (Equation (37) is a convex linear objective function, so the minimization is a linear 
programming problem). For purely hoionomic systems, this approach might be faster than using an SVD method 
since sparsity can be exploited in linear program- ruing methods. However, the complexity and relatively 
unrobust performance of linear programming methods (as compared with SVD methods) is such that the SVD 
method is probably prefer- able for purely holonomic systems. References 1. Barzel, R. and Barr, A.H., 
"Dynamic constraints," Topics in Physically Based Modeling, course notes, vol. 16, SIG- GRAPH, 1987. 
 2. Barzel, R. and Barr, A.H., "A modeling system based on dynamic constraints," Computer Graphics (Proc. 
SIG-GRAPH), vol. 22, pp. 179-188, 1988. 3. Garey, M.R. and Johnson, D.S., Computers and Intracta- bility. 
Freeman, New York, 1979. 4. Gere, J.M. and Timoshenko, S.P., Mechanics of Materials, Wadsworth, Belmont, 
California, 1984. 5. Goldstein, H., Classical Mechanics, Addison-Wesley, Reading, Massachusets, 1983. 
 6. Golub, G. and Van Loan, C., Matrix Computations, John Hopkins University Press, Baltimore. 1983. 
 7. Hahn, J.K., "Realistic animation of rigid bodies," Com-puter Graphics (Proc. SIGGRAPH), vol. 22, 
pp. 299-308, 1988. 8. Isaacs, P.M. and Cohen, M.F., '~Controlling dynamic simulation with kinematic 
constraints," Comlmter Graph- its (Proc. SIGGRAPH), vol. 21, pp. 2 t 5-224, 1987. 9. Kozlov, M.K., Tarasov, 
S.P., and Hacijan, L.G., "'Polyno- mial solvability of convex quadratic programming." Soviet Mathematics 
Doklady, vol. 20, no. 5, pp. 1108-1 I 1 l, 1979. 10. Llewellyn, R.W., Linear Programming, Holt, Rinehart 
and Winston, 1964. 11. MacMillan, W.D., Dynamics of Rigid Bodies, Dover, New York, 1960. 12. Marsten, 
R.E., "The design of the XMP linear program- ming library," ACM Transactions on Mathematical Software, 
vol. 7, no. 4, pp. 481-497, 198 [. 13. Moore, M. and Wilhelms, J., -Collision detection and response 
for computer animation," Computer Graphics (Proc. SIGGRAPH), voi. 22, pp. 289-298, 1988.  14. Murty, 
K.G., Linear Complementarity. Linear and Non- linear Programming, Heldermann Verlag, Berlin, 1988. 15. 
Palmer, R.S., Computational Complexio' of Motion and Stability of Polygons, PhD Diss., Cornell University, 
Janu- ary 1987. 16. Platt, J.C. and Barr, A.H., "Constraint methods for flexible models," Computer Graphics 
(Proc. SIGGRAPH), vol. 22, pp. 279-288, 1988.  17. Shampine, L.F. and Gordon, M.K., Computer Solution 
of Ordinary Differential Equations: The Initial Value Prob- lem, Freeman, 1975. 18. Terzopoulos, D., 
Platt, J.C., and Barr, A.H., -Elastically deformable models," Computer Graphic's (Proc. SIG-GRAPH), vol. 
21, pp. 205-214, 1987.  L,ILj RAPH'89, Boston, 31 July-4 August, 1989 .~SIGG (a) Overbalanced stack 
of bricks. (b) Dominoes.  XHHHINHHHHHHHH I t ~HHIHIIIIHIH J nl n nnn! _ ~HHIIIflR J t (c) Destructive 
chain. fm i (d) Chain curling around a fixed pivot. i i Q (e) Two blocks falling into a chain. [] [] 
[] (f) Many blocks falling into a chain. [] [] [] [] [] [] [] [] [] Figure 14. Assorted simulations (a-f). 
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74357</article_id>
		<sort_key>233</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Goal-directed, dynamic animation of human walking]]></title>
		<page_from>233</page_from>
		<page_to>242</page_to>
		<doi_number>10.1145/74333.74357</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74357</url>
		<abstract>
			<par><![CDATA[This paper presents a hybrid approach to the animation of human locomotion which combines goal-directed and dynamic motion control. Knowledge about a locomotion cycle is incorporated into a hierarchical control process. The desired locomotion is conveniently specified at the top level as a task (e.g. walk at speed <i>v</i>), which is then decomposed by application of the concepts of <i>step symmetry</i> and <i>state-phase-timings</i>. As a result of this decomposition, the forces and torques that drive the dynamic model of the legs are determined by numerical approximation techniques. Rather than relying on a general dynamic model, the equations of motion of the legs are tailored to locomotion and analytically constrained to allow for only a specific range of movements. The dynamics of the legs produce a generic, natural locomotion pattern which is visually upgraded by some kinematic "cosmetics" derived from such principles as <i>virtual leg</i> and <i>determinants of gait</i>. A system has been implemented based on these principles and has shown that when a few parameters, such as velocity, step length and step frequency are specified, a wide variety of human walks can be generated in almost real-time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003728</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Ordinary differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P2576</person_id>
				<author_profile_id><![CDATA[81100008103]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bruderlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School of Computing Science, Simon Fraser University, Burnaby, British Columbia, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39053869</person_id>
				<author_profile_id><![CDATA[81100552470]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Calvert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School of Computing Science, Simon Fraser University, Burnaby, British Columbia, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[William W. Armstrong, Mark Green. The Dynamics of Articulated Rigid Bodies for Purposes of Animation. Graphics Interface '85, Proceedings, 1985, pp. 407-415.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31464</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Norman I. Badler, Kamran H. Manoocherhri, Graham Waiters. "Articulated Figure Positioning by Multiple Constraints". IEEE Computer Graphics and Applications 7, 6 (June 1987), 28-38.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ronen Barzel, Alan H. Barr. A Modeling System Based On Dynamic Constraints. SIGGRAPH '88, Proceedings, August, 1988, pp. 179-188.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Royce Beckett, Kumg Chang. "An Evaluation of the Kinematics of Gait by Minimum Energy". J. Biomechanics 1 (1968), 147-159.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Armin Bruderlin. Goal-Directed, Dynamic Animation of Bipedal Locomotion. Master Th., School of Computing Science, Simon Fraser University,1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Richard L. Burden. Numerical Analysis. Prindle, Weber &amp; Schmidt, 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102341</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Thomas W. Calvert. The Challenge of Human Fi~gure Animation. Graphics Interface '88, Proceedings, 1988, pp. 203-210.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Michael Girard, Anthony A. Maciejewski. Computational Modeling for the Computer Animation of Legged Figures. ACM SIGGRAPH '85, Proceedings, July, 1985, pp. 263-270.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Alan C. Hindmarsh. "LSODE and LSODI, Two New Initial Value Ordinary Differential Equation Solvers". ACM-SIGNUM Newsletter 15, 4 (1980), 10-11.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Veme T. Inman, Henry J. Ralston, Frank Todd. Human Walking. Williams &amp; Wilkins, Baltimore, 1981.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Paul M. Isaacs, Michael F. Cohen. "Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics". Computer Graphics 21, 4 (July 1987), 215-224.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5950</ref_obj_id>
				<ref_obj_pid>5948</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Marc H. Raibert. "Legged Robots". Communications of the ACM 29, 6 (1986), 499-514.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[David Sturman. Interactive Keyframe Animation of 3-D Articulated Models. Graphics Interface '86, Tutorial on Computer Animation, 1986.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Dare A. Wells. Theory and Problems of Lagrangian Dynamics. McGraw-Hill, New York, 1967.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16589</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms. Virya- A Motion Control Editor for Kinematic and Dynamic Aniamtion. Graphics Interface '86, Proceedings, 1986, pp. 141-146.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[David Zeltzer. "Motor Control Techniques for Figure Animation". IEEE Computer Graphics and Applications 2, 9 (1982), 53-59.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>22142</ref_obj_id>
				<ref_obj_pid>22112</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[David Zeltzer. Knowtedge-BasedAnimation. ACM SIGGRAPH/SIGART, Workshop on Motion, 1983, pp. 187-192.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~ ~ Computer Graphics, Volume 23, Number 3, July 1989 Goal-Directed, Dynamic Animation of Human Walking 
Armin Bruderlin Thomas W. Calvert School of Computing Science Simon Fraser University Burnaby, British 
Columbia, Canada V5A 1S6 ABSTRACT This paper presents a hybrid approach to the animation of human locomotion 
which combines goal-directed and dynamic motion control. Knowledge about a locomotion cycle is incorporated 
into a hierarchical control process. The desired locomotion is conveniently specified at the top level 
as a task (e.g. walk at speed v ), which is then decomposed by application of the concepts of step symmetry 
and state-phase-timings. As a result of this decomposition, the forces and torques that drive the dynamic 
model of the legs are determined by numerical approximation techniques. Rather than relying on a general 
dynamic model, the equations of motion of the legs are tailored to locomotion and analytically constrained 
to allow for only a specific range of movements. The dynamics of the legs produce a generic, natural 
locomotion pattern which is visually upgraded by some kinematic "cosmetics" derived from such principles 
as virtual leg and determinants of gait. A system has been implemented based on these principles and 
has shown that when a few parameters, such as velocity, step length and step frequency are specified, 
a wide variety of human walks can be generated in almost real-time. CR Categories and Subject Descriptors: 
1.3.7: [Computer Graphics]: Three-Dimensional Graphics and Realism Animation; G.1.7: [Numerical Analysis]: 
Ordinary Differential Equations. Keywords: Animation, goal-directed animation, human figure animation, 
dynamics, kinematics, inverse kinematics. 1. INTRODUC'I'ION The specification and control of motion in 
human figure animation has always been a challenge, but two recent trends promise to relieve the tedious 
work of the animator. One involves high-level, goal-directed control, which reduces the amount of detail 
necessary to define a motion; the second involves applying dynamic analysis to the motion control process, 
leading to more realism in movements. In traditional keyframing [13], the quality of a motion is usually 
directly proportional to the number of key positions specified. If the desired movements are complicated, 
the animator, rather than the system, does motion control. It has been recognized that if the Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. excessive amount 
of specification for character animation is to be reduced, higher level motion control is necessary [2, 
7, 17]. At the lowest level, all movements are expressed by joint rotations over time, but these joint 
rotations must be coordinated within a limb, between limbs and are subject to the interaction of the 
whole figure with its environment. By incorporating knowledge or rules about these inter-relationships, 
tasks like grasping or jumping can be automated and presented to the user as pararneterized goals. In 
such a goal-directed system, the global coordination of a motion is done by the computer. However, movements 
are still executed kinematic :fly at the lowest level, and the impact of physical laws such as gravity 
or collisions on the motion process are ignored. To achieve realistic and natural movements, dynamic 
analysis must be applied as a motion control technique. By simulating the real world, objects move as 
they should move, according to physical laws. The drawback is that the animator has to specify motion 
in terms of forces and torques; this is neither intuitive nor easy, and it is complicated by the computationalty 
expensive character of this approach. In the past, simulation of human figures concentrated on simple, 
elementary movements not involving coordination between several limbs (e.g. raising an arm or dropping 
an arm under the influence of gravity). By combining a goal-directed higher level control with dynamic 
simulation of motion, a system can be developed for economic and realistic animation of many co-ordinated 
human movements. This paper introduces such a method for the purpose of animating human locomotion. To 
this end, we have implemented the KLAW (Keyframe-Less Animation of Walking) system to animate walking. 
Dynamic simulation provides the low-level control; a dynamic walking model, inspired by research in robotics 
[12] and biomechanics [4] produces a generic walking pattern from different sets of analytically constrained 
equations of motion which are applied as appropriate to the current state of the locomotion. Kinematic 
algorithms are applied to calculate all the body angles from the motion of the dynamic model. The dynamics, 
in turn, are regulated by a higher level control; the proper forces and torques which generate a desired 
locomotion are calculated as a result of a stepwise decomposition of a few walking parameters specified 
by the user. Thus, motion is specified conveniently and realistic animations are obtained based on the 
dynamic equations of motion without explicit specification of forces and torques. The goal-oriented approach 
used in this paper builds on the work of Zeltzer [16], who developed a task-oriented system to animate 
human locomotion; although tasks like walking and jumping were implemented, the calculation of the joint 
angles were done kinematically and based on interpolation methods and clinical data. Thus it was not 
possible to easily realize variations in locomotion by changing step length or speed. The general &#38;#169;1989 
ACM-0-89791-312-4/89/007/0233 $00.75 '89, Boston, 31 July-4 August, 1989 approach to dynamic analysis 
which we have adopted is based on the work of Wilhelrns [15], Armstrong [1] and others [3, 11]. Perhaps 
the most comprehensive approach is that of Wilhelms, who produced Virya, a dynamic system for the animation 
of human figures which also allows for kinematic and hybrid kinematic-dynamic motion specification. In 
the dynamic mode, however, forces and torques have to be input in order to achieve a motion. Badler et 
al. [2] have been developing kinematic techniques to animate human figures. They have proposed a higher 
level of control, where goals such as reaching for a certain position can be defined and the joint angles 
are found using inverse kinematic algorithms. They also investigated dynamic and kinematic animation 
of specific tasks (e.g. movement in a space vehicle). A system to animate legged figures was developed 
by Girard and Maciejewski [8]; dynamic control was applied to the body as a whole, and the legs were 
specified kinematically. The problem of constraining a foot to be on the ground during its support phase 
was formulated as an inverse kinematics problem and solved by means of a pseudoinverse jacobian. 2. THE 
KLAW SYSTEM 2.1 Overview Legged locomotion describes an intricate activity where body translation results 
from rotational movements in the lower limbs; problems such as coordination between the legs, proper 
timing of the individual leg motions and balancing of the upper body have to be addressed. It is clear 
that humans and other animals, however, are able to walk effortlessly without conscious thought. This 
is because they are inherently goal-directed [17]. Rather than thinking in terms of forces and torques, 
humans walk with certain goals like speed or step length in mind --thus, a hierarchical control scheme 
is well suited to animate human locomotion. Figure 1 gives a structural outline of the KLAW system. The 
animator specifies a desired walk with up to 3 fundamental locomotion parameters which largely determine 
the pattern of motion and gait: forward velocity (v), step length (sl) and step frequency (sf). A major 
concern in constructing a goal-directed system has been the degree to which a task should be parameterized. 
The animator should have access to a simple, yet flexible set of movement commands that can generate 
a variety of instances of a task. In KLAW, therefore, in addition to the 3 locomotion parameters, up 
to 28 locomotion attributes [5] may also be specified which individualize the locomotion. The default 
values of these attributes may be modified by the animator. Examples are: lateral distance between the 
feet, toe clearance during swing, and maximum rotation and llst of the pelvis. After parameter specification, 
the system computes and outputs the body angles as functions of time -- these drive the animation of 
a human figure. 2.2 Levels of Control Knowledge about a locomotion cycle occurs at three levels: the 
conceptual abstraction (high-level), the gait refinements (middle- level) and the physical abstraction 
(low-level). The conceptual level contains a few gait-specific rules or laws. These are utilized to transform 
the locomotion parameters into step constraints which are fed to the low-level control to "guide" the 
dynamic simulation of the legs. The middle-level control is responsible for the coordination of the motion 
and functionally operates much like a finite state machine as suggested by Zeltzer [16]. For instance, 
upon a "heel-strike" event, the state "single support" is changed to "double support". Hierarchically, 
the middle-level control manifests a stepwise reduction in the number of degrees of freedom along with 
a decrease in the levels of coordination (e.g. the single support state of a walk consists of a stance 
and a swing Locomotion p ~high-level control arameters ~ .......... I /Conceptual / ............. ! 
...... m Symmetry of Step~ : 1 Abstraction ~ 1 , EState-Phase Timings.~ ! middle-level control Cons~'ainrs 
~'States BLJUUUIO OU~JOOIt,~ [:~OIII910 OUppOlt~ I .............. ..... NApproximation E~of~agrange~Lo~om~tt~ 
] I~ Forces, Torquos~--l~ M0ti0 n~"r------~Modols~ ,' II COflgrO feedback r ...............  Abstraction 
.,, J L t LowerBody Lower uooy ; ........................ M .~.og/es Kinematics ~"a it Determinants| 
=~ J ,, ............ J_,: Pelvic Movement Compensation t l .......................... Upper Body ~,Kinematics 
............ "~" ........... :::::::::::::::::::::: .......  BodyAngles Figure 1: Schematic diagram 
of the control hierarchy in KLAW. phase). The bottom level is represented by sets of specialized equations 
of motion; in fact, the phases are divided into subphases in which the equations are further constrained 
analytically. The low-level control uses the step constraints (which essentially are the durations and 
final leg angles for the stance and swing phases of a locomotion step) as conditions for a special kind 
of a boundary value problem. That is, the equations of motion are solved by approximating the forces 
and torques until the constraints are satisfied. For example, the simulation of the swing leg for the 
current step is repeated by varying the joint-torques until it swings forward in the exact time required 
and heel-strike occurs with the desired hip and knee angles. In practice, this process converges quite 
quickly. 2.3 Dynamic Model A principal objective is to keep the dynamics simple, otherwise the internal 
calculation of the forces and torques becomes infeasible. As shown in figure 2, the swing leg is represented 
by two segments. The stance leg supports the upper body and is implemented as a length-changing telescopic 
segment which simulates knee flexion in the early part and plantar flexion of the ankle in the latter 
part of the stance phase (as explained later, for animation, a full leg with knee, ankle and metatarsal 
joints are superimposed). This approach is chosen since a linear force along the leg axis is much easier 
to control than additional torques at the leg joints. The segment masses are assumed to be constant and 
the segments to be symmetrical. The latter implies that the principal axes of inertia are identical to 
the anatomical axes of rotation, and therefore the products of inertia are zero. Thus, the distribution 
of mass is solely defined by the moments of inertia which are calculated as described in appendix B. 
This simplification is justified for dynamic analysis in computer animation, since it has  ~ Computer 
Graphics, Volume 23, Number 3, July 1989 i (xh,Yh / /(x,y)/ / a) stance leg model with upper body 
b) swing leg model (inverted double pendulum with telescopic leg) (double pendulum) Figure 2: Dynamic 
models for the different phases in locomotion. 03 is negative in this configuration, all other angles 
are positive; see appendix B for anthropometric values. no significant effect on the motion. The equations 
of motion are derived by the method of Lagrange [14] as shown in appendix A.1 and A.2. The ground constraint 
for the stance phase is implemented as an analytical constraint; assuming that the "dynamic foot" does 
not move during stance, the two degrees of freedom, x,y, are removed. In this way, there are a total 
of only 5 degrees of freedom (w, 01 , 0 z , 03, 04) and consequently 5 second order, nonlinear equations 
of motion. The equations are solved by an A-stable, standard numerical integration method [9] which has 
produced numerically stable results for this problem. 2.4 Control Principles The execution of the different 
components in KLAW is based on four assumptions or principles: 1. The control hierarchy as illustrated 
in figure 1 is applied to each step of a walking sequence where a step is defined as the double plus 
the single support state (see also figure 3). While the high- level concepts are executed before the 
impending step, the low- level motion control takes place during the step. Thus, KLAW is able to adapt 
to changes in the locomotion parameters from step to step, i.e. accelerations and decelerations in the 
motion are possible with a granularity of one step. 2. Lower body dynamics and kinematics must be executed 
simultaneously. The dynamic simulation produces the generic locomotion pattern which is visually upgraded 
by kinematic measures. As explained in section 4, a human leg is superimposed onto the telescopic stance 
leg according to the virtual leg principle, and gait determinants like pelvic rotation or list get injected 
into the one-hip dynamic model. In a sense, the equations of motion guide the lower body kinematics, 
but the kinematic computations may, in turn, affect the dynamics. For instance, the simulation of the 
swing leg, where the foot is assumed to be locked, has to take into account the updated position of the 
heel as a result of the kinematic foot rotation, in order to achieve heel- strike properly at the end 
of a step. Similarly, the kinematic pelvic rotation can actually lower the hip during the swing phase, 
which might "force" the dynamic leg to increase its hip torque to avoid stubbing its toe. Though considerable 
kinematic "cosmetics" are applied, the dynamics are the very heart of the control for they guarantee 
natural looking rotational movements of the legs.  3. It is assumed that the upper body follows or depends 
on the lower body movements. Whereas the dynamic model accounts only for a natural forward and backward 
motion of the upper body (02 ), the angles of the arms as well as the rotations in the shoulder and 
spine which compensate for pelvic movemehts are expressed as functions of the corresponding angles in 
the lower body. The arms, for example, swing forward with the opposite legs. Thus, these angles are calculated 
after the dynamic simulation. 4. The last assumption concerns the dynamic model discussed above: the 
simulations for the stance and swing phases are separated which greatly simplifies the control as well 
as the numerical integration process. The rationale is that the stance leg model constitutes the major 
propulsive element in bipedal locomotion. It supports the body and influences the swing leg by its hip 
motion. On the other hand, the swing leg has little or no effect on the stance leg and the upper body. 
Of course, this is not completely true in real human walking, but it can be justified by the fact that 
the mass of the leg is small compared to the total mass of the body (approx. 16 %). Hence, the swing 
leg does not change the inertia of the body significantly unless the motion during swing happens veery 
suddenly, which is hardly the case for a moderate walk. Therefore, for each step, the simulation of the 
stance phase is executed first followed by the swing phase dynamics which incorporate the position of 
the hip (x h, Yh ) from  the stance phase. 3. HIGH-LEVEL CONCEPTS This section gives a discussion of 
the high-level control module whose task is to transform the 3 locomotion parameters v, sl and sf into 
the step constraints for the low-leveI control. At least one locomotion parameter (e.g. desired velocity) 
has to be input by the animator. If all 3 of the parameters are not specified, the system completes the 
parameters using a normalization formula (the parameters are also checked at this point to ensure that 
they are within anatomical limits defined by locomotion attributes, e.g. sfmax= 182steps~rain). Once 
the locomotion parameters are accepted and specified, the step frequency and the state-phase-timings 
are applied to determine the durations of the stance and swing phases, and the step length is used with 
the symmetry of steps concept to compute the final conditions for each phase of the current step. HSL 
"FOR HSR TOL HSL single single states support (left) support (right) loft stance ~A loft swing v~ phase 
right swing = rightstance :E 0% 1 stop 50% 100% HSL = heel strike left HSR = heel strike right = lee 
oll right TOL = toe off le~l Figure 3: Locomotion cycle for bipedal walking.  '89, Boston, 31 July-4 
August, 1989 cycle), it is sufficient to compute movements for one cycle. The human walking cycle has 
been thoroughly studied- see Inman [10], for example. For bipedal walking, a locomotion cycle consists 
of two steps. As long as a symmetric gait is assumed where the left and right leg perform the same movements, 
just shifted in time, the principal unit of locomotion can be reduced to one step (see figure 3). Walking 
is possible at a wide variety of combinations of sl and ST (v = sl. sf). However, a person, when asked 
to walk at a particular velocity, is most likely to choose parameters which minimize energy expenditure. 
This observation is expressed in the experimentally derived equations [10], called normalizing formulae, 
which show a linear relationship between sl and ST, where sl and body_height are measured in m, and sf 
in steps/rain : sl = 0.004 (1) sf . body_height 1J V => sf 2 = 0.004. body_height' because of sl = -~ 
. The body_height normalizes the equation. It indirectly represents the length of the legs, which has 
an effect on the preferred step length. Based on equation (1), the locomotion parameters are now checked 
and supplemented if at least one is specified. For instance, if a velocity is defined, a "natural" step 
length and step frequency are calculated; in the case where a velocity and a step length are specified 
a more angular motion might result if the step length deviates significantly from the "natural" one (see 
also figure 10). The step frequency is the input to the state-phase-timings calculation. A walking cycle 
consists of two steps (figure 3), each step having one double support state (ds) where both feet are 
on the ground and one single support state where one foot is off the ground. With respect to timing of 
the individual legs the following holds, assuming t to denote a duration: tstep = tstance--tea and tstep 
= tswing+tdx. (2) Experimental data [10] suggest that in human walking there is an approximately linear 
relationship between the step frequency and the duration of the double support state as a percentage 
of a cycle, i.e. the duration of the double support state decreases with increasing step frequency. As 
tea vanishes, walking becomes running. Based on results from different experiments, tds can be described 
in terms of sf and tcycl e : tea = ( - O. 16. sf + 29.08 ). tcyde / 100. Since sf is known as one of 
the locomotion parameters, and because of 2 tcycl e = 2" tstep - sT' t~ can be determined, and consequently 
the values for tstance and Iswing are obtained from equation (2). It should be noted that the length 
of the stance phase is greater than a step, i.e. tstance = tst" + tea (see figure 3). To simplify implementation 
and to satisfy t~e step-oriented control principle (assumption 1.), the stance phase of a leg is only 
simulated for the duration of a step and at heel strike, when the stance phase of the leading leg starts, 
the continuing stance phase of the hind leg is completed kinematically. Step symmetry is based on a compass 
gait (figure 4), and means simply that at heel strike, provided that both legs are of the same 236 length, 
the angles of the legs measured from the vertical are identical. That is 0 t = 03 at times t], t 2 and 
t 3 . Further, 0] and 03 depend only on the step length sl. Most importantly, this remains true when 
the body is accelerating or decelerating, indicated in figure 4 by the increased step length at time 
t 3 (i.e. the body accelerated from t 2 to t 3 ). t 1 12 13  V ' 'V sl ,~ LL = left leg RL = right 
leg Figure 4: Symmetry of compass gait for different step lengths. This principle is now adapted to 
the model in figure 5 to determine w, 01 and 03 at the end of a step (heel strike) utilizing the current 
step length sl, Although the actual step configuration at heel strike is no longer symmetric because 
of the introduction of a kinematic foot for the swing leg, the basic idea can still be applied. We just 
imagine the symmetric step situation when the foot is flat on the ground some time after impact (illustrated 
by the dashed line) and calculate "back in time". For this purpose, the step length sl is measured between 
ank/e 1 and ankle 2 . The effect of the foot at heel strike is that the absolute value of 03 is smaller 
than it would be without a foot (also, 03 < 01 ). In addition, the foot raises the position of the hip 
at impact, which has to be compensated by lengthening the telescopic stance leg beyond its initial length, 
i.e. w > l 1 . The origin for the simulation of the stance leg stays fixed at ank/e 1 , which is at a 
distance l 9 above the ground. For the following calculations, it is assumed that the ground is at zero 
height and 05 at impact is specified as one of the locomotion attributes. Given ll, 1 s , 19 ' 111 and 
cos ( co 8 ) = t1~/8, the application of the cosine law yields r 2 = 112+171 -2 l 1 111 COS ( 0 5 + 00 
8 ), and (03 = cs'S T~77 ' Since ankle 1 = (x a, ya ) = (xnh, + l 8,l 9) where x~, is xnh from previous 
step, and heel = (x~,y,~)= (x +sl-ls,O) hip = (xh, Yh) = (Xa+S_ l 2" 4"1. 2 _ (x ~, - xh)2) , it follows 
that ~ . .mirtH. ira,, ill stance le 9 / ~p wing leg / jj~' r~,~ anklet &#38; sl/2 ~- 05-~-~1 ankle 
2 I ! ]5 l   ////Y/1/ IIIII IIIJ Ilil/1111 hee, I 111 I sl i k ! ! Figure 5: Dynamic model at heel 
strike: the swing leg is extended, a foot has been added kinematically, the upper body is ignored; 0 
3 is assumed to be negative, all other angles are positive. w = ~(yh-ya)2+(;) 2 01 = sin "1 ~ 03=-co 
3 -sin "1 . (3) These are the 3 final conditions for a locomotion step; together with the durations for 
the leg phases they form the step constraints that govern the execution of the low-level control and 
determine the motion by leading to the internal calculation of the applied forces and torques. 4. LOW-LEVEL 
CONTROL The low-level control generates the actual motions by application of a mixture of dynamic and 
kinematic algorithms. The essence of this control is explained in this section and a full discussion 
can be found elsewhere [5]. The stance and swing phases of a locomotion cycle are examined separately. 
Although the dynamics are subject to the step constraints which force the execution of a particular step 
length and step frequency, they need to be guided to produce desired motions during a phase by applying 
rules about walking directly at this low level. For instance, regardless of the stiffness of the leg 
spring, the hip of the stance leg model must never be allowed to drop below its minimal value at heel 
strike in order to maintain some kind of a sinusoidal motion pattern; similarly, the swinging leg does 
not just swing forward to reach the final hip angle at impact, but the motion has to be timed appropriately 
throughout the swing to make it look real. For this purpose, additional restrictions are imposed in two 
ways: each phase is divided into a number of subphases, where the equations of motion are "t'me-tuned" 
to further suit bipedal walking, and the trajectories of the applied forces and torques are expressed 
as specific functions of time. The dynamics account  Computer Graphics, Volume 23, Number 3, July 1989 
not only for natural movements within a phase, but they also provide continuity across phases. For example, 
heel strike which occurs between the swing and the stance phase is treated as a collision, whereby the 
new initial conditions for the stance phase are calculated by the conservation of linear and angular 
momentum. Although the dynamically simulated motion appears natural in terms of timing and continuity, 
it does not show human characteristics. To humanize the movements, kinematic algorithms based on the 
principles of the virtual leg and the determinants of gait are integrated into the dynamic motion control 
process as shown below. 4.1 Calculation of Forces and Torques The problem of finding the forces and torques 
to meet the desired constraints for each stance and swing phase is formally expressed as follows, assuming 
the matrix representation of the equations of motion as set out in appendix A: A q = B ( q, i t, Fq ) 
, subject to q( to )= (~, q( te ) = ~ and to_< t_< t e . The generalized forces F are now the independent 
variables and q, the objective is to find the proper forces or torques such that, given the initial conditions 
q( t o ), the system reaches the final conditions q( t e ) in exactly time t e. This is a classical root-finding 
problem where the roots F are approximated by qt numerical techniques. As an example, consider the stance 
phase: the initial conditions come from the end of the preceding swing phase and the collision laws at 
heel strike. The final conditions are the hip angle 01 and the length of the leg w at time tst e as calculated 
from equations (3) and (2). The equations at e motion are now iteratively integrated over the duration 
tstep by modifying the leg torque Fo~ and the leg axis force F w on each iteration until the final conditions 
are met. The approximation of F is performed in two stages. First, the q, Bisection method computes a 
reasonable approximation which is then refined by the Secant method. This technique was employed because 
the Secant method converges fast, but needs a good first approximation [6]. A solution to F is usually 
obtained within a q, few iterations (between 6 and 10). Once the rhythmic phase of a locomotion sequence 
is reached, i.e. the forward velocity of the body as a whole is fairly constant, the algorithm converges 
even faster since the F profiles from one step are carried over to q, initialize the next.  4.2 Stance 
Phase During stance the upper body is balanced by the torque F0. the magnitude of which is determined 
by a simple spring and damping model. The leg torque F0, is calculated by the approximation procedure 
described above to satisfy the hip angle 01 at the end of the step. Since experiments on human subjects 
utilizing electromyography and force plates [10] have shown that a significant torque at the hip occurs 
only just after heel strike and lasts for about 20 % of the cycle time, F0, is applied as a step input 
torque which is turned off at 0.4 t .... . The leg axis force o,-e F is approximated such that the telescopic 
leg w is extended to 1, its desired value at the end of the step. The force profile of F w is expressed 
as a spring and damper model of the form   :~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 F w = k 
w(l t + pa -w) -v ww , (4) where k and v w are spring and damping constants, respectively; l~ is the 
unloaded length of the leg, w is the current leg length and w the velocity along the leg axis A position 
actuator, pa (initially zero), actively controls the magnitude of the force; pa must be chosen such that 
the hip of the stance model prescribes a vertical sinusoidal curve typical in human walking [10]. The 
hip is therefore constantly monitored during stance: if it drops too low, pa is increased and if the 
leg extends too much, the value ofpa is reduced. However, this method might cause the telescopic leg 
to become too long (particularly at a low walking speed where the leg does not shorten much after heel 
strike); if w > l t (which simulates a plantar flexion of the ankle) occurs too early in the stance phase 
an unnatural leg motion results. To prevent this, the stance leg is locked as soon as as it reaches a 
critical length which is either 11 in the early part or the desired length as calculated by equation 
(3) towards the end of the stance phase For this purpose the dynamics of the stance phase are divided 
into subphases: one in which the equations of motion apply as defined in appendix A.1 where the leg is 
represented by a telescopic inverted pendulum, and another phase in which the leg is defined as a rigid 
inverted pendulum, expressed by the following modifications to the matrix form of the equations: at, 
1=1, bl=al, 3=a3,1=0 and ~'=0. The subphases are coordinated by the middle-level finite state machine 
which basically switches between the different sets of equations of motion upon signaling of such events 
"leg too long". If the leg is locked because w > 11 , the lock is removed as soon as the event 01 > 0 
(leg passes through vertical) occurs, and an increase in pa extends the leg to the desired length at 
the end of the step. The virtual leg principle describes the procedure which is applied to superimpose 
a human leg onto the telescopic stance leg (figure 6) at each time step during the simulation Unfortunately, 
the number of possible configurations is infinite, i.e. a unique solution does not exist for the orientation 
of the segments from the hip (H) to the tip of the toe (T). This is a typical inverse kinematics problem, 
where the proximal (H) and distal (T) endpoints are given (H is known from the simulation, T is fixed 
during stance) and the task is to fred the angles of the kinematic chain spanned between these endpoints. 
At least two of the four angles (03 ..... 06 ) must be known to fully specify a particular configuration. 
The information to calculate all leg angles is supplied by rules about the motion of the foot during 
the stance phase These rules express a normal period just after heel-strlke where the foot rotates around 
the heel until it is flat on the ground. The normal period ends when the ankle angle 05 reaches a limiting 
value, at which time the heel begins to come off the ground (heel-offperiod), i.e. the mid-foot rotates 
around M during this period with radius 112. As soon as 06 reaches a limit, the recta-off period is entered 
where the whole foot rotates around T until the end of the stance phase (toe-off). Once 05 and 06 are 
known the hip and knee angles (03 , 04 ) are determined by simple trigonometric calculations The determinants 
of gait [10] mainly describe the movements of the pelvis during locomotion and play a major role in bestowing 
human appeal to the motion. Pelvic rotation (transverse plane), pelvic list (coronal plane) and a lateral 
displacement of the body --the body weaves slightly from side to side following the weight-bearing leg 
-- have been implemented. By introducing a pelvis, the kinematics of the determinants basically add a 
second hip to the locomotion model and must therefore be applied after 238 H 0 B an el/ ~/~~~~1~IT~ 
Figure 6: Superposition of a leg over the dynamic stance leg model. The proportions of the foot (112 
' lib ) are exaggerated. the the stance phase simulation but before the simulation of the swing leg which 
uses the new position of this hip. The rotation (list) of the pelvis is a maximum (minimum) at heel-strike 
and a minimum (maximum) at mid-step, whereas the lateral displacement is a maximum shortly after toe-off 
and a minimum at heel-strike. These boundary values are specified as locomotion attributes and linear 
interpolation is applied to obtain all the intermediate angles. A linear interpolation is justified since 
the absolute displacements produced by the determinants are rather small. 4.3 Swing Phase As with the 
stance phase, the simulation of the swing phase is broken up into subphases in order to achieve a natural 
movement of the leg. Three subphases are distinguished --they are illustrated in figure 7. During swingl 
(from t o to t 1 ) the ankle is constrained to move along the curve P until the toe is exactly under 
the knee. At the same time, the hip angle reaches a maximum, which is the desired value for heel strike 
as calculated by the symmetry of step concept. The swing2 subphase lasts from t t to t 2 and is characterized 
by a rapid extension of the knee joint while the hip angle stays fairly constant. After the knee is fully 
extended at time t 2 , a small moment at the hip forces the heel onto the ground during swing3 to bring 
about heel-strike (at t 3 ). Whereas in the stance phase the subphases are triggered by events, the duration 
of each swing subphase is known a priori. Based on experimental data [4, 10], the end for swingl occurs 
at about 50 % of the time for the swing, which means that after half the swing time, the thigh of the 
swing leg has reached its desired orientation for heel strike. The end of swing2, marked by the straightening 
of the leg, takes place about 85 % into the swing, and the end of swing3 coincides with the end for the 
swing phase. Because the time for the swing lswing of the current step is known from the state-phase 
timing concept, the durations for the subphases can be readily determined. A foot is added kinematically 
to the model whereby the ankle and metatarsal angles are interpolated between their values at toe-off 
and heel- strike (the former are known from the kinematic meta-offperiod, the latter are specified as 
locomotion attributes). During the swingl phase the hip torque vF% is expressed as a  O ~ Computer 
Graphics, Volume 23, Number 3, July 1989 rn3 ~,, = 8 kg, 13 +m 3 r 3 +rn 4 13 14 + m 4 r4 + m 4 13 r 
4 cos 04 03 ][1 222 13~ = 0.426 m +I 4 +m 4 r42 + 2 m 4 l 3 r 4 cos 04 . = r3~ = r 3. 13~ = 0.184m, al,2 
14 + rn4 r42 04 F% + ( m 3 r 3 + m 4 l 3 ) ( xh cos 03 - Yh sin 03 ) + m4 g4 ( xh cos ( 03 + 04 )-- Yh 
Sin ( 03 + O 4 ) +m 413r 404(203+04)sin04 -m 3 g r 3 sin 03 - m 4 g ( l 3 sin 03 + r 4 sin ( 03 + 04 
) ) Fo4+m 4r 4(X hCOs(O 3+04)-yhsill(03+04)) '2 -- m 4 l 3 r 4 03 sin 04 - m 4 g r 4 sin ( 03 + 04 ) 
 B. ANTHROPOMETRIC DATA Table B-1 lists the relative (lengths are fractions of body height, masses are 
fractions of body mass) anthropometric data of the segments used by the dynamics and lower body kinematics, 
l i denote lengths, m i masses, r i distances to centers of mass and "Yi radii of gyration. It should 
be noted, that except for rl, which is measured from the distal end, the centers of mass are given from 
the proximal end of a segment. The radii of gyration are specified with respect to the center of mass: 
segment i l i rn i r i "Yi pelvis 0 0.10059 leg 1 l 3 + 14 m 3 + m 4 0.553 0.326 upper body 2 0.47 0.678 
0.5 0.496 thigh 3 0.23669 0.1 0.433 0.323 shank 4 0.24556 0.061 0.606 0.416 mid foot 5 0.0858 toe 6 0.04734 
hind foot 8 0.02959 ankle-footbase* 9 0.03846 heel-ankle* 11 0.04853 ankle-lstmetatarsal* 12 0.08901 
 lstmetatarsal-toe tip* 13 0.0496 Table B-I: Anthropometric values of lower body segments (the " indicates 
a distance rather than a segment length). The absolute anthropometric data, including the moments of 
inertia/i' are calculated by the system once the values for body height and body mass are specified. 
As an example, if the total body height is to be 1.8m and the body mass 80kg, the following values result 
for the thigh: Y3~ = 'Y3" 13~, = 0.138m, 13 = rn3~" ( 13~" Y3~, ) 2 = 0.0276 kg m 2 . REFERENCES I. 
William W. Armstrong, Mark Green. The Dynamics of Articulated Rigid Bodies for Purposes of Animation. 
Graphics Interface '85, Proceedings, 1985, pp. 407-415. 2. Norman I. Badler, Kamran H. Manoocherhri, 
Graham Waiters. "Articulated Figure Positioning by Multiple Constraints". IEEE Computer Graphics and 
Applications 7, 6 (June 1987), 28-38.  3. Ronen Barzel, Alan H. Barr. A Modeling System Based On Dynamic 
Constxaints. SIGGRAPH '88, Proceedings, August, 1988, pp. 179-188.  4. Royce Beckett, Kumg Chang. "An 
Evaluation of the Kinematics of Gait by Minimum Energy". J. Biornechanics 1 (1968), 147-159.  5. Amain 
Bruderlin. Goal-Directed, Dynamic Animation of Bipedal Locomotion. Master Th., School of Computing Science, 
Simon Fraser University,1988.  6. Richard L. Burden. Numerical Analysis. Prindle, Weber &#38; Schmidt, 
1985.  7. Thomas W. Calvert. The Challenge of Human Figure Animation. Graphics Interface '88, Proceedings, 
1988, pp. 203-210.  8. Michael Girard, Anthony A. Maciejewski. Computational Modeling for the Computer 
Animation of Legged Figures. ACM SIGGRAPH '85, Proceedings, July, 1985, pp. 263-270.  9. Alan C. Hindmarsh. 
"LSODE and LSODI, Two New Initial Value Ordinary Differential Equation Solvers". ACM-SIGNUM Newsletter 
15, 4 (1980), 10-11.  10. Verne T. Inman, Henry J. Ralston, Frank Todd. Human Walking. Williams &#38; 
Wilkins, Baltimore, 1981.  11. Paul M. Isaacs, Michael F. Cohen. "Controlling Dynamic Simulation with 
Kinematic Constraints, Behavior Functions and Inverse Dynamics". Computer Graphics 21, 4 (July 1987), 
215-224,  12. Marc H. Raibert. "Legged Robots". Communications of the ACM 29, 6 (1986), 499-514.  13. 
David Sturman. Interactive Keyframe Animation of 3-D Articulated Models. Graphics Interface '86, Tutorial 
on Computer Animation, 1986.  14. Dare A. Wells. Theory and Problems of Lagrangian Dynamics. McGraw-Hill, 
New York, 1967.  15. Jane Wilhelms. Virya- A Motion Control Editor for Kinematic and Dynamic Aniamtion. 
Graphics Interface '86, Proceedings, 1986, pp. 141-146.  16. David Zehzer. "Motor Control Techniques 
for Figure Animation". IEEE Computer Graphics and Applications 2, 9 (1982), 53-59.  17. David Zeltzer. 
Knowtedge-BasedAnimation. ACM SIGGRAPH/SIGART, Workshop on Motion, 1983, pp. 187-192.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74358</article_id>
		<sort_key>243</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Layered construction for deformable animated characters]]></title>
		<page_from>243</page_from>
		<page_to>252</page_to>
		<doi_number>10.1145/74333.74358</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74358</url>
		<abstract>
			<par><![CDATA[A methodology is proposed for creating and animating computer generated characters which combines recent research advances in robotics, physically based modeling and geometric modeling. The control points of geometric modeling deformations are constrained by an underlying articulated robotics skeleton. These deformations are tailored by the animator and act as a muscle layer to provide automatic squash and stretch behavior of the surface geometry. A hierarchy of composite deformations provides the animator with a multi-layered approach to defining both local and global transition of the character's shape. The muscle deformations determine the resulting geometric surface of the character. This approach provides independent representation of articulation from surface geometry, supports higher level motion control based on various computational models, as well as a consistent, uniform character representation which can be tuned and tweaked by the animator to meet very precise expressive qualities. A prototype system (Critter) currently under development demonstrates research results towards layered construction of deformable animated characters.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.9</cat_node>
				<descriptor>Manipulators</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553.10010554.10010555</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems->Robotics->Robotic components</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P121150</person_id>
				<author_profile_id><![CDATA[81100608797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Chadwick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio Supercomputer Graphics Project, The Advanced Computing Center for the Arts and Design, The Department of Computer and Information Science, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31078987</person_id>
				<author_profile_id><![CDATA[81100097114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Haumann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio Supercomputer Graphics Project, The Advanced Computing Center for the Arts and Design, The Department of Computer and Information Science, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P234807</person_id>
				<author_profile_id><![CDATA[81100414668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Parent]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio Supercomputer Graphics Project, The Advanced Computing Center for the Arts and Design, The Department of Computer and Information Science, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Thomas &amp; Johnston, "Disney Animation: The Illusion of Life", Abbeville Press, New York, '84.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37407</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Lasseter, John, "Principles of Traditional Animation Applied to 3D Computer Animation", Computer Graphics, Vol. 21, No. 4, '87.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gomez, Julian, "Twixt: A 3-D Animation System", Proceedings of Eurographics 84, '84.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sturman, David, "Interactive Keyframe Animation of 3-D Articulated Models", Proc. Graph. Interface, '84.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Van Bearle, "A Case Study of Flexible Figure Animation", 3- D Character Animation by Computer Course Notes, Siggraph '87.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378512</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Forsey &amp; Bartels, "Hierarchical B-Spline Refinement", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan, "Global and Local Deformations of Solid Primifives", Computer Graphics, Vol. 18, No. 3, July, '84.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Sederberg &amp; Parry, "Free Form Deformations of Solid Geometric Models", Computer Graphics, Vol. 20, No. 4, '86.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan, "Dynamic Constraints", State of the Art in Image Synthesis Course Notes, Siggraph, '86.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, Platt, Barr, and Fleischer, "Elastically Deformable Models", Computer Graphics, Vol. 21, No. 4, July, '87.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Haumann &amp; Parent, "The Behavioral Testbed: Obtaining Complex Behavior from Simple Rules", The Visual Computer, Special Issue on Mechanics, Control and Animation, Vol. 4, No. 6, Dec., '88.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378530</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hahn, James, "Realistic Animation of Rigid Bodies", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Moore and Wilhelms, "Collision Detection and Response for Computer Animation", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos and Fleischer, "Modeling inelastic Deformation: Viscoelasticity, Plasticity, Fracture", Computer Graphics, Vol. 22, No. 4, August'88.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617444</ref_obj_id>
				<ref_obj_pid>616002</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos and WitkJn, "Physically Based Models with Rigid and Deformable Components", IEEE CG&amp;A, November, '88.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378508</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Miller, Gavin, "The Motion Dynamics of Snakes and Worms", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Witkin, Fleischer, &amp; Burr, "Energy Constraints on parameterized Models", Computer Graphics, VoI. 21, No. 4, '87.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Barzel &amp; Burr, "A Modeling System Based on Dynamic Constraints", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Witkin and Kass "Spacetime Constraints", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Platt and Burr, "Constraint Methods for Flexible Objects", Computer Graphics, Vol. 22, No. 4, '88.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Girard &amp; Maciejewski, "Computational Modeling for Comuter Animation of Legged Figures"; Computer Graphics, Vol. 19, No. 3, '85.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319131</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Girard, Michael, "interactive Design of 3-D Computer Animated Legged Animal Motion", Chapel Hill Interactive Computer Graphics Interface Workshop, '86.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31464</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Badler, Manoochehri, Waiters, "Articulated Figure Positioning by Multiple Constraints", IEEE CG&amp;A, June, '87]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Armstrong &amp; Green, "The Dynamics of Articulated Rigid Bodies for purposes of Animation", Proc. Graphics Interface 85, '85.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, Jane, "Using Dynamic Analysis for Realistic Animation of Articulated Bodies", IEEE CG&amp;A, June, '87.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Isaacs and Cohen, "Controlling Dynamic Simulation with Kinematic Constraints, Behavioral Functions and Inverse Dynamics", Computer Graphics, Vol. 21, No. 4, July, '87.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>911638</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Zeltzer, David, "Representation and Control of Three dimensional Computer Animated Figures", Ph.D. Dissertation, The Ohio State University, '84.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Amkxaut, Susan, "Flock: A Behavioral Model for Computer Animation", M.A. Thesis, The Ohio State University, '89.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Reynolds, Craig, "Flocks, herds and Schools; A Distributed Behavioral Model", Computer Graphics, '87.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360357</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Burtnyk &amp; Wein, "Interactive Skeleton Techniques for Enhancing Motion Dynamics in Key Frame Animation", CACM, Vol. 19., No. 10, Oct. '76.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908350</ref_obj_id>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Parent, Richard, "A System for Generating 3-Dimensional Data for Computer Graphics", Ph.D. Dissertation, The Ohio State University, '77.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295897</ref_obj_id>
				<ref_obj_pid>2295756</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann &amp; Thalmann, "The Direction of Synthetic Actors in the Film Rendezvous a Montreal", IEEE CG&amp;A, Dec., '87.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Donkin, John, personal communication '88.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Denavit &amp; Hartenberg, "A Kinematic Notation for Lower- Pair Mechanisms Based on Matrices", J Appl Mech, Vol. 23, '55.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Whitney, "The Mathematics of Coordinated Control of Prosthetic Arms and Manipulators", Journal of Dynamic systems, Measurement, and Control, Dec., '72.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Klein, Huang, "Review of Pseudoinverse Control for Use with KinematicaUy Redundant Manipulators", IEEE Transactions on Systems, Man, and Cybernetics, Vol SMC-132, No. 3, March/April '83.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Chadwick and Parent, "Critter Construction: Developing Characters for Computer Animation', Proceedings Pixim, "88.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Steindler, Arthur, "Kinesiology of the Human Body", Charles C. Thomas Publisher, Springfield Illinois, '55.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Burstein, A., Frankel, V., "The Viscoelastic Properties of Some Biological Materials", Materials in Biomedical Engineering Vol. 146, Article 1, p. 158-165, Annals of the New York Academy of Sciences, January 1968.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Schneider D., et al.,"In Vitro Biaxial Stress-Strain Response of Human Skin", Arch Otolaryngol Vol 110, p. 329-333, May 1984]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Fung, Y. C., Biomechanics: Mechanical Properties of Living Tissues, Springer-Verlag, New York, 1981.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Lundin, R. Ruminations of a Model Maker IEEE Computer Graphics and Applications 7 (5):3-5 May 1987]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Waters, K. A Muscle Model for Animating Three-Dimensional Facial Expression Computer Graphics 21(4):17-24 (Siggraph Proceedings) July 1987]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Weil, J. The Synthesis of Cloth Objects Computer Graphics 20(4):49-54 (Siggraph Proceedings) August 1986]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Layered Construction for Deformable Animated Characters John E. Chadwick David R. Haumann Richard E. 
Parent The Ohio Supercomputer Graphics Project The Advanced Computing Center for the Arts and Design 
The Department of Computer and Information Science The Ohio State University Abstract A methodology 
is proposed for creating and animating com- puter generated characters which combines recent research 
ad- vances in robotics, physically based modeling and geometric modeling. The control points of geometric 
modeling deforma- tions are constrained by an underlying articulated robotics skele- ton. These deformations 
are tailored by the animator and act as a muscle layer to provide automatic squash and stretch behavior 
of the surface geometry. A hierarchy of composite deformations provides the animator with a multi-layered 
approach to defining both local and global transition of the character's shape. The muscle deformations 
determine the resulting geometric surface of the character. This approach provides independent representa- 
tion of articulation from surface geometry, supports higher level motion control based on various computational 
models, as well as a consistent, uniform character representation which can be tuned and tweaked by the 
animator to meet very precise expres- sive qualities. A prototype system (Critter) currently under de- 
velopment demonstrates research results towards layered con-struction of deformable animated characters. 
CR Categories and Subject Descriptors: 1.3.7 [Computer Graph- ics]: Graphics and Realism: Animation; 
1.3.5 [Computer Graph- ics]: Computational Geometry and Object Modeling. Additional Key Words and Phrases: 
free form deformations, robotic manipu- lators, kinematics, dynamics, character animation. 1. Introduction 
Rendering quality has improved to the point that images with very high levels of photo-realism and full 
of textural detail may readily be achieved. The development of special purpose graph- ics engines and 
massively parallel hardware suggest extremely complex rendering will soon be economically feasible for 
comput- er character animation production. The largest obstacle facing the realization of computer character 
animation is the motion specification itself. An anatomically precise geometric model must also move 
with an equal degree of realism or we do not ac- cept the illusion. Current commercial animation software 
literally Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
mimics the key frame methodology of traditional animation. Some successful animated films have been realized 
with these ani- mation systems; however, much of the burden of specifying the motion of the character 
form is placed on the animator. The cur- rent research efforts of the authors focus on providing a more 
ef- ficient and effective animation environment designed specifical- ly for constructing and animating 
characters. We are investigat- ing techniques to exploit the power of computational models so as to provide 
the animator with fine tuned local control as well as the ability to orchestrate complexity with higher 
level control. 1.1. Traditional Animation Animation in a general sense could be defined as "things changing 
over time". If we are to address the problem of charac- ter animation, then this definition is not adequate. 
The problem of character animation can best be described by the title of the animation bible: "The Illusion 
of Life", written by Thomas and Johnston [1]. The focus is not on the problem of completing a given motion 
task, but more importantly on how this motion task is performed by the character. All the elements involved 
in an animated character must cooperate in a very synchronized har- mony. This does not necessarily require 
realistic behavior, but behavior that is believable, full of an expressive quality which captures the 
personality of the character. The principles of ani- mation as developed in the Disney heydays are very 
colorfully presented in [1]. Lasseter provides solid working examples of how these principles have been 
applied to track based key frame animation [2]. The track based key frame animation approach [3][4] provides 
a general solution to the animation problem; how- ever, the ability to produce quality animation is principally 
the burden of the animator. Getting an animation to "jump into life" is the craft of the animator, yet 
to literally model the methodolo- gy of traditional drawn animation grossly underestimates the computational 
power potentially available by the medium. If we can formalize some of the concepts which underlie the 
principles of traditional animation such as Squash and Stretch, Exaggera- tion, Follow Through and Overlapping 
Action, then we may pro- vide the animator with more intuitively parameterized models while more effectively 
exploiting the available computational re- sources.  1.2. Geometric Deformations The animation of deformable 
characters requires geometric models of soft tissue which change over time. Lundin and Van Bearle and 
others have applied surface patch descriptions to model smooth character form [5]. Recently Forsey and 
Bartels describe a method for hierarchical B-spline refinement which al- &#38;#169;1989 ACM-0-89791-312-4/89/007/0243 
$00.75 S,GGRAPH '89, Boston, 31 July-4 August, 1989 lows for multiple levels of control ranging from 
broad high level surface description to low level fine tuning control in regions of intricate detail 
[6]. Barr introduced geometric modeling defor- mations which provide abstract data manipulation operators 
cre- ating a useful sculpting metaphor [7]. Sederberg and Parry intro- duced the concept of Free Form 
Deformations (FFDs) based on hyperpatch solids [8]. FFDs provide the flexibility of general free form 
spline control coupled with the sculptural flexibility of deformations. For purposes of animation, a 
key advantage to ab- stracting deformation control from that of the actual surface de- scription is that 
the transition of form is no longer dependent on the specifics of the surface itself. FFDs provide the 
foundation for deformations implemented by the authors. 1.3. Simulation Models A new area of computer 
graphics research focuses on the simu- lation of the physical properties of object models. The motion 
and shape deformation of the objects can be simulated through applied physics [9]. Barr, Terzopoulos, 
Platt, Fleischer, and Haumann have applied discrete macro molecular abstractions of the substance properties 
of the object to model flexible elastic behavior [10][11]. The discrete molecular components of the ob- 
ject can be viewed as point masses interconnected by springs with stiffness and damping attributes based 
upon the physical properties of the object. Hahn, and Moore and Wilhelms have coupled rigid body dynamics 
with collision detection and reac- tive forces to provide realistic animation of objects tumbling and 
colliding through space [12][13]. Terzopoulos and Fleis- cher have extended their model to include rigid 
and flexible com- ponents as well as inelastic behavior [14][15]. The finite ele- ment lattice used by 
Terzopoulos et al for flexible models is anal- ogous to the hyperpatch control lattice [10]. Here the 
spline concept has been extended to include physical properties from whence splines originally sprung 
:) . Physically based models have proven extremely successful at animating "inanimate" or "not consciously 
moving" objects. Miller has provided striking results based on a physical model for simulating the self 
motivat- ed motion dynamics of snakes and worms [16]. The field of bit- mechanics has been concerned 
for some time with modeling the physical properties of body tissues as it relates to the areas of artificial 
implants [39] and the healing of surgical wounds [40], to name just a few. The main difficulties in modeling 
the dynam- ics of soft body parts are the structural inhomogineity and the inelastic, time-dependent 
behaviors of the regions in-volved. For example, skin, fatty tissue, muscle, and skeleton all exhibit 
different physical properties complicated by the pres-ence of migratory fluids (blood and lymph) as well 
as actively contracting muscles. Thus accurate physical simulations of these combined structures requires 
complex, viscoelastic, anisotropic models such as those presented by Fung [41]. All these simula- tion 
methods offer great potential for character animation; how- ever, harnessing this computational power 
remains largely a problem of animator control. Barr, Barzel, Kass, Platt and Wit- kin have addressed 
the control issue by providing user speci-fied constraints, which are then resolved through coupling 
physi- cal models with constraint satisfaction methods based on vari- ous optimization criteria [17][18][19][20]. 
The ability to control articulated figures is a long standing problem addressed by the robotics community. 
Robotics re-search has been applied to the problems of computer animation. Girard and Maciejewski introduced 
inverse kinematics to the figure animation community by providing computational models for legged locomotion 
[21][22]. Badler et al. have also em-ployed inverse kinematics towards figure animation, as well as a 
system for specifying figure positioning based on constraint satisfaction [23]. The dynamic simulation 
of articulated hierar- chies has also been applied to computer animation by Armstrong and Green, and 
Wilhelms [24][25]. With dynamics we achieve greater physical realism, but the ability to control the 
desired ap- plied forces to meet specific motion requirements remains an open problem. Animator applied 
forces such as joint torques seem far less intuitive than direct kinematic specification of joint angles. 
Isaacs and Cohen applied inverse dynamics, also popular within the robotics community, as a mechanism 
for inte- grating kinematic and dynamic conlrol [26]. Often in'character animation, however the dynamics 
are secondary to conveying the emotions of the character. Due to the complexity of articulated figure 
motion, a level of control which is higher than the manual specification of every in- dividual moving 
parameter is needed. Zeltzer addresses the problem of articulated figure control by using a higher level 
"director" control approach [27]. Animator specified goal di- rected behavior is resolved through decoupling 
the goals into task level routines provided by a robust motion library. For the animator, behavioral 
models are a naturally intuitive means of high level control. In addition behavioral models may algorithmi- 
cally suggest to the viewer conscious decision making process-es on the part of the animated characters. 
Amkraut and Reynolds have provided models for bird flocking behavior [28][29]. Flocking behavior provides 
a good example of higher level con- trol orchestrating complexity. From the character animation per- 
spective director level control is often desirable but not suffi- cient, because it does not allow the 
animator precise control over the fine details of motion. What is needed is an intermediate "actor" level 
of control which allows the animator to control, per- haps even act out the gestural details of a character's 
movement. The layered approach to characters presented in this paper is de- signed to support motion 
generated by simulation models while also providing precise control of the transition of the character's 
form.  2. Layered Construction In his 87 Siggraph paper [2] Lasseter stresses that the advan- tage 
offered by computer animation is one of working the anima- tion in layers. The ability to isolate parameters 
is essential to fine tuning motion via local control. The ability to additively build an animation in 
layers provides an effective means for cre- ating complex motion. We would like to extend this notion 
to motion specified through simulation by building the character in layers and specifying the relationship 
between the layers through parametric constraints. A layer can be defined as a conceptual simulation 
model which maps higher level parametric input into lower level outputs. The animator specifies various 
constraint re- lationships between the layers and can control the global motion from a high level. The 
animator defines the layers of the character by specifying parameters and conditions of the constraints. 
This describes how the character moves and not the specifics of the explicit motion. By providing layers 
of the character related through parametric constraints, low level motion can be automat- ed through 
higher level control. This layered philosophy and the notion that the computer be- comes manager of the 
interacting relationships of the various parametric layers is central to the design of the Critter system 
de- veloped by the authors. The ability to defme attributes as con- straints provides a methodology where 
more emphasis is placed on constructing the character so that less emphasis is needed in actually scripting 
an animation. Parametric constraints provide the animator with control of gestural detail, while providing 
con- sistent, automatic motion control based on layered constraints. This layering philosophy has been 
adopted both in construction and animation for computer generated characters. Previous research efforts 
have also attempted to model ani- mated characters through a layered construction approach. Burt- nik 
and Wein presented a 2-D approach to bending a digitized drawing about an underlying articulated figure 
using constrained deformations [30]. Parent presented a 3-D approach to bending geometric surfaces about 
articulated forms for purposes of char- acter animation [31]. Tony De Peltrie was an exciting example 
where a digitized character geometry was applied to an underly- ing articulated skeleton. The Thalmanns 
have created a human fac- tory system designed to animate synthetic actors [32]. Dick Lundin and Susan 
VanBearle provided animated dancers by algo- rithmically weaving a surface patch skin on top of an underlying 
articulated skeleton as well as integrating dynamics to model free fitting clothing [5]. John Donkin's 
Dinosaur provides anoth- er example where a digitized surface geometry skin is fit to an underlying articulated 
skeleton [33]. These methods were de-signed to meet specific film production demands. They primari- ly 
focus on a three layered approach (motion specification, artic- ulated skeleton, geometric skin) and 
are tailored to special pur- pose models. The current approach of ~e authors provides a more general 
solutiori'by using a four: layered construction ap- proach. The approach described in this paper not 
only fits a geo- metric skin to an articulated skeleton, but also captures the fluid squash and stretch 
behavior of the surface geometry by provid- ing volumetric muscle bulging, dynamic fatty tissue response, 
and creasing at the joint. The Critter system is designed to pro- vide a flexible interface to the animator 
for constructing and ani- mating deformable characters. The authors' philosophy supports a four layered 
approach from high to low levels as follows: 1. Motion specification (referred to as the behavior layer 
in the critter system)  2. Motion Foundation, articulated armature (critter skeleton layer )  3. Shape 
transition, squash and stretch (critter muscle and fatty tissue layer)  4. Surface description, surface 
appearance and geometry (critter skin, clothing and fur layer)  Traditional Animation Character Design 
Figure 1. The layered construction approach adopted by the Critter system is similar to the construction 
methods described for tra- ditional drawn characters (Figure 1). The stick figure drawing is analogous 
to the robotics armature or skeleton. The drawn blobby volumetric shapes used to flesh out the character 
form are analogous to muscle and fatty tissue and help provide consistent fluid squash and stretch transitions 
in shape. The detailed charac- ter sketch is representational of the visible surface geometric "skin". 
The key advantage to the layered computer methodolo- gy is that once the layered character is constructed, 
only the un- derlying skeleton need be scripted for an animation; consistent yet expressive shape dynamics 
are generated automatically. Var- ious character layers can be used as templates for other similar character 
forms, thereby providing a robust library of extend- able character parts. The skeleton (second) layer 
is an underlying articulated hierar- chy which provides the foundation for controlling the motion of 
the character. The muscle layer is then added on top of and at- tached to the skeleton hierarchy. The 
foundation for the muscles are represented by freeform deformations. The control points of the deformations 
are constrained by the positioning (joint an- gles) and forces (joint torques) applied to and by the 
underlying skeleton. These deformations then act to glue and deform the ac- tual geometric skin to the 
underlying skeleton. The skirl layer represents the actual visible surface geometry to be rendered. The 
current implementation supports polygonal skin data based on the existing modeling and rendering environment 
at ACCAD. The application of FFDs as a foundation for muscle and fatty tis- sue deformations provides 
for general extension to potential sur- face patch, algebraic, or volumetric skin. Each skin object is 
at- tached relative to a link in the skeletal hierarchy. This attachment defines the local coordinate 
space of the skin component. The skin object may then be attached to any number of deformations. Rigid 
"skin" objects may be connected directly to the skeleton with zero connecting muscles. This allows the 
system graceful degradation to a basic object hierarchy. Figure 2 provides an example where no muscle 
layer was provided. A skeleton data- base (Critter skin) of several bones was attached to a simplified 
articulated skeleton to provide a reasonable number of controlla- ble joints. several bones (critter 
skin) are mapped to a simplified articulated critter skeleton. rnnlllilrm,. Ii [1 illl layelrt ,~ slullotel 
active Irttter: george critter klorlrcky : I )lIlBkt]t.lJtl i pIIvCJ Ftght-leI ~ ..... ~ ...... ~ ....... 
 G z, ft-z,, D ..... O ...... ~1 ....... Q ,..t O .... ~1 .... Q x,t-,~ O ...... O ....... ~I ....... 
 Panel selection of various layers &#38; parts Visual hierarchical display George Skeleton "Skin" Figure 
2. The behavior (first) layer which represents the actual motion specification need only be applied-to 
the skeleton parameters. A general purpose attribute based behavioral foundation was pro-  '89, Boston, 
31 July-4 August, 1989 vided so that the animation system could be easily extended to include various 
computational motion models. The foundation for behavior provides a pose vector which contains the charac- 
ter position, orientation and joint angles for each frame. Addi-tional structures are provided to house 
velocities, accelerations, joint torques, and user specified gesture attributes. To date, the interactive 
and animation behavior models within the Critter sys- tem are based on forward and inverse kinematics 
with additional procedural modeling capabilities. The muscle and skin layers can be automatically generated 
based on a given skeletal state.  3. Skeleton Layer A description is provided of the skeleton layer 
to clarify the interaction of the articulation hierarchy to the deformations which are built on top of 
and constrained by the skeleton. The skeleton acts as the character foundation, providing the articula- 
tion hierarchy from which additional layers are built and con-strained. The skeleton data includes: 1. 
Tree structured hierarchy of robotic manipulators 2. Robotic joint-link parameters (Denevit &#38; Hartenberg) 
 3. Joint angle constraints and physical auributes (max, min, zero, stiffness, mass properties)   The 
basic joint hierarchy has been extended to a hierarchy of manipulators. A manipulator is basically a 
sequential chain of in- terconnected joints and links. Each manipulator may contain any number of child 
manipulator parts. A child manipulator may be connected to any joint within its parent manipulator chain 
so that none of the generality of a basic joint hierarchy is lost. The ma-nipulator extension lends itself 
readily to robotic kinematic and dynamic motion models, in particular inverse kinematics. Denevit &#38; 
Hartenberg parameters (figure 3) are implemented as the basic joint construct, where: Joint i = [ a i, 
Ix i, d i, 0 i ] a i and ~i represent the link parameters where {]t. i is the twist angle between links 
and a i represents the link length. 0 i and d i represent the joint parameters where 0 i is the joint 
angle and d i the offset length along the axis of joint rotation. A more detailed description of the 
D &#38; H parameters can be found in the robotics literature [34][35][36]. These joint primitives provide 
only sin- Denevit and Hartenberg Parameters Joint i+ 1 Joint i c~i  1' t ",-''z gle degree of freedom 
joint motion. If 0 i is varied over time as a parameter then the joint is rotational. If d i is varied 
over time as a parameter then the joint is translational. Primitive robotic joints can be combined at 
common origin (a i = d i = 0) with per- pendicular joint axis (iX i = 90 ) to create universal (2-rotary 
ax- is) and ball (3-rotary axis) joints. Minimum and maximum joint angle constraints provide the ani- 
mator with the capability to restrict the range of joint motion. The zero angle and stiffness at the 
joint provide the animator with control over the relative bending at each joint within a ma- nipulator 
when automated by inverse kinematic control. Mass properties: mass, center of mass, and inertia tensor 
(distribution of mass) parameters are also provided; however, current behav- ior models and interactive 
figure control do not as yet exploit the robotic dynamic models for articulated figures. A more de-tailed 
description of the Critter skeleton may be found in [37]. 4. Muscle and Fatty Tissue Layer The constrained 
deformation layer is central to Critter con- struction. The deformation acts as the connecting relationship 
for mapping the geometric skin data to the underlying articulated skeleton foundation, while capturing 
the flexible fluid quality of squash and stretch behavior. To automate the squash and stretch behavior, 
the animator specifies muscle and fatty tissue at-tributes by defining constraint relationships with 
the underlying skeletal parameter state. The foundation for the muscle and fat deformations is based 
on Free Form Deformations (FFDs) [8]. Composite tricubic bezier based hyperpatches (or parametric solids) 
are used as the basis for the FFD as muscle deformation abstractions. The current implementation of muscle 
and fatty tis- sue structures represents each muscle primitive as a pair of ad- joining FFDs (Figure 
4). In an attempt to provide muscle ab- stractions which deform the skin surface a prototype set of func- 
tional deformation operators are provided. Muscles are represented by a pair of FFDs. This provides 7 
planes of con- trol points orthogonal to the adjoining joint link axis: four planes for each FFD (cubic 
bezier) with one plane shared as the adjoin- ing connection between deformations. The two control planes 
at either end of the muscle deformation (adjoining planes) function principally to preserve continuity 
across connected muscles. Continuity can also be preserved between a muscle and a non-ex- isting (null 
muscle) by assuming the null muscle remains undo- formed. The remaining three planes (mid planes) function 
to mod- el the abstract muscle behavior resulting from kinematic or dy- Abstract Muscle Deformation: 
pair of adjoining FFDs leading deform trailing deform I I 1 II I .... I.~; ~[ H-.// / y X link axis 
/ LAi ~ i~l ~ .. I/~/1 i/ VIII 1; 0 ! 2 3 4 5 6 y y mid planes I adjoining planes Figure 3. Figure 
4. namic attributes of the skeletal state. Each operator or muscle type provides a set of parameters 
for defining the relationship of the control points of the FFDs with the kinematic and dynam-ic skeletal 
parameters. Free form deformations can best be described as a cubical vol- ume in which geometric objects 
are submersed. If we think of this cube as a chunk of jello which can be bent, shaped, or contort- ed, 
then the objects within the volume are distorted accordingly. The basis of the FFD is a trivariate hyperpatch 
or parametric sol- id. A set of control points form a three dimensional lattice with- in the cube. These 
control points are used by the blending func- tions to map parametric weights to positions in space. 
For each vertex comprising the objects embedded within the cube, the three parametric weights can be 
determined, which when substi- tuted into the blending functions for the undeformed cube, pro- duce the 
position of that vertex in the undeformed object. By ma- nipulating the control points which form the 
lattice, the cube sol- id is deformed. The resulting vertex positions of the deformed object are computed 
by using the deformed lattice control points in the hyperpatch blending functions and then sampling at 
the parametric weights associated with the original undeformed ver-tices. Current deformations are based 
on kinematic, dynamic, or sculpted constraints. To provide automatic squash and stretch behavior of the 
character, muscle deformations are modeled to provide bulging and bending of the character geometry based 
on the kinematic state of the articulated skeleton. To increase the expressiveness of the character the 
dynamics of the passively de- formable body parts such as flesh and underlying soft tissue are modeled 
to provide automatic follow through and overlapping action. Exaggeration can be produced by adding sculpted 
defor- mations which give the animator explicit control over the shape transition of the character form. 
4.1. Kinematic Deformation By providing muscle deformations which are constrained by the kinematic skeletal 
state, automatic, consistent squash and stretch behavior can be achieved. While in reality our muscles 
control the skeletal joint motion, from an animation perspective we inversely would like the skeletal 
joint motion to automatical- ly create the resulting muscle flexion required to meet the speci- fied 
motion. The kinesiology literature suggests the following mechanical properties of joint and muscle action 
[3 8]: Elasticity-When tension is applied to a muscle, a passive elon- gation results accompanied by 
a reduction of the cross sectional area of the muscle. A weight attached to a relaxed muscle causes an 
elongation (E) which is directly proportional to the original muscle length (L) and to the pulling force 
(F) and a constant (k) which varies for each body, and inversely proportional tO the cross sectional 
area (A). F*L*k E= A Contractility-is the ability of the muscle to shorten by ner-vous stimuli. The contraction 
of the muscle is an active process, as opposed to the passive elastic elongation. The muscle ten-sion 
represents the force, while the change in length during con- traction represents the distance covered 
by the application of this force, whose product is the visible work accomplished. A constant relationship 
exists between the natural length of the mus- cle, the variable length of the contracted muscle, and 
the degree of rotation at the joint. For each unit of shortening (S) there is a constant rotation angle 
(0). S=0*k The basic property of contraction can be applied to algorith- mic models such that the kinematic 
joint angles act as controlling parameters for abstract muscle behavior. Flexor and extensor muscle deformation 
models function to provide the visible result of muscle contraction. The algorithm for resolving the 
resulting control points of a flexor - extensor for each frame follows: 1. The overall shortening of 
the muscle = joint angle * dis- placement ratio. This shortening is propagated across each control plane 
of the muscle by the square of the ra- tio of length up to control plane / total muscle length. 2. The 
implied shortening is countered by scaling up and out along the local y &#38; z coordinates. If all muscle 
bound- aries are active, then this scaling will be distributed equally in all directions for each of 
the 3 midplanes (see Figure 4). If one boundary side is not active, then the scale factored is doubled 
along the active boundary op- posing the not active side. Fixed boundaries can be used to shape the deformation, 
as in the biceps example (Figure 5.), or to maintain null continuity, in particular, ar-eas in which 
the deformation intersects a skin component object. The radius ratio determines the relative scale fac- 
tors of the two exterior mid planes (2 &#38; 4). The center mid plane (3) is resolved by line plane intersection 
to maintain continuity across the contracted surface. 3. The adjoining planes of the flexor -extensor 
are main-tained to assure continuity with actively connected mus-cles, or remain undeformed with the 
exception of short- ening along the link axis (x).  In addition to kinematic muscle contraction, tendon 
deforma- tions model the bending at the joint. This is designed to cover very short regions of the character 
where a single geometric skin crosses over a joint, covering part of two or more skeletal links to account 
for underlying bone tissue. The control points of the tendon FFDs are resolved for each flame based on 
the following algorithm: Determine the bisection angle of the joint. If the angle ex- ceeds the threshold 
angle, then bisect the threshold an-gle; else bisect the joint angle. For a hinge joint bisec- tion angle 
= angle / 2. For joints with more than one de- gree of freedom we need to know the resulting axis of 
rotation. Quaternions provide a convenient means of re-solving the single axis, and angle about the axis 
result- ing from multiple rotations about several axes. Using this axis &#38; and angle we can now resolve 
the bisection angle. 2. Rotate mid planes by bisection angle about their local z axes. We rotate planes 
2 &#38; 3 by the bisection angle, and plane 4 by -bisection angle. (When the trailing de- form is rotated 
about the joint by the joint angle plane 4 will have proper bisection alignment) 3. Project mid planes 
2 &#38; 4 onto boundary cube of deform. Scale control points to avoid intersections with interior region 
of deform. (This scaling is motivated by underly- ing bone structure forcing the skin and muscle to stretch, 
not penetrate deform interior) 4. Slide planes 0 &#38; 1 away from plane 2; slide planes 5 &#38; 6 away 
from plane 4. Find closest point to adjoining planes. Use this point as reference to maintain distance 
from adjoining plane to midplane. 5. Rotate trailing deform by joint angle at joint. 6. Use line plane 
intersection for line segments connecting each control point pair from midplanes 2 &#38; 4, intersected 
with bisection plane or midplane 3 (plane at joint). Modi-fy control points of joint plane 3 at intersection 
to main- tain O1 continuity.  '89, Boston, 31 July-4 August, 1989 7. If threshold is exceeded, rotate 
joint plane by additional angle (bisection of (joint angle - threshold angle)) 8. Use line plane intersection 
to maintain continuity for out- side control points only (crease now forms for interior points) 9. Working 
out from ,midpianes (2 &#38; 4) towards adjoining planes (1, 2, 5, 6) check for intersection with bisection 
plane at joint (3). If intersection occurs within bounded plane (0 < t < 1 for parametric line segments) 
then set con- trol points which cross bisection plane 3 to intersection point. Use parametric weight 
t to scale control plane out to maintain volume from squash.  skeleton: shoulder, elbow, forearm, wrist 
 Arm Example Kinematic Muscle Deformation ball -hinge -hinge -universal muscle: bleep, elbow, forearm 
geometric skin flexor -tendon -flexor smooth bend at elbow smooth continuity across~ adjoining muscles 
 J crease forms at elbow Figure 5. 4.2. Dynamic Deformation From the point of view of computer generated 
character am-mation, we wish to capture the dynamic properties of soft body structures, but without incurring 
the costs of a complete physical model. Of the physical properties that the simulation must han- dle, 
one of the most desirable effects is that of large deforma- tions (in homage to Tex Avery!). In addition, 
viscous effects must be modeled in order to realistically simulate the damped oscillations of soft parts 
which result from the charac- ter's motion. Finally, the model must allow for spatial varia- tions of 
the physical properties so as to model the different structures within the character. Fortunately, for 
these purposes, a complete physical model is unnecessary because, given the space-time scales of interest, 
many of the effects due to the variation in structures are visually insignificant, or can be greatly 
simplified. The model of deformable body parts pre-sented here was developed specifically to capture 
these nonlin-ear, viscoelastic and anisotropic properties, yet includes spa- tial simplifications which 
help reduce the computational cost. Our technique maps the control points of the FFD to point mass- es 
in a similarly shaped force lattice. Dynamic simulation is per- formed on the mass particles and the 
resulting motion is mapped back onto the FFD control points thus determining the resulting object deformations. 
The physical model we employ is a three-dimensional ex-tension to one developed using the behavioral 
test-bed de-scribed in [11]. The model consists of a three-dimensional grid of point mass elements (3 
degrees of freedom) connected by viscously damped Hookean springs. The spatial simplifica- tions of the 
dynamics models results from the one to one map-ping maintained between the point masses and the control 
points of the FFDs. To capture shear strain behavior, spring elements are connected diagonally between 
mass elements on adjacent planes. Thus, if one were to isolate one "cube" from the grid, it would appear 
as having one point mass at each of the eight cor- ners, with each mass being directly connected by spring 
ele- ments to the remaining seven (see Figure 6). Intuitively, the springs aligned with the major axes 
serve to maintain the linear dimensions of the body, while the cross springs help main-tain the angular 
relationships between the grid planes. The dynamics are simulated by marching along at discrete sub-frame 
time steps. At each step, the spring forces are calcu- lated and applied to the point masses, which respond 
by ac- celerating in the direction of the net force applied. Using a 2nd order runge-kutta scheme with 
adaptive stepsize, the equa- tions of motion are integrated to determine the subsequent posi- tion and 
velocity of each point mass. In order to transfer the motion of the animated character to the physical 
model, we al-low certain chosen mass points to be rigidly fixed to the char- acter skeleton, while the 
remaining mass points are free to dy-namically respond. In effect, these fixed points represent the rigid 
structure of the internal skeleton of the character. As the character moves, changes in the positions 
of the attached points result in spring displacements which force the remaining mass points into motion. 
Dynamics is applied as a post processing step after the articu- lated skeletal motion has been completed. 
The steps are as fol-lows: The entire motion of the character as specified through high level control 
is precomputed. 2. Once computed, the position information for each control point for each FFD at each 
frame in the animation is known. Certain points of each FFD are designated as non dynamic (fixed to move 
along these pre-computed "paths"). 3. The corresponding physical models are constructed. The motion 
paths of the non-dynamic control points are used as scripts to drive the corresponding point masses within 
the dynamics model. The remaining points are free to move as a result of forces generated with the force 
lattice. 4. Once the dynamic simulation is completed the positions of the free point masses are mapped 
back onto the posi- tions of the corresponding "dynamic" control points of the FFD. This determines the 
dynamically deformed shapes of the objects affected by the FFD. 5. Continuity is maintained across internal 
regions of the shared midplane, and with adjoining or null deformations.  The selection of the physical 
constants is performed upon the basis of the visual appeal of the resulting motion. The us- er controls 
the spring constants, damping coefficients, and Hi i the mass properties of each element individually 
or of the mod- el as a whole. We do not attempt to make these parame-ters correspond to actual measured 
values, relying instead up- on the animators tastes, which can fall anywhere within the re- al-surreal 
spectrum. Cheeks Example Dynamic Fatty Tissue spnng etement mass element J Dynamic Cube Abstraction J 
Dynamic Fatty Tissue Lattice Deformation Mapped to Geometric Skin Figure 6.  4.3. Sculpted Deformation 
A fundamental design objective of the authors was to provide a general system for constructing and animating 
computer gener- ated characters. Sculpted deformations provide the most gener- al, but also the most 
labor intensive deformation primitive sup- ported by the Critter system. Sculpted deformations are princi- 
pally key framed deformations. The animator sculpts the deformations by moving individual control points 
of the 3-D lat- tice defining the FFDs, or through translation, scale or rotation of control point planes 
or selected control point groupings of the FFDs. These key deformations are then bound to a key at-tribute. 
If the application of deformation is to imply muscle reac- tion, then the key attribute may be constrained 
by the controlling skeletal joint angle. Several key deformations may be stored as extremes relative 
to various joint angle positions. The resulting deformation for any given skeletal state is then determined 
by applying cubic spline interpolation for each corresponding con- trol point of the FFDs. The parametric 
weight of the interpola- tion is based on the relation of the current joint angle to the sur- rounding 
key angle attributes associated with each key deforma- tion. Sculpted muscles can be used if other muscle 
models do not adequately provide the shape transition desired, or to add deft- nition to other muscle 
models. Sculpted deformations may also be used to provide deforma- tions representational of emotional 
contortions. Gestural quail- ties may be sculpted to provide visual exaggeration. Classic cartoon examples 
of gestural deformation are pride ("V") and sorrow (slumped). The ability to drive a sculpted deformation 
by an attribute exterior to the skeletal parameters frees the anima- tor to control the parametric blending 
of various key deforma- tions by any behavior parameter. This removes the automatic na- ture of the deformation, 
requiring that animator to now control the level of deformation from the scripted behavior. This was 
added as an exception to the rule of only specifying skeletal at- tributes via behavior for added flexibility 
and generality. For example, breathing can effectively be modeled by oscillating the driving parameter 
of a sculpted deformation algorithmically.  4.4. Continuity Maintaining smooth continuity is integral 
to the function of muscle deformations. The ability to build complex musculature in layers depends readily 
on the ability of these composite mus- cle deformations to maintain smooth C1 continuity where de- sired. 
For bezier curves this requires a colinear relationship of the three corresponding control points from 
each midplane. Ini-tial implementations discussed in [37] provided this colinear condition by placing 
the central midplane control point at the line of intersection of the neighboring midplane control points 
based on a line - plane intersection calculation. This worked. However it was extremely limited in controlling 
the shape of the bend, and provided little capability for the animator to control the implied underlying 
bone tissue. Least square line fitting was implement- ed to provide the model for securing continuity 
across adjoining deformations. Rather than an all or nothing line fit, a best fit strategy is employed 
based on the chi-square merit function. Animator specified weights for each control point can be used 
to sculpt the resulting continuous boundary regions. Least square line fitting: p(u) = p(u; a,b) = a 
+ bu Chi-square merit function: N Z2 (a,b) = E ( (pi -a -bui) / ~i )2 i =1 oi represents the uncertainty 
associated with each Pi assum- ing the ui's are known. We want to minimize the merit function to determine 
a and b, by setting the partial derivatives with re- spect to a and b to zero: N ~Z2/ra = -2 ( (pi -a 
-bui) ] eli 2) = 0 i=1 N ~2]~b = -2 ( (ui (pi -a -bui)) / ~i2) = 0 i=1 We can now solve for the best 
fit line given two equations and two unknowns (a &#38; b). Let w i = 1 / Ci2 were w i repre- sents the 
respective relative weight of contribution for the asso- ciated Pi" We now consider these weights as 
an intuitive means of controlling the shape of the resolved continuous curve as op- posed to a measure 
of uncertainty. The animator provides weights for each control point of the deformations to sculpt the 
  :L~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 7. Acknowledgments Don Stredney designed the initial 
prototype critters, and provid- ed valuable background assistance in anatomy and kinesiology, as well 
as providing the hand drawn illustrations for this paper. Michael Girard provided valuable insight into 
related robotics issues. John Donkin provided the chalk -critter interface, with system support from 
John Fujii, who was invaluable in getting the illustrations for this document together. The rendering 
soft- ware was developed by Scott Dyer. The illustrations and video examples were produced using ape 
utilities provided by the Ohio Supereomputer Graphics Group. And a special thanks to C.G. for the pasteups 
and everything. Thanks to Chuck Csuri and Tom Linehan for the environment and opportunity at AC- CAD, 
and to the Ohio Supercomputer Center. This work was supported in part by a grant from Cray Research. 
8. References [1.] Thomas &#38; Johnston, "Disney Animation: The Illusion of Life", Abbeville Press, 
New York, '84. [2.] Lasseter, John, "Principles of Traditional Animation Ap- plied to 3D Computer Animation", 
Computer Graphics, Vol. 21, No. 4, '87. [3.] Gomez, Julian, "Twixt: A 3-D Animation System", Proceed- 
ings of Eurographics 84, '84. [4.] Sturman, David, "Interactive Keyframe Animation of 3-D Ar- ticulated 
Models", Proc. Graph. Interface, '84. [5.] Van Bearle, "A Case Study of Flexible Figure Animation", 3- 
D Character Animation by Computer Course Notes, Siggraph '87. [6.] Forsey &#38; Barrels, "Hierarchical 
B-Spline Refinement", Com- puter Graphics, Vol. 22, No. 4, '88. [7.] Barr, Alan, "Global and Local Deformations 
of Solid Primi- fives", Computer Graphics, Vol. 18, No. 3, July, '84. [8.] Sederberg &#38; Parry, "Free 
Form Deformations of Solid Geo- metric Models", Computer Graphics, Vol. 20, No. 4, '86. [9.] Barr, Alan, 
"Dynamic Constraints", State of the Art in Image Synthesis Course Notes, Siggraph, '86. [I0.] Terzopoulos, 
Platt, Barr, and Fleischer, "Elastically De- formable Models", Computer Graphics, Vol. 21, No. 4, July, 
'87. [11.] Haumann &#38; Parent, "The Behavioral Testbed: Obtaining Complex Behavior from Simple Rules", 
The Visual Computer, Special Issue on Mechanics, Control and Animation, Vol. 4, No. 6, Dec., '88. [12.] 
Hahn, James, "Realistic Animation of Rigid Bodies", Com- puter Graphics, Vol. 22, No. 4, '88. [13.] Moore 
and Wilhelms, "Collision Detection and Response for Computer Animation", Computer Graphics, Vol. 22, 
No. 4, '88. [14.] Terzopoulos and Fleischer, "Modeling Inelastic Deforma- tion: Viscoelasticity, Plasticity, 
Fracture", Computer Graphics, Vol. 22, No. 4, August'88. [15.] Terzopoulos and Witkin, "Physically Based 
Models with Rigid and Deformable Components", IEEE CG&#38;A, November, '88. [16.] Miller, Gavin, "The 
Motion Dynamics of Snakes and Worms", Computer Graphics, Vol. 22, No. 4, '88. [17.] Witkin, Fleischer, 
&#38; Burr, "Energy Constraints on parame- terized Models", Computer Graphics, VoI. 21, No. 4, '87. [18.] 
Barzel &#38; Burr, "A Modeling System Based on Dynamic Constraints", Computer Graphics, Vol. 22, No. 
4, '88. [19.] Witkin and Kass "Spacetime Constraints", Computer Graphics, Vol. 22, No. 4, '88. [20.] 
Platt and Burr, "Constraint Methods for Flexible Ob- jects", Computer Graphics, Vol. 22, No. 4, '88. 
[21.] Girard &#38; Maciejewski, "Computational Modeling for Computer Animation of Legged Figures", Computer 
Graphics, Vol. 19, No. 3, '85. [22.] Girard, Michael, "Interactive Design of 3-D Computer Ani- mated 
Legged Animal Motion", Chapel Hill Interactive Computer Graphics Interface Workshop, '86. [23.] Badler, 
Manoochehri, Waiters, "Articulated Figure Posi- tioning by Multiple Constraints", IEEE CG&#38;A, June, 
'87 [24.] Armstrong &#38; Green, "The Dynamics of Articulated Rigid Bodies for purposes of Animation", 
Proc. Graphics Interface 85, '85. [25.] Wilhelms, Jane, "Using Dynamic Analysis for Realistic An- imation 
of Articulated Bodies", IEEE CG&#38;A, June, '87. [26.] Isaacs and Cohen, "Controlling Dynamic Simulation 
with Kinematic Constraints, Behavioral Functions and Inverse Dynam- ics", Computer Graphics, Vol. 21, 
No. 4, July, '87. [27.] Zeltzer, David, "Representation and Control of Three di- mensional Computer Animated 
Figures", Ph.D.. Dissertation, The Ohio State University, '84. [28.] Amkraut, Susan, "Flock: A Behavioral 
Model for Computer Animation", M.A. Thesis, The Ohio State University, '89. [29.] Reynolds, Craig, "Flocks, 
herds and Schools; A Distribut- ed Behavioral Model", Computer Graphics, '87. [30.] Burtnyk &#38; Wein, 
"Interactive Skeleton Techniques for En- hancing Motion Dynamics in Key Frame Animation", CACM, Vol. 
19., No. 10, Oct. '76. [31.] Parent, Richard, "A System for Generating 3-Dimensional Data for Computer 
Graphics", Ph.D. Dissertation, The Ohio State University, '77. [32.] Magnenat-Thalmann &#38; Thalmann, 
"The Direction of Syn- thetic Actors in the Film Rendezvous a Montreal", IEEE CG&#38;A, Dec., '87. [33.] 
Donkin, John, personal communication '88. [34.] Denavit &#38; Hartenberg, "A Kinematic Notation for Lower- 
Pair Mechanisms Based on Matrices", J Appl Mech, Vol. 23, '55. [35.] Whitney, "The Mathematics of Coordinated 
Control of Prosthetic Arms and Manipulators", Journal of Dynamic sys-tems, Measurement, and Control, 
Dec., '72. [36.] Klein, Huang, "Review of Pseudoinverse Control for Use with Kinematically Redundant 
Manipulators", IEEE Transac-tions on Systems, Man, and Cybernetics, Vol SMC-132, No. 3, March/April '83. 
[37.] Chadwick and Parent, "Critter Construction: .Developing Characters for Computer Animation', Proceedings 
Pixim, "88. [38.] Steindler, Arthur, "Kinesiology of the Human Body", Charles C. Thomas Publisher, Springfield 
Illinois, '55. [39.] Burstein, A., Frankel, V., "The Viscoelastic Properties of Some Biological Materials", 
Materials in Biomedical Engineer- ing Vol. 146, Article 1, p. 158-165, Annals of the New York Academy 
of Sciences, January 1968. [40.] Schneider D., et al.,"In Vitro Biaxial Stress-Strain Re-sponse of Human 
Skin", Arch Otolaryngol Vol 110, p. 329-333, May 1984 [41.] Fung, Y. C., Biomechanics: Mechanical Properties 
of Liv- ing Tissues, Springer-Verlag, New York, 1981. [42.] Lundin, R. Ruminations of a Model Maker IEEE 
Comput- er Graphics and Applications 7(5):3-5 May 1987 [43.] Waters, K. A Muscle Model for Animating 
Three-Dimen- sional Facial Expression Computer Graphics 21(4):17-24 (Siggraph Proceedings) July 1987 
[44.] Weft, J. The Synthesis of Cloth Objects Computer Graphics 20(4):49-54 (Siggraph Proceedings) August 
1986  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74359</article_id>
		<sort_key>253</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Hypertexture]]></title>
		<page_from>253</page_from>
		<page_to>262</page_to>
		<doi_number>10.1145/74333.74359</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74359</url>
		<abstract>
			<par><![CDATA[We model phenomena intermediate between shape and texture by using space-filling applicative functions to modulate density. The model is essentially an extension of procedural solid texture synthesis, but evaluated throughout a volumetric region instead of only at surfaces.We have been able to obtain visually realistic representations of such shape+texture (<i>hypertexture</i>) phenomena as hair, fur, fire, glass, fluid flow and erosion effects. We show how this is done, first by describing a set of base level functions to provide basic texture and control capability, then by combining these to synthesize various phenomena.Hypertexture exists within an intermediate region between object and not-object. We introduce a notion of <i>generalized boolean shape operators</i> to combine shapes having such a region.Rendering is accomplished by <i>ray marching</i> from the eye point through the volume to accumulate opacity along each ray. We have implemented our hypertexture rendering algorithms on a traditional serial computer, a distributed network of computers and a coarse-grain MIMD computer. Extensions to the rendering technique incorporating refraction and reflection effects are discussed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Parallel processors**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39081785</person_id>
				<author_profile_id><![CDATA[81100250413]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Courant Institute of the Mathematical Sciences, New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P72312</person_id>
				<author_profile_id><![CDATA[81538031556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Hoffert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Pixel Machines]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Tuy, H. and Tuy, L. Direct 2-D Display of 3-D Objects, IEEE Computer Graphics and Applications 4, 10 (October 1984), pp. 29-33.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W. Marching Cubes: A High Resolution 3D Surface Construction Algorithm, In Computer Graphics 21, 4 (July 1987), pp. 163-169.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. Functionally Based Modeling. SIG- GRAPH Course Notes (August 1988).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Frieder, G., Gordon, D. and Reynolds, R. A. Backto-Front Display of Voxel-Based Objects, IEEE Computer Graphics and Applications, (January 1985), pp. 52-60.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. An Image Synthesizer, In Computer Graphics 19, 3 (July 1985).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37423</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kaufman, Arie. Efficient Algorithms for 3D Scan- Conversion of Parametric Curves, Surfaces and Volumes, In Computer Graphics 21, 4 (July 1987).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Levoy, Marc. Volume Rendering: Display of Surface from Volume Data, IEEE Computer Graphics and Applications (May 1988), pp. 29-36.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Drebin, R., Carpenter, L. and Hanrahan, P. Volume Rendering, In Computer Graphics 22, 4 (August 1988).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Sabella, Paolo. A Rendering Algorithm for Visualizing 3D Scalar Fields, in Computer Graphics 22, 4 (August 1988).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Upson, C. and Keeler, M. V-BUFFER: Visible Volume Rendering, In Computer Graphics 22, 4 (August 1988).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kaufman, A. and Bakalash, R. A 3D Cellular Frame Buffer, Proceedings of EUROGRAPHICS 1985 (September 1985), Nice, France, pp. 215-220.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Amanatides, J. and Woo, A., A Fast Voxel Traversal Algorithm for Ray Tracing, Proceedings of EURO- GRAPttlCS 1987 (Amsterdam, Holland), pp. 3-10.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325233</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Toth, D. L., On Ray Tracing Parametric Surfaces, In Computer Graphics 19, 3 (August 1985).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74340</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Potmesil, M. and Hoffert, E., The Pixel Machine: A Parallel Image Computer, In Computer Graphics 23, 3 (August 1989).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Blinn, J., A Generalization of Algebraic Surface Drawing, "ACM Transactions on Graphics 1," pp 235., 1982.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J., Herzen, B., "Ray Tracing Volume Densities," In Computer Graphics 18, 3 (August 1984).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801252</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Norton, A. Clamping: A Method of Antialiasing Textured Surfaces by Bandwidth Limiting in Object Space. In Computer Graphics 16, 3 (August 1982).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30282</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Zadeh, L. A., Fuzzy Sets and Applications (selected papers), John Wiley and Sons, New York, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>236293</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Zimmerman, H. J., Fuzzy Set Theory- and Its Applications, Kluwer-Nijhoff, Hingham, 1985, pp. 30-36.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Menzel, D. H., ed., Fundamental Formulas of Physics, vol. 2, Dover, New York, 1960, pp. 370-371.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Cook, R., Distributed Ray Tracing, In Computer Graphics 18, 3 (August 1984).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>19635</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., Synthesizing Realistic Textures by the Composition of Perceptually Motivated Functions {Ph.D. Dissertation}, New York University, (Feb. 1986).]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J., Anisotropic Reflection Models. In Computer Graphics 19, 3 (August 1985).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Hypertexture Ken Perlin Courant Institute of the Mathematical Sciences New York University Eric M. 
Hoffert t AT&#38;T Pixel Machines ABSTRACT We model phenomena intermediate between shape and tex- ture 
by using space-filling applicative functions to modu- late density. The model is essentially an extension 
of pro- cedural solid texture synthesis, but evaluated throughout a volumetric region instead of only 
at surfaces. We have been able to obtain visually realistic representa- tions of such shape+texture (hypertexture) 
phenomena as hair, fur, fire, glass, fluid flow and erosion effects. We show how this is done, first 
by describing a set of base level functions to provide basic texture and control capabil- ity, then by 
combining these to synthesize various phenomena. Hypertexture exists within an intermediate region between 
object and not-object. We introduce a notion of general-ized boolean shape operators to combine shapes 
having such a region. Rendering is accomplished by ray marching from the eye point through the volume 
to accumulate opacity along each ray. We have implemented our hypertexture rendering algorithms on a 
traditional serial computer, a distributed network of computers and a coarse-grain MIMD computer. Extensions 
to the rendering technique incorporating refrac- tion and reflection effects are discussed. CR Categories 
and Subject Descriptors: C.1.2 [Proces- sor Architectures]: Multiprocessors -parallel processors; 1.3.3 
[Computer Graphics]: Picture/Image Generation -display algorithms -viewing algorithms; 1.3.5 [Computer 
Graphics]: Computational Geometry and Object Modeling curve, surface, solid and object representations; 
1.3.7 [Computer Graphics]: Three Dimensional Graphics and Realism - animation - visible line~surface 
algorithms; Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. General Terms: volume modeling, noise, turbulence, translucency, opacity, volume rendering, 
parallel render- ing, distributed rendering Additional Key Words and Phrases: hypertexture, gen- eralized 
boolean, density modulation function (DMF), ray marching, furrier synthesis 1. Introduction In computer 
graphics objects are traditionally modeled as sets having infinitesimally thin boundary surfaces. Often 
a computed or digitized texture or displacement is then mapped onto the surface for enhanced realism. 
However, there are limitations in treating object boundaries merely as surfaces. Many objects, such as 
fur or woven materials, have a com- plex definition which is at best awkward, and at worst impossible, 
to describe by a surface model. For other objects, such as eroded materials or fluids, a highly com- 
plex boundary is actually an artifact of a process that is often more readily described volumetrically. 
Still other objects, such as flame, clouds, or smoke, don't actually have a well defined boundary surface 
at all. We have found that the appearance of many such objects can be described directly by some applicative 
function, evaluated over a sampling of some region of R 3. Within this framework we are intuitively working 
with a solid block of material; visual characteristics of objects can be finely tuned by inserting numerical 
controls into their defining functional descriptions [3]. In that sense this work extends the procedural 
texture generation work of [5]. As in [5], we make use of a single controllable stochastic noise function 
together with a toolkit of shaping functions and programming constructs. We render hypertexture by combining 
ideas from volume rendering ([1],[7],[8],[10],[16]) with some new extensions particularly suited to this 
model. t Current address: Apple Computer, Cupertino, CA &#38;#169;1989 ACM-O-89791- 312-4/89/O07/0253 
$0O.75 '89, Boston, 31 July-4 August, 1989  ,, S GGRAP. 1.1 Overview In this paper, we first discuss 
the modeling issues of hyper- texture. Instead of modeling objects as connected surfaces, we model objects 
as distributions of density. We describe a mechanism to generate simple base-shape density distribu- 
tions. These base-shapes have a hard region where they are completely solid, and a soft region where 
they are indeter- minate. Whenever we are in the soft region, we can apply a toolkit of shaping functions, 
allowing the flexibility to create and manipulate volumetric form. An analogy is to think of this region 
as malleable, where the user can push in, pull out, twist or otherwise deform simulated matter in a controllable 
manner. We also develop a CSG style scheme to combine shapes using the operators union, intersection, 
difference and complement. When the foundation of modeling has been described we show how hypertexture 
is rendered. The renderer needs to evaluate many density samples throughout the volume since the model 
can become highly detailed and may con- tain a high degree of depth complexity. The rendering stage of 
the process allows a user to control the color and opacity of the object at every point in R 3 via the 
use of color maps. Since hypertexture rendering is relatively expensive (O(n 3) with respect to image 
resolution), we have implemented both distributed and parallel renderers. 2. Modeling Hypertexture In 
order to describe hypertexture, we need to introduce the concepts of: an Object Density Function D(x) 
with range [0,1] which describes the density of a 3D shape for all points x throughout R 3. The soft 
region of an object consists of all x such that 0 < D (x) < 1. a Density Modulation Function (DMF) .~, 
which is used to modulate an object's density within its soft region. Each DMF is used to control some 
aspect of an object's spatial characteristics; a collection of DMFs comprises a volume modeling toolkit. 
 Hypertexture is created by successive application of DMFs 3~ to an object's D (x): H(D (x), x)= f~ (....f2 
(fl (f0 (D(x))))) The DMF 3~ can be of three types: position-dependent, position-independent and geometry-dependent. 
Position-dependent DMFs are f ( x ), position-independent are f (k) where k is a scalar and geometry-dependent 
DMFs may depend on variables other than x such as density gradient in the vicinity of x. 2.1 Soft Objects 
Formally, a soft object is a density function D (x) over R 3, where D is 1.0 inside the object, 0.0 outside 
the object, and 0.0 < D < 1.0 in a region of nonzero thickness in between. As an example, consider the 
sphere centered at c of radius r and softness s. This can be defined by the density function: D [c,~sj(x) 
: r 1 := (r-s~2) ~ r02 := (r+s/2) 2 r$ := (x~-cx) 2 + (xFcy) 2 + (x,-c,) 2 D := ifr.2_<r~2 then 1.0 else 
if r~_>ro ~ then 0.0 else (ro2-r~) / (ro2-rl 2) where r 0 is the the outer (D=0) boundary, r 1 is the 
inner (D =1) boundary and r~ is the radius of the sphere at the point x. 2.2 Generalized Booleans We 
extend the boolean operations of set union, set comple- ment, set intersection and set difference t to 
soft objects A and B through their density functions a(x) and b(x): intersection: Ac-tB =- a(x)b(x) complement: 
A ~ 1.0- a(x) s difference: A - B = Ar~ ~_ a(x) - a(x)b(x) * union: A uB = A ~ _-- a (x) + b(x) - a(x)b(x). 
As with traditional boolean shape operators, we can con- struct expressions of arbitrary complexity to 
represent com- binations of different primitive shapes. By using boolean algebra, soft objects can be 
added or subtracted with smooth and controllable fillets at the regions where they join. Note that the 
size of the region where objects join can be controlled by modifying the width of each object's soft 
region. It should be noted that these operations don't actu- ally form a complete boolean algebra (since 
from the above definitions AriA ~:A and Ar-~A~ ) but do allow for stan- dard set operations. 2.3 Base 
Density Modulation Functions Here are the base level DMFs that higher-order DMFs are t There is a rough 
analogy here to the principles of fuzzy set theory [18]. We choose algebraic sum and algebraic product 
for union and inter- section, respectively [19], instead of the fuzzy set theoretic rnin and max operators 
[18], because the former preserve continuity. This is needed to maintain smoothness of fillets at the 
regiotas where objects join. It would be interesting also to try the rain and max operators. built upon. 
  bias We use bias to either push up or pull down an object's den- sity. A function that controls mean, 
bias~, is a power curve defined over the unit interval such that biasb(O)=O, biaSb(1/2)=b, and bias~,(1)=l. 
By increasing or decreasing b, we can thus bias the values in an object's soft region up or down. Biaso.5 
is the identity function over [0,1]. Bias can be defined by the power function: In (b) t/.(0.5) gain 
We use gain to make an object's density gradient either flatter or steeper. A function that controls 
variance, gai% is defined over the unit interval such that: gaing(O)=O, gaing(l/4)=(I-g)/2, gaing(1/2)=l/2, 
gaing(3/4)=(l+g)/2, and gai%(1)=l. By increasing or decreasing g, we can thus increase or decrease the 
rate at which the midrange of a object's soft region goes from 0.0 to 1.0. Gaino.5 is the identity function 
over [0,1]. Gain can be defined as a spline of two bias curves: if t < 0.5 thenbiasl_g(2t) / 2 else 1 
-biasl_s(2-2t) / 2 U V b = 0.25 b = 0.50 b = 0.75 Different bias curves / g = 0.25 g = 0.50 g = 0.75 
Different gain curves  noise An approximation to white noise band-limited to a single octave, noise 
[5] allows us to introduce randomness into the digital signal without sacrificing either continuity or 
control over spatial frequency. We implement noise as a summation of pseudorandom spline knots, one for 
each point on the integer lattice of R 3. The knot ~i,j,k at lattice point (i,j,k) consists of a pseu- 
dorandom linear gradient 1-' i j k weighted in each dimension by a smooth drop off functio~ 0~(t) t: 
 f ia,k(u,v,w) = u)o (v)co(w) (r a,k (u,v,w)) where "o" denotes vector inner product. We choose for 
co(t) the cubic weighting function: if Itl<l then 21t13-31t12+l else 0 giving the spline a support of 
2 in each dimension, so that in practice for any given point in R 3 we only need to take the sum of the 
23 nearest spline knots. Thus our noise implementation is defined at point (x,y,z) by: Lad +1 Ly.] +1 
LzJ +1 E Z E ~i,j,k(X--i, y --j,z--k ) i=[xJ J=LyJ ~=l.,J where" [J " denotes the floor function. For 
speed, we implement the pseudo-random gradient by hashing (i,j,k) to create an index into a precomputed 
gra- dient table G: Fi,j, k = G [~i+~(j+~(k)))] where:  ~(i) = P[i~a,], where P is a precomputeed array 
contain- ing a pseudorandom permutation of the first n integers,  G is a precomputed array of n pseudorandom 
vectors uniformly distributed on the unit sphere,  n is the length of the P and G arrays (in practice, 
we find n =256 to be a reasonable value).  To ensure that each element v of G is uniformly distributed 
on the unit sphere, we employ a three step Monte Carlo t It would have been somewhat faster and simpler 
to use a constant F (which is essentially a wavelet model), but we have found that this pro- duces visible 
artifacts at the lattice points, where gradient becomes zero.   function, so that the displacement 
will occur in an arbitrary direction. This creates a sort of three dimensional ripple glass effect, as 
though straight hair were being seen through a distorted space: d := D(x) x" := x + gaino.8(1 -d) * curliness 
* noise(x) s := noise(freq * project(x')) f := gaino.9(biaso.3(s)) * d There are several things to note 
in the above algorithm. The scalar variable curliness controls the magnitude of the curl. We use the 
expression gaino.s(1-d) to shape the curl, so that the hairs are initially straight where they grow out 
of the root (where D = 1.0), and gradually curl up as they reach the outer boundary (where D = 0.0). 
The vector valued noise function is built from noise as: noise = [ noise(x-c),noise(x),noise(x+~)] where 
the offset vector cr is made large enough so that the three calls to noise are guaranteed to return uncorrelated 
values (since each call will encounter an entirely different set of pseudorandom knots). Note how in 
all of the above we create a relatively simple algorithmic mechanism with a small number of scalar vari- 
ables that control aspects of perceptual interest (filament length, fineness, curliness, etc). As in 
[5], these are essen- tially knobs that a user of a hypertexture system can adjust at a high level to 
synthesize a particular variety of fur, without necessarily knowing the details of furrier synthesis. 
 3. Rendering ttypertexture Implementation of hypertexture rendering is only practical using volume 
rendering techniques, since hypertextural objects often have no well defined surfaces. Since volume rendering 
techniques have rime complexity O(n 3) with respect to resolution, they are typically slow. Fortunately 
the DMF evaluation is independent at each sample point, so hypertexture is particularly suitable for 
parallel or distri- buted implementations. We have found that designing and rendering hypertexture can 
be done on a serial yon Neu- mann machine, but is much more enjoyable when com-puted in parallel. This 
section focuses on the hypertexture rendering algorithm and its different implementations. 3.1 Ray Marching 
Algorithm In this section, we describe the ray marching algorithm [1] to generate images of hypertexture. 
As in traditional ray casting, the ray marcher casts a ray into model space for every pixel. We first 
clip each ray to a parallelpiped that bounds the hypertexture volume, using the optimal bounding test 
of [13]. If the ray does not intersect the paraUelpiped, we move to the next pixel for processing. If 
the ray does intersect the parallelpiped, the ray parameters I.to and l.tl, representing respectively 
the entry and exit points of the parallelpiped, are computed. Ray marching begins at the ray parameter 
value !1o, and proceeds at a fixed increment Ag. We sample the model along the ray at points: x=x~ +k 
Axrt where k=0,1,2 .... such that J.to+k AI.t_<l.t 1 and Ax~t is the displacement along the ray, in model 
space, at each increment. Aliasing of hypertexture is a potential problem. In practice we have achieved 
excellent results by manually tuning each hypertexture to be frequency clamped [17] as a func- tion of 
ray-marching step size. For example, in the tur- bulence function described above, we stop the iteration 
when the period of the noise function is as small as the size of Axe. The fact that an empirical approach 
works so well is encouraging but is clearly not definitive +. At each point along the ray, we first 
evaluate a DMF f(x). If 0 < f (x) < 1, then we evaluate the field gradient V f, nor- malize it, and use 
it as a normal vector for diffuse and/or specular shading, as well as for any refraction and reflection 
computations. To compute Vf it is sufficient to evaluate f at two points perpendicularly off the ray 
in mutually perpendicular directions Ax v and Axe. Since we have already computed the result of fat our 
previous sam- ple x-Ax~t , we can then approximate the gradient of f with respect to (I.t,v,c0) by the 
finite difference vector: f(x)-f(x-Axlx ),f(x+Ax v)-f(x),f(x+Axo)-f(x)] To convert this gradient vector 
in (I.t,v,00) space into a gra- dient vector in (x,y,z) space, we multiply by the transfor- marion matrix: 
Ax~t Axv Axo t A more systematic approach to antialiasing hypertexture is still a subject of research. 
We corljecture that it will involve discovering percep- tually equivalent tradeoffs between different 
base functions (so that, for example, increasing gain atsmall scales, which increases gradient will au- 
tomatically force the properly reduced amplitude).  :(~SlGGBAPH '89, Boston, 31 July-4 August, 1989 
The ray basis vectors Ax~t, Axv, and Ax~ can be precom- puted once per ray. For an orthogonal view, they 
only need be computed once for the entire image. Note that the expense of ray marching triples within 
an object's soft region, since computing Vf requires us to evaluate f three times inslead of just once 
per sample. We must also accumulate opacity for visibility determina- tion. A method similar to that 
of [7] is employed along the ray, so that at the kth step: t := o~k(l-~) color := color + t * colork 
 ~:=~+t where color k and x k are sample color and opacity, respec- tively. To ensure resolution independence, 
we make opa- city a function of both density and step-size: ~k := 1-(1-density) c * stcr,-~izc where 
c is a normalizing constant. Color is the product of the shading value and the user specified color. 
The color mapping can be as simple or as complex as desired; step functions or splines may be appropriate. 
This same approach to color mapping was taken in [5]. Color maps are typically used to identify or isolate 
particular features in a scalar field [10]. Here again the local gradient Vfis used to estimate the local 
normal vector. The use of opacity allows us to see amorphous or very fine volumetric features with a 
great deal of clarity. The above differs from the method of [7], since we proceed in a front to back 
order (as we move along the ray from its entry point towards its exit point) as opposed to back to front 
order. If the accumulated opacity reaches unity, the evaluation along a ray stops before we exit the 
volume. This avoids unnecessary computation for regions that are entirely obscured. Since in practice 
we have been able to tune our hypertex- tures empirically to be frequency clamped [17], do have not needed 
to use supersampling. We note though that sto- chastic ray marching might be employed as an extension 
of our algorithm, implemented by firing jittered rays with jit- tered step phases within each pixel. 
Similarly, motion blur might be achieved by sampling rays over time [21]. Other improvement might be 
made by utilizing recent work on optimization of ray marching [12]. Running Time An nxn image requires 
O (n 3) sample evaluations, so run- ning time rises dramatically with increased resolution. Since increasing 
resolution by a factor of 44 increases running time by 64, we usually do our quick "is it even there?" 
tests at a resolution of 3232, which take a few seconds, our rough tests at 128128, which take a few 
minutes, and our final runs at 512512, which take a few hours if run serially. As a rule of thumb, we 
see how many seconds a run takes at 32x32 to estimate how many serial hours it will be at 512512. Final 
runs would take any- where from 3 to 15 hours, depending on hypertexture com- plexity, on a single Sun 
4-260 workstation. To improve this performance, we have taken the two following approaches to parallelizing 
the algorithm. Parallel Rendering The ray marcher was implemented in C on an AT&#38;T Pixal Machine 
[14], an MIMD coarse-grain computer with gen- eral purpose floating-point processors, having relatively 
lit- tle memory per processor. In our implementation each of 64 processors uses an identical hypertexture 
program to compute a different interleaved subset of the final screen image, an arrangement that tends 
to optimize load balanc- ing among processors. Our memory requirements are particularly small because 
hypertexture is highly procedural. The only significant data space required is for color maps, alpha 
map and the noise function lookup tables. The sum of these is less than 5 Kbytes. Thus we are able to 
maintain a complete copy of the database at each processor. Since hypertexture can be evaluated independently 
at each pixel, and because each processor maintains its own data- base, this implementation has the following 
characteristics: it executes independently and asynchronously at each node no interprocessor communication 
is required the cost associated with parallelizing the algorithm is negligible We have found that increasing 
the number of processors produces a linear (optimal) decrease in execution time. Therefore in principle 
hypertexture could be generated interactively, since with enough processors, the time to render an image 
would be bounded only by the time to render the slowest pixel (in our experience, a fraction of a second 
at most). Distributed Rendering In addition to implementing the ray-marcher on a parallel computer, 
we also implemented the distributed ray-marching computation over a local-area network of Unix workstations 
on a shared Network File System. Each workstation runs the identical program, compiled for its particular 
processor, to compute different pixels of the same image. In practice we have observed a linear speedup 
over the single processor serial version of the algorithm, using the dozen or so workstations in our 
lab. 4. Summary, Conclusions and Future We have described a new modeling technique which modulates shape 
by applying procedural texture to a con- tinuous volumetric region. The method contrasts with pre- vious 
techniques in that we manipulate matter throughout R 3, instead of only at surfaces. This approach allows 
us to create the appearance of complex, real-world phenomena that would be difficult or impossible to 
generate with previ- ous methods. The computational model is O(n 3) but optimally parallelizable, achieving 
linear decreases in exe- cution time with increases in the number of processors. Clearly the model as 
described is highly empirical, leaving unanswered the disturbing question of why such simple techniques 
produce such visually convincing results. Prior work [22] has led us to believe that there is a sound 
percep- tual basis for this, and that in general procedural textures can be organized into a human perceptual 
taxonomy. We plan in future work to extend this taxonomy to the descrip- tion of hypertexture. Our newest 
research concentrates on applying hypertexture to empirical shape data such as cranio-facial structures 
and teapots. By performing preprocessing passes through volumetric shape images, we are currently implementing 
cast shadows and extending geometry-dependent functions such as the project operator of fur hypertexture 
to empiri- cal shapes at O (n 3) cost. We also plan to incorporate more sophisticated shading models, 
in particular the anisotropic shading of Kajiya [23]. 5. Acknowledgements The authors greatly appreciate 
the insightful comments of Don Mitchell, Jim Conant, Dave Weimer, Jim Demmel, and Mark Perlin. The reviewers' 
comments were invalu- able. In particular Ken would like to honor the request of one reviewer by offering 
a most humble apology for inflicting the term "furrier synthesis" on an unsuspecting scientific populace. 
References [1] Tuy, H. and Tuy, L. Direct 2-D Display of 3-D Objects, IEEE Computer Graphics and Applications 
4, 10 (October 1984), pp. 29-33. [2] Lorensen, W. Marching Cubes: A High Resolution 3D Surface Construction 
Algorithm, In Computer Graphics 21, 4 (July 1987), pp. 163-169. [3] Perlin, K. Functionally Based Modeling. 
SIG-GRAPH Course Notes (August 1988). [4] Frieder, G., Gordon, D. and Reynolds, R. A. Back- to-Front 
Display of Voxel-Based Objects, IEEE Computer Graphics and Applications, (January 1985), pp. 52-60. [5] 
Perlin, K. An Image Synthesizer, In Computer Graphics 19, 3 (July 1985). [6] Kaufman, Arie. Efficient 
Algorithms for 3D Scan- Conversion of Parametric Curves, Surfaces and Volumes, In Computer Graphics 21, 
4 (July 1987). [71 Levoy, Marc. Volume Rendering: Display of Surface from Volume Data, IEEE Computer 
Graphics and Applications (May 1988), pp. 29-36. [8] Drebin, R., Carpenter, L. and Hanrahan, P. Volume 
Rendering, In Computer Graphics 22, 4 (August 1988). [9] Sabella, Paolo. A Rendering Algorithm for Visualiz- 
ing 3D Scalar Fields, In Computer Graphics 22, 4 (August 1988). [10] Upson, C. and Keeler, M. V-BUFFER: 
Visible Volume Rendering, In Computer Graphics 22, 4 (August 1988). [11] Kaufman, A. and Bakalash, R. 
A 3D Cellular Frame Buffer, Proceedings of EUROGRAPHICS 1985 (September 1985), Nice, France, pp. 215-220. 
[121 Amanatides, J. and Woo, A., A Fast Voxel Traversal Algorithm for Ray Tracing, Proceedings of EURO- 
GRAPttlCS 1987 (Amsterdam, Holland), pp. 3-10. [13] Toth, D. L., On Ray Tracing Parametric Surfaces, 
In Computer Graphics 19, 3 (August 1985). [14] Potmesil, M. and Hoffert, E., The Pixel Machine: A Parallel 
Image Computer, In Computer Graphics 23, 3 (August 1989). [15] Blinn, J., A Generalization of Algebraic 
Surface Drawing, "ACM Transactions on Graphics 1," pp 235., 1982. [16] Kajiya, J., Herzen, B., "Ray Tracing 
Volume Densi- ties," In Computer Graphics 18, 3 (August 1984).  ~L..._~SIGG RAPH '89, Boston, 31 July-4 
August, 1989 [17] Norton, A. Clamping: A Method of Antialiasing Textured Surfaces by Bandwidth Limiting 
in Object Space. In Computer Graphics 16, 3 (August 1982). [18] Zadeh, L. A., Fuzzy Sets and Applications 
(selected papers), John Wiley and Sons, New York, 1987. [19] Zimmerman, H. J., Fuzzy Set Theory- and 
Its Appli- cations, Kluwer-Nijhoff, Hingharn, 1985, pp. 30-36. [20] Menzel, D. H., ed., Fundamental Formulas 
of Phy- sics, vol. 2, Dover, New York, 1960, pp. 370-371. [21] Cook, R., Distributed Ray Tracing, In 
Computer Graphics 18, 3 (August 1984). [22] Perlin, K., Synthesizing Realistic Textures by the Composition 
of Perceptually Motivated Functions [Ph.D. Dissertation], New York University, (Feb. 1986). [23] Kajiya, 
J., Anisotropic Reflection Models. In Com-puter Graphics 19, 3 (August 1985).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74360</article_id>
		<sort_key>263</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Algorithms for solid noise synthesis]]></title>
		<page_from>263</page_from>
		<page_to>270</page_to>
		<doi_number>10.1145/74333.74360</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74360</url>
		<abstract>
			<par><![CDATA[A solid noise is a function that defines a random value at each point in space. Solid noises have immediate and powerful applications in surface texturing, stochastic modeling, and the animation of natural phenomena.Existing solid noise synthesis algorithms are surveyed and two new algorithms are presented. The first uses Wiener interpolation to interpolate random values on a discrete lattice. The second is an efficient sparse convolution algorithm. Both algorithms are developed for <i>model-directed synthesis</i>, in which sampling and construction of the noise occur only at points where the noise value is required, rather than over a regularly sampled region of space. The paper attempts to present the rationale for the selection of these particular algorithms.The new algorithms have advantages of efficiency, improved control over the noise power spectrum, and the absence of artifacts. The convolution algorithm additionally allows quality to be traded for efficiency without introducing obvious deterministic effects. The algorithms are particularly suitable for applications where high-quality solid noises are required. Several sample applications in stochastic modeling and solid texturing are shown.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP37031228</person_id>
				<author_profile_id><![CDATA[81409595942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Laboratory, New York Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abramowitz, M. and Stegun, I., Handbook of Mathematical Functions. Dover, New York, 1965.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>3651</ref_obj_id>
				<ref_obj_pid>3650</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bohm, W., Farin, G. and Kahmann, J., A Survey of Curve and Surface Methods in CAGD. Computer Aided Geometric Design 1, 1 (1984), 1-60.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bracewell, R., The Fourier Transform and Its Applications. McGraw-Hill, New York, 1965.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807478</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carpenter, L., Computer Rendering of Fractal Curves and Surfaces. Supplement to Proceedings of SIGGRAPH '80 (Seattle, July 1980). In Computer Graphics 14, 3 (July 1980), 180.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, R., Stochastic Sampling in Computer Graphics. ACM Transactions on Graphics 5, 1 (January 1986), 51-72.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cook, R., Shade Trees. Proceedings of SIGGRAPH '84 (Minneapolis, July 23-27 1984). In Computer Graphics 18, 3 (July 1984), 223-23t.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Deutsch, R., Estimation Theory. Prentice-Hall, New Jersey, 1965.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Fussell, D., and Carpenter, L., Computer Rendering of Stochastic Models. Communications ACM 25, 6 (June 1982), 371-384.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808572</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gardner, G., Simulation of Natural Scenes Using Textured Quadric Surfaces. Proceedings of SIGGRAPH '84 (Minneapolis, July 23-27 1984). In Computer Graphics 18, 3 (July 1984), 11-20.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Heckbert, E, Personal communication.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lewis, J.P., Generalized Stochastic Subdivision. ACM Transactions on Graphics 6, 3 (July 1987), 167-190.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16594</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lewis, J.P., Methods for Stochastic Spectral Synthesis. In Proceedings of Graphics Interface 86 (Vancouver, May 1986), 173-179.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Oppenheim, A. and Schafer, R., Digital Signal Processing. Prentice Hall, Englewood Cliffs, N.J., 1975.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Papoulis, A., Probability, Random Variables, and Stochastic Processes. McGraw-Hill, New York, 1965.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Parke, E, Parameterized Models for Facial Animation. IEEE Computer Graphics and Applications 2, 9 (Nov. 1982), 61- 68.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Peachy, D., Solid Texturing of Complex Surfaces. Proceedings of SIGGRAPH '85 (San Francisco, July 22-26 1985). In Computer Graphics 19, 3 (July 1985), 279-286.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., A Unified Texture/Reflectance Model. In SIG- GRAPH '84 Advanced Image Synthesis course notes (Minneapolis, July 1984).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., An Image Synthesizer. Proceedings of SIG- GRAPH '85 (San Francisco, July 22-26 1985). In Computer Graphics 19, 3 (July 1985), 287-296.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Schafer, R. and Rabiner, L., A Digital Signal Processing Approach to Interpolation. Proc. 1EEE 61, 6 (June 1973), 692-702.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1097023</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wiener, N., Extrapolation, interpolation, and Smoothing of Stationary Time Series. Wiley, New York, 1949.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Yaglom, A., An Introduction to the Theory of Stationary Random Functions. Dover, New York, 1973.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  Computer Graphics, Volume 23, Number 3, July 1989 Algorithms for Solid Noise Synthesis J. P. Lewis 
 Computer Graphics Laboratory New York Institute of Technology ABSTRACT A solid noise is a function 
that defines a random value at each point in space. Solid noises have immediate and powerful applications 
in surface texturing, stochastic modeling, and the animation of natural phenomena. Existing solid noise 
synthesis algorithms are surveyed and two new algorithms are presented. The first uses Wiener interpolation 
to interpolate random values on a discrete lattice. The second is an efficient sparse convolution algorithm. 
Both algorithms are developed for model-directed synthesis, in which sampling and construction of the 
noise occur only at points where the noise value is required, rather than over a regularly sampled region 
of space. The paper attempts to present the rationale for the selection of these particular algorithms. 
The new algorithms have advantages of efficiency, improved control over the noise power spectrum, and 
the absence of arti- facts. The convolution algorithm additionally allows quality to be traded for efficiency 
without introducing obvious deterministic effects. The algorithms are particularly suitable for applications 
where high-quality solid noises are required. Several sample ap- plications in stochastic modeling and 
solid texturing are shown. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image 
Generation; 1.3.7 [Computer Graph- ics]: Three-Dimensional Graphics and Realism -color, shading, shadowing, 
and texture. General Terms: Algorithms, Graphics. Additional Key Words and Phrases: Solid noise, texture, 
stochastic modeling, simulation of natural phenomena, texture syn- thesis, fractals. INTRODUCTION A 
solid noise is a random-valued function f : R 3 ~ R. "Noise" is used to denote a random function with 
some known statistical properties. Solid noises are a subset of the concept of solid textures introduced 
in computer graphics by Perlin [17,18] and Peachy [161). Solid noises have been used for texturing three-dimensional 
ob- jects by assigning the color at a visible point on the surface as a function of the noise value at 
that point in space. In this role, solid textures have several advantages over conventional texture mapping: 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. Surfaces with 
Gaussian curvature can be textured homo- geneously, without distortions such as poles that occur in texture 
mapping. The spatial nature of the noise correlation makes possible certain effects which would be difficult 
with texture map- ping, for example, the "carved out of" effect [18] which uses the fact that noise features 
(e.g. veins in simulated rock) can cross overhangs in the object (Fig. 7). Solid noises also have many 
potential applications in describ- ing complex/irregular forms or movement; a few possibilities are shown 
in Section 5 of this paper. 2 SOLID NOISE ALGORITHMS In all applications, it is desirable that a solid 
noise algorithm be controllable and free of artifacts. Consistent with recent work [ 18,9,11 ], the noise 
power spectrum is considered as a reasonably powerful and intuitive framework for developing control 
over the noise. When the noise is used for surface texturing, efficiency is a major consideration, since 
the three-dimensional variants of even simple computations such as linear interpolation are fairly expen- 
sive when the computation is required at each pixel. It is desirable that the noise synthesis algorithm 
allow quality to be traded for ef- ficiency where appropriate, e.g. for previewing or for background 
objects which do not need a high-quality noise. For most applica- tions it is probably preferable to 
trade some control for efficiency rather than adopting an efficient method that has intrinsic artifacts. 
For animation applications the solid noise should also be ban- dlimited. Although the aliasing of an 
improperly sampled noise function will often not be objectionable in a still picture (due to the same 
principle evident in stochastic sampling [5] -objectionable Moire patterns result from the structured 
sampling of a structured signal), the same aliased noise used in an animation will typi- cally produce 
characteristic "shimmering" or "bubbling" aliasing effects. While a large variety of particular three-dimensional 
random- valued functions are conceivable, most can be decomposed into a basic noise source and some functional 
or procedural transfor- mation of this noise. As argued by Perlin [18], the noise source should be a 
controllable "primitive" that allows the user to de- fine various ad hoc solid noise functions in terms 
of this noise primitive. This paper presents two algorithms for the synthesis of high- quality solid 
noises with control of the noise power spectrum and (optionally) distribution functions. Considerations 
that lead to the selection of these particular algorithms are also described. @1989 ACM-0-89791-312-4/89/007/0263 
$00.75 '89, Boston, 31 July-4 August, 1989 IIII I #define RANTABLEN /* something prime */ float Rantab[RANTABLEN] 
; int Indx [ILEN] , Indy [ILEN] , Indz [ILEN] ; float hash3(float x,y,z) (  int i = HASH( Indx[LOWBITS(x)], 
Indy[LOWBITS(y)], Indz[LOWBITS(z)] ); return( Kantab[i 7. KANTABLEN] ); }  Fig. 1 : Pseudocode for the 
lattice white noise function. 2.1 MODEL-DIRECTED SYNTHESIS Although the linear filtering algorithms for 
obtaining noises having desired power spectra are well understood [13], these algorithms are not ideally 
suited to the requirements of computer graphic modeling and rendering. In particular, in place of the 
regular and ordered sampling that is fundamental to digital signal processing we require a model-directed 
synthesis, in which the noise function is constructed only at particular points determined by the object 
model, and in an order that may depend on the model or the viewpoint. In a texturing application, these 
points are the points on the object's surface that project without occlusion to pixels in a perspective 
projection of the object. Similarly, in a modeling application the noise may be constructed at a limited 
and irregular set of points, e.g., the vertices of a polygonal model. Digital filters assume regular 
sampling and spatial or temporal ordering (causality) of the input signal and consequently cannot meaningfully 
operate at isolated points in space. The direct ap- plication of a digital filtering approach for solid 
noise synthesis would thus result in a solid region of filtered noise enclosing the points of interest. 
This is very costly in terms of storage, since the storage size of a solid noise varies with the cube 
of the reso- lution. The direct FFT or digital filter synthesis of a medium- or high-resolution solid 
noise is usually impractical in this respect. Also it would seem inefficient to construct the noise over 
a solid region when it is only needed at isolated points, though this may depend on the number of points 
required and on the respective algorithms. A third drawback of digital filtering approaches is that since 
the noise is sampled it needs to be interpolated from the sampling lattice to the locations of interest. 
Model-directed synthesis can be achieved by constructing the input noise signal as needed at synthesis 
time, and by employ- ing an acausal and metaphorically continuous rather than sampled filtering approach. 
Since the spatial ordering of the synthesis is unknown, particular regions may be visited multiple times. 
The input noise construction must be internally consistent (in the ter- minology of [8]): independent 
constructions of a particular point must produce the same value. While model-directed synthesis ap- proaches 
are suited for many computer graphics problems, it is evident that they cannot easily use the coherence 
provided by reg- ular sampling and consequently will be more costly than standard filtering approaches 
for constructing regularly sampled noises. 2.2 LATTICE WHITE NOISE A consistent uncorrelated ("white") 
noise can be generated using a hash-like pseudo-random function of the mantissa bits of the lo- cation 
coordinates z, y, z. One such function was described in [4]. A variation of this function uses the low-order 
bits of each coordi- nate (scaled suitably) to index a corresponding randomly permuted 'indirection table' 
of indices into a second table of uncorrelated random values with the desired probability density. The 
three re- sulting indexes are hashed to form an index into the prime-length random value table (Fig. 
1). The HASH3 function generates an uncorrelated periodic noise, with the period determined by the number 
of coordinate bits which are retained. The function takes on new values only on the lattice defined by 
the low bits of the coordinate mantissas, thus "lattice noise". For most purposes it will be necessary 
to interpolate or filter the noise values on the lattice to obtain a continuous and correlated solid 
noise. 2.3 PERLIN ALGORITHM Perlin [17,18] outlined a model-directed solid noise algorithm based on 
interpolating a location hashing function such as I-IASH3. The resulting noise is employed as a spectral 
basis function, with a desired noise ~ being approximated by a weighted sum of basis noises r/k at different 
scales: (1) The characteristics of the resulting noise are determined by the selected interpolation 
approach. The cubic polynomial interpola- tion suggested in [18] has certain disadvantages. Interpolation 
in several dimensions using the separable tensor product of a one-dimensional interpolation scheme results 
in preferred direc- tions along the coordinate system axes; this artifact can only be avoided by using 
an intrinsically multi-dimensional interpolation approach. Cubic polynomial interpolation in three dimensions 
is also quite expensive. The direct tensor product scheme for cubic spline interpolation requires a support 
of 43 = 64 points as well as 16(z) + 4(y) + l(z) = 21 spline evaluations [2]. The inter- polation must 
be repeated for each basis function in the spectral summation (1). One popular implementation of Perlin's 
approach employs Her- mite interpolation, using the lattice noise to define gradients at the (eight) 
nearest-neighbor points on the lattice [10]. These val- ues are separably interpolated using a cosine-like 
function. While this approach is considerably more efficient than a cubic spline interpolation, it has 
stronger directional artifacts (Fig. 2). An-other drawback is that the noise value and second-derivative 
are both zero at the lattice points. The directional trends and regu- larly spaced zeros are visible 
(e.g. see Fig. 3), though it may be possible to disguise them through application of the summation (1). 
In order to be approximately orthogonal, candidate spectral ba- sis functions should be zero beyond a 
particular range of frequen- cies ("bandpass"). Approaches which use standard (meaning non- oscillatory, 
energy minimizing, spline-like) interpolation methods to interpolate an uncorrelated noise lattice produce 
a low-pass rather than a band-pass random function, however, since they do not remove or attenuate the 
low frequency portion of the origi- nal noise power spectrum (which has equal expected power at all frequencies) 
(Fig, 4,) This can be seen in part by considering the zero frequency: interpolation will not remove the 
mean. From a signal-processing viewpoint, standard interpolation methods have ~ Fig. 4: Computed amplitude 
spectrum (zero frequency at left) of a long one-dimensional section of the noise shown in Fig. 2. The 
spectrum is not bandpass. the effect of attenuating high frequencies [19] (also see problem 26 in [3]). 
One misinterpretation of the summation (1) is that, by anal- ogy with Fourier summation, a bandpass noise 
might be produced using a lowpass noise primitive by subtracting a more bandlim- ited noise from a given 
noise, in the hope of removing the low- frequency portion of the spectrum. Power spectra of mutually 
uncorrelated noises cannot be meaningfully subtracted however: S(ql -~) = S(~1 ) -2C(nl, 7~ ) + S(~)where 
C(~/,, ~2 ) = 0 is the covariance between the noises. Eq. (1) is a spectral summation but not a Fourier 
summation. The high-frequency (amplitude) spectrum of the Perlin basis noise using cubic interpolation 
falls off as A-4 since the amplitude spectral envelope of a C~ function is A-~-2 [3]. This also is not 
ideally bandlimited. We conclude that polynomially interpolated noise does not provide an ideal spectral 
basis. The various disadvantages of polynomial interpolation for a spectral synthesis approach are avoided 
in the Wiener interpo- lation algorithm presented in section 3 below. 2.4 GARDNER AND PEACHY ALGORITHMS 
Gardner [9] developed a naturalistic texturing function based on a modified Fourier series. This approach 
is unusual in its use of a conceptually deterministic function to simulate irregular texture. 3 The function 
appears as a product of two one-dimensional series in z and y (as described it is two-dimensional but 
an equivalent three-dimensional function can be formulated). A separable func-tion f(u,v) = f~(u)fv(v) 
has strong directional artifacts that make it unsuitable for simulating a naturalistic texture even if 
the component functions f~, f~ are characteristic sections of the desired texture. Gardner overcame this 
'checkerboard effect' by coupling the phases of each term in the u-series to v, and con- versely. The 
resulting texture is not separable and is sufficiently complex that it mimics a random texture when applied 
carefully. The spectrum of the Gardner function has not been analyzed but is not (as might be supposed) 
directly defined by the Fourier series coefficients. This can be seen by considering the kth term of 
the u-series evaluated along a diagonal profile with u and v varying: fk(u) = ak sin(~ku + [sin(wk_av)) 
 This is a form of frequency modulation. From [1] sin(0 --F I sin/3) = Jo() ~in 0 + ~.~ J.([) {si,~(O 
+ k~) + (-~)~ ~in(O -- k~) } k=i I while the computer implementation of any random process is necessarily 
deter- ministic, there is a practical as well as a conceptual difference, in that the period of an n-term 
Fourier series is 2n samples whereas the period of a simulated random process is usually considerably 
larger, as determined by the period of the pseudo-random number function.  Computer Graphics, Volume 
23, Number 3, July 1989 so although the Gardner texturing function has a line spectrum, it is more complex 
than suggested by its Fourier series resemblance (also it is evident that it is not strictly bandlimited). 
Peachy [ 16] proposed solid function generation by the composi- tion (e.g. sum or product) of several 
lower-dimensional functions. If the functions are random the result is a solid noise. As in the Gardner 
algorithm, the composition function can be designed to eliminate separability but the absence of an intrinsically 
three- dimensional correlation structure may be visually evident. 3 WIENER INTERPOLATION ALGORITHM Wiener 
interpolation differs from other interpolation approaches in that it is based on the expected correlation 
of the interpolated function. Since the autocorrelation or autocovariance function is equivalent information 
to the power spectrum, Wiener interpo- lation is particularly suited for noise synthesis where control 
of the noise correlation and spectrum is required. Control of the noise spectrum is intrinsic to Wiener 
interpolation, so problems with band-limiting and the expensive spectral summation (1) are avoided. Wiener 
interpolation has many other potential applications in computer graphics (e.g., as the basis for an improved 
stochastic subdivision method [11], or possibly as an approach to resam-pling stochastically sampled 
images for display). Some additional characteristics and advantages of Wiener interpolation are: -The 
data can be arbitrarily spaced. -The algorithm applies without modification to multi-dimensional data. 
- Wiener interpolation of discrete data is simple, requiring only the solution of a linear equation. 
- In an estimation application the algorithm provides an er- ror or confidence level associated with 
each point on the interpolated surface. - The algorithm is optimal by a particular criterion (see be- 
low) which may or may not be relevant. - The interpolation can be made local or global to the ex- tent 
desired. This is achieved by adjusting the covariance function so that points beyond a desired distance 
have a negligible correlation. - The interpolation can be as smooth as desired, for example, an analytic 
covariance function will result in an analytic interpolated curve or surface. - The interpolation need 
not be "smooth", for example, the correlation can be negative at certain distances, oscillatory, or (in 
several dimensions) have directional preferences.  (The last three properties result from the direct 
spectral control provided by Wiener interpolation.) There are a number of formulations and variations 
of Wiener interpolation [20,7]. A simple probabilistic formulation suitable for solid noise interpolation 
will be used here. The description requires two concepts from probability: - The correlation of two random 
variables is the expectation of their product, E[xy]. The autocorrelation or autocovari- ance function 
of a random process (noise) is the correlation of pairs of points from the process: C(tl, t2) = E [q(t1)77(t2)] 
For homogeneous noise, this expectation is a function only of the distance between the two points: C(t,t 
+ r) =   ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 C(r) = E[z/(t)nn(t + 7")]. The variance is 
the value of the autocovariance function at zero. (Auto)covariance refers to the correlation of a process 
whose mean is removed and (usually) whose variance is normalized to be one. - Expectation behaves as 
a linear operator, so any factor or term which is known can be moved "outside" the expec- tation. For 
example, assuming a and b are known, E {ann + b} = aE[nn] + b Also, the order of differentiation and 
expectation can be interchanged, etc. Wiener interpolation estimates the value ~ of the process nn at 
a particular location as a weighted sum of the values nn~ observed at some number of other locations: 
= ~ a~ ~, (2) The weights aj are chosen to minimize the expected squared dif- ference or error between 
the estimate and the value of the "real" process at the same location: E { (nn -~)2 } (3) The reference 
to the "real" process in (3) seems troublesome be- cause the real process may be unknowable at the particular 
loca- tion, but since it is the expected error which is minimized, this reference disappears in the solution. 
Wiener interpolation is optimal among linear interpolation schemes in that it minimizes the expected 
squared error (3). When the data have jointly Gaussian probability distributions (and thus are indistinguishable 
from a realization of a Gaussian stochastic process), Wiener interpolation is also optimal among nonlinear 
interpolation schemes. 3.I DERIVATION By the orthogonality principle [21,14], the squared error of a 
linear estimator is minimum when the error is orthogonal in expectation to all of the known data, with 
"orthogonal" meaning that the ex- pectation of the product of the data and the error is zero: E{(nn--~)nnk} 
=0 for all k Substituting ~ from (2), E {(nn - E a,~3)r/k} = 0 (4) E {nnnk - Z %nn,,k} : 0 The expectation 
of nn~k is the correlation C(i -ik), and likewise for nn3~k, so: c(t -t~) = ~ %c(t, -t~) or Ca = e (5) 
 This equation can be solved for the coefficients %. The coeffi- cients depend on the positions of the 
data nn3 through the covari- ance function, but not on the actual data values; the values appear in the 
interpolation (2) though. Also, (5) does not directly involve the dimensionality of the data. The only 
difference for multi- dimensional data is that the covariance is a function of several arguments: E[pq] 
= C(xp --xq, yp --yq, Zp --Zq,...). 3.2 COST From (5) and (2), the coefficients aj are a = C-~e, and 
the estimate is it = nntC-lc. The vector c changes from point to point, but nntC-a is constant for given 
data, so the interpolation cost is a dot product =< nntc-~, e > (6) of two vectors whose size is the 
number of data points. 3.3 EVALUATION The spectral definition possible in Wiener interpolation is propor- 
tional to the number of data points considered in the interpolation. For simple spectra requiring a small 
neighborhood of points (e.g. 33 or 43 points), the computation (6) appears to be considerably more efficient 
than polynomial spline interpolation. A fair degree of spectral control can be achieved if larger neighborhoods 
are used, for example, oscillatory (bandpass) noises are possible. The expensive spectral summation (1) 
is also avoided The disadvantage of this algorithm is intrinsic to the approach of interpolating an uncorrelated 
noise lattice: the three-dimensional covariance function, centered at a noise lattice point, should strictly 
be zero when sampled at any other lattice point, since these points are not correlated. For an isotropic 
covariance, this requires that CI(T ) z 0 at distances r = 6~i 2 + j2 + k 2 for all lattice offsets i 
+ j + k >= 1 (6 is the lattice spacing). The co- variance structure is thus artificially constrained. 
If the specified covariance does not satisfy this constraint, the interpolation error (confidence measure) 
will be non-zero and the realized covariance will be somewhat different than that specified. 4 SPARSE 
CONVOLUTION ALGORITHM A second algorithm avoids the covariance function constraints of the noise lattice 
interpolation approach but retains the direct spec- tral control of the Wiener interpolation approach. 
In addition, it has the advantage of conceptual simplicity. In this algorithm a three-dimensional noise 
is synthesized by the convolution of a three-dimensional kernel h(p) with a Poisson noise process 7 ~(P) 
= f~3 ~(o-)h(p -o-)do-(7) The Poisson process consists of impulses of uncorrelated intensity distributed 
at uncorrelated locations in space: 7(P) = ~ ak~(p-- Pk) (Pk is the location of the kth impulse). This 
is a 'sparse' form of white noise, hence "sparse convolution". The power spectrum S v at the output of 
a linear time-invariant filter (expressible as a convolution) is related to the input spectrum S~ by 
[21] sy(~) = s~(~)I~q(j~)l 2 where H is the Fourier transform of the filter impulse response or kernel 
h. Since 7 is uncorrelated its transform is a constant, so the spectrum of a noise synthesized by sparse 
convolution is simply the (deterministic) spectrum of the kernel, scaled by a constant. 4.1 EFFICIENCY 
Sparse convolution has several advantages for digital computation. Because of the impulsive nature of 
the noise, the convolution integral (7) reduces to a summation over the impulses: rl(p) = Z akh(p Pk) 
(8)  ~ Computer Graphics, Volume 23, Number 3, July 1989 Thus, the synthesis is reduced naturally to 
a computationally real- izable form without requiring sampling (and subsequent interpo- lation) of the 
noise. The quality of the noise can be varied as required for the ap- plication by varying the density 
of the Poisson noise. This is an important property, since e.g. background objects or interac- tive previewing 
applications may not require full quality noise. A density of less than one impulse per kernel volume 
produces a "lumpy" noise with little spectral definition. Typical applications require a density of several 
impulses per kernel volume, and noises produced with a density of 10 or more points per kernel are usu- 
ally not distinguishable from those produced by convolving with a uniformly sampled (non-sparse) white 
noise, though the sparse convolution is considerably more efficient. For an isotropic noise the kernel 
h is also isotropic and (as- suming it is non-zero over a finite radius) can be approximately evaluated 
by a one-dimensional table lookup. In this case the sum- mation (8) can be restricted to only those impulses 
7e within the kernel radius of the location /9. The problem then is to identify these points efficiently, 
in particular, without requiring examina- tion of all points and an expensive distance computation requiring 
a square-root. This can be accomplished with an appropriate construction of the Poisson process 7. A 
simple construction is to define a large but finite sampling lattice over the noise domain and approximate 
the Poisson process by choosing N Poisson-distributed impulses in each voxel. The voxels can then be 
numbered, and the voxel number serves as a random number generator seed for generating the impulses within 
that voxel. The lattice spacing and kernel ra- dius are conveniently set to one (with space scaled accordingly). 
Then the impulses lying within a unit radius of a particular lo- cation p are those in the voxel containing 
p and in the adjacent voxels. The summation (8) is modified accordingly. Square roots are entirely removed 
by using the squared distance IP - Pkl 2 to index a prewarped kernel table h(7) = h(vr~). The author's 
implementation of sparse convolution uses stan- dard tricks such as fixed-point computation. In addition, 
the noise impulses Pk are stored in a cache array as they are computed, and are reused if the next location 
falls within the same voxel. With these optimizations, the algorithm using one impulse per voxel is slightly 
slower than the previously described Hermite implemen- tation of Perlin's algorithm, but does not have 
visible artifacts and provides some control over the spectrum. The upper-left panel in Fig. 5 shows a 
planar section of a sample texture generated with the sparse convolution algorithm using a smooth cosine 
kernel 1/2 + 1/2cos(rr), 17-[ < 1.The texture does not reveal the synthesis coordinate system or display 
other artifacts. APPLICATIONS A solid noise algorithm is most useful as a primitive in a lan- guage 
that allows one to easily define functional or procedural transformations of the noise. An important 
characteristic of this language is that it should allow functions to be dynamically de- fined at modeling/rendering/animation 
time -the "user" should have the freedom to define an ad hoc function in the model, rather than requiring 
the original programmer of the graphics system to anticipate and implement libraries of special-purpose 
functions. This requires either an interpreted language or user-compiled func- tions that are dynamically 
linked with the graphics system. An interpreted language was described in [18], while the shade-trees 
approach [6] appears to use compiled functions that are dynami- cally linked to an interpreted expression 
evaluator. In the language approach adopted by the author, a small and portable public-domain Lisp language 
interpreter was adapted to Fig. 8: Porous object model defined by the iso-density surface of a solid 
noise. allow compiled C language functions to be dynamically linked and called from Lisp. This approach 
avoids the definition and implementation of a new special-purpose language, and permits functions to 
be implemented in either Lisp or C or some combi- nation of these. Typically a function is developed 
in Lisp, and if needed the inner loops are reimplemented in C and dynamically "glued" together with Lisp. 
Stepping back from the full power of procedural manipulation of the noise, we note that the special case 
of a functional transfor- mation is useful from an analysis-resynthesis viewpoint, since a desired probability 
density (a commonly measured random texture characteristic) can be obtained by functional transformation 
[12]. 5.1 SOLID TEXTURE Although spectral synthesis adequately simulates most homoge- neous random textures, 
many textures have some structural fea- tures that cannot be simulated using this approach. Such textures 
can often be simulated using a procedural transform of a homo- geneous texture. An example is the marble 
texture described in [18]. Another example of a procedural transform is the solid wood texture shown 
in (Figs. 6, 7). The structure of concentric rings parallel to the tree trunk is produced using a periodic 
or (prefer- ably) quasi-periodic function xtab of the radial distance from the z axis. This function 
describes the color variation across a ra- dial section of a typical ring. Natural irregularity is introduced 
by perturbing the radial distance by a solid noise: ~,ood(p) = ~,tb[~/p.T ~ + p.y2 + ~(p)] (where p.x 
denotes the x-component of p). Various refinements are possible, for example, the radial distance can 
be replaced by a random monotonic function of this distance, thereby creating radial regions of densely 
or sparsely separated rings to simulate periods of slow or fast growth. Fig. 6 shows planar sections 
of several solid wood simulations, where the perturbation noise 7/ and the ring cross section function 
stab are altered to simulate different woods. Fig. 7 shows a figure, model with a solid wood texture. 
This surface/texture combination would be difficult to achieve using texture mapping.  5.2 STOCHASTIC 
MODELING An interesting stochastic modeling approach utilizing solid noise is to define objects as the 
equal-density surface of a solid noise. The overall shape of the object can be controlled by multiplying 
 SIGGFIAPH '89, Boston, 31 July-4 August, 1989 "\ ktD;'c! LI,~I Fig. 12: Trajectories of a number of 
particles forced by a vector solid noise. the noise by an analytic density function that tapers to zero 
outside of the desired object shape. This approach can produce porous and highly irregular shapes such 
as the coral-like form in Fig. 8. 5.3 STOCHASTIC DEFORMATION This is a powerful stochastic modeling technique 
which uses a vector-valued solid noise (vector field) v : R 3 ~ R 3 to perturb an existing object model. 
Three independent scalar solid noises form the components of the vector field. Stochastic deformation 
is particularly efficient for polygonal boundary-represented models, since only the vertices are perturbed. 
Stochastic deformation can be used to simulate the individuality of natural objects by slightly deforming 
a prototype object model (Figs. 9, 11). The noise can be varied to produce either realistic or caricatural 
individuality. Large-amplitude or iterated deformation can produce self-intersecting or twisted forms 
which do not resemble the original object (Fig. 10). A deformation can be animated by offsetting the 
object location by a continuously changing vector before perturb- ing, effectively moving the object 
through the noise. 5.4 CORRELATED FLOW Solid noises may be employed as a correlated random environmen- 
tal factor for many physically motivated simulations. For exam- ple, a solid noise can be used as a force 
field to produce turbulent trajectories or flow. Fig. 12 shows the trajectories of a number of particles 
obeying a simple dynamics equation ~ = 7/(p). The resulting collection of trajectories displays bifurcations 
and resem- bles animal fur and other natural structures. Fig. 13 is a frame from a brief animation in 
which the trajectories are animated by the previously mentioned technique of moving the model through 
the noise. The trajectories are rendered to produce the effect of an "organic fireball". 6 CONCLUSION 
In addition to their demonstrated use in solid texturing, solid noises have direct applications in stochastic 
modeling. In both model- ing and texturing it is desirable that the solid noise synthesis be controllable, 
efficient, and free of artifacts. Spectral synthesis pro- vides a framework for assessing the control 
and quality of various synthesis approaches. Existing solid noise algorithms were sur-veyed from this 
viewpoint. 268 Two new algorithms were described and evaluated. Both al- gorithms provide improved spectral 
control and efficiency. The sparse convolution algorithm is attractive in that it allows a trade- off 
between quality and efficiency as required by the application, without introducing gross artifacts. Several 
solid texturing and stochastic modeling examples visually illustrate the control and quality achievable 
with this algorithm. Symbols S(A) power spectrum C(r) autocovariance function h filter kernel 7 uncorrelated 
noise 7/ correlated synthesized noise p, o" locations in space )% a2 frequency, angular frequency Acknowledgements 
The figure model in Fig. 7 was developed by Dick Lundin and Susan VanBaerle. The head model used in Fig. 
9 was developed by Fred Parke [15] with additions by Rebecca Allen, Steve Di- Paola and Robert McDermott. 
Thanks to Paul Heckbert and Lance Williams for discussions. References [1] Abramowitz, M. and Stegun, 
I., Handbook of Mathematical Functions. Dover, New York, 1965. [21 Bohm, W., Farin, G. and Kahmann, J., 
A Survey of Curve and Surface Methods in CAGD. Computer Aided Geometric Design 1, 1 (1984), 1-60. [3] 
Bracewell, R., The Fourier Transform and Its Applications. McGraw-Hill, New York, 1965. [4] Carpenter, 
L., Computer Rendering of Fractal Curves and Surfaces. Supplement to Proceedings of SIGGRAPH '80 (Seattle, 
July 1980). In Computer Graphics 14, 3 (July 1980), 180. [5] Cook, R., Stochastic Sampling in Computer 
Graphics. ACM Transactions on Graphics 5, 1 (January 1986), 51-72. [6] Cook, R., Shade Trees. Proceedings 
of SIGGRAPH '84 (Minneapolis, July 23-27 1984). In Computer Graphics 18, 3 (July 1984), 223-231. [7] 
Deutsch, R., Estimation Theory. Prentice-Hall, New Jersey, 1965. [8] Foumier, A., Fussell, D., and Carpenter, 
L., Computer Ren- dering of Stochastic Models. Communications ACM 25, 6 (June 1982), 371-384. [9] Gardner, 
G., Simulation of Natural Scenes Using Textured Quadric Surfaces. Proceedings of SIGGRAPH '84 (Min-neapolis, 
July 23-27 1984). In Computer Graphics 18, 3 (July 1984), 11-20. [10] Heckbert, P., Personal communication, 
[1 l] Lewis, J.P., Generalized Stochastic Subdivision. ACM Trans- actions on Graphics 6, 3 (July 1987), 
167-190. [121 Lewis, J.P., Methods for Stochastic Spectral Synthesis. In Proceedings of Graphics Interface 
86 (Vancouver, May 1986), 173-179.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74361</article_id>
		<sort_key>271</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Rendering fur with three dimensional textures]]></title>
		<page_from>271</page_from>
		<page_to>280</page_to>
		<doi_number>10.1145/74333.74361</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74361</url>
		<abstract>
			<par><![CDATA[We present a method for rendering scenes with fine detail via an object called a <i>texel</i>, a rendering primitive inspired by volume densities mixed with anisotropic lighting models. This technique solves a long outstanding problem in image synthesis: the rendering of furry surfaces.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39074029</person_id>
				<author_profile_id><![CDATA[81100653012]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Kajiya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Technology, Pasadena, Ca. 91125]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P275006</person_id>
				<author_profile_id><![CDATA[81100544501]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Kay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Technology, Pasadena, Ca. 91125]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn J.F. and Newell M.E. (1976) "Texture and Reflection in Computer Generated Images" Comm. ACM 19,10, 542-547.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn J.F. (1977) "Models of Light Reflection for Computer Synthesized tures" Picture Computer Graphics 11,2, 192-198.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[BIinn J.F. (1978) "Simulation of Wrinkled Surfaces" Computer Graphics 1,2,3 286-292]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn J.F. (1982) "Light Reflection Functions for Simulation of Clouds Dusty Surfaces" and Computer Graphics 16,3, 21-29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37434</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cabral B., Max N. and Springmeyer R. (1987) "Bidirectional Reflectance Functions from Surface Bump Maps" Computer Graphics 21,4, 273-282.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Catmull E.E. (1974) A Subdivision Algorithm for Computer Display of Curved Surfaces, Ph.D., U. of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cook R.L., Porter T. and Carpenter L. (1984) "Distributed Ray Tracing" Computer Graphics 18,3, 137-146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook R.L. (1984) "Shade Trees" Computer Graphics 18,3, 223-232.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801253</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Crow F.C. (1982) "A More Flexible image Generation Environment", Computer Graphics 16,3, 9-18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807458</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Csuri C., Hakathorn R., Parent R., Carlson W. and Howard M. (1979) "Towards an interactive high visual complexity animation system" Computer Graphics 13,2, 289-299.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Drebin R.A., Carpenter L., and Hanrahan P. (1988) "Volume Rendering", Computer Graphics 22,4, 65-74]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kajiya J.T. and Von Herzen B. (1984) "Ray Tracing Volume Densities" Computer Graphics 18,3, 165-174.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kajiya J.T. (1985) "Anisotropie Reflection Models" Computer Graphics 19,3, 22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378513</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Krueger W. (1988) "Intensity Fluctuations and Natural Texturing" Computer Graphics 22,4, 213 220.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378508</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Miller G.S.P. (1988) "The Motion Dynamics of Snakes and Worms" Computer Graphics 22,4, 169-178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>5515</ref_obj_id>
				<ref_obj_pid>5513</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Max N.L. (1986a) "Light Diffusion through Clouds and Haze" Computer Vision, Graphics and Image Processing 33,280-292.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15899</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Max N.L. (1986b) "Atmospheric Illumination and Shadows" Computer Graphics 20,4, 117-124.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>23954</ref_obj_id>
				<ref_obj_pid>23944</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Max N.L. (1986c) "Shadows for Bump Mapped Surfaces" in Advanced Computer Graphics, Springer V., 145-156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Nishita T., Okamura I. and Nakamae E. (1985) "Shading Models for Point Linear Sources" ACM Trans. on Graphics 4,2, 124-146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37437</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Nishita T., Miyawaki Y. and Nakamae E. (1987) "A Shading Model for Atmospheric Scattering Considering Luminous Intensity Distribution of Light Sources" Computer Graphics 21,4, 303-310.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Ohira T. (1983) "A Shading Model for Anisotropic Reflection" Tech. Rep. El. and Comm. Eng of Japan (in Japanese) 82,235, 47-54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Peachey D.R (1985) "Solid Texturing of Complex Surfaces" Computer Graph- 19,3,279-286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Perlin K. (1985) "An Image Synthesizer" Computer Graphics 19,3, 287-296.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801167</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Reeves W.T. (1983) "Particle Systems--A Technique for Modefing a Class of Fuzzy Objects" Computer Graphics 17,3, 359-376.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Reeves. W,T. and Blau R. (1985) "Approximate and Probabilistic Algorithms Shading and Rendering Structured Particle Systems" Computer Graphics 3, 313-322.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37436</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Rushmeier H.E. and Torrance K.E. (1987) "The Zonal Method for Calculat- Light Intensities in the Presence of a Participating Medium" Computer Graphics 21,4, 293-302.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Sabella P. (1988) "A Rendering Algorithm for Visualizing 3D Scalar Fields", Computer Graphics 22,4, 51-58.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Takagi J., Yokoi S. and Tsuroka S. (1983) "Comment on the Anisotropic Reflection Model" Bull. of SIG. Graphics and CAD, Inf. Proc. Soc. of Japan. (in Japanese) l l ,1 , 1-9.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Upson C., Keeler M. (1988) "VBUFFER: Visible Volume Rendering", Computer Graphics 22,4, 59-64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 i ~! ~! i I i i ~i '! :i ) i! i~!iI 21 1 ~I ~i~ . i i Abstract. We present a method for rendering 
scenes with fine detail via an object called a texel, a rendering primitive inspired by volume den- sities 
mixed with anisotropic lighting models. This technique solves a long outstanding problem in image synthesis: 
the rendering of furry surfaces. Introduction Rendering scenes with very high complexity and a wide 
range of detail has long been an important goal for image synthesis. One idea is to introduce a hierarchy 
of scale, and at each level of scale have a corre- sponding level of detail in a hierarchy of geometric 
models (Crow 1982). Thus very complex small objects may have a hierarchy of progressively simplified 
geometric representations. However, for very fine detail, a significant problem has so far prevented 
the inclusion of furry sufaces into synthetic images. The conventional approach gives rise to a severe, 
intractable aliasing problem. We feel that this aliasing problem arises because geometry is used to define 
sur- faces at an inappropriate scale. An alternative approacti is to treat fine geometry as texture rather 
than geometry. We explore that approach here. This paper presents a new type of texture map, called a 
tezel, inspired by the volume density (Blinn 1982). A texel is a 3-dhnensional texture map in which both 
a surface frame--normal, tangent, and binormal-- and the parameters of a lighting model are distributed 
freely throughout a volume. A texel is not tied to the geometry of any particular surface. Indeed, it 
is intended to represent a highly complex collection of surfaces contained within a defined volume. Because 
of this the rendering time of a texel is independent of thegeometric complexity of the surfaces that 
it extracts. In fact, with texels~ one can dispense with the usual notion of geometric surface models 
altogether. That is, it is possible to render texels directly, foregoing referents to any defined surface 
geometry. We will use the idea of texels to represent fuzzy surfaces and present an algorithm for rendering 
such surfaces. Review of High Complexity Rendering Many attempts to model scenes with very high complexity 
have been made. One method is to attack the problem by brute force computing. A very early effort by 
Csuri, et al.(1979) generated images of smoke and Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. &#38;#169;1989 ACM -0-89791-312 -4/89/007/0271 $00.75 @ (~ 
Computer Graphics, Volume 23, Number 3, July 1989 RENDERING FUR WITIt THREE DIMENSIONAL TEXTURES James 
T. Kajiya Timothy L. Kay California Institute of Technology Pasadena, Ca. 91125  fur with thousands 
of polygons. More recently, Weil(1986) rendered cloth with thousands of Lambert cylinders. Unfortunately, 
at a fairly large scale, microscopic geometric surfaces give rise to severe aliasing artifacts that overload 
traditional antialiasing methods. These images tend to look brittle: that is, hairs tend to look like 
spines. The brute force method fails because the desired detail should be ren- dered through textures 
and lighting models rather than through geom- etry. What is desired is the painter's illusion, a suggestion 
that there is detail in the scene far beyond the resolution of the image. When one examines a painting 
closely the painter's illusion falls apart: zoom-ing in on a finely detailed object in a painting reveals 
only meaningless blotches of color. The most successful effort to render high complexity scenes are those 
based on particle systems (Reeves 1983, Reeves and Blan 1985). We believe their success is due in part 
to the fact that particle systems embody the idea of rendering without geometry. Along the path of the 
particle system, a lighting model and a frame are used to render pixels directly rather than through 
a notion of detailed microgeometry. In some sense, this paper represents the extension of particle systems 
to ray tracing. As the reader will readily discern, even though our rendering algorithm is radically 
different, particle systems and texels are complementary, e.g. particle systems could be used to generate 
texel models. Indeed, this paper can be modified to render particle systems in a manner that is independent 
of the number of particles rendered. Gavin Miller in (Miller 1988) advanced a solution that uses a combina- 
tion of geometry and a sophisticated lighting model much in the spirit of this paper to make images of 
furry animals. However, like particle sys- tems~ the complexity of the geometric part of his algorithm 
is dependent on the number of hairs. The idea of texels is inspired by Blinn's idea for rendering volume 
densi- ties (Blinn 1982). Blinn presented an algorithm to calculate the appear- aalce of a large collection 
of microscopic spherical particles uniformly distributed in a plane. This enabled him to synthesize images 
of clouds and dust and the rings of Saturn. Because Blinn was interested in directionally homogeneous 
atmospheres, he analytically integrated his equations to yield a shnple lighting model. In Kajiya and 
Von Herren (1984), Blinn's equations were solved for nonhomogeneous media by direct computation. It was 
essentially a volume rendering technique for ray tracing. Because our work is based on that earlier effort, 
we now briefly discuss the relevant equations from Kajiya and Von Herzen (1984}. As a beam of light travels 
through a volume of spherical particles, it is scattered and attenuated. The attenuation is dependent 
on the local density of the volume Mong the ray. The scattering is dependent on the density of the particles 
scattering the light and the albedo of each particle. The amount of scattering varies in different directions 
due to the particle partially occluding scattering in certain directions. This scattered fight then is 
attenuated and rescattered by other particles. 271 '89, Boston, 31 July-4 August, 1989 This model ignores 
diffraction around scattering particles. In ray tracing, we follow light rays from the eye backwards 
toward the light sources (figure 1). The progressive attenuation along the ray due to occluding particles 
is computed for each point along a ray emanating from the eye. At each point on the ray through the volume, 
we measure the amount of light that scatters into the direction toward the eye. This light is then integrated 
to yield the total light reaching the eye. In this work we use Blinn's low albedo single scatterhxg approximation. 
That is, we assume that any contribution from multiple scattering is negligible. We assume that the light 
is scattered just once from the light source to the eye. The accuracy of this assumption is relatively 
good for low albedo particles and suffers as the albedo increases (Blinn 1982~ Rushmeier and Torrance 
1987). Figure 1 shows a schematic of the situation. A volume containing par- ticles with density p(x, 
y, z) at each point is penetrated by a ray. The light reaching the eye is computed along the ray R. At 
each point P = (x(t), y(t),z(t)) of the ray at distance t, the illumination Ii for each light source 
is multiplied by a phase factor p(cos 0) that indicates how much of the light is scattered from the light 
source to the ray. The brightness is then weighted by the density p of the particles at this point. The 
attenuation between point P and A due to the medium is given by an integral of the density along the 
ray. The equations are: (1) and (2)  p(~(t), y(t/,.(t/) dt Equation 1 calculates the transparency T 
of the density p. It says that that each small distance ds along a ray multiplicatively accumulates the 
transmission coefficient by e -rpd~. The coefficient r converts the density of the particles into an 
attenuation coefficient. The quantities tne~,tfa~ are the near and far distances of the density that 
contribute to the calculation. Equation 2 calculates the brightness B by integrating the brightness of 
each piece dt along the ray (x(t), y(t),z(t)) according to three fac- tors. The first factor introduces 
the attenuation of the medium Mong the ray into the surface. Bright particles buried deep within a density 
are occluded by many particles, thus the accumulated transmission co- efficient is low and the particle 
will not contribute much light to the pixel. Note that this factor is calculated as in equation 1. The 
second factor multiplies the illumination Ii for each light source i reaching the particle (which is 
given as a transmission as in equation 1), times the lighting model for each single particle, this is 
given by the phase factor p(cos0). This phase factor is a function of the angle 0 between the light direction 
and the eye direction. It represents the amount of occlusion of the scattered light and is much like 
the phase of the moon. The third factor weights the brightness by the density of particles at a given 
point. A few bright particles will contribute less light than a large number of dimmer particles. Calculating 
the illumination component I~ can be done in many ways. Blinn (1982) assumed a homogeneous field and 
calculated the trans-parency of the medium from point P to point C~ for each light source (figure 1). 
Kajiya and Von Herzen (1984) assumed an infinite distance (viz. collimated) light source and precalculated 
the intensities for each point in the volume by marching along a parallel wavefront. Rushmeier and Torrance 
(1987) solve a system of linear equations to yield Ii. Following Blinn(1982), many workers have expanded 
on the volume density theme: Voss(1983), Max(1983), Kajiya and Von Herzen(1984), Max(1986b, 1986e), Rushmeier 
and Torrance(1987), and Nishita, Miyawaki and Nakamae(1987). These algorithms extended Blinn's orig- 
inal work to rendering densities with nonuniform distribution, to high albedo solutions, and to more 
general geometries. Rushmeier and Tor- rance(1987) represents the most sophisticated effort to date, 
calculating a physically accurate distribution of light for true multiple scattering-- albeit with isotropic 
scattering models. The recent popularity of scientific visualization has engcndered much re- cent activity 
in volume rendering, e.g. Sabella(1988), Upson and Keeler (1988), Drebin, Carpenter, and Hanrahan(1988). 
The technique out- lined in this paper has direct application to the volume rendering of vector fields. 
In particular, one result of this work has particular rele- vance to volume rendering: the hnportance 
of shadows. In the results section, we have rendered an identical texel with and without shadows. As 
the pair of torii in figures 10 and 11 show, rendering without taking into account shadows creates a 
situation that is so unphysical that the data cannot be properly interpreted by our visual system. We 
also point out that the technique presented in this paper fits well into the ray tracing/distributed 
ray tracing/rendering equation framework. That is, texels can be mixed with the wide variety of primitives 
already amenable to ray tracing. It is not clear whether texels can be made compatible with the radiosity 
approach to image synthesis. Texels In Kajiya and Von Herzeu(1984) it was suggested that volume densities 
were potentially capable of rendering many complex objects beyond particles of dust and smoke: this would 
include phenomena such as hair and furry surfaces. We began this work attempting to generalize volume 
density rendering along these lines. During the course of the investigation, we found that the idea of 
using volume densities to model surfaces is not entirely appropriate. Although the idea of distributing 
lighting models instead of spherical particles within the volume density is the right idea, we have found 
that one cannot not simply replace particle lighting models with surface lighting models. The physics 
of scattering from surfaces is so different from that of particles that new equations governing the rendering 
process must be derived. To generalize volume densities we now introduce texels. In practical terms, 
a texel is a three dimensional array of parameters approximating visual properties of a collection of 
microsurfaces. If texels are to be used to replace geometry~uch as trees on the side of a mountain--then 
the microsurfaces of leaves and branches will be stored into the volume array. At each point in space, 
several items must be stored. First is the density of microsurfaces. That at certain points, space is 
empty; at others, there is a dense array of leaves. A second item distributed throughout space is a lighting 
model. In a texel, each leaf is not stored as a polygon. Instead the collection of leaves is represented 
by a scattering function that models how light is scattered from the aggregate collection of surfaces 
contained within a volume cell. This scattering function is represented by a pair of quantities, the 
first is a frame, that is a representative orientation of a microsurface within the cell, and a reflectance 
function. Texels may be generated many different ways. We have not investigated techniques for generating 
texels for many interesting cases. For example, the geometry for the trees could be sampled into three~:limensional 
arrays using some sort three-dimensional scan-conversion technique. We have not done thisj however. For 
representing fur~ the generation of texels is straightforward and is presented in a section below. Texels 
are intended to simulate a volume cell that contains bits of sur- faces, not spherical particles. Thus 
the first component of a texel is a scalar density p which represents not relative volume, but an approxi-mation 
to relative projected area of the microsurfaces contained within a volume cell. The second component 
of a texel is a field of frames B, that is the local orientation of the mlcrosurface within a volume 
cell. The third component is a field of lighting models ~, which determine how light scatters from this 
bit of surface. Definition. A texel is a triple p,B, g, consisting of a scalar density p(x,y,z), a frame 
bundle B = [n(x,y,z),t(x,y,z),b(x,y,z)], and a   ~/~ Computer Graphics, Volume 23, Number 3, July 
1989 field of bidirectional light reflection functions ~(~,y,~,0,,). The scalar density p measures 
how much of the projected unit area of a volume cell is covered by microsurfaces. It should properly 
be a higher tensor quantity that takes into account the viewing vector, but we adopt the approximation 
that this quantity is an isotropic quantity and hence a scalar. The frame bundle B indicates the local 
orient ation of the surfaces within the texel. It is a field of coordinate basis vectors n~t~bthat are 
called the normal, tangent, and binormalfields, resp. The bidirectional light reflection function indicates 
the type of surface contained therein. It is possible to combine B and into a single anisotropic lighting 
model field, but we have separated them because, often, either component may be taken to be constant 
throughout the volume while the other varies. Texels appear to be a natural extension of a volume density. 
Because in a volume density the spheres are physically and materially isotropic, the frame and reflectance 
fields are homogeneous. Thus they do not need to be distributed throughout a density but can be established 
as single quantities. Texels simply generalize this a bit. l~endering Texels How can one modify volume 
densities to model hair? A naive approach would be to simply reinterpret the density p to reflect the 
densities of the hair at each volume celt; and to modify the lighting model at each point to correspond 
to scattering from a cylinder instead of a sphere. Unfortunately this direct approach~ while correct 
in spirit, has flaws. For an insight into understanding why volume densities are not appro- priate for 
rendering microsurfaces~ consider the rendering of a single plane surface via a volume density (figure 
2). Assume that the surface is stored into a volume density so that it bisects the cube. The optical 
depth of the surface is so high that it simulates an opaque surface, Let the phase factor of the particle 
lighting model be say a Lambertian sur- face lighting model in equations 1 and 2. Let us not use equations 
1 and 2 to calculate both the transparency and the brightness of the surface. For the transparency calculation, 
even though the optical depth param- eter ~ is set very high, the line integral of the density in the 
exponent will be vanishingly small. This is because the surface is infinitely thin~ so the line integral 
will pierce the surface at only a single point. This yeilds an integral Of 0. A similar problem occurs 
in the brightness calculation. The brightness integrand yields a finite value whose contribution to the 
integral along the ray will be zero, since it is nonzero only for a single point. Thus the transparency 
and brightness for this surface will both be zero-- an invisible surface! Obviously, volume rendering 
needs to be modified somewhat to be able to render surfaces. The problem is that the relative volume 
of mierosurfaces does not determine brightness and opacity for surfaces as it does for point particle 
densities. A single surface with zero volume can be completely opaque and can reflect 100% of its incident 
light. Yet its relative volume will be zero. Thus, what is called for is something like a density which 
is given by Dirac delta functions. This, along with a more general lighting model, is the essence of 
the texel idea. Texels are rendered in a manner which is similar to that for volume densities, suitably 
generalized. Again, the equations model the situation schematized in figure 1. The texel containing surfaces 
with projected area density p(z, y,z) at each point is penetrated by a ray. The light reaching the eye 
is computed along the ray R. At each point P = (x(t),y(t),z(t)) of the ray at distance t, the illumination 
h for each light source is multiplied by the bidirectional reflectance function gt that indicates how 
much light is scattered from the light source to the ray. The brightness is then weighted by the projected 
area density at this point. The attenuation between point P and A due to the medium is given by an sum 
of the density along the ray. The equations for a texel illumination are [~Ii(x(t),Y(t),z(t))ff2(x(t),y(t),z(t),O,,P)] 
T = ,-" E:~L..r ~(~(,),v(,),~(,)) (3) and tfar B= t--tnear (4)  0(=(t), y(tl,.(t)) Equations 3 and 
4 are similar to equations 1 and 2. Equation 3 is just equation 1 with the line integral replaced by 
a sum. We write the sum because integrating Dirac delta functions on microsurfaces sums the contribution 
at each microsurface. In equation 4, the relationship to equation 2 is also evident. The inte- gral has 
again been replaced by a sum. The attenuation along the ray segment AP in figure 1 is represented by 
the first term in the product. The second term models the scattering of light from the microsnrface. 
As in equation 1 there is a term for eacl~ light source. The illumina- tion I reaching the microsnrface 
is multiplied by the bidirectional light reflection function of the microsurface. Finally, the projected 
area density scales the reflected light in the third term. The transmission equation 3 for texels is 
a formal sum instead of an integral. This formal sum is taken over each of the surfaces in the density 
along the ray. If this sum is infinite, then the transmission coefficient is zero, indicating that the 
density is totally opaque. The brightness equation 4 is also a formal sum instead of an integral. This 
is because, at each surface intersecting a ray, we are adding the brightness contribution of the surface 
at that point. It would appear that equation 4 would always yield an infinite quantity, but recall that 
the terms of the formal sum will be zero where there are no surfaces and behind any surface the optical 
depth will be high and will attenuate all contributions to zero. Thus the sums are finite. Calculation 
of the incident intensities I~ are computed by using equation 1 reeursively. That is, a ray is shot from 
the point P to each light source i (figure 1). The transmission coefficient is calculated from equation 
1. The intensity I~ is simply the brightness of the light source attenuated by the transmission coefficient 
along the segment PC~. The algorithm just outlined would be impossibly expensive if the sums were to 
be evaluated by adding terms corresponding to every point along the original ray. The algorithm presented 
in the next section approxi- mates these sums by a Monte Carlo treatment that computes expected values 
of random samples along the ray, in the spirit of distributed ray tracing (Cook, et al. 1984). Texel 
Rendering Algorithm The texel rendering algorithm computes the above sums by approxi- mating them with 
with expected values of random samples along the ray. To find the intensity of light emanating backwards 
from a given ray, the intersection of the ray and each texel boundary is calculated. The distances along 
the ray of these intersections then forms an interval from tnear to t.far along the ray, shown as point 
A and D of figure 1. To compute the sum, we use the technique known as stratified sampling. We divide 
up the ray into a series of segments (delineated by tick marks along the ray in figure 1). In each segment 
a random point is chosen to calculate the scattering term, e.g. point P. The illumination Ii is calcu- 
lated by recursively shooting a ray toward each light source as discussed ;i 273  '89, Boston, 31 July-4 
August, 1989 in the previous section. Finally the sum over segments are calculated to approximate the 
quantities in equations 3 and 4. 1. Intersect a ray with the all texel boundaries to find tnear , ~far 
for each texel. Sort all intersections frora front to back and match with distance. Let Tnear ~ min ~near 
where the minimum is over all segments. Similarly Tfar = max ~far. 2. Divide up the ray from Tnear to 
Tfa r into ray segments ~i of length L, where 1 is a reference length parameter, the number of sexnples 
per unit distance in world coordinates set by the user. (The last segment may be shorter than L). 3. 
Set transparency to unity. 4. FOIl. each segment.  4.1 Shoot shadow rays from the sa*nple toward every 
light source to calculate the amount of light reaclfin s tiffs point. 4.2 Calculate b~ightness from li~shting 
model and illumination intensity and multiply by transparency to give overall brightness contribution 
to the pixelpiffel = pixel + trans * lightblodel. 4.3 Multiply transparency by e to, the transmission 
coefficient of the segment. 5. At the end segment, calculate brightness as above but normalize by fractional 
 length of the segr~nt. Step 5 in the algorithm above is required to avoid bias in the Monte Carlo calculation. 
If the final segment were to be treated as a full length section then the averages would be thrown off. 
This has an effect of making the edges of the volume appear slightly more opaque than they should be. 
This section presents an algorithm for rendering a single texel. However, to make pictures of fuzzy objects, 
four steps must be carried out. These are the creation of the texels, the mapping of texels into world 
space, the intersection of rays with texels, and the computation of the lighting model. Generating Texels 
for Hair We will now direct our attention to methods for generating texels that represent patches of 
hair. The general problem involves long flowing hair. Particle systems could be used to trace the trajectories 
of the individual hairs through a three-dimenslonal array. The particle would leave an ~anti-aliased" 
trail of density that would be summed in with previous densities. A texel representing hair may be simplified 
by storing only the density p and the frame B at each point. The bidirectional reflectance function is 
constant for each hair and common to all hairs (if the hair does not change color). Thus it is not necessary 
to store it throughout the volume. For the lighting model derivation we treat an individual hair as an 
infinitely thin cylindrical surface. Thus, the only element of the frame that is necessary is the tangent 
vector along the hair. The rest of the frame B, normal and binormal, do not enter into the lighting calculations 
and were omitted. Thus a particle system generating hair would not only leave a track of density but 
also store a tangent vector representing the direction of the velocity of the particle. The teddy bear 
model presented in this paper uses a single texel repli- cated over the bear's skin. The contents of 
the texel were generated using a much simplified version of the particle system approach. All hairs on 
the teddy bear are straight lines that point in the same direc- tion, perpendicular to the scalp (in 
texel space). This implies that the hairs will lie along an axis 6f the three-dimensional array used 
to store the texel. Thus the tangent vectors are all the same in that they all perpendicular to the scalp. 
Thus they were also excluded from volume structure. The bear's fur texel was stored as a 40x40xl0 array. 
The contents of the array were designed based on several criteria: 1. The "hairs" axe distributed as 
a Poisson disk. 2. The Poisson disk is created with a torus topology, so the single texel can tile 
 tim entire bears surface without showing seams. 3. Animal fur often comes in two layers, an "overcoat," 
and an "undercoat." The undercoat is a dense cover of short fur, while the overcoat is a sparser distribution 
of long hair. We have found this to be an important feature for avoiding a brushlike appearance. A "modeling" 
program allowed us to search the parameter space and presented us with top and side projections of the 
texel. Using purely aesthetic (and largely arbitrary) judgement, the texel used in figures 15 azld 16 
was created. Mapping Texel To World Space By placing texels over the surface of the bear, we created 
a bear whose fur flows smoothly over its entire body, while at the same time shows local randomness. 
However, a texel representcd as a three-dlmensional array, is shaped as a rectangular sohd, at least 
in texel space. The texels must be mapped onto the shape of the bear in a continuous way to avoid gaps. 
The teddy bear was modeled using a new technique called generative models. Each body part (head, body, 
ear, arm, leg, and nose) was constructed by designing a parametric mapping (I' from a rectangle U (parameterized 
by u and v) into world space R 3. If we were to render the bear as polygons (as we do in the case of 
the bear's nose), we would chop the rectangle into a mesh of n x m small squares. Each square would be 
mapped vertex by vertex through if9 into world space. The resulting objects (bihnear patches) would then 
be rendered (usually by further approximating each patch as two triangles). Figure 3 demonstrates this 
approach. For the sake of simplicity, all figures will present just two dimensions when possible. The 
extension to three dimensions is obvious. The texel cubes are mapped into world space in exactly the 
same way. The parameterized rectangle is chopped into n  m small squares. Each square is mapped into 
world space and is identified with the base of a texel (figure 4). (In the case of the teddy bear, a 
single texel was replicated over the entire surface of the bear.) The mapping q) defined by the generative 
modeling specifies what hap- pens only to the base of each texel; The texel's third dimension (height) 
must also be mapped into world space. This mapping specifies ff the fur on the bear stands straight out 
or if it lies down. The extension of 4) to the third texel dimension need only be defined for the corners 
of the texel. Once the corners of the texels are mapped, they are no longer necessarily boxes. Additionally, 
the gaps between adjacent texels dis- appear (figure 5). The hnear nature of the texel interpolation 
described in a following sections assures that the hairs within a texel will flow in the same general 
direction as the corners. A modeling program was created that allowed the designers to manipu- late the 
orientation of the corners of the texels. The program starts with the corners of each texel sticking 
straight out (i.e., the corners of each texel correspond with the surface norman of the scalp). The corners 
are then perturbed by global Fourier maps. Intersecting Rays With Texels A texel is shaped as a rectangular 
solid in texel space. The mapping of the texel into world space as described above changes each of the 
six faces of the rectangular solid into a bihnear patch. The intersection of a ray with a texel is accomplished 
by intersecting the ray with the six faces of the texel in world space. Intersecting Rays with Bilinear 
Patches Each edge of a bilinear patch, as well as all "horizontal" and "vertical" cross sections on the 
patch are straight lines. All other cross sections of a bihnear patch are quadratics. Therefore, it seems 
reasonable that the ray-patch intersection calculation should involve solving the quadratic equation. 
 ~ Computer Graphics, Volume 23, Number 3, July 1989 A ray is defined by the equation R = at + b with 
0 <_ t. The 3-vectors a and b specify the origin and direction cosines of the ray. A bilinear patch is 
of the form P-~ Auv+Bu+Cv+D with 0 _< u < 1 and 0 < v < 1 where A, B, C, and D are also triples. The 
intersection of the ray R with the patch P occurs when R = /9. Expanding into components yields three 
equations of the form, Aluv + Blu + Clv + Dlt + El = 0, (5a) A2uv + B2u + C2v + D2t + E2 = 0, (5b) and 
A3uv + B3u + Czv + D3t + E3 = 0. (5c) These equations should be reordered so that the first is the one 
with the largest D coefficient. This will assure that, in the case of a patch aligned with an axis~ the 
denominators in the equations that follow will be reasonable (thereby avoiding floating point overflows). 
The first equation is solved for t, yielding A~uv + B=u + C~v + E~ t = D= ' (6) which can be substituted 
into the remaining two equations to remove references to t, resulting in two equations of the form F2uv 
+ G2u + H2v +/2 = 0 (7a) and Fsuv + Gnu+ Hsv + Is = 0. (7b) These two equations can be multiplied by 
Fs and F2 respeetivelyj and the uv term can be eliminated, giving a linear equation relating u and v. 
Solving for u and backsubstituting into equation (7a) or (7b) results in a quadratic equation in v. Once 
v is determined, u quickly follows, as does t. When solving the quadratic equation (of the form ax e 
+ bz + c = 0), there is a possibility that the coefficient on the square term (a) may be very small. 
This could occur, for example, when the four points of the bilinear patch are coplanar. Since we are 
looking only for values of 0 _< u < 1, we can compute if a is too small using the equation b + sgn(b)X/V 
-4ac < 2a. (8) If the equation falls to hold, then the root would be out of the range -1 < u < 1, and 
need not be computed. This and similar tests will help avoid floating point overflows. Mapping Ray-Texel 
Intersections to Texel Space Once the intersections of the ray with the texel have been computed, they 
must be mapped into texel space. Then the texel properties (such as density and tangent vector) can be 
found by trilineax interpolation from the texel arrays. To compute the mapping, all the intersections 
are sorted. Ideally, they will come in pairs, the first of the pair (anear') representing the ray en- 
tering the texel, and the second (afar,) representing the ray leaving the texel. The intersections yield 
pairs of the form (fn .... u ..... v ..... tnear) and (flat, tafar,far~tfar), where f is the index of 
the face intersected, (u, v) is the patch coordinate for the intersection in face f, and t is the distance 
along the ray for the intersection. Each intersection is mapped back to the texel in texel space, resulting 
in points of the form (z ..... Yn.... Z ..... t .... ) and (zf~, Yfar, Zfar,tfar), where (z, y, z) is 
the coordinate withing the unit texel of the intersection. The t values remain unchanged. The (x, y, 
z) coordinates of an intersection in texel space will fall in the unit cube. At least one of the components 
will actually be either 0 or 1, except when an intersection happens for t < 0. In this case, the (x, 
y, z) coordinates of the intersection must be adjusted by interpolation to match the point on the ray 
where t --0. To render the scene, the shader must know the value of the texel at many points along the 
ray. Because the t parameter is invariant under the texel-space-to-world-space mapping, we can use it 
as the interpolant to compute the texel space coordinate for any value of t. The three components are 
t -- tnear ----~-(xf~ --z .... ) + z ..... (9a)Har --~near t-t ..... (yf~r-y .... )+v ...... (gb) tfa 
r -- tnear and t - t.... (Zf~r - Z .... ) + z ...... tfa r ~ tnear Lighting model for hair There are 
two components forming the lighting model for a single hair, the diffuse and specular. The diffuse component 
is derived essentially from the Lambert shading model applied to a very small cylinder. The specular 
component is an ad hoc model similar to the Phong light re- flection model that has been modified for 
cylindrical surfaces. A more rigorous approach to defining a lighting model would be some- thing along 
the lines of Kajiya (1985), of Cabral, Max, and Springmeyer (1987), or of Krueger (1988). These papers 
propose algorithms to con- vert the the surface microgeometry to be represented in the volume directly 
to lighting models. We have found, however, the exact form of the details of the lighting model not to 
be particularly critical to the quality of the images. Examination of the images show that our ad hoc 
approach is adequate. The geometry for deriving the hair lighting model is shown in figure 6. An individual 
hair is a line segment specified by a position x0 and a tangent vector t. The light vector I points from 
Xo to the light source. The eye vector e indicates the direction of the scattered light toward the eye. 
All of these vectors are assumed to be of unit length. The projection I I of 1 onto the plane perpendicular 
to t forms the second basis vector. The third basis vector b is chosen to be perpendicular to both the 
previous basis vectors. The diffuse component The diffuse component of the hair reflection model is obtained 
by in- tegrating a Lambert surface model along the circumference of the half cylinder facing the light 
source. As shown in figure 7, we integrate over the half circle visible from the light source. The back 
of the surface is not il/umlnated. The orthonormal basis formed from the three vectors t~l', b are easily 
calculated. The first basis vector is t, which is perpen- diculax to the texel base. The second vector 
E is the projection of the light vector l onto plane P containing all the normMs to the cylinder. The 
vector l t is given by r = z-(t. 1)t (lO) IIz -(t . z)ttl " It is easy to see that b, orthogonal to 
t and l ~ is calculated as b=lt. (11) These three vectors are shown in figure 6. The total amount of 
light scattered per unit length of cylinder is inte- grated over the semicircle from shadow terminator 
to shadow termina- tor (figure 7). Let us parameterize the position along the cylinder by 0 where 0 ranges 
between 0 and ~r radians. As a function of 0 the normal vector n to the cylinder is = b(cos0) + V(sin 
o). (12)  '89, Boston, 31 July-4 August, 1989 The Lambert model gives the intensity of reflected light 
as ~(~) = (kd)l. n, where /ca is the diffuse reflection coefficient. Thus to find the total amount of 
light per unit length we integrate along the circumference of the half cylinder. The line integral element 
ds along the cylinder is given in terms of 8 by r dO, so // ~dif]use = hd l" n r dO = ke r Z. (b(cosO) 
+ l'(sin 0)) dO (la) f/ = kd r l.l' sinOdO f/ = (gd)l. l' where Kd absorbs all the quantities independent 
of l and l ~. Substitut- ing the definition of l ~ into the definition yields a particularly simple expression 
for the diffuse component: l - (t. l)t ~a,.rf~,~ = K,~ l lit -(t Otll = Kd 1-(t.l) 2 (14) = Kd sin(t,l). 
Thus the diffuse fighting component is proportional to the sine between the light and tangent vectors. 
Thus if the tangent of the hair is pointing straight at the fight, the hair is dark. This is readily 
observed in real hair. The specular component Calculating the highlights on a hair requires some term 
capturing spec- ularity. We could have derived a specular term in a similar manner starting from the 
ad hoe Phong specular model. However, the process is more difficult and the resulting model quite complex. 
We chose in- stead to invent an ad hoc specular model in the same spirit as the Phong model modified 
to approxlmat~ some diffraction around the hair. The model is motivated by figure 8. Any light striking 
the hair is speeularly reflected at a mirror angle along the tangent. Since the normals on the cylinders 
point in all directions perpendicular to the tangent, the reflected light should be independent of the 
azimuthal component of the eye vector. Thus the reflected light .forms the cone whose angle at the apex 
is equal to the angle of incidence as shown in figure 8. The actual highlight intensity is given as ,po,,,, 
= k, cos~(e, e') (15) where k, is some specular refection coefficient, e is the vector pointing to the 
eye, and e n is the specular reflection vector contained in the cone closest to the eye vector, and p 
is the Phong exponent specifying the sharpness of the highlight. The highlight is thus a maximum when 
the eye vector is contained in the reflected cone and falls off v~ith a Phong dependence. To calculate 
this model we note that the only quantities entering into the calculation are the angle of incidence 
and the angle of reflection with respect to the tangent vector, 0 and 0 ~. The intensity is given by 
~]TA/apcula r ~ ha COSP 0 --OI  = hdcose cos0' + sin0 sine'), (16) = h,(t. 1 t s + sin(t, l) einCt, 
e))~ These quantities are easily calculated from the original vectors. Results !i : Figure 9 shows a 
single texel of hair. Discounting the base plane, no geometric model has been used to create this image. 
Figure 10 shows a closer view of the rightmost edge of figure 9. Note that the painter's illusion breaks 
down on the close up view. We should switch from the texel representation to actual geometry when viewing 
the model at this resolution. Figures 11, 12, 13 and 14 show a number test images displaying torli covered 
by texels, modeling brushlike fur. These show what happens when the corners of the texels are not deformed 
by . Figures 11 and 12 are identical except that figure tl was rendered with the shadows turned off, 
so that every cell is always illuminated. It is evident that self shadowing of the texel is one of the 
principal cues for realism. Figures 15 and 16 show two versions of a teddy bear. The underlying geometric 
model is identical for each bear. Different Fourier coefficients were used for defining each local texel 
deformation. Fewer, larger texels appear in figure 15. The processor time for each of these images was 
substantially the same. These images have a resolution of 1280 by 1024 pixels. No antialiasing was done. 
Precise measurements of the CPU time are somewhat problematic, as each image was rendered concurrently 
on a network of large IBM main- frames. We used a total of twelve 3090 processors and four 3081 pro- 
cessors. On average, we obtained approximately 30%-50% of each pro- cessor. Total wall clock time was 
about 2 hours. Further Work The question of how to turn geometry into texture has not yet been solved. 
Thi~ paper represents only a start on the problem. An auto- matic way of generating texel densities from 
complex geometric models is currently unknown to us. We speculate that the theory known as geometric 
measure theory may provide the key mathematical insights into this problem. Applying texels to other 
complex scenes is also left open: consider the problem of rendering a forest covering a mountainside 
in the distance. Instead of having thousands of polygons, each tree and bush could be modeled as an appropriate 
texel. When the texels themselves become very small, one can merge several into a larger texel, somehow 
adding densities and merging lighting functions. We have not modeled long hair, or curly hair; only fur. 
This is an interesting modeling task especially when one decides to include the dynamical behavior of 
long hair in an animation. We believe that the methods presented in this paper will adequately render 
long hair once the modeling problems are solved. References Blinn J.F. and Newell M.E. (1976) "Texture 
and Reflection in Computer Generated Images" Comm. ACM 19,10, 542-547. Blinn J.F. (1977) "Models of Light 
Reflection for Computer Synthesized Pic- tures" Computer Graphics 11,2, 192-198. BIinn J.F. (1978) "Simulation 
of Wrinkled Surfaces" Computer Graphics 12,3, 286-292 Blinn J.F. (1982) "Light Reflection Functions for 
Simulation of Clouds and Dusty Surfaces" Computer Graphics 16,3, 21-29. Cabral B., Max N. and Springmeyer 
R. (1987) "Bidirectional Reflectance Functions from Surface Bump Maps" Computer Graphics 21,4, 273-282. 
Catmull E.E. (1974) A Subdivision Algorithm for Computer Display of Curved Surfaces, Ph.D., U. of Utah. 
Cook R.L., Porter T. and Carpenter L. (1984) "Distributed Ray Tracing" Computer Graphics 18,3, 137-146. 
 !i?i~ 276  ~ Computer Graphics, Volume 23, Number 3, July 1989 Cook R.L. (1984) "Shade Trees" Computer 
Graphics 18,3, 223-232. Crow F.C. (1982) "A More Flexible image Generation Environment", Com- puter Graphics 
16,3, 9-18. Csuri C., Hakathorn R., Parent R., Carlson W. and Howard M. (1979) "To- wards an interactive 
high visual complexity animation system" Computer Graphics 13,2, 289-299. Drebin R.A., Carpenter L., 
and Hanrahan P. (1988) "Volume Rendering", Computer Graphics 22,4, 65-74 Kajiya J.T. and Von Herzen B. 
(1984) "Ray Tracing Volume Densities" Com- puter Graphics 18,3, 165-174. Kajiya J.T. (1985) "Anisotropie 
Reflection Models" Computer Graphics 19,3, 15-22. Krueger W. (1988) "Intensity Fluctuations and Natural 
Texturing" Computer Graphics 22,4, 213 220. Miller G.S.P. (1988) "The Motion Dynamics of Snakes and Worms" 
Computer Graphics 22,4, 169-178. Max N.L. (1986a) "Light Diffusion through Clouds and Haze" Computer 
Vi- sion, Graphics and Image Processing 33,280-292. Max N.L. (1986b) "Atmospheric Illumination and Shadows" 
Computer Graphics 20,4, 117-124. Max N.L. (1986e) "Shadows for Bump Mapped Surfaces" in Advanced Com- 
puter Graphics, Springer V., 145-156. Nishita T., Okamura I. and Nakamae E. (1985) "Shading Models for 
Point and Linear Sources" ACM Trans. on Graphics 4,2, 124-146. Nishita T., Miyawaki Y. and Nakamae E. 
(1987) "A Shading Model for At- mospheric Scattering Considering Luminous Intensity Distribution of Light 
Sources" Computer Graphics 21,4, 303-310. Ohira T. (1983) "A Shading Model for Anisotropic Reflection" 
Tech. Rep. Inst. El. and Comm. Eng of Japan (in Japanese) 82,235, 47-54. Peachey D.R (1985) "Solid Texturing 
of Complex Surfaces" Computer Graph- ics 19,3,279-286. Perlin K. (1985) "An Image Synthesizer" Computer 
Graphics 19,3, 287-296. Reeves W.T. (1983) "Particle Systems--A Technique for Modefing a Class of Fuzzy 
Objects" Computer Graphics 17,3, 359-376. Reeves. W,T. and Blau R. (1985) "Approximate and Probabilistic 
Algorithms for Shading and Rendering Structured Particle Systems" Computer Graphics 19~3, 313-322. Rushmeier 
H.E. and Torrance K.E. (1987) "The Zonal Method for Calculat- ing Light Intensities in the Presence of 
a Participating Medium" Computer Graphics 21,4, 293-302. Sabella P. (1988) "A Rendering Algorithm for 
Visualizing 3D Scalar Fields", Computer Graphics 22,4, 51-58. Takagi J., Yokoi S. and Tsuroka S. (1983) 
"Comment on the Anisotropic Reflection Model" Bull. of SIG. Graphics and CAD, Inf. Proc. Soc. of Japan. 
(in Japanese) ll,1, 1-9. Upson C., Keeler M. (1988) "VBUFFER: Visible Volume Rendering", Com- puter Graphics 
22,4, 59-64. Acknowledgments Thanks to A1 Barr for technical discussions, and to Hewlett Packard Corpo- 
ration for their donation of the HP9000 Model 350SRX workstations to the Caltech Computer Science Graphics 
Lab. Our appreciation to John Snyder for modeling and remodeling (and reremod- chug) the bear, We wish 
to express our thanks to IBM and Alan Norton of IBM T.J. Watson Research Center at Yorktown Heights their 
financial support and gracious donation of a considerable amount of 3090 time, We also th~nk the reviewers 
whose many comments have been invaluable in improving our exposition. \ f /\ -ur~ L j/ !  t \ \ I 
l  '89, Boston, 31 July-4 August, 1989 +. 72 ~8    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74362</article_id>
		<sort_key>281</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Antialiased ray tracing by adaptive progressive refinement]]></title>
		<page_from>281</page_from>
		<page_to>288</page_to>
		<doi_number>10.1145/74333.74362</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74362</url>
		<abstract>
			<par><![CDATA[We describe an antialiasing system for ray tracing based on adaptive progressive refinement. The goals of the system are to produce high quality antialiased images at a modest average sample rate, and to refine the image progressively so that the image is available in a usable form early and is refined gradually toward the final result.The method proceeds by adaptive stochastic sampling of the image plane, evaluation of the samples by ray tracing, and image reconstruction from the samples. Adaptive control of the sample generation process is driven by three basic goals: coverage of the image, location of features, and confidence in the values at a distinguished "pixel level" of resolution.A three-stage process of interpolation, filtering, and resampling is used to reconstruct a regular grid of display pixels. This reconstruction can be either batch or incremental.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P126305</person_id>
				<author_profile_id><![CDATA[81100400443]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Painter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P155287</person_id>
				<author_profile_id><![CDATA[81100524612]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sloan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>356797</ref_obj_id>
				<ref_obj_pid>356789</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bentley, Jon L. and Friedman, J.J. Data Structures for range searching. ACM Comp. Surv. 11, 4 (1979), 397-409.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bergman, Larry, Fuchs, Henry, Grant, Eric and Spach, Susan Image Rendering by Adaptive Refinement. Computer Graphics 20, 4 (Aug., 1986), 29-37, Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blanford, Ronald P., Painter, James S. and Sloan, Kenneth R. Adaptive Sampling, Transmission, and Rendering of Images. SPIE Proceedings 1077 (Jan., 1989), SPIE Conference on Human Vision, Visual Processing, and Digital Display.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617478</ref_obj_id>
				<ref_obj_pid>616004</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. Return of the Jaggy. IEEE Computer Graphics and Applications 9, 2 (Mar., 1989), 82-89.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Burr, Irving W. Applied Statistical Methods. Academic Press, New York, NY, 1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cendes, Zoltan J. and Wong, Steven H. C~ Quadratic Interpolation Over Arbitrary Point Sets. IEEE Computer Graphics and Applications 7, 11 (Nov., 1987), 8-16.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Chert, Shenchang E., Wallace, John R. and Greenberg, Donald P. A Progressive Refinement Approach to Fast Radiosity Image Generation. Computer Graphics 22, 4 (Aug., 1988), 75-82, Proceedings of SIGGRAPH '88 (Atlanta, Georgia, August 1-5, 1988).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L. Stochastic Sampling in Computer Graphics. ACM Transactions on Graphics 5, 1 (Jan., 1986), 51-72.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Porter, Thomas and Carpenter, Loren Distributed Ray Tracing. Computer Graphics 18, 3(July, 1984), 137-146, Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C. Summed-Area Tables for Texture Mapping. Computer Graphics 18, 3 (July, 1984), 207-212, Proceedings of SIGGRAPH '84, (Minneapolis, Minnesota, July 23-27, 1984).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Dipp6, Mark A.Z. and Wold, E.H. Antialiasing through Stochastic Sampling. Computer Graphics I9, 3 (July, 1985), 69-78, Proceedings of SIGGRAPH '85, (San Francisco, California, July 22-26, 1985).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T. The Rendering Equation. Computer Graphics20, 4(Aug., 1986), 143-150, Proceedings of SIGGRAPH '86, (Dallas, Texas, August 18-22, 1986).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lee, Mark E., Redner, Richard A. and Uselton, Samuel P. Statistically Optimized Sampling for Distributed Ray Tracing. Computer Graphics 19, 3 (July, 1985), 61-67, Proceedings of SIGGRAPH '85 (in San Francisco, CA, July 22-26, 1985).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Lounsbery, J. Michael The Renaissance Modeling System. Dept. of Computer Science, Univ. of Washington, Tech. Rep. #89-01-05, Jan., 1989.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mitchell, Don P. Generating Antialiased Images at Low Sampling Densities. Computer Graphics 21, 4 (July, 1987), 65--69, Proceedings of SIGGRAPH '87 (Anaheim, CA, July 27-31, 1987).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37430</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Naiman, Avi and Foumier, Alain Rectangular Convolution for Fast Filtering of Characters. Computer Graphics21, 4 (July, 1987), 233-242, Proceedings of SIGGRAPH '87, (Anaheim, CA, July 27-31, 1987).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Preparata, Franco P. and Shamos, Michael I. Computational Geometry: An Introduction. Springer-Verlag, New York- Heidelberg-Berlin, 1985.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner J. An Improved Illumination Model for Shaded Display. Communications of the ACM 23, 6(June, 1980), 343-349.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Yellott, James I. Jr. Spectral Consequences of Photoreceptor Sampling in the Rhesus Retina. Science 221 (July, 1983), 392- 385.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Antialiased Ray Tracing by Adaptive Progressive Refinement James Painter and Kenneth Sloan University 
of Washington ABSTRACT We describe an antialiasing system for ray tracing based on adaptive progressive 
refinement. The goals of the system are to produce high quality antialiased images at a modest average 
sample rate, and to refine the image progressively so that the image is available in a usable form early 
and is refined gradually toward the final result. The method proceeds by adaptive stochastic sampling 
of the image plane, evaluation of the samples by ray tracing, and image reconstruction from the samples. 
Adaptive control of the sample generation process is driven by three basic goals: coverage of the image, 
location of features, and confidence in the values at a distinguished "pixel level" of resolution. A 
three-stage process of interpolation, filtering, and resam- pling is used to reconstruct a regular grid 
of display pixels. This reconstruction can be either batch or incremental. CR Categories and Subject 
Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation - Display algorithms Additional Keywords 
and Phrases: Adaptive Sampling, An- tialiasing, Filtering, Progressive Refinement, Ray Tracing. Department 
of Computer Science, FR-35 Seattle WA 98195 U.S.A. This work was supported in part by the National Science 
Foundation under grant numbers DCR - 8505713, CCR - 8612543, and IRI -8081932. Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0281 
$0035 1. Introduction Raster graphics is inherently a sampling process. A render- ing program is given 
a scene description and should produce a "realistic" approximation of it for display. The scene description 
and the physical model of lighting embodied in the rendering program define an image function giving 
a color at each point in a continuous domain representing the screen plane. The rendering program's output 
is a discrete array of pixel values representing colors at points on a discrete regular grid representing 
the screen. Because rendering is a sampling process, it is prone to aliasing artifacts where the frequency 
spectrum of the image function is not band limited before sampling. Ray casting methods of rendering 
have become popular in the last several years. Their benefits include conceptual simplicity and the ability 
to model complex lighting effects such as shadows, transparency, and reflections. One of the major disadvantages 
has been their susceptibility to aliasing artifacts. These methods are prone to aliasing because they 
sample the image function only at discrete points in its domain. Aliasing can be reduced, however, if 
the sampling pattern is generated by a stochastic process which is uncorrelated with the image function. 
These randomly placed samples can be filtered and resampled at the screen resolution for display. Ray 
tracing is a very slow process, particularly when an-tialiasing algorithms are used. Should a mistake 
be made in constructing the model for rendering, hours of cpu time may be lost before the error is realized. 
Typically, low resolution images are created first for previewing and then discarded. A ray tracing algorithm 
which produces a usable image relatively quickly and refines it gradually to the final image would alleviate 
this problem. This paper describes a new method for antialiased ray tracing which proceeds by adaptive 
subdivision of the image plane. 2. Prior Work Several researchers [2], [7] have explored the idea of 
pro- gressive refinement in image generation. The main difference in this work is the rendering method. 
Our method is based on ray tracing rather than z-buffer [2], or radiosity [7] algorithms. Our own earlier 
work [3] relates progressive refinement in image transmission to the rendering problem. Previous researchers 
in the area of antialiased raytracing have been concerned with three subproblems: selection of efficient 
sampling patterns, methods to adaptively control the sample rate, and filters for image reconstruction. 
 ':~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 2.1 Sampling Pattern Selection Stochastic sampling 
methods for image synthesis have been reported in [9], [8], [11], and [15]. The qualities desired in 
a stochastic sampling pattern are that it minimize visible aliasing artifacts, minimize visible noise, 
and be efficiently evaluated. The spectral characteristics of the noise are also important: the human 
visual system is more sensitive to narrow-band noise than broad- band noise and to low frequency noise 
rather than high frequency noise. The noise properties of a sampling pattern can be evaluated by examining 
the Power Spectral Density of the sampling pattern applied to a constant image function. Two families 
of sampling patterns have been examined in the literature: Jittered sampling divides the domain to be 
sampled into a regular lattice of rectangular cells. A sample is distributed uniformly into each lattice 
cell. Jittered sampling ensures that the sampling pattern avoids large gaps. Poisson Disk distributions 
sample over the domain uniformly but with the added constraint that no two samples may be closer than 
a specified minimum distance. Poisson disk sampling ensures that the sampling pattern avoids excessive 
clumping. The Poisson disk distribution has been used as a model for the distribution of photoreceptors 
in primates [191. The relative merits of jittered sampling and Poisson disk sampling have been discussed 
in [11], [8], and [15]. Jittered sampling is favored by Cook because the samples can be produced efficiently. 
Mitchell favors the spectral properties of Poisson disk distributions because they minimize low frequency 
noise introduced in the sampling processes. He gives an algorithm for efficiently approximating a Poisson 
disk distribution at a fixed sample rate. A variant of jittered sampling, hierarchical sampling, has 
been used effectively with a variable sample rate. 2.2 Adaptive Sampling Rate Computer-generated images 
do not exhibit uniform local image variation. Edges between objects are areas of high contrast (or variance), 
while large, uniform objects and backgrounds yield regions which have little local variation. Adaptive 
sampling adjusts the sample rate locally to concentrate samples where they are needed most: at edges 
and other regions of high contrast. This can substantially reduce the number of samples required to achieve 
the desired image accuracy. Adaptive sampling requires an error estimator and a stopping condition. The 
error estimator indicates how closely the sample values represent the local mean of the image function, 
or alter- natively, the local noise level present in the sampled image. The stopping condition is a threshold 
on the error estimator used to determine when enough samples have been taken. Lee, Redner and Uselton 
[13] present an error estimator based on local image variance. Their sampling approach is based on area 
sampling of each pixel, evaluating the output image as an expected value of the input image sampled over 
an area. Under the assumption that the image function has a normal distribution locally (a questionable 
assumption), they develop a confidence interval test which gives the probability that the variance of 
the sample mean is below a specified tolerance. Sampling continues until the desired probability is reached. 
Traditionally, stopping conditions for simulation experiments are based on a confidence interval of the 
mean estimator itself rather than its variance [5]. The error estimator given in [13] does not directly 
specify a desired confidence interval of the mean but instead, of its variance. Since the mean is the 
parameter we are interested in estimating, it would be more appropriate to apply the confidence interval 
analysis to it directly. Dipp6 and Wold [11] propose a different error estimate based on the root mean 
square signal to noise ratio (RMS SNR) of the stochastically sampled and reconstructed image function. 
They show that the RMS SNR is proportional to the square root of the sample rate. The constant of proportionality 
depends on the image function and the reconstruction filter but is independent of sample rate. The RMS 
SNR is approximately the absolute value of the difference between the stochastically sampled and filtered 
function and the perfectly filtered function. This allows an estimate of the rate of change of the RMS 
SNR as a function of the square root of the sample rate to be estimated from the sampled and filtered 
image at two different sample rates. Mitchell [15] suggests that variance is not an appropriate measure 
of perceived image variation, because the human visual system does not exhibit linear response properties 
to rapid changes in intensity. Instead, he proposes that contrast is a better measure. Adaptive sample 
rate control places an additional burden on the sample generation scheme. Since it is not known in advance 
how many samples are to be taken, every prefix of an ordered set of samples should be well distributed 
over the sample area. Algorithms which produce samples in a raster scan order are unsuitable. The hierarchical 
sampling method given in [12] is a suitable method for generating jittered sampling patterns. Dipp6 suggested 
that Poisson Disk samples can be created in a uniform order by coupling the minimum distance constraint 
to the local sample rate. As more samples are needed in a given area, the minimum distance is decreased. 
Mitchell avoids the problem by using a very limited form of adaptation with only two different sample 
rates Mitchell [15] uses a two level technique to accomplish a limited form of sample rate adaptation. 
The image is first sampled at a moderate sampling rate. Areas of high contrast are sampled at a higher 
rate. Contrast is measured over a neighborhood of approximately 8 samples. This avoids the problems of 
previous methods which required many samples per pixel just to determine the image variation over a single 
sampling region. It is liable, however, to completely miss small objects which fall between the samples 
in the initial, rather coarse, sampling.  2.3 Image Reconstruction Once the input image function has 
been sampled at a set of stochastic sample points, it must be filtered prior to resampling for display. 
Filtering accomplishes two purposes. First, the image function should be filtered to limit its high frequency 
content to avoid aliasing when it is resampled for display. Second, the filter can be used to attenuate 
noise introduced in the stochastic sampling process. The properties of a filter depend on its width and 
its shape. Practical filters have a finite width, that is, they are non-zero except on a finite region. 
Commonly used filter shapes include box filters, triangular filters, raised cosine filters and Gaussian 
filters. The choice of filter width and shape depends on the desired attenuation of frequencies above 
Nl/2 (the Nyquist limit), and the tolerance for attenuation of frequencies below Nx/2. In addition, the 
computational costs must be considered. Extremely wide filters are expensive to compute by direct convolution. 
A varying sample rate compounds the problem of applying a filter. The number of samples under the filter 
kernel will vary depending on the local sample rate. If direct convolution is used, areas with more samples 
appear brighter than areas with fewer samples. Dipp6 suggested that the filter should be normalized: 
the sum of the weighted sample values should be divided by the sum of the filter weights. A normalized 
filter improves matters but does not eliminate the problem. Some consideration must be made for the size 
of the region each sample represents. Otherwise, image values in areas of dense sampling will dominate 
nearby' areas which are sparsely sampled. Ideally, we would like to weight each sample point by the volume 
contained under the filter function over the area the sample represents. The hierarchical sampling method 
associates a cell with each sample. This cell provides a natural region for use in weighting the sample. 
Mitchell attacl&#38; the problem with a multi-stage filter. The sampled image function is filtered multiple 
times with filters of wider and wider support, resulting in lower and lower cutoff frequencies. The narrow 
filters in the early stages average densely sampled regions into single samples covering a larger region. 
Subsequent stages average these larger regions into pixel sized samples for display. Mitchell used four 
stages of box filters with three different widths. While a single box filter does not provide adequate 
high frequency attenuation, repeated box filtering does, approaching a Gaussian filter in the limit. 
3. System Description Our method is composed of three stages: sample generation, sample evaluation and 
image reconstruction (resampling). 3.1 Sample Generation The purpose of the sample generator is to choose 
points in the spatial domain of the image where the image function is to be evaluated. Information from 
prior samples is used to decide which areas of the image have the greatest need for additional samples. 
In addition, the sample generator determines when to stop sampling. It should also order the samples 
to allow for progressive refinement of the rendered image. Early methods [ 13], [ 12] treat the sample 
generation problem independently at each pixel. Each pixel is sampled until a stopping condition is meet. 
Samples taken for one pixel are not used for other pixels. One of the major problems with this approach 
is that a fairly high minimum sample rate (typically 8 samples per pixel) is required simply to determine 
that a pixel is uninteresting and need not be sampled further. Later work [15] lowers the average sample 
rate, in part by sharing samples between pixels. This lowers the minimum sample rate required to evaluate 
the stopping condition. [15] uses a very simple, two level stopping condition. The image is first sampled 
at a coarse sample rate. Selected areas are sampled at a finer rate as needed. It is our belief that 
a further reduction in the sample rate will be realized if the sample rate is allowed to vary over a 
wider range of values. Our sample generator is based on hierarchical integration, a sampling method described 
by Kajiya in [12]. Kajiya applied hierarchical integration independently to each pixel. We apply the 
technique to refine the entire image plane. 3.1.1 Data Structures In our implementation, as in [12], 
the sample generator maintains a k-D tree [1] containing all the samples taken. The k-D tree is a binary 
tree which partitions the two dimensional image plane by alternately splitting in x and y. On even levels, 
the domain is split along a line parallel to the x axis. On odd levels, the domain is split along lines 
parallel to the y axis. The leaf nodes in the tree store the raw sample values and positions. An internal 
node of the tree stores an estimate of the mean value of the image function over the region covered by 
that node, an estimate of the variance of this mean estimate (internal variance), and the number of samples 
in the subtree rooted at this node. All nodes also store an external measure of variance. The external 
variance is computed from the mean estimates of the node and all of its neighbors at the same level in 
the tree. 3.1.2 Refinement Rules When a new sample is needed, a path from the root to a leaf is followed 
leading to the region with the greatest need for further refinement. At each (binary) branch in the k-D 
tree, a decision is made as to which subnode to refine. The decision is based on the variance estimates 
(both internal and external) of the node, the area of the node, the number of samples already contained 
in the node and the level of the node in the tree. We distinguish a level of the tree, called the pixel 
level which is the level of the tree corresponding to pixels in the anticipated reconstruction. The goal 
of the refinement process is to produce the best answers at the pixel level. This leads to different 
strategies above and below the pixel level. At coarse levels, above the pixel level, we are driven by 
the progressive refinement goals: Coverage --refine large regions before smaller ones and Feature Location 
--refine "edge" cells before non "edge" cells. A heuristic is required to rank the pixel level nodes 
according to refinement priority. We use the product of external variance and area as a priority measure. 
The area term enforces the coverage goal while the external variance enforces the feature location goal. 
Nodes at the pixel level, or leaves above the pixel level, are assigned a priority by direct computation. 
Internal nodes above the pixel level are assigned a priority value which is the maximum of the two child 
priority values. Thus, a path can be followed from the root to the highest priority pixel by always branching 
toward the subnode with higher priority (ties are broken randomly.) At finer levels, below the pixel 
level, our only goal is to increase our confidence in the mean of the pixel level node above. To do this, 
we use the principles of stratified sampling [13]. If two subnodes have mean estimates of #~ and It2 
and mean estimate variances of crj and ~r2 and are of equal area, the mean of the parent node can be 
estimated as It = (It1 + It2)/2 with variance of the mean estimate given by ~r = (~rl + ~r2)/4. This 
mean estimate is often better and never worse than that given by the mean of all the sample values. If 
we want to improve the mean estimate of the parent node, the best choice is to refine the subnode with 
the highest mean variance. This is the only refinement principle used in hierarchical sampling [12] since 
it only operates below the pixel level. 3.1.3 Stopping Condition The stopping condition is based on 
a confidence interval test. A desired confidence level and confidence interval is selected. For example, 
we require that 99% of the time (or = .01, the confidence level) the mean estimate at each pixel will 
be within 1/255 (the confidence interval) of the correct value. We can take into account the nonlinear 
response characteristics of human visual perception by allowing the confidence interval to vary with 
the mean estimate value. For example, we might specify that small mean estimates require a smaller confidence 
interval than large mean estimates. The confidence interval for a given confidence level can be computed 
from the variance of the mean estimate and the number   ~,...~SIGGRAPH '89, Boston, 31 July-4 August, 
1989 of samples taken, [5]. If the desired confidence level is 1 -c~, the confidence interval is given 
by t~/2a where t~/2 is taken from the student-t distribution with n -1 degress of freedom, n is the number 
of samples contributing to the mean estimate, and a is the variance of the mean estimate. When the sample 
count within a pixel node is small, the mean estimate variance can approximated from the external vari- 
ance. A subtree rooted at a pixel level node is "'closed off" when the confidence interval at the desired 
confidence level becomes at least as small as the desired confidence interval. Once closed off, no more 
samples will be taken within the subtree. An internal node above the pixel level is closed off when both 
of its offspring are closed. The confidence interval test is not the only stopping con-dition. A coverage 
condition is imposed to ensure that small objects are not missed completely. We require that all nodes 
are refined at least to the pixel level to ensure that no objects larger than one pixel are missed. Note 
however that no direct limit on the number of samples within a pixel is required. An upper bound on number 
of samples per pixel can be determined from the confidence interval and confidence level requirements. 
3.2 Sample evaluation The purpose of the sample evaluator is to evaluate the image function at a single 
point in the image plane. In this implementation, the image function is evaluated by a ray tracing algorithm 
[18]. The sample evaluator used here is part of Renaissance, a modelling and rendering system developed 
at the University of Washington [14]. 3.3 Reconstruction The purpose of the reconstruction process is 
to resample the image function on a regular grid for display. This can be considered as a three step 
process: First, an interpolation scheme is used to interpolate color values between the samples generated 
by the sample generator. Next, the resulting image function is convolved with a low-pass filter to reduce 
aliasing and to attenuate high frequency noise introduced in the original sampling process. Finally, 
the filtered image function is point sampled at the center of each pixel of the display. In practice, 
the last two steps are combined so that the filtered image function need only be evaluated at the center 
of each display pixel. 3.3.1 Piecewise Constant Interpolation We first consider a very simple interpolant: 
piecewise con-stant. While the interpolant is not particularly well behaved (it's not continuous) it 
makes the filter convolution computationally efficient. The k-D tree data structure generated during 
sampling pro- vides a basis for our interpolation scheme. The data structure partitions the plane into 
rectangular cells aligned with the coordi- nate axes, each containing exactly one sample point. An obvious 
interpolant, albeit not a continuous one, is to assign the value of the sample to the entire cell in 
which it is contained. This gives a piecewise constant image function defined everywhere in the image 
plane. The piecewise constant form of the interpolated image func- tion can be exploited to simplify 
filtering. Convolution of a filter with a constant function reduces to integration of the filter function. 
i(u, v) * f(u, v) = j j$ z(u , v')f(u -u , v -v') du' dv' = C ~JR f(u -u', v -v') du' dr' where i(u, 
v) is constant with value C over the region R and zero elsewhere. To find the contribution one of the 
sampling cells makes on a display pixel, we need only integrate the filter function over the sample cell 
and multiply it by the value in the cell. The filtered image value at a pixel is evaluated by summing 
the contributions from all the sample cells which overlap the domain of the filter function centered 
at the pixel. I(x,y)=~C(s) ]] f(u -u',v-v')da' dv' (3.1) sES J J Rn~ where 1 is the value to be assigned 
to pixel (x, y), S is the set of sample cells that overlap the filter support, and R is the filter support 
centered at pixel (z, y). For polynomial filters, the integral can be evaluated ana-lytically. When analytic 
integration is intractable, the filter can integrated approximately and stored in a summed area table 
as described in [ 10]. The summed area table stores the pre-integrated filter function. Integrals of 
the filter function over sample ceils can be evaluated by querying the filter summed area table at the 
corners of the sample cell. The idea of storing the filter function in a summed area table has been explored 
in font filtering, [16]. A bivariate filter function f(~, v) is separable if it can be decomposed into 
the product of two univariate filters, fl(u)f2(v). Most filters used in computer graphics are separable. 
A separable filter kernel can be stored more compactly as two 1-D summed area tables rather than one 
2-D summed area table. The space required is O(N) rather than O(N 2) where N is the number of discrete 
intervals used to approximate the filter. The example images shown in the figures were reconstructed 
using a Lanczos windowed sinc filter [4] over a 7x7 pixel filter support. The filter was discretized 
and stored as a 1-D summed area table with 4096 entries. 3.3.2 Higher Degree Interpolants The method 
described above uses a particularly simple interpolant to simplify convolution with the filter function. 
We are currently considering reconstruction methods using higher quality interpolants. First, the sample 
points can be used to triangulate the image plane using a Delaunay triangulation, [17]. A triangle based 
interpolation scheme can be used to interpolate a surface through the sample values. The simplest interpolation 
scheme is piecewise planar: interpolate within each triangle in the plane formed by the three triangle 
vertices. This scheme produces an image function which is C , but not C ~. C ~ triangle based interpolation 
is also possible [61. Next, the interpolated image function must be convolved with the filter function 
and evaluated at the pixel centers. When the filter function and the image function are both piecewise 
polynomial, this convolution can be performed analytically. When analytic convolution is not tractable, 
a discrete approximation may be used. However, the usual summed area table requires rectangular regions. 
We are currently exploring appropriate data structures for discrete convolution over triangular patches. 
 3.3.3 Progressive Reconstruction One of the the goals of this work is to have the rendered image available 
in a usable form very early in the rendering process and to progress incrementally toward the final result. 
We have seen that the sample generator meets this goal. In this section we consider the impact of the 
progressive refinement goal on reconstruction algorithms. When the time required for reconstruction is 
much smaller than the sample generation and evaluation time, the image can be reconstructed from scratch 
from the available samples each time an update is desired. Hence, a fast batch method may be adequate 
for viewing intermediate results. A slower, higher quality reconstruction method can be used for the 
final image. An alternative is an incremental reconstruction scheme. Each time a new sample is taken, 
the pixels affected by the sample are updated. The reconstruction method described in section 3.3.1 is 
batch oriented. The value of a each pixel is determined only after all the samples which affect it are 
known. With a little effort, the computation can be reordered to allow an incremental algorithm. When 
a sample cell is created, a single term from the sum in equation 3.1 can be evaluated. This term can 
be added to a running sum for the pixel. This must be done for every pixel affected by the sample cells, 
those whose filter supports overlap the sample cell. When a sample cell is subdivided, its contribution 
must be subtracted from the pixels it affects and the contribution of its new subcells added in. The 
reconstruction methods described in section 3.3.2 can also be evaluated incrementally by the use of an 
incremental Delaunay triangulation algorithm. Each time a triangular tile is included or removed, its 
contribution to each pixel affected is evaluated and added or subtracted respectively. 4. Performance 
Two test images are shown in Figures 2 and 3 to illustrate the performance of the system. The tables 
below give performance statistics for the system when evaluating the two test images. The cpu time is 
divided into three categories: sample genera- tion, sample evaluation, and reconstruction. Note that 
sample evalutation time dominates. The cost of evaluating samples via ray tracing is high enough that 
the time spent generating sample points and filtering the samples for reconstruction is relatively unimportant. 
Note that as the resolution increases the average sample rate decreases. This is accounted for by the 
fact that with increasing resolution, the ratio of "edge" pixels to "internal" pixels in general decreases. 
Images involving fractal based textures may not show this behavior. Figures 4 and 5 show the number of 
rays required at each pixel as an intensity image. The intensity image is scaled from full black at 0 
samples per pixel to full white at 20 samples per pixel. Any pixels above 20 samples per pixel are painted 
red. The histograms of the number of samples show that nearly all pixels require fewer than 10 samples 
per pixel. Comparisons with data reported in [13] show a significant reduction in the sample rate required. 
It is difficult to compare our performance figures with [15] since he did not report comparable statistics. 
5. Conclusions We have presented a rendering system which produces high quality antialiased images with 
relatively low average sample densities. A single adaptive sampling mechanism can be used to achieve 
several, sometimes conflicting, goals. This method generalizes hierarchical integration [12]. At coarse 
levels of resolution, we concentrate on producing a low-quality sketch of the final image. The emphasis 
is on detecting objects and features (such as edges.) Subsequent samples are aimed at refining these 
features. Finally, we concentrate on improving the accuracy of averages over "pixel-sized" pieces of 
the image. The quality of images reconstructed from these samples is roughly the same everywhere in the 
image. The amount of work done can be controlled interactively ("that looks good enough") or by a pre-set 
specification of the image quality. A two parameter family of reconstruction algorithms for scattered 
samples has been presented. The methods consist of three phases: interpolation, filtering and resampling. 
The interpolation scheme and reconstruction filter may be selected to choose a particular reconstruction 
method from this family. 6. Acknowledgements Dan O'Donnell provided the lamp model. Gemini Lasswell provided 
the solid texture function for the teapot. Thanks to the UW Grail group for providing a rich supply of 
ideas and a software base to build on. ':L,f~SIGG RAPH '89, Boston, 31 July-4 August, 1989 References 
1. Bentley, Jon L. and Friedman, J.J. Data Structures for range searching. ACM Comp. Surv. I1, 4 (1979), 
397---409. 2. Bergman, Larry, Fuchs, Henry, Grant, Eric and Spach, Susan Image Rendering by Adaptive 
Refinement. Computer Graphics 20, 4(Aug., 1986), 29-37, Proceedings of SIGGRAPH '86 (Dallas, Texas, August 
18-22, 1986). 3. Blanford, Ronald P., Painter, James S. and Sloan, Kenneth R. Adaptive Sampling, Transmission, 
and Rendering of Images. SPIE Proceedings 1077 (Jan., 1989), SPIE Conference on Hu- man Vision, Visual 
Processing, and Digital Display. 4. Blinn, James E Return of the Jaggy. IEEE Computer Graph- ics and 
Applications 9, 2 (Mar., 1989), 82-89. 5. Burr, Irving W. Applied Statistical Methods. Academic Press, 
New York, NY, 1974. 6. Cendes, Zoltan J. and Wong, Steven H. C l Quadratic Inter- polation Over Arbitrary 
Point Sets. IEEE Computer Graphics and Applications 7, 11 (Nov., 1987), 8-16. 7. Cohen, Michael E, Chert, 
Shenchang E., Wallace, John R. and Greenberg, Donald E A Progressive Refinement Approach to Fast Radiosity 
Image Generation. Computer Graphics 22, 4 (Aug., 1988), 75-82, Proceedings of SIGGRAPH '88 (Atlanta, 
Georgia, August 1-5, 1988). 8. Cook, Robert L. Stochastic Sampling in Computer Graphics. ACM Transactions 
on Graphics5, I (Jan., 1986), 51-72. 9. Cook, Robert L., Porter, Thomas and Carpenter, Loren Dis-tributed 
Ray Tracing. Computer Graphics 18, 3 (July, 1984), 137-146, Proceedings of SIGGRAPH '84 (Minneapolis, 
Min- nesota, July 23-27, 1984). 10. Crow, Franklin C. Summed-Area Tables for Texture Mapping. Computer 
Graphics 18, 3 (July, 1984), 207-212, Proceedings of SIGGRAPH '84, (Minneapolis, Minnesota, July 23-27, 
1984). 11. Dipp6, Mark A.Z. and Wold, E.H. Antialiasing through Stochastic Sampling. Computer Graphics 
I9, 3 (July, 1985), 69-78, Proceedings of SIGGRAPH '85, (San Francisco, Cali- fornia, July 22-26, 1985). 
 12. Kajiya, James T. The Rendering Equation. Computer Graph- ics20, 4(Aug., 1986), 143-150, Proceedings 
of SIGGRAPH '86, (Dallas, Texas, August 18-22, 1986). 13. Lee, Mark E., Redner, Richard A. and Uselton, 
Samuel E Statistically Optimized Sampling for Distributed Ray Tracing. Computer Graphics 19, 3 (July, 
1985), 61-67, Proceedings of SIGGRAPH '85 (in San Francisco, CA, July 22-26, 1985). 14. Lounsbery, J. 
Michael The Renaissance Modeling System. Dept. of Computer Science, Univ. of Washington, Tech. Rep. #89-01-05, 
Jan., 1989. 15. Mitchell, Don P. Generating Antialiased Images at Low Sam- pling Densities. Computer 
Graphics 21, 4 (July, 1987), 65-69, Proceedings of SIGGRAPH '87 (Anaheim, CA, July 27-31, 1987). 16. 
Naiman, Avi and Fournier, Alain Rectangular Convolution for Fast Filtering of Characters. Computer Graphics21, 
4(July, 1987), 233-242, Proceedings of SIGGRAPH '87, (Anaheim, CA, July 27-31, 1987). 17. Preparata, 
Franco P. and Shamos, Michael I. Computa-tional Geometry: An Introduction. Springer-Verlag, New York- 
Heidelberg-Berlin, 1985. 18. Whitted, Turner J. An Improved Illumination Model for Shaded Display. Communications 
of the ACM 23, 6 (June, 1980), 343-349.  19. Yellott, James I. Jr. Spectral Consequences of Photoreceptor 
Sampling in the Rhesus Retina. Science 221 (July, 1983), 392- 385. Samples per Pixel Histogram for Lamp 
Image (512x512) 120~ 100 - 80 --Number of 60 - Pixels (x 103) 40 -i 20 - 02 5 t0 15 20 25 Figure 1. 
The k-D subdivision of the image plane. The bold path Samples per Pixel leads to the next node to be 
subdivided. Samples per Pixel Histogram for Teapot Image (512x512) Algorithm Performance: Lamp Image 
 120 Cpu time (seconds) 100 Resolution Generate I Evaluate Reconstruct Rays per Pixel 64 250.5 2900 
286.1 5.002930 80 Number 128 753.9 9800 906.6 3.905520 of Pixels 60 256 2117.9 33900 2883.7 3.012775 
(N 103) 40 512 7075.3 103620 9505.7 1.880589 20 0 --1 5 10 15 20 25 Algorithm Performance: Teapot Image 
 Samples per Pixel Cpu time (seconds) Resolution Generate Evaluate Reconstruct Rays per Pixel 64 125.1 
710 169.2 2.607670 128 456.8 2680 605.6 2.347838 256 1777.9 9594 2276.7 2.139068 512 6466.6 34217 8629.7 
1.970165  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74363</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Ray tracing deterministic 3-D fractals]]></title>
		<page_from>289</page_from>
		<page_to>296</page_to>
		<doi_number>10.1145/74333.74363</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74363</url>
		<abstract>
			<par><![CDATA[As shown in 1982, Julia sets of quadratic functions as well as many other deterministic fractals exist in spaces of higher dimensionality than the complex plane. Originally a boundary-tracking algorithm was used to view these structures but required a large amount of storage space to operate. By ray tracing these objects, the storage facilities of a graphics workstation frame buffer are sufficient. A short discussion of a specific set of 3-D deterministic fractals precedes a full description of a ray-tracing algorithm applied to these objects. A comparison with the boundary-tracking method and applications to other 3-D deterministic fractals are also included.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P123372</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electronic Visualization Laboratory, University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39078342</person_id>
				<author_profile_id><![CDATA[81100455127]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Sandin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dept, of Mathematics, Statistics and Computer Science, University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31083915</person_id>
				<author_profile_id><![CDATA[81100470405]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Kauffman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dept, of Mathematics, Statistics and Computer Science, University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>59931</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F. Fractals Everywhere. Academic Press, New York, 1988.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15918</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, A. H. Ray tracing deformed surfaces. Computer Graphics 20, 4 (1986), 287-296.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blanchard, P. Disconnected Julia sets. Chaotic Dynamics and Frac~als (1986), 181-201.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325176</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bouville, C. Bounding ellipsoids for ray-fractal intersection. Computer Graphics 19, 3 (1985), 45-51.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Branner, B., and Hubbard, J. H. The iteration of cubic polynomials, Part I: The global topology of the parameter space. Acta Mathema~ica 160, 3 ( 988), 43-20 .]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61163</ref_obj_id>
				<ref_obj_pid>61153</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fisher, Y. The Science of Fractal Images. Springer-Verlag, New York, 1988, ch. Exploring the Mandelbrot Set, pp.-287-296.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hamilton, W. R. Elements of Quaternions, 3rd ed. Vol. 1-2, Chelsea Publishing Company, New York, 1969.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hart, J. C. Image Space Algorithms for Visualizing Quaterniou Julia Sets. Master's thesis, University of Illinois at Chicago, 1989.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357324</ref_obj_id>
				<ref_obj_pid>357323</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T. New techniques for ray tracing procedurally defined objects. A CM Transactions on Graphics 2, 3 (1983), 161-181.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Levoy, M. Display of surfaces from volume data. IEEE Computer Graphics and Applications 8, 3 (1988), 29-37.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, B. B. Fractal aspects of the iteration of z ~ Az(1 - z) for complex A and z. Annals New York Academy of Sciences 357 (1980), 249-259.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, B. B. The Fractal Geometry of Nature, 2nd ed. Freeman, San Francisco, 1982.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Milnor, J. Computers in Geometry and Topology. Marcel Dekker, Inc., 1989, ch. Selfsimilarity and hairiness in the Mandelbrot set, pp. 211-257.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801263</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Norton, V. A. Generation and rendering of geometric fractals in 3-D. Computer Graphics 16, 3 (1982), 61-67.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Norton, V. A. Julia sets in the quaternions. To appear in Computers and Graphics.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Norton, V. A., and Melton, E. A close encounter in the fourth dimension. SIGGRAPIt Video Review 39 (1988), 30.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61158</ref_obj_id>
				<ref_obj_pid>61153</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Peitgen, H. The Science of Fractal Images. Springer-Verlag, New York, 1988, ch. Fantastic Deterministic Fractals, pp. 169-218.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Peitgen, H., and Richter, P.H. The Beauty of Fractals. Springer-Verlag, New York, 1986.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617443</ref_obj_id>
				<ref_obj_pid>616002</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, P., and Sandness, G. Koch curve as attractors and repellers. {EEE Computer Graphics and Applications 8, 6 (1988), 26-40.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I., Sproul, R., and Schumacker, R. A characterization of ten hidden-surface algorithms. Computing Surveys 6, 1 (1974), 1-55.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ ~ Computer Graphics, Volume 23, Number 3, July 1989 Ray Tracing Deterministic 3-D Fractals John C. 
Hart*, Daniel J. Sandin*, Louis H. Kauffman t *Electronic Visualization Laboratory tDept, of Mathematics, 
Statistics and Computer Science University of Illinois at Chicago Abstract As shown in 1982, Julia sets 
of quadratic functions as well as many other deterministic fractals exist in spaces of higher dimensionality 
than the complex plane. Originally a boundary-tracking algorithm was used to view these structures but 
required a large amount of storage space to operate. By ray tracing these objects, the storage facilities 
of a graphics work- station frame buffer are sufficient. A short discussion of a specific set of 3-D 
deterministic fractals precedes a full description of a ray-tracing algorithm applied to these objects. 
A comparison with the boundary- tracking method and applications to other 3-D deter- ministic fractals 
are also included. CR Categories and Subject Descriptors: 1.3.7 [Computer Graphics]: Three Dimensional 
Graphics and Realism --Color, shading, shadowing and texture. General Terms: Algorithms, Theory. Additional 
Keywords and Phrases: fractal, quaternions, distance estimate, ray tracing, surface determination. 1 
Introduction Computer graphics has greatly aided the investiga- tion of the dynamics of iterative functions. 
Stan- Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
&#38;#169;1989 ACM-O-89791-312-4/89/O07/0289 $00.75 dard 2-D frame buffer techniques have provided suffi- 
cient visual information about the structures since most of the research has concentrated on the dy-namics 
of complex variables. However, recent inves- tigations into higher-dimensionM dynamical systems [14,15,3,5,17] 
have shown the need for 3-D visualiza- tion tools that will give researchers a better under- standing 
of these objects. One such method is ray tracing, but this method is prohibitively slow unless an efficient 
ray-surface in- tersection computation is used. While these functions are available for Euclidean surfaces, 
they do not exist (yet) for fractal ones. However, using an unusual con- struction called the unbounding 
volume, made pos- sible by a recent advance in the study of dynamics, swift ray tracing of these deterministic 
fractal objects is possible. Prior to the description of the algorithm, a specific family of 3-D deterministic 
fractals, quaternion Julia sets, is outlined. The generation algorithm is then developed using this family 
as example. Rendering procedures specific to fractal surfaces are then dis- cussed. Finally, the algorithm 
is compared with its predecessor [14] and applications to other families of 3-D deterministic fractal 
objects are shown. 2 Dynamics in the Quater-nions The dynamics of quadratic functions have been ob- 
served mainly in the complex plane. However, as shown first in 1982 [14], they exist in the 4-D space 
of the quaternions as well. A discussion of the spe- cial properties of Julia sets in the quaternions, 
for which the ray-tracing algorithm was developed to vi- sualize, is preceded by an introduction to dynamics 
and quaternion algebra.  ',,( S,GGRAPH '89, Boston, 31 July-4 August, 1989 2.1 Dynamics of Quadratic 
Functions The examples used in this paper are derived from the quadratic function f (z) = + (1) where 
z is the iterated variable and p is a constant parameter of the equation. The dynamics of a function 
f are expressed as the n-fold application of function f to an initial value z. The result is denoted 
as fn (z) and should not be confused with simply raising the result of f(z) to the nth power. The resulting 
value fn(z) is used to classify the initial point z depending on its attraction to infinity. Two sets 
may be constructed under this classification. The filled-in Julia set/C~ and the Mandelbrot set .M. Definition 
1 /C~, = {z: lira f~(z)74 oo} rl---* Cx:) Definition 2 .h4 = {p: li~noo f; (zc) -74 oo, f~(zc) --- 0} 
Note that z is the critical point of the function. There is only one critical point of eq. (1) and it 
is always 0. Several critical points are common for poly- nomials of degree 3 or greater. The interesting 
property that Julia and Mandel-brot sets share is that they are both fractal [12] pos- sessing detail 
at every level of magnification. 2.2 The Quaternions The values z and p are commonly defined as real 
or complex. However, these values may be defined in any algebraic system closed under addition and multiplication. 
One such system, the quaternions [7], possesses the additionM benefit of having four dimen- sions. Definition 
3 A quaternion value q is a four-tuple consisting of one real part and three imaginaries q = ql + qii 
+ qjj + qkk where i~ j~ k are imaginary units, i = j2 = k: = -1. (2) Algebraic operations can be defined 
in the quater- nions by treating the quaternion values as polynomi- als of three variables i, j, k. For 
example, the co-efficients of the sum of two quaternion values may be found by adding their corresponding 
coefficients. Quaternion multiplication is also similar to polyno- mial multiplication but with the special 
cases ij = k; jk= i; ki = j, (3) and ji =-k; kj ik =-j, (4) revealing an unfortunate side effect of the 
quater-nions: noncommutative multiplication. 2.3 Julia Sets in the Quaternions By using the rules of 
quaternion algebra, eq. (1) can be iterated in the quaternions and Julia sets may be computed. Since 
the complex plane is a subset of the quaternions, the same complex Julia sets exist in the quaternions 
but often have extensions outside the complex plane. In fact, if ~ has an imaginary compo- nent, then 
the extensions are nontrivial, containing more information than their complex subsets. A subset of these 
extensions can be visualized in 3-D by examining the intersection of the 4-space with a 3-space such 
as that spanned by 1,i,j at Ok. It should be mentioned that the Julia sets of eq. (1) in the 3-space 
spanned by i t j, k at 0 are always concen- tric spheres centered at the origin [8]. An interesting property 
about quaternion Julia sets is that given two complex Julia sets differing only by a rotation about the 
origin, their supersets in 3-D may have completely different shapes. The rotation of the Julia set in 
the complex plane is computed by incorporating the homeomorphism g0(z) = (5) into the iterated function 
such that L,,e(z) = (6) which suffices to rotate the positive real axis into the positive imaginary axis 
and so forth in a counter-clockwise manner about the origin in the complex plane. The resulting Julia 
set is merely rotated in the complex plane but appears quite differently in the quaternions since its 
intersection with the imaginary 3-space is changed. See [15,8] for details. 3 Ray Tracing 3-D Julia Sets 
Ray tracing is one of the more realistic methods of rendering objects. Easily accounting for hidden sur-faces 
and self-shadowing, it also provides a method for displaying reflection, transparency and refraction. 
Mathematical objects may be ray traced by detecting 290  '89, Boston, 31 July-4 August, 1989 |  ro 
~i r2 r3 r4 r5 Figure 2: Ray traversal using unbounding spheres.  3.3 Thin Objects Often the extensions 
of K: into 3-D are very thin, such as when ~ is a dendrite. This creates the possibility that incrementing 
by ~ may traverse the ray com-pletely through the object. This problem has also had manifestations in 
the 2-D study of these images such as the complex Man- delbrot set. To show that the "islands" off the 
main continent of .M are connected to it, the Mandelbrot set may be defined computationally as .A4, = 
{z: d(z) < e} (11) where d 0 is the distance estimate as defined in eq. (7). The result is the "hairy" 
Maudelbrot set [13] revealing its dendritic structures 2. A similar technique is used to ray trace dendritic 
sheets in 3-D. By terminating ray traversal when the distance is less than the minimum ray increment, 
thickness is added to the object while maintaining its structure and detail. 3.4 Avoiding Bad Distance 
Estimates When the approximation to eq. (7) is used, it is inac- curate when z is far from the set. This 
can result in exaggerated distance estimates which could possibly push the ray far into the interior 
of the object. To avoid these bad estimates a single bounding vol- ume may be used to contain the fractal 
set if it can be bounded. Another alternative is to set a maximum distance to increment along the ray. 
4 Rendering Fractal Surfaces The deterministic family of fractals has provided com- puter graphics with 
the most complicated borders. 2Note that these hairs may be seen very clearly as the set .Me- 2v[, The 
surfaces defined by these borders in 3-D, al-though quite chaotic, often reveal the structure of the 
object. A proper rendering of a fractal surface should reveal its order while hinting at its chaos. Since 
the surface of a fractal is infinitely convo- luted, its normal can only be approximated. The ap- proximated 
normal signifies the structure of the sur- face while at finer resolutions the light is scattered in 
all directions. Thus the surfaces should be diffusely shaded using the Lambertian model. Also, to achieve 
the most information from each view, it is often better to use axle light instead of ambient light. By 
defining a point light source at the eyepoint, every viewable point on the object will re- ceive light 
and thus even heavily-shadowed sections of the object will reveal information about themselves. 4.1 Normal 
Approximation One reason fractal lines, such as the border of/C, are so interesting is that they are 
nondifferentiable. The slope at any point is undefined because closer exam- ination shows that the point 
has different surround- ings. Hence, when expanded to surfaces, 3-D fractal surfaces are nondifferentiable 
and thus have no exact normal defined. In order to realistically render these surfaces a shading model 
must be used which requires the defi- nition of a surface normal. Normals may be approx- imated by examining 
a point's relationship with its surroundings. Two approximations have been found to work quite well: 
Z-buffer neighbors, previously dis- cussed in [14], and the gradient. 4.1.1 Z-buffer Neighbors As shown 
in [14], the surface normal of a fractal sur- face may be approximated as the cross product of two vectors 
embedded in the surface. Given a buffer of visible z-values Z we can define three points x = {~, 0, z~+~,~ 
-z~,~} (12) Y = {0,e,z~,v+c-z~,u] (13) 0 -= {0,0, Z~,y-Zz,~} (14) where e is the width of an element 
in the z-buffer. The surface normal may then be approximated as the normal of the plane defined by these 
three points. 4.1.2 Gradient Computation The previous method is a useful normal determina- tion tool 
if a Z-buffer is maintained during rendering. Ray tracing does not require a Z-buffer so a normal  
 @ ~ Computer Graphics, Volume 23, Number 3, July 1989 The main disadvantage of Boundary Tracking is 
that it requires storage of every point in the object. This amount of storage can approach cubic propor- 
tions since the number of points defining a surface is O(rD), the resolution r of the surface raised 
to its fraetal dimension D [12]. The ray tracing technique, using image-space, requires exactly r 2 + 
O(1) space 4, the storage resources of a graphics workstation frame buffer. Another problem with Boundary 
Tracking is con- stant resolution. However, a variable-resolution Boundary Tracking algorithm was developed 
to cre- ate [16] by generating certain sections of the set al- ready known to be closely examined in 
the fly-by at higher resolutions. Although Boundary Tracking saves computing time by generating the object 
only once, the ray-tracing algorithm is the better choice for fly-bys since its dynamic resolution allows 
a more realistic inspection of the surface. Finally, ray tracing allows certain special effects such 
as reflections and refractions. The former pro- duces the interesting effect of revealing only macro- 
scopic images of its environment; the subtle details are lost in the convoluted interreflections of the 
frac- tal surface. Refraction as well as simple transparency should be avoided until a reliable internal 
distance es- timate is developed to prevent minimum increments in the interior of the sets.  7 Conclusion 
The research on this project began as a method of visualizing quaternion Julia sets in 3-D using the 
resources of a common computer graphics worksta- tion. The first attempt relied on the Inverse Iteration 
method of generating Julia sets [11,18] which oper- ated in image-space and object-time but produced 
less than satisfactory results due to inherent problems of the process itself magnified by the addition 
of an extra dimension [8]. The ray-tracing solution, being forward iterative, does not experience the 
problems of the Inverse Iteration method while still requiring only image-space. 7.1 Parallel Implementation 
The current implementation of the algorithm runs on an AT&#38;T Pixel Machine with 64 parallel processors 
each running at about 10 MFLOPS. The architecture 4If the gradient normal approximation method is used, 
a Z-buffer is not required. The only other considerable amount of memory used is a small array the size 
of the maximum al- lowable iteration count used to optimize the computation of the distance estimate 
[17]. of the Pixel Machine, each processor connected only to its portion of the frame buffer, dictates 
that image- space, image-time algorithms will run at the most optimal level. The ray-tracing code is 
replicated into 64 equiva- lent programs running simultaneously as if in a race, each generating and 
rendering its ~4th of the image. Of course, the first operation of each program is to find out which 
pixel with respect to the entire frame buffer it is working on. Currently, full screen images (1280  
1024) take about an hour to generate. When positioning the ob- ject, lower image resolutions are used 
to create a more interactive environment. Also, reducing the depth resolution will increase the speed 
of the algorithm. 7,2 Acknowledgments The authors wish to thank Alan Norton and Charlie Gunn for their 
communications, AT~T for its ma-jor grant to the Electronic Visualization Laboratory which supported 
this research, Maggie Rawlings for her artistic advice with the illustrations, and Tom DeFanti and Maxine 
Brown for their assistance with the manuscript. This research would not have been possible without the 
efforts of the faculty, staff and students of the Electronic Visualization Laboratory.  References [1] 
Barnsley, M. F. Fractals Everywhere. Academic Press, New York, 1988. [2] Barr, A. H. Ray tracing deformed 
surfaces. Computer Graphics 20, 4 (1986), 287-296. [3] Blanchard, P. Disconnected Julia sets. Chaotic 
Dynamics and Fractals (1986), 181-201. [4] Bouville, C. Bounding ellipsoids for ray-fractal intersection. 
Computer Graphics 19, 3 (1985), 45-51. Branner, B., and Hubbard, J. It. The iteration of cubic polynomials, 
Part h The global topology of the parameter space. Acta Mathematica 160, 3 (1988), 143-206. [6] Fisher, 
Y. The Science of Fractal Images. Springer-Verlag, New York, 1988, ch. Exploring the Mandelbrot Set, 
pp. -287-296. [71 Hamilton, W. R. Elements of Quaternious, 3rd ed. Vol. 1-2, Chelsea Publishing Company, 
New York, 1969.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74364</article_id>
		<sort_key>297</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Guaranteed ray intersections with implicit surfaces]]></title>
		<page_from>297</page_from>
		<page_to>306</page_to>
		<doi_number>10.1145/74333.74364</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74364</url>
		<abstract>
			<par><![CDATA[In this paper, we present a robust and mathematically sound ray-intersection algorithm for implicit surfaces. The algorithm is guaranteed to numerically find the nearest intersection of the surface with a ray, and is guaranteed not to miss fine features of the surface. It does not require fine tuning or human choice of interactive parameters. Instead, it requires two upper bounds: "L" that limits the net rate of change of the implicit surface function <i>f(x,y,z)</i> and "G" that limits the rate of change of the gradient. We refer to an implicit surface with these rate limits as an "LG-implicit surface."Existing schemes to intersect a ray with an implicit surface have typically been guaranteed to work only for a limited set of implicit functions, such as quadric surfaces or polynomials, or else have been ad-hoc and have not been guaranteed to work. Our technique significantly extends the ability to intersect rays with implicit surfaces in a guaranteed fashion.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31081847</person_id>
				<author_profile_id><![CDATA[81100004305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kalra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, California Institute of Technology, Pasadena, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034822</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, California Institute of Technology, Pasadena, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1300009</ref_obj_id>
				<ref_obj_pid>1299941</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alan H. Barr, Superquadrics and Angle-Preserving Transformations, IEEE Computer Graphics and Applications, Jan '81.]]></ref_text>
				<ref_id>BARR 81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alan H. Barr, Global And Local De.formations of Solid Primitives, Computer Graphics, July '84.]]></ref_text>
				<ref_id>BARR 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn, A generalization of Algebraic Surface Drawing, ACM Transactions on Graphics, Vol. 1, No. 3, July 1982, pp 235-256.]]></ref_text>
				<ref_id>BLINN 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325249</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jules Blomenthal, Modeling the Mighty Maple, Computer Graphics, Vol 19, No. 3, July 1985.]]></ref_text>
				<ref_id>BLOOMENTHAL 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jules Blomenthal, Polygonization of Implicit Surfaces, Course Notes on "The Modeling of Natural Phenomena", Siggraph 1987.]]></ref_text>
				<ref_id>BLOOMENTHAL 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806346</ref_obj_id>
				<ref_obj_pid>800205</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Collins, G.E. and Akritas, A. G., Polynomial real root isolation using Descartes' rule of signs, Proc. 1976 AOM Symposium on Symbolic and Algebraic Computation.]]></ref_text>
				<ref_id>COLLINS AND AKRITAS 76</ref_id>
			</ref>
			<ref>
				<ref_obj_id>540426</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gear, G. William, Numerical lnitial Value Problems in Ordinary Di.~erential Equations, Prentice-Hall, Englewood Cliffs, N J, 1971.]]></ref_text>
				<ref_id>GEAR 71</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Space Subdivision for Fast Ray Tracingr Andrew S. Glassnet, IEEE Computer Graphics and Applications, October '84.]]></ref_text>
				<ref_id>GLASSNER 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801136</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Pat Hanrahan, Ray Tracing Algebraic Surfaces, Computer Graphics. July '83.]]></ref_text>
				<ref_id>HANRAHAN 83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Devendra Kalra and Alan H. Barr, Guaranteed lntersection.~ with lmplicit surfaces, Galtech Computer Science Tech Report.]]></ref_text>
				<ref_id>KALRA and BARR 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Mathematics Applied To Deterministic Problems In The Natural Sciences, C. C. Lin and L. A. Segel, Macmillan Publishing Co., Inc., New York.]]></ref_text>
				<ref_id>LIN AND SEGEL 74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Marching Cubes: A high resolution 3d surface construction algorithm, William E. Lorensen and Harvey E. Cline, Computer Graphics, July 1987.]]></ref_text>
				<ref_id>LORENSEN AND CLINE 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325231</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Alan E. Middleditch and Kenneth H. Sears, Blend Surfaces for Set theoretic volume Modeling Systems, Computer Graphics, Vol. 19, No. 3, July 1985, pp. 161-170.]]></ref_text>
				<ref_id>MIDDLEDITCH et al 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[John Ptatt and Alan Barr, Constraint Methods for Flexible Models, Computer Graphics, Aug 88.]]></ref_text>
				<ref_id>PLATT and BARR</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Steven Wolfram et ~1,, SMP: A symbol manipulation Package, California Institute of Technology, 1981.]]></ref_text>
				<ref_id>SMP</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Demetri Terzopoulos, John Pl~tt, A1 Barr, Kurt Fleischer, Elastically Deformable Models, Computer Graphics, July 87.]]></ref_text>
				<ref_id>TERZOPOULOS et al</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Uspensky, J. V., Theory of Equations, McGraw-Hill, 1948.]]></ref_text>
				<ref_id>USPENSKY 48</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Brian P. Van Herzen, Sampling Deformed, Intersecting Surfaces with Quadtrees, Master's Thesis, Caltech, 1984.]]></ref_text>
				<ref_id>VON HERZEN 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>76222</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Brian Van Herzen, Applications of SurJace Networks to Sampling Problems in Computer Graphics, (Jnltech Ph D Thesis.]]></ref_text>
				<ref_id>VON HERZEN 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Brian Van Herzen, Alan H, Barr, Harold R. Zatz, Collision Determination for Parametric Surfaces, Caltech CS Technica} Report.]]></ref_text>
				<ref_id>VON HERZEN 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13045</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Space Division for Ray Tracing in CSG, GeolJ Wyvill, Tosiyasu L. Kunii and Yasuto Shirai, IEEE Computer Graphics and Applications, April '86.]]></ref_text>
				<ref_id>WYVILL 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295898</ref_obj_id>
				<ref_obj_pid>2295756</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Solid Texturing of Soft Objects, Geo}J Wyvill, Brian Wyvill, Craig Pheeters, IEEE Computer Graphics and Applications, December '87.]]></ref_text>
				<ref_id>WYVILL 87(1)</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Animating Soft Objects, Geoff Wyvill, Craig Pheeters, Brian Wyvill, The Visual Computer, (1986)2.]]></ref_text>
				<ref_id>WYVILL 87(2)</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '89, Boston, 31 July-4 August, 1989 &#38; l a non-trivial task for general implicit surfaces, 
and could depend on the camera view angles and viewing parameters of the scene. (Our technique can be 
adapted to produce guaranteed polygonalizations, but we feel direct rendering is easier). Even in directly 
rendering a geometric primitive, rather than its polygonal tesselation, a "guaranteed" technique, which 
does not require any corrective interaction or fine tuning of parameters by a human be- ing, is most 
vahlable. Tbis is especially attractive to people making computer animation. In fact, we frequently use 
computer animation as a means to verify the accuracy of our rendering algorithms. Imagine running iongscripts 
to make a movie and then finding that frame num- ber 129 has pixel dropouts because the frame uses a 
particular camera angle and parameters for the rendering algorithm that worked for other frames but do 
not work for this frame. The recourse is to find the right set of parameters for this frame and restart 
the animation until we notice other anomalies. With a guaranteed "direct" method, one is assured of the 
correctness of the whole sequence, without re-rendering frames. Even in making still-frames, much time 
is spent modeling a scene. With an algorithm that guarantees the correctness of the rendering, there 
is less to worry about, as changes are made to other object pa- rameters of the scene. The utility of 
having a wider variety of surface types can be seen in Figures 16 and 20. The polygonal or patch representation 
for these objects would be more difficult to specify and would require moie data than implicit techniques. 
Finally, developing a "direct" guaranteed algorithm that works ev- ery time without any searches through 
a parameter space was an ex- hilarating research experience for us. 1.2 Previous Methods To Render Implicit 
Surfaces An implicit surface S is defined by a function S : f(x) = 0. The func- tion is negative inside 
the surface and positive outside (Figure 1). Polynomial Implicit Functions The efforts to render implicit 
surfaces have been two-fold. The first ap- proach has been to limit types of implicit functions. [HANRAHAN 
83] limited the implicit functions to be polynomial functions of spatial vari- ables. Using some results 
presented in [USPENSKY 48] and [COLLINS and AI<Rr'FAS] and a theorem due to Descartes, this method gurarantees 
the nearest intersection of a ray with a polynomially defined implicit surface. [MIDDt.EOITCH et al 85] 
have also used polynomially defined surfaces to generate some kinds of blend surfaces. Polygonizing Implicit 
Surfaces The second approach has tried to render more general implicit surfaces by polygonizing implicit 
surfaces. There is a basic difficulty with using a naive polygonization of a surface. With a view independent 
polygonization algorithm, we could either end up rendering too many polygons when the object covers very 
small number of pixels on the screen or rendering too few polygons when the objects covers a large area 
on the screen. [VON HERZEN 87] has attempted to deal with view dependent potygonization. On the other 
hand, ray casting automatically samples an object at a level that depends on the ohjeet's coverage of 
the screen. It is also more natural and easier to model some objects in one modeling domain than another. 
The pictures in this paper have been modeled in a sculptor's paradigm of adding a little clay here or 
remov- ing a little clay there. This can be done most naturally with blended implicit functions. However, 
some researchers have polygonized implicit surfaces with varying success. The schemes that try to polygonize 
implicit surfaces compute the value of f(x) defining the surface for points Pi on a grid. These methods 
consider segments at whose two endpoints f(x) has opposite signs. Then the intersection of S with this 
segment is ap- proximated by various methods such as linear interpolation. These "intersections" along 
the edges of the rectangular boxes forming the sampling lattice are then connected according to some 
heuristics to form polygons. These polygons are then rendered. See [WYVILL 8711]], [WYVILL 87[2]], and 
[BLOOMEINTHAL 87], Forming polygons out of approximate intersections along the box edges is heuristic 
and leaves ambiguities in many cases when more Approximate + ~Xx 'n~ers~//u/~ (b) "~ Figure 3: Possible 
problems with a naive Implicit S~face Polygonizing Algorithm; (a) small features are liable to missed 
because both sample points are outside the surface, (b) incorrect intersections may be computed because 
of strange behaviour of the function near the sample points. than one possibility exists. A second more 
important problem with the above algorithm is that they are based only on the values of the implicit 
function at certain points. As noted before, this means that features finer than the sampling grid will 
be either completely ignored (Figure 3(a)) or the approximate intersections formed will be grossly incorrect 
(Figure 3(b)). There is not enough information in the function values even to provide an estimate of 
the size of the sampling grid. In section two, we describe our mathematical approach. In section 3, we 
describe an overview of the algorithms, while in section 4 we describe the algorithms in more detail. 
In sections 5 and 6, we describe our results and conclusions, and provide supplemental mathematical information 
in the appendices. 2 Our Approach: Creating LG-Surfaces We present an algorithrr~that a) Guarantees that 
the smallest features of the surface are sampled. b) Obtains the nearest intersection of a ray from the 
origin of the ray with the implicit surface S represented by the implicit function f(x). We do not generate 
polygons, but obtain guaranteed numerical in- tersections of rays with the implicit surface. 2.1 Mathematical 
Preliminaries: We first present some mathematical definitions and preliminaries: Definition of Implicit 
Surface: A general implicit surface S is defined by (See Figure 1) /(z, y, z) = 0 or, in vector notation, 
f(x) = 0 Ray Definition We define a ray via: x= o~t +fl, t>0, where vector c~ is a unit vector ray direction 
and vector /3 is the origin of the ray corrsponding to ~ = O. Definition of F(t) Given a function f(x) 
= 0 of spatial variables x = (z, Y, z), we substi- tute x = o~t +/3 into f(x) to define F(t) = f( o~t 
+ ~9) (1)   ~ Computer Graphics, Volume 23, Number 3, July 1989 " 'qA / \  Figure 4: Given a point 
Z0, r = f(x0)/,C isthe radius or the sphere S ~ound X0 such that. f(z) does not change sign in S..~ is 
the Lipschit.z constant in equation 3 in the region of ~. Spheres (a) and (b) are guaranteed not ~o intersect 
the surface si.o, Lips~t~ ~ri r~ = f(x~)/L~ < 1~ and ~b = f(zb)/~Cb < R. H....... "Pc > R and ~c may 
intersect the surface. Definition of g(t) We now define a new function dF g(O = dt = ~ vf(x)1~,+/3 (2) 
 Note that g(t) is the directional derivative of f(x) along the ray direction o~ ('g' relating to "gradient"). 
Definition Of Lipschitz Constant A (positive) real number  is cMled a Lipschitz constant on a function 
f(x) in a region T~, if given any two points xl and x2 in ~, the following condition holds: Ilf(xt)-f(x2)ll 
<  Ilxx-x~ll (3) where I1.11 is a vector norm. If the constant  exists, a lipschitz condition is said 
to exist on the function f(x) in the region ~. (See Figure 4.) We also note that other schemes based 
on Lipschitz Constants have been used for accurate sampling of parametric surfaces by [VON HERZEN 87], 
[VON HERZEN 88] and [VON HERZEN 89]. 2.2 LG-surface Description We define an LG surface to be an implicit 
function f(x~y,z) which has bounds on the net rate of change of the function and its directional derivative 
(that we call L and G). Mathematically, these bounds are the Lipschitz constants as defined above; Lipschitz 
constants have other useful applications in applied mathematics and numerical analysis (see [GEAR 7I] 
and [LIN AND SEGELT4]). Definition of LG-surfaces Let L be the Lipschitz constant for the function f(x) 
in a three-dimensional region ~ and G be the Lipschitz constant for the cor-responding function g(t) 
in a closed interval T=[Q,t2], iv., Ilf(xo)- f(xb)ll _< L [Ixa- x~,][ (4) IIg(to)-g(tb)ll _< c lit. -tdl. 
(5) for any ~a,~b E7 and any ta,tb E T. An implicit surface S represented by an implicit function f(x) 
= 0 is an LG-implielt surface, if the Lipschitz constants L and G as defined above exist and are computable. 
2.3 How To Compute L's and G's It can be seen from equation (3) that a Lipschitz constant is a measure 
of the maximum rate of change of a function in a region over which the function is defined. This can 
be seen by dividing equation 3 by Ilxt -x211, taking the limit ~ Xl ~ x2 and using the definition of 
derivative. Figure 5: The straddling boxes of a surface as found by part A, Space Pruning step of the 
algorithm. The figure shows a two-dimensional slice through the three dimensional collection of boxes. 
   "1 I" Figure 6: What is straddling? The box vertices straddle the surface if at least one of the 
vertices of the box is inside and at least one of the vertices is outside the surface (case (a)). Cases 
(b), (c) and (d) are all non-straddling. Computing L: Given a three dimensional rectangular region T~, 
we shall call the Lips- ehitz constant for f(x) for 7~ to be L. L is equal to or greater than the maximum 
rate of change of f(x) in 7~. That is L  > lvs(x I Computing G: Given a one dimensional closed interval 
T= [q,t2], we call the Lips- chitz constant for g(t) in 7- to be G. T is equal to or greater than the 
maximum rate of change of 9(t) in 7-. That is max d9 I G > 7-~ (7) The algorithm works faster for smaller 
values of L and G. 3 Rendering LG-surfaces We render LG-surfaces by casting rays and obtaining intersections 
of the ray with the surface using two algorithms, A and B. Algorithm A) Space Pruning Algorithm A is 
an efficiency measure. Even if algorithm A is not used, the ray intersection method in algorithm B is 
guaranteed to work. This algorithm prunes away large parts of space that are guaranteed not to contain 
any part of the LG-surface as in Figure 5. We obtain a volume "12, composed of non-overlapping rectangular 
boxes, that con-tains the whole surface. The vertices of each of the boxes in V straddle the surface 
(figure 6). This initial pruning reduces the space in which we have to search for intersections of rays 
with the surface.  SIGGRAPH '89, Boston, 31 July-4 August, 1989 Algorithm B) Ray" Intersection In algorithm 
B, the volume Y in space generated in the algorithm A is used to intersect a ray with the surface. The 
rectangular boxes composing Y are intersected with a ray in order of appearance along the ray. In any 
box, if one or more intersection exists, the nearest intersection is determined and we are done with 
this ray. The algorithm guarantees that if an intersection in the box exists, the intersection is found. 
Further, if more than one intersection exists, the nearest one is computed (nearest to the origin t = 
0 of the ray vtt + 13). We now discuss each algorithm in more detail. 3.1 Part A: Pruning Away Empty 
Regions Of Space The vertices of a rectangular box are said to straddle an implicit surface if at least 
one of the vertices lie inside the surface and at least one of the vertices lie outside. In Figure 6, 
part (a) shows a straddling box. We do not consider'the box vertices in part (b) to be straddling even 
though the box itself contains a part of the siarface. Boxes (c) and (d) are obviously non-straddling. 
The sign of f(x), the inside-outside function for the surface tells if the point x is inside or outside 
the surface. Algorithm A (Space Pruning) of the algorithm is shown in pseudo code in Figure 7 and in 
pictures in Figure 8. In this algorithm, we start with a bounding box that surrounds the surface of interest 
(Figure 8, step 1). This bounding box is subdivided (Figure 8, step 2) to some level n and sub-boxes 
guaranteed not to contain any portions of the surface are thrown away ((Figure 8, step 6 Box Bi). Only 
boxes that straddle the surface are kept (Figure 8, step 4 Box B4). By keeping the boxes that only straddle 
the surface, each box is guaranteed to contain a part of the surface and we get a collection of boxes 
that lie close to the surface. Given a sub-box B, how do we decide if it is to be accepted and not pruned 
away? If B straddles the surface, it certainly contains a part of the surface and it is kept (Figure 
S, step 4 box .B4). tf B does not straddle the surface, it still might contain a portion of the surface 
(Figure 8. step .4 box B3). The L Lipschitz constant tells us if B does not contain any part of the surface: 
Let xs be the center of B, and d be half the length of the principal diagonal of B. Since the maximum 
rate of change with respect to distance of f(x) is L and the maximum distance of any point in B from 
x0 is d, the maximum change in the value of f(x) in B from .f(x0) is Ld. Hence if )f(xo)[ > Ld (8) then 
f(x) is guaranteed to stay the same sign that it has at x 0 and never assume a value of zero in B and 
hence B can be thrown away (fig 7, steps 5 and 6, box B1). If B does not satisfy condition in equation 
(8), it is subdivided into eight sub-boxes and each of the sub-boxes is checked again to check that it 
satisfies either the straddling condition or equation (8). In Figure 8, step 7, Ba is subdivided and 
upon subdivision we find some sub-boxes that straddle the surface. For box Bz, none of the sub-boxes 
straddle the surface and the subdivision is stopped after condition (8) is satisfied. Figure 5 shows 
a surface and its straddling box forming P as found by our algorithm. This initial subdivision in algorithm 
A is not an essential require- ment for the algorithm. It is guaranteed to work even if the initial subdivision 
level n = 0, i.e., no initial subdivision of the bounding box is performed. The level of initial subdivision 
does effect the perfor- mance of the ray-intersection. Subdivision Termination Is it guaranteed that 
the subdivision algorithm terminates? If any of the vertices of a box lies exactly on the surface, condition 
(8) will never be satisfied. Even if we compute the smallest possible L, we can meet the condition If(xo)[ 
= Ld rather than the inequality. Hence, we have to stop subdivision at some level if it does not stop 
in the natural course of the algorithm. Since we compute the intersec- tions numerically, stopping the 
intersection when the box size becomes smaller than the tolerance of the numerical method is a natural 
con-dition to use. Experimentally, in all the pictures we have computed Step I. Compute a bounding box 
B for surface ~. Subdivide B to a level n 3. For each sub-box b 4 Accept b if b straddles surface 
else 5. Compute L for b 6. If if(x0) [ > Ld 7. Reject b else 8. Subdivide b into eight sub-boxes 9. 
For each sub-box of b, I0. Repeat the above  Figure 7: Algorithm A prunes away parts off space guaranteed 
not to contain any portion of the surface. The algorithm is shown in pictures in Figure 8. The steps 
in this figure and in Figure 8 correspond. Box B Box B  ' It~ AN/AS ,~/.~./ />. ////"///"//) ~6..~_..z.z..~_/ 
/.'/ /j Step 1 Step 2 [~]Bl --Bs [Z]B1 ~-1B3 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Figure 8: Algorithm 
A prunes away parts of space gurarazlteed not to contain any portion of an LG-surfac. Cross hatched 
boxes are added to V, lightly shaded box~ are thrown away. The pseudocode for the algoritlu'n is given 
in Figure 7. The steps in this figure and in Figure 7 correspond. so far, such a terminating condition 
has never taken place. The strad- dling condition occurred before the box reached the numerical precision 
limit. * Computer Graphics, Volume 23, Number 3, July 1989 3.2 Part B: Intersection of a Ray with an 
LG- surface This part of the algorithm is designed to guarantee finding the inter- section of a ray 
with an LG-surface nearest to the origin of the ray. In algorithm A, we have formed a set of boxes that 
comprise a volume ~ and the vertices of each of the boxes in 1; straddle the surface. The volume V completely 
encloses the surface of interest. Hence all intersections lie in V. V is composed of non-overlapping 
boxes. The ray intersection problem is now broken down into a simpler problem: a) Find the box in V nearest 
to the origin of the ray. b) Compute any ray intersections in this box; if none exist, consider the next 
box in order. The problem of finding the nearest box is described later in sec- tion 4. Here we consider 
the following problem. Problem Statement Intersection of a ray with the surface in a straddling box: 
Given a ray and a box B whose vertices straddle the surface, either ensure that there is no intersection 
of the ray with the surface in B or find the nearest intersection. Preliminaries We wish to compute intersections 
along the ray cd + ~. ttenee, we are interested in the behavior of f(x) along the ray. As defined in 
equation 1, F(t) represents the behavior of f(x) along the ray and dF g(t) = -~-. An intersection is 
given by values of t such that F(t) = 0. The reliability of our ray intersection algorithm depends on 
our abil- ity to determine if g(t) becomes zero in an interval. The following two cases describe two 
important situations, one in which there is exactly one ray-surface intersection in an interval, and 
second in which there is none. 1. If F(t~) and F(t~) are of opposite signs at two points t~ and t~ along 
the ray, tl < t~, there is at least one intersection between tt and t2. Further, ifg(Q = dF/d~ does not 
become zero between t~ and t~, there is exactly one intersection between the ray and the surface in the 
interval from tl to t~ (see below z ). 2. If F(Q) and F(tz) have the same sign at Q and t~ along the 
ray, t~ < t2 and g(t) = dr~dr does not become zero between t~ and t~, there is no intersection between 
the ray and the surface in the interval from Q to t2.  Given that G is the Lipschitz constant for g(t) 
in an interval [Q, t~] and tm = (tt +tz)/2 d = (t z -- tl)/2 , Ig(t~)l > Gd (9) in [/~,tz], then g(t) 
nevers becomes zero in the interval. (G is equal or more than the maximum rate of change of g(t) and 
d is the maximum distance along the ray from trn.) Gd is the maximum possible change in g(t) from g(tm). 
Ill a continuous function f(t) att~ns two consecutive zero values at tl and tz, by the mean value theorem, 
there exists at lea~st one point between tl and t~ where d]/ dt = O. I. Intersect ray oct +~9 with box 
B in t~ and tz, t2 > Q 2. Compute G with respec$ to midpoint tm = t2 + Q/2 Let half distance d= (t 2-tin)~2 
 3. i~ Ig(t~)]> Cd  4. i~ F(~) ~a f(tz) are of opyosite signe  S. there is exactly one intersection: 
 compute intersection via newton iteration or regula falsi else 6. there is no intersection in the 
interval [~i, I~] else 7. llg(~m)ll< Cd  8. sttbdivide into two subintervals [tl,t,n~  and [tm,tz] 
9. and repeat steps 2 to 8 on each subinterval until tm--tl < e or t2--tm < Figure 9: Algorithm to intersect 
a ray with art LG-surface. Given a "box B~ determine if there is no intersection in B or else compute 
the nearest intersection. is the tolerance of the numerical method used to compute the intersection. 
 B) Ray Intersection Algorithm The ray intersection algorithm is delineated in Figure 9. We will use 
the above observations to design our ray intersection algorithm. We are looking for the interval [tl,tz] 
nearest to the origin of the ray with exactly one intersection. Given a box B, we will make decisions 
about closest intersections of the surface S and the segment of the ray in the box. Let the ray intersect 
box B in points PI and P2 corresponding to the ray parameter values tl and tz. Let t~ be the midpoint 
of the segment between tl and t2, tm-t2 + tl d = (t2 - tl)/2.2 ' How to Find a Ray intersection 1. If 
F(Q) and F(tz) are of opposite signs and []g(tm)[[ > Gd, there is exactly one intersection between tl 
and is. The intersection is com- puted numerically using a newton iteration and regula falsi method. 
 2. If F(tl) and F(t2) have the same sign and [[g(tm)][ > Gd, there is no intersection between tl and 
t2. The next box B along the ray is considered. If there are no more boxes along the ray, the ray does 
not hit the surface.  If equation 9 is not satisfied in it1, tz], the interval is sudivided into two 
sub-intervals at tm and the two subintervals [t,,lm] and [Zm,tz] tested in order. Interval Subdivision 
Termination The termination condition of the interval subdivision algorithm needs equation 9 to be satisfied. 
Since both G and d are positive, if g(t) becomes exactly zero along the ray, this condition is never 
satisfied and the algorithm will not terminate naturally. This situation occurs at the silhouette edges 
of the surface 2. At a point Ps on the silhouette edge, the gradient of f(x) is perpendicular to the 
ray and hence the directional derivative g(t) is zero. Hence at Ps condition (9) will never be satisfied. 
To avoid an infinite subdivision, one has to stop when it2 - tl[ be- comes less than the precision of 
the numerical method used to compute the intersections, typically of the order of 10 -8 . The surface 
will be smooth within the same error tolerance. The above considerations also imply that the algorithm 
spends more time near the silhouette edges. This is shown in Figure 12.   3.3 Note about the Algorithm 
Note that the Space Pruning algorithm has to be done only once for each surface. The same volume 12 can 
be used repeatedly to make multiple pictures of that surface. Hence if we wish to make many 2A point 
Ps on ~ surface S : ./(X} = 0 is said to he on a silhouette cdse with respect to a view point Pu, if 
the ray ori~natin s from Pv and passing through P, is tangent to S.     @~ Computer Graphics, Volume 
23, Number 3, July 1989 8 Acknowledgements We would like to thank Steve Gabriel for his helpful comments 
and also to Harold Zatz. Thanks also are due to our sponsors for this work, Ap- ple Computer, AT&#38;T, 
Hewlett Packard, IBM, and the National Science Foundation. A Computing L and G A.1 Lipschitz Constants 
For Sum Of Functions Given a set of functions f~(x), f~(x), ..., f.(x), with Lipschit~ constants L~, 
g~, ..., Ln respectively in a region "R., define the sum function Fs as. F, =  f,(x). i=1 Then the 
Lipschitz constant L~ of F,(x) in ~ satisfies the relation, n Ls _< ~ L~ i=l A.2 Computing L and G for 
generalized algebraic surfaces A.2.1 Case h EUlpsoidal Blending Functions An ellipsoidal blending function 
is defined ws f(z,y,z) = Be -A~(='~'O where ~(z, ~, ~) = .~=~ + b~u~ + c~z ~ (13) We sketch out the 
derivation of computing L and G here. For details see the Caltech CS Technical Report [KALRA and 8ARR 
89]. Computing L in a region R The L Iipschitz constant is computed by computing the gradient of f(z, 
y, z) in equation 12, taking its magnitude and maximizing it over a rectangular region. For a rectangular 
region R bounded by (z~i.,ymi.,z~i~) and (=.... y .... z~=), L i.s given by, Ln = 2ABR~=e -A~ (14) where 
R= ~a4x 2+b4y 2+c~z 2. Note that R~o= and r~i. occur at the maximum and minimum distances respectively 
of any point in ~ from the origin. Note that, if the region "R straddles any of the coordinate planes, 
r does NOT take its minimum value at (Zrnln, y,ni~, stain) which is one of the vertices of ~, Computing 
G in an interval 7- : [tt,t2] The G lipschitz constant is computed by substituting (x,y,z) = at  fl 
in equation 12 to obtain F(Q, differentiating to obtain g(t) = d.F/dt and maximizing dg/dt over the interval 
its,t2]. Define h(O = -2ABe -A~ (h -A (k~ + k~) ~) where ~, = u~ + ~ + ~] Thus max G=t6T h(~) But 
h(t) can have a maximum value only at the endpoints t~ or t2, or else at a stationary point of h(Q, -x/5~-/2A 
-k~ ta kl -k2 t,i = --k, t5 k~ See Figure 21. Thus max  G=ti6T h(t~) h(O t > Figure 21: Hog of h(t) 
= dg(Q/dt alons a ray. T .... pure G, pick ghe maximum value of h(t) in slay interval (t I ,t2). A.2.2 
Case 2: Superquadratic Blending Functions An superquadric blending function is defined as f(~,y,~) = 
Be -~'~'~/ (15) where ~(~,~,~) = (~"+ ~")~ +~ (]6) The mathematics for L and G gets somewh~.t involved 
~nd we shall sketch out the derivation steps. Please see [KALRA and BARR sg] for full expres- sions and 
details. Method to Compute L in a region Td Differentiate f(x, y, z) with respect x, y and z respectively 
and maximize the partial derivatives over a rectangular region 7L bounded by (x~,~, y~i., Zmi~) and (z 
.... y .... z~=) to get L1, L2 and L3 respectively. L1 L~ .... (mABe-A~ [(xn+yn)'~'-'y"-l]) L3 .... (~ABe-~'W 
-~) We then use L= jL~ + L~ + LL Method to Compute G in an Interval [tl,t2] To compute G, substitute 
(x,y, z) = (~t + ~) iu f(x,y,z). Differentiate to get g(t). Differentiate again and maximize over an 
interval [tl, t2]. We found the use of a symbolic manipulation package such as [SMP] very useful in substituting 
for common sub-expressions etc. during the derivation of L's and G's. Again, for more details see the 
Caltech CS Technical Report [KALRA. and BA.RR S9]. A.3 Lipschitz Constants For Deformations Let h(z, 
y, z) be an inside/outside function. Let D(x, y, z) be a deformation function. The deformation function 
El(x) maps a 3-d point to another 3-d point. Examples are taper, twist, and bend [BARR 84]. The inside-outside 
function of the surface generated by deforming h(x, y, z) by the deformation D is given by f(z,y,z) = 
h(D-a(x)) ~L~SIGGRAPH '89, Boston, 31 July-4 August, 1989 Computing L in a region T~ A Lipschitz constant 
L for a region V is computed L > max where II'll rep~ese.ts a vector uorm. Computing G in an interval 
[tl,t~] Define d g(t) ~ff(~ + ~). = for a ray x = c~t +ft. Then G for an interva/ 7" along the ray is 
computed as > max dg(t) G-t6T ~ The detailed derivation and expressions for L and G may be found in 
[KALRA and BARR 89]. References [BARR 81 ] Alan H. Burr, Superquadrics and Angle-Preserving Transforma- 
tions, IEEE Computer Graphics and Applications, Jan '81. [BARR 84 ] Alan I-I. Ban, Global And Local Deformations 
of Solid Primi- tives, Computer Graphics, July '84. [BLINN 82 ] James F. Blinn, A generalization of Algebraic 
Surface Drawing, ACM Transactions on Graphics, Vol. 1, No. 3, July 1982, pp 235-256. [BLOOMENTHAL 85] 
Jules Blomenthal, Modeling the Mighty Maple, Computer Graphics, Vol 19, No. 3, July 1985. [BLOOMENTHAL 
87] Jules Blomenthal, Polygonization of Implicit Sur- faces, Course Notes on "The Modeling of Natural 
Phenomena", Sig- graph 1987. [COLLINS AND AKRITAS 76] Collins, G.E. and Akritas, A. G., Polyno-mial real 
root isolation using Descartes' rule off signs, Proc. 1976 ACM Symposium on Symbolic and Algebraic Computation. 
[GEAR 71 ] Gear, C. William, Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-Hall, 
Englewood Cliffs, N J, 1971. [GLASSNER 84 ] Space Subdivision for Fast Ray Tracing r Andrew S. Glass- 
ner, 1SEE Computer Graphics and Applications, October '84. [HANRAHAN 83] Pat Hanrahan, Ray Tracing Algebraic 
Surfaces, Com-puter Graphics. July '83. [KALRA and BARR 89] Devendra Kalra and Alan H. Burr, Guaranteed 
In- tersections with lmplicit surfaces, Calteeh Computer Science Tech Re- port. [LIN AND SEGEL74 ] Mathematics 
Applied To Deterministic Problems In The Natural Sciences, C. C. Lin and L. A. Segel, Macmillan Publishing 
Co., Inc., New York. [LORENSEN AND CLINE 87 ] Marching Cubes: A high resolution 3d sur- face construction 
algorithm, William E. Lorensen and Harvey E. Cline, Computer Graphics, July 1987. [MIDDLEDI-I-CH et al 
85] Alan E. Middleditch and Kenneth H. Sears, Blend Surfaces for Set theoretic volume Modeling Systems, 
Computer Graphics, Vol. 19, No. 3, July 1985, pp. 161-170. [PLAT-[- and BARR ] John Platt and Alan Burr, 
Constraint Methods for Flexible Models, Computer Graphics, Aug 88. [SMP] Steven Wolfram et al,, SMP: 
A symbol manipulation Package, Cali- fornia Institute of Technology, 1981. [TERZOPOULO~5 et al ] Demetri 
Terzopoulos, John Platt, AI Burr, Kurt Fleischer, Elastically Deformable Models, Computer Graphics, July 
67. [USPENSKY 48] Uspensky, J. V., Theory of Equations, McGraw-Hill, 1948. [VON HERZEN 84 ] Brian P. 
Von Herzen, Sampling Deformed, Intersecting Surfaces with Quadtrees, Master's Thesis, Caltech, 1984. 
[VON HERZEN 88 ] Brian Von Herzen, Applications of Surface Networks to Sampling Problems in Computer 
Graphics, Caltech Ph D Thesis. [VON HERZEN 89 ] Brian Von Herzen, Alan H, Burr, Harold R. Zatz, Col-lision 
Determination for Parametric Surfaces, Caltech CS Technical Report. [WYVILL 86] Space Division for Kay 
Tracing in CSG, Geo~ Wyvill, Tosiyasu L. Kunii and Yasuto Shirai, IEEE Computer Graphics and Applications, 
April 786. ~WYVILL 8711] ] Solid Texturing of Soft Objects, Geoff Wgvill, Brian Wyvill, Craig Pheeters, 
IEEE Computer Graphics and Applications, December '87. [WYVILL 87[2]] Animating Soft Objects, Geoff Wyvill, 
Craig Pheeters, Brian Wyvill, The Visual Computer, (1986)2.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74365</article_id>
		<sort_key>307</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Parameterized Ray-tracing]]></title>
		<page_from>307</page_from>
		<page_to>314</page_to>
		<doi_number>10.1145/74333.74365</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74365</url>
		<abstract>
			<par><![CDATA[The construction and refinement of a computer graphics scene is unacceptably slow when using ray tracing. We introduce a new technique to speed up the generation of successive ray traced images when the geometry of the scene remains constant and only the light source intensities and the surface properties need to be adjusted. When the scene is first ray traced, an expression parameterized in the color of all lights and the surface property coefficients of all objects is calculated and stored for each pixel. Redisplaying a scene with a new set of lights and colors then consists of substituting values for the corresponding parameters and re-evaluating the expressions for the pixels. This parameter updating and redisplay takes only a few seconds, as compared to the many minutes or hours required to ray trace the entire scene again, but it uses much more memory and disk space. With suitable expression sharing, however, these storage needs can be reduced to an acceptable level.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39078621</person_id>
				<author_profile_id><![CDATA[81100058395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[S&#233;quin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Division, Electrical Engineering and Computer Sciences, University of California, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P73740</person_id>
				<author_profile_id><![CDATA[81100639582]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Smyrl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Division, Electrical Engineering and Computer Sciences, University of California, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>6448</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[AHO, ~D V., RAVI SETI-H, AND JEFFREY D. ULLMAN, Compilers: Principles, Techniques, and Tools, Addison-Wesley, Reading, Mass., 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[COHEN, }V{ICHAEL F. AND DONALD P. GREENBERG, "The Hemi- Cube: a Radiosity Solution for Complex Environments," Proceedings of SIGGRAPH '85 (San Francisco, California, July 22-26). In Computer Graphics 19, 3, pp. 31-40, July 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[FUJIMOTO, AIR, TAKAYUK/ TANAKA, ANt) KANSEI IWATA, "ARTS: Accelerated Ray-Tracing System," IEEE Computer Graphics and Applications, pp. 16-26, Apr. 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>563895</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[HAMLIN, GRIFFITH AND C. WmLtAM GEAR, "Raster-Scan Hidden Surface Algorithm Techniques," Computer Graphics, vol. 11, no. 2, pp. 264-271, Summer 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>893927</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[MARSH, DONALD M., "UgRay: An Efficient Ray-Tracing Renderer for UniGrafix," Tech. Report UCB/CSD 87/360, U.C. Berkeley, May 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[SEQUIN, CARLO H. AND PAUL R. WENSLEY, "Visible Feature Return at Object Resolution," Computer Graphics and Appl.,vol. 5, no. 5, pp. 37-50, May 1985,]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>577153</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[TREMBLAY, JFAN-PAUL AND PAUL G. SORENSON, The Theory and Practice of Compiler Writing, pp. 620-631, McGraw-Hill, New York, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[WHrI'mD, TURNER, "An Improved Illumination Model for Shaded Display," CACM, vol. 23, no. 6, pp. 343-349, June 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357295</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[WHITTED, ~mNER AND DAVID M. WEIMAR, "A Software Testbed for the Development of 3D Raster Graphics," ACM Transactions on Graphics, vol. 1, no. 1, pp. 43-58, January 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~' Computer Graphics, Volume 23, Number 3, July 1989 Parameterized Ray Tracing Carlo H. Sdquin and 
Eliot K. Smyrl t Computer Science Division Electrical Engineering and Computer Sciences University of 
California, Berkeley, CA 94720 ABSTRACT The consmaction and refinement of a computer graphics scene 
is unacceptably slow when using ray tracing. We in~oduce a new technique to speed up the generation of 
successive ray traced images when the geometry of the scene remains constant and only the light source 
intensities and the surface properties need to be adjusted. When the scene is first ray traced, an expression 
parameterized in the color of all lights and the surface property coefficients of all objects is calcu- 
lated and stored for each pixel. Redisplaying a scene with a new set of lights and colors then consists 
of sub- stituting values for the corresponding parameters and re-evaluating the expressions for the pixels. 
This parameter updating and redisplay takes only a few seconds, as compared to the many rnirtutes or 
hours required to ray trace the entire scene again, but it uses much more memory and disk space. With 
suitable expression sharing, however, these storage needs can be reduced to an acceptable level. CR 
Categories and Subject Descriptions: 1.3,3 [Computer Graphics]: Picture/Image Generation - Display algorithms 
1.3,7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Color, shading, shadowing, and texture 
General Terms: Algorithms, Graphics Additional Key Words and Phrases: Ray Tracing, Rendering, Parameterlzatlon, 
Surface Properties, Runlength Encoding, Subexpression Elimination, Hashing t Current Address: Pixar, 
San Rafael. CA Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Associatibn for Computing Machinery. To e0py otherwise, or to republish, requires a fee and/or specific 
permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0307 $00.75 1. INTRODUCTION The production of a computer 
graphics scene normally proceeds in stages: first, the various objects are created, then the scene is 
assembled, a proper view point is chosen, and finally the artist adjusts the colors and surface properties 
of the various objects and the lighting of the scene. Realistic and sophisticated scenes with shadows, 
reflections, and other lighting phenomena are often rendered with ray tracing methods [Whitted80], which 
are, however, computationally very demanding. Thus the re-rendering of a scene after every minor adjustment 
is time consum- ing and tedious. Furthermore, shading equations used in ray tracing often contain many 
coefficients that interact in complex ways. It is difficult even for experienced users to determine values 
that will produce the desired results when redisplaying after every small coefficient change takes such 
a long time. In these examples, the adjustment of the surface properties and light intensifies leaves 
the scene geometry unchanged; thus a ray going through a particular pixel will always hit the same object. 
Parameterized Ray Tracing is a method to re-render a ray traced scene which avoids retracing the path 
of the various rays after some adjustments to surface properties, colors, or lighting. This method calculates 
and stores a parameterized expression for each pixel as the scene is ray traced with a variant of an 
ordinary ray tracing program. These expressions explicitly contain all potential contributions from the 
various surfaces hit by the ray and by its reflected and refracted secondary and higher order com- ponents. 
The parameters in these expressions are the colors and intensities of the various ambient and directional 
light sources and the coefficients defining the surface properties of the various objects. Updating the 
surfaces and fights in a scene then consists of substituting values for these parameters and recalculating 
the expressions for the pixels in the display. The most straightforward implementation of the parameter- 
ized ray tracing concept is fairly simple, but it is slow and uses excessive amounts of memory. By incorporating 
several refinements, it is possible to reduce the time necessary to ray trace a scene and to redisplay 
successive images, as well as to reduce the amount of memory required to hold the expressions. The pro- 
cess of updating and redisplaying then takes only a few seconds, a significant improvement over the many 
minutes or hours required to ray trace the entire scene again. This allows rapid production of an image 
by an artist and also makes the effects of changes in surface properties much more obvious and intuitive. 
This tech- nique could even be used to provide a tutorial tool to demonstrate the visual effects of the 
many coefficients typically associated with the description of realistic physical surfaces. The next 
section reviews the shading equation used for building up the parameterized expressions for each pixel. 
Subse- quently we present the development of our renderer from the  :~~SIGG RAPH'89, Boston, 31 July-4 
August, 1989 above basic concept to a practical implementation with reasonable memory requirements and 
performance; we also show how the display times and memory needs decrease with subsequent stages of development 
and refinement. 2. SHADING EQUATION Figure 1 shows schematically the ray associated with one pixel leaving 
the eye and striking a surface A, which is both reflective and transparent. Thus a secondary ray is reflected, 
represented by the solid line, and another one, represented by the dashed line, is transmitted through 
the surface. The reflected ray strikes the surfaee of a solid object B, which is also reflective. The 
subsequent re fleeted ray then strikes another surface C, again reflective and transparent. The transmitted 
ray finally strikes the dark object D which is neither reflective nor transparent. The reflected ray 
hits one of the "background walls" which also ter- minates the ray. In order to derive an expression 
for the resulting pixel color seen by the eye, the contributions of these various components of the ray 
tree must be determined and properly summed. Our pararneterized ray tracer was implemented as a varia- 
tion of the already-existing ray tracer UgRay [Marsh87], developed as part of the Berkeley UniGrafix 
environment, and the latter program's paradigms for surface color, reflectance, and lighting were automatically 
adopted. For this ray tracer, the color visible on a surface is computed with the equation: I = (resulting 
intensity) (1) la ka c (ambient illumination term) + h~il kn c (~ t) (diffuse illumination term) + h~, 
ll ks(d'l~)p (rac+ (1-rn ~s)pecular illuminationterm) +I,k,(mc+(1-m)) (contribution of reflected ray) 
+It~ c (contribution of transmitted ray) In this equation: I = the red, green, and blue intensifies of 
the color returned. The unchanging geometry coefficients are: r~ = unit vector normal to surface at the 
intersection point, [ = unit vector pointing toward one of the light sources, : = unit vector in direction 
of ray, /~= unit vector hallway between F and ft. The light source parameters that can be varied are: 
ta = intensity of ambient light, Ii = intensity of light arriving from a light source. The surface properties 
that can be varied are: c = color of the surface at the point of intersection, ka = coefficient of diffuse 
reflection, k~ = coefficient of specular reflection, ki = coefficient of transmission, p = constant specifying 
specular highlight sharpness, m = metalness of the surface. The colors of secondary rays from other surfaces 
are: Is = color returned by a specularly reflected ray, It = color returned by a transmitted ray. This 
equation, similar to the shading equation in [Whit- ted80], is used to build the expressions for all 
pixels in the image. It must be evaluated separately for the red, green, and blue com- ponents of the 
intensity I using the appropriate R, G, or B com- ponents of the parameters 1,, Ii, and e as well as 
the secondary intensity contributions I, and It. A~ "''"""'""''"~ --4.... .... Figure 1: The Ray Tree 
for One Pixel The reflected and transmitted ray intensifies, I, and It, are the components I returned 
from some other surface. They may therefore change during an update and affect the value of the expression 
and the color of the pixel. These terms induce a tree structure on the evaluation of the resulting color 
of a pixel with subtrees that represent the values of reflected and transmitted higher order components. 
To evaluate an expression tree, these subexpressions are successively evaluated and "passed up the tree" 
to higher-level expressions. Finally the highest level expression at the root of the tree is evaluated 
and the actual pixel color is determined. Each node in this tree corresponds to one surface interac- 
tion and is represented by one expression of the form of Eqn.(1). Figure 2 shows the tree representing 
the scene in Figure 1. The nodes at A, B, and C represent interactions with the corresponding reflective 
or transparent surfaces. Interaction with surface D creates a leaf-node, since it is neither reflective 
nor transparent. "Background" represents ray tree components that leave the explicitly defined scene 
and are assigned a background color. Eye A . ///'" Background B C  o/ '//'/" D Background 
Figure 2: The Expression Tree for Figure 1. The various surface properties used in Eqn.(1), c, ka, k,, 
kt, p, and m, may be viewed collectively as a surface property vec- tor. All nodes at any level in the 
expression tree that refer to the same surface have the same surface property ~ector, independent ~ 
Computer Graphics, Volume 23, Number 3, July 1989 of viewing angle or surface orientation. Thus a surface 
property vector need be stored only once for each surface, not once for every ray that strikes the surface. 
Expression nodes thus contain only a reference to the appropriate surface property vector rather than 
a complete copy of the vector. 3. PRELIMINARY DEMONSTRATION Table 1 shows the problem posed by standard 
ray tracing: the time necessary to generate successive images becomes unac- ceptable as scene resolution 
and complexity increase. For Scene A (see plate A), ray tracing was performed on an HP 9000 Model 350SRX 
workstation with a Motorola 68020 pro- cessor, a floating-point coprocessor and 6 Megabytes of main memory. 
This scene contains some fractal mountains in the back- ground and a few regular, reflective geometric 
objects in the fore- ground. It is illuminated with ambient light and with one direc- tional light source; 
no shadow calculations have been performed. This scene contains 1080 faces and requires 775 kilobytes 
of memory for scene storage at any resolution. The runtimes for standard ray tracing shown in Table 1 
were obtained with UgRay, using uniform spatial subdivision [Fujimoto86] to give good per- formance on 
complicated scenes. For a high-resolution image, the ray tracing time may exceed an hour, so any kind 
of interactive updating is clearly impossible. Scene B (see plate B) drives home the magnitude of the 
problem. This scene combines many transparent and reflective objects, shadows, fog, ambient light, and 
three directional light sources, and was also rendered with anti-aliasing by adaptive oversampling [Whitted80]. 
It has 3576 faces and requires 7.89 Megabytes of scene storage memory. The rendering time given here 
is for a VAX 8650 with a floating-point coprocessor and 64 Megabytes of memory. The HP machine was not 
able to render this picture because it did not have enough memory and spent an excessive amount of time 
in paging. Even with a significantly more powerful computer, the time required to generate one image 
obviously precludes any realistic attempt to generate a series of images in order to fine-tune surface 
properties. With this problem in mind, we first implemented a straight- forward preliminary version of 
the basic concept of parameterized ray tracing. In this initial implementation, the only parameter varied 
was c, the surface color. This allowed the intensity expres- sion (1) to be collapsed into the much simpler 
form I= e y+ K+ Is (Gee +o)+Itxcc (2) where ~: = t,~l, k,(~'/~y (1 -m) ~c = ks m 0 = ks(1--m) and where 
y and ~: are vectors of three elements: one for each of R, G, and B. 'y, ~ oc, o, and x, are calculated 
once for each expression, so there are nine values for each expression that can be precomputed during 
ray tracing to reduce expression storage requirements and to make update evaluation faster. An expres- 
sion node comprises these values, together with pointers to at most two subexpressions and a pointer 
to the surface property vector which in this ease consists of only the surface color c. Standard Ray 
tracing SCENE A 1080 faces 0.8 Mb 100100 pixels 34 see 250250 pixels 207 see 500500 pixels 833 see 
1280x1024 pixels 5219 see SCENE B 3576 faces 8 Mb 1024768 pixels 73 I40 sec Table 1: Memory and CPU 
Requirements for Ray Tracing Image updating and evaluation then proceeds by evaluating the entire tree 
for each pixel in a post-order traversal. Each node is evaluated using equation (2) with the node's stored 
values, its subtrees, and the surface color it references. Successive contribu- tions are passed up the 
tree until a final pixel color can be calcu- lated and displayed. Parameterized Ray Tracing Redisplay 
Memory Use SCENE A 1080 faces 100x100 pixels 2 sec 1.3 Mb 250250 pixels 9 see 7.3 Mb 500500 pixels 
? see >20 Mb Table 2: Preliminary Parameterized Ray Tracing The results from this restricted implementation, 
given in Table 2, clearly demonstrated that the basic concept worked: update times for small images were 
typically reduced by about an order of magnitude. However, it became clear that a larger speed-up was 
necessary to make pararneterized ray tracing practi- cal for interactive scene refinement. Furthermore, 
medium-resolution images required more memory than the HP workstation could handle, Thus unless steps 
were taken to reduce memory requirements, only the most trivial scenes would be tractable even on midsize 
computers with several tens of Megabytes of memory.  4. ALGORITHM REFINEMENT The primary goals through 
the development process were to reduce memory requirements and the time necessary for redisplaying an 
image. This was accomplished primarily by reducing the number of expression nodes, which clearly reduces 
the amount of data that must be stored, but also speeds up the update and redisplay of the image since 
fewer expression nodes need to be evaluated. Further speed improvements are achieved if the data structure 
gets small enough so that it fits entirely into main memory, reducing the large paging overhead. This 
section presents and discusses various enhancements added to the basic concept in order to achieve the 
above two goals. For didactic reasons, we present these enhancements in the chronological order in which 
we implemented them, although some early developments were later superseded. The correspond- ing performance 
improvements will be compared in Section 5.  ~f,,~[~SIGG RAPH '89, Boston, 31 July-4 August, 1989 4.1. 
Sharing Expression Trees Many of the developments took advantage of various forms of image coherence. 
Objects and faces on objects in a typi- cal scene often cover many adjacent pixels, and thus, over some 
horizontal and vertical extent, pixels may be of identical color. It is then natural that all these pixels 
should share the same expres- sion tree. In smooth Shaded faces, adjacent pixels may often be very similar 
but not quite identical, so some quantitative decision must be made as to when pixels are similar enough 
so that they can share an expression tree. The computed total color value of a pixel, however, is not 
a sound basis for comparison; the resulting color may be an accidental coincidence of quite different 
combinations of various parameter values. In general this similarity would not persist when the parameters 
are changed. The comparison therefore requires a complete match of the entire expression trees. To determine 
whether two pixels are similar enough to share an expression tree, all geometric coefficients associated 
with each expression node in one tree are compared to the corresponding coefficients in the other tree. 
For this comparison, the range of the geometric dot products [0,1] is uniformly divided into lfE regions 
of size , and any two coefficients that lie in the same region are defined to be equivalent. 4.2. Runlength 
Encoding The first improvement to the preliminary implementation was the addition of simple rurdength 
encoding, taking advantage of the horizontal coherence of objects. The tree of the newest ray traced 
pixel is compared to the tree of the previous pixel on the current scan line. If it is similar enough, 
the new expression tree is discarded and the length of the current pixel run is increased by one. In 
the end, each run is represented by one expression tree, a starting x-value, and its length in number 
of pixels. This is simi- lar to the span buffers found in [Whitted82] but has been extended to include 
all the rendering information needed for ray tracing. Scanlines are now represented by a list of runs, 
rather than an array of pixel trees. Evaluation proceeds as before, except that only a single tree is 
evaluated for an entire run, and all the associ- ated pixels are displayed together. 4.3. Selective Expression 
Updating If the user adjusts one surface's color or other properties, it is unnecessary to reevaluate 
every expression in the image. To speed up reevaluation of many expression trees, the last computed value 
of the corresponding subtree is stored at each node of the tree, and a flag in each surface property 
vector indicates whether there was a change made to this surface. This flag is set during an update for 
all those surface property vectors that have been changed by the user. Before anode is evaluated, the 
flag on its associated surface property vector is checked; the node is reevaluated only if it has actually 
changed, otherwise, the "old" value is passed up the tree. However, if any expression node changes, all 
nodes above it must be reevaluated, even if the flags on their associated surface property vectors are 
not set. For exam- ple, consider a scene with a blue plate reflected in a shiny pink ball; if the blue 
surface is changed, all pixels on the shiny pink surface containing the blue reflection must also change, 
even though the node representing the shiny pink surface does not have its flag set. Although every expression 
node is still examined, actual calculation is now done only for nodes that need it. This enables much 
faster image update when only a limited area of the image is changed. For example, consider an image 
containing one small silver ball and other non-silver objects. If the silver is made shinier then only 
the expression lrees containing the ball, or reflected or transmitted rays that hit the ball, need to 
be reevaluated. All other pixels are simply redrawn with their old values. The cost of redisplay after 
a change of some parameters now depends on the number of nodes affected by the change. 4.4. 2-D Runlength 
Encoding In addition to horizontal coherence, objects usually have some vertical coherence, which can 
be exploited by a variation on runlength encoding, dubbed 2-D runlength encoding. In addition to comparing 
the new pixel to the previous pixel on the current line, the pixel is compared with the three nearest 
pixels on the pre- vious scan line. Thus two-dimensional areas and entire polygons can in principle be 
represented by a single expression tree. This further reduces the number of expressions. Scan lines still 
consist of runs, but now runs on different scan lines may point to the same expression tree. 4.5. Subexpression 
Sharing with Hashing So far, only pixels that were physically contiguous were able to share expression 
trees. However, a particular surface may be seen through several holes, and the background color often 
shows up in many separate discontiguous areas. The key to reducing the number of expressions for such 
a scene is to use a good scheme to find all such similar areas and permit them to share a single expression 
tree. Some kind of hashing scheme comes readily to mind for this purpose. We have used such an approach, 
and generalized it to permit sharing not only of entire expression trees, but of subtrees as well. In 
an average scene, many expression subtrees may be similar, even if the upper levels of the tree are different. 
For example, two differently-colored reflective walls may reflect the same floor polygon. Thus the subtree 
representing the ray contri- bution from the floor polygon can be shared between the two expression trees. 
This idea is very similar to the concept of com- mon subexpression elimination found in many optimizing 
com- pilers [Tremblay85, Aho86]. Our hashing scheme determines when sublrees might be equivalent and 
should be compared in detail. After the expression tree for a new pixel has been constructed, its nodes 
are entered into one of several hash tables in a bottom-up manner. If a node to be entered is similar 
enough to some node already in the table, the new node and its subtrees may be discarded and replaced 
by a reference to the already-existing node and its subtrees. In this way equivalent subtrees of all 
sizes throughout the image may be compared and redundant copies eliminated. The determination of node 
similarity is performed by comparing the entire subtrees rooted at those nodes. This is done in the same 
way as the com- parison of complete expression trees (Section ,4.1). As mentioned above, a temporary 
coincidence may allow nodes with different surface property vectors to appear the same, but this may 
change whenever any surface properties are altered. Because each node only represents one surface, nodes 
may be dis- tinguished immediately if they refer to different surface property vectors. Therefore, nodes 
with different vectors need not be com- pared further. A separate hash table is created for each surface 
property vector, containing all the nodes that use this vector. The result is a greater separation of 
nodes and thus greater hashing efficiency. The hash function for expression nodes is based only on geometric 
coefficients: light source directions, ray directions, and normal vectors; these are the only properties 
that cannot change during an update process. This separates nodes that may tem-porarily appear similar 
but will respond differently to coefficient changes. The geometric coefficients are represented in the 
expression nodes by the dot product terms in equation (1). @ ~ Computer Graphics, Volume 23, Number 3, 
July 1989 After much experinaentation, we chose the Weinberger hash function hashpjw given in [Aho86], 
which performs bit operations to fold individual bytes of a string into an integer result, and returns 
this result modulo a prime number equal to the hash table size. We construct the result by successively 
folding in the bytes of the geometric coefficients truncated down to an e- region boundary (Section 4.1). 
This function gives a very even distribution of nodes over the hash table, and all nodes within the same 
e-region will hash to the same location. In our implementation, collisions are resolved by chaining, 
When a node is classified into a particular chain by the index returned from the hash function, it is 
compared to the other nodes in the chain. If it is equivalent to another node in the sense described 
above, the new node is discarded, and a reference is created to the equivalent node. Since new entries 
are added at the front of the chains in the hash tables, new nodes will be compared to the most recent 
entries. This exploits the coherence in the pic- ture to minimize the number of comparisons that need 
to be made. Hashing supersedes simple 1-D or 2-D runlength encoding. Each node is now compared to nodes 
anywhere in the scene that hash to the same table location, not just to nodes from adjacent pixels. However, 
the scanline ordering of the data structure is preserved, with each scanline comprising runs of identical 
pixels as before. As a result, a given expression tree is still referenced by whole pixel runs, but these 
runs may now be scattered throughout the image. 4.6. Production of Intermediate File The parameterized 
ray tracing process consists of two dis- tinct phases. The first phase is the generation of expression 
trees as the scene is ray traced, and the second phase is the interactive process of successively changing 
parameters and redisplaying the image. These two phases were separated into two programs linked by an 
intermediate file that is generated by the first pro- gram and read by the second one. The file contains 
all the surface property vectors, the light source information, expression nodes, and scanline information 
in a binary encoded form. This intermediate file was not only convenient during development, allowing 
the different programs to be developed separately, but also gives the user more flexibility in scene 
genera- tion. An image once produced can be kept in such an intermedi- ate file, and the user may thert 
come back to the image whenever and as often as desired to change different parameters. 4.7. One-Time-Only 
Expression Updating As noted above, expression trees may be associated with more than one pixd run, and 
since runs are examined in scanline order, a tree may be encountered and thus evaluated more than once. 
Since subtrees are shared throughout the scene, any node or subtree may also be evaluated more than once. 
To avoid redun- dant evaluations, a serial number was attached to successive image updates, and a corresponding 
field in each expression node is set to the number of the current update. If a node is encoun- tered 
more than once during a single update, this number field will reveal this, and the previously computed 
value stored at this node will be used. 4.8. Generalization of Parameters The above optirnizations and 
refinements improved the performance and reduced the memory requirements significanfly. Thus we could 
afford to lift the preliminary restriction that only the surface color e could be varied, and allowed 
all of the surface properties and light source intensities to change. This required a more general form 
of storing the expression nodes, both in memory and in the intermediate file format, since equation (2) 
no longer applies. The only numbers stored directly with the expres- sions are now the dot product terms 
in equation (1), two for each light source. All surface properties are now kept explicitly in the surface 
property vectors, and light source intensifies are kept in similar "light source intensity vectors". 
 4.9. Addition of More Advanced Features The parameterization was extended further to handle vari- ous 
more complex features available in UgRay such as anti-aliasing, fog, attenuation of rays in solids, and 
local light sources. A concurrent change in the coefficient storage format from floating-point to fixed-point 
saved more memory. Although UgRay does not currently handle spline surfaces, our method can easily accommodate 
curved surfaces and other features commonly found in ray tracing programs. We also attempted to further 
speed up the algorithm by optimizing the data structure and node evaluations for eases where the user 
wants to vary only a limited set of parameters. However, even with a reduced set of parameters the shading 
equation (1) requires significant computation for each node evaluation, and we obtained little speed 
improvement in most cases. Since this ver- sion of the program actually required more memory, this "optimi- 
zation" was abandoned. 5. PERFORMANCE AND STORAGE IMPROVEMENTS Table 3 shows the improvements made by 
the successive refinements described in Section 4 for the example of a 500500 pixel rendering of Scene 
A. Note that minimum and maximum redisplay times axe given because selective expression updating (Section 
4.3) allows redisplay time to vary with the number of nodes affected by a change. Ray trace Redisplay 
Memory time (see) time (see) usage (Mb) Standard (UgRay) 833 833 0.8 Preliminary version > 200,000 ? 
> 20.0 Runlength encoding 934 10 2.5 Selective updating 949 3 to 7 2.8 2-D rurdength encoding 936 3 to 
6 1.6 Hashing 904 2 to 5 0.9 Full parameterization 917 5 to 8 1.2 Final implementation 910 5 to 8 1.2 
  Table 3: Development Summary Scene A with 500x500 resolution Overall, ray tracing time has increased 
by ortly about 10% over the time used by the standard ray tracer, UgRay. Redisplay time, on the other 
hand, has been reduced by a factor of 100 to 170. This performance improvement has been bought by an 
increase in memory usage; but note that of the 1.2 Mb required, 0.8 is used by the ray tracer for scene 
storage. The pararneterization over- head on memory is only 50%. Disk storage for the intermediate file 
has concurrently increased by a factor of 5 over that of an ordinary UgRay image file. Ray trace Redisplay 
Memory Ray tracing time (see) time (see) usage (Mb) Standard 4904 4904 8 Parameterized 5640 30 to 81 
28 Table 4: Scene B with 512><512 resolution The gearbox scene statistics in Table 4 are for the VAX 
8650 again. Parameterized ray tracing has reduced the average redisplay time for this difficult image 
from over an hour to a time on the order of one minute, which is just acceptable for interactive refinement. 
311 RAP H '89, Boston, 31 July-4 August, 1989     : SIGG 6. DISCUSSION AND CONCLUSIONS With all 
the discussed refinements included, pararneterized ray tracing achieves a speed improvement for redisplay 
by factors ranging from 50 to 175 for a scene composed of polyhedral objects. The additional overhead 
in initial ray tracing time to gen- erate the various expression trees is only about 10% to 15%. This 
performance improvement for scene updates comes at the cost of increased storage requirements. The main 
memory requirements increase by about a factor of 3, while the intermediate file that holds all the expression 
trees can be 10 to 15 times larger than the corresponding UgRay image file. In view of the continued 
rapid improvements in memory and disk technology, these increased storage demands seem acceptable. However, 
for any given machine, we can always construct a scene that is so complex that it will no longer fit 
into the avail- able main memory. This will result in significant paging overhead and lead to a dramatic 
performance drop. Unfortunately the current data structure shows little locality in its accesses since 
the node expressions can be shared between arbitrary pixels. An open research issue is to look for data 
structures that have more locality in their accesses and that might promise more gradual perfor- mance 
degradation when they exceed the available memory. In an environment with limited memory, it might even 
be worthwhile to restrict subtree sharing in favor of better disk management. Currently every expression 
is examined at each update, but only those that need to be changed are reevaluated, Is there a way to 
avoid even examining nodes that do not need to be changed? Conceptually, a network of pointers is required 
that links a chang- ing parameter to everything that can be affected. Our current tree structure provides 
connections only in the opposite direction, and requires every node to check all possible sources of 
a change. The enhanced structure would need to add pointers from every surface property vector and light 
intensity vector to all nodes that use them, and also pointers from all nodes to their parents. Then 
the nodes affected by a parameter change could be found directly and reevaluated, and this change could 
be propagated up the expression trees. We estimate that such a data structure would increase memory needs 
by about 20%, while reducing redisplay time by as much as 90% in some cases. This work is currently in 
progress. Parameterization techniques similar to those we have explored are applicable to other rendering 
algorithms, and in fact to many algorithms in which an invesmaent of time to precompute a structured 
representation of invariants can significantly speed up later computation. For example, the concept of 
pixel parameteri- zation was inspired by older rendering techniques that explicitly return all visible 
polygons found during hidden-surface elimina- tion [Hamlin77,Sequin85]. These polygons can be similarly 
linked to parameterized surface property vectors, permitting color changes without the need for redoing 
the hidden-surface calcula- tions. Radiosity algorithms use other techniques to take advan- tage of a 
fixed scene geometry. After calculating the form-factor matrices once, light source intensities and object 
colors can be changed rapidly by simply changing the patch brightnesses and then re-solving the matrices 
[Cohen85]. Parameterized ray tracing has proven useful not only for scene development and refinement, 
but also to provide an "interactive tutorial" for the many somewhat counter-intuitive surface property 
coefficients found in our shading formula. Novice users often experience great difficulties in obtaining 
exactly the parameter values they want for a particular surface. Pararneterized ray tracing allows them 
to "twiddle" the various eoeffieients individually or together and discover their effects on the appearance 
of a surface. Overall, the response of a few initial users to our prototype of a pararneterized ray tracer 
has been quite positive. Acknowledgements This work was supported by a National Science Founda- tion 
Graduate Fellowship, and is part of the research done in the context of the CISE Institutional Infrastructure 
Program: "Mas- sive Information Storage, Management, and Use" at U.C. Berke- ley. It was also supported 
by a grant from Tektronix, Inc. References AHO, ALFRED V., RAVI SETHI, AND JEFFREY D. ULI,MAN, Com- 
pilers: Principles, Techniques, and Tools, Addison-Wesley, Read- ing, Mass., 1986. COHEN, MICHAEL F. 
AND DONALD P. GREENBERG, "The Hemi- Cube: a Radiosity Solution for Complex Environments," Proceedings 
of SIGGRAPH '85 (San Francisco, California, July 22-26). In Computer Graphics 19, 3, pp. 31-40, July 
1985. FUJIMOTO, AKIRA, TAKAYUKI TANAKA, AND KANSEI IWATA, "ARTS: Accelerated Ray-Tracing System," IEEE 
Computer Graphics and Applications, pp. 16-26, Apr. 1986. HAMLIN, GRIFFITI-I AND C. WmLtAM GEAR, "Raster-Scan 
Hidden Surface Algorithm Techniques," Computer Graphics, vol. 11, no. 2, pp. 264-271, Summer 1977. MARSH, 
DONALD M., "UgRay: An Efficient Ray-Tracing Renderer for UniGrafix," Tech. Report UCB/CSD 87/360, U.C. 
Berkeley, May 1987. SEQUIN, CARLO n. AND PAUL R. WENSLEY, "Visible Feature Return at Object Resolution," 
Computer Graphics and Appl.,vol. 5, no. 5, pp. 37-50, May 1985. TREMBLAY, JEAN-PAUL AND PAUL G. SORENSON, 
The Theory and Practice of Compiler Writing, pp. 620-631, McGraw-Hill, New York, 1985. WH[t-rLD, TURNER, 
"An Improved Illumination Model for Shaded Display," CACM, vol. 23, no. 6, pp. 343-349, June 1980. WI-tu-r~O, 
TURNER AND DAVID M. WEIMER, "A Software Testbed for the Development of 3D Raster Graphics," ACM Transactions 
on Graphics, vol. 1, no. 1, pp. 43-58, January 1982.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74366</article_id>
		<sort_key>315</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[A Ray tracing algorithm for progressive radiosity]]></title>
		<page_from>315</page_from>
		<page_to>324</page_to>
		<doi_number>10.1145/74333.74366</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74366</url>
		<abstract>
			<par><![CDATA[A new method for computing form-factors within a progressive radiosity approach is presented. Previously, the progressive radiosity approach has depended on the use of the hemi-cube algorithm to determine form-factors. However, sampling problems inherent in the hemi-cube algorithm limit its usefulness for complex images. A more robust approach is described in which ray tracing is used to perform the numerical integration of the form-factor equation. The approach is tailored to provide good, approximate results for a low number of rays, while still providing a smooth continuum of increasing accuracy for higher numbers of rays. Quantitative comparisons between analytically derived form-factors and ray traced form-factors are presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P128978</person_id>
				<author_profile_id><![CDATA[81414601063]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Wallace]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[3D/EYE, Inc., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P153130</person_id>
				<author_profile_id><![CDATA[81540309256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Elmquist]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[3D/EYE, Inc., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P72204</person_id>
				<author_profile_id><![CDATA[81100474675]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Haines]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[3D/EYE, Inc., Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, Arthur, "Some Techniques for Shading Machine Renderings of Solids," Proceedings of the Spring Joint Computer Conference 32, 1968, pp. 37-49.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Afro, James, "Backwards Ray Tracing," Developments in Ray Tracing, SIGGRAPH Course Notes, Vol. 12, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30321</ref_obj_id>
				<ref_obj_pid>30300</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chattopadhyay, Subdeb, and Akira Fujimoto, 'q3i- Directional Ray Tracing," Computer Graphics 1987: Proceedings of CG International '87, Springer-Verlag, Tokyo, 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F. and Donald P. Greenberg, "A Radiosity Solution for Complex Environments," Computer Graphics (SIGGRAPH '85 Proceedings) 19, 3 (July 1985), pp. 31-40.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications 6, 2 (Jan. 1986), pp. 2&amp;35.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Shenchang Eric Chen, John R. Wallace, Donald P. Greenberg, "A Progressive Refinement Approach to Fast Radiosity Image Generation, .. Computer Graphics (SIGGRAPH "88 Proceedings) 22, 3 (August 1988), pp. 75-84.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter and Loren Carpenter, "Distributed Ray Tracing," Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), pp. 137-145.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., "Stochastic Sampling in Computer Graphics," A CM Transactions on Graphics 5, 3 (January 3241986), pp. 51-72.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dippe, Mark A. Z., Erling Henry Wold, "Antialiasing Through Stochastic Sampling", Computer Graphics (S{G- GRAPH '85 Proceedings) 19, 3, pp. 69-78.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, Bennet Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), pp. 213-222.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gouraud, Henri, "Continuous Shading of Curved Surfaces," 1LEE Transactions on Computers 20, 6 (June 1971), pp. 623-629.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Howell, John R., A Catalog of Radiation Co1~figuration Factors, McGraw-Hill, New York, 1982.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation," Computer Graphics (SIGGRAPH "86 Proceedings) 20, 4 (August 1986), pp. 143-150.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Malley, Thomas J. V., '~A Shading Method for Computer Generated Images," Master's Thesis, The University of Utah, 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>17755</ref_obj_id>
				<ref_obj_pid>17751</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Maxwell, Gregory M., Michael J. Bailey, and Victor W. Goldschrnidt, "Calculations of the Radiation Confi~tration Factor Using Ray Casting," Computer.Aided Design 18, 7 (September 1986), pp. 371-379.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki and Eihachiro Nakamae, "Continuous Tone Representation 06 Three-Dimensional Objects Taking Account of Shadows and Interreflection," Computer Graphics (SIGGRAPH '85 Proceedings) 19, 3 (July 1985), pp. 22-30.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>914720</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Rushmier, Holly E., '~Realistic Image Synthesis for Scenes With Radiatively Participating Media," Doctoral Thesis, Cotnell University, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert and John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC, 1981.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ward, Gregory J., Francis M. Rubinstein, Robert D. Clear, "A Ray Tracing Solutior~ for Diffuse Interreflection,"Computer Graphics (SIGGRAPH '88 Proceedings) 22, 3 (August 1988), pp. 85-92.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display," Communications of the A CM .32, 6 (June 1980), pp. 343-349.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 O~ Computer Graphics, Volume 23, Number 3, July 1989 A RAY TRACING ALGORITHM FOR PROGRESSIVE RADIOSITY 
John R. Wallace, Kells A. Elmquist, Eric A. Haines 3D/EYE, Inc. Ithaca, NY. ABSTRACT A new method for 
computing form-factors within a progres- sive radiosity approach is presented. Previously, the progres- 
sive radiosity approach has depended on the use of the hemi-cube algorithm to determine form-factors. 
However, sampling problems inherent in the hemi-cube algorithm limit its usefulness for complex images. 
A more robust approach is described in which ray tracing is used to perform the numerical integration 
of the form-factor equation. The approach is tailored to provide good, approximate results for a low 
number of rays, while still providing a smooth contin- uum of increasing accuracy for higher numbers 
of rays. Quantitative comparisons between analytically derived form- factors and ray traced form-factors 
are presented. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation 
-Display algorithms. 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism General Terms: 
Algorithms Additional Key Words and Phrases: radiosity, ray tracing, progressive refinement, distributed 
ray tracing, global illumi- nation.  INTRODUCTION The synthesis of realistic images requires the evaluation 
of a shading model which simulates the propagation of light within an environment. To obtain images quickly, 
local shad- ing models are often used in which shading is computed based only on direct illumination 
by the light sources. Real-istic shading, however, requires the use of a global illumina- tion model, 
in which secondary illumination provided by light reflected from other surfaces and the shadowing of 
one sur-face by another are taken into account. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to repub[ish, requires 
a fee and/or specific permission. In recent years much work has been applied to methods for evaluating 
the Lambertian diffuse illumination model. For Lambertian diffuse reflection, the intensity of light 
reflected by a surface is given by: Io., = p fI,.(O)cos0 d,~ (1) 2w where Io~ = intensity of reflected 
light p = diffuse reflectMty 0 = angle between surface normal and incoming direction O Ii,(O) = intensity 
of light arriving from direction O For local illumination models, the evaluation of this equation is 
straightforward, since the incoming light, 1~, arrives only from the light sources. However, for a global 
illumination model the problem is more difficult, since incoming light may arrive via secondary reflection 
from any surface visible to the point to be shaded. Evaluation is recursive, since the light arriving 
from other surfaces depends in turn on light arriving at those surfaces. Several approaches to solving 
this problem have been developed. One direction has been to extend conventional ray tracing using a monte 
carlo solution of the integral equation [7][8][20][13][19][17]. Radiosity methods derived from the field 
of radiative heat transfer have also been applied success- fully [10][4][16][5]. The radiosity method 
has the attractive characteristic of providing a view-independent solution. Hence, once the solution 
has been performed, a hardware renderer can be used to display the scene from changing viewpoints at 
interactive rates. Despite the advantage of view independence the radiosity method was, until recently, 
considered impractical for scenes of high complexity. Both the time and storage costs of the algorithm 
were O (n 2) (where n is the number of surfaces). However, the performance of the radiosity method has 
been greatly improved through the use of a progressive refinement strategy that provides good images 
early in the solution pro- cess [6]. AC M -0-89791-312 -4/89/007/0315 $00.75 '89, Boston, 31 July-4 
August, 1989  ~t(~.~SlGG RAP H In the progressive radiosity algorithm, illumination is com-puted one 
step at a time. At each step, the reflected or emit- ted illumination provided by a single surface is 
distributed to all the other surfaces. The determination of where the illumination fails in the scene 
is accomplished using the hemi-cube algorithm, in which the scene is scan converted from the point of 
view of the surface providing illumination. In effect, light is shot out from the source in a predefined 
uniform set of directions to land where it may in the environ- ment. Although the overall progressive 
radiosity approach provides an important improvement over previous radiosity methods for graphics, the 
use of the hemi-cube to determine illumination suffers inherently from aliasing and undersam-pling, particularly 
as the scene complexity increases. In this paper a new progressive radiosity algorithm is described in 
which ray tracing is used to determine the distri- bution of illumination from each primary or secondary 
source. The process of determining illumination can then be turned around; instead of shooting light 
out from the source in the uniform directions determined by the hemi-cube pixels, the new algorithm samples 
the illumination source from the point of view of each of the other surfaces in the environ- ment. Illumination 
is determined at exactly those points for which shading is desired, and problems of inadequate sam-piing 
and aliasing are reduced. In addition to improving illumination sampling, ray tracing provides new directions 
for broadening the scope and increasing the efficiency of radiosity. Examples include: non-physical 
light sources (e.g., point lights, unattenuated lights)  shadow testing against exact geometries  
ability to turn shadows on or off on a surface by surface basis  continuous shading of curved surfaces 
modeled by independent polygonal facets  shadows due to semi-transparent surfaces (filters)  Several 
of these features are illustrated in the results section. The new algorithm was developed as part of 
a software pack- age providing photorealism extensions to Hewlett-Packard's Starbase graphics interface. 
The development of this package demanded that all the primitives, attributes and other 3D graphics functionality 
provided by Starbase, a typical graphics interface, be supported for radiosity. The next section of this 
paper reviews the basic progressive radiosity algorithm and the inherent problems arising from the use 
of the hemi-cube in a progressive algorithm. The third section provides a solution to these problems 
in the form of a ray tracing algorithm for evaluating form-factors, the central step of the new progressive 
radiosity approach. Results are presented in the fourth section. PROGRESSIVE RADIOSITY The radiosity 
approach computes diffuse global illumination by solving a system of equations expressing the dependence 
of the energy leaving each surface on that arriving from every other surface. The energy leaving a surface 
is given by: n n~ = E~, + p,~B/jfj, (z) j=t where Bi = radiosity of surface i (energy per unit area) 
Ai = area of surface i Ei = emitted energy per unit area p~ = reflectivity of surface i Bj = radiosity 
of surface j Aj = area of surface j Fji = form-factor from surface j to surface i The form-factor, Fji, 
gives the fraction of energy leaving sur- face j that arrives at a second surface i. An equation of this 
form exists for every surface in the scene. The resulting.system of simultaneous equations can be solved 
using iterative techniques to determine the surface radiosities. A final shading calculation then uses 
these surface radiosities to determine the radiosity at the vertices of smaller polygonal elements into 
which the surfaces have been subdivided. Fol- lowing the radiosity solution, Gouraud interpolation based 
on the element vertex radiosities can be used to render smoothly shaded images. Unfortunately, forming 
the matrix prior to the solution requires determining and saving the form-factor between each surface 
and every other surface, a process that is O (n 2) both in time and memory (where n is the number of 
sur-faces). The progressive radiosity approach overcomes this difficulty by solving the radiosity equations 
in a series of steps. The solution proceeds as follows: do until converged Select surface with greatest 
reflected and/or emitted energy Compute form-factors from that surface to all surface elements in environment 
Based on form-factors, add contribution from source surface to radiosity of each element The form-factors 
from the source surface to the receiving elements are computed using the hemi-cube algorithm [4], in 
which all elements are projected, scan converted and z-buffered onto the five faces of a hemi-cube positioned 
at the source surface. In the early steps, the source surfaces chosen will be the light emitters since 
other surfaces will have as yet received very little illumination. Subsequent steps will select secondary 
sources, starting with those surfaces that received the most light directly from the light sources, and 
so on. Since each solution step updates the radiosity of all surfaces, the increasingly accurate result 
can be displayed following ~ Computer Graphics, Volume 23, Number 3, July 1989 each step. An estimated 
ambient term derived from the known energy yet to be distributed can be added to improve the image. Useful 
images can thus be produced very early in the solution process. There are, however, inherent problems 
in using a hemi-cube placed at the source surface to deter- mine form-factors. These problems will be 
discussed in the next section, following a brief discussion of some related approaches. SHOOTING ALGORITHMS 
In the progressive radiosity algorithm, the hemi-cube can be pictured as "shooting" light out from the 
source surface on which it is placed. The pixels of the hemi-cube determine a uniform point sampling 
of the environment as seen from the source. The form-factor from the source to a receiving sur-face, 
and thus the energy it receives, depends on the summed effect of any sample points that "landed" on the 
surface. The usual strategy for determining shading in computer graphics is to follow the path of light 
from the eye into the scene, thus avoiding the consideration of light that doesn't reach the eye. Ray 
tracing and its derivatives distributed ray tracing and path tracing are classic examples of this approach. 
However, such methods do not have information about where in the scene to look for important sources 
of light, other than the light emitters themselves. Hence, for a diffuse surface, much sampling may be 
expended on direc-tions from which little energy turns out to arrive. By starting at the emitters and 
at each step sending into the environment the light from the source of greatest reflected or emitted 
energy, the progressive radiosity algorithm continu- ally has information about where energy arrives 
from. Atten- tion can thus be focused on the most important sources of illumination. Even very small 
secondary sources that happen to reflect a great deal of light will be detected, a very difficult case 
when working entirely from the eye, as pointed out by Ward [19]. Several shading methods previous to 
progressive radiosity have noted the possible advantages of working from the point of view of the source. 
In an early experiment by Appel shad- ing was determined by shooting random rays from the light source 
into the scene, with the density of hits on a surface representing the shading value [1]. This approach 
was aban-doned because of the large number of rays required to get smooth results. Arvo [2] describes 
an algorithm for determining the secon-dary illumination of diffuse surfaces by light reflected or refracted 
by specular surfaces. Rays are shot from a point light source, refracted and reflected by specular surfaces, 
until they finally land on a diffuse surface. The diffusely reflected portion of the ray's energy is 
recorded on an illumi-nation map for the surface, that is, a grid mapped parametri- cally to the surface. 
The incoming energy is gathered to the vertices of the grid, which then provide diffuse shading values 
during a conventional ray tracing rendering of the scene. Arvo points out that "illumination rays must 
be many times as dense as the grid points" [2]. Otherwise, the shading produced is statistically uneven. 
Chattopadhyay [3] also describes a shading algorithm in which ray tracing from the primary light sources 
is used to determine the direct iUumination of diffuse surfaces, which are then treated as secondary 
light sources for a radiosity solution. The final image is determined by conventional ray tracing.  
Limitations of the Hemi-cube As noted by both Appel and Afro, the foremost difficulty with the shooting 
approach is uneven and inadequate sam-piing. For the hemi-cube, a surface that is large in the image 
may, when viewed from the light, be small enough to fall between the hemi-cube pixels. Such a surface 
will receive no illumination (figure 1). In addition, since the hemi-cube is a uniform sampling method, 
it will produce aliasing. The shad- hag of a fine grid of small polygons will show a distinct plaid pattern 
if the polygons are small enough to alias on the hemi-cube (figure 2.) Increasing the resolution of the 
hemi- cube to reduce these effects becomes expensive and, in any case, can never guarantee adequate sampling 
for all polygons. Source ~ ~ hemicube A/ Figure 1. Determining form-factors from a source to receiv- 
ing surfaces A, B and C using a hemi-cube placed at the source. Surface C incorrectly receives no illumination. 
A second difficulty with the use of the hemi-cube for progres- sive radiosity is that sources are normally 
surfaces with area. Performing a single hemi-cube at a source surface is equivalent to reducing that 
source to a point. To approxi-mate an area source, hemi-cubes must be performed at several points on 
the surface. However, the number of points necessary for a good approximation depends on how close the 
source is to the surface it illuminates. Using the hemi- cube, the number of points representing the 
source area will be the same for all receiving surfaces, since all surfaces are projected onto each hemi-cube. 
Finally, a hemi-cube placed on a source can only determine form-factors to receiving surfaces with finite 
areas (the ele- ments), not to point receivers (i.e., differential surface areas). Thus the radiosities 
at the element vertices, which are used to actually render the final image, cannot be determined directly. 
The radiosity at each vertex must be determined by '89, Boston, 31 July-4 August, 1989 Source ,~)urc 
grid of polygons polygon grid O[ polygorts polygon vertices vcrlices Figure 2. a) Aliasing due to uniform 
sampling imposed by the hemi-cube. A surface subdhdded into 11 by 13 elements is illuminated by a light 
source, b) The regular hemi-cube sampling pattern interacts with the regular receMng grid to generate 
aliasing. averaging the radiosity of the elements surrounding it. This introduces an additional level 
of imprecision and is a particu- lar problem when shading curved surfaces approximated by independent 
polygonal facets. Continuity of shading across such surfaces is normally ensured by calculating shading 
directly at the facet vertices using the true surface normal, as in Gouraud shading [11]. AN IMPROVED 
PROGRESSIVE RADIOSITY SOLUTION Clearly, the benefits of following light from the emitters pro- vided 
by progressive radiosity are worth preserving. For-tunately, the problems described in the previous section 
are not fundamental to the progressive algorithm. They originate from the fact that form-factors are 
determined by viewing the scene from the source to see what surfaces are visible in a uniform set of 
directions. What is ignored by this approach is that the points at which shading must ultimately be determined 
are the element ver-tices. It is the shading at these vertices that will be used when images of the environment 
are finally rendered. All of the problems just described may be eliminated by determining the illumination 
of these vertices directly. The new approach to progressive radiosity proceeds as fol-lows. As before, 
at each solution step the surface with the most reflected and/or emitted energy to contribute to the 
environment is treated as the source surface. Instead of per- forming a hemi-cube at this source, each 
element vertex in the scene is then visited and a form-factor is computed from the source surface to 
the vertex by shooting rays from the vertex to sample points on the source. This eliminates the sampling 
problems inherent in the hemi- cube approach, since illumination is guaranteed to be com-puted at every 
vertex (figure 3). Since the form-factors are computed independently at each vertex, each form-factor 
may be computed to any desired accuracy. The number of sample points on the source may vary from one 
vertex to the next, thus allowing area sources to be approximated as accurately as desired. Furthermore, 
the true surface normal at the ver- tex may be used, thus solving the problem of continuous Figure 3. 
a) Aliasing does not occur when illumination is computed directly at the vertices of the elements, as 
shown schematically in b). shading of independent surface facets. The use of ray tracing to point sample 
source-to-vertex form-factors is the key development in the new algorithm. A Ray Tracing Algorithm For 
Computing Form-Factors Ray tracing has already been used as a method for determin- ing form-factors [14][15]. 
In each of these works, form factors between a surface and one or more other surfaces are deter-mined 
by tracing rays outwards from the surface in directions distributed over the entire hemisphere above 
the surface. No knowledge about the energy arriving from other surfaces is available at the time form-factors 
are computed. Thus, there is no opportunity for concentrating sampling effort on sur-faces that will 
have the most effect on the illumination of the point. In progressive radiosity, the problem to be solved 
at each solution step is more restricted, since the surface with the most energy to emit or reflect into 
the environment is known. For each element vertex in the scene it is only necessary to determine the 
form-factor from the single source surface to the vertex (more rigorously, a differential area located 
at the vertex). In what follows, a technique for numerically integrating the form-factor equation using 
ray tracing is derived. The development of this technique was driven by the constraint that it provide 
good, approximate results for a low number of rays, while allowing increasingly accurate results for 
higher numbers of rays. The derivation begins with the equation for the form-factor from differential 
area dA 1 to a differential area dA 2 (figure 4a) [18]: cos01 cos02 ~ (3) dFdR1-dR 2 -- ,Trr 2 where 
0x = angle between normal at dA 1 and direction to dA 2 0 2 ~-angle between normal at dA 2 and direction 
to dA 1 r = distance between the areas @ ~ For the form-factor to a finite area A 2 equation 3 must 
be integrated over the finite area: cos01 cos02 Fa"II'A2 = fa2 dA2 (4) fftr 2 This integral can be solved 
analytically for simple configura- tions, but in general it must be evaluated numerically. Numerical 
integration may be accomplished in a straightfor-ward manner by approximating the integral as the sum 
of form-factors computed for smaller regions of area ALl 2 (fig- ure 4b): FaAi.A2 = ~ CS01i cs02/ Z~k,zl2 
(5) i = 1 '1TFi 2 However, equation 5 breaks down if A,,l 2 is large relative to the distance; as r becomes 
less than one, AA 2 must shrink correspondingly, or the result grows without bound. To limit the subdivision 
of the source and thus the cost of computing form-factors while avoiding the difficulty of equa- tion 
5, the delta areas are treated explicitly as finite areas. An equation for the form-factor from finite 
delta areas can be obtained by approximating each delta area by a simple fin- ite geometry for which 
an analytical solution is available. dA2  U r, dA 1 (b) Figure 4. a) Form-factor from differential 
area 1 to differen- tial area 2. b) Numerical integration of form-factor from differential area 1 to 
finite area 2. Analytical solutions for a variety of configurations can be found in the literature [18][12]. 
Because of its simplicity, a disk has been chosen as the finite area upon which to base the approximation. 
The form-factor from a differential area dA l to a directly opposing receiving disk of area A 2 and radius 
a is given by: F,~ra 2 = a2 / ( r 2 + a 2 ) (6) Using the reciprocity principle, dA 1Faa l-A2 = A 2dFa 
2-aA i (7) Computer Graphics, Volume 23, Number 3, July 1989 r r'~d.4 t  (a) (b) Figure 5. a) Configuration 
for form-factor between disk and differential area facing each other on parallel planes, b) Configuration 
for approximate form-factor between arbitrarily oriented disk and dif-ferential area. the form-factor 
from a disk source to a differential area receiver (figure 5a) can be obtained: dFA 2 "aA l = dA 1 / 
( 'rrr2 + A 2 ) (8) This relationship can be generalized by making some approx- imations. The effect 
of different orientations of the source and receiving areas can be approximated by including the cosines 
of the angles between the normal at each surface and the direction between the source and the receiver 
(figure 5b). dFA2.dA 1 ~-~ dA 1 cos01 cos02 / ( qrr 2 +" A2 ) (9) A further approximation is to assume 
that the area is disk shaped. The accuracy of this approximation depends, of course, on the area's actual 
shape. A study of the effects of these approximations is presented in the results section. To evaluate 
the form-factor from a general source to a ver- tex, the source is divided into delta areas. The form-factor 
due to each delta area is computed using equation 9. Occlu-sion is tested by shooting a single ray from 
t.he receiving ver- tex to the center of the delta area on the source. This ray is a simple shadow ray, 
in other words, it provides only a yes or no answer to the question of whether anything is intersected. 
In further discussion, this will be referred to as sampling the source, and rays will be said to be shot 
from the vertex to sample points on the source. If sample points are distributed uniformly on the source 
then the total form-factor is simply the sum of the form-factors computed for each sample point i: 1 
n COS01i COS02/ = dA 1--~i (a0) dFA 2-aA 1 n i=1 ql"ri 2 --t- a 2/trl where n = number of sample points 
on source ~i = 1 ff sample point is visible to vertex, 0 if occluded  ~ Computer Graphics, Volume 23, 
Number 3, July 1989 source. However, the use of a constant, uniform distribution of sample points on 
the source can produce form-factor alias- ing, which is particularly noticeable at shadow edges. If the 
surface mesh is fine enough, for a small number of sample points overlapping sharp-edged shadows may 
appear where only one soft-edged shadow is expected (figure 6). The problem of aliasing can be addressed 
in several ways. Some improvement may be gained by simply filtering the ver- tex radiosities using a 
weighted average of neighboring vertex radiosities, as shown in figure 6c. However, this can only be 
done if the vertex connectivities are known. One approach to eliminating aliasing is to jitter the location 
of the sample points on the source. This converts the alias- ing to noise [8][9] and is a powerful antialiasing 
approach if the number of samples is high enough. However, stochastic methods in image synthesis generally 
take advantage of the fact that noise at the pixel level is not interpreted by the eye as structure in 
the image. In the radiosity method shading is evaluated at the vertices of a surface mesh in object space, 
not at individual pixels. In the image these vertices may be separated by tens of pixels, with intervening 
pixels shaded by interpolation. Statistical irregularities that might be accept-able for neighboring 
pixels become artifacts at this scale. This is particularly true when the number of samples is very small. 
An example of this result is shown in figure 6. In general, obtaining accurate form-factors in difficult 
cases requires increasing the sampling rate, that is, the number of sample points on the source. Since 
the form-factor from a source to a vertex is computed independently of all other ver- tices, the number 
of sample points used to represent the source can be varied from vertex to vertex as necessary. One possibility 
is to simply recompute the form-factor for a given vertex-source pair using successively greater numbers 
of uni- formly distributed sample points, until the difference between the resulting form-factors drops 
below a certain criterion. Thus, at vertices lying on shadow boundaries many rays may be shot to achieve 
an accurate form-factor, while vertices completely inside or outside the shadow will require a much smaller 
number. This technique was used for the shading of the office in figure 10. When a large number of sample 
points are required, how- ever, the use of a uniform distribution can be extremely wasteful. Figure 7 
illustrates a particularly difficult case, a large source very dose to the receiving surface. When a 
uni- form distribution of 16 samples is used, the results are dearly inadequate. Increasing this number 
will expend unnecessary effort in shooting rays from each vertex to points that make little difference. 
The solution is to subdivide the source adaptively for each receiving vertex, as shown in figure 7b. 
For each receiving vertex, the source was initially subdivided uniformly into 16 delta areas. The form-factors 
and the amount of energy received from each delta area were deter-mined by shooting a ray to the center 
of the area. Each delta area was then subdivided reeursively until the amount of energy received fell 
below a user specified criterion. Note that when the source is subdivided into unequal areas, the summation 
in equation 12 must become the area weighted average of the form-factors due to each of the delta areas. 
The images in the following results section were all computed using uniformly spaced sample points. Filtering 
of the vertex radiosities was also used where connecthdtty information was available. RESULTS Form factors 
obtained using ray tracing from a vertex to an area source are compared to analytical results for several 
configurations in figures 8 and 9. The analytical formulas were obtained from Howell [12]. These results 
illustrate several characteristics of point sampling using equation 10. The results are quite close for 
a square source. Accuracy decreases as the source becomes more oblong (figure 8). The results also become 
less accurate as the source and ver- tex move off axis from one another (figure 9). However, since the 
magnitude of the form-factors decreases at the same time, relative error is greatest at angles where 
incoming energy will make the smallest contribution. In each case, increasing the number of sample points 
brings the approxi- mate result closer to the correct result. In figure 10 an office scene has been rendered 
for three suc- cessive points in the solution process. The image in figure 10a was generated by an initial 
step in which direct illumination due to light sources was computed without shadow testing, an easy modification 
to the ray sampling algorithm that provides a fast initial image. Figure 10b was rendered after nine 
solu- tion steps and consists of direct illumination by the light sources with shadow testing. Figure 
10c was rendered after 21 solution steps and took 12 minutes on a Hewlett-Packard 9000 Series Model 835 
turboSRX workstation (all subsequent statistics are for this machine). The office model contains 903 
polygons, nine area light sources and 22,775 element vertices. In figure 11 a quadratic spline surface 
trimmed with several cubic spline trimming curves is illuminated by an area light source. The resulting 
shading is smooth, even though the ele- ments used to approximate the spline surface are small. (The 
spline surface is subdivided into 28 by 42 elements.) Such surfaces would require the use of a very high 
hemi-cube reso-lution to avoid aliasing. The scene contains 6086 element ver- tices. It was computed 
for 10 steps and took 3 minutes. Five sample points per source were used. The use of ray tracing allows 
the geometry used for shadow testing to be different from that used to represent objects for shading 
and rendering. For example, in figure 12 a lattice constructed of spheres and cylinders is illuminated 
by an area light source. The spheres and cylinders are divided into polygonal elements for shading and 
display. However, for shadow testing during the form-factor computation, the ray tracer intersects the 
original, true surface geometries. The ability to use different geometric representations for shadow 
testing and for shading and rendering provides an important source of efficiency for radiosity, since 
representing complex shading can require subdividing surfaces into a very large number of small elements. 
By ray tracing against the original geometries surfaces can be represented by as many elements as desired 
without increasing the cost of each shadow test. The model consists of 64 spheres and 108 cylinders. 
The    "~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 potential amount of energy to be received 
from the current source. The use of ray tracing to determine form-factors in a radios- ity approach 
simplifies the integration of radiosity with stan- dard 3D graphics interfaces. Features common to these 
inter- faces, such as non-physical light sources and facet modeling of curved surfaces can easily be 
handled. When fully integrated with such an interface, the progressive strategy can be extended so that 
images rendered at interactive rates using a hardware shader can then smoothly progress to the realism 
provided by the full radiosity solution. ACKNOWLEDGMENTS Particular thanks go to Michael Cohen for contributions 
to both the development of the algorithm and the writing of this paper. Samir Hanna, Don Greenberg and 
Dave Larson also provided helpful readings of early drafts. The team that developed the radiosity and 
ray tracing software included Louise Watson and Dan Loewus, as well as the authors, at 3D/EYE, Inc. and 
Ken Martin, Dave Larson, Kent Montgomery and Joan Bushek at Hewlett-Packard. Model-ing credits go to 
John Lin for Chartres cathedral, Adam Stettner for the office and Paul Booth for the gears. All models 
except the spline and the lattice where produced using Hewlett-Packard ME Series 30. All images were 
photo- graphed by Lee Melen. REFERENCES 1. Appel, Arthur, "Some Techniques for Shading Machine Renderings 
of Solids," Proceedings of the Spring Joint Com- puter Conference 32, 1968, pp. 37-49. 2. Afro, James, 
"Backwards Ray Tracing," Developments in Ray Tracing, SIGGRAPH Course Notes, Vol. 12, 1986. 3. Chattopadhyay, 
Subdeb, and Akira Fujimoto, "Bi-Directional Ray Tracing," Computer Graphics 1987: Proceed- ings of CG 
International '87, Springer-Verlag, Tokyo, 1987. 4. Cohen, Michael F. and Donald P. Greenberg, "A Radiosity 
Solution for Complex Environments," Computer Graphics (SIGGRAPH '85 Proceedings) 19, 3 (July 1985), pp. 
31-40. 5. Cohen, Michael F., Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity 
Approach for Realis- tic Image Synthesis," IEEE Computer Graphics and Applica- tions 6, 2 (Jan. 1986), 
pp. 26-35. 6. Cohen, Michael F., Shenchang Eric Chen, John R. Wal- lace, Donald P. Greenberg, "A Progressive 
Refinement Approach to Fast Radiosity Image Generation," "Computer Graphics (SIGGRAPH "88 Proceedings) 
22, 3 (August 1988), pp. 75-84. 7. Cook, Robert L., Thomas Porter and Loren Carpenter, "Distributed 
Ray Tracing," Computer Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), pp. 137-145. 8. Cook, 
Robert L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics 5, 3 (January  1986), 
pp. 51-72. 9. Dippe, Mark A. Z., Erling Henry Wold, "Antialiasing Through Stochastic Sampling", Computer 
Graphics (S[G-GRAPH '85 Proceedings) 19, 3, pp. 69-78. 10. Goral, Cindy M., Kenneth E. Torrance, Donald 
P. Green- berg, Bennet Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer 
Graphics (SIGGRAPH '84 Proceedings) 18, 3 (July 1984), pp. 213-222.  I1. Gouraud, Henri, "Continuous 
Shading of Curved Sur-faces," IEEE Transactions on Computers 20, 6 (June 1971), pp. 623-629. 12. Howell, 
John R., A Catalog of Radiation Configuration Factors, McGraw-HLll, New York, 1982. 13. Kajiya, James 
T., "The Rendering Equation," Computer Graphics (SIGGRAPH "86 Proceedings) 20, 4 (August 1986), pp. 143-150. 
 14. Malley, Thomas J. V., 'A Shading Method for Computer Generated Images," Master's Thesis, The University 
of Utah, 1988. 15. Maxwell, Gregory M., Michael J. Bailey, and Victor W. Goldschmidt, "Calculations 
of the Radiation Configuration Factor Using Ray Casting," Computer-Aided Design 18, 7 (September 1986), 
pp. 371-379. 16. Nishita, Tomoyuki and Eihachiro Nakamae, "Continuous Tone Representation 06 Three-Dimensional 
Objects Taking Account of Shadows and Interreflection," Computer Graphics (SIGGRAPH '85 Proceedings) 
19, 3 (July 1985), pp. 22-30. 17. Rushmier, Holly E., "Realistic Image Synthesis for Scenes With Radiatively 
Participating Media," Doctoral Thesis, Cor- nell University, 1988. 18. Siegel, Robert and John R. Howell, 
Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington De, 1981. 19. Ward, Gregory 
J., Francis M. Rubinstein, Robert D. Clear, "A Ray Tracing Solution for Diffuse  Interreflection,"Computer 
Graphics (SIGGRAP[I '88 Proceed- ings) 22, 3 (August 1988), pp. 85-92. 20. Whitted, Turner, "An Improved 
Illumination Model for Shaded Display," Communications of the ACM 32, 6 (June 1980), pp. 343-349.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74367</article_id>
		<sort_key>325</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Improving radiosity solutions through the use of analytically determined form-factors]]></title>
		<page_from>325</page_from>
		<page_to>334</page_to>
		<doi_number>10.1145/74333.74367</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74367</url>
		<abstract>
			<par><![CDATA[Current radiosity methods rely on the calculation of geometric factors, known as form-factors, which describe energy exchange between pairs of surfaces in the environment. The most computationally efficient method for form-factor generation is a numerical technique known as the hemi-cube algorithm. Use of the hemi-cube is based on assumptions about the geometry of the surfaces involved. First, this paper examines the types of errors and visual artifacts that result when these assumptions are violated. Second, the paper shows that these errors occur more frequently in progressive refinement radiosity than in the originally proposed full matrix radiosity solution. Next, a new analytical technique for determining form-factors that is immune to the errors of the hemi-cube algorithm is introduced. Finally, a hybrid progressive refinement method that invokes the new technique to correctly compute form-factors when hemi-cube assumptions are violated is presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Viewing algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P52167</person_id>
				<author_profile_id><![CDATA[81100268787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Baum]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P104665</person_id>
				<author_profile_id><![CDATA[81100255828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Rushmeier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P129281</person_id>
				<author_profile_id><![CDATA[81100128670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Winget]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akeley, Kurt, Tom Jermoluk, "High Performance Polygon Rendering," Computer G raphics(SIGG RAPH ' 88 Proceedings), Vol.22, No.4, August 1988, pp.239-246.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Afro, James, "Backward Ray Tracing," Developments in Ray Tracing(SIGGRAPH '86 Course Notes), Vol. 12, August 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bergman, Larry, Henry Fuchs, Eric Grant, Susan Spach, ~'Irnage Rendering by Adaptive Refinement," Computer Graphics (SIGGRAPH '86 Proceedings), Vol.20, No.4, August I986, pp.29-38.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, "The Hemi-Cube: A Radiosity Solution for Complex Environments," Computer Graphics(SIGGRAPH '85 Proceedings), Vol.19, No.3, July 985, pp.31-40.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, Vol.6, No.2, March 1986, pp.26-35.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Shenchang Eric Chen, John R. Wallace, Donald P. Greenberg, "A Progressive Refinement Approach to Fast Radiosity Image Generation," Computer Graphics (SIGGRAPH '88 Proceedings), Vol.22, No.4, August 1988, pp.75-84.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., "A Consumer's and Developer's Guide to Radiosity," A Consumer's and Developer's Guide to Image Synthesis(SIGGRAPH "88 Course Notes), 1988.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C., "The Aliasing Problem in Computer- Generated Shaded Images," Communications of the ACM, Vol.20, No. 11, November 1977, pp.799-805.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Domancich, Micheline. "Graphics Research: A Rambling Tour of French Research Labs Finds Them Hard at Work," Computer Graphics World (July I988) pp. 113-1 I4.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, Bennett Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics(SIGGRAPH'84 Proceedings), Vol. 18, No.3, July 1984, pp.213-222.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hottel, Hoyt C., Adel F. Sarofim, Radiative Transfer, McGraw- Hill, New York, NY, 1967.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Howell, J. R.,A Catalog of Radiation Configuration Factors, McGraw-Hill, New York, 1982.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki, Eihachiro Nakamae, "Continuous Tone Representations of Three Dimensional Objects Taking Account of Shadows and Interreflection," Computer Graphics (SIGGRAPH '85 Proceedings), Vol.19, No.3, July 1985, pp.23-30.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44654</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Samet, Hanan, Robert E. Webber,"Hierarchicat Data Structures and Algorithms for Computer Graphics, Part lit Applications," IEEE Computer Graphics and Applications, Voi.8, No.4, July 1988, pp.59-75.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert, John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC, 1981.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sparrow, E. M.,"A New and Simpler Formulation for Radiative Angle Factors," Transactions of the ASME, Journal of Heat Transfer, Vol.85, No.2, 1963, pp.81-88.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Walton, George. N., "Algorithms for Calculating Radiation View Factors Between Plane Convex Polygons with Obstructions," Fundamentals and Applications of Radiation Heat Transfer (24th National Heat Transfer Conference and Exhibition), HTD-Vol.72, August, 1987, pp.45-52.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Zhu, Yining, Qunsheng Peng, Youdong Liang, "PERIS: A Programming Environment for Realistic Image Synthesis," Computers and Graphics, Vol. 12, No.3/4, 1988, pp.299-308.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ ~ Computer Graphics, Volume 23, Number 3, July 1989 Improving Radiosity Solutions Through the Use 
of Analytically Determined  Form-Factors Daniel R. Baum, Holly E. Rushmeier* and James M. Winget Silicon 
Graphics Computer Systems 2011 N. Shoreline Blvd. Mountain View, CA 94039-7311 +George W. Woodruff School 
of Mechanical Engineering Georgia Institute of Technology Atlanta, GA 30332-0405 Abstract Current radiosity 
methods rely on the calculation of geometric factors, known as form-factors, which describe energy exchange 
between pairs of surfaces in the environment. The most computationally efficient method for form-factor 
generation is a numerical technique known as the hemi-cube algorithm. Use of the hemi-cube is based on 
assumptions about the geometry of the surfaces involved. First, this paper examines the types of errors 
and visual artifacts that result when these assumptions are violated. Second, the paper shows that these 
errors occur more frequently in progressive refinement radiosity than in the originally proposed full 
matrix radiosity solution. Next, a new analytical technique for determining form-factors that is immune 
to the errors of the hemi- cube algorithm is introduced. Finally, a hybrid progressive refinement method 
that invokes the new technique to correctly compute form- factors when hemi-cube assumptions are violated 
is presented. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation--display 
algorithms, viewing algorithms; 1.3.7[Computer Graphics]: Three-Dimensional Graphics and Realism --color, 
shading, shadowing, and texturing.  General Terms: Algorithms. Additional Key Words and Phrases: analytical 
form-factor, global illumination, progressive refinement, radiosity, Z-buffer. 1. Introduction Generating 
realistic computer images requires accurate modelling of visible light. The radiosity method has proven 
to be a useful approach for computer graphics illumination calculations. For efficiency, radiosity methods 
rely on a numerical algorithm known as the hemi-cube algorithm [4] to compute form-factors. This paper 
examines the sources of error in the hemi-cube algorithm and develops a new technique to analytically 
determine form-factors and eliminate these errors. The radiosity method, borrowed from thermal engineering 
[ 15] and introduced to computer graphics by Goral et al. [ 10] and Nishita and Nakamae [13], models 
light interreflections between diffuse surfaces. In the original, full matrix radiosity method, the environment 
to be rendered is discretized into small surfaces. Geometric factors, Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0325 
$00.75 known as form-factors, which describe the energy exchange between surfaces are calculated for 
each pair of discrete surfaces. The form- factors are then used to generate a set of simultaneous equations 
defining the interrelationships between surfaces in the environment. Given the emitted intensities of 
light sources, the simultaneous equations are solved to yield the intensity of light leaving each small 
surface. Once the intensities have been calculated, the environment can be viewed from any direction 
without performing additional illumination calculations. The primary advantage of the radiosity method 
is that, unlike ray-tracing, the solution is view independent, Precomputed light intensities from the 
radiosity method can be used for interactively directed tours of synthetic environments. Because of its 
view independence, the full matrix method has been implemented in several image synthesis testbeds [9][18]. 
In the radiosity method, much of the computational burden is in the determination of the form-factors. 
In an environment of N surfaces, N 2 form-factors must be determined. Originally, in Goral's presentation, 
form-factors were calculated by numerical integration of contour integrals [ 16]. This approach, however, 
did not allow for hidden surfaces. In Nishita and Nakamae's approach, again using numerical integration, 
hidden surfaces were detected by performing visibility tests between pairs of vertices. Cohen replaced 
these techniques with the hemi-cube algorithm which efficiently determines form-factors in the presence 
of hidden surfaces by combining Nusselt's analogy from heat transfer with the Z-buffer algorithm from 
computer graphics [41. Even when the hemi-cube algorithm is used, a disadvantage of the full matrix radiosity 
method is the large computation and storage requirement prior to image generation. Cohen et al, [6] developed 
a revised method that greatly reduced the time to first image and overall storage costs by applying progressive 
refinement [3] to the radiosity method. In progressive refinement radiosity, the process of finding all 
form-factors and then solving a set of equations is replaced by a process that sequentially computes 
the incremental effect on all surfaces of the light emitted and/or reflected from each surface. Generally, 
a small number of light sources and bright surfaces determine most of the global illumination in an environment. 
By processing these first, the progressive method quickly iterates to a good estimate of the global illumination. 
The disadvantage of a long wait to first image is converted to the advantage of quickly obtaining an 
estimate of the global illumination of the environment. Furthermore, since form-factors are computed 
on-the-fly for each iteration, storage costs are reduced from O(N 2) to O(N). For efficiency, the progressive 
refinement approach utilizes the hemi-cube algorithm to compute form-factors. The hemi-cube algorithm 
is based on various assumptions about environmental  ~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 
 geometry. When these assumptions are violated, the hemi-cube algorithm produces inaccurate form-factors, 
which in turn produce visual artifacts in the image. The structure of the progressive refinement method 
causes the hemi-cube assumptions to be violated more frequently and to a greater extent than in the full 
matrix method. As a result, not only are the visual artifacts more pronounced, but the method generally 
will not converge to the same solution as the more exact full matrix method. This paper presents a new 
approach for calculating form- factors, employing a hybrid combination of analytical and numerical techniques. 
The analytical technique does not rely on the geometric assumptions underlying the hem i-cube algorithm. 
Thus, by employing the new analytical technique when the hemi-cube assumptions are violated, inaccuracies 
of form-factors and subsequent visual artifacts can be reduced and often eliminated. The next section 
reviews the formulations of the full matrix and progressive radiosity techniques. Section 3 explains 
the assumptions underlying the hemi-cube algorithm and examines the inaccuracies that result when these 
assumptions are violated. In Section 4, the impact of the hemi-cube form-factor errors on both the full 
matrix and progressive radiosity solutions is investigated. Additionally, Section 4 explains why, in 
general, the progressive refinement method and the full matrix method do not produce equivalent solutions. 
In Section 5, an analytical technique for computing form- factors is formulated that is independent of 
the geometric assump- tions required for the hemi-cube. Section 5 also integrates the new technique into 
a hybrid progressive refinement method. The implementation and results of the new algorithm are presented 
in Section 6. 2. Full Matrix And Progressive Refinement Radiosity Algorithms In this section, a brief 
review of the full matrix and progressive refinement radiosity methods is presented in preparation for 
later error analysis. 2A. Full Matrix Radiosity In the full matrix (FM) radiosity method, the light 
intensity leaving each surface in the environment is found by solving the following matrix equation: 
f l-plFll -plFI2 ]Fill F'El-] -p2F21i I-p2F22i (l) [-pNFNI -9NFN2 i_pNFNN._] LIN.z LIEN_I where: p~ 
= reflectivity of surface i I i = intensity of surface i (for diffuse surfaces = radiosity of surface 
i ht) IE~ = the emitted intensity of surface i N = the number of surfaces in the environment The form-factor 
F.. equals the fraction of energy leaving surface i that arrives at surface j and is given by: 1 ["f 
cos0i cos 0 i HID dAidA i Fij = A'-T 2 (2) nr ij Ai where: 0~, 0j, and r u are shown in Fig. 1 HID is 
equal to 1 if dA i is visible to dA. and is equal to 0 otherwise. J ej Ni /  Figure 1. Form-factorGeometry 
Implicit in Eq. (1) is the assumption that the intensity across each surface is constant. Equation (2) 
can be viewed as the average over area Ai of the integral over Aj. Solving Eq. (1) for a coarse discretization 
of the environment yields a good global estimate of illumination, but does not give the detail required 
for a realistic image. Details are obtained without increasing the size of the matrix in Eq. (1) by using 
a substructuring method developed by Cohen et al. [5], based on a hierarchy of surfaces [ 14]. Each surface 
is divided into relatively large subsurfaces or patches. Each patch is further divided into subsurfaces, 
termed elements. Form-factors are found from each element to each patch. Patch-to-patch form-factors 
are then calculated using: 1 Fij -Ai E A e Fej (3) e~ E i where: E~ is the set of elements in patch 
i F~3 = the form factor from patch i to patch j Fej = the form factor from element e to patch j Ae, A 
i = the areas of element e and patch i, respectively Using these patch-to-patch form-factors, the intensity 
ot each patch is found by solving Eq. ( 1 ). The intensity of each element is then calculated using back 
substitution: Ie =Pe [Fel Fe2 ..-FeN] I2 (4) I where the I N are the intensities of the N patches in 
the environment. 2B. Progressive Refinement Radiosity Progressive refinement (PR) radiosity can be viewed 
as the radiosity equivalent of backward ray tracing [2] or two-way ray tracing [18]. Intensities in the 
environment are incremented by shooting energy out from surfaces for which estimates of intensity have 
already been found. The incremented intensities are found from the following equation: ~ Computer Graphics, 
Volume 23, Number 3, July 1989 I AIi- ] ~-plFli- l (5) AIN_I I_pN:FNi_I where: I~ = the intensity of 
a surface i for which an intensity estimate has already been made At e = the increment in the estimated 
intensity for element e. As in the FM solution, a low cost, detailed solution is needed. Again, patch/element 
substructuring is employed Intensity Ii on the right hand side of Eq. (5) is shot from the relatively 
large patches. Incremental intensities on the left hand side are calculated for the smaller elements. 
3. Calculation Of Form-Factors Using The Hemi-Cube Algorithm In this section the formulation and assumptions 
of the hemi- cube algorithm are reviewed. Then, for each assumption, the errors associated with its violation 
are discussed. 3A. The Hemi-Cube Algorithm Both the FM and PR radiosity methods require form-factors 
F between every pair of surfaces The first step in simplifying the U integral for F~j in Eq. (2) requires 
two geometric assumptions: first, the proximity assumption, that the distance between surfaces A i and 
A. is great compared to the effective diameter of Ai; second, the visibility assumption, that the visibility 
of surface i from dAj does not change. The form-factor may then be approximated as: " cos 0icos 0 i HIDdA 
i Fij ~ 2 (6) nr ij J Aj In the hemi-cube (He) algorithm, form-factors are found by placing a HC over 
the center of surface i, as shown in Fig. 2. Each side of the HC is discretized into hemi-cubepixels. 
The form-factors from the center of surface i to each of these pixels are precomputed and are termed 
delta form-factors. All surfaces are projected onto each face of the HC using the Z-buffer algorithm 
to determine visibility. assumption, is that the true projection of each visible surface onto the HC 
be accuractely accounted for using a finite resolution He. This assumption and the equivalence of form-factors 
implied by Nusselt's analogy [15], allows the form-factor Fij to be approximated by: Fij ~ ZAFq (7) qeQij 
where: Q~j is the set of HC pixels through which surface j is visible to the center of surface i. AFq 
is the delta form-factor associated with pixel q. The HC algorithm is efficient for finding the form-factors 
F.. from surface i to all other surfaces j (i.e. a matrix row). However, U in the PR method, the form-factors 
F. from all surfaces j to a surface jl i are needed (t.e. a matrix column). In this case, the HC algorithm 
can be used to find F~j, followed by application of the reciprocity relation- ship to yield: Ai Fji = 
~j Fij (8) Note that the accuracy of Fj~ depends strongly on the accuracy of F~j, A i , and A;  3B. 
Errors Created By The Violation Of The Proximity Assumption The proximity assumption is violated whenever 
surfaces are adjacent to one another. Consider two perpendicular surfaces, S, and S 2, of dissimilar 
size as shown in Fig. 3. The analytical values of the form-factors between these surfaces are F2~ =.247 
and F 12 =.0494. The limiting values of these form-factors calculated with an infinite resolution hemi-cube 
are equal to the analytical values of the form- factors calculated from the centers of the surfaces: 
Fd2 ~ =.238 and Fdl 2 =.00857. The approximation Fd21 is relatively good, since the area of S 2, is much 
smaller than the area of S,. In general, except for points near the boundary of S 2 and S~, the distance 
from S 2 to any particular point on S~ is nearly the same for all points on S 2. The approximation Fd~.2 
is quite poor, however, The distance from the center of S~ to points in S 2 is quite different than the 
distance from the edges of S~ to points on S 2. Since form-factor dependence on distance is non- linear, 
the effects of changing distance do not cancel out, and the result is a poor estimate of the form-factor. 
"q"- -i ......h.. 1 Figure 2. The Hemi-cube In the limiting case of an infinite resolution HC, the integral 
over A in Eq. (6) may be replaced with a summation over the J assomated HC pixels. In practice, only 
finite resolution HCs are possible. The third major assumption, the resolution or aliasing Figure 3. 
Two perpendicular surfaces of dissimilar size '89, Boston, 31 July-4 August, 1989 SIGGRAPH Errors in 
form-factors are not limited to surfaces oriented at right angles to one another. In Fig. 4a we consider 
nine geometries: three possible HC pixel locations in combination with three possible element normal 
orientations. In Fig. 4b, the relative errors between true form-factors and form-factors calculated with 
the HC algorithm are plotted versus normalized distance for each geometry. Normalized distance is the 
distance between the patch center and the element center, divided by the patch diameter. For example, 
an element with a normal that is parallel to the patch normal, and that projects onto a pixel on the 
comer of the hemi-cube, the relative error in the form- factor is greater than 100% for normalized distances 
less than 0.3, and comes within 2.5% only for normalized distances greater than 1. For all of the geometries, 
the form-factors produced with the HC algorithm converge to the true values as the distance is increased. 
It is also true, however, that relative errors approach infinity as the normalized distance approaches 
zero. In the worst case, the two surfaces must be separated by at least five patch diameters (assuming 
a square patch) for the relative error to drop below 2.5 percent. Center Corner ray ray ,. , Perpendicular 
1 ~# Racual L / ~ Parallel Ilk Edge &#38; ,," &#38;,/ i .,'" L ~, ~ I ~(.:..~.1 -1~ ray ..~i!i!~, hemi-cube 
Element orientations relative to patch normal Figure 4a. Geometric orientations used to generate Figure 
4b Radial-Center [] Para-Center X Perp-Center O Radial- Comer A Para-comer ;g Perp-Corner Radial-Edge 
~-Para-Edge Perp-Edge % Error 100 >--~---" ~ ._.i 75 ~ ! 50 ~- 25 , ~ x, A -25 -~,'f l I  -75 * 
i J -100 I ~ C ,~ .. 0.1 1 10 Normalized Distance Figure 4b Relative errors between HC computed form-factors 
and true values (note Radial-Center is equivalent to Para.-Center) 3C. Errors Created By The Violation 
Of The Visibility Assumption The visibility assumption requires that the variable HID stay constant across 
surface i for any given HC pixel j. Because HID is a discontinuous function (either 0 or 1), the single 
point evaluation is a possible source of significant error. In Fig. 5, the center of surface 1 has a 
complete view of surface 2, while intervening surface 3 obscures much of surface 1 from surface 2. In 
this case, the HC algorithm will overestimate Ft2 by using Fd~ 2 calculated from the center of surface 
1. t I / t I i / t l t i t t I J , t ii /  I I / / I I ii 1 I iI / /" ,~L.S~ace 1/ Figure 5. Geometry 
where form-factor from center of surface 1 to surface 2 is a poor estimate of F12 because of intervening 
surface 3 3D. Errors Created By The Violation Of The Aliasing Assumption The aliasing assumption, that 
surfaces project exactly onto whole numbers of He pixels, results in a problem very similar to that encountered 
in image display [8]. Consider the geometry shown in Fig. 6. An accurate value of the form-factor requires 
the true projected area of the surface onto the He. Because of the finite resolution of the HC pixels 
however, the projected area and resultant form-factor may be either over or under estimated. Figure 6. 
HC aliasing can cause over/underestimate of projected surface area In many cases, HC aliasing results 
in intensity errors that are not visually detectable. However, HC aliasing can cause significant errors 
and disturbing visual artifacts when calculating form-factors to or from light sources. HC aliasing can 
be reduced by increasing the HC resolution or by using multiple HC samples and filtering the results 
(thus increasing the computational expense of finding form- factors).  ~,1~ SIGGRAPH '89, Boston, 31 
July-4 August, 1989 was noted in the original PR approach, and the recommended so- lution was to subdivide 
the shooting patch. The following criteria were given: subdivide a shooting patch if 1) there is a large 
intensity gradient across the patch and/or 2) if any element-to-patch form- factors exceed unity. These 
criteria are necessary but not sufficient. Criterion 1 fails to improve the most critical form-factors-- 
those from light sources. Figure 4 shows that element-to-patch form-factors computed with the HC can 
erroneously exceed unity when the element is extremely close to the patch. Thus, criterion 2 only corrects 
the size of the shooting patch when other surfaces lie very close to the patch. In PR, HC aliasing is 
most apparent when shooting from a light source. For a given HC resolution, aliasing effects will appear 
and worsen as surfaces are subdivided into smaller elements. Fig. 9 shows the plaiding effect which can 
occur when computing form-factors from the light source. 5. Calculation Of Accurate Form-Factors The 
inaccuracies due to violation of HC assumptions can be reduced or eliminated by recognizing that the 
HC serves two distinct functions: first, visibility determination between surfaces, second, form-factor 
calculation at the HC pixel level. For pairs of surfaces which do not violate the HC assumptions discussed 
in the previous section, the HC algorithm can be used for both visibility and form- factor calculation. 
When computing form-factors involving surfaces which are too close relative to their size, or for form-factors 
involving light sources, the HC should be used only for visibility determination. For these special cases, 
the form-factors should be determined by an alternate more accurate method. In this paper, the form-factors 
for close surfaces and the form-factors involving light sources are determined using an analytical formula. 
A general approach to the generation of efficient algorithms is the appropriate application of specialized 
analytical simplifications prior to invocation of more general numerical methods. Many analytical solutions 
for form-factors have been determined for specific geometries [ 12]. However, for environments containing 
surfaces of arbitrary size and orientation a more general approach is needed. Some general analytical 
simplifications of the form-factor integral which are useful in numerical calculations have been outlined 
by Walton [17]. The most common simplification is application of Stoke's theorem to reduce the form-factor 
double area integral to a double contour integral. As mentioned earlier, Goral used the contour integral 
form to calculate form-factors. In this paper, we propose an algorithm in which the outer integral in 
Eq. (2) will be integrated numerically while the inner integral will be evaluated analytically. By applying 
Stoke's theorem, the inner area integral can be reduced to a contour integral. For an arbitrarily oriented 
planar polygon, this contour integral can be evaluated pointwise for a differential surface area dA in 
closed form J as: 1 FdAjAi=~" Z Nj * Fg (9) g~Gi where: G~ is the set of edges in surface i Nj is the 
surface normal for the differential surface j F is a vector with magnitude equal to the angle gamma (in 
ragdians) illustrated in Fig. 10, and direction given by the cross product of the vectors gg and Rg, 
l as illustrated in Fig. 10. A detailed derivation of Eq. (9) can be found in [ 11 ]. Figure 10. Geometry 
for evaluating analytical form-factor Next we describe a procedure for combining Eq. (9) with the HC 
algorithm within the framework of the PR method. To minimize computational expense we employ a hybrid 
combination of the HC and analytical calculations. The hybrid method processes HC pixels in the standard 
fashion until detecting a violation of the geometric assumptions. For those selected pixels analytic 
evaluation is used. The new procedure uses the same patch/element substructuring as the previous radiosity 
methods. We first describe the application of this new approach to simple convex environments, then to 
more complex environments with hidden surfaces. 5A. Application To Convex Environments In a convex environment 
all surfaces are in full view of one another. Variations of intensity across individual surfaces are 
continuous since there are no shadows. The procedure has two stages: first, the highly radiative surfaces 
are processed, then the remaining surfaces are considered. Usually the highly radiative surfaces correspond 
to light sources To facilitate the description of the new method, light sources are used in place of 
highly radiative surfaces. Figure 11. Using the HC to identify element sample points Initially, the energy 
is shot from each light L. All elemems in the environment are projected onto a HC positioned over the 
center of L. As shown in Fig. 11, each HC pixel corresponds to a sample point on a visible element. Each 
sample used in determining the form- factor Fee is weighted by the area of the pixel projected onto the 
element, AA , divided by the total visible element area. The . ep . . increment of intensity for each 
element e is equal to the element-to- light form-factor, Fee, times the light intensity, I e. The form-factors 
FeL are found by: @ ~ Computer Graphics, Volume 23, Number 3, July 1989 Initialize." For all elements 
e{ Normalize. For all elements e whose form-factors were FeE= 0 computed analytically { } Process. Project 
all elements onto HC centered over L } For each HC pixel p and associated sample point on element e{ 
.._analytical FeL += ~eL AAep } Normalize." For all elements e{ FeL /= L &#38;Aep } analytical where: 
FeL is computed using Eq. (9) ,~Aep is the element area associated with pixel p. Note that using this 
procedure: 1.) The accuracy of FeE is independent of the point chosen on the light source with respect 
to geometrical errors. 2.) Here AA plays the role of dA in Eq. (9) thus the assumption ep . j . ' . 
. that the area from whmh the form-factor is calculated is small is satisfied by calculating from these 
small, sub-element sized areas. 3.) F L is a weighted average of samples, rather than a sum depending 
on sample count. Because the magnitude of FeL does not depend directly on the number of HC pixels onto 
which element e projects, HC aliasing effects will begin to occur only when some elements entirely miss 
being projected onto the HC, rather than when the projection of elements cover a relatively small number 
of pixels. To minimize sensitivity to aliasing, we apply this analytical approach to find all form-factors 
from elements to light sources, regardless of whether the elements and light source are in close proximity. 
In the second stage, the remaining surfaces are processed. Since these surfaces have a smaller effect 
on the overall illumination, the analytical approach is only required for surfaces found in close proximity. 
For far surfaces the patch-to-element form-factor is computed using the original HC algorithm followed 
by the application of reciprocity to yield the desired element-to-patch form-factor. Given an upper bound 
on the acceptable form-factor error, the criterion for whether two surfaces are close to each other can 
be determined using information from Fig. 4. With this criterion the procedure for non-light source patch 
is: Initialize: For all elements e{ } Process." Project all elements onto HC centered over patch i For 
each HC pixel p and associated sample point on element e{ IF (Dep < Dmi n) ELSE +=AFp } For all elements{ 
   (- )eie } where: ~ei is the analytically computed portion of Fei is the numerically computed portion 
of Fei Dep is the distance from the origin of the HC on patch i to sample point p on element e D is the 
minimum distance derived from Fig. 4 such that the mm HC form-factor satisfy acceptable error bounds 
AFp is the delta form-factor associated with pixel p from Eq. (7) Using the analytical formula together 
with the closeness criterion substantially increases accuracy at a small computational expense. 5B. Application 
To A Non-Convex Environment In a non-convex environment, not all surfaces have an unobstructed view of 
one another. While the HC is useful for determining visibility of an element from one particular point 
on a shooting patch, it provides no information on whether the element has unobstructed view of the entire 
shooting patch. Using either reciprocity alone to find F. (as in the original PR method) or using the 
J.J . analyUcal formula described above assumes a full vmw of the shooting patch and gives an incorrect 
result when part of the shooting patch is occluded. To avoid violation of the visibility assumption, 
each shooting patch must be subdivided until its components are either fully visible to or fully hidden 
from each element in the environment. We propose two methods for detecting when such subdivision is necessary. 
First, visibility errors in using the procedure described in Section 5A can be detected in a non-convex 
environment by forming the following sum after finding all the element-to-patch form-factors to patch 
i: TOTAL F=  -~-F -Ai ei (10) e The value of TOTAL F in Eq. (10) is the approximation of the sum of 
Fie for all elements e in the environment. For the interior of a closed region, this sum should be unity. 
If the sum is greater than 1.0, some form-factors have been over estimated because of partially hidden 
surfaces. If the sum exceeds unity by a small amount (e.g. less than a few percent), the form-factors 
are approximately correct. In this instance, to avoid shooting out more energy from patch i than it actually 
has, the form-factors ~i should be normalized by: Fei /= TOTAL_F (11) If the sum exceeds 1.0 by a significant 
amount then visibility errors exist for one or more surfaces in the environment. In this instance, the 
shooting patch needs to be subdivided, and the procedure recursively applied to each sub-patch. A precise 
estimate of visibility is particularly crucial when shooting from light sources. The above procedure 
generates an average visibility error estimate over the entire environment. Errors in form-factors from 
lights, even for a relatively small number of elements, can produce undesirable artifacts. To avoid such 
errors, we   '~,,~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 and a high level of geometric detail. 
Although the number of elements has increased only slightly, the number of patches is almost an order 
of magnitude larger. For this reason it was impractical to compute the O(N z) storage FM solution; in 
contrast, the various O(N) PR methods were viable. The results of the new hybrid PR method are shown 
in two scenes from a walk-thru of the pavilion in Figs. 14 and 15. In the images, note the shadow detail, 
diffuse interreflections, and the lack of HC aliasing artifacts (plaiding) 7. Conclusion This paper 
detailed the three assumptions underlying the numerical HC algorithm: proximity, visibility, and aliasing. 
When any of these assumptions are violated, the HC algorithm produces inaccurate form-factors causing 
visual artifacts in the resultant images. Although both the FM and PR methods as originally proposed 
rely on the HC algorithm to determine form-factors, it was shown both theoretically and empirically that 
the PR approach is much more likely to violate the HC assumptions. As a result, the PR method will generally 
not converge to the same solution as the more accurate FM method. A new analytical technique to compute 
form-factors that is immune to the errors of the HC algorithm was introduced. Finally, a hybrid PR method 
that combines the new analytical technique with the original HC algorithm was presented. The hybrid method 
computes form-factors analytically when violations of the HC assumptions are detected and computes form-factors 
numerically otherwise.  8. Ackno~vledgements We gratefully acknowledge the support of the entire Silicon 
Graphics team. In particular, Eft Fogel cofounded the radiosity project and wrote much of the testbed 
software. Dave Ligon modeted the Barcelona Pavillion. Torn Davis provided valuable input on the derivation 
of Eq. 9, and Rolf Van Widenfelt wrote visualization software. Val Jerrnoluk and Bill Staab expedited 
required equipment for this collaborative research effort. Paul Haeberli and Mark Compton prepared all 
color images in this paper for accurate reproduction by creating digital color separations using image 
processing tools that come standard with SGI's IRIX rM operating system. Finally, we thank George Walton 
of the National Bureau of Standards for providing useful information about existing computer programs 
for computing form-factors.  9. Reference 1. Akeley, Kurt, Tom Jermoluk, "High Performance Polygon Rendering," 
Computer Graphics(SIGGRAPH' 88 Proceedings), Vol.22, No.4, August 1988, pp.239-246. 2. Arvo, James, 
"Backward Ray Tracing," Developments in Ray Tracing(S1GGRAPH '86 Course Notes), Vol. 12, August 1986. 
 3. Bergman, Larry, Henry Fuchs, Eric Grant, Susan Spach,"Image Rendering by Adaptive Refinement," Computer 
Graphics (SIGGRAPH '86 Proceedings), Vol.20, No,4, August 1986, pp.29-38. 4. Cohen, Michael F., Donald 
P. Greenberg, "The Hemi-Cube: A Radiosity Solution for Complex Environments," Computer Graphics(SIGGRAPH 
'85 Proceedings), Vol. 19, No.3, July 1985, pp.31-40.  5. Cohen, Michael F., Donald P. Greenberg, David 
S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer 
Graphics and Applications, Vol.6, No.2, March 1986, pp.26-35. 6. Cohen, Michael F., Shenchang Eric Chen, 
John R. Wallace, Donald P. Greenberg, "A Progressive Refinement Approach to Fast Radiosity Image Generation," 
Computer Graphics (SIGGRAPH '88 Proceedings), Vol.22, No.4, August 1988, pp.75-84.  7. Cohen, Michael 
F., "A Consumer's and Developer's Guide to Radiosity," A Consumer's and Developer's Guide to Image Synthesis(SlGGRAPH 
"88 Course Notes), 1988. 8. Crow, Franklin C., "The Aliasing Problem in Computer- Generated Shaded Images," 
Communications of the ACM, Vol.20, No. 11, November 1977, pp.799-805.  9. Domancich, Micheline. "Graphics 
Research: A Rambling Tour of French Research Labs Finds Them Hard at Work," Computer Graphics World (July 
I988) pp. 113-114.  10. Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, Bennett Battaile, 
"Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics(SIGGRAPH '84 Proceedings), 
Vol. 18, No.3, July 1984, pp.213-222. 11. Hottel, Hoyt C., Adel F. Sarofim, Radiative Transfer, McGraw-Hill, 
New York, NY, 1967.  12. Howell, J. R., A Catalog of Radiation Configuration Factors, McGraw-Hill, New 
York, 1982. 13. Nishita, Tomoyuki, Eihachiro Nakamae, "Continuous Tone Representations of Three Dimensional 
Objects Taking Account of Shadows and Interreflection," Computer Graphics (SIGGRAPH '85 Proceedings), 
Vol. 19, No.3, July 1985, pp.23-30. 14. Samet, Hanan, Robert E. Webber,"Hierarchicat Data Structures 
and Algorithms for Computer Graphics, Part I[: Applications," IEEE Computer Graphics and Applications, 
Voi.8, No.4, July 1988, pp.59-75. 15. Siegel, Robert, John R. Howell, Thermal Radiation Heat Transfer, 
Hemisphere Publishing Corp., Washington DC, 1981. 16. Sparrow, E. M.,"A New and Simpler Formulation 
for Radiative Angle Factors," Transactions of the ASME, Journal of Heat Transfer, Vol.85, No.2, 1963, 
pp.81-88. 17. Walton, George. N., "Algorithms for Calculating Radiation View Factors Between Plane Convex 
Polygons with Obstructions," Fundamentals and Applications of Radiation Heat Transfer (24th National 
Heat Transfer Conference and Exhibition), HTD-Vol.72, August, 1987, pp.45-52. 18. Zhu, Yining, Qunsheng 
Peng, Youdong Liang, "PERIS: A Programming Environment for Realistic Image Synthesis," Computers and 
Graphics, Vol. 12, No.3/4, 1988, pp.299-308.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74368</article_id>
		<sort_key>335</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[A general two-pass method integrating specular and diffuse reflection]]></title>
		<page_from>335</page_from>
		<page_to>344</page_to>
		<doi_number>10.1145/74333.74368</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74368</url>
		<abstract>
			<par><![CDATA[We analyse some recent approaches to the global illumination problem by introducing the corresponding <i>reflection operators</i>, and we demonstrate the advantages of a two-pass method. A generalization of the system introduced by Wallace <i>et al.</i> at Siggraph '87 to integrate diffuse as well as specular effects is presented. It is based on the calculation of <i>extended form-factors</i>, which allows arbitrary geometries to be used in the scene description, as well as refraction effects. We also present a new sampling method for the calculation of form-factors, which is an alternative to the <i>hemi-cube</i> technique introduced by Cohen and Greenberg for radiosity calculations. This method is particularly well suited to the extended form-factors calculation. The problem of interactive display of the picture being created is also addressed by using hardware-assisted projections and image composition to recreate a complete specular view of the scene.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31096847</person_id>
				<author_profile_id><![CDATA[81100402503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sillion]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Laboratoire d'Informatique de l'Ecole Normale Sup&#233;rieure, U.R.A. 1327, CNRS]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31090777</person_id>
				<author_profile_id><![CDATA[81100047435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Puech]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Laboratoire d'Informatique de l'Ecole Normale Sup&#233;rieure, U.R.A. 1327, CNRS]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn. Models of light reflection for computer syntl~esized pictures. Computer Graphics, 11:192-198, 1977. Proceedings SIGGRAPH 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Michael F'. Cohen, Shenchang Eric Chen, John R. Wallace, and Donald P. Greenberg. A progressive refinement approach to fast radiosity image generation. Computer Graphics, 22(4):75-84, August 1988. Proceedirtgs SIGGRAPH 1988 in Atlanta.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Michael F. Cohen and Donald P. Greenberg. The hemi-cube : A radiosity solution for complex environments. Computer Graphics, 19(3):31- 40, July 1985. Proceedings SIGGRAPH 1985 in San Fransisco.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, Thomas Porter, and Loren Carpenter. Distributed ray tracing. Computer Graphics, 18:137-147, July 1984. Proceedings SIGGRAPH 1984 in Minneapolis.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook and Kenneth E. Torrance. A reflectance model for computer graphics. A ChI Trar,sactions on Graphics, 1:7-24, 1982.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Franklin C. Crow. Summed-area tables for texture mapping. Computer Graphics, 18:207-212, July 1984. Proceedings SIGGRAPIt 1984 in Minneapolis.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Olivier Devillers, Claude Paech, and Franqois Sillion. CIL : un rnod- ~le d'illumination int~gs'ar~t les rdflexionz diffuse et sp~culaire. Technical Report 87-12, Labori~toire d'Informatique de I'ENS, 45 rue d'Ulln, 75230 Paris Cedex 05, France, October 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cindy M. Goral, Kenneth E. Torrance, Donald P. Greenberg, and Bennett BattaJle. Modeling the interaction of light between diffuse surfaces. Computer Graphics, 18(3):213-222, July 1984. Proceedings SIG- GRAPH 1984 in Minneapolis.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Robert W. ttornbeck. Numericttl Methods. Quantum Publishers, 1975.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[David S. Immel, Michael F. Cohen, and Donald P. Greenberg. A radiosity method for non-dlffuse environments. Computer Graphics, 20(4):133-142, August 1986. Proceedings SIGGRAPH 1986 in Dallas.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya. The rendering equation. Compute1" Graphics, 20(4):143-150, August 1986, Proceedings S1GGRAPH 1986 in Dallas.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Nishita and E. Nakanlae. Continuous tone represent atiol~ of threedimesional objects taking account of sltadows and interrellection, Cornputer Graphics, 19(3):23-30, July 1985. Proceedings SIGGRAPIt 1985 in San Francisco.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906584</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Bui-Tuong Phong. Illumfi~ation for Computer Generated Images. PhD thesis, University of Utah, t973.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37436</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Holly E. Rushmeier and Kenneth E. Torrance. The zonal method for calclflating light intensifies in the presence of a part.icip~ting medi~m. Computer Graphics, 21(4):293-302, July 1987. Proceedings SIG- GRAPH 1987 in Anaheim.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378492</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Min-Zhi Shao, Qun-ShelLg Peng, and You-Dung Liang. A llew radiosity approach by procedural refinements for realistic image synthesis. Cornpurer Graphics, 22(4):93-101, August 1988. Proceedings SIGGRAPH 1988 in Atlanta.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Franqois Siilion. Sintulatio~ de l'dclairage pour la synthdsc d'images : l~dalisme et Dderactivit(. PhD thesis, Universitd Paris XI. June 1989. (available from LIENS).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[John R. Wallace, l~lichac'l F. Cohen, and Donald P. Greenberg. A twopass solution to the rendering e(luation : a synthesis of ray-~,racing and radiosity methods. Cort~puter Graphics, 21(4):311-320, July' 1987. Proceedings SIGGRAPII 1987 in Anaheim.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Gregory J. Ward, Francis M. Rubinstein, and Robert D. Clear. A ray tracing solution for diffuse interreflection. Computer Graphics, 22(4):85-92, August 1988. ProceedingsSIGGRAPlt 1988 in Atlanta.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[John E. Warnock. A Hidden-Surface Algorithm for Computer Generated Halftone Pictures. Technical Report 4-15, University of Utah Computer Science Dept., June 1969. NTIS AD 753 671.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 A General Two-Pass Method Integrating Specular and 
Diffuse Reflection. Francois Sillion, Claude Puech Laboratoire d'Informatique de l'Ecole Normale Sup~rieure 
U.R.A. 1327, CNRS Abstract We analyse some recent approaches to the global illumination prob- lem by 
introducing the corresponding reflection operators, and we demonstrate the advantages of a two-pass method. 
A generaliza- tion of the system introduced by Wallace et al. at Siggraph '87 to integrate diffuse as 
well as specular effects is presented. It is based on the calculation of extended form-factors, which 
allows arbitrary geometries to be used in the scene description, as well as refraction effects. We also 
present a new sampling method for the calculation of form-factors, which is an Mternative to the hemi-cube 
technique introduced by Cohen and Greenberg for radiosity calcu- lations. This method is particularly 
well suited to the extended form-factors calculation. The problem of interactive display of the picture 
being created is also addressed by using hardware-assisted projections and image composition to recreate 
a complete specular view of the scene. CR Categories and Subject Descriptors: 1.3.3 [Computer Graph-ics]: 
Picture/Image Generation -Display Algorithms. 1.3.7 [Com- puter Graphics]: Three-Dimensional Graphics 
and Realism. Additional Key Words and Phrases: radiosity, interreflection, two-pass method, extended 
form factors, z-buffer, progressive re- finement, global illumination, ray tracing.  Introduction The 
problem of light interreflection has been one of the main issues for realistic image synthesis during 
the last few years. It is now widely known that local lighting models are not sufficient to corn- LIENS 
: 45, rue d'Ulm. 75230 Paris Cedex 05. FRANCE. Tel : (33) (1) 43 29 12 25 ext. 32-16. Fax : (33) (1) 
46 34 05 31. e-mail : sillion~fl'uhn63.bitnet, puech@fruhr163.bitnet. Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1989 ACM-0-89791-312-4/89/007/0335 
$00.75 pute an accurate distribution of light within an environment [13] [1] [5]. The multiple reflections 
of light on the objects in the scene ac- count for a large part of the total distribution of light, and 
a global solution must therefore be computed, for the intensity of light at some point may depend on 
the intensity at any other point. The first global models, ray tracing and radiosity, made strong assump- 
tions about the reflection process, namely that it is either purely specular or purely diffuse. During 
the last three years, some advanced models have been introduced that allow arbitrary reflection modes 
to be used. We review these models briefly in section 2, and show how to describe them using a common 
formulation, similar to the one introduced by Kajiya with the renderin 9 equation [111. This leads to 
a new com- putational system (section 3) extending the work of Wallace el el. [16]. It is a general two-pass 
system that permits the inclusion of refraction among the effects modeled, and removes the previous restriction 
that all specular surfaces must be planar mirrors. We then present a sampling method using adaptive subdivision 
(sec- tion 4) particularly suited to our two-pass method, and show that it is an interesting alternative 
to the classical hemi-cube technique [3] in the diffuse radiosity case as well. Finally, we show in section 
5 how to produce pictures integrating a complete specular behavior at interactive rates, using multiple 
hardware z-buffers. 2 A reformulation of previous models us-ing the rendering equation At the $iggraph 
'86 conference, Kajiya introduced an equation de- scribing the transfer of light between surfaces in 
an environment [11]. We shall here reformulate some recent models within this framework, and introduce 
different kinds of reflection operators, corresponding to the assumptions made by these models. 2.1 The 
equation Kajiya's rendering equation is the following : l(x, x') = g(x, ~')[c(x, x') + f p(~, ~', x")J(x', 
x")dx"]. JS (We use here the exact formulation of Kajiya's paper, and we shall not discuss this formulation. 
The reader is invited to refer to [11] for further details and a discussion of its validity). Let us 
just recall what the different terms of this equation mean : The domain S, over which the integral is 
calculated, is the union of the surfaces of all objects composing the scene. [(x,x r) is the transport 
intensity from point x t to point x, g(x, x ~) is a visibility function between x and x r, which value 
is 0 if x and x%annot see    ~~~SIGG RAPH '89, Boston, 31 July-4 August, 1989 each other, and 7rzJzT-r~ 
otherwise, ee(z,a .I) is the transport ernit- ~(z,~') tance from x' in the direction of z. p(x, z', z") 
is a bi-directional reflectance function at point z'~, with respect to the directions of z and x'. 2.2 
The global reflection operator As Kajiya states it in his paper, one can define a reflection operator 
7g as an integral operator which describes the effects of the reflec- tion on all surfaces on a given 
light distribution, and express the rendering equation as : l=ge+7~I (please note that the visibility 
term is integrated in the reflection operator. This means that the reflected light appears only at points 
that can see the reflector). The rendering equation can then be formally inverted to give an expression 
which makes apparent the contributions of the successively scattered terms. on 1= ~ 7~9 ~ n=0 2.,3 Direct 
solution using Monte-Carlo integration Stochastic sampling, as introduced in the computer graphics field 
by Cook et al. [4], gives a way to actually evaluate the reflection integral, which was further investigated 
by Kajiya, in the same paper where he coined the rendering equation. This is an elegant solution because 
it solves the entire equation, for all directions converging to the viewpoint, but it involves sampling 
a huge number of directions, if complex reflective behaviors are to be modeled. Furthermore, the solution 
is dependent on the light sources in the scene. The problem is to find a general law for the choice of 
the samples, solving the tradeoff between accurate sampling and computation time. The method introduced 
by Ward el al. [17] at Siggraph '88 can be used to reduce the number of samples at each stage, as it 
concentrates on specular, rapidly-varying effects, calculating the slowly-varying "ambient" effects less 
often. 2.4 Radioslty-based solution At the same '86 conference, Irrnrnel et al. ['10] presented another 
general solution of a similar equation, based on the previous radios- ity method. The basic idea of radiosity 
is to discretize the space of variables in the transfer equations, thus transforming the integral equation 
into a system of linear equations. This involves computing the matrix elements of the reflection operator. 
The solution of the linear system is inherently a global solution, and the good points of radiosity are 
that the geometric dependency of the matrix elements needs not to be recomputed if only lighting conditions 
are changed, and that the solution is independent from the viewpoint, as it gives an intensity value 
for each discretized sample. In the classical radiosity method [8],[3], the discretization is performed 
by defining an intensity value (radioslty) for each of a number of surface patches, It is then assumed 
that the directional distribution of the emitted light is larnbertian (diffuse). The method of Immel 
ctal. is more general, because it removes the restriction that surfaces must be larnbertlan reflectors. 
This is done by taking as a discrete unit a couple (patch, direction), with a finite number of patches, 
and a finite number of directions. The matrix coefficients of operator 7~ are calculated during the solution 
process, using the visibility information provided by the usual hemi- cube [3, see also section 4.1 for 
a definition of the herni-cube]. Immel's solution is thus a complete solution, like Kajiya's path tracing, 
but it involves computing and solving a gigantic linear sys- tem of equations, Even if the matrix is 
very sparse, the CPU power needed makes it unpractical for application purposes. Therefore, some hybrid 
solutions have been proposed, which attempt to capi- talize on ray tracing or radiosity strengths. 2.5 
Shao's progressively refined form-factors At Siggraph '88, Shao et al. [15] presented a method allowing 
ren- dering of specular effects, while maintaining a relatively low CPU cost. Their method is a simplification 
of Imrnel's one where, in- stead of keeping track of the energy emitted by each patch for each direction, 
one only considers the energy emitted from a patch to an- other patch (thus grouping together all corresponding 
directions). Recall that for the diffuse radiosity this reduces further to one en- ergy value per patch, 
since the distribution of this energy among the other patches is entirely specified by Lambert's law 
(plus the visibility information from the hemi-cubes). Shao's idea is to use the geometrical information 
provided by the herni-cube as energy transfer information. The percentage of energy leaving a given patch, 
say i, for another patch j is estimated by considering the geometrical relationships between patch i 
and all other patches in the scene, which allows a directional analysis of the impinging light on i. 
In other words, one determines where the incoming light comes from, in order to decide whether it is 
reflected toward patch j or not. Shao's use of the terminology "form factor" is somewhat misleading, 
although the definition matches the one for the usual form factors, since it depends on the current distribution 
of light in the scene, and not only on geometrical aspects. Another way to express this idea is to introduce 
the reflection operator modeled by such form factors. It is easy to see that each step of Shao's iterative 
procedure computes a "current" light distribution lk, such that Ik =gE+~klk * Ik = ~7~gE ~0 by performing 
a radiosity solution with a current reflection operator "K~k. The initial operator 7g0 is a diffuse (Lambertian) 
operator, which corresponds to the usual diffuse form factors. The form fac- tors are re-computed at 
each stage, producing a new reflection op- erator based on the current light distribution, and the whole 
process is started again. The crucial point in the method is the derivation of ?~k (the improved form 
factors at step k), from a given light distribution lk-i. The convergence of the process towards the 
correct distribution of light is established using a subtle argument in Shao's paper, and can be intuitively 
guessed (but not proved) since each step basically adds to the description of the light leaving a given 
patch the light reflected from the directions where "new" light has arrived. Thus specular propagation 
of light is simulated, and the contribution of each step is decreasing as the process runs. One important 
thing to note is that, even if I~ successfully converges towards the correct distribution, this is not 
the case for "/~-k. The final operator "/'~-oo is different from the global reflection operator 7g, as 
it models only light transfers that actually occur under the given lighting conditions. In other words, 
the effets of ~oo and of "/~ on the limit distribution I~o are the same. This implies that the form factors 
must be re-computed when lighting conditions change, in contrast to conventional radiosity. Although 
this method, like Immel's one, produces directional information about the light leaving each patch, the 
authors had to add a finM ray tracing pass in order to accurately render the rapid changes in the specular 
effects across the surfaces, as seen from the eye. However, this method is not inherently a two-pass 
method like the ones studied later in this paper (see discussion in section 3.3). 336  ~ Computer Graphics, 
Volume 23, Number 3, July 1989 2.6 Two-pass naethods First introduced by Wallace et ol. [16] in a specific 
case, the two- pass approach is based on a distinction of reflection modes. The essence of the approach 
is to have a radiosity program calculate the diffuse part of light, and a ray tracing program calculate 
the specular part. Unfortunately, one cannot completely separate the computation of the diffuse and the 
specular components for the light, because the light itself is not diffuse nor specular; these qual- 
ifications apply in fact only to the reflection modes of the light. In other words, some quantity of 
light can be specularly reflected by a surface ,-ql, then diffusely reflected by a surface $2, and so 
on... (figure 1). Figure 1: Light traveling along the path R becomes successively "specular" (from $1 
to $2), "diffuse" (from $2 to $3), and "spec- ular" again (after $3). 3 The extended two-pass method 
We present a two-pass method, referred to as the extended two-pass method in the sequel, which allows 
all types of reflection modes to be simulated, removes the restriction in [16] that specular surfaces 
must be planar mirrors, and includes refraction among the set of lighting effects modeled. 3.1 The basic 
equations In our method, we separate light reflection into two modes : A diffuse reflection : some part 
of the incident light is re- emitted according to Lambert's law.  A specular (directional) reflection 
(and refraction) : some other part is re-emitted around the directions associated with the incident direction 
by Snell's laws.  In other words, we express the reflectance function as a sum : p(z, ~', ~") = pd(x') 
+ p"(x, x', z") pd is the diffuse reflection coefficient at point x I, and p~ is the specular (anisotropic) 
reflection function, which depends on the positions of points x and x" relative to point x I. For fixed 
points x and x t, this specular function, as a function of x II, exhibits a peak around the mirrored 
image of point x by the surface at point x I (and another peak around the refracted direction). The exact 
form of this function needs not to be specified at this point. Furthermore, we shall assume that all 
self-emission of light in the scene is purely diffuse (i.e. c(x, x') _= e(x')). Under these assumptions, 
we can, by replacing p by its full expression, rewrite Kajiya's rendering equation as : I(x, x') = g(x, 
x')Nx') + T]fx, x') where/3 dependsonly on x I : ~(z') = c(-~') + pe(z')[ r(x', x")~." JS and T, the 
specular reflection-refraction operator; is such that : TI(x, a") = g(x, z')fsP'(x, x', z")I(x', x")d:c" 
 '~ iS a linear operator, transforming the light distribution l into the distribution obtained by allowing 
one specular reflection and refraction on all surfaces in the scene (figure 2). The new equation states 
the relationship between the directional (1) and isotropic (~) distributions, and it can be formally 
inverted to yield : up [=[1-T]-tgfl = [~7klff,~ = S.gfl (1) k=O where ,5' = ~=o 7"'~, the global specular" 
operator represents the ~--,~. ~tl[ b NxN ,"' \ \ f t f "y/////~/// (a) Operator "7" (b) Operator S 
(c) Operator 7) Figure 2: Effects of the operators 7-(specular refiec-tion-refraction), S (global specular 
reflection-refraction) and 79 (diffuse reflection) on a single light ray. effect of all possible specular 
reflections on distribution 1. We can be sure that the infinite sum converges, as the eigenvalues of 
T have a module strictly less than one. Indeed, the energy balance within the enclosure states that the 
total reflected intensity is less than the incident intensity, the difference being absorbed by the various 
materials. The distribution ,~ may be expressed in the same manner as : 3=E+7~.I. (2) where D is the 
diffuse reflection operator, defined by : DI(x') = pd(x') fs I(x', x")dr". The operator 'D represents 
the effect of a single diffuse reflection (on all surfaces), on distribution I. It is the operator used 
in the conventional radiosity method. Finally, replacing I by its value given by equation (1) in equa- 
tion (2), we find an equation on the isotropic distribution ft. [,~ = ~ + v.s.~,~.] (3)  3.2 How to 
use these equations We shall now discuss how the above formulation of the rendering equation leads toa 
calculation algorithm. Until now, we only dealt with integral equations. By dividing the environment 
into patches of finite size, we can turn these integrals into summations over the 337 '89, Boston, 31 
July-4 August, 1989 patches. Let us assume for now a purely specular behavior, which means that the function 
pS actually equals zero everywhere but in the exact reflected and refracted directions. This assumption 
is not really necessary here, we merely use it for sake of clarity, as it permits the use of a conventional 
ray-tracing algorithm. The two passes of the algorithm will first estimate the isotropic distribution 
/3, and then derive the complete distribution 1, for the directions reaching the eye. It is important 
to see that none of these two passes can be omitted. The result of first pass is a distribu- tion of 
light where each patch acts as a diffuse illuminator, even if the amount of energy emitted depends on 
the specular interactions within the environment (see figure 13, and comments in section 6). It should 
be stressed here that the discretization of the objects into patches is necessary only for the radiosity-like 
calculation, and not for the ray-tracing calculation. We can thus use a simpler, more compact representation 
of objects, to be used in all the ray-tracing part of the process. First pass : diffuse light. Equation 
3 gives us a way to calculate the "isotropic" distribution of light ~. In fact, this is a radiosity equation, 
like the one introduced by Goral et al., with the diffuse reflection operator being replaced by the product 
~) S. The usual radiosity method solves this equa- tion by computing geometrical form-factors, which 
represent the relationships between all patches in the scene. These form-factors are used to build the 
matrix of the diffuse reflection operator, and this matrix is then numerically inverted. This suggests 
that a ra- diosity method, in which only the form-factor calculation needs to be modified, will give 
us the distribution ft. More precisely, the notion of form-factor will be extended to include specular 
effects. The extended form-factors have a slightly different meaning, compared to the usual ones : Fij 
is the proportion of the energy leaving surface element i and reaching surface element j, after any number 
of specular reflections or refractions. Wallace el al. also use some extended form factors, but they 
only allow one reflection on planar mirrors. Our extended form factors are more general because they 
allow an arbitrary number of specular interactions, with patches of any geometry. The calculation of 
these extended form-factors can be derived just by closer examination of the equation. We want to model 
the action of the operator ~. S, which is equivalent to determining where the light received by some 
point - or surface element - comes from, after having been operated on by this operator. The operator 
~) means that we must consider all the surface elements visible from that point, as in a classical form 
factor computation, and the operator S that, for each of these elements, we have to study a tree of reflected 
and refracted rays. The process is summarized in figure 3. We can use these extended factors in a classical 
radiosity pro- cess : we form the matrix relating the distributions E and fl by multiplying the form-factors 
by the diffuse reflectance values for For each surface element i { For each direction in space d { Trace 
a ray in direction d. Distribute the elementary form-factor of the direction among the objects in the 
ray-tracing tree. } Figure 3: Calculation of the extended form-factors. each wavelength band [8] , and 
we invert the matrix using an it- erative Gauss-Seidel algorithm [9] (the actual matrix to be built and 
inverted is in fact the matrix of the operator [1 -Z)Sg], as ,~ = [] -Z)Sg] -1 ~. It is worth noting 
here that the diffuse reflection coefficients can be changed very easily, as in the classical radiosity 
process, since they have no impact on the extended form-factors. Conversely, the specular coefficients 
are used in the computation of the extended form-factors, and thus can not be changed without re-calculating 
these factors. Second pass : directional distribution The directional distribution of light, 1, must 
be computed for all di- rections of space converging to the observation point. We calculate this distribution 
with equation (I) derived above. The distribution fl has been calculated by the extended radioslty process, 
so that we just have to evaluate the effects of applying operator ,S to it. Let us recall that S represents 
the effect of any number of specu- lar reflections-refractions. In order to compute I for all directions 
reaching the eye, it i~ sufficient to use a classical ray-tracing algo- rithm from the eye position, 
with only the following modifications : No shadow rays are needed, which makes the process faster than 
conventional ray-tracing. Also the computation time is not dependent on the number of light sources. 
 The "shading model" is trivial. It is simply the value of the distribution fl calculated at the given 
point.  The general case for specular reflection We modeled the global specular reflection operator 
as a ray-traci~g operalor because of the pure specular behavior assumption. It is possible to use a more 
complicated reflectance function, as long as there is a way to compute the effect of the operator S. 
A dis- tributed ray-tracing algorithm [4] could be used for this purpose, both in the computation of 
the extended form-factors, and in the second pass. Wallace's method, which uses z-buffer computations 
and simulates distributed ray tracing, could be used as well. It is important to note, however, that 
the same computational method should be used in the extended form factor computation (first pass), and 
in the final rendering (second pass), if true light transfer simula- tion is wanted. Otherwise we can 
obtain images with a very realistic rendering, including non-mirror specular reflectance functions, but 
with an incomplete "diffuse" solution, if pure ray tracing was used in the first pass. 3.3 Discussion 
The two-pass approach is certainJy a good compromise between image fidelity and CPU cost, as it uses 
the respective strength of ray tracing and radiosity to compute the different components of light. Although 
it involves the computation of extended form fac- tors, which requires more CPU than the computation 
of diffuse form factors, this method has a number of advantages against Shao e~ al.'s method : It is 
independent of light distribution. If the extended form factors are stored in a file, a new picture can 
be generated with new lighting conditions, at the only expense of the radiosity solution and the second 
pass (see last section of this paper for a method to display the final images more quickly).  There 
is no need to store the hemi-cubes for the specular patches.  ~ Computer Graphics, Volume 23, Number 
3, July 1989 Specular patches do not have to be finely subdivided. A problem that appears when studying 
the reflection of light on a specular surface is that directions of interest vary rapidly on the surface 
(fig. 4). Therefore, all specular patches should be finely subdivided in order for Shao et al.'s method 
to produce accurate results. Figure 4: Precision in specular reflection. On, the other hand, Wallace's 
"image method" (though re-stricted to plane mirrors) and our ray tracing technique, allow specular patches 
to be treated as a whole, without further substruct uring. This lack of precision for specular reflection 
is precisely the reason that makes Shao et al. use a ray-traced second pass, and one can wonder if the 
precision of specular transfers is not as important during the first pass than during the sec-ond. Actually, 
it would make more sense to either use Shao's method as one pass, with finely subdivided specular patches 
(but then there will be a huge number of hemi-cubes to store), or a complete two-pass method like the 
one presented here. However, Shao's method could prove very useful for simple en- vironments, if a complex 
reflectance function is to be used. 4 An alternative to the hemi-cube sampling technique. A new sampling 
method using adaptive subdivision is introduced for the calculation of form-factors, which is an alternative 
to the hemi- cube technique [3]. The use of an adaptive subdivision scheme proves especially useful when 
extended form-factors are to be com- puted, as it reduces the number of rays to be shot, but our statis- 
tics show that the approach is efficient even for the diffuse case, especially for high sampling resolutions. 
We shall first explain the method in the diffuse case, and then show hew it can be used for extended 
form factors. 4.1 Adaptive sampling of the half-space In a radiosity program, the form-factor calculation 
requires a sam- pling of the solid angle visible from a given surface element. We should therefore analyse 
a whole half-space above the tangent plane at this point, in order to account for all possible transfers 
of light. Cohen and Greenberg suggested to replace the sampling hemisphere by a hemi-cube of unit size, 
and to project the environment on its faces [3]. The faces are subdivided in "pixels" and a fast classical 
algorithm (z-buffer) is used to solve the visibility problems (fig- ure 5). A surface element is thereby 
associated with each pixel, and the corresponding component of the form-factor (which has been pre-calculated) 
is added to the form-factor between the two elements. We present here a different method, where we project 
the environment only once, on a plane parallel to the tangent plane at the given point. We then choose 
to consider only a restricted area on this plane, thus neglecting all the portion of the half-space that 
projects itself out of the selected area. This approximation is ~Z3 1 (a) (b) Figure 5: By using a 
single projection, the five images of the hemi-cube become a unique, very.deformed image. made possible 
by the angular dependency of the form-factor : in the calculation of the form-factor, one must integrate 
a numerical function depending on the cosine of the angle between the direction of sight and the surface 
normal. The contribution of directions that are nearly tangential to the surface considered is thus much 
smaller than the one of almost perpendicular directions. More precisely, the energy diffused through 
the differential cone shown on figure 6 is given by : AP = /90 sin 20d8 [8] (./90 is the total radiated 
power). We can estimate an upper bound for the energy fraction that is neglected when we analyse the 
energy being diffusely emitted through a square area of size 2D, centered in a projection plane at a 
distance H from the emitting surface (with H << D, see figure 6). Actually, the "lost" energy is less 
than the energy radiated in the directions with 0 C [-~ - ~, -~]2, if tan c = ~. The neglected energy 
fraction is such that : AP -- < sin 2~ P0 E is small compared to one, so that we can write tall~ ~ ~ 
and sin 2~ ~ 2~. Finally we get --~ 262 ~ 2( )2P0 If, for example, we decide that an error of 1% is 
acceptable, we calculate the value of tile ratio @: -~ ~ ~-l ~ V/~ ,~ 1,1. (We used this value in our 
implementation of the radiosity method). The above estimation relies on a lambertian distribution for 
the emitted light, but this condition is met even for the extended form factors, since light distribution 
fl is lambertian. : dO Figure 6: The differential solid angle is dw = 27r sin OdO. SIGGRAPH '89, Boston, 
31 July-4 August, 1989 We now have to analyse the projection of the scene on our "screen". Due to the 
perspective distortion induced by the projec- tion, it seems unreasonable to sample uniformly the inside 
of the square. This would lead to oversampling the external regions, in order to obtain a sufficient 
resolution at the center. We divide the screen in variable-size "proxels" (projection elements), each 
proxel contributing for about the same amount to the form-factor. The elementary form-factor associated 
from the origin with a rectangular area, bounded by xl, x:2, Yl, Y2 (see figure 7) is given by [8113] 
: ~2 y2 H 2 ~Fx ..... yl,~ = Li ~, (x2 + y2 q_ l/~)2 dxdy. H Figure 7: Geometry for the calculation 
of the elementary form-factors. We want to find a sequence of integers (xl)i=o...g, N being a fixed resolution, 
such that x0 = 0, XN = D, and 1 Vi,j ~F~,~.~+~,~,=j+ I ~ N---~. Practlca[ly, due to the radial symmetry 
of the integrand, the above requirement is impossible to meet. We chose the values so that all AF along 
the axes have approximately the same value, by numer- ically estimating the integral (see figure 8). 
We obtain a partition of the plane in rectangular regions, by a number of axis-parallel lines. The location 
of these lines (the (x~)i=0...N) needs only to be calculated once, for a given resolution. They are stored 
in a file, and will be used as proxel coordinates. For each patch in the scene, we want to analyse the 
projection of the environment on this rectangular grid, and associate another patch to each proxel. Figure 
8: Subdivision of the screen in "proxels". We want to obtain regions with equal contributions to the 
form-factor. In order to capitalize on the spatial coherence of the projection, we use an adaptive subdivision 
scheme to analyse the image on the screen, as introduced by Warnock [18]. The principle of this algorithm 
is to analyse the projected image in a rectangular region of the plane, or window. If the content of 
the window is "simple enough", or in other words, if the visibil- ity problem is solved, the algorithm 
stops. In all other cases, the window is subdivided, and the process applied to the sub-windows. Once 
the contents of a window have been identified as corre- sponding to a given surface element, we should 
add to the form- factor of this element the contribution of the window. The con-tribution of the different 
proxels, which are not all equal, are pre- calculated and stored in a table, but still, as a window could 
(and should) contain many proxels, we do not want to sum all the proxel contributions within the window. 
We therefore store in the table, in place of the (i,j) proxel contribution, the sum of the contribu- 
tions of all proxels (p, q)p_<i,q_<j, following an idea used for example by Crow [6] to store textures. 
In this way, the contribution of any window can be estimated in constant time, with only one addition 
and two subtractions : if the integrals are stored in a bi-dimensional array T, we have : LxFx, ,~j,yk 
,u, = T[j, l] - T[j, k] - T[i, l] + T[i, j]. 4.2 Generation of the extended form factors The above algorithm 
is able to associate an elementary form factor to any rectangular region of the projection plane, corresponding 
to diffuse emission towards this window. While for traditional radiosity the regions are simply patch 
visibility regions, this is no longer true for the extended form factors, since we want to follow the 
light along specular reflections. Actually, when Warnock's algorithm detects a window, and an associated 
patch, rays are shot at the corners of the window, and the ray trees are compared. A subdivision criterion 
is tested, which basically states that the first few levels of the tree should be the same. If this is 
not the case, the window is subdivided and new rays are shot. We see that the algorithm is only modified 
by a post-process to be executed for each Warnock window. Once a window is subdivided enough so that 
the ray-tracing trees at the corners match, the elementary form factor associated with the window is 
distributed among the objects in the tree. In order to avoid shooting the same rays several times during 
the subdivision, a storage algorithm has been developed, that only requires 2N storage locations, where 
N 2 is the number of proxels [7]. 4.3 Comparison to the henri-cube method An analysis of running times 
has been performed with the two algo- rithms, for different sampling resolutions (figure 9). Times were 
obtained on a Bull DPX-5000 minicomputer, and represent the time needed to compute a whole set of diffuse 
form factors, for the scene shown on figure 15. The resolutions of the hemi-cube and the proxel plane 
can be compared because they correspond to the same sampling cell size at the center of the plane. However, 
both programs were software implementations. There is little doubt that a hardware-assisted hemi-cube, 
as suggested in [16], would be much faster. We see that the two methods are comparable in time consump- 
tion, but that the hemi-cube times seem to increase more rapidly with the resolution. This is predictable, 
since a depth test must be performed at each pixel, while the subdivision in Warnock's al- gorithm depends 
mainly on the projected image. Asymptotically, for a given scene, the time needed by our algorithm is 
bounded by a linear growth, as the subdivision occurs only on "edges" in the 340 ~ Computer Graphics, 
Volume 23, Number 3, July 1989 200C CPU tirae (mn) 180C x 160C x 140C x o 120C o x o 100C o x o 800 
 600 9 400 o x o ~2 200 o  x 5 o 0 Resolution ~- 64 96 :?@ !(~ 97 22,~ 256 28P 320 352 384 416 448 480 
5]2 Figure 9: Colnparison of running times (11..52 patches). A resolution of N means a. N x N grid. 
(o) stand for our unique projection method, and (x) for the hemi-cube program. image plane. Therefore, 
in the diffuse case, it can be interesting to use our method for large resolutions (which provide more 
accurate form factors). When extended form factors are to be computed, for the ex-tended two-pass method, 
our algorithm allows a strong decrease in the number of rays to be shot, and should therefore be preferred 
to the hemi-cube. 5 One step further towards interactivity Cohen et al. [2] presented at Siggraph '88 
a reformulation of the radiosity solution which allows the display of intermediate images, that gracefully 
converge towards the correct solution. This is a sig- nificant advance in the process of making realistic 
rendering prac- tical for designers, because it makes the interaction loop shorter between the human 
and the machine. It is important to notice that the first pass of our extended two-pass method can be 
adapted in the same way. Our experiments show that for a "typical" scene such as the room shown on figure 
15, progressively refined images integrating specular reflections and refractions of "diffuse" light 
are generated at a speed which is only 20 % less than that of Cohen ct al.'s method (see table 1 and 
comments). The problem remains, however,to interactively display a com- plete solution, including the 
eye-related specular effects (action of the operator $). We present a method, based on hardware-assisted 
z-buffer and image composition, which solves this problem for pla- nar mirrors. This method is not meant 
to replace the second pass completely, as it is limited to such mirrors, but instead the goal is to quickly 
display a picture incorporating some important specular effects. It should be stressed that the solution 
process as expressed by Cohen el al, is still independent of the viewpoint, so that a per- son sitting 
in front of a workstation is able to move through the scene while the solution progresses. We show how 
to accelerate the rendering of mirror effects when viewing conditions are allowed to change. 5.1 Quick 
generation of a picture with mirrors If a particular patch is a planar mirror, one can view the intensity 
coming from a point on the patch towards the eye as a composition of the (diffuse) radiosity of the patch, 
and of the intensity arriving from the reflected direction. If a picture has been computed, with the 
viewpoint transferred to its reflected position relative to the mirror, one can easily retrieve this 
reflected intensity (figure .10). ~ff(Of Vidual //*~ viewpoi~././ -- Figure 10: Calculation of a reflected 
image. Care must be taken of a few points while computing the re-flected image : Reflection on the mirror 
changes the orientation of the coor- dinate system.  An additional clipping plane (the mirror itself) 
should be con- sidered.  On most modern graphics workstation such as the Hewlett-Packard 835-SRX used 
in our implementation, an off-screen portion of the frame buffer can be used to compute the reflected 
image. Displaying the complete picture then only involves masking (to ex- tract the portion of the picture 
where the mirror is seen) and a frame buffer to frame buffer copy of a block of pixels. Thus the extra 
time required to display the final picture, including first re-flection on planar mirrors, is about the 
number of mirrors times the time needed for a z-buffered projection, For a simple scene like the one 
shown in figure 14, the display time is roughly doubled, which allows interaction with the picture (the 
complete display must be done each time the radiosity values are updated by the solution process). 5.2 
Moving tile viewpoint When the viewpoint is to be moved "continuously", and for complex scenes, even 
a factor two in the display time is too much. On the other hand the precision required for displayed 
images is less, because each frame is displayed only for a very short time. To reduce the time spent 
for each picture, we actually store a reflected 341    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74369</article_id>
		<sort_key>345</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Incremental computation of planar maps]]></title>
		<page_from>345</page_from>
		<page_to>354</page_to>
		<doi_number>10.1145/74333.74369</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74369</url>
		<abstract>
			<par><![CDATA[A <i>planar map</i> is a figure formed by a set of intersecting lines and curves. Such an object captures both the geometrical and the topological information implicitly defined by the data. In the context of 2D drawing it provides a new interaction paradigm, <i>map sketching</i>, for editing graphic shapes.To build a planar map, one must compute curve intersections and deduce from them the map they define. The computed topology must be consistent with the underlying geometry. Robustness of geometric computations is a key issue in this process. We present a robust solution to B&amp;eacute;zier curve intersection that uses exact forward differencing and bounded rational arithmetic. Then, we describe data structure and algorithms to support incremental insertion of B&amp;eacute;zier curves in a planar map. A prototype illustration tool using this method is also discussed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.1</cat_node>
				<descriptor>Spline and piecewise polynomial interpolation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14139180</person_id>
				<author_profile_id><![CDATA[81100393077]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gangnet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation, Paris Research Laboratory, Rueil-Malmaison, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P129861</person_id>
				<author_profile_id><![CDATA[81332504028]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.-C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Herv&#233;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation, Paris Research Laboratory, Rueil-Malmaison, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P276026</person_id>
				<author_profile_id><![CDATA[81100483853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pudet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation, Paris Research Laboratory, Rueil-Malmaison, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P130078</person_id>
				<author_profile_id><![CDATA[81361591651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[J.-M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Thong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation, Paris Research Laboratory, Rueil-Malmaison, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Baroni. Art Graphique Design. Editions du Chine, Paris, 1987.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>67511</ref_obj_id>
				<ref_obj_pid>67449</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Baudelaire and M. Gangnet. Planar Maps: an Interaction Paradigm for Graphic Design. In CHI'89 Proceedings, Addison-Wesley, 1989.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J.L. Bentley and T.A. Ottmann. Algorithms for Reporting and Counting Geometric Intersections. IEEE Trans. on Comput., 28(9), 1979.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42265</ref_obj_id>
				<ref_obj_pid>42188</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T.D. DeRose and B.A. Barsky. Geometric Continuity for Catmull-Rom Splines. ACM Transactions on Graphics, 7(1), 1988.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D.H. Greene and F.F. Yao. Finite-Resolution Computational Geometry. In Proc. 27th IEEE Syrup. on Found. Comp. Sci., Toronto, 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73404</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Dobkin and D. Silver. Recipes for Geometry and Numerical Analysis. In Proceedings of the Fourth Annual ACM Symposium on Computational Geometry, ACM Press, New York, 1988.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>28905</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Edelsbrunner. Algorithms in Combinatorial Geometry. Springer-Verlag, New York, 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Edelsbrunner, L. Guibas, J. Pach, R. Pollack, R. Seidel, and M. Sharir. Calculating Arrangements of Segments, Circles, or Other Curves in the Plane. 1988. Submitted for publication.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H. Edelsbrunner and L.J. Guibas. Topologically Sweeping an Arrangement. Research Report #9, Digital Equipment Systems Research Center, Palo Alto, 1986.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. R. Forrest. Geometric Computing Environments: Some Tentative Thoughts. In Theoretical Foundations of Computer Graphics and CAD, Springer-Verlag, 1988.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Gangnet and J.C. Herv6. D2: un 6diteur graphique interactif. In Acres des Journdes SM90, Eyrolles, Paris, 1985.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282923</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Guibas and J. Stolfi. Primitives for the Manipulation of General Subdivisions and the Computation of Voronoi Diagrams. ACM Transactions on Graphics, 4(2), 1985.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73405</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C.M. Hoffmann, J.E. Hopcroft, and M.S. Karasick. Towards Implementing Robust Geometric Computations. In Proceedings of the Fourth Annual ACM Symposium on Computational Geometry, ACM Press, New York, 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[P.A. Koparkar and S.P. Mudur. A new class of algorithms for the processing of parametric curves. Computer-Aided Design, Vot. 15, 1983.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J.F. Lane. Curve and Surface Display Techniques. Tutorial, ACM SIGGRAPH'81,1981.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37416</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S.L. Lien, M. Shantz, and V. Pratt. Adaptive Forward Differencing for Rendering Curves and Surfaces. ACM Computer Graphics, Vol. 21(4):111-118, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>696466</ref_obj_id>
				<ref_obj_pid>646504</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P. Lienhardt. Extensions of the Notion of Map and Subdivision of a Three-Dimensional Space. In STACS'88, Lecture Notes in Computer Science 294, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. Michelucci. Th~se. Ecole Nationale Suprrieure des Mines de Saint-Etienne, Saint-Etienne, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Michelucci and M. Gangnet. Saisie de p~ans ~t partir de tracrs ~ main-levre. In Actes de MICAD 84, Hennas, Paris, 1984.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[F.P. Preparata and M.I. Shamos. Computational Geometry: an Introduction. Springer-Verlag, New York, 1985.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[L. Ramshaw. Blossoming: A Connect-the-Dots Approach to Sptines. Research Report # 19, Digital Equipment Systems Research Center, Palo Alto, 1987.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M.H. Schultz. Sptine Analys&amp;. Prentice Hall, 1973.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>18559</ref_obj_id>
				<ref_obj_pid>18548</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[T.W. Sederberg and S.R. Parry. Comparison of three curve intersection algorithms. Computer-Aided Design, Vol. 18, 1986.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[W.T. Tutte. Graph Theory. Addison-Wesley, 1984.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[G. Wang. The Subdivision Method for Finding the Intersection between two B6zier Curves or Surfaces. Zhejiang UniversiO, Journal, 1984. Cited in reference {23}.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Incremental Computation of Planar Maps Michel Gangnet Jean-Claude Hervd Thierry Pudet Jean-Manuel Van 
Thong Digital Equipment Corporation Paris Research Laboratory Rueil-Malmaison, France Abstract Aplanar 
map is a figure formed by a set of intersecting lines and curves. Such an object captures both the geometrical 
and the topological information implicitly defined by the data. In the context of 2D drawing, it provides 
a new interaction paradigm, map sketching, for editing graphic shapes. To build a planar map, one must 
compute curve intersec- tions and deduce from them the map they define. The com- puted topology must 
be consistent with the underlying geom- etry. Robustness of geometric computations is a key issue in 
this process. We present a robust solution to Brzier curve in- tersection that uses exact forward differencing 
and bounded rational arithmetic. Then, we describe data structure and al- gorithms to support incremental 
insertion of Brzier curves in a planar map. A prototype illustration tool using this method is also discussed. 
CR Categories and Subject Descriptors: 1.3.5 [Com- puter Graphics]: Computational Geometry and Object 
Mod- eling - Curve, surface, solid, and object representations; Ge- ometric algorithms, languages, and 
systems; 1.3.6 [Computer Graphics]: Methodology and Techniques -Interaction tech- niques; G. 1.1 [Numerical 
Analysis/: Interpolation -Spline and piecewise polynomial interpolation; J.5 [Arts and Hu- manities]: 
Arts, fine and performing. Additional Keywords and Phrases: Brzier curves, forward differences, curve 
intersection, planar maps, map sketching. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. 01989 ACM-O-89791-312-4]891007/0345 $o0.~ 1 Introduction There is growing 
interest in the robustness of geometric com- putations [10,6,13]. Different graphics algorithms have 
dif- ferent sensitivity to numerical errors. In some cases numeri- cal errors are acceptable. In others, 
one can find ways around them. However, exact computation is sometimes mandatory. The following examples 
demonstrate the range of effects. When scan-converting 3D polygons, rounding errors on face equations 
will not prevent the z-buffer method from ren- dering a scene. The few erroneous pixels may not even 
be visible. This is a case where numerical errors are innocuous. A second example is a function performing 
point location in a polygon with a parity test, using floating point arithmetic. If the result returned 
by this function is used for identifica- tion of the polygon and, say, modification of its color, then 
it is acceptable for the function to return an empty result when a reliable answer cannot be computed. 
Hence, in some 2D drawing programs, the user must click well inside a polygon to select it (which is 
better than selecting the wrong polygon). As a third example consider a program implementing an al- gorithm 
which presumes infinite precision. The Bentley- Ottmann algorithm [3,20] for reporting intersections 
of a set of non vertical line segments relies on the fact that two seg- ments may intersect iff there 
exists a position of the vertical sweep-line where they are consecutive. If the implementa- tion produces 
an error when inserting a new segment in the sweep-line then some intersections may be missed. In this 
case, it is imperative to provide an exact answer. Methods involving topological decisions based on geo-metric 
computations are generally difficult to implement. We describe a robust solution to an intersection problem 
which arises in the context of a 2D drawing application. A set of lines and curves like in Fig. 1 dissects 
the plane into vertices, edges and faces. This type of geometric object is known in graph theory as a 
map of a planar multigraph [24], hence the name planar map we use below, and in computational ge- ometry 
as an arrangement in the plane [7]. Data structures describing embeddings of planar graphs in the plane 
can be traced back to Baumgart's winged-edge data structure and have been studied by numerous researchers 
[20,12,9]. It is standard practice to distinguish between the geometry, the position of the vertices, 
geometric definition of the edges and the topology, the incidence and adjacency of the vertices, RAPH 
'89, Boston, 31 July-4 August, 1989 SIGG edges, and faces. The problem addressed here is building a data 
structure to support incremental insertion of new curves in a planar map, dynamically computing new intersections 
and updat- ing the data structure. In this case, topological information has to be deduced from geometrical 
information. When two curves intersect at a new vertex, the ordering of the four edges around the vertex 
provides topological information used to follow the contour of a face incident to the vertex. If floating 
point arithmetic is used, it has been shown that the computed slopes can give the wrong order [10,18]. 
This is similar to the Bentley-Ottmann algorithm example above. Our first implementation [19] used the 
Bentley-Ottmann algorithm and rational arithmetic to compute the planar map formed by a set of line segments, 
[11] is the description of a 2D illustration tool based on this first software. The method was not incremental 
and the map had to be recomputed each time a new segment was added. In [5], Greene and Yao solve the 
intersection problem for line segments by working di- rectly in the discrete plane. In [8], Edelsbrunner 
et al. study arrangements of Jordan curves in the plane from a theoretical point of view. Figure 1: A 
planarmap. In the next section, the utility of planar maps for 2D draw- ing is briefly discussed. Section 
3 details curve intersection. First, Brzier curves are interpolated by polylines using for- ward differencing. 
Then, the intersection between two inter- polating polylines is computed with rational arithmetic, we 
show how it is possible to limit the number of bits in this process and how to control the quality of 
the interpolation. Section 4 describes the map data structure and the two main algorithms used in the 
planar map construction process: in- cremental insertion of a curve and point location in a map. The 
map topology is computed from the geometry of the polylines. Since exact arithmetic is used in this process, 
the map topology, although it may be different from the topol- ogy defined by the true curves, is always 
consistent with the geometry of the interpolating polylines.   Map Sketching Our interest in planar 
maps is motivated by practical con-cerns: with traditional graphic arts media (pencil, eraser, ink, etc.), 
it is common practice to build shapes by drawing lines and curves, erase some pieces thereof, and color 
or ink the areas they delimit (see [1] and Fig. 2). Figure 2: Graphic design by space division (B. Munari 
in [1]). The design of logos and monograms, floor plan sketching by architects, cartoon ceils drawing 
and inking are examples where this technique is used. In typical drawing software there is no way to 
mimic this method. If Fig. 3a is drawn by the user of a drawing application as four lines, it is impossible 
for him to color the rectangle (as in Fig. 3b) since no such rectangle exists. If the drawing were computed 
as a planar map, this dual interpretation would be possible. b Figure 3: Four lines and a rectangle. 
In [2], we have proposed two extensions to the 2D graphics drawing paradigm: a) objects are multicolor, 
multicontour shapes (i.e., planar maps), b) they are constructed by itera- tion of three basic steps: 
drawing, erasing, and coloring. We call this technique map sketching and have implemented it in prototype 
illustration software used to draw the figures in this paper. Fig. 4 illustrates map sketching. Strokes 
drawn by the user are incrementally added to the map describing the draw- ing. Two additional operations 
are allowed on a map: edge erasing and face coloring. These steps can be iterated in any order. Map sketching 
closely parallels the traditional pencil and eraser method and is more natural and more efficient for 
constructing certain classes of drawings. User interface de- sign issues in map based illustration software 
are discussed in [2]. l  Figure 4: Map sketching. 3 B~zier Curve Interpolation and Intersection 3.1 
Overview Curves to be inserted in a map are first converted to Brzier form [21,4]. The incremental insertion 
algorithm (Sec. 4) has two requirements. First, intersection points must be ordered without error along 
a curve by their parameter values, in- cluding the case of self-intersection. Second, if two or more 
curves intersect at one point, they must be ordered without error around the point. To meet these requirements, 
we use the following strategy: i. The control points of the Brzier curves have integer co- ordinates 
on a grid large enough for 2D graphics appli- cations. Grid size is discussed in Sec. 3.4. 2. The curve 
is replaced with an interpolatingpolyline. We compute an exact interpolation of the curve by exact forward 
differencing (FD). It is necessary that enough bits are available to perform FD without a loss of preci- 
sion (Sec. 3.2). Rather than storing polylines in the data structure, they are computed as needed. 3. 
Computing the intersection of two exact polylines causes an explosion in the number of bits. Thus, we 
round the points of an exact polyline to the grid. This reduces the intersection of two rounded polylines 
to the intersection of line segments whose endpoints have inte- ger coordinates. Ordering two intersection 
points along the same line segment and ordering two intersecting line segments around their intersection 
point is done with ra- tional arithmetic. Note that the intersection points are  not rounded since this 
could modify the map topology. 4. Finally, it is natural with the map sketching technique to use an existing 
intersection point as a new curve end- point. We will show how to achieve this without in- creasing the 
bit length of the arithmetic (Sec. 3.4).  The map deduced from the intersection process is the one defined 
by the rounded polylines. No other rounding oc-curs. The map topology, although it may be different from 
the topology defined by the true curves, is always consistent with the geometry of the rounded polylines. 
 ,3.2 Interpolation Method Wang [25,23] gives the following result. If the de Castel- jau subdivision 
algorithm (midpoint case) is applied down to depth k to a polynomial Brzier curve of degree d > 2 with 
control points Vr, where: then, all the chords (straight line segments) joining the end- points of the 
2 k control polygons which are the leaves of the subdivision tree are closer to the curve than the thresh- 
old e. In (I), D = ma.xo<,<d-2 IIV~+2 -2V~+l + Vrll and Ilvll = max (Iz, I, IVy I) for a vector v. D 
can be called the diagonal of the curve. Since reference [25] is not available to us, an independent 
proof of this result is given in appendix A, together with a bound on the chord length. Consider the 
chord endpoints E~, 0 < i < 2 k . They form a polyline E. It is faster to use ordinary FD [16] than sub- 
division to compute E. Since a priori subdivision computes  ~t~~SIGGRAPH '89, Boston, 31 July-4 August, 
1989 the complete tree to depth k, FD with fixed step size 2 -k will generate the same polyline, provided 
that exact compu- tations are done in both cases. We now show that the num- ber of bits needed to perform 
exact FD is bounded. Suppose that the control points of the curve have coordinates coded into b bits. 
Then, computing the subdivision tree down to depth k requires at most b + kd bits for the coordinates 
of the Ei. In the FD loop, the only values involved in the ith iter- ation are the forward differences 
&#38;JEi, 0 ~ 3" <_ d. Since we know from subdivision that, for all i, the computation of Ei = xEi 
requires at most b + kd bits, ~x3Ei requires at most b + kd + j bits. Thus, exact FD with step size 2 
-k can be performed on the curve if b + {k + 1)d bits are available. To limit the total number of bits 
needed when updating a planar map, the intersection algorithm uses rounded poly-lines. FD computes the 
exact coordinates of the Ei which are then rounded to b bits. 3.3 Intersection Algorithm B6zier curve 
intersection is studied by Sederberg and Parry [23]. In two of the algorithms they consider, rejection 
of non-intersecting pieces of two curves is done by bounding box comparison. FD is not convenient for 
successive mid- point evaluations of a curve. To take advantage of bounding boxes, a preprocessing step 
breaks the rounded polylines into monotonic pieces. For such a piece, the box of any subpiece is given 
by its endpoints coordinates. This method is also used by Koparkar and Mudur [14] with another curve 
evalu- ation method. During the planar map construction process, a new curve is intersected with a subset 
of the curves already inserted in the map. The preprocessing of the new curve finds the monotonic pieces, 
saving data to be used in later compu- tations. The new curve is then immediately inserted in the map. 
Preprocessing. Let C be the new curve, a) use FD to com- pute the exact polyline E and the rounded polyline 
P of C, b) store P in an array, to be discarded after the insertion of C, c) find the monotonic pieces 
of P, d) at the end of a monotonic piece, save the permanent data associated with it, that is, its first 
and last indices (i I , Q), its bounding box, its quadrant, and the FD context at i I (i.e., ~JEil , 
for all .7"). All these steps can be performed in one single FD loop. Intersection. It is enough to consider 
the intersection of a monotonic piece of P, with indices (if,it), with a monotonic piece of an existing 
curve G, with indices (].t, 3i), whose bounding boxes overlap. First, compute Q, the rounded polyline 
of G, between 3) and 3} using the FD context at 9"// which has been saved when pre- processing G, and 
store the result into an array. Then, search the intersecting chords using binary subdivision on the 
respective arrays (the box of any subset of points considered in this subdivision is given by its two 
end- points and the quadrant information). In the map sketch- ing application, the existing curve G may 
be partially erased. In this case only the monotonic pieces contain- ing a non-erased part of G are intersected 
with C. Two special cases must be handled: rounded chords with a null length, and partially overlapping 
polylines (i.e., non transverse intersections). After preprocessing, a new curve is intersected with 
itself to detect multiple points and self- overlapping. Naturally, line segments are not subdivided since 
they are ready for intersection. It is worthwhile to cache partially or totally generated curves. Two 
cases are frequent: a) the same monotonic piece of G intersects different pieces of C, b) successive 
new curves intersect the same existing curve.  3.4 Topology Consistency This section describes how a 
consistent topology is obtained from the geometrical data given by the intersection process. For illustration 
software, the input can be rounded to an in- teger grid if the grid size is large enough and if the scaling 
factors are limited accordingly. A typical case is to output the results on a 24"  24" page at 300 dpi. 
Then, input con- trol points may be defined on twice as large an area, to permit clipped curves. We must 
also choose a maximum zoom fac- tor: a reasonable value is 8. Since the rounded chords must have even 
coordinates (see below), the input is scaled up by a factor of two. 'The control points coordinates are 
thus coded on b = 18 bits. Setting e = 1 in equation (1) gives k = 10 for a degree 4 curve with the maximum 
diagonal, which is twice the grid size. Thus, 62 bits are needed for the exact FD of this curve, this 
goes up to 102 bits for a degree 7 curve with the same diagonal. The much more usual case of a cubic 
with a 4" diagonal is 45 bits. If chord intersection is performed on the exact polylines the number of 
bits grows very rapidly. When two chords AB and CD intersect at I, the coordinates of I and the values 
of the two parameters u and v such that A1 = uAB and CI = vCD must be computed exactly. All of these 
can be expressed as rational numbers; for example, u = (AC  CD) + (AB  CD) where  is the cross product. 
With endpoints coded on b + kd bits, this is 2(b + kd) + 3 bits for the numerator and the denominator 
of the rationals. Since different intersections along the same chord are ordered by comparing their rational 
parameter values, the final number of bits is 4(b + kd} + 6. For the first curve in the example above, 
this is 238 bits. The situation is worse if we want to use an existing intersection as the endpoint of 
a new curve. Setting b = 238 in the above computations gives 1118 bits. As noted by Forrest and Newell 
[10], the major drawback in the rational arithmetic approach is the blow-up in the number of bits. To 
limit this number, the chord endpoints of the exact polylines are rounded to even integer values. Chord 
intersec- tion is done on the rounded chords and the intersection points are exactly represented as rational 
numbers. To use an exist- 3 ' ' 4 a b c Figure 5: Vertex (rn, n) and chord ordering. ing intersection 
point as the endpoint of a new curve without (e.g., tangencies) where intersections between the true 
curves increasing the bit length, we consider the semi-open rectan- are ignored. Likewise, polylines 
may intersect even if true gles Rm,,~ = [rn - 1, m + 1) x [n - 1, n + 1), where rn and curves do not 
(e.g., two concentric circles with very close n are even. Since the vertical and horizontal lines limiting 
the radii interpolated by regular polygons whose sides intersect rectangles have odd coordinates, there 
are no rounded chords pairwise). Second, the topology of a map computed in this collinear with these 
lines. So, it is always possible, if two or way is not invariant under general affine transforms. Thus, 
more chords intersect inside R~,,~, to order them along the the map has to be recomputed from the original 
data when- boundary of Rrn,n by using either the coordinates of their in- ever it is rotated or scaled. 
The first limitation is inherent in tersections with the lines limiting the rectangle or their slopes 
any linear interpolation process. However, for 2D graphics if they leave Rm,r~ at exactly the same point 
(Fig. 5a). We applications, it is always possible to prevent any visible ef- define the center of t~m, 
n as the vertex of the intersection fects by choosing an appropriate grid size. The second limita- points 
lying inside R~,,~. This associates intersection points tion can only be solved by using exact arithmetic 
on real num- with vertices but does not round their coordinates. To use a bers or symbolic computation 
on algebraic curves, which are chord intersection point as the endpoint of a new curve, we do currently 
too slow for interactive applications. Without re- not use the point itself but the coordinates of the 
associated computing the map, it is possible to perform integer transla- vertex (Fig. 5b). Therefore, 
small faces lying inside a single tion (i.e., dragging) and scaling by a power of 2 (i.e., zoom- rectangle 
will not be represented in the map data structure ing), if we remain inside the grid. (Fig. 5c). In this 
section, we have shown that a robust method for the computation of planar maps with linearly interpolated 
BEzier On a curve, an intersection point is represented as a pa-curves requires at most b + (k + 1)d 
bits for the FD step and rameter value p = (i, u) where i is the chord index on the 4b + 6 bits for the 
intersection and sorting steps. Our imple- polyline and u a rational number giving the exact position 
of mentation uses a variable length integer arithmetic package the point on the chord. Since all chords 
have now rounded coded in assembly language. In practice, the average size of endpoints, ordering two 
intersection points along one curve the numbers involved in the process is much smaller than the requires 
at most 4b + 6 bits. We need also to order the inter- above bounds. The only operation we must perform 
on ratio- sections of the chords with the lines limiting the rectangles nal numbers is comparison, which 
is two integer multiplica- Rra,n. These are Brzier curves of degree 1, thus the stated tions and a test. 
The value of b is a parameter of the program, bound is valid. In the common case where only one intersec- 
allowing the grid size to be adapted to the resolution of the tion point is associated with a vertex, 
the slopes are used to display. order the chords, requiring at most 2b+3 bits. In addition, the method 
must support the erasing of curve pieces limited by intersection points. It is therefore necessary to 
keep the initial 4 Data Structure and Algorithms data defining the curve and to mark as erased or non-erased 
the corresponding pieces. As noted above, the intersection After describing the planar map data structure, 
we detail be- algorithm uses this information to return only actual inter- low the two main algorithms. 
Curve insertion uses point lo- sections. A curve is removed from the map data structure iff cation in 
a map to find the face containing the first endpoint it has been totally erased. of a curve. However, 
since point location is equivalent to the The method has two limitations. First, intersection is per- 
insertion of a dummy line segment, curve insertion will come formed on the rounded polylines. Thus, there 
are situations first. '89, Boston, 31 July-4 August, 1989  , S,GGRAPH aws(s) e 8 Figure 6: Map topology. 
4.1 Planar Map Description A map contains two different sets of data. The first one de- scribes the geometry 
of the curves and their intersections, and the second contains the topological data. In what follows, 
the word curve should be understood as the rounded polyline as- sociated with the curve. Geometry. When 
inserted, a curve is cut into arcs by the other curves. An arc is described by its endpoints on the curve. 
Each point (i.e., an intersection or a curve endpoint) is known by its parameter value p = (i, u) on 
the curve, as in Sec. 3.4. An intersection yields two points, one on each curve. As parameters are totally 
or- dered along a curve, an arc is noted below as a parame- ter interval [101, p2 ]. Arcs are marked 
as either erased or non-erased. Topology. The mapping defined in Sec. 3.4 associates with each point 
a unique vertex. To support arc overlap, we attach to an arc an edge connecting its vertices. Arcs lying 
entirely in one rectangle R,~,~ are not considered. Overlapping arcs share the same edge. The geometry 
of an edge is the geometry of one of the arcs it supports. Different edges can connect the same pair 
of vertices. The ordering of the edges around a vertex is the chord ordering defined by the rectangles 
Rmn. To access the faces of a planar map, it is convenient to consider an edge as two directed edges, 
called sides. If an edge e is a loop incident to the vertex v, then the clockwise (cw) and counterclockwise 
(ccw) orien- tations along e define the two sides associated with e (Fig. 6a). Two mappings are defined 
on the sides of a map: o~(8) is the side next to 8 in the ccw order around the vertex incident to 8, 
and o~ (~) is the other side of the edge [17]. We note the ordering of the sides around a vertex, c~-order. 
To follow the boundary containing a side s, the compound mapping c~o~ is applied repeatedly until back 
in a (Fig. 6b). The result is a face boundary called a contour. Contours with a ccw orientation are outer 
contours, others are inner contours. Adding a vir- tual inner contour located at infinity, there is exactly 
one inner contour for each face of a map. The edges may form several connected components which are partially 
ordered by inclusion in the plane. This partial ordering is described by an inclusion tree whose nodes 
are the contours. The root is the virtual in- ner contour at infinity. The leaves are either inner con- 
tours with no connected component included or outer contours with an empty interior. This tree is stored 
in the data structure and used by the curve insertion and point location algorithms.  4.2 Curve Insertion 
We say that an arc is visible in a face if this arc is supported by an edge of which at least one side 
is in a contour bounding the face. Curve insertion uses the method described in Sec. 3 to compute the 
intersections between a new curve C and all the arcs visible in the faces where C is lying (Fig. 7). 
Along C, p is the current parameter value and ne:et (p) the parameter value of the next intersection 
point, p < next(p}. Figure 7: Curve insertion (first iteration). Step 1. Using point location (Sec. 4.3), 
find the face F con- taining the first point of C. Set parameter p to 0. 350 Step 2. If F has already 
been processed, jump to step 3. Otherwise, compute the intersections between arc [p, 1] and all the arcs 
visible in F. Cut the arc [p, 1] and the intersected arcs of F at each intersection point and cre- ate 
the corresponding vertices and sides. At the end of this step, there are no more intersections between 
p and next{p), and the a-order around the vertices along C has been updated. Step 3. If there is no overlapping, 
create an edge between the vertices associated with p and next(p), link it with the arc [p, next(p)] 
in the data structure, and update the inclusion tree accordingly (see appendix B). Otherwise, the edge 
already exists, link it with the arc [p, next(p)]. Step 4. If next(p) = 1 then stop. Otherwise, let 8 
be the side of arc [next(p), next(next(p))] associated with next(p). Since the a-order around the two 
correspond- ing points is known, 8 is known. Set F to the face inci- dent to a(s), and p to next(p). 
Repeat step 2. An arc is visible in at most two faces but an existing curve G can be visited several 
times. However, the intersection between the arc [p, 1] of (7 and G is done only once: the first time 
an arc of G becomes visible in the current face F. The intersection points located outside F are stored 
for further use. 4.3 Point Location Given a query point with integer coordinates, the point loca- tion 
algorithm returns either a face, an edge, or a vertex. In map sketching, all selections are done through 
this algorithm (e.g., coloring a face or selecting an existing intersection as the endpoint of a new 
curve). A first method is to intersect a line segment S with all curves. S is defined by the query point 
M, with parameter 0, and a point outside the bounding box of the map, with parameter 1. If no intersection 
is found, M is inside the infinite face. Else, retain the curve G whose intersection is closest to M. 
This intersection is known by its parameter values p on S and q on G. The parameter q gives the arc of 
G containing the intersection. Ifp = 0, then M is exactly on the edge supporting this arc. Otherwise, 
M is inside one of the two faces incident to the edge. The side which sees M to its right gives the answer 
(a side defines a unique orientation on a curve). This method does not take advantage of the partition 
of the plane defined by the faces of the map. To reduce the average number of visited curves, the following 
algorithm uses face adjacency (Fig. 8). This algorithm is similar to the curve in- sertion algorithm, 
but it uses curve intersection instead of arc intersection. We say that a curve is visible in a face 
if one of its arcs is visible in the face. Step 1. Set F to the infinite face and S to [02 1]. S is the 
line segment defined above. G FF Figure 8: Point location. Step 2. If F has no outer contours then return 
F. Oth- erwise, intersect S with the curves visible in the outer contours of F (if two or more curves 
are overlapping, it is enough to consider one of them). If there is no in- tersection, return F. Otherwise, 
let e be the edge which gives the smallest parameter p on S, and 8 the side of e which sees M to its 
right. If s is part of an outer con- tour, return F. Otherwise, set ,_q to [0, p] and set F to the face 
incident to s. Step 3. Intersect S with the curves visible in the inner con- tour of F. If there is 
no intersection, call recursively step 2. Otherwise, let e be the edge which gives the smallest parameter 
p on S, and s the side of e which sees M to its right, s is necessarily part of an inner contour. Set 
F to the face incident to this contour and ,9 to [0, Pl. Repeat step 3. As curve insertion does, point 
location may visit a curve several times, but only one intersection with S is performed. The geometric 
tests are performed on rational numbers, they are thus exact. Indications on the complexity of both algo- 
rithms are given by the horizon theorem for Jordan curves included in [8]. However, this last result 
cannot be applied in a straightforward way as the number of intersections be- tween two polylines may 
be greater than the number of in- tersections between the true curves, and the polylines may be partially 
overlapping. 5 Conclusion A method has been presented which allows for incremen- tal construction of 
planar maps. Robustness of the compu- tation and consistency between geometry and topology are achieved 
through linear interpolation of B~zier curves and exact intersection of the rounded resulting polylines. 
Our main goal was to produce fast and reliable code to be used in the context of 2D drawing. Though it 
has some limitations, the method described in this paper gives a powerful tool for constructing illustrations. 
The planar map data structure allows also for automated com- pound operations, such as the ones described 
by Fig. 9 and 10. Fig. 11 and 12 show illustrations produced with the map sketching technique.  :+,~11~ 
SIGGRAPH '89, Boston, 31 July-4 August, 1989 Figure 9: Cleaning a face removes its dangling edges. Figure 
10: Cookie-cutter. Figure 11 : Wickerwork. Figure 12:CHI'88 logo. Acknowledgements We would like to thank 
Dominique Michelucci for his con- tribution to the initial work on planar maps done at Ecole des Mines 
de Saint-Etienne. We thank Leo Guibas and Lyle Ramshaw for helpful discussions. We are grateful to Patrick 
Baudelaire for his encouragement during the project. A A priori Subdivision A polynomial B6zier curve 
of degree d is defined by: d V(t} = EV,.B~a(t}, 0< t < 1, r~O where the Vr are the d+ I control points 
that form the control plygnfV(t}'and B~a(t) = ( d ) tr(1-t)a-r isthe Bemstein polynomial of degree 
d [21,4]. If v is a vector in the Euclidean plane, we note I[vll the quantity max (Ix~ I, lYv I)" For 
d > 2, the diagonal D and the length L of the control polygon of V(t} are defined as: D = max Jrvr+=-2Vr+l 
+ Vr]l, O<r<d--2 L = max II. O<r<d--1 D is considered by Wang [25,23] as a subdivision criterion. Computing 
the first and second derivatives of V (t) and using the properties of the Bemstein polynomials gives, 
for all t in [0, 1]: lIv(~) (t) I[ < d(d-1} D, (2)  IIV")(t)ll _< d L. (3) @ ~ Computer Graphics, Volume 
23, Number 3, July 1989 To find the number of subdivisions, we use a chord in- terpolation theorem [22] 
which states that: if f(t) is a real valued function of class C ~ on [a, b], then, for all t in [a, b] 
: if(t ) _ c(t) I < (b-a) 2 max ff(2)(t) , (4) --8 a<t<b where c(t) is the chord (straight line segment) 
between (a, ](a)) and (b, f(b)). This result is used by Lane [15] in the context of curve rendering. 
Let a, 0 < 0. < 1, be a step size on the interval [0, 1] and n the integer such that na = 1. This defines 
n in-tervals h = [i0., (i + 1)a], and n chords Ci(t) with end- points Ei = V(icr) and E+i = V((i + 1)~r). 
Let e be a given threshold measuring the maximum allowed deviation between the curve and the chords Ci. 
We want to ensure that: IIv(t) -c~(t)ll _<, (5) holds for all i, 0 < i < n, and all t in/h. Applying 
(4) to the coordinates of V (t} on the interval Ii and using the bound (2), it is straightforward to 
see that any a _< 1 such that: 8e o < 0 .2 < (6) -d(d-1)D will satisfy (5). Let k be the smallest integer 
such that ~r = 2 -k satisfies (6), then: Equation (7) is cited in [23] as a result derived by Wang. We 
can now bound the length of the chords given by apri-ori subdivision of depth k. The mean value theorem 
applied to V(t) on interval Ii gives: lIE,+1 -E, II _< 0. max IIV(1)(t)l I. trI~ The maximum of liE(l)(t)ll 
over h is less than or equal to its maximum over [0, 1]. Using (3), one gets: IIE~+i -E~[I _< adL. The 
bound on o" from (6) gives for all i, 0 < i < 2 ~: [iEi+l_ E~ll < ~/ 8d n v/~. - vd-vr5 B Updating the 
Inclusion Tree The degree d of a vertex v is the number of sides incident to v, v is a dangling vertex 
if d(v) = 1. If both sides of an edge are in the same contour, it is a dangling edge, otherwise it is 
a border edge. A dangling edge is connecting if it has no dangling vertex, terminal if it has exactly 
one dangling vertex, and isolated if it has two dangling vertices. A loop incident to a vertex v with 
d(v) = 2 is an isolated border edge. An edge falls into one of the following types: 1. a terminal edge 
with both sides in an inner contour, 2. a connecting edge with both sides in an inner contour, 3. a 
border edge with both sides in two distinct inner con- tours,  4. a border edge with one side in an 
inner contour and the other side in an outer contour,  5. an isolated edge, 6. a terminal edge with 
both sides in an outer contour, 7. a connecting edge with both sides in an outer contour, 8. an isolated 
border edge.  When inserting a curve, new edges may be added to the map. Adding an edge implies creating 
its sides, vertices, and updating the c~-order around the latter. The updated contours are thus available 
through the mapping ~w. The inclusion tree is updated after each new edge addition, it is therefore possible 
to find the type of a new edge by counting its dan- gling vertices and checking the updated contours. 
The inclu- sion tree is then updated by performing the following actions, indexed by edge type: 2. merge: 
inner &#38; outer ~ inner 3. split: inner ~ inner &#38; inner 4. split: outer ~ outer &#38; inner 
5. create: outer  7. merge: outer &#38; outer ---~ outer 8. create: outer &#38; inner  For example, 
if an edge of type 2 is added to a map, one inner contour and one outer contour are merged to give a 
single inner contour. When erasing a curve or an arc, old edges may be removed from the map. The inclusion 
tree is updated before each old edge removal, using the same tests as above. When the type of the edge 
has been found, the inclusion tree is updated by performing the following actions, indexed by edge type: 
2. split: inner ~ inner &#38; outer 3. merge: inner &#38; inner ~ inner 4. merge: outer &#38; inner 
---+ outer 5. delete: outer  7. split: outer ~ outer &#38; outer 8. delete: outer &#38; inner  Adding 
or removing an edge of type 1 or 6 (i.e., terminal edges) does not modify the inclusion tree. :~~SIGGRAPH 
'89, Boston, 31 July-4 August, 1989 References [1] D. Baroni. Art Graphique Design. Editions du Chine, 
Paris, 1987. [2] P. Baudelaire and M. Gangnet. Planar Maps." an Inter- action Paradigm for Graphic Design. 
In CH1'89 Pro- ceedings, Addison-Wesley, 1989. [3] J.L. Bentley and T.A. Ottmann. Algorithms for Re- 
porting and Counting Geometric Intersections. IEEE Trans. on Comput., 28(9), 1979. [4] T.D. DeRose and 
B.A. Barsky. Geometric Continu- ity for Catmull-Rom Splines. ACM Transactions on Graphics, 7(1), 1988. 
[5] D.H. Greene and F.F. Yao. Finite-Resolution Com- putational Geometry. In Proc. 27th 1EEE Symp. on 
Found. Comp. Sci., Toronto, 1986. [61 D. Dobkin and D. Silver. Recipes for Geometry and Numerical Analysis. 
In Proceedings of the Fourth An- nual ACM Symposium on Computational Geometry, ACM Press, New York, 1988. 
[7] H. Edelsbrunner. Algorithms in Combinatorial Geom- etry. Springer-Verlag, New York, 1987. [8] H. 
Edelsbrunner, L. Guibas, J. Pach, R. Pollack, R. Sei- del, and M. Sharir. Calculating Arrangements of 
Seg- ments, Circles, or Other Curves in the Plane. 1988. Submitted for publication. [9] H. Edelsbrunner 
and L.J. Guibas. Topologically Sweeping an Arrangement. Research Report #9, Dig- ital Equipment Systems 
Research Center, Palo Alto, 1986. [lO] A. R. Forrest. Geometric Computing Environments: Some Tentative 
Thoughts. In Theoretical Foundations of Computer Graphics and CAD, Springer-Verlag, 1988. [tl] M. Gangnet 
and J.C. Hervr. D2: un 6diteur graphique interactif. In Actes des Journ~es SM90, Eyrolles, Paris, 1985. 
[12] L. Guibas and J. Stolfi. Primitives for the Manipula- tion of General Subdivisions and the Computation 
of Voronoi Diagrams. ACM Transactions on Graphics, 4(2), 1985. [13] C.M. Hoffmann, J.E. Hopcroft, and 
M.S. Karasick. To- wards Implementing Robust Geometric Computations. In Proceedings of the Fourth Annual 
ACM Symposium on Computational Geometry, ACM Press, New York, 1988. [14] P.A. Koparkar and S.P. Mudur. 
A new class of algorithms for the processing of parametric curves. Computer-Aided Design, Vol. 15, 1983. 
[15] J.F. Lane. Curve and Surface Display Techniques. Tu-torial, ACM SIGGRAPH'81, 1981. [16] S.L. Lien, 
M. Shantz, and V. Pratt. Adaptive Forward Differencing for Rendering Curves and Surfaces. ACM Computer 
Graphics, Vol. 21(4):111-118, 1987. [17] P. Lienhardt. Extensions of the Notion of Map and Sub- division 
of a Three-Dimensional Space. In STACS'88, Lecture Notes in Computer Science 294, 1988. [18] D. Michelucci. 
ThEse. Ecole Nationale Suprrieure des Mines de Saint-Etienne, Saint-Etienne, 1987. [19] D. Michelucci 
and M. Gangnet. Saisie de plans ~t partir de tracrs h main-levre. In Actes de MICAD 84, Hermes, Paris, 
1984. [20] F.P. Preparata and M.I. Shamos. Computational Ge- ometry: an Introduction. Springer-Verlag, 
New York, 1985. [21] L. Ramshaw. Blossoming: A Connect-the-Dots Ap- proach to Splines. Research Report 
#19, Digital Equip- ment Systems Research Center, Palo Alto, 1987. [22] M. H. Schultz. Spline Analysis. 
Prentice Hall, 1973. [23] T.W. Sederberg and S.R. Parry. Comparison of three curve intersection algorithms. 
Computer-Aided De- sign, Vol. 18, t986. [24] W.T. Tutte. Graph Theory. Addison-Wesley, 1984. [25] G. 
Wang. The Subdivision Method for Finding the In- tersection between two Brzier Curves or Surfaces. Zhe-jiang 
University Journal, 1984. Cited in reference [23].   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74370</article_id>
		<sort_key>355</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[A characterization of ten rasterization techniques]]></title>
		<page_from>355</page_from>
		<page_to>368</page_to>
		<doi_number>10.1145/74333.74370</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74370</url>
		<abstract>
			<par><![CDATA[With widespread use of raster scan displays and the ever-increasing desire for faster interactivity, higher image complexity, and higher resolution in displayed images, several techniques have been proposed for rasterizing primitive graphical objects. This paper characterizes the performance of these techniques and shows how they evolve for more complex images on higher resolution displays. This characterization will not only show the strengths and deficiencies of existing rasterization techniques, but will also reveal new architectures for future raster graphics systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P204775</person_id>
				<author_profile_id><![CDATA[81100648858]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gharachorloo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14021608</person_id>
				<author_profile_id><![CDATA[81332502486]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39079493</person_id>
				<author_profile_id><![CDATA[81100302488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Sproull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sutherland, Sproull, and Associates, Inc., 4516 Henry Street, Pittsburgh, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39079814</person_id>
				<author_profile_id><![CDATA[81100265287]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[I.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Sutherland]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sutherland, Sproull, and Associates, Inc., 4516 Henry Street, Pittsburgh, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[K. Akeley and T. Jermoluk. High Performance Polygon Rendering. Proceedings of SIGGRAPH, 22(4):239-246, August 1988.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378518</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. Apgar, B. Bersack, and A. Mammen. A Display System for the Stellar Graphics Supercomputer Model GS 1000. Proceedings of SIGGRA PH, 22(4):255-268, August 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16306</ref_obj_id>
				<ref_obj_pid>16304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Mike Asai, Graham Short, Tom Preston, Richard Simpson, Derek Roskell, and Karl Guttag. The TI34010 Graphics System Processor. Computer Graphics and Applications, 6(10):24-39, October 1986.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807466</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Bechtolsheim and F. Baskett. High-Performance Raster Graphics for Microcomputer Systems. Computer Graphics, 14(3):43-47, July 1980.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J.E. Bresenham. Algorithm for computer control of a digital plotter. IBM Systems Journal, 4(1):25-30, July 1965.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J.E. Bresenham. Raster Line Run Length Slice Algorithm, IBM System Communication Division, TR 29.0180, Research Triangle Park, North Carolina. January 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J.E. Bresenham. Incremental Line Compaction. The Computer Journal, 25(1): 116-120, 1982.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J.H. Clark. The Geometry Engine: A VLSI Geometry System for Graphics. Computer Graphics, 16(3):127-133, July 1982.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J.H. Clark and M.R. Hannah. Distributed Processing in a High-Performance Smart Image Memory. LAMBDA (Now VLSI Design), (4th. Quarter):40-45, 1980.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378468</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Deering, S. Winner, B. Schediwy, C. Duffy, and N. Hunt. The Triangle Processor and Normal Vector Shader: A VLSI System for High Performance Graphics. Proceedings of SIGGRAPH, 22(4):21-30, August 1988.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Demetrescu. High Speed Image Rasterization Using Scan Line Access Memories. Proc. 1985 Chapel Hill Conference on VLSI, pages 221-243, Computer Science Press, 1985.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs and J. Poulton. Pixel Planes: A VLSI-Oriented Design for a Raster Graphics Engine. VLSI Design, 2(3):20-28, 3rd. Quarter 1981.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74341</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs, J. Poulton, J. Eyles, T. Greer, J. Goldfeather, D. Ellsworth, S. Molnar, G. Turk, B. Tebbs, and L. israel. A Heterogeneous Multiprocessor Graphics System Using Processor- Enhanced Memories. Proceedings of SIGGRAPH, 1989.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. Fussell and B.D. Rathi. A VLSI-Oriented Architecture for Real-Time Raster Display of Shaded Polygons. Proc. of Graphics Interface, pages 373-380, 1982.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378474</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[N. Gharachorloo, S. Gupta, E. Hokenek, P. Balasubramanian, B. Bogholtz, C. Mathieu, and C. Zoulas. Subnanosecond Pixel Rendering with Million Transistor Chips. Proceedings of SIGGRAPH, 22(4):41-49, August 1988.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[N. Gharachorloo and C. Pottle. SUPER BUFFER: A Systolic VLSI Graphics Engine for Real Time Raster Image Generation. Proc. 1985 Chapel Hill Conference on VLSI, pages 285-305, Computer Science Press, 1985.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30659</ref_obj_id>
				<ref_obj_pid>30657</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Goris, B. Fredriekson, and H. Baeverstad. A Configurable Pixel Cache for Fast Image Generation. IEEE CGdA, pages 24-32, 1987.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[S. Gupta. Architectures and Algorithms for Parallel Updates of Raster Scan Displays, Computer Science Department, Carnegie-Mellon University, CMU-CS-82-111, Pittsburgh, PA. December 1981.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806791</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[S. Gupta, R.F. Sproull, and I.E. Sutherland. A VLSI Architecture for Updating Raster Scan Display. Computer Graphics, 15(3):71-78, July 1981.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807486</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J.H. Jackson. Dynamic Scan-converted Images with a Frame Buffer Display Device. Proceedings of S1GGRAPH, page 163, 1980.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360836</ref_obj_id>
				<ref_obj_pid>360827</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[B.W. Jordan, Jr. and R.C. Barrett. A Cell Organized Raster Display for Line Drawings. Comm. of the ACM, 17(2):676, Febraury 1974.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807459</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Kaplan and D. Greenberg. Parallel Processing techniques for Hidden Surface Removal. Proceedings of SIGGRAPH, page 300, August 1979.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[L. Kohn and S.W. Fu. A 1,000,000 Transistor Microprocessor. ISSCC, pages 54-55, February 1989,]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1317</ref_obj_id>
				<ref_obj_pid>1313</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[R. Matick, D.T. Ling, S. Gupta, and F.H. Dill. All Points Addressable Raster Display Memory. IBM Journal of Res. and Dev., 28(4):379-382, July 1984.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[W.M. Newmann and R.F. Sproull. Principles of Interactive Computer Graphics. McGraw Hill, 1973.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808580</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[H. Niimi, Y. Imai, M. Murakami, S. Tomita, and H. Hagiwara. A Parallel Processor System for Three Dimensional Color Graphics. Proceedings of SIGGRAPH, page 67, July 1984.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[I. Page. Disarray: A 16 x 16 RasterOp processor. Eurographics 83, pages 367-377, Amsterdam: North Holland, 1983.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807467</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[F.I. Parke. Simulation and Expected Performance Analysis of Multiple Processor Z-Buffer Systems. Siggraph, pages 48-56, 1980.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[R. Schumacker. A New Visual System Architecture. Proc. of Second Interservice/Industry Training Equipment Conf., page 1, November 1982.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357312</ref_obj_id>
				<ref_obj_pid>357311</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[R.F. Sproull. Using Program Transformations to Derive Line-Drawing Algorithms. ACM Transactions on Graphics, 1 (4):259-273, 1982.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>17816</ref_obj_id>
				<ref_obj_pid>17814</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[R.F. Sproull. Frame Buffer Display Architectures. Annual Review of Computer Science, 1 : 19-46, Annual Reviews Inc., 1986.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357316</ref_obj_id>
				<ref_obj_pid>357314</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[R.F. Sproull, I.E. Sutherland, A. Thompson, and S. Gupta. The 8 by 8 Display. A CM Transactions on Graphics, 2(1 ):32-56, January 1983.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[I.E. Sutherland, R.F. Sproull, and R.A. Schumacker. A Characterization of Ten Hidden-Surface Algorithms. Computing Surveys, 6(1): 1, March 1974.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[R.W. Swanson and L.J. Thayer. A Fast Shaded- Polygon Renderer. Proceedings of SIGGRAPH, pages 95-102, 1986.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[C.P. Thacker, E.M. McCreight, B.W. Lampson, R.F. Sproull, and D.R. Boggs. Alto: A Personal Computer". Computer Structures: Readings and Examples, McGraw Hill, 1981.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[A.M. Walsby. Fast colour raster graphics using an array processor. Eurographics 80, pages 303-313, Amsterdam: North Holland, 1980.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[G.S. Watkins. A Real Time Visible Surface Algorithm, University of Utah, UTEC-CSC-70-101, June 1970.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[R. Weinberg. Parallel Processing Image Synthesis and Anti-Aliasing. Proceedings of SIGGRAPH, pages 147-154, july 1982.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[M.C. Whitton. Memory Design for Raster Graphics Displays. Computer Graphics and Applications, 4(3):48-65, March 1984.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>737295</ref_obj_id>
				<ref_obj_pid>647872</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Paul Winser. 3D Graphics for Consumer Applications- How Realistic Does it Have to Be?. Eurographics, 1988.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Characterization of Ten Rasterization Techniques Nader Gharachorloo Robert F. Sproull Satish Gupta 
Ivan E. Sutherland IBM Thomas J. Watson Research Center Sutherland, Sproull, and Associates, Inc. Yorktown 
Heights, NY 10598 4516 Henry Street, Pittsburgh, PA 15213 Abstract With widespread use of raster scan 
displays and the ever-increasing desire for faster interactivity, higher image com-plexity, and higher 
resolution in displayed images, several techniques have been proposed for rasterizing primitive graphical 
objects. This paper characterizes the performance of these techniques and shows how they evolve for more 
complex images on higher resolution displays. This charac- terization will not only show the strengths 
and deficiencies of existing rasterization techniques, but will also reveal new ar-chitectures for future 
raster graphics systems. Introduction The raster-scan display is now the most popular computer output 
device because of the rapid decrease in the cost of semiconductor memories and the low cost of raster-scan 
CRTs. Such displays are now used in a wide range of appli- cations, from home computers to engineering 
design to flight simulation. Raster-scan displays are most commonly driven by a frame buffer, a memory 
that stores the color value for every picture element on the screen and refreshes the display continuously. 
The process of generating these picture clement values from a geometric description of the image is known 
as rasterization. The principal strength of the frame buffer is that it can show an arbitrary image on 
the display with an arbitrary number of primitive objects, subject only to the limit of spatial and in-tensity 
resolution of the display device. The weakness of a frame buffer is that a great many bits must be changed 
to change the picture. Because of their large size, frame buffers are usually implemented using the highest 
density, and hence the slowest, memory chips. The difficulty of accessing pixel data rapidly in such 
frame-buffer memories can be overcome by several different techniques. This paper will characterize ten 
such techniques. These techniques will be characterized along three aspects of the display user's desires: 
interactivity, image complexity, and resolution. Interactivity is determined by how rapidly the im- Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. age is updated 
and hence how rapidly the user can interact with his application. Image complexity is characterized by 
the number of the primitive objects (shaded triangles, vectors, characters) displayed. Resolution refers 
strictly to the number of pixels on the display device and will provide a measure of how these techniques 
are likely to evolve as resolution in-creases. Examining the full spectrum of rasterization tech-niques 
will help predict the evolution of future graphics architectures.  Background Figure 1 shows a typical 
rasterization system based on the frame buffer. The host computer generates graphical primi- tives, the 
rasterization processor converts these primitives into pixel values and stores them in the frame buffer, 
which is ac- cessed continuously to refresh the screen. Any rasterization system must be able to receive 
graphical primitives, rasterize these primitives, and continuously refresh the raster display. Given 
that all rasterization systems must satisfy these common input and output requirements, the only fundamental 
differ-ence among rendering systems is the frame-buffer memory organization and the rasterization processor 
to match it. Before examining the details of different rasterization tech-niques, it is necessary to 
have an understanding of the primi- tives being rasterized, the sources of parallelism in the rendering 
problem, and the organization of the rasterization processor. Rasterization Primitives We have chosen 
three primitives for characterization: Gouraud-shaded three-dimensional triangles, two-dimensional vectors, 
and characters. With the advent of windowing sys- tems, it is desirable that the same rasterization system 
be ca- pable of efficiently rendering all three types of primitives on the same screen. Higher-level 
curve and surface primitives can be broken down into these basic primitives, i.e. polylines and triangular 
meshes. Three-dimensional triangles are represented by three vertices, each of which is described by 
x,y,z screen coordinates and an r,g,b color triplet. The triangle is rasterized by linearly in- terpolating 
the depth and color values for each pixel inside the triangle and conditionally updating the frame buffer 
and the z-buffer values only if the triangle is visible [25]. Most systems use 8 or 24 bits per pixel 
for storing color values and 16 or more bits per pixel for storing depth information. Given P triangles 
of average pixel area A, a total of P x A pixels must be accessed to render the scene. Assuming the &#38;#169;1989 
ACM -0-89791-312-4/89/007/0355 $00.75  ,~~SIGG RAPH'89, Boston, 31 July-4 August, 1989 Primitives J 
Rasterization 7 Processor ~ Pixels Host  Computer Frame Videos Screen Buffer -L 1  Rasterization System 
Figure 1. Prototypical frame buffer system. scene covers a screen of N pixels and that each triangles 
are overlaid in D layers everywhere, we have [33]: PxA=NxD where D is the depth complexity. The average 
height or width of a triangle is proportional to Average width = Averageheight = v'~ = v/~/P For performance 
comparisons, the average values are good approximations to the actual area and height distributions. 
The average depth complexity, D, is dependent upon the type of scene being rendered: tesselated or non-tesselated. 
Con-sider rendering a scene composed of several spheres, each of which is rendered with 100 triangles. 
Tesselating the sphere into smaller triangles (say 1000) will increase the number of triangles while 
reducing the area of each triangle. In this case, D remains constant, while P increases and A decreases. 
Zooming out will have a similar effect. On the other hand, adding more spheres to the scene will increase 
the depth com-plexity, but will not change the average area of each triangle in the scene. This is a 
non-tesselated scene, where P and D change without affecting A. Typical scenes mix tesselated and non-tesselated 
characteristics and the response time is bounded by the response time for these two extremes. Two-dimensional 
vectors are represented by a pair of xd, endpoints. Vectors are rasterized by drawing a digitized line 
between the endpoints [5]. The performance of the various rasterization techniques is sensitive to the 
angular distribution of the vectors. We consider two types of angular vector dis- tributions: uniform 
and the 25/25/50 distribution. For some applications, all angles are equally likely and the angular dis- 
tribution is uniform. For applications that do not allow rota- tion (such as electrical circuit design), 
we will assume that 25% of the vectors are horizontal, 25% are vertical, and the remaining 50% have an 
equal probability over all angles with a slight preference for 45 degrees, which we will ignore. We will 
assume that there are V vectors with an average length of L pixels. For characters, we will assume that 
they tesselate the whole screen, and hence the area of each character is N/C, where C is the number of 
characters on the screen. Parallelism in Rasterization To meet the requirements of interactive systems 
that demand response in less than a second, or even less than a tenth of a second, rasterization must 
use parallel processing. Different kinds of parallelism can be exploited, such as: Pixel Level: Parallelism 
within a pixel to access and in- terpolate up to six parameters in parallel: xd,,z,r,g,b. Primitive Level: 
Parallelism within a triangle to access several pixels along a horizontal span or in a rectangu- lar 
region. Multiple Primitive Level: Parallelism obtained by rasterizing several primitives at once. Frame 
Level: Parallelism within a frame to process se- veral sub-frames or full frames at once. Effective exploitation 
of parallelism requires tradeoffs due to overhead computations associated with parallelizing any problem. 
Optimal solutions minimize the parallelization overhead and maximize the speedup. We assume that the 
overhead processing can be overlapped with the parallel rasterization and hence make no attempt to compare 
overhead costs. In some cases, the overhead due to parallelism may ex- ceed the speedup. Rasterization 
Processors For low-performance applications, a general-purpose processor can be used for rasterization. 
Somewhat greater performance can be achieved with "graphics processors" which have specialized instructions 
for rasterization [3, 23]. These processors usually require several instruction cycles to compute the 
value of each pixel to be stored, thus limiting the update rate. Equally limiting is the update rate 
of the frame- buffer memory designs used with these processors. If only a single pixel can be written 
in a memory cycle, performance is low. Clearing the million pixels on a 1024 x 1024 screen will take 
1/4 second, assuming each memory cycle requires 250 ns. Although the speed of the frame-buffer memory 
can be increased by using Static RAM memory chips, these are more expensive and bulkier than conventional 
Video RAMs. A first step in parallel rasterization is to design a special processor that computes one 
pixel value in every clock cycle. Wide data paths are used to access the parameters of the ge- ometry 
primitive (xy~,r,g,b) in parallel, rather than sequen-tially as required in a conventional microprocessor. 
To achieve even greater performance, pixel values for several pixels in the same graphics primitive are 
computed in parallel.  TEN RASTERIZATiON TECHNIQUES I I I I Frame Buffer Virtual Buffer Object Oriented 
Standard Memory Custom Memory Sca.rdine Buffer ] F --L] I I I a _ e Figure 2. Ten rasterization techniques. 
High-performance rasterization requires special rasterization processors and special frame-buffer organizations. 
The mem-ory is designed to access more than one pixe! in a single cycle, and the processor uses parallelism 
to compute pixel values fast enough to keep the frame-buffer memory busy. These struc- tures use primitive-level 
parallelism. The response time increases linearly with the number of prim- itives (P, V, or C). The rasterization 
time for each primitive is the sum of two pieces: the constant setup time for the primi- tive rasterization 
loop and the iteration time for the rasterization loop, which is proportional to the size of the primitive. 
If setup and iteration are overlapped, the total time is the maximum of the setup and the iteration time. 
Systems with fast setup hardware do best on small size primitives, while systems with fast iteration 
hardware do best on larger primi- tives. Although scenes are composed of both small and large primitives, 
the rasterization of an average primitive is typically dominated by the iteration time. Henceforth, we 
will charac- terize only the average iteration time and assume the setup time is performed in parallel 
or is negligible. Taxonomy Figure 2 shows a taxonomy of ten rasterization techniques surveyed in this 
paper. The three primary branches categorize the techniques based on their underlying pixel memory model: 
Frame-buffer techniques that allocate a memory lo-cation for every pixel in the frame and rasterize all 
primitives into this random-access memory. Virtual-buffer or partial-buffer techniques that rasterize 
primitives into a small portion of the screen memory and reuse this virtual portion repeatedly to construct 
the full frame. Object-oriented techniques that refresh the display di- rectly from computations on each 
primitive and there- fore may operate without a frame buffer. Frame-Buffer Techniques The frame buffer 
is a two-ported memory: the refresh port is used to read the pixel values in serial order for displaying 
the raster image and the update port is used by the rasterization processor to change the picture at 
arbitrary locations on the screen. Before the introduction of Video RAM chips [24], single-ported dynamic 
RAM chips were used to implement frame buffers. In these frame buffers the refresh port con-sumed a significant 
fraction of the frame-buffer bandwidth. The Video RAM augments the dynamic RAM with an on-chip shift 
register that can be loaded in a single memory cycle and can be shifted out asynchronously to refresh 
the CRT, freeing the random-access port for use by the rasterization processor. High-performance systems 
often contain two frame buffers, where one is used to display the current frame while the other is used 
to render the next frame. Today, most frame buffers are implemented using 256 Kilotbit and 1 Megabit 
Video RAM chips [39]. The 256K Video RAM is organized as a 64Kx4 RAM with 4 bits available in parallel 
both at the random and the serial ports. These chips have random-acess cycle times of Tcyc (typically 
250 nsec), with faster "Page mode" access to locations in the same page (256 bit bank for 64K x 4 RAMs), 
namely Tpm (typically 125 nsec). For read-modify-write cycles, we will assume a cycle time of Trmw (typically 
375 nsec). The serial port has a cycle time of Tser (typically 40 nsec). As memory chips become more 
dense, high-performance rasterizers become more difficult to design because the mem- ory bandwidth does 
not increase as fast as the memory capac- ity. For example, switching from 64Kx4 Video RAMs to 256K x 
4 Video RAMs results in a factor of four reduction in maximum available memory bandwidth for equivalent 
memory capacity. Techniques that obtain high performance by operat- ing many memory chips in parallel 
are less effective for fewer memory chips. To counteract this problem, designers turn to more exotic 
memory organizations or to special-purpose memory chips that do some of the rasterization processing 
on-chip. '~.~SIGGRAPH '89, Boston, 31 July-4 August, 1989 The frame-buffer techniques described in 
this section differ in the number of pixels that are accessed in each cycle and in the geometric configuration 
of the pixels in each access. The single-pixel organization accesses a single pixel in each cycle. The 
linear array organization accesses a few pixels that lie to- gether on the same horizontal scan line. 
The square array or- ganization accesses in one cycle a small square of pixels. In each of these structures, 
only a modest number of pixels are accessed in parallel (up to about 100) and the rasterization processor 
or processors are distinct from the memory. Achieving greater performance requires specially-designed 
memory chips that integrate the memory and rasterization processors. The scan-line access memory (SLAM) 
accesses all pixeis on a single scan-line in one cycle, while the Pixel- Planes design accesses every 
pixel in the frame buffer in one cycle. Single Pixel Access The single-pixel technique organizes the 
frame buffer to access one pixel in each memory cycle. Although normal updates will require full memory 
cycles, if successive updates lie on the same scanline, page-mode cycles can be used to increase rasterization 
speed. For three-dimensional primitives, we assume that the frame buffer is augmented by a z-buffer that 
provides one depth value each memory cycle. For the rasterization of three-dimensional primitives, we 
need to read, compare, and write the depth value for every pixel in the primitive. Using the read-modify-write 
memory cycle, a pixel can be updated in time Trmw. When the scan conversion is done in raster order, 
faster page-mode cycles can be used. An even faster technique that uses VRAMs to implement the z -buffer 
is shown in Fig- ure 3. The depth value stored in the z-buffer is read from the serial port, compared, 
and written back into the update port in page mode such that the average pixel update time is re- duced 
to Tpm[40] . Note that the pixel value write is over- lapped with z-buffer write. Linear ,4 rray ,4 ccess 
 A linear-array frame buffer is organized so that each cycle accesses W pixels that lie along a continuous 
part of a hori- zontal scanline of the image. Successive sets of W pixels are called words; boundaries 
between words occur after every multiple of W pixels in the scanline. Access is normally to a particular 
word, though it is possible to access W pixels start- ing at any arbitrary pixel location by using different 
parts of two consecutive words. Such arbitrary access requires provid- ing different memory chips with 
one or the other of two con- secutive addresses [4, 31, 32]. Although pixel-aligned access can provide 
a performance advantage over word-aligned ar-rays, computing two memory addresses can lead to a longer 
memory cycle, and hence can offset the gain in performance. The linear array is potentially capable of 
a W-fold speedup over the single-pixel structure. However, this maximum speedup can be achieved only 
if the primitives being rasterized are parallelizable such that Whorizontal pixels can be updated in 
every memory cycle. Since this may not be the case, the speedup must be discounted by an efficiency factor, 
which is a function of both W and the average number of horizontal pixels (span) in the primitive being 
rasterized. Figures 4a and Z-Buffer i Update Port  OId-Zw-Z i Rasterization Processor ~l New-RGB 
Update Port ~ Frame ~-Video Buffer Figure 3. Fast Z-buffer. 4b plot the speedup Slint, for the word 
and pixel aligned linear array organizations for typical character and triangle span sizes (8 and 32) 
against different word sizes. For the word aligned case, the point of diminishing returns is at word 
sizes that are greater than twice the average span size, and for pixel aligned case it is achieved when 
the word size is greater than the average span size. If the spans are sufficiently big relative to the 
word size, then the speedup is independent of the word aligned or pixel aligned memory organization. 
For vectors, the speedup provided by the linear array memory organization depends on the angular distribution 
of the vec-tors. Figures 4c and 4d show the vector speedup Slinv for dif- ferent word sizes. Figure 4c 
shows vector speedup for a 25/25/50 distribution of vectors. This distribution exhibits a rapid increase 
in vector drawing speed with larger word sizes due to the speedup of horizontal and nearly horizontal 
vectors. FOr uniformly distributed vectors, shown in Figure 4d, the performance increase with increasing 
word size is less dra- matic. To realize the maximum speedup of vectors in the linear array organization 
requires that a full horizontal run be generated in every memory cycle. An algorithm for generating lines 
by run-length has been described by Bresenham [6, 7]. For a pixel-aligned linear array with W = 16, the 
speedup for uni- formly distributed vectors would be 2.3 and would increase to 5.3 for the 25/25/50 distribution 
because of the greater frac- tion of horizontal vectors. Square Array Access Based on the belief that 
graphical objects are no more likely to be short and wide than tall and thin, several frame buffers have 
been built to access a square array of M x M pixels in each memory cycle [9, 27, 32, 36]. Such an organization 
can take advantage of two-dimensional locality in the scan con-version of primitives. As an example, 
a character 8 pixels wide and 12 pixels high could be stored in two memory cycles in an 8 x 8 organization, 
but would require 12 memory cycles in a linear array. The techniques used for providing pixel aligned 
  addressing for linear arrays can be extended to square arrays [321. As for the linear organization, 
the potential performance of the square organization must be reduced by an efficiency fac- tor, which 
is a function of the size of the square, M, and the average area of the primitives being rasterized. 
Figures 5a and 5b show the possible speedup Ssqt, i.e., the average number of pixels that can be written 
in each memory cycle, for differ- ent word sizes (M x M) for typical character and triangle sizes (8 
and 32). Notice that pixel alignment has a higher payoff as the square size approaches the size of the 
primitives. The square organization achieves speedup for vectors of any orientation, while the linear 
organization is able to achieve parallelism only for horizontal vectors. The overall speedup ( Ssqv) 
achieved is shown in Figures 5c and 5d. A 4 x 4 pixel- aligned square array will increase vector-generation 
speed by a factor of four for any distribution of vector orientations. In an M x M array, vector generation 
can be done either by generating M pixels sequentially in the time required by one memory cycle, or by 
using an algorithm that chooses from a set of predefined M x M strokes [18, 30]. Scan Line Access The 
Scan Line Access Memory (SLAM) architecture is the extreme case of a linear array where the array size 
is equal to the width of the screen, and a scanline of pixel processors work in parallel to update the 
memory [ 11]. SLAM implements on one chip a modified Video RAM and pixel processors that can update horizontal 
spans of any size in each memory cycle, SLAM is a memory chip architecture that can be used as a component 
to implement single, linear, or square frame-buffer accesses. Since each individual memory chip accesses 
only a few bits of every pixel, this memory design cannot be easily extended to 3D z-buffer algorithms. 
The performance of SLAM is like that of the linear array with W = ~-. Since SLAM can write an arbitrary 
horizontal span of a triangle in a single cycle, Slint = v~--, the width of a tri- angle. For vectors, 
SLAM's speedup is Slinv, like that for the linear array but somewhat better because of the larger value 
of W. Performance on characters is limited by the rate with which font data can be delivered to the SLAM 
and whether more than one character can be written in a single cycle. We have chosen to characterize 
SLAM's character performance equal to that of the linear array. Full Frame Access At the extreme in 
parallel access, a frame buffer that can ac-cess all N pixels on the screen in a single cycle can write 
any object in a single cycle. Such a structure generally requires N pixel processors as well. Parameters 
describing a graphics primitive are broadcast to all processors, and each processor computes a pixel 
value to store in its associated pixel, or de- cides that the primitive does not affect its pixel, and 
leaves the current value unchanged. This technique is implemented in Pixel-Planes [ 12]. A triangle is 
described by three plane equations ~(x~v) = Aix + B~ + C i = 0 . The plane equation coeffi-cients, A,B,C 
are broadcast bit serially to bit-serial pixel processors that evaluate the F~ to determine which pixels 
lie inside the polygon. Each pixel location has sufficient bits to store depth and color values. The 
interior pixels then evaluate Z(x,y) = A,x + By + CCz and compare the value to the stored value to determine 
which pixels are visible, Finally, the red, green, and blue intensities are calculated in three passes 
by evaluating three equations of the form R(x,y) = A,x + By + Cr. For a triangle, a total of about 300 
bits are broadcast serially to the pixel processors. The number of bits is proportional to log N and 
can hence be considered a constant. The response time is independent of screen resol-ution, but depends 
on the number of triangles on the screen and the speed of serial broadcast. Virtual- Buffer Techniques 
Virtual buffer techniques rasterize primitives into a band buffer and use the band buffer repeatedly 
to construct the whole image a piece at a time. The primary motivation for a virtual buffer memory is 
to exchange the large and slow frame buffer memory for a smaller and faster virtual buffer memory to 
increase performance. The virtual buffer organization for a 1024 x 1024 screen ranges anywhere from a 
1024 x 1 scanline buffer, or 1024 x 16 band buffer, or 32 x 32 square virtual buffer. Larger virtual 
buffers such as a 1024 x 512 half-frame buffer or a 512 x 512 quarter-frame buffer have been implemented 
primarily to save memory rather than to increase performance. Virtual buffers have been used to pre- 
pare raster images for laser printers [35]. Virtual buffers may be used in two distinct ways: in a sweep 
algorithm or as a pixel cache. Sweep algorithms make one pass over the entire image, assigning the virtual 
buffer to successive portions of the image in turn. For each assignment, the virtual buffer is cleared, 
primitives are rasterized into it, and the vir- tual buffer is then output, either in real time to a 
display or laser printer, or in near real time to a full-frame buffer. Alter- natively, a virtual buffer 
can be used as a pixel cache, a fast window on a conventional frame buffer [2]. In the course of rasterizing 
a scene, the contents of the virtual buffer may be exchanged with those in the frame buffer many times. 
The strategies for sorting primitives into bands for rasterization are strongly influenced by the size 
of the virtual buffer. To best realize the advantages of virtual buffer tech- niques, the primitives 
must be structured so that all primitives corresponding to each virtual buffer can be rasterized to-gether. 
For large virtual buffers (i.e. 1024 x 512) it is ac- ceptable to make two passes over the primitives, 
where in the first pass all primitives are clipped to the top half of the screen and in the second pass 
they are clipped to the bottom half. For smaller virtual buffers, multipass strategies fail because of 
the large transformation and clipping overhead. A common technique is to sort primitives according to 
the topmost line on which the primitive is activated. A Watkins-style [37] active edge list algorithm 
is then implemented, where new primitives are activated by insertion and rasterized primitives are deacti- 
vated by deletion. Alternatively, an active polygon ring [16] can generate all the horizontal spans for 
the current line in the virtual buffer before proceeding to spans in the next line. The smaller the virtual 
buffer, the larger the overhead of dealing with leftover primitive information that must be saved for 
the next buffer. A full discussion of sorting strategies and over-head is beyond the scope of this paper. 
Our characterizations    ~L.,,~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 VIRTUAL BUFFER TECHNIQUES 
I I Scanline Buffer Band Buffer Square Buffer  I I I I I I I I I I, o d t/3 Figure 6. Taxonomy of Virtual 
Buffers. of performance assume that these activities are overlapped with rasterization, and are therefore 
ignored. As the examples suggest, there are three possible virtual buffer organizations: scan line virtual 
buffers, multiple scan line vir- tual buffers, and square virtual buffers. Figure 6 shows the taxonomy 
for all possible virtual buffer techniques. This paper will characterize only the scanline virtual buffer 
technique. Scan Line Virtual Buffer The scanline virtual buffer uses a single scan line buffer for rasterization. 
For every scanline on the display, the rasterization processor updates the contents of the current scanline, 
while the previous scanline is either being directly shifted out to the screen or into an intermediate 
frame buffer as shown in Figure 7. If the screen is being updated directly, then the next scanline must 
be shifted in while the current scanline is being updated. The virtual buffer technique is best utilized 
when the time taken to update a scanline is compara- ble to or greater than the time taken to shift the 
scanline in or out. It is better used in a sweep algorithm than as a pixel cache. Transfer of the virtual 
buffer contents to the frame buffer does not cause any memory bottlenecks because the frame buffer can 
be updated serially (possibly through the video port) and requires only one access per pixel to the frame 
buffer. Multiple memory accesses caused by overlapping objects (D times for triangles) are handled within 
the virtual buffer, and only the final image is sent to the frame buffer. The z values are never needed 
for the whole image and hence exist only in the virtual buffer, As in the case of frame buffers, a scanline 
virtual buffer can be updated either as a single pixel at a time [20], in a hori-zontal word with Wpixels 
[35], or using a processor for every pixel of the scan line [16]. The response time for single and W 
pixel updates is the same as for frame buffers, improved only by the faster memory cycle of the virtual 
buffer Tvb. Us-ing fast static memories, these could potentially lead to a two- to ten-fold performance 
improvement over the frame buffer. Super Buffer The Super Buffer [15, 16] takes advantage of VLSI chip 
technology by constructing a linear systolic array of pixel processors to rasterize horizontal span primitives 
into an on- chip virtual scan line buffer. A complementary active polygon ring generates all the horizontal 
span primitives for each scan line from polygon descriptions. The highly pipelined structure and the 
systolic communication of the rasterization processors allow the system to be clocked as fast as 40 nsec. 
The Super Buffer has sufficient processing power to rasterize the image in real time so that the frame 
buffer can be avoided. However, without a frame buffer, any virtual-buffer architecture will have a limit 
on the complexity of the image it can display. In the case of the Super Buffer, the limit is that the 
number of spans per scanline cannot exceed the number of pixets in a Scanline Z-Cache I Z 3D Rasterization 
 p ri m it ive s-'----.4~,' Processor RGB "  I Scanline RGB-Cache I RGB Frame I VideoBuffer I Figure 
7. Scan Line Virtual Buffer. m.. scanline. The use of a frame buffer allows the system to de- grade 
gracefully with increasing image complexity. Object-Oriented Techniques Object-oriented techniques refresh 
the display directly from processors that compute in real time how to display each primitive and therefore 
operate without any pixel memory. Object-oriented techniques can be broken down into two cat- egories: 
techniques that deal only with non-overlapping ob- jects, and techniques that resolve object overlap 
according to a preassigned priority or by performing depth comparisons. Character~Sprite Displays The 
most common object-oriented display is the character display, where the screen is split into a fixed 
number of non- overlapping character boxes. The display is generated from a list of characters sorted 
in raster order. For each character in the list, the corresponding image is read from a character lookup 
table to generate a video signal in real time [21]. By making the character definitions loadable, arbitrary 
ge- ometric shapes such as lines and polygons can be shown. For each character box, the vectors and polygons 
must first be clipped against the box and then rasterized to the pixel resol- ution of the box. If a 
similar box exists in the lookup table, then that character is referenced, otherwise a new character 
must be loaded into the lookup table. The size of the character lookup table limits the complexity of 
images that can be dis- played. The response time for displaying such images is lim- ited by the coding 
of the images into loadable character definitions rather than by the update of the display list. Note 
that as the size of the lookup table approaches the size of the corresponding frame buffer, arbitrarily 
complex images can be displayed. By allowing the character boxes to have arbitrary size, to ap- pear 
anywhere on the screen, and to overlap, geometric images can be generated more easily. Such character 
boxes are often called sprites and are commonly used in video games. These systems are typically limited 
to two to eight sprites and use logic to select the pixels from the frontmost nonempty sprite for display 
on the screen. Processor per Polygon Maximum parallelism can be extracted from the scene by as- signing 
a processor to every polygon. As the image is being rasterized, each of the P processors incrementally 
computes and reports its color and depth at that pixel. For pixels outside the polygon, the processor 
reports the maximum depth. The pixel with the minimum depth will have its color displayed on the screen. 
The minimum depth can be found by using a comparator tree of size P log P[14, 38]. The number of required 
polygon processors can be reduced significantly by assigning a processor to only those polygons that 
are active on a given scanline [10]. Scanlines are com-puted by pipelining a pixel stream through the 
processors and overwriting pixel values that are deeper than the interpolated depth for the local polygon. 
This avoids the need for a separate comparator tree. Furthermore, by using a frame buffer as a frame 
store device and recirculating the pixel stream through the processors, the system can virtually rasterize 
scenes of any complexity with a fixed number of polygon processors. The response time for triangles is 
independent of the number of triangles and is NTppoly where Tppoly is the clock rate for the polygon 
processor, assuming there are enough processors to accommodate all triangles on the most complex scan 
line. If Tpp is less than or equal to the pixel clock, the display can be refreshed directly, otherwise 
the image must be stored in a frame buffer. Vectors are converted to polygons and then rendered. Frame 
Parallelism All of the rasterization techniques we have surveyed may be configured to use frame parallelism, 
that is, to rasterize with separate parallel processor/memory configurations separate subparts of the 
frame [13, 22, 28, 29]. A video signal is generated by scanning out pixel values from the subframes in 
an appropriate order. The effectiveness of this approach is reduced because objects may not be distributed 
uniformly over the screen and some overhead will be incurred by objects that cross subframe boundaries 
and must be examined by more than one subframe. However, frame parallelism overcomes a key problem with 
heavy use of primitive parallelism, namely that the number of pixels accessed in one memory cycle may 
vastly exceed the number of pixels in a single primitive, thus wasting memory bandwith and rasterization 
processor power. At the extreme, full-frame access of a million pixels is largely wasted to rasterize 
a 100-pixel triangle. The Pixel-planes 5 architecture [13] is an example of a square virtual buffer that 
uses frame parallelism. Pixels in the virtual buffer are accessed using the processor per pixel technique, 
using logic-enhanced memory chips similar to those in the earlier Pixel-Planes systems. The buffer is 
128x128 pixels in size, and because most polygons will fit within a given 128x128 region of the screen, 
the virtual buffer can provide a performance similar to the earlier processor per pixel frame buffer 
systems. The full systems contains a number of such virtual buffers, operating on separate streams of 
polygon input data. The screen is divided into a number of 128x128 regions, and the virtual buffers are 
dynamically allocated to these re- gions in such a way that the virtual buffers process equal numbers 
of polygons, and loading is balanced. Performance Characterization Our taxonomy has shown ten different 
techniques that will rasterize a given set of primitives to yield identical images. From the user's point 
of view, the key parameter that differ- entiates the techniques is response time. Although other sys- 
tem parameters such as cost, size, power, available technology, and design effort cannot be ignored, 
we believe response time serves well as a common metric for making first-order com- parisons among different 
techniques. There are many imple- mentation factors that influence the response time of any system, but 
our main interest is to know the theoretical per- formance limit thai a given technique can achieve under 
com- parable operating conditions. Figure 8 presents expressions for response times for each of the ten 
different techniques. The expressions are given in terms of a small set of parameters that characterize 
the image being rasterized. They allow us to understand how the per-   :c-,~~ SIGGRAPH '89, Boston, 
31 July-4 August, 1989 Tesselated Triangles Non- Tesselated Triangles Vectors Characters Frame Buffer 
Techniques Single Pixel NDTpm PA Tpm VL Tcyc NTpm Linear Array (I4I) ND Tcyc Slint PA Tcyc Slint VL Tcyc 
Slin v NTcyc Slint Square Array (M x M) ND Tcyc Ssqt PA Tcyc Ssqt VL Tcyc Ssqv NTcyc Ssqt SLAM v@D P 
Tcyc P~ Tcyc VL Tcyc Slinv _ Pixel-Planes 300PTpp 300PTpp 300 VTpp - Scan Line Virtual Buffer Techniques 
Single Pixel NDTvb PA Tvb VL Tvb NTvb Linear Array (W) NDTvb S lint PA Tvb S lint VL Tvb S lin v NTvb 
S lint Super Buffer Nv@~ Tsb Pv/ A Tsb VLTsb Slinv _ Object-Oriented Techniques Character Display C Tcyc 
Processor/Polygon NTppoly NTppoly VTppoly Notations Tcyc = Frame buffer cycle time Tpm = Frame buffer 
page mode cycle time Tpp = Pixel-Planes clock speed Tvb = Virtual buffer cycle time Tsb = Super buffer 
clock speed Tppoly = Processor~polygon clock speed Slint = Speedup for Triangles with Linear Access Slinv 
= Speedup for Vectors with Linear Access Ssqt = Speedup for Triangles with Square Access Ssqv = Speedup 
for Vectors with Square Access N = Number ofpixel on screen D = Average depth complexity of 3D images 
P = Number of 3D triangles A = Average pixel area of triangles V = Number of vectors in image L = Average 
pixel length of vectors C = Number of characters in image W = Word Size for Linear Access M = Word Size 
for Square Access Figure 8. Response time for the ten rasterization techniques. formance of the techniques 
changes when the parameters are Three-Dimensional Triangles changed. They help determine how the response 
wiLl change We list two expressions for response times for triangle primi- when the number of primitives 
increases, the average size of tives: the tesselated case, in which P and A may change but triangles 
changes, the technology parameters such as memory D remains constant, so N x D pixels are updated; and 
the cycle times decrease, or the screen resolution increases. The non-tesselated case, in which A remains 
constant but P and D reader is cautioned that these expressions are approximate, may change, so P x A 
pixels are updated. In both cases,and ignore a great many important factors in actual imple- P x A = 
N x D. For single-pixel access, the response time is mentations. Our characterization is intended to 
illustrate gross the number of pixels updated, multiplied by the cycle time for performance effects, 
and does not precisely evaluate any of the each pixel. The response time for the linear and square frame 
techniques. buffer organizations is similar to the single pixel case except @ ~ Computer Graphics, Volume 
23, Number 3, July 1989 Single Linear Linear Square Square Word Pixel Word Pixel aligned aligned aligned 
aligned FB Access lxl 16xl 16xl 4x4 4x4 FRAME BUFFER Tcyc 250 nsec 250 nsec 250 nsec 250 nsec 250 nsec 
Polygons/sec Large (32x32) 4K 43K 62K 52K 62K Small (8x8) 62 K 390K 500K 562 K 1, O00K Vectors~see Uniform 
(32) 125K 245K 290K 350K 500K 25/25/50 (32) 125K 490K 662K 405K 500K VIRTUAL BUFFER Tvb 1 O0 nsec 1 O0 
nsec 1 O0 nsec 1 O0 nsec 1 O0 nsec Polygons/ sec Large (32x32) IOK 1 IOK 155K 130K 155K Small (8x8) 155K 
975K 1,250K 1,405K 2,500K Veetors /sec Uniform (32) 312K 612K 720K 875K 1,250K 25/25/50 (32) 312K 1,225K 
1,665K 1,012K 1,250K Figure 9. Peak Performance for Single, Linear, and Square Memory Organizations. 
 that a speedup factor of Slint or Ssqt is applied. SLAM per- formance is the same as that of the linear 
array, with Slint = Averagewidth = v/A-. Pixel-Planes broadcasts about 300 bits to render each triangle 
and hence has a response time of 300PTpp independent of the size of the triangles. The re- sponse time 
for virtual buffer single, linear, and Super Buffer organizations is given by substituting the virtual 
buffer access time for the corresponding frame buffer cases. The processor per polygon has a fixed response 
time of NTppoly, which is independent of the area and number of polygons in the scene. If Tppoly is less 
than or equal to the pixel clock then the display can be refreshed directly in real time, otherwise the 
image needs to be buffered in a frame store. Vectors The analysis for vectors is similar to that for 
non-tesselated triangles, but the number of pixels updated is the product of V, the number of vectors 
displayed, and L, the vector length. Since the vector response time is linearly proportional to vec- 
tor length, as opposed to quadratic sensitivity of polygon re- sponse to polygon height or width, we 
have chosen to characterize non-tesselated vectors only. However, the vector response time is strongly 
sensitive to the angular distribution of vectors, which is reflected in the speedup factors Slin for 
the techniques that can update more than one pixel along a scanline and Ssq for the techniques that update 
rectangular arrays of pixels. Characters We assume that characters tesselate the entire screen and thus 
require that all N pixels be updated for a new page of text. The difference between the architectures 
is primarily the different memory update speeds and the speedup factors Slint and Ssqt, which depend 
on the size of the memory word and the size of the characters. Observations Given so many techniques 
to choose from, now does one de- cide which one to use? The exact decision for a system de- signer is 
invariably based on the intended application, and the cost and performance requirements. This characterization 
of the various possible techniques can be used only as a guideline for system design. Three key observations 
emerge from this characterization: Updating pixels in parallel is an effective means of in- creasing 
the performance of rasterization. However, parallelism beyond the average size of the primitives is inefficient. 
For all the techniques and primitives, the response time is always directly proportional to the memory 
cycle time. The faster response time of virtual buffer tech- niques is due purely to the fact that they 
use smaller and faster memory parts than their frame-buffer counterparts, which results in a performance 
gain of 2-10 times. s GGRAPH '89, Boston, 31 July-4 August, 1989 Lastly, an increase in screen resolution, 
i.e. from N1 = 512  512 to N2 = 1024  1024 will slow down the vector response time by a factor of v/N2/Ni 
= 2, whereas the triangle response time drops by a factor of Nz/N~ = 4. SLAM and Super Buffer are exceptions 
because their performance is not sensitive to triangle width, so their performance degrades by a factor 
of v/ Nz/ N, = 2.  Case Study To understand the performance limits of different techniques, we have 
tabulated the performance for single, linear, and square access frame buffers in Figure 9. For the parallel 
access cases, we have chosen to access 16 pixels in parallel as a 16  1 linear array or as a4 x 4 square. 
Using the polygon and vector speedup factors from Figures 4 and 5, and the performance equations in Figure 
8, we can predict the maxi- mum theoretical performance for each of these cases. Observe that switching 
from single pixel access to parallel pixel access increases the performance by a factor of 2 to 16. However, 
within the different parallel techniques, the performance does not vary by more than a factor of 2.5. 
The performance numbers are directly influenced by memory cycle times. Virtual buffer techniques may 
use fast memory cycle times in the 25-100 nsec range, which will directly in- crease the performance 
by factors of 2.5-10 over their corre- sponding frame buffer counterparts. It is interesting to compare 
the predicted peak performance with the actual performance of some commercial graphics systems. The Silicon 
Graphics 4D GT Graphics Workstation is rated at 400K short vectors/see and 100K-120K 100-pixel polygons/see 
[1]. It has a screen resolution of 1280x1024, using 5 x 4 word-aligned square frame buffer organization, 
Tcyc = 250nsec for vectors, and Trmw = 500nsec for polygons. The table predicts a peak vector performance 
of 350K-405K vectors/see. After correcting for the longer memory cycle, the table predicts a peak polygon 
performance of 26K large polygons/sec and 280K small polygons/sec which translates to about 180K 100-pixel 
polygons/sec. A closer look at the machine architecture reveals that it is not strictly a 5 x 4 square 
organization, but more like 5 inde- pendent sets of 1  4 image processors. If we assume that each column 
receives one span out of every five then the ar- chitecture behaves more like a single 1 x 20 linear 
array, and the table predicts a peak performance of 195K small polygons/see, or about 125K 100-pixel 
polygons/see. Another interesting case is the HP 320 SRX, which is rated at 300K vectors/see and 16K 
large polygons/sec [17, 34] It has a screen resolution of 1280 x 1024, 4 x 4 word-aligned square organization 
for vectors (Tcyc---360nsec), that is switched to a 1  I single-pixel access into a linear virtual buffer 
(pixel cache) for polygons (Tvb = 60nsec). Correcting for the cycle times, the table predicts 240K-300K 
vectors/see and a peak polygon performance of 260K small and 17K large polygons/see. The Future of Rasterization 
Users of graphics systems will continue to require higher levels of performance and function in the future. 
Semiconductor technologies will continue to make this feasible. New and better rasterization techniques 
will be required to provide for the needs of future systems. The characterization of the cur- rent techniques 
provide a framework to develop future tech- niques. To achieve higher rendering performance, it is necessary 
to overcome the frame buffer bandwidth bottleneck. Semicon-ductor technology will soon enable us to design 
video memory chips with 4 megabit densities and logic chips with over one million transistors. At such 
high circuit densities, interchip communication bandwidth becomes the primary bottleneck, forcing designers 
to integrate the rasterization processor and frame buffer memory onto the same chip. One may choose to 
enhance the video memory with rasterization logic, which is the message carried by SLAM and Pixel Planes, 
or enhance the rasterization processor with fast local memory, which is the message of virtual buffer 
techniques. Higher circuit densities, combined with integrating the rasterization processor and frame 
buffer memory will lead to lower size and cost. A 512  512 frame buffer with 8 bits/pixel will occupy 
only half of a 4 megabit VRAM chip. The other half could be used to implement the rasterization processor. 
The result will be a high performance single chip rasterization system. Still greater performance can 
be achieved by operating several such chips in parallel, partitioning the frame buffer into several planes 
or spatially into rectangles or bands. Rendering algorithms will continue to use larger numbers of bits 
per pixel to provide higher levels of functionality. Graphics systems have already made a transition 
from 1 bit/pixel to 8 and 24 bits/pixel to provide color and smooth shading. Double buffering doubles 
the number of bits per pixel to obtain smooth animation. Z -buffers require an addi- tional 16-32 bits 
per pixel, resulting in a total of up to 100 bits/pixel. The trend of using larger number of bits per 
pixel to provide higher functionality will continue and force graphics systems to provide multiple sets 
of buffers totalling to 100 -1000 bits per pixel. The extra memory could be used to pro- vide realtime 
video capture, anti-aliasing, transparency, tex- ture mapping, image composlting, direct CSG rendering, 
and shadows. On the other hand, providing such a large number of bits per pixel with physical memory 
may become prohib- itively expensive. Virtual buffer techniques have demon-strated that a fast small 
physical memory can be reused to execute algorithms requiring a large number of bits per pixel. Our characterization 
suggests that designers are going to face stiff problems getting another factor of 4-10 in rasterization 
performance. Bulk memory speeds will not grow by this factor. Improving the speed of rasterization techniques 
surveyed here requires integrating on one chip logic and small fast memories, a capability not well supported 
by today's ASIC design and fabrication techniques. Nevertheless, we should expect to see more designs 
using "pixel caches" or virtual buffers for the same reason caches are used on all high performance comput- 
ers: small memories have fast response. Another general approach to achieving high performance is to 
divide the screen spatially into multiple non-overlapping sub- frame buffers or multiple overlapping 
frame buffers and rasterize the primitives into each buffer independently in par- allel. While the cost 
of these approaches rises at least linearly with performance, the engineering is straightforward. We 
can see these structures emerging as an important part of high performance systems [13]. It is very likely 
that the rasterization systems of the future will not be based on any one single technique, but will 
use a crea- tive combination of the best features of known techniques to obtain even higher levels of 
performance.  Acknowledgements We would like to thank John Eyles and Henry Fuchs for con- tributing 
to the section on Pixel Planes.  Bibliography 1. K. Akeley and T. Jermoluk. High Performance Polygon 
Rendering. Proceedings of SIGGRAPH, 22(4):239-246, August 1988. 2. B. Apgar, B. Bersack, and A. Mammen. 
A Display System for the Stellar Graphics Supercomputer Model GS 1000. Proceedings of SIGGRA PH, 22(4):255-268, 
August 1988. 3. Mike Asai, Graham Short, Tom Preston, Richard Simpson, Derek Roskell, and Karl Guttag. 
The TI34010 Graphics System Processor. Computer Graphics and Applications, 6(10):24-39, October 1986. 
 4. A. Bechtolsheim and F. Baskett. High-Performance Raster Graphics for Microcomputer Systems. Com-puter 
Graphics, 14(3):43-47, July 1980. 5. J.E. Bresenham. Algorithm for computer control of a digital plotter. 
IBM Systems Journal, 4(l):25-30, July 1965.  , J.E. Bresenham. Raster Line Run Length Slice Al- gorithm, 
IBM System Communication Division, TR 29.0180, Research Triangle Park, North Carolina. January 1978. 
7. J.E. Bresenham. Incremental Line Compaction. The Computer Journal, 25(1):116-120, 1982. 8. J.H. Clark. 
The Geometry Engine: A VLS1 Geom- etry System for Graphics. Computer Graphics, 16(3):127-133, July 1982. 
 9. J.H. Clark and M.R. Hannah. Distributed Processing in a High-Performance Smart Image Memory. LAMBDA 
(Now VLSI Design), (4th. Quarter):40-45, 1980.  10. M. Deering, S. Winner, B. Schediwy, C. Duffy, and 
N. Hunt. The Triangle Processor and Normal Vector Shader: A VLS! System for High Performance Graphics. 
Proceedings of S1GGRAPH, 22(4):21-30, August 1988. II. S. Demetrescu. High Speed Image Rasterization 
Using Scan Line Access Memories. Proc. 1985 Chapel Hill Conference on VLSI, pages 221-243, Computer Science 
Press, 1985. 12. H. Fuchs and J. Poulton. Pixel Planes: A VLSI-Oriented Design for a Raster Graphics 
Engine. VLSI Design, 2(3):20-28, 3rd. Quarter 1981. 13. H. Fuchs, J. Poulton, J. Eyles, T. Greer, J. 
Goldfeather, D. Ellsworth, S. Molnar, G. Turk, B. Tebbs, and L. Israel. A Heterogeneous Multi-processor 
Graphics System Using Processor-Enhanced Memories. Proceedings of SIGGRAPH, 1989. 14. D. Fussell and 
B.D. Rathi. A VLSI-Oriented Archi- tecture for Real-Time Raster Display of Shaded Polygons. Proc. of 
Graphics Interface, pages 373-380, 1982. 15. N. Gharachorloo, S. Gupta, E. Hokenek, P. Balasubramanian, 
B. Bogholtz, C. Mathieu, and C. Zoulas. Subnanosecond Pixel Rendering with Million Transistor Chips. 
Proceedings of SIGGRAPH, 22(4):41-49, August 1988. 16. N. Gharachorloo and C. Pottle. SUPER BUFFER: 
A Systolic VLSI Graphics Engine for Real Time Raster Image Generation. Proc. 1985 Chapel Hill Conference 
on VLSI, pages 285-305, Computer Sci- ence Press, 1985. 17. A. Goris, B. Fredrickson, and H. Baeverstad. 
A Configurable Pixel Cache for Fast Image Gener-ation. IEEE CG&#38;A, pages 24-32, 1987. 18. S. Gupta. 
Architectures and Algorithms for Parallel Updates of Raster Scan Displays, Computer Science Department, 
Carnegie-Mellon University, CMU-CS-82-111, Pittsburgh, PA. December 1981. 19. S. Gupta, R.F. Sproull, 
and I.E. Sutherland. A VLSI Architecture for Updating Raster Scan Display. Computer Graphics, 15(3):71-78, 
July 1981. 20. J.H. Jackson. Dynamic Scan-converted Images with a Frame Buffer Display Device. Proceedings 
of S1GGRAPH, page 163, 1980. 21. B.W. Jordan, Jr. and R.C. Barrett. A Cell Organized Raster Display 
for Line Drawings. Comm. of the ACM, 17(2):676, Febraury 1974.  '89, Boston, 31 July-4 August, 1989 
22. M. Kaplan and D. Greenberg. Parallel Processing techniques for Hidden Surface Removal. Proceedings 
of SIGGRAPH, page 300, August 1979. 23. L. Kohn and S.W. Fu. A 1,000,000 Transistor Microprocessor. 
ISSCC, pages 54-55, February 1989, 24. R. Matick, D.T. Ling, S. Gupta, and F.H. Dill. All Points Addressable 
Raster Display Memory. IBM Journal of Res. and Dev., 28(4):379-382, July 1984. 25. W.M, Newmann and 
R.F. Sproull. Principles of Interactive Computer Graphics. McGraw Hill, 1973. 26. H. Niimi, Y. Imai, 
M. Murakami, S. Tomita, and H. Hagiwara. A Parallel Processor System for Three Dimensional Color Graphics. 
Proceedings of SIGGRAPH, page 67, July 1984. 27. I. Page. Disarray: A 16 x 16 RasterOp processor. Eurographics 
83, pages 367-377, Amsterdam: North Holland, 1983. 28. F.I. Parke. Simulation and Expected Performance 
Analysis of Multiple Processor Z-Buffer Systems. Siggraph, pages 48-56, 1980.  29. R. Schumacker. A 
New Visual System Architecture. Proc. of Second lnterservice / lndustry Training Equipment Conf., page 
1, November 1982. 30. R.F. Sproull. Using Program Transformations to Derive Line-Drawing Algorithms. 
A CM Trans-actions on Graphics, 1(4):259-273, 1982. 31. R.F. Sproull. Frame Buffer Display Architectures. 
Annual Review of Computer Science, 1 : 19-46, Annual Reviews Inc., 1986.  32. R.F. Sproull, I.E. Sutherland, 
A. Thompson, and S. Gupta. The 8 by 8 Display. ACM Transactions on Graphics, 2(1 ):32-56, January 1983. 
 33. I.E. Sutherland, R.F. Sproull, and R.A. Schumacker. A Characterization of Ten Hidden-Surface Algo-rithms. 
Computing Surveys, 6(1): 1, March 1974. 34. R.W. Swanson and L.J. Thayer. A Fast Shaded-Polygon Renderer. 
Proceedings of SIGGRAPH, pages 95-102, 1986. 35. C.P. Thacker, E.M. McCreight, B.W. Lampson, R.F. Sproull, 
and D.R. Boggs. Alto: A Personal Com- puter". Computer Structures: Readings and Examples, McGraw Hill, 
1981. 36. A.M. Walsby. Fast colour raster graphics using an array processor. Eurographics 80, pages 
303-313, Amsterdam: North Holland, 1980. 37. G.S. Watkins. A Real Time Visible Surface Algo- rithm, 
University of Utah, UTEC-CSC-70-101, June 1970. 38. R. Weinberg. Parallel Processing Image Synthesis 
and Anti-Aliasing. Proceedings of SIGGRAPH, pages 147-154, July 1982. 39. M.C. Whitton. Memory Design 
for Raster Graphics Displays. Computer Graphics and Applications, 4(3):48-65, March 1984. 40. Paul Winser. 
3D Graphics for Consumer Applica- tions-How Realistic Does it Have to Be?. Eurographics, 1988.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74371</article_id>
		<sort_key>369</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Separable image warping with spatial lookup tables]]></title>
		<page_from>369</page_from>
		<page_to>378</page_to>
		<doi_number>10.1145/74333.74371</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74371</url>
		<abstract>
			<par><![CDATA[Image warping refers to the 2-D resampling of a source image onto a target image. In the general case, this requires costly 2-D filtering operations. Simplifications are possible when the warp can be expressed as a cascade of orthogonal 1-D transformations. In these cases, separable transformations have been introduced to realize large performance gains. The central ideas in this area were formulated in the 2-pass algorithm by Catmull and Smith. Although that method applies over an important class of transformations, there are intrinsic problems which limit its usefulness.The goal of this work is to extend the 2-pass approach to handle arbitrary spatial mapping functions. We address the difficulties intrinsic to 2-pass scanline algorithms: bottlenecking, foldovers, and the lack of closed-form inverse solutions. These problems are shown to be resolved in a general, efficient, separable technique, with graceful degradation for transformations of increasing complexity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Geometric correction</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15020853</person_id>
				<author_profile_id><![CDATA[81100061501]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wolberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14155023</person_id>
				<author_profile_id><![CDATA[81100441482]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Boult]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>807505</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[CatmuU, E. and A.R. Smith, "3-D Transformations of Images in Scanline Order," Computer Graphics, (SIGGRAPH '80 Proceedings), vol. 14, no. 3, pp. 279-285, July 1980.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cook,' R.L., "Stochastic Sampling in Computer Graphics," ACM Trans. on Graphics, vol. 5, no. 1, pp. 51-72, January 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dippe, M.A.Z and E.H. Wold, "Antialiasing Through Stochastic Sampling," Computer Graphics, (SIGGRAPH '85 Proceedings), vol. 19, no. 3, pp. 69-78, July 1985.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13056</ref_obj_id>
				<ref_obj_pid>13050</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fant, K.M., "A Nonaliasing, Real-Time Spatial Transform Technique," IEEE Computer Graphics and Applications, vol. 6, no. 1, pp. 71-80, January 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Heckbert, P., "Survey of Texture Mapping," IEEE Computer Graphics and Applications, vol. 6, no. 11, pp. 56-67, November 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D., "Generating Antialiased Images at Low Sampling Densities," Computer Graphics, (SIGGRAPH '87 Proceedings), vol. 21, no. 4, pp. 65-72, July 1987.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16579</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Paeth, A.W., "A Fast Algorithm for General Raster Rotation," Graphics Interface '86, pp. 77-81, May 1986.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37433</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Smith, A.R., "Planar 2-Pass Texture Mapping and Warping," Computer Graphics, (SIGGRAPH '87 Proceedings), vol. 21, no. 4, pp. 263-272, July 1987.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Tanaka, A., M. Kameyama, S. Kazama, and O. Watanabe, "A Rotation Method for Raster image Using Skew Transformation," Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 272-277, June 1986.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807506</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Weiman, C.F.R., "Continuous Anti-Aliased Rotation and Zoom of Raster Images," Computer Graphics, (SIGGRAPH '80 Proceedings), vol. 14, no. 3, pp. 286-293, July 1980.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wolberg, G., "Geometric Transformation Teehniques for Digital Images: A Survey," Columbia University Computer Science Tech. Report CUCS-390-88, December 1988. To appear as a monograph by IEEE Computer Society Press.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 23, Number 3, July 1989 SEPARABLE IMAGE WARPING WITH SPATIAL LOOKUP TABLES 
 George Wolberg Terrance E. Boult Department of Computer Science Columbia University New York, NY 10027 
[wolberg I tboult]@cs.columbia.edu ABSTRACT Image warping refers to the 2-D resampling of a source image 
onto a target image. In the general case, this requires costly 2-D filtering operations. Simplifications 
are possible when the warp can be expressed as a cascade oforthogonal 1-D transformations. In these cases, 
separable transformations have been introduced to realize large performance gains. The central ideas 
in this area were formulated in the 2-pass algorithm by Catmull and Smith. Although that method applies 
over an important class of transformations, there are intrinsic problems which limit its usefulness. 
The goal of this work is to extend the 2-pass approach to handle arbitrary spatial mapping functions. 
We address the difficulties intrinsic to 2-pass scanline algorithms: bottlenecking, foldovers, and the 
lack of closed-form inverse solutions. These problems are shown to be resolved in a general, efficient, 
separable technique, with grace- ful degradation for transformations of increasing complexity. CR Categories 
and Subject Descriptors: 1.3.3 [Computer Graph- ics]: Picture/Image Generation; 1.4.3 [Image Processing]: 
Enhance- ment -- Geometric correction, filtering. Additional keywords and Phrases: 2-pass, scanline algorithm, 
warping, bottleneck, foldover, antialiasing. 1, INTRODUCTION Image warping is a geometric transformation 
that redefines the spatial relationship between points in an image. This area has received considerable 
attention due to its practical importance in remote sensing, medical imaging, computer vision, and computer 
graphics. Typical applications include distortion compensation of imaging sensors, decalibration for 
image registration, geometrical normalization for image analysis and display, map projection, and texture 
mapping for image synthesis. Image warping has benefited dramatically from developments in separable 
geometric transformation algorithms. Also known as scan- line algorithms, these methods reduce a 2-D 
resampling problem into a sequence of 1-D scanline resampling operations. Machines based on these techniques 
produce limited real-time video effects for the television industry. The central ideas to scanline algorithms 
are presented in the semi- nal paper by Catmull and Smith [1], They describe a 2-pass tech- nique that 
decomposes the 2-D resampling problem into two orthogo- nal 1-D resampling stages. This is the basis 
for almost all of the other separable work. Nevertheless their approach suffers from problems known as 
"bottleneck" and "foldover" --difficulties which can result in visual artifacts and costly memory requirements. 
This work was supported in part by NSF grant CDR-84-21402, NSF grant IRI8800370, and DARPA grant N00039-84-C-1065. 
 Permission to copy without fee all or part of this material is granted provided that the copies are 
not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the 
publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
This paper introduces a novel scanline algorithm which properly addresses these limitations. This extends 
the benefits of separable transformations to efficiently process arbitrary spatial mappings --geometric 
transformations that, until now, required costly 2-D resam- pling operations. Section 2 of this paper 
introduces separable geometric transforma- tion algorithms with special emphasis on the Catmull-Smith 
algo- rithm. Section 3 describes the novel scanline warping algorithm. Examples are presented in section 
4. Finally, section 5 discusses con- clusions and future work. 2. BACKGROUND Separable geometric transformation 
algorithms, also known as scanline algorithms, spatially transform 2-D images by decomposing the mapping 
into a sequence of orthogonal 1-D transformations. The primary motivation for scanline algorithms is 
efficiency. Tradition-ally, geometric transformations have been formulated as either for- ward or inverse 
mappings operating entirely in 2-D. While either for- ward or inverse mappings can be used to realize 
arbitrary mapping functions, they are costly. Separable a/gorithms present an alternate technique that, 
for a small decrease in accuracy, yield significant computational savings. 2.1. DEFINITIONS A spatial 
transformation defines a geometric relationship between each point in the input and output images. The 
general mapping function can be given in two forms: either relating the output coordi- nate system to 
that of the input, or vice versa. Respectively, they can be expressed as Ix, y] = [X(u,v), y(u,v)], (1) 
or [u, v] = [.U(x,y), V(x,y)] (2) where [u,v] refers to the input image coordinates corresponding to 
output pixel [x,y], and X, Y, U and V uniquely specify the spatial transformation. Since X and Y map 
input onto output, they are referred to as the forward maps, while U and V are known as the inverse maps. 
 2.1.1. Forward Mapping The forward mapping consists of interpolating each input pixel into the output 
image at positions determined by the X and Y mapping functions. Each input pixel is passed through the 
spatial transforma- tion where it is assigned new output coordinate values. Since this is a mapping from 
pairs of integers to pairs of reais, f'dtering is required to generate the output image. The real-valued 
output positions assigned by X and Y present   :t~SIGGRAPH '89, Boston, 31 July-4 August, 1989 complications. 
For discrete images, pixels are taken to be finite ele- ments defined to lie on a (discrete) integer 
lattice. Implementing the spatial transformation as a point-to-point mapping can give rise to two types 
of problems: holes and overlaps. The shortcomings of point-to-point mappings are avoided using a four-corner 
mapping paradigm which considers input pixels as square patches assumed to be transformed into quadrilaterals 
in the output image. Because the projection of an input pixel is free to lie anywhere in the output image, 
the projections often straddle several output pixels, or lie embedded in one. An accumulator array is 
required to properly integrate all input pixel fragments that contribute to each output pixel. Partial 
contributions are handled by scaling the input intensity by the relative area of the output pixel that 
it covers. There are two main problems in the forward mapping process. First, costly intersection tests 
are needed to derive the area coverage. Second, additional filtering is necessary to ensure that a single 
input value is correctly handled when undergoing magnification. For a complete review see [5, 11]. 2.1.2. 
Inverse Mapping The inverse mapping operates in screen order, projecting each out- put coordinate into 
the input image via U and V. The value of the data sample at that point is copied onto the output pixel. 
Again, filtering is necessary to combat aliasing artifacts. The principal advantages of this method are 
that no accumulator array is necessary and output pixels which lie outside a clipping window need not 
be evaluated. This method is useful when the screen is to be written sequentially, U and V are readily 
available, and the input image can be stored entirely in memory. Inverse mappings are more commonly used 
to perform spatial transformations. By operating in seanline order at the output, square output pixels 
are back-projected onto arbitrary quadrilaterals in the input. The quadrilaterals, also known as preimages, 
may cover many input pixels. Each preimage must be sampled and convolved with a low-pass filter to compute 
an intensity at the output. In general, the input image is not accessed in scanline order. Efficient 
approaches to sampling and convolution have received much attention in the recent literature [3, 4, 5, 
6, 11 ]. 2.1.3. Separable Mapping Separable mapping decomposes the forward mapping function into a series 
of 1-D transforms. This offers several advantages. First, the resampling problem is made simpler since 
reconstruction, area sampling, and filtering can now be done entirely in 1-D. Second, efficient data 
access and substantial savings in I/O time can be real- ized because the input image can be read in row/column 
order and the output image produced in seanline order. Third, the approach ~is amenable to stream-processing 
techniques such as pipelining, and facilitates the design of hardware to operate at real-time video rates. 
It is important to elaborate on our use of the term separable. In signal processing literature, a filter 
T is said to be separable if T(u,v)=F(u)G(v). We extend this definition by defining T to be separable 
if T(u,v)=F(u). G(v). This simply replaces multiplica- tion with the composition operator in combining 
both 1-D functions. The definition we offer for separablity in this paper is consistent with standard 
implementation practices. For instance,, the 2-D Fourier Transform, separable in the classic sense, is 
generally implemented by a 2-pass algorithm. The first pass applies a 1-D Fourier Transform to each row, 
and the second applies a 1-D Fourier Transform along each column of the intermediate result Multi-pass 
seanline algorithms that operate in this sequential row-column manner are referred to as separable in 
this paper. The underlying theme is that processing is decomposed into a series of 1- D stages that each 
operate along orthogonal axes. For example, image rotation has been shown to be decomposable into a 2-pass 
scale/shear succession [1], a 4-pass scale/shear sequence [10], and a 3-pass shear transformation [7, 
9]. 2.2. CATMULL-SMITH ALGORITHM The most general presentation of the 2-pass technique appears in the 
seminal work described by CatmuU and Smith in [1]. That paper tackles the problem of mapping a 2-D image 
onto a 3-D surface and then projecting the result onto the 2-D screen for viewing. They show that in 
some cases a 2-D resampling problem can be replaced with two orthogonal 1-D resarnpling stages. 2.2.1. 
First Pass In the first pass, each horizontal seanline (row) is resampled according to spatial transformation 
F(u), generating an intermediate image I in scanline order. All pixels in i have the same x-coordinates 
that they will assume in the final output; only their y-coordinates now remain to be computed. Since 
each seanline will generally have a dif- ferent transformation, function F(u) will usually differ from 
row to row. Consequently, F can be considered to be a function of both u and v. Obviously, F(u,v) is 
identical to X(u,v). We rewrite F(u,v) as Fv(u) to denote that F is applied to horizontal scanlines, 
each hav- ing constant v. Therefore, the first pass is expressed as [x, v] = [Fv(u), v] = [X(u,v),v ]. 
(3) This relation maps each [u,v] point onto I, an intermediate image in the [x,v ] plane. 2.2.2. Second 
Pass In the second pass, each vertical scardine (column) in I is resam- pied according to spatial transformation 
G (v), generating the final image in seanline order. The second pass is more complicated than the first 
pass since the expression for G assumes we can get [u,v] from Ix, v] so that we can access Y(u,v). This 
requires us to solve the equation X(u,v) -i = 0 for u to obtain u = Hi(v) for vertical scanline (column) 
.r. Function H, known as the auxiliary function, represents the u-coordinates of the inverse projection 
of ~, the column we wish to resample. Thus, for every column in 1, we compute Hx(v) and use it together 
with the available v-coordinates to index into mapping function Y. The second pass is therefore expressed 
as [x, yl = [x, Gx(v)] (4) where Gx(v) refers to the evaluation of G (x,v) along vertical scan- lines 
with constant x. It is given by Gx(v) = Y(H=(v), v) (5) The relation in Eq. (4) maps all points in 1 
from the Ix, v] plane onto the [x,y ] plane, defining the final image.  2.2.3. Bottleneck Problem After 
completing the first pass, it is sometimes possible for the intermediate image to collapse into a narrow 
area. If this area is much less than that of the final image, then there is insufficiem data left to 
accurately generate the final image. This phenomenon, referred to as the bottleneck problem in [1], is 
the result of a many- to-one mapping in the first pass followed by a one-to-many mapping in the second 
pass. An example is the rotation of an image by 90  . Each row will collapse onto a point, resulting 
in an intermediate image consisting of a diagonal line. Obviously, no inverse function can resolve the 
intensifies for the second pass. In both [1] and [8], it is suggested that a solution to this problem 
lies in considering all the possible orders in which a separable algo- rithm can be implemented. Four 
variations, collectively referred to as V, are possible to generate the intermediate image: 1) Transform 
u first. ~ Computer Graphics, Volume 23, Number 3, July 1989 2) Transform v first. 3) Transpose the 
input image and transform u first 4) Transpose the input image and transform v first. In each case, the 
area of the intermediate image can be calculated. They suggest implementing the transformation with the 
variation that yields the largest intermediate area. For instance, an 87  rotation is best implemented 
by first rotating the image by 90  via image tram sposition and then applying a -3  rotation using 
the 2-pass technique. They purport that the above heuristic has not been known to fail, however no proof 
of its correctness is given. We now give three difficulties with their solution to the bottleneck problem. 
The most critical problem is that the area of the intermedi- ate image is a global measure which may 
fail to highlight compres- sion variations in local areas. Although the heuristic seems to be satisfactory 
for the transformations considered in their original paper, it is inadequate for arbitrary mappings -- 
the "mappings considered here. For example, consider warping an image into a circular region with each 
row becoming a radial line, i.e., (x, y)~(r, 0). This demonstrates a simple example in which different 
areas of the output map are best computed from different variations of V; no single transform from V 
could correctly process the entire image. The second problem is that the heuristic does not properly 
con- sider aliasing artifacts. In particular, maximizing the intermediate area may require excessive 
compression in the second pass. For example, in Fig. 8 of [8] variations (1) and (2) were used to map 
a regular grid onto a sphere. Although variation (2) maximized the area of the intermediate image, it 
actually caused more severe aliasing. This non-intuitive result is due to error properties of cascading 
I-D filters to approximate a 2-D filter (see section 3.5.) The third difficulty arises when the closed-form 
approximation to the intermediate area does not exist. While this does not prove trou- blesome in simpler 
domains, the evaluation of the intermediate areas for complex spatial mappings requires as much or more 
work as com- puting the first passes for each variation in V. 2.2.4. Foldover Problem The 2-pass algorithm 
is particularly well-suited for mapping images onto surfaces with closed-form solutions to auxiliary 
function H. The process is more complicated for surfaces of higher order, e.g., bilinear, biquadratic, 
and bicubic patches, which may be self-occluding. This makes F or G become multi-valued at points where 
the image folds upon itself, a problem known asfoldover. Foldover can occur in either of the two passes. 
A partial solution for single folds in G is to compute output pixels in back-to-front order, overwriting 
the hidden layers. Generating the image in this manner becomes more complicated for surfaces with more 
than one fold. In the general case, this becomes a hidden surface problem. The only reasonable solution 
has been to severely limit the amount of foldover, (e.g., up to three folds for cubic surfaces) and to 
use additional framebuffers to store the folded layers. This solution is inefficient inasmuch as an entire 
framebuffer must be utilized even if only a small folded area is involved. 2.2.5. Computing Auxiliary 
Function H Closed-form solutions do not exist for H unless the patch has no folds. When folds occur, 
a solution u =Hx(0 ) is found for the first horizontal scanline. Since surface patches are assumed to 
be smooth, a Newton-Raphson iteration method can be used to solve for Hx(1) using the solution from Hx(0) 
as a starting value. The need to evaluate H can be avoided altogether if we make use of earlier computations. 
In particular, we have H use the u-coordinates associated with the preimage of a pixel in t_he intermediate 
image. Thus, by introducing an auxiliary framebuffer to store these u's while we are in the first pass, 
H becomes available by trivial lookup table access. 2.3. DISCUSSION The 2-pass algorithm has been shown 
to apply m a wide class of transformations of general interest. These mappings include the per- spective 
projection of rectangles, bivariate patches, and superqua- drics. Smith has discussed them in detail 
in [8]. In that paper, he emphasizes the mathematical consequence of decomposing mapping functions X 
and Y into a sequence of F followed by G. Smith distin- guishes X and Y as the parallel warp, and F and 
G as the serial warp, where warp refers to resampling. Serial warps offer dramatic compu- tational reductions 
with only minor degradation. Nevertheless, they are plagued by several complications: the bottleneck 
problem, fold- overs, and computing auxiliary function H. 3, DESCRIPTION OF ALGORITHM In this section 
we describe an algorithm that addresses the diffi- culties that are particular to 2-pass methods. The 
result is a separable approach that is general, accurate, and efficient, with graceful degra- dation 
for transformations of arbitrary complexity. 3.1. OVERVIEW The goal of this work is to realize an arbitrary 
warp with a separ- able algorithm. The proposed technique is an extension of the Cat.mull-Smith approach 
where attention has been directed toward solutions to the bottleneck and foldover problems, as well as 
remov- ing the need for closed-form inverses. Conceptually, the algorithm consists of four stages: intensity 
resarnpling, coordinate resampling, distortion measurement, and compositing. Figure 3.1 shows the interaction 
of the stages. Note that bold arrows represent the flow of images through a stage, and thin arrows denote 
those images which act upon the input. The subscripts x and y are appended to images which have been 
resampled in the horizontal and vertical directions, respectively. 1 XLUT 3"LUT Figure 3.1: Block diagram 
of the algorithm. The intensity resampler applies a 2-pass algorithm to the input image. Since the result 
may suffer bottleneck problems, the identical process is repeated with the transpose of the image. This 
accounts for the vertical symmetry of Fig. 3.1. Pixels which suffer excessive botttlenecking in the natural 
processing can be recovered in the tran- sposed processing. In our implementation, we realize transposition 
as a 90  clockwise rotation so as to avoid the need to reorder pixeIs left to right. :L~SIGGRAPH '89, 
Boston, 31 July-4 August, 1989 The coordinate resampler computes spatial information necessary for the 
intensity resampler. It warps the spatial lookup table Y(u,v) so that the second pass of the intensity 
resampler can access it without the need for an inverse functiorL Local measures of shearing, perspective 
distortion, and bottlenecking are computed to indicate the amount of information lost at each point. 
This information, together with the transposed and non-transposed results of the intensity resampler, 
are passed to the compositor. The final output image is generated by the compositor which samples those 
pixels from the two resampled images such that information loss is minimized in the final output.  
3.2. SPATIAL LOOKUP TABLES Scanline algorithms generally express the coordinate transforma- tion in terms 
of forward mapping fimctions X and Y. Sampling X and Y over all input points yields two new real-valued 
images, XLUT and YLUT, specifying the point-to-point mapping from each pixel in the input image onto 
the output images. This paper refers to XLUT and YLUT as spatial lookup tables since they can be viewed 
as 2-D tables which express a spatial transformation. In addition to XLUT and YLUT we also provide a 
mechanism for the user to specify ZLUT which associates a z-coordinate value with each pixel. This allows 
warping of planar textures onto non-planar surfaces, and is useful in dealing with foldovers. Our goal, 
however, is not to solve the general 3-D viewing problem. The z-coordinates are assumed to be from a 
particular point of view which the user determines before supplying ZLUT to the system. The motivation 
for introducing spatial lookup tables is generality. Our goal is to find a serial warp equivalent to 
any given parallel warp. Thus, we find it impossible to retain the mathematical elegance of closed-form 
expressions for the mapping functions F, G, and the aux- iliary function, H. Therefore, assuming the 
forward mapping func- tions, X and Y, have closed-form expressions seems overly restrictive. Instead, 
we assume that the parallel warp is defined by the samples that comprise our spatial lookup tables. This 
provides a general means of specifying arbitrary mapping functions. For each pixel (u,v) in input image 
I, spatial lookup tables XLUT, YLUT, and ZLUT are indexed at location (u,v) to determine the corresponding 
(x,y,z) position of the input point after warping. This new position is orthographically projected onto 
the output image. Therefore, (x,y) is taken to be the position in the output image. (Of course, a perspective 
projection may be included as part of the warp). The z-coordinate will only be used to resolve foldovers. 
This straightforward indexing applies only if the dimensions of 1, XLUT, YLUT, and ZLUT are all identical. 
If this is not the case, then the smaller images are upsampled (magnified) to match the largest dimensions. 
 3.3. INTENSITY RESAMPLING This section discusses how spatial lookup tables are used to resample intensity 
images. The 1-D intensity resarnpling algorithm is well-suited for hardware implementation and compatible 
with spatial lookup tables. It is the basis of the 2-pass intensity resampling stage depicted in the 
first row of Fig. 3.1. 3.3.1. 1-D Intensity Resampler The central benefit of separable algorithms is 
the reduction in complexity allowed by 1-D resampling algorithms which provide efficient solutions for 
the image reconstruction and antialiasing com- ponents of resampling. Fant presents a detailed description 
of such a 1-D algorithm that is well-suited to hardware implementation and compatible with spatial lookup 
tables [4]. It is the principal 1-D resampling method used in separable transformations, including that 
of the work presented here, The process treats the input and output as streams of pixels that are consumed 
and generated at rates determined by the spatial map- ping. The input is assumed to be mapped onto the 
output along a sin- gle direction, i.e., with no folds. As each input pixel arrives, it is weighted by 
its partial contribution to the current output pixel and integrated into a single element accumulator. 
For input pixels that spread out over many output pixels, image reconstruction is currently implemented 
with linear interpolation. 3.3.2. Example Consider the 1-D arrays shown in Fig. 3.2. The first row is 
taken from XLUT, the second from YLUT, and the third from input intensity image L The next two arrays 
show YLUT and I resampled according to XLUT. I ,o, I ,,5112o z lool106 90] 92 ,Lo . 10o I lOl I lO, 113] 
4o 1 lOl1 I Figure 3.2: Resampling example. The computation of the resampled intensity values is given 
below. Ix[0] = 100 (.4) = 40 lx[1] = [100 (1-.4 + 1.7)+ 106 (.4 + 1.7)] (1) = 101 lx[2] = [100 (1-1.4 
+ 1.7) + 106 (1.4 + 1.7)] (.3) + 106 (.7) = 106 I x [3] = [106 (1-.7 + .9) + 92 (.7 + .9)] (.2) + 92 
(.1) + 90 (. 6) = 82 The algorithm demonstrates both image reconstruction and antialiasing. When we are 
not positioned at pixel boundaries in the input stream, linear interpolation is used to reconstruct the 
discrete input. If more than one input element contributes to an output pixel, the weighted results are 
integrated into an accumulator to achieve antialiasing. The intersection tests needed for weighting are, 
of course, one-dimensional. 3.3.3. 2-Pass Intensity Resampling The I~D intensity resampler is applied 
to the image in two passes, each along orthogonal directions. The first pass resamples horizontal scanlines, 
warping pixels along a row in the intermediate image. Its purpose is to deposit them into the proper 
columns for vertical resam- pling. At that point, the second pass is applied to all columns in the intermediate 
image, generating the output image. In Fig. 3.1, input image I is shown warped according to XLUT to 
generate intermediate image Ix. In order to apply the second pass, YLUT is warped alongside 1, yielding 
YLUTx. This resampled spatial lookup table is applied to Ix in the second pass as a collection of 1-D 
vertical warps. The result is output image I n. The intensity resampling stage must handle multiple output 
values to be defined in case of foldovers. This is an important implementa- tion detail which has impact 
on the memory requirements of the algo- rithm. We defer discussion of this aspect of the intensity resampler 
until section 3.6, where foldovers are discussed in more detail. @ ~ Computer Graphics, Volume 23, Number 
3, July 1989 3.4. COORDINATE RESAMPLING YLUT~ is computed in the coordinate resampling stage depicted 
in the second row of the block diagram in Fig. 3.1. The ability to resam- pie YLUT for use in the second 
pass has important consequences: it circumvents the need for a closed-form inverse of the first pass. 
As briefly pointed out in [1], that inverse provides exactly the same information that was available 
as the first pass was computed, i.e., the u-coordinate associated with a pixel in the intermediate image. 
Thus, instead of computing the inverse to index into YLUT, we simply warp YLUT into YLUT x allowing direct 
access in the second pass. 3.4.1. Coordinate Resampler The coordinate resampler is similar to the intensity 
resampler. It differs only in the notable absence of antialiasing filtering --the out-put coordinate 
values in YLUT x are computed by point sampling YLUT. Interpolation is used to compute values when no 
input data is supplied at the resampling locations. However, unlike the intensity resampler, the coordinate 
resampler does not weigh the result with its area coverage nor does the resampler average it with the 
coordinate values of other contributions to that pixel. This serves to secure the accuracy of edge coordinates, 
even when the edge occupies only a partial output pixel. 3.4.2. Example The following example is offered 
to demonstrate the coordinate resampling algorithm. Consider the arrays shown before in Fig. 3.2. YLUTx 
in the example is the output of the coordinate resampling as computed below. Notice that the output consists 
of point samples taken at pixel boundaries in the output stream. They are not influ- enced by any other 
entries deposited into their respective output pix- els. The computations are given below. YLUT~[0] = 
100(1--0+1.7)+106(0+1.7)= 100 YLUTx[1 ] = 100(1-.4 + 1.7)+106 (.4 + 1.7) = 101 YLUTx[2] = 100(1-1.4+ 
1.7)+106(1.4 1.7) = 105 YLUTx[3] = 106(1-.7 + .9) + 115 (.7 *.9) = 113 As mentioned before, the user 
can clefme ZLUT which associates a z-coordinate with each pixel. While it does not appear in the system 
block diagram of Fig. 3.1, we also apply this resampling to ZLUT in exactly the same manner as it was 
applied to YLUT. 3.5. DISTORTIONS AND ERRORS In forward mapping, input pixels are taken to be squares 
that map onto arbitrary quadrilaterals in the output image. Although separable mappings greatly simplify 
resampling by treating pixels as points along seanlines, the measurement of distortion must necessarily 
revert to 2-D to consider the deviation of each input pixel as it projects onto the output. As is standard, 
we treat the mapping of a square onto a general quadrilateral as a combination of translation, scaling, 
shearing, rota- tion, and perspective transformations. Inasmuch as separable kernels exist for realizing 
translations and scale changes, these transforma- tions do not suffer degradation in scanline algorithms 
and are not con- sidered further. Shear, perspective and rotations, however, offer sig- nificant challenges 
to the 2-pass approach. In particular, excessive shear and perspective contribute to aliasing problems 
while rotations account for the bottleneck problem. We first examine the errors introduced by separable 
filtering. We then address the three sources of geometric distortion for 2-pass scan- line algorithms: 
shear, perspective, and rotation. 3.5.1. Filtering Errors One of the sources of error for scanline algorithms 
comes from the use of cascaded orthogonal 1-D filtering. Let us ignore rotation for a moment, and assume 
we process the image left-to-right and top-to- bottom. Then one can easily show that scanline algorithms 
will, in the first pass, filter a pixel based only on the horizontal coverage of its top segment. In 
the second pass, they will filter based only on the vertical coverage of the left-hand segment of the 
input pixel. As a result, a warped pixel generating a triangular section in an output pixel is always 
approximated by a rectangle (Fig. 3.3). Note this can be either an overestimate or underestimate, and 
the error depends on the direction of processing. This problem is not unique to our approach. It is shared 
by aU scanline algorithms known to us. A B A B A It CD C D C BD AB A B AB C D C D C D B B A B I. iI C 
D C C D D Figure 3.3: Examples of filtering errors. 3.5.2. Shear Figure 3.4 depicts a set of spatial 
lookup tables which demonstrate horizontal shear. For simplicity, ihe example includes no scaling or 
rotation. The figure also shows the result obtained after applying the tables to an image of constant 
intensity (100). The horizontal shear is apparent in the form of jagged edges between adjacent rows. 
0 1 2 3 0 0 0 0 2 3 4 5 1 1 1 1 4 5 6 7 2 2 2 2 XLUT YLUT Aliased Output Image Figure 3.4: Horizontal 
shear: Spatial LUTs and output image. Scanline algorithms are particularly sensitive to this form of 
dis- tortion because proper f'fltering is applied only along scanlines --filtering issues across scanlines 
are not considered. Consequently, horizontal (vertical) shear is a manifestation of aliasing along the 
vertical (horizontal) direction, i.e., between horizontal (vertical) scan- lines. The prefiltering stage 
described below must be introduced to suppress these artifacts before the regular 2-pass algorithm is 
applied. This problem is a symptom of undersampled spatial lookup tables, and the only real solution 
lies in increasing the resolution of the tables by sampling the continuous mapping functions more densely. 
If the continuous mapping functions are no longer available to us, then new values are computed from 
the sparse samples by interpolation. (In this paper, linear interpolation is assumed to be adequate.) 
"~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 We now consider the effect of increasing the spatial 
resolution of XLUT and YLUT. The resulting image in Fig. 3.5 is shown to be antialiased, and clearly 
superior to its counterpart in Fig. 3.4. The values of 37 and 87 reflect the partial coverage of the 
input slivers at the output. Note that with additional upsampling, these values con- verge to 25 and 
75, respectively. Adjacent rows are now constrained to lie within 1/2 pixel of each other. The error 
constraint can be specified by the user and the spatial resolution for the lookup tables can be determined 
automatically. This offers us a convenient mechan- ism in which to control error tolerance and address 
the space/accuracy tradeoff. For the examples herein, both horizontal and vertical shear are restricted 
to one pixel. Figure 3.5: Corrected output image. By now the reader may be wondering if the shear problems 
might be alleviated, as was suggested in [1], by considering a different order of processing. While the 
problem may be slightly ameliorated by changing processing direction, the real problem lies in undersampling 
the lookup tables. They are specifying an output configuration (with many long thin slivers) which, because 
of filtering errors, cannot be accurately realized by separable processing in any order. 3.5.3. Perspective 
Like shear, perspective distortions may also cause problems by warping a rectangle into a triangular 
patch which results in significant filtering errors. In fact, if one only considers the warp determined 
by any three comers of an input pixcl, one cannot distinguish shear from perspcctive projection. The 
latter requires knowledge of all four corners. The problem generated by perspective warping can also 
be solved by the same mechanism as for shears: resarnpling the spatial lookup tables to ensure that no 
long thin slivers are generated. How- ever, unlike shear, perspective also effects the bottleneck problem 
because, for some orders of processing, the first pass may be contrac- tive while the second pass is 
expansive. This perspective bottleneck- ing is handled by the same mechanism as for rotations, as described 
below. 3.5.4. Rotation In addition to jagginess due to shear and perspective, distortions are also introduced 
by rotation. Rotational components in the spatial transformation are the major source of bottleneck problems. 
Although all rotation angles contribute to this problem, we consider those beyond 45  to be inadequately 
resampled by a 2-pass algorithm. This threshold is chosen because 0  and 90  rotations can be per- 
formed exactly. If other exact image rotations were available, then the worst case error codd be reduced 
to half the maximum separation of the angles. Local areas whose rotational components exceed 45  are 
recovered from the transposed results, where they obviously undergo a rotation less than 45 . 3.5.5. 
Distortion Measures Consider scanning two scanlines jointly, labeling an adjacent pair of pixels in the 
first row as A, B, and the associated pair in the second row as C, and D. Let (XA ,YA), (XB,YB), (Xc,Yc), 
and (xD,YD) be their respective output coordinates as specified by the spatial lookup tables. These points 
define an output quadrilateral onto which the square input pixel is mapped. From these four points it 
is possible to determine the horizontal and vertical scale factors necessary to com- bat aliasing due 
to shear and perspective distortions, and also determine if extensive bottlenecking is present. For convenience, 
we defme Axq= Ixi-xjl; Ay0= lYl-Y#1; sij= Aylj/ Axi). Pseudo-code for the procedure is given below. 
bottleneck = 0 /* Initiatly no bottleneck */ IF( AyAB ~ AxAB ) { /" AB remains horizontal */ vfctr = 
max ( AXAc, ~XBD ) /* measure horizontal shear *I } ELSE IF( gAB --< SAC ) { /" AC remains vertical */ 
hfetr = max ( AyAB, AYco ) /* measure vertical shear */ } ELSE bottleneck = I /* Bottleneck occurs */ 
 If AB has not rotated from the horizontal by more than 45 , then its error due to bottlenecking is 
considered acceptable, and we say that it remains "horizontal." Only the vertical aliasing distortions 
due to horizontal shearing and/or perspective need to be considered in this case. The vertical scale 
factor, vfctr, for XLUT and YLUT is given by vfctr = MAX(AxAc, AXBD ), Briefly, this measures the maximum 
deviation in the horizontal direction for a unit step in the vertical direction. To ensure an alignment 
error of at most e, the image must be rescaled vertically by a factor of vfctrle. Examples of quadrila- 
terals that satisfy this case are illustrated in Fig. 3.6. B B C Figure 3.6: Warps where AB remains horizontal. 
 IfAB is rotated by more than 45 , then we say that it has become "vertical" and ttao possibilities 
exist: vertical shearing/perspective or rotation. In order to consider vertical shear/perspective, the 
magni- tude of the slope of AC is measured in relation to that of AB. If sAs -< sac, then AC is considered 
to remain vertical and the pixel is tested for vertical shear/perspective. (In order to enhance computa- 
tional efficiency and to avoid divide-by-zero errors, the test condition is actually posed in terms of 
multiplication only.) If the test condition is satisfied, the horizontal scale factor, hfctr, for the 
spatial lookup tables is expressed as hfctr = MAX(Ay,~, AycD). Briefly stated, this measures the the 
maximum deviation in the vertical direction for a unit step in the horizontal direction, Again, alignment 
error can be limited to e by rcscaling the image horizontally by a factor of hfctr/e. Examples of this 
condition are shown in Fig. 3.7. C D C C D Figure 3.7: AB has rotated while AC remains vertical. Vertical 
shear. If, however, angle BAC is also found to be rotated, (i.e., neither of the above tests are satisfied) 
then the entire quadrilateral ABCD is considered to be bottienecked because it has rotated and/or undergone 
a perspective distortion. The bottleneck flag is set to one to denote the presence of the bottleneck 
problem at this pixel and, as described below, its contributions will be taken from the transposed result. 
This case is depicted in Fig. 3.8. The code fragment listed above is applied to each input pixel. Currently, 
the maximum values of hfctrle and vfctr/e art used to scale the spatial lookup tables before they enter 
the 2-pass resampling stage. In this manner, the output of this stage is guaranteed to be free @ ~ Computer 
Graphics, Volume 23, Number 3, July 1989 B c C A Figure 3.8: Both AB and AC have rotated. Bottleneck 
problem. of aliasing due to undersampled spatial lookup tables. In the future, we will examine using 
this as a local measure to adaptively resample the tables. 3.5.6. Bottleneck Distortion The bottleneck 
problem was described earlier as a many-to-one mapping followed by a one-to-many mapping. The extent 
to which the bottleneck problem becomes manifest is intimately related to the order in which the orthogonal 
1-D transformations are applied. The four possible orders in which a 2-D separable transformation can 
be implemented are listed in section 2.2.3. Of the four alternatives, we shall only consider variations 
(1) and (3). Although variations (2) and (4) may have impact on the extent of aliasing in the output 
image (see Fig. 8 of [8]), their roles may be obviated by upsampling the spatial lookup tables before 
they enter the 2-pass resampling stage. A solution to the bottleneck problem thereby requires us to con- 
sider the effects which occur as an image is separably resampled with and without a preliminary image 
transposition stage. Unlike the Catrnull-Smith algorithm which selects only one variation for the entire 
image, we are operating in a more general domain which may require either of the two variations over 
arbitrary regions of the image. This leads us to develop a local measure of bottleneck distor- tion which 
is used to determine which variation is most suitable at each output pixel. Thus alongside each resampled 
intensity image, another image of identical dimensions is computed to maintain esti- mates of the local 
bottleneck distortion. A 2-pass method is introduced to compute bottleneck distortion estimates at each 
point. As above, the bottleneck flag is determined for each input pixel. If no bottlenecking is present, 
then the area cov- erage of that input pixcl is integrated into bottleneck image B x. If, however, the 
bottleneck flag is set to one, then that pixcl makes no contribution to B x. The bottleneck image thus 
reflects the fraction of each pixel in the intermediate image not subject to bottleneck distor- tion 
in the first pass. The computations are simple, and serve a secon- dary function in that the entries 
correspond exactly to the weights needed for antialiasing in the intensity resampling stage. Thus we 
are getting a local distortion measure at virtually no additional cost. The second pass resamples intermediate 
image Bx in the same manner as the intensity resampler, thus spreading the distortion esti- mates to 
their correct location in the final image. The result is a double-precision bottleneck-distortion image 
B~, with values inversely proportional to the bottleneck artifacts. The distortion com- putation process 
is repeated for the transpose of the image and spatial lookup tables, generating image B~. Since the 
range of values in the bottleneck image are known to lie between 0 and 1, it is possible to quantize 
the range into N intervals for storage in a lower precision image with log2N bits per pixel. This space/accuracy 
tradeoff will be assessed in future work. We point out that the measure of area is not exact. It is subject 
to exactly the same errors as intensity filtering. 3.6. FOLDOVER PROBLEM Up to this point, we have been 
discussing our warping algorithm as though both passes resulted in only a single value for each point. 
Unfortunately, this is often not the case -- a warped scanline can fold back upon itself. In [1] it was 
proposed that multiple framebuffers be used to store each level of the fold. While this solution may 
be viable for low-order warps, as considered in [1] and [8], it may prove to be too costly for arbitrary 
warps where the number of potential folds may be large. Furthermore, it is often the case that the folded 
area may represent a small fraction of the output image. Thus, using one frame buffer per fold would 
be prohibitively expensive, and we seek a solution which degrades more gracefully. If we are to allow 
an image to fold upon itself, we must have some means of determining which of the folds are to be displayed. 
The simplest mechanism, and probably the most useful, is to assume that the user will supply not only 
XLUT and YLUT, but also ZLUT to specify the output z-coordinates for each input pixel. In the first pass 
ZLUT will be processed in exactly the same way as YLUT, so the second pass of the intensity resampler 
can have access to the z-coordinates. Given ZLUT we are now faced with the problem of keeping track of 
the information from the folding. A naive solution might be to use a z-buffer in computing the intermediate 
and final image. Unfor-tunately, while z-buffering will work for the output of the second pass, it cannot 
work for the first pass because some mappings fold- over on themselves in the first passonly to have 
some of the "hid- den" part exposed by the second pass of the warp. Thus, we must find an efficient means 
of incorporating all the data, including the foldovers, in the intermediate image. 3.6.1. Representing 
Foldovers Our solution is to maintain multiple columns for each column in the intermediate image. The 
extra columns, or layers, of space are allocated to hold information from foldovers on an as-needed basis. 
The advantage of this appro~ach is that if a small area of the image undergoes folding, only a small 
amount of extra information is required. When the warp has folds, the intermediate image has a multi-layered 
structure, like that in Fig. 3.9. Foldover Pointers Foldover Layers Column x- 1 Column x Column x + 1 
Figure 3.9: Data structure for folded warps. While this representation is superior to multiple frame 
buffers, it may still be inefficient unless we allow each layer in the intermediate image to store data 
from many different folds (assuming that some of them have terminated and new ones were created). Thus, 
we reuse each foldover layer whenever possible In addition to the actual data stored in extra layers, 
we also main- tain a number of extra pieces of information (described below); such as various pointers 
to the layers, and auxiliary information about the last entry in each layer. 3.6.2. Tracking Foidovers 
It is not sufficient to simply store all the necessary information in some structure for later processing. 
Given that folds do occur, there is the problem of how to filter the intermediate image. Since filtering 
requires all the information from one foldover layer to be accessed coherently, it is necessary to track 
each layer across many rows of the ~~.~SIGGRAPH '89, Boston, 31 July-4 August, 1989 image. For efficiency, 
we desire to do this tracking using a purely local match from one row to the next. The real difficulty 
in the matching is when fold layers are created, terminated, or bifurcated. We note that any "matching" 
must be a heuristic, since without strong assumptions about the warps, there is no procedure to match 
folds from one row to another. (The approach in [1] assumes that the Newton-Raphson algorithm can follow 
the zeros of the auxiliary function H correctly, which is true only for simple auxiliary functions with 
limited bifurcations.) Our heuristic solution to the matching problem uses three types of information: 
direction of travel when processing the layer (left or right in the row), ordering of folds within a 
column, and the original u-coordinate associated with each pixel in the intermediate image. First, we 
constrain layers to match only those layers where the points are processed in the same order. For instance, 
matching between two leftward layers is allowed, but matching between left- ward and rightward layers 
is not aUowed. Secondly, we assume the layers within a single column are par- tially ordered. Within 
each column, every folded pixel in the current row is assigned a unique number based on the order in 
which it was added to the foldover lists. The partial order would allow matching pixels 12345 with 1?23?74 
(where the symbol ? indicates a match with a null element), but would not allow matching of 12345 with 
1?437?2. Finally, we use the u-coordinate associated with each pixel to define a distance measure between 
points which satisfies the above constraints. The match is done using a divide-and-conquer technique. 
Briefly, we first find the best match among all points, i.e., minimum distance. We then subdivide the 
remaining potential matches to the left and to the right of the best match, thus yielding two smaller 
sub- sets on which we reapply the algorithm. For hardware implementa- tion, dynamic programming may be 
more suitable. This is a common solution for related string matching problems. Consider a column which 
previously had foldover layers labeled 123456, with orientation RLRLRL, and original u-coordinates of 
10,I7,25,30,80,95. If two of these layers disappeared leaving four layers, say abed, with orientation 
RLRL and original u-coordinates of 16,20,78,101, then we would do the matching finding abed matching 
1256 respectively. 3.6.3. Storing Information from Foldovers Once the matches are determined, we must 
rearrange the data so that the intensity resampler can access it in a spatially coherent manner. To facilitate 
this, each column in the intermediate image has a block of pointers that specify the order of the foldover 
layers. When the matching algorithm results in a shift in order, a different set of pointers is defined, 
and the valid range of the previous set is recorded. The advantage of this explicit reordering of pointers 
is that it allows for efficient access to the folds while processing. We describe the process from the 
point of view of a single column in the intermediate image, and note that all columns are processed identically. 
The first encountered entry for a row goes into the base layer. For each new entry into this column, 
the f'dl pointer is advanced (using the block of pointers), and the entry is added at the bottom of the 
next fold layer. After we compute the "best" match we move incorrectly stored data, reorder the layers 
and define a new block of pointers. Let us continue the example from the end of the last section, where 
123456 was matched to 1256. After the matching, we would then move the data, incorrectly stored in columns 
3 and 4 into the appropriate location in 5 and 6. Finally we would reorder the columns and adjust the 
pointer blocks to reflect the new order 125634. The columns previously labeled 34 would be marked as 
terminated, and considered spares to be used in later rows if a new fold layer begins. 3.6.4. Intensity 
Resampling with Foldovers A final aspect of the foldover problem is how it affects the 2-D intensity 
resampling process. The discussion above demonstrates that all the intensity values for a given column 
are collected in such a way that each fold layer is a separate contiguous array of spatially coherent 
values. Thus, the contribution of each pixel in a fold layer is obtained by standard 1-D filtering of 
that array. From the coordinate resampier, we obtain ZLUT~, and thus, merging the foldovers is equivalent 
to determining which filtered pix- els are visible. Given the above information, we implement a simple 
z-buffer algorithm, which integrates the points in front-to-back order with partial coverage calculations 
for antialiasing. When the accumu- lated area coverage exceeds 1, the integration terminates. Note that 
this z-buffer requires only a 1-D accumulator, which can be reused for each column. The result is a single 
intensity image combining the information from all visible folds. 3.7. COMPOSITOR The compositor generates 
the final output image by selecting the most suitable pixels from 1~ and IT~ as determined by the bottleneck 
images Bxy and BT~. A block diagram of the compositor is shown in center row of Fig. 3.1. Bottleneck 
images Bxy and B~ are passed through a comparator to generate bitmap image S. Also known as a vector 
mask, S is initial- ized according to the following rule. S[x,y] = ( B~[x,y] _< BT~[x,y] ) Images S, 
I~, and 1T~ are sent to the selector where 1o= is assembled. For each position in Io~, the vector mask 
S is indexed to determine whether the pixel value should be sampled from Ixy or IT~. 4. EXAMPLES This 
section illustrates some examples of the algorithm. The top row of Fig. 4.1 shows two images that will 
be used as source images for numerous examples. We refer to these images as the checkerboard and as Madonna. 
The bottom row of that figure shows the final result of warping the checkerboard and Madonna into a 360 
 circle. This transformation takes each row of the source !mage and maps it into a radial line. This 
corresponds directly to a mapping from the Carte- sian coordinate system to the polar coordinate system, 
i.e., (x, y)-~(r, 0). Figure 4.2 illustrates the output of the intensity resarnpler for the non-transposed 
and transposed processing, lxy appears in the upper- left quadrant, and 1~ is shown in the upper-right. 
The lower-right quadrant shows S, the vector mask image. S selects points from I~7 (white) and lr~ (black) 
to generate the final output image lo=. Gray points in S denote equal bottleneck computations from both 
sources. Ties are arbitrarily resolved in favor of l~y. In the bottom-left qua- drant of Fig. 4.2, the 
two spatial lookup tables XLUT and YLUT that defined the circular warp, are displayed as intensity images, 
with y increasing top-to-botttom, and x increasing leA-to-fight. Bright inten- sitty values in the images 
of XLUT and YLUT denote high coordinate values. Note that if the input were to remain undistorted XLUT 
and YLUT would be ramps. The deviation from the ramp configuration depicts the amount of deformation 
which the input image undergoes. Figure 4.3 demonstrates the effect of undersampl.ing the spatial lookup 
tables. The checkerboard is again warped into a circle. How- ever, XLUT and YLUT were supplied at lower 
resolution. The jaggi- hess in the results are now more pronounced. Figure 4.4 illustrates an example 
of foldovers. The lower-left qua- drant shows XLUT and YLUT. A foldover occurs because XLUT is not monotonically 
increasing from left to right. In the upper-right quadrant, the output image is composed by simply selecting 
the     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>74372</article_id>
		<sort_key>379</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1989</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[An efficient algorithm for hidden surface removal]]></title>
		<page_from>379</page_from>
		<page_to>388</page_to>
		<doi_number>10.1145/74333.74372</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=74372</url>
		<abstract>
			<par><![CDATA[We give an efficient, randomized hidden surface removal algorithm, with the best time complexity so far. A distinguishing feature of this algorithm is that the expected time spent by this algorithm on junctions which are at the "obstruction level" <i>l</i>, with respect to the viewer, is inversely proportional to <i>l</i>. This provably holds for any input, regardless of the way in which faces are located in the scene, because the expectation is with respect to randomization in the algorithm, and does not depend on the input. In practice, this means that the time complexity is roughly proportional to the size of the <i>actually visible</i> output times logarithm of the average depth complexity of the scene (this logarithm is very small generally).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39076331</person_id>
				<author_profile_id><![CDATA[81332517345]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mulmuley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808735</ref_obj_id>
				<ref_obj_pid>800061</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ben-Or M., "Lower bounds for algebraic computation tres", Pro,. o} the 15th STOG, 83.]]></ref_text>
				<ref_id>Be</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chazelle B., Edelsbrunner It., "An optimal algorithm for intersecting line segments in the plane", Proceedings of the FOCS, 1988.]]></ref_text>
				<ref_id>CE</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73394</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Clarkson K., "Applications of random sampling to computational geometry, II", Pro,. 4th Ann. ACM Symposium on Computational Geom., 1988.]]></ref_text>
				<ref_id>Cl</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73395</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Clarkson K., Shor P., "Algorithms for diametral pairs and convex hulls that axe optimal, randomized, and incremental", Proc. 4th Ann. A CM Symposium on Computational Geometry, 1988.]]></ref_text>
				<ref_id>CS</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[ttamlin G., Gear C., "Raster-Scan hidden surface algorithm techniques", Computer Graphics, vol. i1, no. 2, pp. 1206-213.]]></ref_text>
				<ref_id>HG</ref_id>
			</ref>
			<ref>
				<ref_obj_id>10522</ref_obj_id>
				<ref_obj_pid>10515</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Haussler D., Welzl E., "Epsilon nets and simplex range queries", Pro,. 2nd Ann. A CM Symposium on Computational Geometry, 86.]]></ref_text>
				<ref_id>HW</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27627</ref_obj_id>
				<ref_obj_pid>27625</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mckenna M., "Worst-case optimal hidden surface remowl algorithm", ACM transactions on graphics, vol.6, no. 1, 1987.]]></ref_text>
				<ref_id>Mc</ref_id>
			</ref>
			<ref>
				<ref_obj_id>101761</ref_obj_id>
				<ref_obj_pid>101759</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mulmuley K., "A fast planar partition algorithm, I", Proceedings of the 29th FOCS, 1988, full version to appear in a special computational geometry issue of the Journal of Symb. Logic.]]></ref_text>
				<ref_id>Mu1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73837</ref_obj_id>
				<ref_obj_pid>73833</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mulmuley K., "A fast planar partition algorithm, II", To appear in the Proceedings of the 5th Ann. ACM symposium on Computational Geometry, 89, full version submitted to JACM.]]></ref_text>
				<ref_id>Mu2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>108110</ref_obj_id>
				<ref_obj_pid>108107</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Mulmuley K., "On levels in arrangements and Voronoi diagrams", Technical report, TR 88-21, University o} Chicago, December,88, submitted to the Journal of Discrete and Computational Geom.]]></ref_text>
				<ref_id>Mu3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Mulmuley K., "An efficient algorithm for hidden surface removal, I', a complete manuscript.]]></ref_text>
				<ref_id>Mu4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mulmuley K., "An efficient algorithm for hidden surface removal, II", in preparation.]]></ref_text>
				<ref_id>Mu5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Newell M., Newell R., Sancha T., "A new approach to the shaded picture problem", Proc. ACM. National Conf., 1972.]]></ref_text>
				<ref_id>NSS</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Schmitt A. "Time and space bounds for hidden line and hidden surface algortithms', Eurographics, 81.]]></ref_text>
				<ref_id>Sc</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., R. F. Sproull, and R. A. Schumaker, "A characterization of ten hidden surface algorithms", Computing Surveys 6: 1-55, 1974.]]></ref_text>
				<ref_id>Sut</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Warnock J., "A hidden surface algorithm for computer generated half-tone pictures", computer science dept., University o} Utah, TR J-15, 1969.]]></ref_text>
				<ref_id>Wa</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Weiler K., Athetton P., "Hidden surface removal using polygon axes sorting", computer graphics (Proc. SIGGRAPH), July, 77.]]></ref_text>
				<ref_id>WA</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Efficient Algorithm For Hidden Surface Removal Ketan Mulmuley The University of Chicago 1 Abstract 
We give an efficient, randomized hidden surface removal al- gorithm, with the best time complexity so 
far. A distinguish- ing feature of this algorithm is that the expected time spent by this algorithm on 
junctions which are at the "obstruction level" 1, with respect to the viewer, is inversely proportional 
to i. This provably holds for any input, regardless of the way in which faces are located in the scene, 
because the ex- pectation is with respect to randomization in the algorithm, and does not depend on the 
input. In practice, this means that the time complexity is roughly proportional to the size of the actually 
visible output times logarithm of the average depth complexity of the scene (this logarithm is very small 
generally). 2 Introduction In this paper we give an efficient, randomized hidden sur-face removal algorithm, 
with the best time complexity so far. A basic theory behind this algorithm is a theory of probabilistic 
geometric games and a theory of a certain/9 se- ries, that can be associated with combinatorial arrangements 
[Mul,Mu2,Mu3]. The concept of a/9 series is essential to the discussion of this aigorithm. So let us 
first see how one can associate such a series with a collection of faces in three dimensions. For the 
sake of simplicity, we shall assume that the faces are nonintersecting. Intersecting faces are treated 
in [Mu5]. We, of course, allow faces to share edges. Imagine an observer located at the origin. Assume, 
for the sake of simplicity, that the origin is located at (0, O, -oo); this can be achieved by an appropriate 
perspective transformation. Project all faces orthonormally in the z direction onto the "view" plane. 
Abstractly speaking, the problem of hidden surface removal is concerned with finding a suitable partition 
of the view plane, and labelling each region of this partition with a face Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. that is visible there. When one 
projects all faces onto the view plane, this gives rise to several junctions formed by crossings of the 
xy-projections of the face boundaries. Only a few of these junctions are visible. An efficient algorithm 
should spend as little time as possible on the invisible junc- tions. To make this statement precise, 
we shall associate levels with all junctions. Consider a junction q located at an intersection of the 
xy-projections of the boundaries of two faces f and g. A face h is said to obstruct q, with respect to 
the observer o at (0, 0, -0), if the presence of h makes q invisible to the observer. This means, that 
if we consider the line of sight from the observer, corrresponding to the junction q, h occurs on this 
line of sight before f or g. Define the obstruction level of q, level(q), as the number of faces in the 
scene, which obstruct q. Let Vt be the set of junctions at level 1 - 1, and let v(l) be the size of Vt. 
Thus V1 is precisely the set of visible junctions. For a fixed collection of faces, define a 9 series 
as follows: for every real number s > 0, v(l) 8(s) l, i A similar 8 series can also be associated with 
a collection of intersecting faces. The main motivation behind associating such a series is that it has 
a lot of combinatorial information encoded in it. For example, in [Mu3], we showed how a 0 series can 
be associated with an arrangement of hyperplanes in any dimnesion d. It was then shown that the worst 
case behaviour of this series can be analyzed as a function of s, and that s = [d/2] is a critical point 
on the real axis where this behaviour changes abruptly. This has a lot of combinatorial implications. 
A similar theory can also be developed for the /9 series associated with a collection of intersecting 
faces (in any dimension) [Mu5]. In this paper, we shall restrict ourselves to only an algorithmic implication 
of this theory in the context of hidden surface removal. The implication is that the running time of 
our randomized hid- den surface removal algorithm depends linearly on the value of the/9 function at 
s = 1: /9(1) = ~=1 v(i)/l. To see what this means, let us first see what /9(0) is. It is easy to see 
that /9(0) is simply the number of all junc- tions in the view plane, visible as well as invisible. Whether 
hidden surface removal can be performed in time that de- pends linearly on 8(0), in a strict theoretical 
sense, is itself a nontrivial question. The reason is that, this requires a method to find all m intersections 
of n segments in a plane in optimal O(m + n logn) time. This question has been &#38;#169;1989 ACM-0-89791-312-4/89/007/0379 
$00.75   c~,,~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 ii resolved in the affirmative recently 
in [Mul,CE,CI]. The optimal planar partition algorithm in [Mull can be easily extended so as to obtain 
an O(n log n + 8(0)) hidden surface removal algorithm. Thus, hidden suface removal can indeed be performed 
in time that is linear in 0(0). But that is still far from satisfactory, because most of the O(0) junctions 
in the view plane are invisible. We surely do not want to spend equal time on all of them. Linear dependence 
of the expected running time of our algorithm on 0(1) achieves precisely that. Note that the expectation 
is with respect to the randomization used in the algorithm, very much as in Quicksort, and does not depend 
on the input. So we are assuming nothing about the input. Linear dependence of the running time on 6(1) 
is, in es- sense, the characteristic feature of the new algorithm. What this means is that the work done 
by the algorithm on the junctions with level I is inversely proportional to !. Intu-itively, the work 
done on junctions quickly decreases as we move farther from the observer. In practice, sizes of the various 
sets  are comparable. Hence, one approximately gets an harmonic series in the expansion for 8(1). And 
it follows that the running time of the algorithm is roughly proportional to the size of the actually 
visible output, i.e. v(1), times logarithm of the (average) depth complexity of the scene (which is quite 
small generally). A intuitive ex-planation for the linear dependence of the running time on 8(1) is the 
following. The algorithm proceeds by adding one face at a time in a random order. The crux of the algorithm 
lies in ensuring that if a junction q is computed at some instant, during the algorithm, none of the 
faces added before that instant could obstruct q. Thus, intu-itively, a junction is computed with a probability 
inversely proportional to its obstruction level. This naive explanation is, unfortunatately, misleading 
and fallacious, because the dominant part of the algorithm is not the computation of the junctions, but 
the computation, and the management, of the so called conflicts. Conflict is a transient, imaginary junction, 
which has no real conterpart. For other uses of conflicts, see [Mul,CS,C1,Mu2,Mu3]. Note that 0(oo) is 
precisely the number of visible junc- tions. Can one perform hidden surface removal in time that is linear 
in 0(0), or even e(s), where s > 1? That is an open question. However, it seems plausible that, in the 
algebraic computation tree model, t2(nlog n + 8(1)) is actually a lower bound for hidden surface removal. 
The only nontrivial bound that has been proved so far in this model is ~(n log n) (for sorting) [Be]. 
This is essentially based on the Milnor-Thom bound on the number of connected compo- nents of a real 
algebraic variety. To prove an f~(8(1)) bound in. this model will definitely require a deeper insight 
into a sinailar aspect of algebraic geometry. Another feature of our algorithm, in contrast to the pre- 
vious methods [HG,NSS,Sut,Wa,WA,Sc,Mc], is its essential use of randomization. That randomization should 
help hid- den surface removal is only to be expected. This is because hidden surface removal is a kind 
of sorting, and the power of randomization has already been demonstrated by Quicksort for sorting in 
dimension one. However, in higher dimensions, the situation is completely different. For example, the 
divide and conquer stragegy of Quicksort fails to be as powerful in higher dimensions. The division step 
of Quicksort is power- ful because it results in two problems of a roughly equal size, whereas the division 
with respect to a geometric element, say a face, in a higher dimension invariably results in an unbal- 
anced division, even if that geometric element were to be chosen randomly. This makes it necessary to 
follow a differ- ent approach in higher dimensions, to be able to exploit the power of randomization. 
In this approach, Quicksort is to be viewed not as a divide and conquer method, but as a method which 
exploits the random evolution of the underlying one dimensional configuration. Thus we are led to analyze 
the nature of a random evolution in higher dimensions, where it is much more interesting and complex 
than in dimension one. A theory of probabilistic geometric games and 9 series in [Mul,Mu2,Mu3] was developed 
precisely with the aim of analyzing this random evolution. This theory is a key to the algorithm in this 
paper. Also of related interest is a theory of random sampling [HW,C1,CS]. The theoretical time complexity 
of the new method is much better compared to the previous methods, but can one expect it provide any 
improvement in practice? This seems quite plausible, because the algorithm is also very simple. With 
this in mind, we also provide (see the complete manuscript [Mu4]) another related hidden surface removal 
algorithm. This algorithm makes use of some ideas in the planar partition algorithm of [Mull. Its running 
time is not guaranteed to be linear in 8(1), but it is quite closely related to the original algorithm. 
So its observed behaviour might not be too different. Besides, it maintains less auxi- allary information 
than the first algorithm, and this might be significant in practice. Both algorithms make no use of coherence 
in the image plane. This should make them robust with respect to the rounding errors and degeneracies 
in the input. This is especially so because randomization is well known for its suppressing the propogation 
of error. On the other hand, our algorithm is a general purpose hid- den surface removal algorithm, which 
can not detect cheaply special situations, such as a car in front of a grass field, a box with lots of 
things inside etc. In fact, if one could prove our above mentioned lower bound conjecture, that would 
provide a formal proof that a general purpose hidden surface algorithm must take at least t2(9(1)) time 
to detect such special situations. It is as important to use the usual heuristics, such as clipping and 
hierarchial comparisons, in conjuction with this method, as with any other method. We shall not deal 
with the question of heuristics in this paper. We shall, however, mention that [Mu2] gives a new clipping 
technique called virtual clipping, which has all advantages of the conventional clipping, in the amortized 
sense, but with a logarithmically small overhead in comparison. For hidden surface removal in the presence 
of intersecting faces, curved faces etc. see [MuS]. 3 Algorithm We assume that we are given some standard 
specification of the scene, which consists of a specification of the faces in the scene together with 
their edges and vertices. Let n be the number of faces. We assume that the faces are uonintersecting 
(intersecting faces are treated in [Mu5]), and that the facelengths are bounded by a constant. But the 
faces are allowed to have arbitrary shapes. We also assume that the usual preprocessing operations such 
as perspective trasformation, clipping against the view window, culling out irrelevant faces, have already 
been done. We are thus dealing with only a simple orthographic projection of the scene along the z axis. 
Given a face f in the scene, we shall denote its projection on the zy plane by f. The boundary of f will 
be denoted by Of. Similarly the xy projection of an edge e or a vertex v in the scene will be denoted 
by e and v respectively. We also assume that there is a special face O in the scene which serves as a 
background for the whole scene. The overall organization of the algorithm is as follows. We first form 
an initial partition H0 of the (view) window. H0 is simply the whole window, and thus has just one region. 
This region will be labelled with the background face O, implying that, in the begining of the algorithm, 
O is visible throughout the view window. Starting with H0, we form a sequence of convex partitions Ho, 
Hi,..., Ha, by "adding" the faces in the scene in a random order. This means that Hk+l will be obtained 
from Hk by adding to it a face ffk+a, which is randomly chosen from the set of remaining scene faces. 
As a convention, we shall let f0 denote the background face O. By this convention, f0 is the very first 
"randomly" chosen face. Each region R in Hk will be labelled with the face f(R), which is "currently 
visible" in R, among the k + 1 faces, f0, "" ,fk, that have been added so far. This means that the face 
f(R) would be visible in R, if the scene were to consist only of the faces fo,-. ",fA- H,, will be the 
final visibility partition of the view window. Hn tells us which face in the scene is visible at any 
given location in the view window. Now one can scan Hn from left to right, and paint each region of Hn 
in accordance with the face visible in that region. Let us specify in more detail the partition HA of 
the win- dow induced by the randomly chosen faces f0," ", fk. For this purpose, imagine that the scene 
consists only of the faces fo," ",fk. Consider an edge e of one of these faces. It is clear that, in 
general, one will only see parts of e -possibly none. The xy projections of these disconnected visible 
parts of e will be called fragments. Fragments of the edges of fo,... ,fk induce a partition of the view 
win- dow. Unfortunately, the regions of this partition can have complicated boundaries. To overcome this 
difficulty, we pass a vertical attachment through each loose endpoint of a fragment, which extends in 
upward, as well as downward, direction until it hits either another fragment or a window border. For 
the input in fig la, we have shown in fig lb the partition that results, if the first three randomly 
chosen faces are A, C, D. The partition obtained in this fashion is convex, but there is still one theoreticM 
difficulty. A region of this partition, at least theoretically, can have arbitrarily many borders. To 
overcome this difficulty, we also pass a vertical attachment through every t-junction, where two fragments 
meet. This vertical attachment will, however, extend in only one direction (see fig lc). What we have 
now is the partition Hk. Note that each region of Hk is a trapezoid; a triangle is regarded as a degenerate 
trapezoid. Hence, Hk can be called a trapezoidal decomposition induced by the visible fragments of the 
edges of f0,...,fA. We point out, however, that in practice, it might be more desirable to impose just 
a convexity requirement, because a convex partition, as in fig lb, is less expensive to maintain than 
a trapezoidal decomposition, as in fig. lc. Accordingly, the algorithm, we are about to present, can 
be readily modified. This easy modification will be left to the reader. We still have to specify, exactly 
how the trapezoidal de- composition Hk is to be represented. One possibility is an obvious planar graph 
representation. This has a disadvan- tage that the representation of a fixed region of Hk can be arbitrarily 
large, as it can have arbitrarily many vertices on its border. In [Mnl], we presented another representation 
of a planar partition, which does not have this defect. It is based on the following notion of visibility 
(this notion of visibility has nothing to do with visibility, as in the context of hidden surface removal): 
Definition 1 A vertex v of the partition is said to be vis- ible in a face R, if OR, the boundary of 
R, has a tangent discontinuity at v. In the partition given in fig lc, u is visible in R0, R1 and R4, 
whereas it is invisible in R3. Each trapezoid of Hk will be specified by a circular list of the visible 
vertices on its border. Thus the representation of R3 in fig lc is (a~, an, a2). If v is visible in R, 
we shall refer to the corresponding entry in the representation of R by yR. In addition to specifying 
the faces of the partition, we also need to specify adjacency relationships at each vertex to complete 
the representation. If a vertex v is visible in R, we shall link vR to vR,, where R' is the next face, 
in the counterclockwise order, in which v is visible. Thus at the vertex u in fig lc, we will have links 
in the order: uR4 --* unl ~ uR0 ~ uR4. To avoid any confusion, we shall, henceforth, reserve the terms 
faces, edges, and vertices exclusively for those in the scene. Ver-tices of the partition Hk will be 
called junctions. A junction can be of three kinds: 1) it can be located at an intersection between two 
fragments, (e.g. the junction u in fig lc), 2) it can be located at the projection of a scene vertex 
(e.g. a0 in fig lc), 3) or else it can be a point of attachment, i.e. a t-junction, where some vertical 
attachment meets a fragment or a window border (e.g. all, al",u I in fig lc). Junctions of the first 
two kinds will be called concrete. A point of attachment, on the other hand, is not concrete. The faces 
of Hk will always be called trapezoids or regions. A border of a region in Hk is defined as usual. A 
border in //k is called concrete if it lies on a fragment (e.g. the border (a[, a2) of R3 in fig lc). 
A border which lies on a vertical attachment is not concrete (e.g. (aS,a1) of R3). As already mentioned, 
each region R of Hk will also be labelled with the face, among the k+l faces f0,-.-, fk added so far, 
that is currently visible there. This face currently vis- ible in R will be denoted by f(R). Thus f(n3) 
= A, f(n~) = C, f(Rl) = O etc. This completes the specification of Hk. Unfortunately, there is still 
not enough information to make the "addition" of the next randomly chosen face fk+l to Hk easy. The reason 
is that we have to somehow know which regions of Hk will be affected by the addition of fA+a- With this 
in mind,  ':~~SIGGRAPH '89, Boston, 31 July-4 August, 1989 m we also associate with Hk some conflict 
information. For the use of conflicts in other contexts see [Mul,CS,CI, Mu2,Mu3]. First let us make a 
few definitions. A face g, other than the added faces f0,'-- fk, and a trapezoid R E HA are said to be 
in conflict if 1. ~, the xy-projection of g, intersects R, and  2. f(R) does not obscure g in the region 
R. Intuitively, if g is in conflict with R, then g will be at least partially visible in R, if it were 
the next face to be chosen for addition to HA. We shall say that f(R) is a background face of this conflict 
between g and R.  If g is in conflict with R E HA then one, or possibly more, of the following kinds 
of conflicts must occur. 1. a trapezoid-vertex conflict: A vertex v of g is in conflict with the trapezoid 
R, i.e. to say 0, the zy-projection of v, lies in R. This conflict is said to be located at ~. 2. a 
border-edge conflict: An edge e of g is in conflict with a border b of R, i.e. to say e, the zy-projection 
of e, intersects b. This conflict is said to be located on b at the intersection of e and b. 3. a junction-face 
conflict: a concrete junction t of R is in conflict with g, i.e. to say 9, the zy-projection of g, contains 
t. This conflict is said to be located t. Note that we do not consider conflicts at junctions, which 
are not concrete.  Each of these conflicts is said to have f(R) as its background face. Examples: 
In fig. ld, we have overlayed on Hz, for the sake of visual- ization, those parts of the boundaries of 
the remaining faces B and E, that are not occluded by the already added faces A,C, D. Referring to this 
figure, the following observations can be made. Face E conflicts with regions R0, R~, R4, but no other 
region, as it is occluded everywhere else. E conflicts with the junction u in R1, Ro, R4. Because u is 
"invisible" (Definition 1) in R3, the question about a conflict in R3 does not arise. If there were some 
nnadded face, behind G looking from u, it would conflict with u in R1, but not in R0 and R4. The background 
face of the conflict between u and E, in R0, is C, whereas the background face of the conflict between 
u and E, in R1, is O. These conflicts have the same locations but different backgrounds, hence they are 
completely differ- ent. On the other hand, the conflict between u and E, in R0, has the same location 
as well as background as the conflict between u and E in R4. Indeed, there is no real reason to regard 
these two conflicts as different. Hence, they can be identified. The vertex e0 is in conflict with the 
trapezoid R0, whereas e3 is in conflict with R4. Other vertices of E are all occluded by the added faces, 
and hence, are not in coflict with any trapezoids. The edge (e2,ea) of E is in conflict with the border 
(u, a2) of R4. But it is rwt in conflict with the border (a~, a2) of R3, which lies on the other side 
of the fragment (ao,a2). On the other hand, the edge of (b0,bz) of B is in conflict with both borders, 
(u, a2) of R4, as well as, (a~, a2) of R3. Though the locations of both these con- flicts with (bo, b3) 
are the same, their background faces are different (C and A respectively). Hence, these two conflicts 
are to be regarded as completely different. The same edge (b0, b3) also conflicts with the vertical attachment 
(u, u') in R0, as well as, R4. Locations, as well as backgrounds, of these conflicts are the same. Again, 
there is no real reason to regard the border-edge conflicts such as these, which lie on the opposite 
sides of the same vertical attachment, as different. They too can be identified. There are various ways 
to associate conflict information with Hk. Basically, one should be able to deduce in an efficient fashion, 
the various kinds of conflicts, as defined above, that occur within Hk. The scheme we will choose is 
not the most efficient, both in terms of memory and time. However, it has an advantage that it simplifies 
the descrip- tion of the algorithm. The reader will be able to see many other alternative schemes. The 
conflict information associated with Hk will be orga- nized so that: 1. Given any concrete junction t 
in Hk, we know the un- added faces that are in conflict with t, and conversely, given any unadded face 
ff, we know the concrete junc- tions in Hk that are in conflict with f. Note that we do not store conflicts 
with the points of attachment in Hk. 2. Given any border b in Hk, concrete or otherwise, we know the 
scene edges that are in conflict with b, and conversely, given any edge e, we know the borders in Hk 
that are in conflict with e. Moreover, we assume that the borders of all faces in the scene are oriented 
so that the corresponding orientations of their xy-projections is counterclockwise. This orients e, the 
projection of e, too. We assume that all conflicts of e are kept ordered, by simple links, along the 
orientation of e. 3. Given any region R E Hk, we know the scene vertices that are in conflict with R, 
and conversely, given any vertex v, we know the region in Hk that is in conflict with v. Moreover, we 
assume that all conflicts with a given region R are kept ordered, by simple links, according to the ~-cordinates 
of their locations.  The conflict size of a region R E Hk is defined to be the total number of conflicts, 
of all three kinds, that are associated with R. Now we are ready to describe how the addition of a ran- 
domly chosen face f = fk+l to the partition Hk is achieved. 3.1 Preliminary update along the boundary 
In this step, we split the trapezoids of Hk that are in conflict with the boundary Of, i.e. the trapezoids 
which conflict with either an edge or a vertex in Of. Let us specify this step in more detail. Exploiting 
the ordering of the border-edge conflicts, we visit these trapezoids along the given counter- clockwise 
orientation of 0f. Note that we are not visiting all regions of Hk that intersect Of, but only the ones 
which conflict. Intuitively, these are the regions where ~f is not occluded by any of the added faces 
f0,-.., fk. Assume, for example, that the fourth randomly chosen face to be added to Ha, in fig ld, is 
E. In this case, we shall travel on c9~ from the conflict on (c~,u) to the one on (u, a2). Here the conflicting 
part of 0E is connected. In general, the conflict- ing part of Of~+~ can have many connected components. 
But that does not cause any problems. As we visit the con- flicts on O] in the counterclockwise direction, 
we split every conflicting border that we visit. Moreover, when we split a border adjacent to a vertical 
attachment through some concrete vertex, say v, we retain only that split part which contains v. For 
example, in the addition of ff4 = E to H3 in fig ld, we shall retain only the upper half of the border 
(u, u'). In addition, we pass a vertical attachment through every new intersection that corresponds to 
a conflict on a concrete border of Hk. We also create a new junction for every conflict that is located 
at the xy-projection of a vertex of fk+l- Remember that we perform these actions, as we travel. It is 
possible that, during this travel, we will visit the same region of the old partition Hk more than once. 
But this should cause no problem. It only means that we have to split sometimes an already added vertical 
attachment even further. When we travel in this manner on the conflicting parts of Off, what we obtain 
at the end is a new trapezoidal decom- position H~,+i , that is obtained from Hk by appropriately splitting 
the regions of Hk, that conflicted with Of. We also need to label each newly formed trapezoid R r with 
a face that will be visible in R ~ after the addition of f = fk+l. This is easy to do. Notice that each 
newly formed trapezoid is either completely covered by ] or is completely disjoint front f, except at 
its boundary. If R' is covered by f, we label it with f, else R' will retain the old label f(R) of R. 
We also have to associate conflict information with each newly formed region R'. R', in general, consists 
of parts of some old trapezoids in H~, say R1, .. -, Rt, that were in conflict with Off. So we have to 
derive the conflict informa- tion, to be associated with R', from the conflict information associated 
with R1,... ,Rt. Notice that an unadded face can conflict with R' only if it was in conflict with one 
of the trapezoids R1,-..,Ri. Moreover, a face g that was in conflict with some Rj, 1 < j _< l, can be 
in conflict with R only if 1) ~, the xy-projection of g, intersects R t, 2) and, in case R' is covered 
by f, the face g is not occluded by f in R'. With the help of these observations, it is easy to derive 
the conflict information, to be associated with R', in time proportional to the sum of the conflict sizes 
of R1, -- , Rt. As each R E Hk, that was in conflict with Of, can be split into only a bounded number 
of trapezoids, the preliminary update along the boundary takes time that is O( . conflict.size(R)), where 
R ranges over the trape-  EREH~ zoids that were in conflict with Of. Needless to say, all trape- zoids 
of Hk in conflict with Of and the conflict information associated with them can now be destroyed. 3.2 
A preliminary update in the inte-rior In this step, we access all trapezoids in the partition, that 
are in conflict with f, and which are in the interior of f, but are not adjacent to Of. We update the 
conflict infor- mation associated with each of these trapezoids. At the end of this operation, the new 
trapezoidal decomposition Hi+l, that was obtained above, will have proper, updated conflict information 
associated with it. It is easy to see that every conflicting trapezoid in the interior of f has two concrete 
junctions that are in conflict with f. Hence, using the list of junctions in conflict with f, we can 
readily access all conflicting regions in the interior of f. For each region R, accessed in this fashion, 
we do the following: 1. We label R with f, because f will be the face visible in R after the addition 
of f. 2. We reduce the conflict information associated with R, by discarding every conflict with a face 
(or its edge or a vertex) that is occluded by f.  The second step requires us to know, for every face 
g that is in conflict with R, if f occludes (overlaps) g. The same face g might be in conflict with many 
of the accessed trapezoids. In this case, it is clearly desirable to carry out the required overlap comparison 
just once, if that is possible. This is indeed possible if f and g do not overlap cyclically, which is 
always the case if f and g are convex. In the absense of a cyclic overlap, we carry out the overlap comparison 
between f and g just once. To expediate this comparison, it is often advantageous to test first if the 
z-extents of f and g overlap; a complicated test is necessary only if they do [NSS]. At the end of this 
preliminary update in the interior, we have a partition Hi+l, with the correct conflict information associated 
with it. However, H~+ 1 might contain several fragments which have been rendered invisible during the 
ad- dition of f. These fragments have to be removed from H~+i; this step is called reconfiguration. After 
reconfiguration we shall update the conflict information once again. Let us first turn to reconfiguration. 
 3.3 Reconfiguration Consider all trapezoids of H~+ 1 which are labelled with f = ffk+l at the end of 
the preliminary update. The union of these trapezoids form a region C = Ck+l in the plane. Clearly the 
trapezoids of H~+ 1 outside C need not be con- sidered in reconfiguration. Note that the region C can 
have many connected components and the connected components themselves can have complicated, disconnected 
boundaries (see fig. 2). All these factors have to be taken into account during reconfiguration. Let 
0C be the boundary of C. It is easy to see that a vertical attachment cart not form a part 0C. Thus every 
border of H~+ 1 that lies on aC is concrete. Moreover, every such border on OC will remain visible after 
the addition of f = fk+l. Thus the fragments which have become invisible after the addition of f must 
lie strictly in the interior of C. And conversely, every fragment which lies in the interior of C has 
become invisible after the adddition of f = fk+l. Hence a naive method to reconfigure is the following: 
re-move everything within C, and then find a new trapezoidal decomposition of C. This can turn out to 
be too expensive for two reasons. First, OC can be very complicated, hence one will need the power of 
a full fledged triangulation procedure. Second, we also have to "relocate" later the conflicts of the 
scene vertices, which were located within C. (We need to relocate other kinds of conflicts too.) This 
means we will '89, Boston, 31 July-4 August, 1989  , S,aGRAPH also need a full fledged a planar point 
location algorithm. Obviously, this approach is too costly. Fortunately, there is a less expensive way 
to reconfigure. It exploits the fact that what we have at our disposal is not just a boundary of C, but 
some trapezoidal decomposition of C. It is, of course, true that this trapezoidal decomposition has many 
unnecessary trapezoids. But it should still be possible to make use of this initially given decomposition 
somehow. The idea is to remove only a few of the unneces- sary trapezoids at a time. More precisely, 
let A1,...Ah be the set of fragments within C. We shall "remove" these fragments one at a time, but in 
a random order. This will be a randomized, decre- mental algorithm. In contrast, the overall hidden surface 
removal algorithm is randomized, and incremental. Clearly, the two strategies are complementary. As we 
said earlier, we shall deal with the problem of updating conflicts later. So let us consider the removal 
of a single fragment in more detail. Fig. 3a shows the fragment l = (10, 11), which has been randomly 
chosen for removal, together with the adjacent trapezoids. Let ao,al,...,% be the junctions adjacent 
to the "lower" side of l and let b0, bl, -. -, br be the junctions adjacent to the "upper" side of l. 
Some of these will be the junctions, where other fragments meet I and the remaining will be the points 
of attachment. Note that, by our definition 1, the junctions ao,...aq are "invisible" on the upper side 
of I, and b0,-'.,br are "in-visible" on the lower side of 1. So we need to merge the two sorted streams 
a0,...,aq, and b0, .. ,b~ to get a sorted stream co,. ., Cq+,.+l. Having done this, it is easy to remove 
1, by extending the vertical attachments ending on the upper side of I in the lower direction, and by 
extending the vertical attachments ending on the lower side of 1 analogously. See fig. 3b. When this 
procedure is repeated, in a random order, for all fragments lying within C, we obtain, at the end, the 
desired trapezoidal decomposition of C. This gives us the partition Hk+~, that we sought. But we still 
have to associate conflict information with the newly formed trapezoids. This is done next. 3.4 Relocating 
and generating conflicts In this step, we derive the conflict information, to be as-sociated with the 
trapezoids formed during reconfiguration, from the conflict information that was associated with those 
trapezoids in Hi+l, that existed within C = Ck+l before reconfiguration. We shall proceed by cases. trapezoid-vertex 
conflicts For every scene vertex v, that was in conflict with a trape- zoid R E H~+i within C, we need 
to find the new trapezoid R' E Hk+l within C that contains v. We call this step relo- cation of the conflict 
at ~. Relocating this conflict at the end of reconfiguration is a bit difficult. Instead, we shall modify 
the reconfiguration procedure a little, so that, at the end of reconflguration, we also know the conflicting 
trapezoid R' for every scene vertex v, that was in conflict with some trapezoid R E H~+I within C. The 
idea is to perform relocation of these conflicts along with reconfiguration. Note that, because of the 
way in which we organize the 384 conflict information, the vertex-trapezoid conflicts located within 
any trapezoid of H~+l are kept ordered by their x-coordinates. We shall ensure that this invariant holds 
throughout reconfiguration. More precisely, at any stage of the reconfiguration procedure, all conflicts 
of the scene vertices within any given trapezoid will be kept ordered by their x-coordinates. So reconsider 
the removal of a randomly chosen fragment l = (I0, 11) as in fig. 3a. We shall perform the following 
extra steps during this removal. First, we concatenate the fists of the trapezoid-vertex conflicts lying 
in the trapezoids adja- cent to the the upper side of l, and do the same for the lower side of l. Next 
we merge these two sorted lists. By a simple "interleaving" procedure, one can now split this merged 
list into various sorted lists of conflicts, corresponding to the new trapezoids formed after the removal 
of 1 (fig 3b). Now one is ready for the removal of the next randomly chosen fragment. border-edge conflicts 
Let us see how one can update the border-edge conflicts within C. Note that we do not need to worry about 
the conflicts which lie outside g, including the ones which fie on the "outer" side of 0ft. First, let 
us worry about the update on the inner side of 0C. Each new border-edge conflict on the inner side of 
0C is obtained from a similar conflict that existed in H~+i before reconfiguration. Hence, our task is 
basicMly to relocate the conflicts that existed in H~+i, on the inner side of 0C before reconfiguration. 
Ignoring the vertical attachments in Hk+l, that end on ~9C, one sees that 0C is a union of many linear 
segments. Group the above conflicts in H~+I according to the segments in 0C containg their locations. 
Let 1 be one of the segments on C, and let St be the set of border-edge conflicts located on the inner 
side 1. At the end of reconfig- uration, the vertical attachments ending on OC can split the inner side 
of I into many borders. Hence, for each conflict in St, we need to find out the new border that will 
contain this conflict. We shall find out this border by a simple sequential search along 1. So assume 
that we have relocated the conflicts on the inner side of OC. We also need to generate the border-edge 
conflicts, that lie on the vertical attachments within C. This will be done next. If g is scene face, 
define a concrete conflict of Og to be a conflict of a vertex on ~gg with some trapezoid, or a conflict 
of an edge in 0g with some concrete border. At this stage of the algorithm, we know all concrete conflicts 
within C. Consider a concrete conflict of 0g within C. This is either a conflict of an edge of 0g with 
a border on OC, or a conflict of a vertex in Og with a trapezoid wihin C. We shall travel from this conflict 
to the next concrete conflict of 0g within C, in the counterclockwise direction along O~, if it is pos- 
sible to do so without leaving C. This travel only involves skipping an appropriate number of vertical 
attachments in Hk+l, until the next concrete conflict is reached. For every vertical attachment encountered 
on the way, we generate a border-edge conflict. This procedure is repeated for every concrete conflict 
of Og within C. The same can be done for every Og which had a conflict within C. This procedure will 
generate all border-edge con- flicts on the vertical attachments within C. junction-face conflicts Fortunately, 
nothing elaborate needs to generate these conflicts. What makes our task easy is the fact that we store 
these conflicts only at concrete junctions. It is easy to see that, for every concrete junction t in 
Hk+l, the faces which conflict with t in Hk+l are precisely the ones which conflict with t in H~,+i. 
This makes the updating task straightfor- ward. At the end of this step, Hk+l has been associated with 
proper conflict information. Now we are ready to add the next randomly chosen face to Hk+l. This finishes 
the description of the hidden surface removal algorithm.  Probabilistic games A basic idea behind the 
analysis is to analyze a random evo- lution of the underlying partition Hk and the associated con- flict 
information. As this global evolution is overwhelmingly complex, we need a tool to break this complex 
behaviour into tractable parts. The tool, that we will use, is a prob- abilistie theory of geometric 
games, which was developed in [Mul,Mu2,Mu3]. We shall summarize in this section the results from this 
theory, that we will need in our analysis. Suppose that we are given a universe set N of some elments. 
The game we are going to play in this section, consists in drawing the elements of N in a random order 
without replacement. Fix two disjoint subsets S and R of N throughout this section. Let r = ]R[, and 
s = ]S]. Let us associate an observer with this pair of sets S and R. The following rule will determine 
the active phase of the observer during the game. The observer is active at any given instant of the 
game if the following two conditions are satisfied at that instant: 1) all elements from R have been 
chosen, 2) and no element from S has been chosen so far. If the observer does indeed become active during 
the game, he will go into the inactive phase as soon as the second condition is violated. The sets R 
and S will called the sets of triggers and stoppers respectively. Now assume that we are given one more 
subset M of the universe N, and let m = [M]. M need not be disjoint from either S or R. But we shall 
assume that M is linearly ordered. Imagine, just for the sake of visualization, putting elements of M 
on the positive real axis, according to the ordering of M, with the ordering increasing in the positive 
direction. Place the observer o, associated with the pair of sets S and R, at the origin. Assume that 
the observer can "see" only along the positive real axis. We shall soon make this notion precise. We 
say that an element b E M was observed by o, at some instant of the game, if b was chosen at that instant 
and no element e E M, s.t. c < b, was chosen before this instant. The idea is that the chosen elements 
in M are supposed to act as barriers to the sight of the observer. Let O be the number of elements observed 
by o in his active phase. If the observer never became active in the game, O is defined to be zero. Theorem 
1 E(O) = O(1 + ln(m + 1)), /or s = O, t = 0 = O(1+1n(1+-~)), lots>O, t=O. Now let us define the visibility 
span of the observer, at any instant during the game, as follows: Let b be the least element in M chosen 
at or before this instant. Then the visibility span of the observer at this instant consists of all elements 
in M less than b. Notice that none of the elements in the visibility span at a given instant, could been 
chosen before that instant. Thus the visibility span at any instant consists of the elements in M, not 
yet chosen, which lie within the visibility extent of the observer o. Let V be the number of elements 
in the visibility span of the observer, at the instant he became active. V is defined to be zero, if 
the observer does not become active at all. We shall define one more random variable W as follows. Charge 
the observer a cost equal to the length of his visibility span, i.e. V, at the moment he became active. 
After this, every time the observer observes in his active phase some element of M, say b, we charge 
the observer a cost equal to the number of elements _< b in M. (Thus the cost is equal to the length 
of the visible span at the instant b was observed.) Let W be the total cost charged to the observer. 
Then it is clear that V<W. Theorem 2 E(V) < E(W) (r)) fort >2 = O "TTg77 , r--] = O(ln(m+l)+l), fors=O, 
t= 1. = O(l+ln(l+-~)),fors>O, t=l. 5 A part of the analysis We shall first state the expected running 
time of the algo- rithm. Let c(f), the coupling coefficient of a face f, be the number of faces g whose 
projected borders 0~ intersect ]. For a fixed point q in the view plane, let c(q) ---- max{e(f)), where 
f ranges over the faces whose projections cover q. If q is an intersection of Of and 09, recall from 
Section 2 that the obstruction level of q, level(q), is the number of faces in. the scene, which obscure 
either f or g at q. Intuitively, the presence of any of these level(q) faces will make the junction between 
the boundaries of f and g invisible at q. If q is the xy-projection ~ of a vertex v of some face f, define 
level(q) to be the number of faces in the scene which occlude v at q. Let depth(q) be the number of faces 
whose projections cover q. Theorem 3 The expected running time ol the hidden sur-lace removal algorithm 
is O( n log n+nlog(l+cl) log(1 +r)+ 0(1) + log(1 + c2)0(2)), where r is the average ol the ratio  :~,~SIGGRAPH 
'89, Boston, 31 July-4 August, 1989 depth(q)/level(q) over the projections of the scene vertices, and 
el and c2 are the averages of the coupling coefficients c(q) over the projections of the vertices, and 
intersections of the projected boundaries respectively. The factor log(1 +e2)O (2) is smaller than e(1) 
in practice, but in theory, it is a nuisance. This factor can be removed from the running time, at the 
cost of a considerable complication in the algorithm [MuS]. On the other hand, we have not been able 
to remove, so far, the factor n log(1 + cl) log(I-t-r). This factor is, in practice, much smaller compared 
to 0(1). It is plausible that the algorithm as presented here, or its variant, has O(n log n+0(1)) expected 
running time. That is an open question. A complete proof of Theorem 3 can be found in the com- plete 
manuscript of the paper [Mu4]. Here we shall deal with only a part of the analysis, that deals with bounding 
the expected number of conflicts created in the algorithm. In this section, we shall prove the following 
Theorem 4 The expected number of conflicts created and destroyed in the whole course of the algorithm 
is O(n log n + o(1)). Our prime goal is to illustrate the use of probabilistic games in Section 4. Complete 
analysis is, in a sense, a long exercise in applying these games over and over again. Recall our convention 
to regard two conflicts with same locations but different background faces as different. This makes Theorem 
4 more interesting. Thus, if many conflicts with different background faces were created, during the 
algorithm, at the same location, they are all counted as dis- tinct in the theorem. A created conflict 
can be destroyed but once, hence we need not worry about the destroyed conflicts anymore. In the proof, 
we shall treat the three different kinds of conflicts seperately. Junction-face conflicts Recall that, 
in the algorithm, we stored conflicts of this kind at the concrete junctions only. Lemma 1 The expected 
number of conflicts, created in the algorithm, that are located at a concrete junction q is 0 1 at an 
intersection (TTrgg~T(~y.q ), if q is located of the pro- jections of two face boundaries, and O(1 T--log[ 
l~/ev~e/" t 1.-I-depth(q)~.. )1," if q is located at the projection of a vertex. (If a concrete junction 
was never created at q, during the algorithm, the number of conflicts created at q is defined to be zero.) 
Proof. We shall only consider the first case, where q is located at an intersection of say Of and 0~. 
Fix f,g and q. Refer to fig. 4a. Note that, by our Definition 1, q is invisible in the zone Q0. Thus 
no conflict located at q can come into existence in Q0. Also note that among the conflicts located at 
q, the ones which occur in the zone Q1, and the ones which occur in the zone Q2 have different background 
faces. Hence one has to treat the conflicts in these two zones seperately. We shall only treat here conflicts 
in the zone Q1- A similar treatment of the conflicts in the zone Q2 will be omitted. The lemma will be 
derived by applying the probabilistic game of Section 4. The setup is the following. The universe 386 
set N will be the set of all faces in the scene. (This will be the choice for the universe set throughout 
the analysis of the algorithm.) We shall place an observer at q who can "see" only in the positive z-direction. 
M, the set of objects that the observer can see, is defined to be the set of faces in the scene, whose 
projections cover q. The set M is linearly ordered according to the increasing z-coordinate of the faces 
in M at the location q. The sets R and S of stoppers and triggers, that will determine the active phase 
of the observer, are defined as follows. Let R = {f, g}, and let S be the set of level(q) faces which 
obscure f or g at q. Intuitively, the observer remains active as long as the junction q remains visible 
in the algorithm, and it is easy to see that q is visible iff all elements of R are chosen, and no element 
from S is chosen. In this setup, it is easy to see that the number of conflicts, created at q in the 
zone Q1, is precisely the random variable W defined in Theorem 2. This takes into account the fact that 
the conflicts located at q, but having different background faces, are to be considered different. Now 
the lemma follows from Theorem 2. Trapezoid-vertex conflicts Let v be a vertex of some face f. Fix f 
as well as v. Lemma 2 The expected number of trapezoid-vertex con-flicts, created in the algorithm, that 
are located at q = ~, is ~l .... l+depth(tl)~ t.Ak X -'1-tog~. l  level( q) ))" Proo Place, as in Lemma 
1, an observer at q, who can only see in the positive z-direction. Let M be the set of faces, whose projections 
cover q, and let S be the set of faces, which obscure v at q. The set of triggers R is now defined to 
be an empty set. The reason is that the trapezoid-vertex conflicts located at q can come into existence 
even when the face f has not been chosen for addition by the algorithm, assuming, of course, that no 
face from S has been chosen. In this set up, it is clear that the number trapezoid-vertex conflicts which 
are created at q is precisely the random variable O defined in Theorem 1: everytime such a conflict with 
a background face h is created, the observer at q can "see" the face h that is being added at the time 
of creation. Now apply Theorem 1. fl Border-edge conflicts Each border-edge conflict, created in the 
algorithm, is located either on ~ vertical attachment or on ~ fragment passing through some concrete 
junction. Lemma 3 The expected number of border-edge conflicts, created in the algorithm, that are located 
on a vertical at. tachment or a fragment through a concrete junction q, is 0 1 ( ll,wt(q)), if q is 
located at an intersection of the projec. l__[ l + depth( q) "t'~ tions of two face boundaries, and 
O(1 + .u~t l+t,~,t(q) )), if q is located at the projection of some vertex. (If a concrete junction was 
never created at q, during the algorithm, the number of conflicts created at q is defined to be zero.) 
Proo We shall only consider the first case. So suppose that q is located at an intersection of the projected 
borders Of and 0~ of two faces f and g. Fix f, g, as well as q. We will only estimate the conflicts created 
on a verti-cal attachment through q; the ones that are created on a fragment through q can be estimated 
similarly. Assume, without loss of generality, that f is in front ofg at q. Notice that, depending upon 
how Of and 0~/ are situated at q, a vertical attachment through q will either extend upwards or downwards. 
Assume, without loss of generality, that it extends downwards. Referring to rigA, notice that a vertical 
attachment lies either in the region that does not intersect or in the region that intersects ~. We will 
only consider the first case, and omit the second (easier) case. Let L be the set of level(q) faces which 
obscure either f or g at q. Let Sq be the set of faces, other than f and g, whose projections cover q. 
Fix a face h ESq. We shall esimate the expected num-ber of conflicts, created on a vertical attachment 
through q, which have h as their background face. First notice that h can be a background face for such 
a conflict only if h  L U {f, g}. Assume, henceforth, that h  n U {f, g}. Let levelq(h) be the obstruction 
level of h at q, i.e. the number of faces, other than f or g, which obscure h at q. Obviously levelq(h) 
> level(q). Claim: The expected number of conflicts created on a verti- cal attachment through q, which 
have h as their background  is O((2+;,~ltq(h))~). This will prove the lemma since, by elementary calculus, 
1 1 (2 + ievelq(h)) 2 -< 1 + level(q)' h where h ranges over all faces in Sq which do not belong to Lu{f,g}. 
Let Sh C Sq be the subset of those faces which are in front of h at q. Let T be the semi-infinite imaginary 
line through q extending downwards. A conflict with a border Ok of a face k, with h as a background face 
of the conflict, can come into existence on T, only if k obscures h somewhere on T, but not at q. This 
condition is just necessary, and not sufficient. Let Mh be the set of faces k, which satisfy the above 
condition. Linearly order Mh by letting kl << k2 iff 0kl intersects T before 0k2, i.e. the intersection 
between 0kl and T, that is closest to q, is closer to q than the similar closest intersection between 
0k2 and T. The following observation is crucial: Observation 1 Ilk1 << k2, and kl is chosen for addition 
in the algorithm before k2, then Ok2 cannot conflict with a vertical attachment through q, with the face 
h in the back- ground. (This does not hold, if the background is allowed to vary.) Now let Rh = {f, g, 
h}. Letting Rh, Sh and Mh play the roles of R, S, M in Theorem 2, it follows from the above observation 
that the number of conflicts, that come into existence on T with h in the background, is bounded, upto 
a constant factor, by the random variable V in that theorem: all faces whose boundaries create these 
conflicts are in the "visibility span" of the observer located at q, when the face h was added. The claim 
now follows from that theorem. D Using Lemma 1, Lemma 2, Lemma 3, and summing over all concrete junctions, 
we conclude that the expected number of conflicts created during the algorithm is O(n log n + 0(1)). 
This finishes the proof of Theorem 4. References [Be] Ben-Or M., "Lower bounds for algebraic computa- 
tion tres", Proc. of the 15th STOC, 83. [CE] Chazelle B., Edelsbrnnner I-I., "An optimal algo- rithm 
for intersecting line segments in the plane", Proceedings of the FOCS, 1988. [Cl] Clarkson K., "Applications 
of random sampling to computational geometry, II", Pro,. $th Ann. A CM Symposium on Computational Geom., 
1988. [CS] Clarkson K., Shot P., "Algorithms for diametral pairs and convex hulls that are optimal, random-ized, 
and incremental", Pro,. Sth Ann. ACM Sym- posium on Computational Geometry, 1988. [HG] Itamlin G., Gear 
C., "Raster-Scan hidden surface algorithm techniques", Computer Graphics, vol. 11, no. 2, pp. 206-213. 
[HW] Haussler D., Welzl E., "Epsilon nets and simplex range queries", Proc. 2nd Ann. ACM Symposium on 
Computational Geometry, 86. [Mc] Mckenna M., "Worst-case optimal hidden surface removal algorithm", ACM 
transactions on graph- ics, vol.6, no. 1, 1987. [Mull Mulmuley K., "A fast planar partition algorithm, 
I", Proceedings of the 29th FOCS, 1988, full version to appear in a special computational geometry issue 
off the Journal of Symb. Logic. [Mu2] Mulmuley K., "A fast planar partition algorithm, II", To appear 
in the Proceedings of the 5th Ann. ACM symposium on Computational Geometry, 89, full version submitted 
to JACM. [Mu3] Mulmuley K., "On levels in arrangements and Voronoi diagrams", Technical report, TR 88-21, 
University of Chicago, December,88, submitted to the Journal of Discrete and Computational Geom. [Mu4] 
Mulmuley K., "An efficient algorithm for hidden surface removal, I', a complete manuscript. [Mu5] Mulmuley 
K., "An efficient algorithm surface removal, II", in preparation. for hidden [NSS] Newell M., Newell 
R., San,ha T., "A new approach to the shaded picture problem", Proc. ACM. Na-tional Conf., 1972. [Sc] 
Schmltt A. "Time and space bounds for hidden line and hidden surface Mgortithms', Eurographics, 81. [Sut] 
Sutherland, I. E., R. F. Sproull, and R. A. Schu- maker, "A characterization of ten hidden surface algorithms", 
Computing Surveys 6: 1-55, I974. [Wa] Warnock J., "A hidden surface algorithm for com- puter generated 
half-tone pictures", computer sci- ence dept., University of Utah, TR 4-15, 1969. [WA] Weiler K., Atherton 
P., "Hidden surface removal using polygon area sorting", computer graphics (Pro,. SIGGRAPtt), July, 77. 
  :~~SIGGRAPH '89,Boston,31July-4August,1989 a; / i / /::::::ii! 5: aol l l ~ !~:i!:i Qo!ili!~i 
:~ii!i!~! i:~: ~" :; R a t d2 3f ~ ' 1tI 3g / 0: Background .7 Figure 4a a; Figure la: Input aI a" 
a, Figure lc: H3 ble .................. i~}\ w :: Q0 :" i" 2 i ! Figure Ib: H3 a: _/ Figure ld: conflicts 
in H3 t,,~t ,Roy1 07 Figure 4b Figure 3: a) Before removal of 1= (10,h) Figure 2: Region C (shown dotted) 
Figure 3: b) After removal of l  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1989</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

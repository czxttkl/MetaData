<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>08-08-1979</start_date>
		<end_date>08-10-1979</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Chicago]]></city>
		<state>Illinois</state>
		<country>USA</country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>800249</proc_id>
	<acronym>SIGGRAPH '79</acronym>
	<proc_desc>Proceedings of the 6th annual conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-004-4</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1979</copyright_year>
	<publication_date>08-08-1979</publication_date>
	<pages>317</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Theory</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP15032130</person_id>
			<author_profile_id><![CDATA[81100432746]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Tom]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[DeFanti]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P33614</person_id>
			<author_profile_id><![CDATA[81100577497]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>2</seq_no>
			<first_name><![CDATA[Bruce]]></first_name>
			<middle_name><![CDATA[H.]]></middle_name>
			<last_name><![CDATA[McCormick]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P329174</person_id>
			<author_profile_id><![CDATA[81100439572]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>3</seq_no>
			<first_name><![CDATA[Bary]]></first_name>
			<middle_name><![CDATA[W.]]></middle_name>
			<last_name><![CDATA[Pollack]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>PP95038263</person_id>
			<author_profile_id><![CDATA[81452608047]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>4</seq_no>
			<first_name><![CDATA[Norman]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Badler]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>PP39058581</person_id>
			<author_profile_id><![CDATA[81100315822]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>5</seq_no>
			<first_name><![CDATA[S.]]></first_name>
			<middle_name><![CDATA[H.]]></middle_name>
			<last_name><![CDATA[Chasen]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1979</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>807417</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[A tutorial on compensation tables]]></title>
		<page_from>1</page_from>
		<page_to>7</page_to>
		<doi_number>10.1145/800249.807417</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807417</url>
		<abstract>
			<par><![CDATA[<p>The generation of computer-shaded pictures requires that a program calculate intensities for each pixel. These intensities are then viewed on a monitor or transferred to film. It is desirable that the intensity values on the monitor or the reflectance values on the film have a linear relationship with the original calculated intensities both to give the user fine control over the appearance of the object and to do anti-aliasing properly. However, after the calculated intensity values are sent to the DAC'c some nonlinear distortions occur both in the CRT and on film. We can compensate for this by adjusting the intensity number just before digital-to-analog conversion. This compensation can be accomplished by a table lookup using the intensity as an index into the table and the corresponding value as the new intensity. Fortunately, most hardware manufacturers have made table lookup features part of their equipment. However, the entries in the table must still be generated. The methods for doing this are not well known in the computer graphics community. This paper presents an algorithm for generating a compensation table.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Compensation]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Film]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.10</cat_node>
				<descriptor>Intensity, color, photometry, and thresholding</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor>Reflectance</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P75663</person_id>
				<author_profile_id><![CDATA[81100160637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Catmull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Lab, New York Institute of Technology, Old Westbury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Heyl, Jack, A Digital Correction for Cross-absorption Photographic Dyes, master thesis, Dept. of Comp. Sci., Univ. of Utah, 1974]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Frei, Werner, Visual and Density Correction for CRT Film Recording, U.S.C. Image Processing Institute Report 620, Sept. 1975, p. 100-108.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A ~UTORIAL ON CCMPENSATION TABLES Edwin Catmull Computer Graphics Lab New York Institute of Technology 
Old Westbury, New York 11568 ABSTRACT The generation of computer-shaded pictures re- quires that a 
program calculate intensities for each pixel. These intensities are then viewed on a monitor or transferred 
to film. It is desirable that the intensity values on the monitor or the re- flectance values on the 
film have a linear rela- tionship with the original calculated intensities both to give the user fine 
control over the appear- ance of the object and to do anti-aliasing proper- ly. However, after the calculated 
intensity values are sent to the DAC'c some nonlinear distortions occur both in the CRT and on film. 
We can compen- sate for this by adjusting the intensity number just before digital-to-analog conversion. 
This compensation can be accomplished by a table lookup using the intensity as an index into the table 
and the corresponding value as the new intensity. For- tunately, most hardware manufacturers have made 
table lookup features part of their equipment. However, the entries in the table must still be generated. 
The methods for doing this are not well known in the ca~puter graphics co,munity. This pa- per presents 
an algorithm for generating a compen- sation table. Key words: computer graphics, compensation, film 
 CRclassification: 8.2 INTRODUCTION It is becoming increasingly common to transfer raster-scan images 
to film. The images produced on film should accurately represent the calculated computer model. However, 
because of various non- linear intensity distortions in the CRT and on film, we do not get the desired 
image. This aggra- vates the problem of aliasing in that methods for eliminating "staircasing" on edges 
are weakened. There are methods for correcting this distortion that are used in the image processing 
ccmmunity. These methods are not well known in the computer graphics community and are not found in computer 
graphics literature in sufficient detail to facili- tate implementation. This is unfortunate since the 
subjective improvement that results from proper compensation is very marked. In general, one corrects 
the distortion by us- ing a desired intensity value as an index into a table which has a new value to 
compensate for the nonlinearities. This table is called a compensa- tion table and is commonly implemented 
in hardware under such names as "color-map" or "color-table." See figure i. The problem we are confronted 
with is determining the values to be put into the com- pensation table. An algorithn for generating the 
table is presented here along with a justification for the necessity of compensation. compensation table 
 [ intensity ~ camera [_A Figure 1 An intensity value (0-255) is used as an index into the compensation 
table. The corresponding value from the table is sent to the DACs and on to the CRT. The table is filled 
with a value to precompensate for the nonlinearities introduced by the CRT and film.  A PHYSICAL MODEL 
 The importance of compensation can be under- stood by considering a physical model. We wish to create 
a diagram of white lines on a black back- ground by construction from photographic print pa- per. Lines 
then are thin strips of white paper pasted onto black paper. We wish to consider a small area of the 
diagram which may be partially or entirely covered by white paper. A useful characterization of this 
area is "re- flectance." Reflectance is the percentage of in- cident light reflected by the paper. It 
ranges from 0 (black) to 1 (white). Black photographic paper is not pure black; it reflects a small anount 
of light rmin. The white paper reflects most but not all of the light; call that reflectance rmax. Any 
image or portion of the image that is con- structed from these two papers must have a reflec- tance between 
rmin and rmax.  o1979 ACM O-89791-004--4/79/0800--001 $00.75 See Copyright Pg. I Consider a tiny square 
(which we shall later associate with a pixel. ) See figure 2. The area of the square is one. If the square 
is constructed of black paper over which we lay a small piece of white with area I, then the reflectance 
r of the square is dependent on I. With no white paper, I=0 and r=rmin. If the white covers the square 
then I=l and r=rmax. In general r=I*(rmax-rmin)+rmin. See figure 3. If we step back from our square 
so that it ap- pears very tiny then we cannot detect the internal arrangement of black and white pieces 
but we can detect the total reflectance r from that square, i.e. half white and half black will appear 
grey and we could replace the square with a piece of grey paper with the same reflectance. Now instead 
of constructing each square this way let us imagine that the diagram is modeled in a computer and we 
wish to expose undeveloped film to a generated raster image of the diagram such that the square corresponding 
to a pixel will have the sane reflectance. The computer can provide the I for each pixel depending on 
the model in the com- puter. Since the area exposed by the pixel can only have one value over its area 
and doesn't have an internal black and white structure, we can only require that the reflectance from 
the film be the same as if we had physically constructed the di- agram. pixel square black -'~. ------': 
:':-7. background ~c _ ---C L~:[~,~7 ..71~.< .. / : rmax  white/~/-//// rm:Ln i i n e @:-'~-:'/'-"~" 
 Figure 2 qlJe backgrouna is constructed from black paper. The ]Jne is of white paper. The square that 
we wish to consid6r is partly covered by whit~ paper. Now what happens if the square in the film re- 
flects too much light because of some nonlinear operation that happens to I on its way from the DAC's 
through the CRT to film. If too much light is reflected, then this is equivalent to having more white 
paper in the square than the computer has calculated. The error, which is the difference between the 
expected and measured reflectance, depends on I, i.e. there is no error at I=0 or I=l but there is error 
in between. The result is that a long straight edge at a slight angle appears "scalloped." So an anti-aliasing 
algorithm that correctly calculates the area of the white in each pixel can still get more staircasing 
than expected. This n~nber I which we called the area of the white in fact corresponds to intensity. 
There are many ways to calculate intensity, including the techniques used in shaded-surface algorithms. 
In all cases though we want intensity to be linearly related to the reflectance on print film, the tranamittance 
of projection film, or the intensity of a television monitor. (Transmittance can be treated the same 
as reflectance. ) We would expect the graph of reflectance vs. intensity to appear the same as in figure 
3. J rmax -~ measured I reflectance rmin - o o  area Figure 3 A graph showing the exE~cted reflectance 
from the square as a function of the pe_rcentage of the square that is v~ite. NONLINEARITIES There 
are several reasons that the intensity gets modified on its way to the final print: i. If the light 
from the CRT is controlled by vary- ing the intensity of the beam then the amount of light L produced 
by the phosphor is relateda~tO the intensity by a power law i.e. L = kl g under the right conditions. 
Since we want the light to be proportional to I, we could compen- sate by modifying I before send~am 
~ to the DACs. This function should be I " ~ . If, on the other hand, the beam is kept at constant in- 
tensity then the light L is controlled by vary- ing the length of time that the beam is on. Thus we easily 
get I=kL. 2. Even if the light L is proportional to I, film will still add distortion to the intensity. 
Ob- viously once the film is saturated, no addition- al light can make a difference. The relation- ship 
between exposure and reflectance is shown in figure 4. Since this relationship is fairly stable for a 
film we can again compensate I to make up for the distortion of film. ~4 ~4 intensity nLm~ber Figure 
4  3. There are some other bad things that can happen to I that we don't address in this paper: a. 
Beam bounce. Bright areas on the face of the CRTwill cause adjacent areas to be lit too.  b. Extra light 
- ambient light from the CRT in the canera assembly affects the film.  c. Color cross talk - sending 
light through a green filter will still affect the blue and red dyes, etc.  Fortunately, the effects 
of the CRT and film distortion can be compensated for in a single compensation table. The method presented 
here will take an existing compensation table and create a new m~re accurate one. HOW TO CORRECT FOR 
NONLINEARITIES For this discussion we assume that each entry of the table has 12 bits for a 12 bit DAC. 
AssLlne also that we have 8 bits for intensity. Thus the table has 256 entries. Let i := 1"255. So i 
is an index into the table. We wish to put in each location of the compen- sation table a value that 
will cause the desired reflectance from film. One way to do this is to display and measure all possible 
values. Then we can use the one that achieves the right reflectance for each i. Of course this is impractical. 
 A better method is to display from 8 to i0 in- tensities and then fit a curve to the measured values. 
We can then use the curve to determine the compensation values. Suppose we have a compensation table 
C. We display, measure, and plot certain values in figure 5 and then fit these values (x's) with a curve. 
The straight line represents the desired curve. Now we want to make a new table N that will give us a 
straight line. We can use the measured curve to determine the new values to put in N. For example if 
I=.6 then the desired reflectance is .6*(rmax- rmin) +rmin. This is the reflectance actually achieved 
at I=.3 when C is used. So N[.6"255] := C [. 3*255 ] . desired measured curve I rmax  rmir .3 .6 
I (desired intensity) Figure 5  This is so simple that one might wonder why compensation isn't mere 
widely implemented. Unfor- tunately there are some complications in the pro- cess. i. Since the eye 
and film are approximate loga- rit~ic devices, we would like the separation between intensity samples 
to also be logarithm- ic. i.e. with 8 bits we could use 1 2 4 8 16 32 64 128 255 It is not easy to 
fit a nice spline to these unevenly spaced sample points. However if we take the log of the index and 
plot it against density which is the log of the reflectance, then once again we have a straight line, 
but this time the sample points are evenly space making it easier to fit a spline. See figure 6. Devices 
for measuring density are readily avail- able. The densities can be easily converted to reflectance. 
The relationship is:(] d = -iogl0(r ) and r = i0 . 1.8 4~ ,,4 b9 log2i figure 6  2. The data may 
have inaccuracies. One approach is to use a least squares spline fit of a curve to the data. However 
the approach presented here uses a b-spline for simplicity. The b-spline will aproximate the data points 
but after one iteration of the correction process the data forms a nearly straight line so that the approx- 
imating spline is very close to the points and performs a little smoothing. Before using any measured 
data points it is wise to plot them as in figure 6 to check for bad data. It may be necessary then to 
"correct" the data by hand. The density curve may be S shaped (see figure 6) but it should not be lumpy. 
 PRELIMINARY SETUP There are several variables involved in any CRT-photographic system including brightness, 
gain, intensification time, and f-stop. We wish to ad- just these in order to fully use the dynamic range 
of the film, the range of computer intensity ntm%bers, and to fully expose the film in a reason- ably 
short period of time. i. The stepwedge We must have some progran for generating test and calibration 
patterns. One such program would display a flat field of one color. Anoth- er is a program which generates 
a pattern of rectangles for measuring. See figure 7. For the method we use here ten areas are generated 
from black to white: I = 1/512, 1/256, 1/128, 1/64, 1/32, 1/16, 1/8,  1/4, 1/2, 1 These are converted 
to indices into the compen- sation table. For ease of arithmetic we call 256 the largest index even though 
it is really 255, except at 255 itself. Also since we cannot have a partial index we approximate the 
index 1/2 with zero. The resulting indices are: 0, i, 2, 4, 8, 16, 32, 64, 128, 255 A sample stepwedge 
is shown in figure 7. The extra information in the figure is a plot of the conpensation table and a wedge 
of all 256 en- tries.  2. Brightness  Display a zero flat field and examine the face of the CRT by 
eye in a darkened room. The brightness should be adjusted so that the field is just below the threshhold 
of visibility. This provides a convenient reference point: any future use of the CRT should be preceded 
by this calibration. Setting the zero flat field to visual cutoff also ensures that the CRT is a power 
law device.  3. Gain and f-stop  The CRTgain and camera lens opening should be adjusted so that a 
white square just fully sa- turates the film. Care must be taken not to overload the phosphor. If too 
much light is provided to the film then the resulting compen- sation table will waste bits and intensity 
quantization can result. If the square from i=128 appears almost the same as for i=255 then there is 
too much light.  4. Garma  If a time modulated recorder is used (eg. Di- comed D48) then it should 
be put into a linear mode and no further concern need be paid to gam- ma. For intensity modulation, the 
densities should be read from a step wedge made using a linear C. Then the densities should be plotted 
as D vs LOgl^i. The average slope of the curve is gamma, uIt will probably be around 3. The precision 
display at the University of Utah had a gamma of 3. The color tv monitors at NYIT have 2.3 as gamma. 
Typically gamma is 1 for a time modulated display, 2.3 for a color tv moni- tor, and 3 for a precision 
intensity modulated display. This gsmma should be used to make a first guess at a table C.  THE PROCEDURE 
 i. Make a preliminary compensation table C[i] := (i/255)i/gamna*dacmax  where gsmma is i, 2.3, or 
around 3 as discussed above and dacmax is maximomvalue to go to DACs (4095 for 12 bits). 2. Set CRT 
to correct brightness and gain.  3. Take photograph of stepwedge.  4. Measure the ten densities from 
black to white and enter into a table D.  5. Plot D and hand correct data errors.  6. If the plot 
of D vs. Loggi is a straight line  (see figure 9) then you are done. C is the correct compensation table. 
If only the left couple of values are off then it is not serious. If the plot of r vs. i looks itm~py 
then some bad data points have thrown things off and the pro- cess should be restarted.  7. Calculate 
a new table N using C and D.  8. Replace C with N and go back to step 2.   Figure 7 shows the compensation 
table, stepwedge, density data, and density and intensity plots for the time modulated display at NYIT 
where gamma is i. Figure 7 also shows the new compensa- tion table. Figure 8 shows the resulting compar- 
able data and plots. Figure 9 shows a last itera- tion for a final compensation table. The smooth wedge 
below the stepwedge shows a slight problem with quantization (although this may not show up in the reproduction 
of this article.) This is because our film recorder has only 8 bits resolution in in- tensity. THE ALGORITHM 
 i. We already have the table C used to make the stepwedge and table Dwhich has ten entries with D[0] 
corresponding to i=0 and D[9] to i=255. A b-spline is used to approximate the densities. We are going 
to fill the table N. 2. Calculate rmin and rmax from D[9] and D[0].  3. Loop through each entry of 
N. N[i] should cause a reflection of: r = (rmin- rmax) (i/256.-I) / (i/5!2.-i) + rmax This is slightly 
different from the (rmax-rmin) (i/255) + rmin suggested above and is used because the highest density 
corresponds to 1/2 instead of 0. This is necessary to make the math work out. We are looking now for 
the entry in C that would create r.  4. Convert r to density by:   d = -lOgl0(r)  Use an iterative 
procedure to find the fraction- al index j into D where the value can be found. j varies between 0. and 
9. j = logg(n) therefore n = 23. so n varies between-0 and 255 but is fractional. Since n is fractional, 
the desired value is: k := integerpar t (n) fp := n-k N[i] := C[k] + fp*(C[k+l] - C[k])  A PROGRAM 
 To facilitate implementation, the algorithm is presented here in a presentation lanquage. (The actual 
implementation is in the language C.) Note that: -C is the old compensation table. - D is a table of 
i0 density readings with D[0] be- ing the largest value, D[9] being the smallest, the values are monotonically 
decreasing, and bad data points have been fixed. The user should have the code check for monotonicity 
of the den- sities since it is likely that D[0] through D[2] will not be decreasing. - N is an array 
that will get the new compensation table. -The user has provided a plot routine. -comments are enclosed 
by /* and */ procedure makecomp(C,D,N) real array C[0:256],N[0:255],D[0:I0]; begin real rmin,rmax,r,f,a,fp; 
integer i,j,imin; /* extend last entry of tables * to set up for method of spline used */ D[10] := 
DIg] + (D[9] - D[8]); C[256] := C[255]; /* get reflectance extremes */ -a rmin := 10.~'(-d[0]); /* i0 
~[0] */ rmax :-- 10.T(-d[9]); /* make new table */ N[0] := C[0]; for i:=l step 1 while i<=255 begin 
 /* calculate desired reflectance */ r : =(rmin-rmax) *( i/256. -i) / (i./512-1) +rmax; /* find fractional 
index into D */ f := search(D,r) -i; /* find index into.C that produced r */ a := 2if; /* 2 r */ if(f<0)a 
:= f+l; /* if near high density */ j := intpart(a); /* integer part */ fp :-- a-j; /* fractional part 
*/ N[i] := (l.-fp)*C[j] + fp*C[j+l];  end; end; /****** search ****** * find fractional index into 
D that aives  * requested reflectance.  */ real procedure search(D,r) real array D[0:10]; real r; 
 begin real den ,dleft,dr ight, xleft,xr ight ,x ,ddif ,datx; integer i; /* note: as index increases, 
D[x] decreases */ den := -logl0 (r) ; dleft := d[0] ; dright := d[9]; if(den eq dleft ) return(0.); if(den 
eq dright) return(l.); xleft := 0. ; xright := 9. ; /* iterate up to I0 times to find index */ for i:=0 
step 1 while i <= 9 begin ddif := dright - dleft; if( -ddif < .0001) exitforloop; /* estimate x by linear 
interpolation */ x := (den-dleft)*(xright-xleft)/ddif+xleft; /* now see how close we are */ datx := 
getden(D,x) ; if(datx < den) begin dright := datx; xright := x; end else begin dleft := datx; xleft := 
x; end;  end; return (x) ; end; /****** getden ***** * Get the density at a particular fractional 
index.  * Fit a b-spline to the four points  * surrounding the index x.  */ /* Preload the 4 by 
4 matrix m for the b-spline */ real array m[0:3] [0:3] { -i., 3.,-3., i., 3.,-6., 3., 0., -3., 0., 3., 
0.,  i., 4., i., 0.  }; real procedure getden(D,x) real array D[0:9] ; real x; begin int index,i,j 
; real t; real array p[0:3] ,temp[0:3] ; index := intpart(x); / z*--Tntnteger part */ t := x - index; 
/* fractional part */ /* pick off the surrounding four points */ for i:=0 step 1 while i<4 p[i] := D[index-i+l]; 
 /* calculate 4 coefficients of cubic curve */ for i:= 0 step 1 while i<4 begin temp[i] = 0. ; for j:=0 
step 1 while i<4 temp[i] := temp[i] + m[i][j]*p[j]; end;  /* use fraction as parameter into curve */ 
return ( (t*t*t*temp[0] +t*t*temp[l] +t*temp[2]+temp[3] )/6) ; end;   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807418</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Color table animation]]></title>
		<page_from>8</page_from>
		<page_to>13</page_to>
		<doi_number>10.1145/800249.807418</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807418</url>
		<abstract>
			<par><![CDATA[<p>Even a small amount of animation can greatly enhance graphic communication&#8212;particularly when it is desired to show change, movement, or a complex idea or relationship. In raster scan display systems, however, the cost of providing animation has usually been prohibitively high due to the large bandwidths involved in changing a picture rapidly. This paper describes a simple method for providing a limited but very useful real-time interactive animation capability on many existing frame buffer systems. Color table animation relies on changing only the colors of objects and areas present within a single, static picture via the frame buffer's color table RAM. Several variations of this technique are discussed and examples are given of such a capability in use for illustration, educational animation, and television graphics.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color table]]></kw>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Frame buffer]]></kw>
			<kw><![CDATA[Raster scan]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Bitmap and framebuffer operations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Color</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P242985</person_id>
				<author_profile_id><![CDATA[81100366482]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Shoup]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>807375</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Weinberg, R. Computer Graphics in Support of Space Shuttle Simulation. Proc. ACM Siggraph '78, Computer Graphics 12, 3 (Aug. 1978), 82-86]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563870</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hackathorn, R.J. Anima II: A 3-D Color Animation System. Proc. ACM Siggraph '77, Computer Graphics 11, 2 (Summer 1977), 54-64.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563871</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Levoy, M. A Color Animation System Based on the Multiplane Technique. Proc. ACM Siggraph '77, Computer Graphics 11, 2 (Summer 1977), 65-71.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Goldstein, R. A System for Computer Animation of 3-D Objects. Proc. 10th Annual UAIDE Meeting (1971).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807414</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. The Problems of Computer-Assisted Animation. Proc. ACM Siggraph '78, Computer Graphics 12, 3 (Aug. 1978), 348-353.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563281</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Baecker, R. M. A Conversational Extensible System for the Animation of Shaded Images. Proc. ACM Siggraph '76, Computer Graphics 10, 2 (Summer 1976), 32-39.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Honey, F.J. Artist-Oriented Computer Animation. J. Soc. of Motion Picture and Television Engineers, (March, 1971).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Faust, M. Stanford University Artificial Intelligence Laboratory, private communication.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lippman, A. MIT Architecture Machine Group, private communication.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Knowlton, K. Color display on the DDP-224 computer, private communication.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T., Sutherland, I. E., and Cheadle, E. C. A Random Access Video Frame Buffer. Proc. IEEE Conf. on Computer Graphics, Pattern Recognition and Data Structure, (May 1975) 1-6.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[9000 Series Display Systems, Ramtek Corporation, 585 North Mary Ave., Sunnyvale, CA 94086.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807361</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R. Color Gamut Transform Pairs. Proc. ACM Siggraph '78, Computer Graphics 12, 3 (Aug. 1978), 12-19.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807362</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Joblove, G. H. and Greenberg, D. Color Spaces for Computer Graphics. Proc. ACM Siggraph '78, Computer Graphics 12, 3 (Aug. 1978), 20-25.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Shoup, R. G. Some Experiments in Television Graphics and Animation Using a Digital Image Memory. Presented at the 13th Television Conf. of the SMPTE and published in Digital Video Vol. II, SMPTE, Scarsdale, 1979, 88-98.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COLOR TABLE ANIMATION Richard G. Shoup Xerox Palo Alto Research Center Palo Alto, CA ABSTRACT Even 
a small amount of animation can greatly enhance graphic communication --particularly when it is desired 
to show change, movement, or a complex idea or relationship. In raster scan display systems, however, 
the cost of providing animation has usually been prohibitively high due to the large bandwidths involved 
in changing a picture rapidly. This paper decribes a simple method for providing a limited but very useful 
real-time interactive animation capability on many existing frame buffer systems. Color table animation 
relies on changing only the colors of objects and areas present within a single, static picture via the 
frame buffer's color table RAM. Several variations of this technique are discussed and examples are given 
of such a capability in use for illustration, educational animation, and television graphics. Key words 
and phrases: computer animation, color table, raster scan, frame buffer, computer graphics. CR Categories: 
8.2, 3.41, 3.11. INTRODUCTION The value of dynamics in visual communication is great. It is said that 
a picture is WOrth a thousand words (more than ten thousand, according to the old Chinese proverb), and 
a picture which moves is often worth at least a thousand static pictures. Despite recent technological 
advances and reductions in the cost of digital hardware, animation is still prohibitively expensive or 
impossible in most raster scan display systems. For systems where significant animation is required, 
off-line or non-real-time generation of the images is often necessary. While these approaches can be 
completely general, they lack the powerful capability of interactively editing and manipulating the animation 
as it is being created, Direct updating of a frame buffer image generally requires a large amount of 
bandwidth. A typical frame buffer picture is represented by over 2 Mbits of pixel data (480 x 640 x 8 
bits/pixel, for example) which must be updated at a rate of at least 10 frames per second for reasonably 
smooth animation. Thus at least 20 Mbits/sec must be transferred more or less continuously in order to 
provide animation by this direct update approach. Very few frame buffer systems can support such a data 
rate from CPU to frame buffer, no less from disk or other secondary storage. There are several ways in 
which dynamics and animation have been achieved in raster scan display systems: 1. The picture can be 
computed on-the-fly from a higher-level data structure. Using real-time hardware and perhaps also double-buffering 
of the image, new frames are continuously scan-converted from the object data structure. This general 
approach has been used extensively, for example, in visual flight simulators where the data structure 
consists of polygons in 3-space t. While a certain degree of real-time interaction is hereby provided, 
this type of system requires large computing power obtained via special-purpose hardware and is consequently 
very expensive by comparison to a static display of the same data base, 2. Various methods can be employed 
to reduce tile real- time picture update bandwidth to the range which can be supplied from secondary 
storage 2. Such methods include run-length or other encoding of pixel data, reduced resolution, updating 
only changed elements, structured overlays, etc. Thus a representation which is close to the final picture 
data can be computed, stored on disk and later played back in real-time. This approach usually requires 
a high-performance disk memory and a small amount of special-purpose hardware. More important, non-real-time 
picture generation severely limits the interaction possible during creation of the animation and therefore 
requires much greater predictive skills on the part of the user (just as in conventional cel animation). 
A separate outline or "pencil test" capability 3 may also be provided which permits previewing in real 
time. 3. A frame-at-a-time recording device such as a video  disk or film camera can be used to record 
the already-computed or assembled frames at a rate less th~,n real- time and later play them back at 
full speeof 4,~'. This recording device is often expensive compared to the computing and display hardware 
itself. Again the interactive possibilities are very limited. 4. Another real-time approach has been 
implemented in a personal computer 6 where the images are composed of overlaid bit-maps, albeit in black/white 
(1 bit/pixel) and at fairly low resolution (256 x 256) and update rate (3-10 frames/sec). In this case, 
the hand-drawn bit-map &#38;#169;1979 ACM O-89791-004--4/79/0800--008 $00.75 See Copyright Pg.  Thus 
an object drawn with two colors plus background could ACKNOWLEDGEMENTS move or deform arbitrarily in 
a five-frame animation cycle. In practice, however, the number of areas actually necessary is often much 
less than this limit since not all areas intersect all others during motion. Thus, more frames and/or 
more colors than indicated here may be possible depending on the content of the animation. While only 
a small number of colors and frames can usually be handled in this way, there are no restrictions on 
the kind of motion possible. APPLICATION AND EXAMPLES The system utilized to create these illustrations 
and examples was built in 1973 and developed subsequently at the Xerox Palo Alto Research Center by this 
author and is known informally as "SuperPaint "15. It provides an image of 480 x 640 pixels in a standard 
525-1ine raster at 8 bits/pixel with a 256-word 10-bit/component color table. The color table can be 
updated by the program during both vertical and horizontal blanking intervals. The system can also be 
configured as two 4-bit/pixel frame buffers, each with its own 16-word color table and separate D/As 
and RGB video outputs. Standard composite video is also available via an NTSC encoder. Hardcopy output 
is provided via a laser-driven xerographic color printer. The usual mode of operation maintains the menu 
or control panel picture in one frame buffer and the new image being created in the other, The SuperPaint 
software provides several different types of color table animation with interpolation, color space editing 
and variable speed and cueing control Painting or pointing into the picture (with an arrow-shaped brush, 
for example) can take place while the animation is running in real time. In the SuperPaint program, ten 
colors are used for cycling and animation and six are static or background colors. It is worth noting 
that only ten animating colors (or ten steps in the animation) have proved to be quite sufficient for 
most simple cartoon-like animated graphics of this type. Figures 6a through 6d show various examples 
of color table animation created for the NASA Pioneer Venus mission in December 1978 and seen widely 
on television news broadcasts. Figures 7a and 7b show diagram examples created recently for the PBS television 
series "Over Easy". CONCLUSIONS Color table animation is a useful and inexpensive technique for creating 
real-time dynamics and animation in a frame buffer display system. Our application here is not continuous, 
story-telling animation, but rather short self-contained graphic communications such as diagrams, illustrations 
for talks, charts, title sequences, transitional material, effects, etc. Although the animation available 
by this means is somewhat limited, it is more than adequate to convey a rich variety of graphical ideas 
and concepts. I would like to thank Bob Flegal for his early versions of this idea and Damon Rarey for 
his enthusiastic use of the system as a real graphic arts tool. REFERENCES 1. Weinberg, R. Computer Graphics 
in Support of Space Shuttle Simulation. Proc. ACM Siggraph "78, Computer Graphics 12, 3 (Aug. 1978), 
82-86 2. Hackathorn, R.J. Anima I1: A 3-D Color Animation System.  Proc. ACM Siggraph "77, Computer 
Graphics 11, 2 (Summer 1977), 54-64. 3. Levoy, M. A Color Animation System Based on the Multiplane Technique. 
Proc. ACM Siggraph "77, Computer Graphics 11, 2 (Summer 1977), 65-71. 4. Goldstein, R. A System for 
Computer Animation of 3-D Objects. Proc. lOth Annual UAIDE Meeting (1971). 5. Catmull, E. The Problems 
of Computer-Assisted Animation. Proc. ACM Siggraph "78, Computer Graphics 12, 3 (Aug. 1978), 348-353. 
 6. Baecker, R. M. A Conversational Extensible System for the Animation of Shaded Images. Proc. ACM Siggraph 
"76, Computer Graphics 10, 2 (Summer 1976), 32-39. 7. Honey, F.J. Artist-Oriented Computer Animation. 
J. Soc. of Motion Picture and Television Engineers, (March, 1971). 8. Faust, M. Stanford University 
Artificial Intelligence Laboratory, private communication. 9. Lippman, A. MIT Architecture Machine Group, 
private communication. 10. Knowlton, K. Color display on the DDP-224 computer, private communication. 
 11. Kajiya, J. T., Sutherland, I. E., and Cheadle, E. C. A Random Access Video Frame Buffer. Proc. IEEE 
Conf. on Computer Graphics, Pattern Recognition and Data Structure, (May 1975) 1-6. 12. 9000 Series 
Display Systems, Ramtek Corporation, 585 North Mary Ave., Sunnyvale, CA 94086. 13. Smith, A. R. Color 
Gamut Transform Pairs. Proc. ACM Siggraph 78, Computer Graphics 12, 3 (Aug. 1978), 12-19. 14. Joblove, 
G. H. and Greenberg, D. Color Spaces for Computer Graphics. Proc. ACM Siggraph "78, Computer Graphics 
12, 3 (Aug. 1978), 20-25. 15. Shoup, R. G. Some Experiments in Television Graphics and Animation Using 
a Digital Image Memory. Presented at the 13th Television Conf. of the SMPTE and published in Digital 
Video Vol. I_1, SMPTE, Scarsdale, 1979, 88-98.  i2 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807419</article_id>
		<sort_key>14</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[An improved illumination model for shaded display]]></title>
		<page_from>14</page_from>
		<doi_number>10.1145/800249.807419</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807419</url>
		<abstract>
			<par><![CDATA[<p>To accurately render a scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of &#8220;rays&#8221; extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. The visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Raster displays]]></kw>
			<kw><![CDATA[Shading]]></kw>
			<kw><![CDATA[Visible surface algorithms]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P285628</person_id>
				<author_profile_id><![CDATA[81100586999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Turner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitted]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Bell Laboratories, Holmdel, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Improved Illumination Model for Shaded Display Turner Whitted Bell Laboratories Holmdel, New Jersey 
07733 ABSTRACT To accurately render a scene, global illumi- nation information that affects the intensity 
of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, 
this information is stored in a tree of "rays" extea~ing from the viewer to the first surface e!aeountered 
and from there to other surfaces and to the light sources. The visible surface algo- rithm creates this 
tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to 
determine the intensity of the light received by the viewer. Considera- tion of all of these factors 
allows the shader to accurately simulate true reflection, shadows, and refraction as well as the effects 
simulated by con- ventional shaders. Anti-aliasing is included as an integral part of the visibility 
calculations. Sur- faces displayed include curved as well as polygo- nal surfaces. KEY WORDS AND PHRASES: 
computer graphics, computer animation, visible'surface algorithms, shading, raster displays CR CATEGORIES: 
8.2 &#38;#169;1979 ACM O-89791-004--4/79/0800--014 $00.75 See Copyright Pg. 14 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807420</article_id>
		<sort_key>15</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Some raster graphics extensions to the Core System]]></title>
		<page_from>15</page_from>
		<page_to>24</page_to>
		<doi_number>10.1145/800249.807420</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807420</url>
		<abstract>
			<par><![CDATA[<p>The Core System is a proposed standard subroutine package for line-drawing graphics. We present some Core System extensions for use with raster graphics equipment. The extensions, which are upward-compatible with the present Core System, provide filled polygons, display of arrays of pixels, use of a color look-up table, and hidden-surface or hidden-edge removal. The extensions are being intergrated into an existing Core System implementation.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Core system]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
			<kw><![CDATA[Raster displayes]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P132223</person_id>
				<author_profile_id><![CDATA[81100302796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Foley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The George Washington University, School of Engineering and Applied Science, Department of Electrical Engineering and Computer Science, Washington, D. C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14017996</person_id>
				<author_profile_id><![CDATA[81100013771]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Templeman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The George Washington University, School of Engineering and Applied Science, Department of Electrical Engineering and Computer Science, Washington, D. C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P329722</person_id>
				<author_profile_id><![CDATA[81100103805]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dara]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dastyar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The George Washington University, School of Engineering and Applied Science, Department of Electrical Engineering and Computer Science, Washington, D. C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H., Prown, B., and McLary, L. "A General Purpose Computer Graphics Display System for Finite Element Models", Light, Shock and Vibration Bulletin, Part 5 (August 1976), 61-66.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Foley, J., Templeman, J. and Dastyar, D. Study of Raster Extensions to GCS, final report to Waterways Experiment Station, Contract DACA39-78-M-0073, August 1978.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Foley, J., Templeman, J. and Dastyar, D. Reference Manual - Raster Extensions to the Core System, George Washington University, EE &amp; CS Dept., Washington, D. C. 20052, December 1978.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fulton, D.L. and Duquet, R.T. "List Processing Primitives for BASIC", Computers and Graphics 1(2/3), September 1975, pp. 203-210.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. "Computer Display of Curved Surfaces", IEEE Transactions on Computers C-20, 6 (June 1971), 623-628.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Status Report of the Graphics Standards Planning Committee of ACM/SIGGRAPH. Published as Computer Graphics 11 (3), Fall 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Second Status Report of the Graphics Standards Planning Committee of ACM/SIGGRAPH. To be published in Computer Graphics.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA["Guidelines for Initiation of a Program for Graphics Standards and a Graphic Standards Planning Committee", Computer Graphics 8, 2(Summer 1974), 19-20.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[IGPL - Interactive Graphics Programming Language User's Reference Manual. NORPAK Ltd., Pakenham, Ontario, Sept. 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807362</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Joblove, J.H. and Greenberg, D. "Color Spaces for Computer Graphics", SIGGRAPH '78 Proceedings, published as Computer Graphics 12, 3 (August 1978), 20-25.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356747</ref_obj_id>
				<ref_obj_pid>356744</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Michner, J., and van Dam, A. "A Functional Overview of the Core System with Glossary", Computing Surveys 10, 4 (December 1978), 381-388.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356746</ref_obj_id>
				<ref_obj_pid>356744</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Newman, W. and van Dam, A. "Recent Efforts Toward Graphics Standardization", Computing Surveys 10, 4 (December 1978), 365-380.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563740</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[O'Brien, C.D. and Fown, H.H. "IMAGE: A Language for the Interactive Manipulation of a Graphics Environment", SIGGRAPH '75 Proceedings, published as Computer Graphics 9 (1), Spring 1975, pp. 53-60.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. GPAC User's Manual, University of Toronto, Department of Computer Science, January 1977.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807361</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Smith, A.R., "Color Gamut Transform Pairs", SIGGRAPH '78 Proceedings, published as Computer Graphics 12, 3 (August 1978), 12-19.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sproull, R., and Newman, W. "The Design of Grey-Scale Graphics Software", Conference on Computer Graphics, Pattern Recognition and Data Structures, IEEE, 1975, 18-20.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 50~E RASIEh G~APHICS F~T~NSICNS TO IFF COliF SYSI+EN Jan.as D. ~o]ey James N. ~en,plen, an Dare Dastyar 
 ?he Ceorge kashin~ton Cniversity School of En~ineerin~ and Applied Science bepartn,ent ol Electrical 
En~ineerin~ and Co, puter Science Washington, L. C. 20052 ~BS]FAC] lhe Core System is e proposer standard 
subroutine package for ]ine-drawinF Eraph- ice. We present some Core System exten-sions for use with 
rester Fraphics eouip- mont. The extensions, which are upward-compatible with the present Core System, 
provide filled pclypons, display cf arrays of pixe]s, use of e color ]ook-,p table, and bidden-surface 
or hidden-edge removal. The extensions are beinF interpreted into an existin Core System implementation. 
KF~ WORDS A~D PHRASES: Interactive Graphics,Core System,Raster Cisp]ayes C~ C~l ECOI~JES: 6.2 ~. Introduction. 
]wo trends in ccmputer ~raphics have motivated the work reported here. lhe first treno is the development 
of portable, device-independent graphics subroutine packages for use with various line-drawiog graphics 
devices, beth passive and interactive. This trend has most re- cently focussed on the Core System, a 
pro- posed standaro graphics subroutine package [GSPC??]. The Core System is making e sub- stantial in:pact 
on the current development of national and international standards. ]he second trend is the emergence 
of raster Fraphics hardware from its tradi-tional domains of image display and process control into the 
world of interactive ~rephics. ]his has occurred becet, se of rapid cbanEe in the economics of ]erre 
scale intepreted circuits and because cf user devend for the color and shaded ~rees so easy to provide 
with rester prephics end so difficult to provide with ]Jne-drewinF prephics. ~n some applications, raster 
graphics is e very natural complement to line-drawinF graphics, while Jn cther ap- plications, raster 
graphics will sooner or later replace line-drawing graphics. Still other applications, never considered 
prac-tical with line-drawin~ graphics for rea-sons of either economics or display aes-thetics, suddenly 
become feasible with raster graphics. Consioerable effort has been devoted to developing standard software 
for line- drawing graphics, while in the meantime raster graphics has been growing at 8 rapid pace. ~his 
is not unexpected, because standards of necessity lag the technology. It was in recognitio5 of" this 
lag end of the rapid developments and changes in raster graphics that the original charter for development 
of a standard explicitly excluded rester ~raphics [GULF74]. Now, however, there is bot~' a modicum of 
stab- ility in raster graphics concepts end a sizable bose of inst~lled rester displays. Pence now is 
the time to start worPinp to-ward standard software for rester Frephies. 2. ~ Protctypice] Rester Display 
System. lee Core Systev extensions sin" to ,eWe ef- fective use of the prototypical raster disp]ay shown 
in Fi@ure I. The imeEe crea- tion system processes 2D entities such as lines, text, points, and areas. 
]~s output is placed in the refresh buffer as the pixel values needed to cause the entities to be displayed. 
The refresh buffer has a 2L organization, with each row correspond- ing to a scan-line ol the raster 
display. ]he size o~ the re,rash buffer and number of bits per pixel varies from one system to another. 
 the image display system reads the refresh buffer in synchronism with a TV raster scan, usinp the pixel 
values to control the color or intensity of points on the display screen. ~n optional leak-up table in 
the image display system con dynan, ically assign intensities or colors to llhis wcrk v~as sponsored 
F, rir, eri~]]y by I'aticne] Peronal;tics and S[ece #dministre-tion, ~rant DLC 156~, and by the Weterways 
kxFerir(ent ~taticn, Contrect CACA39-?@-F- CC?3. pixel values. There is a fixed 1-I cor-respondence between 
pixels in the refresh buffer and points on the display screen (some contemporary raster systems do not 
impose this restriction). The interaction system a]]ows devices such as keyboards and tablets to be used, 
with appropriate feedback being disp]ayed on the screen. Text is typically echoed on the screen, while 
tablets and ~oysticks control the position of a cursor on the screen. Raster display systems with other 
or-ganizations, such as COP fi]m recorders, can also be aoapted to this model. There is, however, a fundamental 
mismatch between a refresh buffer system and COP systems. In the former, a pixel's color is the cne most 
recently displayed, while in the latter, the color is based on subtractive mixing of all the colors displayed 
at the pixel. ~ Related ~ork. Several line-oriented graphics packages with some raster graphics capabilities 
have been implemented. In all eases, the packages' basic intent is to create computer-synthesized images, 
taking advantage of raster systems' ability to display solid areas. In a 2D package developed by Sprou]] 
and Newman [SPRC75], a polygonal area is specified by calling the procedure F]IL- PEGIN, followed by 
a seouence of [,INK or LI}[ETO procedure invocations to define the polygon, followed finally by F]LLFN[ 
to mark the end of the polygon. Polygons and other output prinitives are contained in segments, whose 
nun'eric name is used to deternine the priority (hence visibility) of overlapFing primitives. Within 
a seg- ment, temporal sequence determines visibi-lity of overlapped primitives: the most recently created 
primitive obscures others. Pulton and Duquet added 2D area-oriented output primitives (circles, tri-angles, 
rectangles) to ~ASIC for use with a plasma panel display [FULT?5]. Each prim- itive can be erased by 
respecilying the parameters used to generate it. ]his allows the appropriate cells of the plasma panel 
to be turned off. If several prim-itives overlap, temporal seauence deter-mines which cells are turned 
off by an erasure. The 2D Interactive Graphics Program- ming Language (GPL), first deve]oped by O'~rien 
and Pown [O~RI75], is now provided with raster extensions by a raster syste~ manufacturer [IGPL77]. The 
system cur-rently allows filled rectangles to be drawn, and is bein extended to include convex and concave 
polyFons. ]he syste, provides a segment-like facility to group outi~ut primitives. Temporal sequence 
of creation determines visibility of overlap- ping primitives. GPAC, a 2D system developed by Reeves 
[REEV77], uses the FILLBEGIN...FILLEND construct to define polygonal areas. Seg-ments have a depth attribute 
which is used to determine visibility when output prim- itives from different segments overlap. ~ithin 
a segment, temporal order of crea-tion determines visibility. The FO~IE.BYU system developed by Christiansen 
[CHRS76] is a ~D package which allows objects defined by polygons to be disp]ayed on a vector or raster 
display. ]he package by itself is output-oriented: interacive construction is not supported. Pany manufacturers 
of raster displays provide support software for their equip- .,ent, often in the form cf microprocessor 
~OPis. The software is 2D, with temporal priority. 4. Design Objectives. The most funda-n ental design 
objective of this work has been to extend the Core System for raster graphics in a fashion compatible 
with the design objectives cf the Ccrc System it-self, so that the extended systen: might possess a conceptual 
integrity in its own right. ]hose objectives, summarized in [NEWk?6] and detailed in [CSPC??], demand 
that simplicity, mini, ality of function (but without substantial loss of capabili- ty), and consistency 
be sought. A second design objective has been for the raster extensions to Ee ,yward- ccmI'atib]e with 
the Core System. ]'Dis ob- jective derives in part from our use of the Core System as a startin~ point, 
but in more substantial measure from the belief that vector and raster ~raphics will exist side-by-side 
in many enviroments, sug- gesting that the sarJ~e graphics package support both classes of systenLs. 
Another najor design objective has been to do hid- den surlace removal cn the basis of either temporal 
priority (for 2D) or depth (for 3b). interactive raster display systems and many applications ol raster 
graphics use temporal priority, while other applications (such as co~Futer aided design) require 3D-based 
hidden surface removal. l~aster graphics also implies the need for color and intensity specifications, 
filled areas, and the display of digitized inages created by cameras, X-rays, radars, etc. The look-up 
table found in ~any raster image displ2y systeps is a]so intergrated into the extensions, but as an option, 
because not all systems have such a table. The extensions do mot include the ]igFtinv mcde]s which would 
allow surface shading to be calculated by the extended Core System. Lighting models and surface texturing 
models are considered as hi,her-level capabilities, just as ,odel- lJnF was considered a hinDer-level 
cape- 16 bility with respect to the Core System [GSPC773 . Furthermore, these are stil. active research 
areas in their own right, 5. 1he baster Graphics Extensions. In this section our raster extensions to 
the Core System are described. The extensions fall into several areas, each of which is treated in a 
separate subsection. In some subsections several design alternatives are discussed, with a more detailed 
discussion of the selected alternative. ~ reference manual defining the details of each sub-routine in 
the extensions is available [FOLE78b]. 5.1 Hidden Surface Femova]. The Core System currently has no capabilities 
for defining surfaces, so bidden surface and hidden edge removal have never been con-sidered. }lowever, 
this capability is central to effectively using raster graph-ics. The key Question here is how the ap-plication 
proprammer tells the graphics package which surfaces obscure other sur- faces. ~here are several possible 
solu- tions. 1he simplest soluton is temporal priority: the most recently displayed output ~rimitives 
obscure overlapped, less recently displayed output primitives. ]his is particulerly easy to implement, 
and works equally well for 2D or 3D output primitives. ~he temporal priority is ap- plied to the image 
of the primitives on the view surface. ]f the primitives are ~D, the image is of course a projection 
 into 2D. Alternatively, segments or output primitives can explicitly be assigned pri-orities. For eoua] 
priorities, temporal sequence is used. If the priorities are associated with segments, they could be 
treated as dyna,;ic segnent attributes, and hence could be changed For 3P systems, there is only one 
generally viable alternative: the X,Y,Z World Coordinates of the objects and the viewing specification 
are used by a hidden surface ~lgorithn to create the proper i~age. We call this 3D priority. For this 
3D priority there is a ~ro- blen, with multiple segments. In the Core System, many segments can simultaneously 
be displayed on the view surface, and each segnent can have a different viewing spec-ification. The synthetic 
camera analogy of the Core System is useful in motivating the difficulty in dealing with multiple seg-n~ents. 
Each segment and its viewing spec-ification defines a "photograph" which is displayed within e viewport 
on the view surface. When several viewports overlap or are identical (frecuent]y the c~se), the pbotoprapbs 
cver]ep on the v~ew surface. For ]ine-drewjnps, this J s no problem, since eec~ pbetcFreFh is jt~st a 
cc]]ectiep of lines, add one photopraph does not obscure another. For raster graphics, a photograph can 
include filled areas, which can obscure lines and other filled areas. hidden surface removal must consider 
all segments defining the object. One way to permit this is to define a second level of structuring 
in the Core System -a collec- tion of segments, liidden surface removal in 3D would be done on each 
such collection of segments. ]his approach is unaccepta- ble, because it would introduce a second level 
of structuring to the Core System. Furthermore, the priority of the photo- graphs produced by each 
such collection of segments could still be unresolved. We have developed a way to include temporal 
priority, explicit priority, and ~D priority in the extensions, and to solve the overlapping viewport 
problem. We use some of the concepts from ].eve] ~ of the Core System, in which the viewing trans-formation 
specifies not a prbjection from ~D World Coordinates into a rectangular 2D normalized device coordinate 
viewport on the view surface, but rather specifies a transformation from 3D World Coordinates onto a 
3D solid rectangular viewport in 3D Normalized Device Coordinates. The display on the view surface is 
then a parallel projection of the entire contents of 3D NLC space (the unit cube) onto the front plane 
of the unit cube, with hidden surface re-moval performed on &#38;l] of ~DC space. Fig-ure 3 shows two 
diffferent view volumes being transformea into hLC space, and the subsequent projections of the ~D viewports 
onto the view surface. Fecause the hidden surface algorithm operates on ell of ~D NDC space and produces 
a single "phctograph" on the view surface, there Js no need to be concerned about the priority of several 
overlapping sag, ants. If several serments are used to define en object, the same viewing transformations 
will be used for all segments. Thus all parts of the object will be positioned properly in 3D NDC space, 
producin~ a correct result. If two output primitives have identical coordi-nates in 3D NDC space, then 
temporal pri-ority is still used to determine visibili-ty. ~he most recently created output pri-rr;itive 
will take priority over others. The translOrmation of a 3D view volume (be it the truncated pyra, iO 
of a perspec-tive view or the solid rectangle of a par-allel view) into a 3D unit cube is straightforward 
and is commonly used pre-paratory to use of a hidden surface algo-rithm. ]his concept is being extended 
here to multiple 3D viewports within a unit cube. In some cases, such as displaying an airport runway 
and surrounding buildings, a single viewport would be used, with size equal to the unit cube. In other 
cases, such as simultaneously displaying front, top, side, and isometric projections of the same object, 
several non-overlapping (as seen from the view surface) viewports would be used (FJFure ~). In still 
other cases, such ~s displayin~ ~n object with ~ super- 17 imposed cut-out showing enlarged detail of 
a particular area, overlapping (as seen from the view surface) viewports would be used (Figure 5). If 
clipping is enabled while the output primitives are defined to the Core System, then in 3D NDC space 
all output primitives will be containeO within 3D viewports. }!idden surface algorithms can use this 
knowledge to advantage, to avoi~ unnecessary comparisons between out- put primitives. How coos this 
approach accomodate temporal priority and explicit priority as special oases? Consider first temporal 
priority, which is in fact the default for the extensions. ~iewports default to 2D in the Core System, 
which means they are on the front face of 3D NDC space. Hence output primitives after being transformed 
into NDC space have no depth, so the hidden surface algorithms have no basis other than temporal order 
for decidJnF which output primitives are visible. Consider next the case of explicit priority, wherein 
each segment has an explicit priority for visibility. Segment priorities in the range of 0-I are used. 
A segment with priority P and a 2D view- port on the view surface defined by corner points of (XnJn,~min) 
and (Xmax,Ymax) will be delined to have a 3D viewport defined by corner points (%min,~min,P) and (Xmax,Ymax,P). 
7hat is, the 3D viewport is in the Z=P plane, hence the effect of the explicit priority for a segment 
is achieved by putting the image of the seg- ment on the appropriate constant Z plane in 3D NDC space, 
as in Figure ~. Once all the segments are defined, hidden surface removal is performed: the segments 
(and hence the planes) can be defined in arbi- trary order. 7he depth priorities can he vade dy-namic, 
simply by app]yin~ en i~aFe tran~-formation to the seyment: a translation along the Z-axis of NDC space 
is used to reposition a segment's image onto the ap-propriate plane of constant Z. ]hus the facilities 
for either a static or dynamic explicit priority capa- bility are available. A novice programmer might 
have trouble using the facilities in the context of ~D viewports and NDC space, but a very simple set 
of additional sub- routines can be trivially built on top el the extended Core System to make the fa- 
cilities more accessible. It so happens, then, that the Core System already contains the key concept 
needed to provide biaden surface removal in a general and flexible way -3D viewports and 3D NDC space. 
Furthermore, the concept can be used to provide two other hidden surface concepts commonly used in raster 
graphics: temporal priority and explicit priority. 5.2 Polygons. ~ po]pen is specified by a simple cell 
which passes arrays of coordinates for all vertexes of the poly-gon. Four versions of the call, for 2~, 
~D, absolute, and relative coordintes are defined, as is always the case for Core System primitives. 
The polyyon is automa- tically closed by adding an edge from the last vertex tc the ~irst. Many objects 
displayed gr~phically consist of numerous interconnected polygo-nal Iaces. If each face were specified 
by a separate polygon primitive, coordinates of shared vertices woulo be passed to the Core System several 
times, and connec-ivity/shared edge information would have to be deduced from the equality of vertex 
co-ordinates, therefore a second way of de- fining polygons is provided: the polygon mesh. Polygons in 
a polygon mesh are de-fined in a 2-step process: - A collection ol vertices, numbered fron l to N, is 
specified. - Facb polygon is defined by giving a list of vertex numbers. The vertices are connected 
in the order ~iven, with the last vertex being eutomatieally connected to the first for closure. The 
vertex list is specified with a single call, in much the same fashion as e polygon. A polygon in the 
mesh is specified with POLYGON EDGE LIST [VERTE~ INDFX- LIST,E3. A p~]ygon mesh exists-entirely within 
a segment, and is terminated either by beginnin~ another polygon mesh or by closing the segment. ]he 
POLYGON NESH S[iAPE attribute is a primitive attribute which applies to poly- gon meshes. It takes cn 
three values to indicate: - the polygon mesh does not bound a }D volume, and hence is not a polyhedron 
(this is the default). - the po].yFon mesh is a non-convex (concave) polyhedror. - the polygon mesh 
is a convex polyhedron. Sone hidden-surface algorithms con use such information to decrease processing 
time. There are other primitive attributes of polygons which determine the color(s) used to fill polygons. 
These attributes are discussed in a later section, 5.3 Color and Intensity. In raster graphics, precise 
contrcl of color and in- tensity are central to many applications. ]he Core System has a color attribute 
and an intensity attribute, but their details are unspecified. Furthermore, intensity is part of the 
color specification, so the color and intensity attributes are non-orthogonal. Given a color attribute, 
in-tensity is actually redundant. We have, however, retained both color and intensity, 18 but reeuJre 
that for a given view surface only one of two intensities be used. In- tensity has Deem retained only 
as a con- venience for ~rey-]eve] app]ications. The displayable ranges of colors amd intensities can 
vary greatly from ome raster display to another ard are critical to many applications, thereby suggesting 
that only one view surface be selected at a time. lhis removes from the Core System the impossible task 
of trying to second-guess tlie programmer in mapping a color attribute value to two dissimilar raster 
displays. Color can be specified in several ways, as discussed in JOBL?8 and SMTIi78. ~he most fundamental 
choice is between red, green, blue (RGB) and hue, saturation, in-tensity (HSI) or some variation thereof. 
We have chosen to use RGB primarily because it is used by most of today's raster dis-plays. Inclusion 
of severs] color spec-ifications was exceedingly tempting, hut minimality dictated that a single choice 
be made, The discussion here centers on the color attribute and functions for its comtrol. A parallel 
set of capabilities for the intensity attribute also exists, and is described in the Reference Fanual 
[FOLF78b]. Conceptually, the extensions define an ordered set of colors specified by (R,C,B) triples: 
{(Pi,Ci,Pi)}. This set is called the active color set, and repre- sents the set of colors which can 
simul-taneously be displayed on a view surface. lee size of the set varies m~ong view sur-f'aces, and 
can be determined with the in-quiry function INQUIRE NUMBER OF COLORS[N]. Another inquiry function, IRQUIR[ 
COLOR- %ALUE[I,R,L,5], can be used to find the values of the R, C, and E components in the Ith triple. 
 The color attribute for output primi- tives is specified in one of two ways: by value, or by index. 
The function SET- CURRENT COLOR [R,G,PJ specifies the current value o~ the color attribute. ]f the exact 
[R,G,BJ triple specified is not included in the active color set, the~ a best fit to an available trip]e 
is performed. Alterna- tively, the function SET CUFRFNT COLOR- INDEX[I] specifies that ~be Ith ~rip]e 
from the (ordered) active color set is to be used as the color attribute. 5.4 Dynamic Color and Intensity 
Changes. A separate set of extensions is provided for access to the look-up table found in many image 
display systems. ~hese exten-sions are structured to be strictly upward-compatible with the basic color 
or intensity attribute, and hence need not be used by applications having no need for use of dynamic 
color cLanges with a look-up table, lee previously described active color set becomes a subset of the 
global color set. ]he size of the active color set is just the number of entries in the look-up table. 
The size of the global color set is the size of the umiverse of colors wbicb can be specified in the 
look-up table, and is usually two raised to the number of bits per entry in the table. INCUI~F NUbFFF 
OF GICPAI CC[05S[N) cam be used to i~nd the-si~e of the F]obal color set. 3he [P,C,~) triple for globs] 
co]or J is found with INCUIRE GLOBAL- COLOR[J,R,G,E). FFDEFINE COLO~ INDEX [J,5,C,E] changes the Jt~ 
active color to [E,C,E]. If [R,C,~] is not in the set of ~lobal colors, a best-fit to a global color 
is perforn~ed. A change in the color associated with an index affects already-created output pri~,itives, 
as well as those that will be created in the future. Conceptually, it is the index, rather than the 
color associated with the index, which is the static at- tribute of output primitives. It is pos- sible 
to dynamically change thebinding of the index to a particular color. ]his conceptual ,,odel for working 
with the color attribute is usable with a wide range of systems, from the inexpensive two to eight color 
systems (one to three bits per pixel) without look-up table, through the typical eight bit per pixe] 
syste~ with a 256 entry look-up table of twelve bits per pixel, up to the 24 to ~6 bit per pixe] systems. 
 The extended Core System Deed not always explicitly store either the active or global color set, but 
need only be able to generate triples in the set. For in- stance, the device driver for a 24 bit per 
pixel system could use the 24 bit color index as the color specification, by simply dividing the 24 bits 
into three groups of eight bits each. On the other hand, the device driver lor an eight color system 
can trivially store an eight-entry table. 5.5 Pixel Arrays and Polygon Filling. Pixel Arrays are two-dimensional 
arrays of intensity or color values. They occur in several environments. In traditional image processing, 
the pixel arrays represent real objects, and cove from devices such as cameras, X-rays and ultrasound 
scanners. In some cases these devices produce direct digital information, and in other cases film ~ust 
be scanned and digitized. Piel arrays representing synthetic or modelled objects ere reFv]arly created 
by computer programs, sometimes using quite sophisticated modelling, lighting, and surface texturing 
techniques. Artists often use interactive painting programs to create aesthetically pleasing scenes de-fined 
by pixel arrays. Part of the objec- tive of extending the Core System for raster graphics is to allow 
such pixel arrays to be displayed easily, along with lines and polygons. Pixel arrays could easily be 
treated as a rather special type 19 of output primitive, beinR placed directly onto the front plane 
of ~D NDC space. Then, however, other constructs in ~D NCC space might be obscured. Furthertrore, using 
NDC space directly is unattractive, because then the mixing of pixe] arrays and other output primitives 
is complicated by using two different coordinate systems. Yet ap- plications such as interactive i~age 
anal- ysis ano interpretation, and interactive graphics arts applications demand such mixing. An attractive 
alternative, used in our extensions, is to place the pixel arrays into World Coordinates using the pixel 
 array as e way to fill a polygon. An en- tire pixel-array can be displayed hy using it to fill a rectangular 
polypon. Cne might wish to display not the entire rec-tangular pixel stray, but rather some por-tion 
thereof: this would occur if a photo were cropped eround sn irregular conto,r. ]ndicating the portion 
of the pixel arrey to be iFnored might be done usinF a special pixe] value me~ninf "iFnore me". In the 
extensions, however, 8 polygon is used to circumscribe that part of the pixe] arrey to be displayed. 
If a polygon is to be filled with a pixe] ~rray, a mapping is needed as shown in Figure 7. A polygons] 
part of the pixel array is mapped into a similar polygonal part of the 3D world. Notice that the mapping 
might mean that elements of the pixel array do not coincide with the raster display grid as is illustrated 
in Figures S and 9. Appropriate averaging or convolu- .tions must be used to find the correct values 
to display. We are currently in- vestigating efficient ways to perform this operation. Of course, special 
cases, for example when the pixel erray coincides with the raster display grid, can be detected and 
processed efficiently. The mapping from e pixel ~rrey to e ~D World Coordinate polygon is specified 
in several steps. The pixe] array, for con-venience, is thought of as having en arbi-trary size, defined 
by SET PIYE[, AREAY- EXTENT [X LENGT}!,Y LFNOTF]? ~he-two para-meters are the width and heipht of the 
pixe] array~ in arbitrary units (some a~-plications may ccnveniently think of these as World Coordinate 
units). Figure 7 shows the pixel ~rray and its length and height. The (O,0) origin is always at the lower 
left of the pixel array, in the lower left corner el the pixel. Similarly the point (X_LENGTH,Y LENGTH) 
is in the upper right corner of the upper right pixel. Using this pixel array coordinate system, three 
points in the pixel array (not necessarily centers of" pixels) are defined and asso-ciated with three 
World Coordinate points on the plane of the polygon. 7he three points in the pixel array and three World 
Coordinate points define e mapping which transforms the pixel array coordinate space onto the plane of 
the three polygon points. Whatever part of the pixe], errey fells within the polygon is visible, as in 
Figure 7. (Naturelly the three points cannot be colinear). This mapping is defined with the function 
SE1 VERTEX N~P. Texturing cf polygons can be achieved usin~ pixel strays, because the pixel array is 
replicated ~s often as necessary to fill the polygon. Figure i0 illustrates this replication. The POLYGON 
TYPE attribute specifies how polygons are-to be filled. ~here are three possibilities, qhe first is that 
polygons are filled with a constant color given by the current color attribute. The second possibility 
is that the polygon is to be filled by linear interpolation be-tween colors specified for each vertex 
of the polygon (using SE~ VERTEX COLORS). In-terpolation is linear ~n the ~ndividua] RCB components of 
the colors (one might choose to extend this attribute to else specify other types of interppolation). 
A special cese of' this interpo]etion is Couraud shading [GOUR71). ~he fins] type of poly- gon fi]lin~ 
is the pixel stray filling. Other polygcn ettributes might also be described, although no others have 
been provided in these extensions. For example, an attribute might be used to cause poly- gons to be 
outlined in black (or some ether background color). This is ettactive for charts and graphs. 5.6 Operations 
on the View Surface. For our prototypical raster graphics system the view surface and refresh buffer 
are one and the same. ghe refresh buffer is mode directly available to the application pro- gramner, 
to read or write individual pixels or arrays of pixels. Pixels can be ad- dressed using a 2D integer 
coordinate sys- tem corresponding to the addressing system for the refresh buffer. (Raster systems doing 
scan conversion eech refresh cycle have no refresh buffer, so these capabili- ties would not work for 
them.) This is perhaps the ,cat substantie] end only ares in which the extensions depart signifi- cantly 
from the Core System philosophy: for vector systems, the Core System explicitly allows only very ]iE~ted 
m~nipu]stion of the view surface ~,age, hy way of segment manipulations. Ibis has been done for numerous 
rea- sons. Some interaction techniques must directly modify and restore portions of the refresh bulfer. 
]remendous amounts of ccn;puter time night ~o into celculating pixel velues for a single picture. That 
time woulo be lost if the view surface pixel array could not be saved. (A similar cost selOom exists 
with line-drawing dis- play files.) Powerful visual effects can be achieved by some view surface (pixel 
array) ~anipulations, or by combining on e screen the outputs of numerous different progra,~s which create 
images in different ways. On the other hand, re geometrical trarsfermations on the view surface have 
been de,ind. If the view surface pixel array can be read and written, then a mul- titude of geometrical 
(rotate, scale, translate, etc.) and image-oriented (aver-ae, filter, etc.) operations can be ~m-plemented 
in the application program it-sell, or ~s utility programs. 5.7 Control. In standard line-drawing graphics 
packages, output primitives can always be oisplayed as soon as they are defined. It hidden surfaces (or 
edges) are to be removed, however, then all output primitives must usually be defined before any output 
primitives can be displayed. Some control function is needed to indicate when all output primitives have 
been de- fined, so that a hidden surface algorithm can be initiated, githout such a function, the Core 
System would be forced to display each visible output primitive as it is de- fined, possibly also removing 
from the disp]ay output primitives (or portions thereof) obscured by the new output primi-tive. The Core 
System's batcbinp capabi- lity is used for this. Hidden surface re- moval is initiated when the end of 
a batch of updates occurs. lhree display modes have been defined to control how and when output primitives 
are disp]ayed. In "fast" mode, output primitives can be displayeO immediately. Polygon boundaries are 
displayed, but their interiors are not filled, and no hidden surface removal is necessary, in fast mode, 
batchin~ has no et/ect beyound what it normally does: guarantee that the view surface is up to date. 
In "hidden edge" mode, the end of batch triggers a hidden edge removal algorithm. Again, polygon in-teriors 
are not filled -only boundaries are displayed. ( Raster extensions being plementation (in FORTRAN on 
a VAX ii1780). Figures ii through 15 were created usinF the Core Systen, and illustrate scrip of the 
capabilities described Jn the raper. The extensions have helped form the basis for adding raster capabilities 
to COS [FO[FT@a], and have been integrated into the recommendations of the GSPC raster ex- tensions subcommittee 
[GSPC79). 7. Acknow]edFements. We are grateful to those members of SIGGRAPH's Graphics Standards FlanninF 
Committee who have cri- tiqued these raster extensions, especially Lansing hattield, Chris l,erot, Lee 
betrick, and Jim ~ichener. Dr. Steve Fark of kASA-Langley provided helpful comments. Ybe George kashington 
bniversity im-plen:entation el the Core System which we used as the base for implementing the ex-tensions 
was developed by Nike Callahan, Dara Dastyar, Patty Lenbrook, and Jim l empleman, kr. Pat Senyo did the 
text processing work for this paper and the re-f'erence marius]. ~. ~EFERENCES CHRS76 Christiansen, 
H., Prown, B., and WcLary, L. "A General Purpose Computer Graphics Display System for Finite Fle~ent 
Fodel~" Light Shock and Vibration Fulletin, Part (August i76), 61-66. ~OLE78s Foley, J., Temple,ran, 
J. and Dastyar, O. Study el Raster Ex-tensions tc GCS, final report to Waterways Experiment Station, 
Contract DACA39-76-~-OO73, August 1978. FOLE78b Foley, J., Templeman, J. and Dastyar, L. Reference Kanual 
-Raster Extensions to the Core developed for GCS will optionally display hidden edges as dashed lines. 
) In ',hidden surface" mode, the end of hatch triggers a hidden surface removal algorithm. If the selected 
view surface is a vector device, then hidden surface mode is treated as hidden edge mode. 6. Sunmary. 
In genera], the-Core Sys- te, proved to be a receptive host for these raster graphics extensions. The 
3D NDC space provides a convenient way to inte-grate the various approaches to surface priorities, the 
hatching is useful to trigger hidden edge or hidden surface re-moval, and t~e attribute structure was 
easily extended to accomodate po]yfons, polygon meshes, color, and pixel arrays. Furthermore, the Core 
System design's em-phasis on consistency and minimality chal- lenged us to examine numerous alternative 
designs before reaching a final design. 7he extensions are in the process of being integrated into our 
Core System im- FL:LT75 COUP71 CSPC?7 GSPC?9 System, George Washington Univer- sity, EE g CS I:ept., 
Washingtcn, D.C. 2C052, December i97@. Fulton, ~.L. and [uquet, ~.3. ',List Processing Primitives for 
FASIC", Computers and Graphics i (2/R),. September io7 ~. ~, pp. 203-210. Oouraud, F. "Computer Display 
of Curved Surfaces", IFEE ~ransac, tions on Computers 0-2@, 6 (June %971), 623-628. Status ~eFort of 
the Craphics Standards Plannin~ Committee of ACM/SIGG~AFH. ublished as Com-puter Graphics ii (3), Fall 
19?7. Second Status heport of the Graphics Standards 1annin'g Com- mittee of AC~/SIGGRAP[I.. To be published 
in Computer Graphics. 21 GUIL74 "Guidelines for Initiation OfIa Program for Graphics Standards and a 
Graphic Standards Plannin Com-mittee", Computer Graphics P, 2 (Summer 1974), i9-2C. IGPL77 IGPL -Interactive 
Craphics Pro- @rammin# LenFuaEe User's Reference Nanue]. NORPAK Ltd., Fakenha~, Ontario, Sept. 1977. 
JOFL7&#38; Joblove, J.H. and Creenberg, D'. "Color Spaces for Computer Graph- ics", SIGG~APH '78 Prcceedin~s, 
published as Computer Graphics ~2, (August 1978), 2[)-25. P:1C}i78 kichner, J., and van Dam, A. "A Functional 
Cverview o~ the Core System with Glossary", Surveys 10,4 (December 361-388. Computin E i97), NEWMT~ 
Newman, k. and van Dam, A. "Secant Efforts ]oward Graphics Standard-ization", Computin~ Surveys 10, a 
(December ~978), ~65-380. 05RI75 O'Brien, C.D. and Fown, H.H. "IVACF: A Language for the Inter- active 
Vanipulation of a Graphics Environment',, SIGGRAPH '75 Pro- ceedinps, published as Computer Graphics 
9 (I), SprlnF 1975, pp. 53-60. ~EE~IT7 keeves, W. GPAC User's b.anual, University of Toronto, Lepartment 
of Computer Science, January 1~77. Smith, A.R., "Color Gamut 1tans-form Pairs", SIGGRAPII '78 Pro- ceedings, 
published as Computer Graphics 12, 3 (August 1978), ;2-19. SPRO75 SproulI, R.,and Newman, W. "The DesiFn 
of Grey-Scale Graphics Software", Conference on Computer Graphics, Fattern Recognition ~nd Data Structures, 
IFFF, iQ75, iE-20, FIGURE 1 Prototype Paster Display System T ~Am~ -- R pI~EL VALUE ~ZIDRE$S FROM 
~F~SH BUFFR IN T/~BLE DISPLAY B IN TAm~ FICUEE 2 Look Up ]able VIEW VIEW < VIEWING =:~LTION 2 ] cOORDINATE 
SPACE  VIEW SURFACE FIGURE 3 Creation of Eisplay From Several View Volumes OF OBJECT VIWOF OBJECT 
~D VI B~OFT WITH PRCNT VIEW OF aBJECT / ~D NOR~%W_I~ OF CEJECT DEVICE C~ INATE SPACE DI ~CTI CN OF PROJECTION 
VIEW SURFACE FIGUhE 4 Arran[~ement of Four Separate 3D Viewports 22 OF OBJECT ~D VIE~PORT WITH BLO~ 
UP CUIOUT OF OBJECT 3D NO~"ALI ZF..I) DEVICE COORDI ~t~1~ Y  DIRECTION OF PRD~CTION VIEW SLIRF,~ FIGUBE 
5 ArranFement of Two Over]appir~ ~[' Viewports z = 1~/-- Z= 0.0 LOWESTPRIORITY ~.GMENT --ON 1HIS PLANE 
I~IATE PR lORlIY SEG"IHWTS ON 1HESE ~S --i HIi~EST ~RIORITY SEe,B,'T ON 1HIS I]EVI CI~ ~1 NA1E f SPA~ 
DIRECTION OF pROJCTION VIEW SURFACE ~IGb 6 Use of Viewports on Parallel Planes in 3D NDC Space (Explicit 
2 ~/2L) PIXEL ARRAY (X_I.B~I~, y_LENGTH) / ~ PORTION OF PIE ARRAY TO BE MAPPED ONTO POLYG0tl SURFACE 
(0, 0) "n~NSFORM~TI ON INTO WORLD COORDI NA~S POLYBON IN 5D RDINAI~S FlOb~E ? Transformation of Pixel 
Array into World Coordinates, Only Portion of the Array is Displayed ( RASTER DISPLAY GRID FIGUEE high 
hesolution Pixel Array hotated and Placeo on a Low 5esolution Grid / , / / / / /-v PERSPECTIVE RASlER 
DISPLAY GRID PROJECTION OF A PIlL A~RAy GRID ONTORAS~R DISPLAY GRID FIGURE 9 A Perspective Frojeetion 
of a Pixe] Array Placed on a Grid PI)~L ARRAY CONTAINING TE)CFLR PAITE~ CORRESPONDENCE BEI~ POINTS 
OF PIXEL ARRAY AND POINTS ON POLYGON POLYGON IN 3D WORLD COORDINATES FIGURE 10 l{eplieaticn of a Pixel 
Array to Fill a Polypon 23  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807421</article_id>
		<sort_key>25</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[A general purpose graphic system for computer aided design]]></title>
		<page_from>25</page_from>
		<page_to>32</page_to>
		<doi_number>10.1145/800249.807421</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807421</url>
		<abstract>
			<par><![CDATA[<p>The experimental Advanced Integrated Designer's Activity Support (A-IDAS) system is intended to be a base for a total engineering system rather than a pure graphic system. The system provides a database in which graphic data, geometric data and engineering data are stored in a relational data model. It also provides a graphic management facility which can manipulate not only pictures drawn with lines, but those drawn as areas. Areas are represented by crosshatched lines or colors. In more complicated ways, they can be represented as texture or scenery. The system controls two kinds of graphic display devices: a vector display and a raster display. These devices are supported through a device independent user interface when pictures are drawn with lines. With this experimental system, it has been found out that one can develop an engineering system having fairly general purpose capabilities.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer aided design]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Device independent graphics]]></kw>
			<kw><![CDATA[Engineering database]]></kw>
			<kw><![CDATA[Relational data model]]></kw>
			<kw><![CDATA[Scenery]]></kw>
			<kw><![CDATA[Texture]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.6.1</cat_node>
				<descriptor>Systems development</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003491.10003496</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->Project and people management->Systems development</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P258646</person_id>
				<author_profile_id><![CDATA[81100419305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sakae]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Uno]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Japan, Ltd., Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P110440</person_id>
				<author_profile_id><![CDATA[81100244828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hideo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matsuka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Japan, Ltd., Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>807383</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dungan, W. Jr. Texture tile considerations for raster graphics. Computer Graphics 12, 3 (August 1978), 130-134.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Fujisaki, T., Ohkohchi, M., Morohashi, M. and Mashita, H. ETOILE: A system supporting a shared intelligent I/O controller. Proceedings of 3rd USA-Japan Computer Conference (1978), 477-481.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Matsuka, H. and Uno, S. Canonical geometric model in architecture or civil engineering. Tokyo Scientific Center Report GE18-1891, IBM Japan (December 1978).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sibuya, M. and Uno, S. Specific requirements in engineering data base. (to appear).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[SIGGRAPH GSPC. General methodology and the proposed standard. Computer Graphics 11, 3 (Fall 1977).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Uno, S. Basic relational table handler. Tokyo Scientific Center Report GE18-1816, IBM Japan (July 1975).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563309</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Weller, D. and Williams, R. Graphic and relational data base support for problem solving. Computer Graphics 10, 2 (Summer 1976), 183-189.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A General Purpose Graphic System for Computer Aided Design Sakae Uno Hideo Matsuka IBM Japan, Ltd. 
Tokyo, Japan ABSTRACT The experimental Advanced Integrated Designer's Activity Support (A-IDAS) system 
is intended to be a base for a total engineering system rather than a pure graphic system. The system 
provides a database in which graphic data, geometric data and engineering data are stored in a relational 
data model. It also provides a graphic management facility which can manipulate not only pictures drawn 
with lines, but those drawn as areas. Areas are represented by crosshatched lines or colors. In more 
complicated ways, they can be represented as texture or scenery. The system controls two kinds of graphic 
display devices: a vector display and a raster display. These devices are supported through a device 
independent user interface when pictures are drawn with lines. With this experimental system, it has 
been found out that one can develop an engineering system having fairly general purpose capabilities. 
KEY WORDS AND PHRASES: computer aided design, computer graphics, device independent graphics, engineering 
database, relational data model, scenery, texture. CR CATEGORIES: 3.20, 8.2. 1. INTRODUCTION Graphics 
plays an essential role in computer aided design (CAD). In developing a graphics system for CAD, we should 
consider: i) a variety of graphic devices, 2) the designer's interaction with these devices, and 3) use 
of data for reference and computation, e.g., for engineering analysis. For the first consideration, CAD 
systems are using a plotter and a graphic display and will eventually use more sophisticated devices. 
These devices are expected to be supported in a unified way, for example, by the proposed standard (5). 
 Authors' address: Tokyo Scientific Center, IBM Japan, 3-2-12 Roppongi Minato-ku, Tokyo 106, Japan The 
second consideration is that, although a picture on a display screen is traditionally drawn with lines, 
it should be drawn as areas if ares are designer's components. Further, it will be better that the areas 
are represented as images rather than as outlines when their texture is concerned. Some systems have 
been proposed to implement these functions (1), (7). The last consideration means that there must be 
an engineering database which includes more than graphic data. Since the structure of an engineering 
database is very complicated, its geometric data, graphic data and engineering data should be well integrated 
to structure a complete and satisfactory database (4). To satisfy all these requirements, the experimental 
Advanced Integrated Designer's Activity Support (A-IDAS) system is being developed. The system is designed 
as a nucleus for a variety of CAD systems. In general, designer~system interactions cause either of the 
following two: i) data transfer/input from graphics to a database for generation and modification of 
data, and 2) data transfer vice versa for output as a result of i). The ways of interactions for data 
input or the program modules that support these interactions, depend on design process (methodology) 
of an application. On the other hand, data output can be handled in a fairly independent way providing 
that data is stored in the database according to established rules. Therefore, the nucleus for a CAD 
system should be provided with general purpose modeling structures and output methods. And this paper 
discusses these points, proposing a solution to data modeling methodology and graphics for a CAD system. 
 2. GEOMETRIC MODELING Geometric data is a key bridge between an engineering database and graphics. 
The geometric model in the A-IDAS system is represented by a directed graph. That is, every geometric 
element is divided into four geometric "classes": vertex, edge, face and body. Each class consists of 
several geometric categories or "legion."  &#38;#169; 1979 ACM O-89791-004--4/79/0800--025 $00.75 See 
Copyright Pg. 2.5 The class edge, for example, includes a straight line, a circle (arc), a spline function 
curve, etc. Legions are application dependent and not pre-defined. This geometric information is stored 
in a tabular form or a relation of a relational data model. Although the system does not limit the number 
of geometric legions, the representation of a newly defined legion and its relating links should, however, 
be compatible with a structure proposed below. 2.1 ATTRIBUTIVE RELATIONS  Attributes of geometric elements 
are stored in tables called "attributive relations." Figure 1 shows the relationships of + ..... + !POINT! 
  ..... + .......... + ............ + ...........  !geometric ] graphic !engineering! l data l data 
! data ! + .......... + ...... + ..... + ........... + !coordinate! line I l l +.......... + or !color!application! 
! x y z !symbol! ! dependent ! + .......... + ...... + ..... + ...........  + .... + !LINE! + .... 
 ................. + .................. + ! geometric data ! graphic ! +.......  ......... + and 
[ lpassing!directionl engineering l l point ! cosine I data ! + ....... + ......... + .................. 
+ l x y z [ 1 m n I same as POINT ! + ....... + ......... + .................. + + ...... + !CIRCLE! 
  ..... + ......................  ...........  ! geometric data ! graphic l +......  ...... + 
......... + and l !center!radius!direction!engineering! l l ! cosine ! data ! + ......  ...... + ......... 
+ ........... + l ! ! [ same as l !x y z ! r ! 1 m n ! POINT ! + ...... @ ...... + ......... + ........... 
 + ..... + !PLANE!  + ..... + ................. + ................. + ! geometric data ! graphic 
l + ....... + ......... + and ! !passing!direction! engineering ! ! point I cosine l data ! + ....... 
+ ......... + ................. + ! x y z ! 1 m n l same as POINT l + ....... + .........  ................. 
+ Fig. i. Attributive relations  attributes to a legion. For example, the geometric attributes of a 
circle are: center, radius and direction cosine. In addition to geometric attributes, each legion is 
supported by graphic attributes and engineering attributes. The geometric and graphic attributes are 
used by the system for data manipulation and graphic output. The last attribute category (i.e., engineering 
data) is optional and is user- generated depending on application. This capability is designed into 
the database.  2.2 LINKING RELATIONS  Topological information about geometric elements should also 
be stored in tables called "linking relations" in terms of geometric classes. There are three linking 
relations: E-VV, F-EE and F-BB relations which show edge-vertex, face-edge and + .... + !E-VV! .... 
 .......... + ............  .......... + ! EDGE !start VERTEX!end VERTEX! + ...... +.._+ ....... + 
.... + ...... +___+ !legionXkey] legion! key!legion!key! +...... +___+ ....... + .... + ...... +___+ 
 + .... + ZF-EE!  --+-+ ........ + .......... + ....... + ........ + ! ! !forward!backward! ! FACE 
l EDGE ! EDGE ! EDGE ! + ...... +--- ...... +---+ ....... + ........  [legionlkeyllegionlkey] key 
! key ! ! ! I I !(F-EE) I (F-EE) 1  ...... +--- ...... +---+ ....... + ........  + .... + !F-BB] 
 + .... + .......... + .......... + .......... + ! FACE !front BODY! back BODY! + ...... +--.+ ...... 
+--.+ ...... +--.+ !legion!key!legion!key!legion!key! +L ..... +--.+ ...... +.-.+ ...... +---+ Fig. 
2. Linking relations  face-body links, respectively (See Fig. 2). These relations are system defined. 
 The E-VV relation shows the start and end vertexes of each edge. An edge is, thus, directed from the 
start vertex to the end vertex. This direction is used in the F-EE relation as the sign of an element 
key: positive for the direction, and negative for the opposite. The F-EE relation expresses surrounding 
edges of each face. Since the number of surrounding edges is not fixed, some difficulties arise if edges 
are stored within a single row or a tuple. For example, the relation might need a variable column tuple 
or a multiple value column or many columns which are used only for an exceptionally large number of edges. 
Therefore, a single tuple of the F-EE relation represents one of surrounding edges of a face. The whole 
information about surrounding edges is expressed by the same number of tuples as that of the edges. Edge 
order information which shows an adjacent edge in the face is also stored in the tuple. The order forms 
a round robin because the edges of a face compose a closed loop. The direction of an order distinguishes 
an inner boundary from an outer one, i.e., a clockwise direction is for an inner boundary and a counterclock- 
wise for an outer one. The third linking relation, F-BB, shows 26 front and back bodies of each face. 
As a normal vector is defined for a face, the direction is determined uniquely. The main reason why the 
relation is expressed in terms of a lower class (face) instead of a higher class (body) is that an order 
of faces which constitute a body is not so clear as that of egdes constituting a face.  2.3 GEOMETRIC 
MODEL STRUCTURES Table 1 shows a classification of geometric model structures and examples of Table 
I. Geometric model structure  .............. + .......... + ......  ........  ! structure!wire frame! 
area ! volume [ !background ! ! ! ! + .............. + .......... + ...... + ........ + !2-dimensional 
[ W2 [ A2 [ --! !S-dimensional ! W5 l A5 l V5 l + .............. + .......... + ...... + ........ + ! 
Examples ! !W2: wire printing, plate or sheet shape,! l engineering drawing ! IA2: house layout, plant 
layout, building! [ floor plan, land shape (2 and half! ! dimensional) ! !WS: piping, frame structure 
(tower,[ ! building, etc.) ! !AS: hull or shell structure (vehicle! l body, etc.) l [VS: machine parts 
(solid), building room,! ! ship compartment (spatial) [  .........................................  
 applications. A set of adequate relations to express a structure differs from one to another. In the 
wire frame structure, needed are attributive relations for vertexes and edges and the E-VV (edge-vertex) 
linking relation. In the area structure, attributive relations for faces and the F-EE (face-egde) linking 
relation are necessary in addtion to what is needed in the wire frame structure. In the volume structure, 
attributes for bodies and the F-BB are also needed. A problem to be solved can be modeled by one of these 
structures (5). 5. GRAPHICS  5.1 GRAPHIC DATA AND DRAWING ROUTINES Graphic data in attributive relations 
is used as graphic output parameters for a vertex, an edge and a face. Every geometric element has a 
color attribute plus either a line attribute or a symbol code. The line attribute means the style and 
width with which a vertex or an edge is drawn (the style is neglected in the case of a vertex). In the 
case of a face, it means crosshatching the face with lines of a specified style and width. If the symbol 
code is used, a geometric element is illustrated by the specified symbol instead of a line. This is 
especially convenient to a map application. For example, a vertex which represents the location of a 
temple is indicated by the symbol "~" and a face where rice is cultivated is filled with the symbols 
"2" (Fig. 3). These symbols are registered into the Kanji (Chinese character) font database as special 
characters. The color attribute is used to specify the color of a line or a symbol. When graphic data 
is provided in the database, the system standard drawing routines can be invoked. These routines interpret 
graphic meanings and issue drawing commands using the device independent interface. If an object to 
be considered is in a 5-D representation, viewing transformation is achievable: perspective or parallel. 
During the transformation, hidden lines are partially eliminated. That is, if a face is rotated to the 
rear of the object, the edges of that face are not drawn. In order to completely eliminate hidden lines, 
the following are required. At the first step, a 3-D object is projected as a 2-D area structure, face 
by face. Body information disappears and faces remain as faces, by projection, inheriting graphic attributes. 
Faces are merged by set operations and rearranged to express a picture with hidden lines completely removed. 
The next step is to draw the picture without any transformation. The drawing routines have a selective 
output capability with which they draw only these geometric elements that have specified values in specified 
columns. For example, elements which have "red" in the "color attribute" column can be drawn. Any column 
of an attributive relation can be used for selective output. Unconditional selection is allowed to draw 
all elements in a relation. To crosshatch a face, additional parameters are needed, i.e., distance between 
lines and line gradient. These are not stored in the database, but in a global parameter area for the 
drawing routines. As crosshatching is used for appearance rather than to portray the nature of an element, 
a line distance is specified in terms of the physical device coordinates for presentation (Fig. 4). By 
setting the value for the distance to be one, a face can be colored. 5.2 DEVICE INDEPENDENT GRAPHIC 
MANAGEMENT FACILITY The A-IDAS system includes a device independent graphic management facility (it 
is in the form of subroutines so that they may be used independently of the A-IDAS system.) It currently 
supports an interactive vector storage tube with  27  database. The end output command causes physical 
transfer of data to a device. This command may not be necessary if the device coordinates are directly 
addressable. However, this is essential for such a device as a dot printer which is only sequentially 
addressable. When the end output command is issued, the graphic management facility compiles queued data 
and rearranges it against the physical device coordinates. In our system, the end output command should 
always be issued because the output buffering technique is used for any devices to reduce data transfer 
overhead. Color attributes are values of red, green and blue components and a specification mode, i.e., 
absolute or relative. The relative mode is useful when making a shadow or a shade of an object. It is 
also applicable when making a transparent object (Fig. 5). Line attributes are style and width. Character 
attributes are size and spacing. These are common to alphanumeric and Kanji characters. Two kinds of 
optional output files are maintained by the graphic management facility. These are a projection file 
and a display file. Excepting a device selection command, all the data passed on to the graphic management 
facility are stored in the projection file before being processed. Thus, the file contains device independent 
information and makes it possible to re-display onto a different device without referring to source data 
(database) nor viewing transformation. A display file is prepared for each device. device dependent 
codes so pictures rapidly reappear. It that contains output 5.5 15~GE DATA MANIPULATION It is quite 
valuable to include image data in computer graphics. At present, we are interested in images such as 
scenery, which is used as a background for landscape evaluation, and material texture, such as a wall 
for a building design. These images are obtained by scanning and digitizing a photograph. An image file 
which contains raster data is provided for image data manipulation. The graphic management facility 
is extended to include image manipulation functions. These functions are applicable only to a color display 
device. Major functions are background processing, image deformation, domain extraction and image composition. 
 Background processing is the setting of initial values in the work area for images or the image buffer. 
Either a uniform color value or the name of an image file is specified. If a color value is specified, 
the buffer is set to the color. In the case of a file name, data for all the pixels are read from the 
file. Image deformation includes geometric transformation and image expansion (Fig. 6). Geometric transformation 
means linear transformation, affine transformation, projective transformation or more complex transformation 
such as cylinder surface-to- development plane transformation. Image expansion is to provide periodically 
a part of an image. Smoothing of a periodic boundary is also available. The result can be stored as an 
image file. Thus, image deformation is useful for deriving a new image from a small sample of standard 
 texture. Domain extraction is the selecting of an area of interest out of an image. There are two mothods 
for specifying an area or a domain. One is extraction of the domain from the image by means of the clustering 
technique. By specifying both a reference raster which represents the domain of interest and a polygonal 
zone which comprises the domain, the rasters which have color values (or texture) similar to the reference 
raster within the zone are selected, within the specified allowable variance. This information is extracted 
and stored as an image mask. This method is useful in extracting a characterized texture with vague boundaries 
(Fig. 7). The other method of extraction is to indicate the vector boundaries of the domain. This is 
done either by manual input of a polygon or by reading face boundary information from the geometric model. 
 Image composition is the superimposing of one image onto another (Fig. 8). An "active image" which is 
represented in the image buffer is modified by an operation, an "operand image" and an image mask. The 
operand image is obtained from an image file of texture or is a uniform color value. The allocation of 
a corresponding file or a color value can be specified interactively. This makes it possible to compare 
one texture image with another by trial and error. Now the active image and the operand image are operated 
raster by raster if the image mask of the raster is "on". Supported operations are unconditional substitution 
of the operand image for the active image, addition/ subtraction of the operand and/from the active images, 
selection of a larger/ smaller color value and merging both images (e.g., taking a mean value). A complementary 
image of the active one can also be created as a special case of subtraction. The results of the operation 
are stored in the image buffer again. Multi-image superimposition is supported. Multi-masks are needed 
to achieve this. Each mask has an operand image, an operation and an operation priority. The graphic 
management facility interprets and executes image composition from the lowest  29  A mechanical scanner 
is used to input image data and make an image file from a photograph. It has the capability of color 
scanning using 8 data bits per color component through an analog-digital converter. For scanning image 
data, either a transmitted beam or a reflected beam is used. Sampling pitch can be selected to 25, 50, 
i00, 200, 500 or i000 microns.  4.2 SOFTWARE The A-IDAS system is running under VM/CMS. A virtual 
machine (VM) is logged on as an A-IDAS user through a character display terminal. Two interruption driven 
service VM's are running behind, waiting for special service requests from unspecific users. One is ETOILE 
VM which manages and controls all the peripheral devices under System/7 (2). The other is Kanji VM which 
manages the Kanji database (requests from the A-IDAS system to read the stroke database). These service 
VM's are designed to share and utilize resources in a time sharing environment. The A-IDAS VM communicates 
with the service VM's through virtual channel to channel adapters. The A-IDAS system issues an ETOILE 
command and asks the ETOILE VM to execute it whenever an input/output request from/to a graphic device 
is made. A geometric model of the A-IDAS system is implemented on top of the BARTH which is a relational 
database management system and provides a tuple-wise user interface (6). The A-IDAS system currently 
supports two kinds of graphic displays, DVST and color displays. Including a character display as a VM 
terminal, three CRT's are used in the system. This enables separated output of information. The graphic 
displays are free from non-graphic information. The character display, on the other hand, is used for 
input of command, data, etc., and for output of tutorial information, database contents, various paratemters, 
etc. Suppose that a perspective picture is displayed on a graphic display and the corresponding parameters 
are on a character display. If a command is issued for changing a parameter, a picture is re-displayed 
on the graphic display while the character display remains unchanged. 5. CONCLUDING REMARKS  Although 
many CAD systems have been developed, the majority of the systems are designed to solve specific problems 
and therefore, they have no flexibility, generality or expandability. This is not only because of performance 
reasons or speciality reasons, but because of lack of guidance on how to design a "rich" system. A special 
purpose system prevents itself from growing and becoming a total engineering system. From this point 
of vlew, the A-IDAS system is a design with an engineering application system which deals with geometric 
and graphic information as well as engineering data. To establish an application system, it is necessary 
to define the problems and select a suitable model structure. Once the model structure is selected, its 
geometric classes will be automatically determined. The geometric legions to be used should, then, be 
determined according to application. Further, engineering data of each legion needs to be determined. 
Besides typical legions that are already registered in the system, new legions if necessary can be added 
together with the corresponding drawing routines. The graphic management facility, on the other hand, 
can generally be used, whatever application one may consider, because graphic data stored in the database 
is common to all applications. The A-IDAS system has been used and evaluated for topography, cartography, 
iconic landscape simulation and house building applications. ACKNOWLEDGEMENTS The authors would like 
to thank George Takama of Waseda University and Teruo Yamada of Tokyo University for their assistance 
in implementing the A-IDAS system. REFERECES i. Dungan, W. Jr. Texture tile considerations for raster 
graphics. Computer Graphics 12, 3 (August 1978), 150-154. 2. Fujisaki, T., Ohkohchi, M., Morohashi, 
 M. and Mashita, H. ETOILE: A system su2porting a shared intelligent I/O controller. Proceedings of 3rd 
USA-Japan Computer Comference (1978), 477-481. 3. Matsuka, H. and Uno, S. Canonical geometric model 
in architecture or civil engineering. Tokyo Scientific Center Report GE18-1891, IBM Japan (December 1978). 
 4. Sibuya, M. and Uno, S. Specific requirements in engineering data base. (to appear).  5. SIGGRAPH 
GSPC. General methodology and the proposed standard. Computer Graphics ii, 3 (Fall 1977).  6. Uno, S. 
Basic relational table handler. Tokyo Scientific Center Report GE18-1816, IBM Japan (July 1975).  7. 
Weller, D. and Willams, R. Graphic and relational data base support for problem solving. Computer Graphics 
i0, 2 (Summer 1976), 185-189. 32  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807422</article_id>
		<sort_key>33</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Computer graphics for large scale two- and three-dimensional analysis of complex geometries]]></title>
		<page_from>33</page_from>
		<page_to>40</page_to>
		<doi_number>10.1145/800249.807422</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807422</url>
		<abstract>
			<par><![CDATA[<p>A comprehensive set of programs have been developed for analysis of complex two- and three-dimensional geometries in the Mechanical Engineering Department of the University of California's Lawrence Livermore Laboratory. State of the art finite element and hydrodynamic codes are being used for the analytical portion of the work. To assist the analytical effort, several additional codes which depend heavily on graphics have been developed. These are basically used for the pre- and post-processing of the data. Prior to running any analysis, the geometry of the body of interest must be represented in the form of small &#8220;finite elements&#8221;. After the analysis is run, the data must be post-processed. Both spatial and temporal data exist in the database. It is the database between the analysis codes and the post-processors which allows a wide variety of analysis codes to use the same post-processors.</p> <p>The temporal plotting codes produce time histories for specified quantities (i.e. temperature, pressure, velocity, stress, etc.) at various locations within the body. They may also produce cross-plots of these variables (i.e. stress vs strain at a particular position). For plotting of the spatial data two codes are used. The first is for two-dimensional geometries and the second is for three-dimensional models. For three dimensions, the Watkins' hidden surface/line processor is utilized for plots. The spatial plotters will display contour lines on vector output devices and color fringes (or gray values) on raster output devices. They both may also display deformed geometries. Further the three-dimensional code has extensive animation capabilities for movie productions. These graphics codes are used with a wide variety of analyses codes and form a very comprehensive package for the engineering analysis of two- and three-dimensional bodies.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Engineering databases]]></kw>
			<kw><![CDATA[Finite elements]]></kw>
			<kw><![CDATA[Three-dimensional applications]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39023242</person_id>
				<author_profile_id><![CDATA[81100013374]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[Eric]]></middle_name>
				<last_name><![CDATA[Brown]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Lawrence Livermore Laboratory, Livermore, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Gerhard, M. A., "SLIC User's Manual," University of California, Lawrence Livermore Laboratory, Livermore, California, UCID-18166, May 1979.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brown, B.E., "GRAPE - A General Purpose Display Program for Three-Dimensional Finite Element Models," University of California, Lawrence Livermore Laboratory, Livermore, California, (to appear).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burger, M.J., "ZONE - A Finite Element Mesh Generator," University of California, Lawrence Livermore Laboratory, Livermore, California, UCID-17139, May 1976.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Goudreau, G.L., private communication, June 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gerhard, M.A., "OASIS - A General Purpose Three-Dimensional Mesh Generator," University of California, Lawrence Livermore Laboratory, Livermore, California, ENN-78-36, Oct. 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Winslow, A.M., "'Equipotential' Zoning of Two-Dimensional Meshes," University of California, Lawrence Livermore Laboratory, Livermore, California, UCRL-7312, 1963.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908582</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Brown, B.E., "Modeling of Solids for Three-Dimensional Finite Element Analysis," Ph.D. Dissertation, Department of Computer Science, University of Utah, Salt Lake City, Utah, June 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hallquist, J. O., "NIKE2D - An Implicit, Finite Deformation, Finite Element Code for Analyzing the Static and Dynamic Response of Two-Dimensional Solids," University of California, Lawrence Livermore Laboratory, Livermore, California, UCRL-52768.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hallquist, J. O., "NIKE3D," to appear.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hallquist, J. O., "DYNA2D - An Explicit Finite Element and Finite Difference Code for Axisymmetric and Plane Strain Calculations (User's Guide)", University of California, Lawrence Livermore Laboratory, Livermore, California, UCRL-52429, March, 1978.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hallquist, J. O., "Preliminary User's Manual for DYNA3D and DYNAP," University of California, Lawrence Livermore Laboratory, Livermore, California, UCID-17268, 1976.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mason, W.E., Jr., "TACO - A Finite Element Heat Transfer Code," University of California, Lawrence Livermore Laboratory, Livermore, California, UCID-17980, November, 1978.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sackett, S.J., "SAP4 User's Manual," University of California, Lawrence Livermore Laboratory, Livermore, California, internal document.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hallquist, J.O. and Goudreau, G.L., "SAPP - A Post-Processor for Two-Dimensional Finite Element Codes," University of California, Lawrence Livermore Laboratory, Livermore, California, UCRL-52318, August 1977.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mason, W.E., Jr., "POSTACO - A Post-Processor for Scalar, Two-Dimensional Finite Element Codes," University of California, Lawrence Livermore Laboratory, Livermore, California, UCID-17979, November 1978.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Goudreau, G.L., private communication, October, 1977.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Young, R.W., "GPLOT - A Temporal Post-Processor for Two- and Three-Dimensional Finite Element Codes," University of California, Lawrence Livermore Laboratory, Livermore, California, (to appear).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H.N., and Stephenson, M.B., "MOVIE.BYU - A General Purpose Computer Graphics Display System," Proceedings of the Symposium on Applications of Computer Methods in Engineering, University of Southern California, Los Angeles, V. 2, August 1977, pp. 759-769.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Watkins, G.S., "A Real-Time Visible Surface Algorithm," Department of Computer Science, University of Utah, Salt Lake City, Utah, UTEC-CSc-70-101, June 1970.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Computer Graphics for Large Scale Two- and Three-Dimensional Analysis of Complex Geometries Bruce Eric 
Brown* University of California, Lawrence Livermore Laboratory Livermore, California ABSTRACT A comprehensive 
set of programs have been developed for analysis of complex two-and three-dimensional geometries in the 
Mechanical Engineering Department of the University of California's Lawrence Livermore Laboratory. State 
of the art finite element and hydrodynamic codes are being used for the analytical portion of the work. 
To assist the analytical effort, several additional codes which depend heavily on graphics have been 
developed. These are basically used for the pre-and post-processing of the data. Prior to running any 
analysis, the geometry of the body of interest must be represented in the form of small "finite elements". 
After the analysis is run, the data must be post-processed. Both spatial and temporal data exist in the 
database. It is the database between the analysis codes and the post-processors which allows a wide variety 
of analysis codes to use the same post-processors. The temporal plotting codes produce time histories 
for specified quantities (i.e. temperature, pressure, velocity, stress, etc.) at various locations within 
the body. They may also produce cross-plots of these variables (i.e. stress vs strain at a particular 
position). For plotting of the spatial data two codes are used. The first is for two-dimensional geometries 
and the second is for three-dimensional models. For three dimensions, the Watkins' hidden surface/line 
processor is utilized for plots. The spatial plotters will display contour lines on vector output devices 
and color fringes (or gray values) on raster output devices. They both may also display deformed geometries. 
Further the three-dimensional code has extensive animation capabilities for movie productions. These 
graphics codes are used with a wide variety of analyses codes and form a very comprehensive package for 
the engineering analysis of two-and three-dimensional bodies. KEY WORDS AND PHRASES: computer graphics, 
finite elements, three-dimensional applications, engineering databases. CR CATEGORIES: 8.2, 3.23, 3.26 
*Work performed under the auspices of the U.S. Department of Energy by the Lawrence Livermore Laboratory 
under contract number W-7405-Eng-48. INTRODUCTION The first set of programs to be discussed are the modeling 
codes. These are used to discretize the body into the finite element or finite difference mesh prior 
to analysis. There is currently only one program which is fully interactive and it is called SLIC (1). 
Others are available and have companion programs to the graphics. Both two-and three-dimensional models 
may be generated with SLIC. After discussing the modeling codes a brief description of the analysis programs 
will be given. These are basically the supported and maintained programs within the Lawrence Livermore 
Laboratory (LLL) for engineering analysis. The post-processing of the data will then be described. Only 
one of the codes, GRAPE(2), is truely interactive but all use graphics. The purpose of these codes is 
to present the data to the analyst in the most understandable way. There are many options in these codes 
which will be enumerated but only a few graphical examples will be given. PRE-PROCESSING OR MODELING 
The pre-processing or modeling prior to analysis is the most time-consuming and labor intensive portion 
of the analyst's work. Here graphics and interactive techniques can make the largest contributions. It 
is also here that the most research needs to be performed. What is going to be described below are several 
production codes which are used daily at LLL for the generation of models. All of these modeling codes 
require the external boundaries to be specified as straight lines, arcs of circles, piecewise linear 
segments, or combinations of the above. This is for both two- and three-dimensional modeling. The limitation 
of boundary only data is severe for three-dimensional modeling when the user has surface data but can 
only enter edge data. Programs under development at LLL will handle surface data for volume modeling 
but they are not as yet production codes. The codes used at LLL are ZONE and its plotter PLOT(3), MESH2 
(4), OASIS (5), and SLIC. The first two are strictly two-dimensional modelers while the last two may 
be used in two or three dimensions. The most interactive code, SLIC, has some limited graphics within 
the program. Data is given from the keyboard or read from a disc file. The other codes &#38;#169;1979 
ACM O-89791-004--4/79/0800--033 $00.75 See Copyright Pg. 33 mentioned only take data from the disc. As 
the model is being constructed, the user may ask for a display of the boundary curves. When the boundaries 
are judged to be correct, the internal points are generated by a bilinear interpolation scheme. Figure 
l on the left shows a fluid with a spherical hole, all of which is within a steel shell. This was modeled 
by SLIC from the keyboard in about 10 minutes. ~i \ ~ ~ ' Figureelements.3. Increased number of nodes 
and internal nodes have been "relaxed" and this relaxing is a feature of most modeling programs. SLIC 
and OASIS have two modes for relaxation. The first is called "equipotential" and is based upon the work 
of Winslow (6). The second is the application of LaPlace's equation to the internal nodes. This feature 
is also in MESH2. Unfortunately the relaxation of the meshes require a lot of user foreknowledge concerning 
the analysis code in use. An attempt to automate this was done by the author (7) but more work needs 
to be performed. Figure 2 further demonstrates SLIC's modeling Figure 2. Model generated by reflection. 
capability. Only one half of the model was defined and the other created by reflection. Figure 3 shows 
the same model as Figure2 but the number of nodes has been increased. This feature of defining the number 
of nodes desired after the geometry has been described is one of the most used features of the code. 
Figure4 demonstrates a mesh for a finite difference calculation which has been generated by ZONE. The 
problem of the spherical hole in a fluid has also been modeled in three dimensions. One of the early 
attempts is shown on the left in Fig. 5. This is a simplified version of the model in Fig. 1 rotated 
about its symmetry axis. Numerical considerations of the analysis code prevented realistic answers being 
~ Oe,o~,t~onl ~int Figure 4. ZONE generated hydrodynamic model. Figure 5. Three-Dimensional model by 
rotation (left) and restructure (right). obtained because of the wedge type elements along the pole. 
For these reasons, the sphere of water with a spherical hole in it was modeled as shown on the right 
in Fig. 5. This distribution of nodes and elements gave a much better result. The real geometry which 
was being approximated had a steel torodial shell partially full of water and pipes exhausting steam 
into the water. Figure 6 shows a later geometry used for this problem. This series of pictures also demonstrates 
the usual mode of operation. The analyst first approximates the geometry in two dimensions. If the problem 
is not satisfactorily solved, then a three-dimensional model is generated and analyzed. Figure 6. More 
accurate three-dimensionalmodel. More detail is added until the approximation is as accurate as needed 
or until the limit of the computer is met. Usually it is the latter. SLIC has some graphics capabilities 
in it but these last few three-dimensional views were generated with the hidden lines removed by GRAPE 
which will be discussed later. The outer surfaces can be displayed by SLIC and a sample is shown in Fig. 
7. We have of course specified which surfaces are to be displayed so that the picture is not too messy. 
Figure 7. Selected outer surfaces. The model shown in Fig. 8 is of a building structure. This model cannot 
conveniently be generated by any of the modeling routines just described. The previous Figure 8. Building 
structure, without hidden lines removed (upper) and with hidden lines removed (lower). routines are for 
modeling continuum in two or three dimensions. They do not presently allow for modeling structures and 
space frames in three dimensions and this is an area which we are presently pursuing. The next section 
will discuss several of the analysis codes used at LLL for which these modeling routines generate data. 
ANALYSIS CODES The purpose of this section is to give the reader a feel for the types of engineering 
analysis run at LLL. The codes described are the workhorse codes and are for continuum analysis in two 
dimensions, three dimensions, and for axisymmetric geometries. NIKE2D/NIKE3D -implicit large deformation, 
large strain, finite element codes for analyzing both static and dynamic response (8,9). DYNA2D/DYNA3D 
-explicit finite element and finite difference codes (10,11). TACO - an implicit, nonlinear, finite element 
heat transfer code (12). SAP4 -a linear code for static and dynamic response of continuum as well as 
structural finite elements (13). For the two-dimensional case, the capacity of the codes running on a 
CDC 7600 is in excess of 5000 zones or elements. In the three-dimensional case, it is about 4000 bricks. 
Typical running time for a large (five to seven thousand) brick problem for DYNA3D is 10 to 20 hours. 
On the CRAY-1 computer, the two-dimensional capacity is 40000 elements. For three-dimensional problems, 
about 20000 elements. The next section will detail how the data produced by such runs are post-processed. 
POST-PROCESSING This discussion of post-processing will be broken into three parts. First the plotting 
of spatial data in two dimensions. This is accomplished with two codes which have a common origin. The 
second part is plotting temporal data. For both two and three dimensions, the program is the same. The 
final part will be the plotting of spatial data for the three-dimensional analyses. TWO-DIMENSIONAL SPATIAL 
PLOTTING The present spatial post-processor for NIKE3D and DYNA2D is SAPP (14). For the TACO2D we use 
POSTACO (15). Both are descendants of POST2 (16) which was written about seven years ago. These are batch 
oriented programs primarily for vector output. The first use of SAPP is usually to view the geometry 
distorted according to the calculated displacements. In Fig. 4 we showed a model generated by ZONE. This 
is a model of a shape charge, high explosive in a steel cylinder with copper plates on the bottom and 
top. The explosive is detonated and DYNA2D calculates the burn of the explosive and the motion of the 
copper plates. In Fig. 9 we have displayed part of the high explosive and the copper plates at an early 
time, 50 microseconds. In Fig. 10 the copper plate is shown forming into a fragment at various times. 
These distorted shapes have been compared with x-ray pictures of an actual device fired and found to 
be in 35 [ I I lllllllllll II / / / / Z- II]lllll' ]llllll~ IlllLl[~II11111LIII lllllllll Figure 9. 
Deformed shape at 50 microseconds. ! I 20/~s 40ps 60,us 80,~s lOOps 120ps 140#s 160ps 180#S 200#S Figure 
10. Calculated formation of fragment. good agreement. Another example of SAPP is shown in Figs. 11, 12 
and 13. This problem concerns a metal O-ring being deformed to seal a shipping container. Fig. 11 shows 
the model as it is deformed at an early time. All of the elements used are shown and the original geometry 
is indicated by dots. These dots would be of no use in the copper fragment views but here they help to 
indicate the amount of deformation. Fig. 12 shows the final shape of the O-ring. The actual elements 
have been removed and only material boundaries are plotted. This helps eliminate many small vectors which 
may detract from the view. The original geometry again is shown by dots. One of the most important features 
of these post-processors is the ability to display scalar data as contours. Figure 13 shows effective 
plastic strain within the O-ring. Other variables such as pressure, temperature, or components of stress/strain 
may also be plotted. A new feature of both SAPP and POSTACO is the ability to produce continuous tone 
color images. More will be said about the color work when we discuss three-dimensional spatial plotting 
but Fig. 14 demonstrates the results of a thermal problem. .-i,. Figure 11. O-ring displaced at early 
time.  / ii i I I Figure 12. Final shape of the O-ring. T IM[--1. OOE-I.O0 MIN(N)= O. MAX(X): 3.53E'-0! 
,CONTOUR LEVI[LS A=O. B = 7.06E-02 C: = 1.061:-01 0 = 1.41[-.01 [ = 1,76E-01 F" -- 2.12E~-01 G = 2.47[-01 
H = 2.82;'-'01 I = 3.18[-01 Figure 13. Contours of effective plastic strain. TEMPORAL PLOTTING The most 
useful code for temporal plotting is GPLOT (17). GPLOT will read the two-or three-dimensional data files, 
store specified quantities for certain nodes or elements, and then plot the values. Up to ten nodal or 
elemental quantities can be plotted on each frame. The nodal quantities are displacement, velocity, 36 
  SUMMARY (9) Hallquist, J.O., "NIKE3D, to appear. A comprehensive package of codes exist in the M.E. 
Department of LLL for the pre- and post-processing of data for and from finite element and finite difference 
analyses. Most are batch oriented and two are interactive. All use graphics as their major means of communication 
with the user. These codes are used daily by many analysts who are not graphics experts. More work needs 
to be performed mostly on the human engineering side of the codes and in the use of color. REFERENCES 
 (1) Gerhard, M.A., "SLIC User's Manual," University of California, Lawrence Livermore Laboratory, Livermore, 
California, UCiD-18166, May 1979. (2) Brown, B.E., "GRAPE -A General Purpose Display Program for Three-Dimensional 
Finite Element Models," University of California, Lawrence Livermore Laboratory, Livermore, California, 
(to appear).  (3) Burger, M.J., "ZONE - A Finite Element Mesh Generator," University of California, 
Lawrence Livermore Laboratory, Livermore, California, UCID-17139, May 1976. (4) Goudreau, G.L., private 
communication, June 1978. (5) Gerhard, M.A., "OASIS -A General Purpose Three-Dimensional Mesh Generator," 
University of California, Lawrence Livermore Laboratory, Livermore, California, ENN-78-36, Oct. 1978. 
 (6) Winslow, A.M., " 'Equipotential' Zoning of Two-Dimensional Meshes," University of California, Lawrence 
Livermore Laboratory, Livermore, California, UCRL-7312, 1963. (7) Brown, B.E., "Modeling of Solids for 
Three-Dimensional Finite Element Analysis," Ph.D. Dissertation, Department of Computer Science, University 
of Utah, Salt Lake City, Utah, June 1977.  (8) Hallquist, J.O., "NIKE2D -An Implicit, Finite Deformation, 
Finite Element Code for Analyzing the Static and Dynamic Response of Two-Dimensional Solids," University 
of California, Lawrence Livermore Laboratory, Livermore, California, UCRL-52768.  (10) Hallquist, J.O., 
"DYNA2D -An Explicit Finite Element and Finite Difference Code for Axisymmetric and Plane Strain Calculations 
(User's Guide)", University of California, Lawrence Livermore Laboratory, Livermore, Calif o~'nia, UCRL-52429, 
March, 1978. (Ii) Hallquist, J.O., "Preliminary User's Manual for DYNA3D and DYNAP," University of California, 
Lawrence Livermore Laboratory, Livermore, California, UCID-17268, 1976. (12) Mason, W.E., Jr., "TACO 
-A Finite Element Heat Transfer Code," University of California, Lawrence Livermore Laboratory, Livermore, 
California, UCID-17980, November, 1978. (13) Sackett, S.J., "SAP4 User's Manual," University of California, 
Lawrence Livermore Laboratory, Livermore, California, internal document. (14) Hallquist, J.O. and Goudreau, 
G.L., "SAPP -A Post-Processor for Two-Dimensional Finite Element Codes," University of California, Lawrence 
Livermore Laboratory, Livermore, California, UCRL-52318, August 1977. (15) Mason, W.E., Jr., "POSTACO 
- A Post-Processor for Scalar, Two-Dimensional Finite Element Codes," University of California, Lawrence 
Livermore Laboratory, Livermore, California, UCID-17979, November 1978. (16) Goudreau, G.L., private 
communication, October, 1977. (17) Young, R.W., "GPLOT -A Temporal Post-Processor for Two- and Three-Dimensional 
Finite Element Codes," University of California, Lawrence Livermore Laboratory, Livermore, California, 
(to appear). (18) Christiansen, H.N., and Stephenson, M.B., "MOVIE.BYU -A General Purpose Computer Graphics 
Display System," Proceedings of the Symposium on Applications of Computer Methods in Engineering, University 
of Southern California, Los Angeles, V. 2, August 1977, pp. 759-769. (19) Watkins, G.S., "A Real-Time 
Visible Surface Algorithm," Department of Computer Science, University of Utah, Salt Lake City, Utah, 
UTEC-CSc-70-101, June 1970.  40 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807423</article_id>
		<sort_key>41</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Stereoscopic computer graphics for simulation and modeling]]></title>
		<page_from>41</page_from>
		<page_to>47</page_to>
		<doi_number>10.1145/800249.807423</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807423</url>
		<abstract>
			<par><![CDATA[<p>A visually effective stereoscopic CRT display technique has been developed which uses continuous tone computer graphics in combination with electro-optic shutter viewing devices. The technique involves the generation of left and right perspective views of an object model using continuous tone computer graphics. The perspective views constitute stereo pairs and are displayed in an alternating manner on the even and odd field scans of a conventional 2:1 interlace raster scan CRT display. When viewed with electro-optic shutters operated synchronously with the CRT field scan rate, the alternating perspective views are perceived as stereoscopic images with strong binocular depth-of-field sensations. Lightweight stereoscopic viewing glasses have been developed which use lead lanthanum zirconate titanate (PLZT) ceramics as electronically controlled shutter elements. Representative applications of the stereoscopic display technique to dynamic flight simulation and complex molecular modeling are presented. The flight simulation illustrates a landing sequence on an aircraft carrier while the modeling application shows complex three-dimensional structures of double helix DNA and bacterial ferredoxin molecules. The stereoscopic display technique has been shown to be highly effective for adding binocular depth-of-field to computer graphics displays with a resulting enhancement of object model realism.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Flight simulators and trainers]]></kw>
			<kw><![CDATA[Modeling]]></kw>
			<kw><![CDATA[Molecular modeling]]></kw>
			<kw><![CDATA[PLZT electro-optic shutters]]></kw>
			<kw><![CDATA[Simulation]]></kw>
			<kw><![CDATA[Stereoscopic displays]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Stereo</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P331553</person_id>
				<author_profile_id><![CDATA[81332524008]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Roese]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Naval Ocean Systems Center, San Diego, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332012</person_id>
				<author_profile_id><![CDATA[81100650516]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lawrence]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[McCleary]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Naval Ocean Systems Center, San Diego, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H., and Stephenson, M. MOVIE-BYU, A general purpose computer graphics display system. Proceedings of Symposium on Applications of Computer Methods in Engineering, University of Southern California, Los Angeles (August 1977).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cutchen, J. T., Harris, J. O., Jr., and Laguna, G. R. Electro-optic devices utilizing quadratic PLZT ceramic elements. 1973 WESCON Technical Papers, 30/2 (September 1973).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Khalafalla, A. S., Jurisson, J., Burbank, D., and Schuck, J. Proceedings of the Society of Photo-Optical Instrumentation Engineers (30 April - 1 May 1973).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Land, C. E., Thacher, P. D., and Haertling, G. H. Electro-optic ceramics. Applied Solid State Science, Wolfe, R. (Ed.). Academic Press, New York (1974).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>639789</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Porter, T. K. Spherical shading. Computer Graphics, Vol. 12, No. 3 (August 1978), 282-285.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Roese, J. A. and Khalafalla, A. S. Stereoscopic viewing with PLZT ceramics. Ferroelectrics, Vol. 10 (1976), 47-51.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Roese, J. A. and McCleary, L. E. Stereoscopic computer graphics using PLZT electro-optic ceramics. Proceedings of the Society for Information Display, 19/2 (1978), 69-73.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S. A Real-time visible surface algorithm. Department of Computer Science, University of Utah, Technical Report UTEC-CSC-70-101 (June 1970).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 STEREOSCOPIC COMPUTER GRAPHICS FOR SIMULATION AND MODELING John A. Roese Lawrence E. McCleary Naval 
Ocean Systems Center San Diego, CA ABSTRACT A visually effective stereoscopic CRT display tech- nique 
has been developed which uses continuous tone computer graphics in combination with electro-optic shutter 
viewing devices. The technique involves the generation of left and right perspective views of an object 
model using continuous tone computer graphics. The perspective views constitute stereo pairs and are 
displayed in an alternating manner on the even and odd field scans of a conventional 2:1 interlace 
raster scan CRT display. When viewed with electro-optic shutters operated synchronously with the CRT 
field scan rate, the alternating perspective views are perceived as stereoscopic images with strong 
binocular depth-of-field sensations. Light- weight stereoscopic viewing glasses have been devel- oped 
which use lead lanthanum zirconate titanate (PLZT) ceramics as electronically controlled shutter elements. 
Representative applications of the ste- reoscopic display technique to dynamic flight simu- lation and 
complex molecular modeling are presented. The flight simulation illustrates a landing sequence on an 
aircraft carrier while the modeling appli- cation shows complex three-dimensional structures of double 
helix DNA and bacterial ferredoxin mol- ecules. The stereoscopic display technique has been shown to 
be highly effective for adding bin- ocular depth-of-field to computer graphics displays with a resulting 
enhancement of object model realism. KEY WORDS AND PHRASES: computer graphics, stereo- scopic displays, 
PLZT electro-optic shutters, simu- lation, flight simulators and trainers, modeling, molecular modeling 
 CR CATEGORIES: 8.1, 8.2 INTRODUCTION The combination of continuous tone computer graphics used with 
electro-optic shutter viewing devices has resulted in visually effective stereoscopic CRT displays 
with strong binocular depth-of-field sen- sations. Stereoscopic computer graphics display techniques 
are ideally suited for the creation of realistic simulations which give true or exaggerated depth-of-field 
effects and for computer modeling applications which require unambiguous visualiza- tions of complex 
structural features. The use of continuous tone computer graphics algo- rithms to generate stereoscopically 
complementary left and right perspective views of object models is straightforward. These algorithms 
are parametric in terms of object viewing orientation and can be used to generate stereo pairs of left 
and right object model perspective views. The stereo pairs are displayed on alternate field scans of 
a con- ventional 2:1 interlace raster scan CRT display. Stereoscopic viewing of the sequence of alternat- 
ing perspective views is accomplished with the use of electro-optic shutters which are mounted in lightweight 
stereoscopic viewing glasses. Syn- chronous operation of the electro-optic shutters with the display 
of alternating left and right computer generated perspective images results in highly effective stereoscopic 
computer graphics displays. Two major areas of applications for stereoscopic continuous tone computer 
graphics displays are simulation and modeling. Representative of dis- play problems in these areas are 
dynamic flight simulations and the visualization of complex three- dimensional molecular structures. 
 STEREOSCOPIC DISPLAY SYSTEMS Many different methods for producing stereoscopic displays have been devised 
dating from the inven- tion of the familiar parlor stereoscope in the nineteenth century. For display 
applications in- volving computer driven CRT devices, two major classes of stereoscopic viewing systems 
have evolved. These are: systems which simultaneously present both left and right perspective views in 
a side-by-side manner on the CRT display (or on adja- cent CRT displays) and use reflective or refractive 
optical means to superimpose the two perspective views; and systems which rapidly alternate the left 
and right perspective views on a single CRT display for viewing with synchronized shutter mechanisms. 
 A recent innovation in the latter class of alter- nating image stereoscopic CRT displays has been the 
use of lead lanthanum zirconate titanate (PLZT) ceramic wafers as electronically controlled optical 
 shutters mounted in a stereoscopic viewer (6,7). Use of PLZT electro-optic ceramics represents a highly 
desirable alternative to earlier electro- mechanical shutter viewing mechanisms. &#38;#169; 1979 ACM 
O-89791-004--4/79/0800--041 $00.75 See Copyright Pg. 41 STEREOSCOPIC COMPUTER GRAPHICS In order to 
produce realistic computer generated stereoscopic images, computer programs are used which produce continuous 
tone images of three- dimensional object models on raster scan CRT dis- plays. These programs are parametric 
in terms of the viewing angle and permit complementary left and right image pairs to be generated and 
combined for stereoscopic displays. Two programs which are well suited for this task are MOVIE-BYU (I) 
and the Spherical Shading Program developed at the National Institutes of Health (5). MOVIE-BYU is 
a highly user oriented program which can be used to produce perspective displays of two- and three-dimensional 
models of static images as well as dynamic animated sequences of line drawing or raster scan displays. 
The program works with polygonal representations of the object model and uses the Watkins algorithm (8) 
for performing hidden surface removal. In order to build a computer model to be displayed, a MOVIE-BYU 
preprocessor called UTILITY is executed on an interactive com- puter terminal. The user inserts X, Y, 
Z coordinate values for each nodal point of the object model and provides connectivity information in 
order to build triangular and/or quadrilateral panels (polygons) which define the surfaces of the object 
model. Panels are them grouped together to form major object parts which are displayed using various 
MOVIE-BYU options. A powerful feature of the pack- age for many applications is the ability to assign 
translational displacements and scalar functions to individual object model nodes. MOVlE-BYU can be invoked 
from the user terminal to display the entire object model or subsets (parts) of the model as it is being 
developed. Parameters which are easily changed in an interactive mode by the user include: o field of 
view, object viewing distance, and near and far Z clipping planes;  o rotation and translation of the 
entire object or separate parts;  o geometric distortions based on nodal dis- placements or scalar functions; 
 o selection of line drawing mode for vector displays or continuous tone mode for raster displays; 
 o color assignment by parts for raster displays;  o amount of ambient light for each part for raster 
displays;  o type of shading for raster displays inclu- ding flat and uniform for a faceted appear- 
ance and smooth shading for a curved surface effect; and  o color assignments for encoding a fourth 
var- iable on a three-dimensional object model.  The Spherical Shading Program has also been used very 
successfully to produce color shaded surface displays of intersecting spheres. The techniques used for 
representing spheres provide speed and storage improvements over the polygonal approach of MOVIE-BYU. 
The Spherical Shading Program provides orthographic views of the object model and is imple- mented on 
a frame buffer with memory large enough to retain the entire image. Additional features of this program 
are the ability to soften the effects of aliasing around the sphere silhouettes and the ability to display 
scenes with both opaque and par- tially transparent spheres. With the generation of left and right perspective 
views of an object using continuous tone computer graphics techniques, a composite image is produced 
which is suitable for stereoscopic viewing. This is accomplished by displaying the pair of images on 
a 2:1 interlace raster scan CRT using one view on the odd line field scan and the stereoscopically complementary 
view on the even line field scan. Stereoscopically complementary images are two views with a rotation 
about the vertical axis which will produce an effective depth of field sensation when viewed. Typically, 
the vertical axis rotation is about a point near the center of the object so that the front of the object 
will appear to extend out from the screen, while the rear of the object will appear to extend into the 
screen. Also, the amount of rotation is an important consideration. In general, the horizontal viewing 
orientation specified for generation of the left and right views should increase with decreasing object 
viewing distance. The stereoscopic computer graphics technique is illustrated in Figs. 3 through 5 for 
an idealized submarine hull model data set. MOVIE-BYU was used to produce the perspective views with 
smooth shad- ing for the curved surfaces. Fig. 3 shows the left perspective view on one field scan with 
the inter- laced field scan blanked. The right perspective view is contained in the other field scan 
as shown in Fig. 4. The composite image in the form required for stereoscopic viewing is shown in Fig. 
5. Here the greatest horizontal displacements are at the bow and stern with little or no displacement 
near the center of the body. Points with no horizontal displacement will appear to be at the surface 
of the CRT screen while the bow will extend outward and the stern inward from the viewing surface. The 
visual sensation of a three-dimensional image is achieved when the composite image is displayed on a 
2:1 interlace CRT and viewed with the PLZT stereoscopic viewer. The electro-optic shutters in the stereoscopic 
viewer are operated synchronously with the CRT vertical retrace sync pulse such that the perspective 
view for one eye is seen during one field scan while the other eye's view is blocked. The process is 
reversed during the subsequent field scan to accommodate the perspective view for the other eye. Repetition 
of this sequence at or near normal 30 frames/sec (60 fields/sec) rates causes the observer to merge the 
rapidly alternating pe T - spective views into a composite three-dimensional image. Losses in vertical 
resolution are inherent in this technique because the perspective view seen by each eye is contained 
on a single field scan. However, since the odd and even field scan lines are interleaved when written 
on the CRT, the re- sulting resolution loss as perceived by the observer is minimal. When used with newer 
60 frames/sec CRT displays, each perspective view is presented at full resolution and, consequently, 
there is no loss in resolution when viewing stereoscopic images. 43   REFERENCES i. Christiansen, 
H., and Stephenson, M. MOVlE-BYU, A general purpose computer graphics display system. Proceedings of 
Symposium on Applications of Computer Methods in Engineering, University of Southern California, Los 
Angeles (August 1977). 2. Cutchen, J. T., Harris, J. O., Jr., and Laguna, G. R. Electro-optic devices 
utilizing quadratic PLZT ceramic elements. 1973 WESCON Technical Papers, 30/2 (September 1973). 3. Khalafalla, 
A. S., Jurisson, J., Burbank, D., and Schuck, J. Proceedings of the Society of Photo-Optical Instrumentation 
Engineers (30 April -i May 1973).  4. Land, C. E., Thacher, P. D., and Haertling,  G.H. Electro-optic 
ceramics. Applied Solid State Science, Wolfe, R. (Ed.). Academic Press, New York (1974). 5. Porter, 
T. K. Spherical shading. Computer Graphics, Vol. 12, No. 3 (August 1978), 282-285.  6. Roese, J. A. 
and Khalafalla, A. S. Stereoscopic viewing with PLZT ceramics. Ferroelectrics, Vol. i0 (1976), 47-51. 
 7. Roese, J. A. and McCleary, L. E. Stereoscopic computer graphics using PLZT electro-optic ceramics. 
Proceedings of the Society for Information Display, 19/2 (1978), 69-73.  8. Watkins, G. S. A Real-time 
visible surface algorithm. Department of Computer Science, University of Utah, Technical Report UTEC-CSC-70- 
i01 (June 1970).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807424</article_id>
		<sort_key>48</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Digital video display systems and dynamic graphics]]></title>
		<page_from>48</page_from>
		<page_to>56</page_to>
		<doi_number>10.1145/800249.807424</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807424</url>
		<abstract>
			<par><![CDATA[<p>Most digital video display systems have been capable of producing only text or static imagery. This paper shows that these limitations are not intrinsic to the technology, but are rather a direct consequence of the display system architecture. The paper begins by summarizing some of the background required to understand digital video display systems. The state-of-the-art is then surveyed, supported by an extensive bibliography. Existing systems are described in terms of a methodology which clarifies the effect of system architecture on capabilities and performance. It is shown how dynamic graphics capabilities can be provided if systems adhere to one or the other of two possible architectures. Examples of such systems are presented.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Animated graphics]]></kw>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Digital video display]]></kw>
			<kw><![CDATA[Dynamic graphics]]></kw>
			<kw><![CDATA[Raster display]]></kw>
			<kw><![CDATA[Raster graphics]]></kw>
			<kw><![CDATA[Video display]]></kw>
			<kw><![CDATA[Video raster system]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Video (e.g., tape, disk, DVI)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010248</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Video segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010230</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Video summarization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P248880</person_id>
				<author_profile_id><![CDATA[81100448368]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ronald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baecker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Associate Professor of Computer Science and Electrical Engineering, University of Toronto]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Donald I. Andrews, "Line Processor&#8212;A Device for Amplification of Display Terminal Capabilities for Text Manipulation", Proceedings of the NCC, 1974, pp. 257-265.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R.A. Aziz, "An Instructional Display Terminal", Proceedings of the Eighth National Symposium on Information Display, May 1967, San Francisco, pp. 83-90.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>888547</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ronald M. Baecker, Interactive Computer-Mediated Animation, Ph.D. Thesis, M.I.T. Dept. of Electrical Engineering, Project MAC Technical Report 61, April 1969.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ronald M. Baecker, "Picture-Driven Animation", Proceedings of the SJCC, May 1969, pp. 273-288.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ronald M. Baecker, "GENESYS&#8212;Interactive Computer-Mediated Animation", appears in Computer Animation (John Halas, Editor), Hastings House, New York, 1974, pp. 97-115.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ronald M. Baecker, "A Computer Animation Facility for Research and Educational Filmmaking: Design and Application", Proceedings of the Fourth NRC Man-Computer Communications Conference, May 1975, pp. 19.1-19.11.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563281</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ronald M. Baecker, "A Conversational Extensible System for the Animation of Shaded Images", Computer Graphics, Volume 10, Number 2, Summer 1976, pp. 32-39.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Barenholtz and C. Dewhurst, "A Run Length Encoding Scheme for Real Time Video Animation", Proceedings of the Northwest 76 ACM/CIPS Regional Symposium.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360905</ref_obj_id>
				<ref_obj_pid>360860</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R.C. Barrett and B.W. Jordan, Jr., "Scan Conversion Algorithms for a Cell Organized Raster Display", Communications of the ACM, Volume 17, Number 3, March 1974, pp. 157-163.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563316</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Forest Baskett and Leonard Shustek, "The Design of a Low Cost Video Graphics Terminal", Computer Graphics, Volume 10, Number 2, Summer 1976, pp. 235-240.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H.G. Bown, C.D. O'Brien, W. Sawchuk, and J.R. Storey, "A General Description of Telidon:&#8212;A Canadian Proposal for Videotex Systems", CRC Technical Note No. 697-E, Communications Research Centre, Canadian Department of Communications, Ottawa, December 1978.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[N. Burtnyk, P. Carey, K. Steele, and M. Wein, "A Video Terminal for Interactive Graphics", Proceedings of the Fifth Man-Computer Communications Conference, May 26-27, 1977, Calgary, pp. 31-44.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Graphics Standards Planning Committee of ACM/SIGGRAPH, Status Report, Computer Graphics, Volume 11, Number 3, Fall 1977.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Peter B. Denes, "Computer Graphics in Colour", Bell Laboratories Record, Vol. 52, May 1974, pp. 138-146.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Peter B. Denes, "A Scan-type Graphics System for Interactive Computing", Proceedings of the Conference on Computer Graphics, Pattern Recognition, and Data Structure, IEEE Computer Society, May 14-16, 1975, pp. 21-24.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Jeffrey F. Eastman and David R. Wooten, "A General Purpose, Expandable Processor for Real-Time Computer Graphics", Computers and Graphics, Volume 1, Number 1, 1975, pp. 73-77.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Jeffrey Entwisle, "An Image Processing Approach to Computer Graphics", Computers and Graphics, Volume 2, Number 2, 1977, pp. 111-117.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>988012</ref_obj_id>
				<ref_obj_pid>988011</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Michael Fischer, "MAPS&#8212;A Generalized Image Processor", Computer Graphics, Volume 7, Number 3, Fall 1973, pp. 1-9.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>988045</ref_obj_id>
				<ref_obj_pid>988044</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Michael A. Fischer and Robert E. Nunley, "Raster Graphics for Spatial Applications", Computer Graphics, Volume 9, Number 2, Summer 1975, pp. 1-8.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[David R. Galloway, The Modelling of Dynamic Digital Video Display Systems, M.Sc. Thesis, Dept. of Computer Science, University of Toronto, 1979 (forthcoming).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D.J. Grover, "Low cost graphic display with serial access store", Computer Bulletin, Volume 15, Number 1, January 1971, pp. 33-37.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[John Halas and Roger Manvell, The Technique of Film Animation, Focal Press, 3rd Ed., 1971.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Herbert C. Hendrickson, "The display/control complex of the Manned Space Mission Control Center", Information Display, May/June 1967, pp. 52-58.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Herbert C. Hendrickson, "A high-precision display system for command and control", Information Display, July/August 1967, pp. 32-36.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Articles on the Model 2640A Interactive Display Terminal Family, Hewlett-Packard Journal, June 1975, Palo Alto Ca.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Articles on the Model 2648A Graphics Terminal, Hewlett Packard Journal, January 1978, Palo Alto Ca.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Francis J. Honey, "Computer Animated Episodes by Single Axis Rotations", Proceedings of the Tenth Annual Meeting of UAIDE, 1971, pp. 3-210-3-226.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Gregory M. Hunter, "Full-colour Television from the Computer, Refreshed by Run-length Codes in Main Memory", Technical Report Number 182, Computer Science Laboratory, Princeton University, April 21, 1975.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Gregory M. Hunter, "Computer Animation and Run-length Codes", Technical Report Number 199, Computer Science Laboratory, Princeton University, February 25, 1975.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Charles H. Irby, "Display Techniques for Interactive Text Manipulation", Proceedings of the NCC, 1974, pp. 247-255.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>362537</ref_obj_id>
				<ref_obj_pid>355611</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[B.W. Jordan, Jr. and R.C. Barrett, "A Scan Conversion Algorithm with Reduced Storage Requirements", Communications of the ACM, Volume 16, Number 11, November 1973, pp. 676-682.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360836</ref_obj_id>
				<ref_obj_pid>360827</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[B.W. Jordan, Jr. and R.C. Barrett, "A Cell Organized Raster Display for Line Drawings", Comunications of the ACM, Volume 17, Number 2, February 1974, pp. 70-77.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya, Ivan E. Sutherland, and Edward C. Cheadle, "A Random-Access Video Frame Buffer", Proceedings of the Conference on Computer Graphics, Pattern Recognition, and Data Structure, IEEE Computer Society, May 14-16, 1975, pp. 1-6.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Alan Kay, Presentation at the First Annual Conference on Computer Graphics and Interactive Techniques, Boulder Colorado, July 1974.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[W.J. Kubitz. and W.J. Poppelbaum, "The Tricolor Cartograph: a display system with automatic coloring capabilities", Information Display, November/December 1969, pp. 76-79.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[B.A. Laws and W.M. Newman, "A Gray-scale Graphic Processor using Run-length Coding", Proceedings of the Conference on Computer Graphics, Pattern Recognition, and Data Structure, IEEE Computer Society, May 14-16, 1975, pp. 7-10.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Learning Research Group, Personal Dynamic Media, Xerox Palo Alto Research Center, 1976.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Malcolm Macaulay, "A Low Cost Computer Graphic Terminal", Proceedings of the FJCC, 1968, pp. 777-785.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Roy Madsen, Animated Film: Concepts, Methods, Uses, Interland Publishing Inc., 1969.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Rex Malik, "The TV as a Terminal", Datamation, March 1978, pp. 213-215.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807387</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Philippe Matherat, "A Chip for Low-Cost Raster-Scan Graphic Display", Computer Graphics, Vol. 12, No. 3, August 1978, pp. 181-186.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[T.E. McCracken, B.W. Sherman, and S.J. Dwyer III, "An Economical Tonal Display for Interactive Graphics and Image Analysis Data", Computers and Graphics, Volume 1, Number 1, 1975, pp. 79-94.]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Richard A. Metzger, "Computer generated graphic segments in a raster display", Proceedings of the SJCC, 1969, pp. 161-172.]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[David H. Miller, David R. Galloway, William T. Reeves, Ronald M. Baecker, and H. Dominic J. Covvey, "SPIWRIT: A Proposed Dynamic Colour Video Graphics Device", Computer Systems Research Group, University of Toronto, revised version, 1979.]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[David H. Miller, Two Dimensional Video Animation Processors, M.A.Sc. Thesis, Dept. of Electrical Engineering, University of Toronto, 1979 (forthcoming).]]></ref_text>
				<ref_id>45</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563283</ref_obj_id>
				<ref_obj_pid>965143</ref_obj_pid>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Allan J. Myers, "A Digital Video Information Storage and Retrieval System", Computer Graphics, Volume 10, Number 2, Summer 1976, pp. 45-50.]]></ref_text>
				<ref_id>46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Nicholas Negroponte, "Raster Scan Approaches to Computer Graphics", Computers and Graphics, Volume 2, Number 3, 1977, pp. 179-193.]]></ref_text>
				<ref_id>47</ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Theodore H. Nelson, The Home Computer Revolution, The Distributors, 702 South Michigan, South Bend, Indiana 46618, 1977.]]></ref_text>
				<ref_id>48</ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[William M. Newman and Robert F. Sproull, "An Approach to Graphics System Design", Proceedings of the IEEE, Volume 62, Number 4, April 1974, pp. 471-483.]]></ref_text>
				<ref_id>49</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[William M. Newman and Robert F. Sproull, Principles of Interactive Computer Graphics, 2nd Edition, McGraw-Hill, 1973.]]></ref_text>
				<ref_id>50</ref_id>
			</ref>
			<ref>
				<ref_obj_id>362567</ref_obj_id>
				<ref_obj_pid>362566</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[A. Michael Noll, "Scanned-Display Computer Graphics", Communications of the ACM, Volume 14, Number 3, March 1971, pp. 143-150.]]></ref_text>
				<ref_id>51</ref_id>
			</ref>
			<ref>
				<ref_obj_id>363385</ref_obj_id>
				<ref_obj_pid>363347</ref_obj_pid>
				<ref_seq_no>52</ref_seq_no>
				<ref_text><![CDATA[D. Ophir, S. Rankowitz, B.J. Shepherd, and R.J. Spinrad, "BRAD: The Brookhaven Raster Display", Communications of the ACM, Volume 11, Number 6, June 1968, pp. 415-416.]]></ref_text>
				<ref_id>52</ref_id>
			</ref>
			<ref>
				<ref_seq_no>53</ref_seq_no>
				<ref_text><![CDATA[D. Ophir and B.J. Shepherd, "ITN&#8212;Data Terminal Network Computer System", Nuclear Instruments and Methods 62, 1968, pp. 285-294.]]></ref_text>
				<ref_id>53</ref_id>
			</ref>
			<ref>
				<ref_seq_no>54</ref_seq_no>
				<ref_text><![CDATA[D.E. Pearson, Transmission and Display of Pictorial Information, Halsted Press, John Wiley &amp; Sons, 1975.]]></ref_text>
				<ref_id>54</ref_id>
			</ref>
			<ref>
				<ref_seq_no>55</ref_seq_no>
				<ref_text><![CDATA[Richard B. Preiss, "Storage CRT Display Terminals: Evolution and Trends", Computer, Vol. 11, No. 11, November 1978, pp. 20-26.]]></ref_text>
				<ref_id>55</ref_id>
			</ref>
			<ref>
				<ref_seq_no>56</ref_seq_no>
				<ref_text><![CDATA[Gordon A. Rose, "Intergraphic&#8212;A Microprogrammed Graphical-Interface Computer", IEEE Transactions on Electronic Computers, Volume EC-16, Number 6, December 1967.]]></ref_text>
				<ref_id>56</ref_id>
			</ref>
			<ref>
				<ref_seq_no>57</ref_seq_no>
				<ref_text><![CDATA[Gordon A. Rose, "Computer Graphics Communication Systems", Proceedings of the IFIP Conference, 1968, pp. 211-220.]]></ref_text>
				<ref_id>57</ref_id>
			</ref>
			<ref>
				<ref_seq_no>58</ref_seq_no>
				<ref_text><![CDATA[Ellen Roseman, "Video Games Are Back With A New Wrinkle", The Globe and Mail, Nov. 26, 1977, p. 4.]]></ref_text>
				<ref_id>58</ref_id>
			</ref>
			<ref>
				<ref_seq_no>59</ref_seq_no>
				<ref_text><![CDATA[R.S. Rougelot, "The General Electric Computer Color TV Display", appears in Pertinent Concepts in Computer Graphics (M. Faiman and J. Nievergelt, Editors), University of Illinois Press, 1969.]]></ref_text>
				<ref_id>59</ref_id>
			</ref>
			<ref>
				<ref_seq_no>60</ref_seq_no>
				<ref_text><![CDATA[Don Ruder "Data Disc Television Display System", Proceedings of the UAIDE Annual Meeting, 1968, pp. 338-357.]]></ref_text>
				<ref_id>60</ref_id>
			</ref>
			<ref>
				<ref_seq_no>61</ref_seq_no>
				<ref_text><![CDATA[William A. Saxton and Morris Edwards, "Data Base Access Through Home TV Is Now A Reality", Canadian Datasystems, December 1977, pp. 56-57.]]></ref_text>
				<ref_id>61</ref_id>
			</ref>
			<ref>
				<ref_seq_no>62</ref_seq_no>
				<ref_text><![CDATA[Richard Shoup, Presentation at the First Annual Conference on Computer Graphics and Interactive Techniques, Boulder Colorado, July 1974.]]></ref_text>
				<ref_id>62</ref_id>
			</ref>
			<ref>
				<ref_seq_no>63</ref_seq_no>
				<ref_text><![CDATA[Robert F. Sproull and William M. Newman, "The Design of Gray-scale Graphics Software", Proceedings of the Conference on Computer Graphics, Pattern Recognition, and Data Structure, IEEE Computer Society, May 14-16, 1975, pp. 18-20.]]></ref_text>
				<ref_id>63</ref_id>
			</ref>
			<ref>
				<ref_seq_no>64</ref_seq_no>
				<ref_text><![CDATA[John Staudhammer and Deborah J. Ogden, "Computer Graphics for Half-tone Three-dimensional Object Images", Computers and Graphics, Volume 1, Number 1, 1975, pp. 109-114.]]></ref_text>
				<ref_id>64</ref_id>
			</ref>
			<ref>
				<ref_seq_no>65</ref_seq_no>
				<ref_text><![CDATA[M.M. Taylor and J.A. Norton, "A Versatile Colour Raster Display System for Visual Psychophysics and Image Processing", Proceedings of the Digital Equipment Computer Users Society (Canada), February 1977, pp. 923-929.]]></ref_text>
				<ref_id>65</ref_id>
			</ref>
			<ref>
				<ref_seq_no>66</ref_seq_no>
				<ref_text><![CDATA[Articles on the Tektronix 4025 Computer Display Terminal in Tekscope, Volume 10, Number 1, 1978, Tektronix Inc., Beaverton Or.]]></ref_text>
				<ref_id>66</ref_id>
			</ref>
			<ref>
				<ref_seq_no>67</ref_seq_no>
				<ref_text><![CDATA[Articles on the Tektronix 4027 Computer Display Terminal in Tekscope, Volume 10, Number 4, 1978, Tektronix Inc., Beaverton Or.]]></ref_text>
				<ref_id>67</ref_id>
			</ref>
			<ref>
				<ref_seq_no>68</ref_seq_no>
				<ref_text><![CDATA[R.H. Terlet, "The CRT Display Subsystem of the IBM 1500 Instructional System", Proceedings of the FJCC, 1967, pp. 169-176.]]></ref_text>
				<ref_id>68</ref_id>
			</ref>
			<ref>
				<ref_seq_no>69</ref_seq_no>
				<ref_text><![CDATA[Daniel E. Thornhill and Thomas B. Cheek, "Raster-scan tube adds to flexibility and lower cost of graphic terminal", Electronics, February 7, 1974, pp. 95-101.]]></ref_text>
				<ref_id>69</ref_id>
			</ref>
			<ref>
				<ref_seq_no>70</ref_seq_no>
				<ref_text><![CDATA[Michael D. Tilson, Editing Computer Animated Film, Technical Report CSRG-66, Computer System Research Group, University of Toronto, January 1976.]]></ref_text>
				<ref_id>70</ref_id>
			</ref>
			<ref>
				<ref_seq_no>71</ref_seq_no>
				<ref_text><![CDATA[Edwin R. Tripp III and Jimmie R. Suttle, "An Interactive Three-Dimensional Color Graphics System", Computers and Graphics, Volume 1, Number 2/3, 1975, pp. 211-214.]]></ref_text>
				<ref_id>71</ref_id>
			</ref>
			<ref>
				<ref_seq_no>72</ref_seq_no>
				<ref_text><![CDATA[K.W. Uncapher, "The RAND Video Graphics System&#8212;An Approach to a General User-Computer Graphic Communication System", RAND Report P-753-ARPA, April 1971.]]></ref_text>
				<ref_id>72</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 DIGITAL VIDEO DISPLAY SYSTEMS AND DYNAMIC GRAPHICS Ronald Baecker Associate Professor of Computer Science 
and Electrical Engineering University of Toronto President Human Computing Resources Corporation Abstract: 
Most digital video display systems have been capable of produc- ing only text or static imagery. This 
paper shows that these limitations are not intrinsic to the technology, but are rather a direct consequence 
of the display system architecture. The paper begins by summarizing some of the background required to 
understand digital video display systems. The state-of-the-art is then surveyed, supported by an extensive 
bibliography. Existing systems are described in terms of a methodology which clarifies the effect of 
system architecture on capabilities and performance. It is shown how dynamic graphics capabilities can 
be provided if systems adhere to one or the other of two possible architectures. Examples of such sys- 
tems are presented. C.R. categories: 8.2, 6.35 Keywords and phrases: digital video display, video display, 
video raster system, raster display, raster graphics, dynamic graphics, computer anima- tion, animated 
graphics. 1. BACKGROUND 1.1. Digital Video Display Systems 1.1.1. Fundamental Concepts A digital video 
display system is one in which: 1) The final image-is displayed on a raster scan cathode ray tube (televi- 
sion type terminal); and, 2) There is an underlying digital representation of the image stored in a controlling 
computer. (This condition excludes systems such as the Tri- color Cartograph [Kubitz 69], and Computer 
Image's Scanimate and Cae- sar [Honey 71].) The raster scanning signal may but need not conform to an 
international TV standard, such as NTSC or PAL, which determines characteristics of the signal such as 
its frame rate, the number of lines per frame, and the method of colour encoding [Pearson 75]. The digital 
representation may be a frame buffer, in which contiguous chunks of memory (such as bits or bytes) represent 
contiguous pixels (discrete elements of the final picture), or it may be an encoded representation of 
the picture. In the latter case, it must be transformed into video format (scan converted) by a video 
display processor on its way to the cathode ray tube. 1.1.2. Advantages Digital video systems emerged 
in the late 60s and came into their own in the middle 70s as a viable alternative to random scan displays 
(also known as calligraphic, stroke-writing, line-drawing, or vector displays). Initially, digital .video 
displays were attractive because they were clustered systems which shared expensive image generators 
and allowed additional worksta- tions to be added at low incremental cost. The universality of television 
meant that digital video workstations based on TV monitors could take advantage of their low cost and 
ready availability of maintenance expertise. The communication of images from site to site could also 
be facilitated by the use of the established technology of television transmission. (An early discussion 
of these advantages appears in [Hendrickson 67a,b].) Other aspects of television gave raster scan displays 
an advantage over ran- dom scan terminals. Lines could easily be thickened; areas could be shaded. Grey 
scale, colour, and black-and-white reversal could be employed. The computer-generated images could easily 
be mixed with live television images, either still or moving. 1.1.3. Disadvantages Raster scan displays, 
however, have had some significant problems to overcome, Most have been limited to resolutions such as 
256 X 256, 240 X 320, 512 X 512, or 480 X 640. They have been expensive due to the cost of providing 
this much electronic memory. They have been slow due to the difficulty of the processing required for 
scan conversion. These two components, memory and processing power, will prove central to the analysis 
which follows. 1.2. Display Processors for Vector Graphics Translation of an encoded picture into a television 
signal requires a video display processor. These are similar to the display processors which tradi- tionally 
have been used to refresh vector displays from display files. Thus we will review our current understanding 
of vector displays, with an analysis and figures adapted from [Newman 74]. i~ums~vorS / ~SP~v Figure 
1 - Typical Structure of an Interactive Graphics System NOTE: Figures 1 through 4 are adapted from [Newman 
74].  &#38;#169;1979 ACM O-89791-004--4/79/0800--048 $00.75 See Copyright Pg. 48 A diagram of a typical 
graphics system appears in Figure 1. The output process consists of the modules beginning with and to 
the right of output routines. Output routines are the statements in the application program which define 
how the data is to be visualized for display purposes. The transformation and clipping routines carry 
out scaling, rotating, and translat- ing of the pictures, and clip them to rectangular boundaries to 
remove parts that should not appear on the screen. The concatenation routine car-ries out the combining 
of multiple tranformations which are to be applied to the same object. The display generator usually 
includes a vector genera- tor and a character generator, and converts the picture into a form suitable 
for the display's deflection system. Figure 2 --A Simple Refreshed Display These modules comprising 
the display output process have typically been realized in a variety of different forms, such as those 
depicted by Figures 2, 3, and 4. Figure 2 shows the organization of a simple refreshed display. The CPU 
performs the transformations, inserting new transformed and clipped pictures into a transformed display 
file, in which each distinct picture is stored as a distinct entity, or segment. Performance of the system 
tends to be limited by the speed with which segments can be recomputed by the CPU. Figure 3 -A 'High-Performance' 
Display with a Structured Picture Definition The "high-performance" display architecture in Figure 3 
was developed as a solution to this performance limitation. Pictures are stored in an encoded or structured 
form, a structured picture definition (SPD). A display proces- sor, usually hard-wired, interprets this 
structure, performs the appropriate transformation and clipping, and sends the picture to the display. 
The intent of the design is that changes to the SPD are to be immediately visi- ble on the screen. However, 
if the display becomes too complicated rela- tive to the capabilities of the display processor, the picture 
will begin to flicker. An alternate solution, the buffered transformation processor depicted in Fig- 
ure 4, overcomes this difficulty. As in the previous solution, we have a hard-wired transformation processor, 
but now its function is separated from the refresh processor. Thus transformations and refreshing can 
occur independently and at different rates. Because each segment is double buffered in the display file, 
the old version will always be visible until the new one is computed. Since the refresh process is typically 
faster than the transformation process, a more complex fiicker-free image may be displayed. There are 
other possible architectures for vector graphics, for example, the storage tube display [Preiss 78]. 
Storage tubes have been popular because they are cheap and because they can display a complex flicker-free 
image of high resolution. Digital video displays have long been regarded as Figure 4 --A Buffered Transformation 
Processor selectively eraseable storage tube replacements. This is misleading, for it suggests, incorrectly, 
that digital video technology is only appropriate for static graphics. 1.3. Related Technological Developments 
The evolution of digital video display systems has been and will continue to be affected by a variety 
of technological and economic factors. 1.3.1. Advances in Microelectronics Large-scale integrated circuit 
technology makes feasible digital video display system designs that were impossible a few years ago. 
Most important has been the availability of large cheap semiconductor memories. The 1K MOS RAM was first 
delivered in 1970 and became available in volume in 1972. The 4K MOS RAM was first delivered in 1973 
and became available in volume in 1975. The 16K MOS RAM was first delivered in 1976 and is now available 
in volume. 64K MOS RAMs are just now becoming available. Thus we already have the capability of storing 
a binary medium resolution (256 X 256) raster image in randomly accessible form on a single chip. The 
pace of these developments is expected to continue through several more advances before encountering 
any fundamental obstacles, although they may be slowed somewhat by the need to move from visible light 
to electron beams to X-rays for drawing the integrated circuit masks. Thus the cost in the mid 1980s 
of buffering an entire 512 X 512 X 8-bit picture in random access memory should be under $100. Another 
relevant technology is that of shift registers, or cyclic memories. Semiconductor shift registers could 
be used cost-effectively in frame buffers in the early 1970s when RAMs were still much too expensive. 
Currently, charge-coupled devices (CCDs) seem to be offering four times the storage of RAMs at comparable 
prices. Thus systems that would be too expensive using RAMs may be feasible albeit with reduced perfor- 
mance using CCDs. 1.3.2. Home Terminals -Complementary Technologies and Competing Vendors The largest 
potential market for digital video display systems is in home computer terminals. There are three complementary 
technologies whose vendors will compete in the evolution of home computer terminals. These technologies 
are those of the computer, the television screen, and the communications link to outside resources. Vendors 
of hobby and personal computers will seek increasingly to expand their machines into complete home computers 
and into terminals to sophisticated remote services. Since the advent of the personal computer early 
in 1975, over 200,000 have been sold in North America. Sales in the 1980s have been projected as high 
as tens of millions of units [Nelson 77]. Vendors of TV games will seek increasingly to achieve greater 
flexibility and versatility by providing programmable systems of greater and greater power. One vendor 
has predicted that every family would have its own home computer by 1983 [Roseman 77]. 49 Vendors of 
interactive television will seek increasingly to enhance the range of services and imagery that 2-way 
cable can provide. For example, the British Post Office has for several years been working with two experi- 
mental systems, Teletext and Viewdata [Saxton 77; Malik 78]. Teletext allows the viewer to request, store, 
and display one of a small number of pages of text which are constantly being transmitted in unused lines 
of the television signal. Viewdata allows him to request a specific page from a large library of pages. 
In both cases, the desired page is stored in a digital memory inside a specially modified television 
receiver. Teletext constantly cycles a fixed number of pages; the viewer selects one by means of thumb 
wheel switches or push buttons. With Viewdata, the viewer requests a specific page from the library by 
dialing a central computer and indicating his choice with a touch-tone phone or special keyboard. Although 
the image display capabilities of these systems are quite limited, this need not be so, as can be seen 
in the Canadian Department of Communications Telidon project [Bown 78]. 2. A METHODOLOGY FOR THE DESCRIPTION 
OF DIGITAL VIDEO DISPLAY SYSTEMS Numerous digital video display systems have been designed and built 
in the past ten years. Some have been created as unique experimental imple- mentations; others have been 
developed and sold commercially. Some have been singie-user displays; others have consisted of clusters 
of termi- nals. Systems have been developed using a great diversity of techniques for a great diversity 
of applications. How can we compare and contrast existing designs if they are so diverse? We propose 
a methodology for describing digital video display systems which focuses on a few key attributes of their 
organization. This metho- dology will help us organize our understanding of existing systems, and, embodied 
in an appropriate modelling environment, could help us predict the efficacy of proposed designs. The 
methodology is particularly helpful in clarifying the relationship between the design of a digital video 
display system and its capacity for dynamic graphics. We shall introduce the methodology with a simple 
example. MEMORY Figure 5 --A Character-Oriented Video Display Terminal Consider the common alphanumeric 
(character-oriented) video display ter- minal One possible architecture for such a system is shown in 
Figure 5. The CPU is a microprocessor. The memory contains a display file consist- ing of the ASCII characters 
currently on the screen, and also a font definition, a representation of the appearance of the characters. 
The former is always stored in RAM; the latter is often stored in ROM. The display processor combines 
the ASCII values, the representations of the characters in the font memory, and the positions of the 
characters on a coarse grid (such as 24 X 80) to provide successive intensity amplitudes for the television 
scan. The display processor is simple because it inter- prets only one instruction, i.e., display a character. 
It is so simple that it is now possible to Synthesize it out of a few chips. Yet this is not the only 
system architecture that can carry out the same task. Characters can also be displayed with systems constructed 
according to the architecture depicted in Figure 6. Processor P1 performs character expansion from the 
memory of the CPU into a bit map, which is a frame buffer with a single bit of memory per pixel. Processor 
P2 fetches succes- sive chunks from this memory and uses them to provide successive inten- sity amplitudes 
for the television scan. There are advantages and disadvantages to both approaches. The design of Figure 
5 has typically led to a cheaper realization. It is also more dynamic, allowing more rapid change to 
the picture on the screen. The design of Figure 6 is more flexible, allowing characters in arbitrary 
fonts as well as vectors, curves, and line drawings. Figure 6 -Another Architecture for Character Display 
in Video Format The example suggests an approach to the analysis of existing designs and the synthesis 
of new ones. Our methodology represents digital video display systems as configurations of processors 
and memories with specific performance characteristics. This technique helps us to survey, compare, and 
contrast the great diversity of past and present systems. A common element in these systems is the need 
for scan conversion. Scan conversion is the transformation of a picture represented in terms of points, 
vectors, and characters into one represented in a raster scan for- mat. In Figure 5, scan conversion 
is carried out by the display processor. In Figure 6, scan conversion is carried out by P1. Scan conversion 
can be a time-consuming computation, one which can be carried out in different ways depending upon the 
representations in which the picture is stored before and after the conversion process, and the amount 
of available storage. Various scan conversion algorithms are described in [Newman 79], [Metzger 69], 
[Jordan 73], [Barrett 74], and [Thornhill 74]. 3. A SURVEY OF EXISTING SYSTEMS  3.1. Sequential Access 
Frame Buffer Systems The earliest digital video displays were clustered systems in which multiple terminals 
were refreshed from one expensive centralized image computa- tion and storage system. They were frame 
buffers, in which there was a direct correspondence between chunks of memory and image pixels on the 
screen. Most early realizations, developed in the late 60s, were based on rotating memories. (A delay 
line implementation is described in [Graver 71].) Later systems, in the early 70s, incorporated electronic 
shift registers. These choices were the only cost-effective solutions available with the then current 
technology. A diagram describing the architecture of such systems appears as Figure 7. Processor P1, 
when present, performs such services as vector and charac- ter expansion. The sequential nature of the 
cyclic memory limits perfor- mance, because P1, in updating the frame buffer, must wait until the appropriate 
point of the memory is available for updating. Processor P2, which reads from the frame buffer to control 
the television scan, is not limited by the cyclic memory, because the data is stored in the order that 
is required for the scan. -y Scan Coeven~on Figure 7 --A Sequential Access Frame Buffer System 3.1.1. 
Systems with Physically Rotating Memories One of the earliest systems of this kind was the IBM 1500 Instructional 
System [Aziz 67; Terlet 67]. The system provided coarse resolution text in a variety of fonts to 32 terminals. 
Character streams and font definitions were stored in the CPU, which scan converted them (12 scan lines 
at a time) and wrote them onto tracks of a digital disk. Processors P1 and P2 were minimal. 50 A similar 
system was the Brookhaven Raster Display System [Ophir 68a,b]. The system provided 512 X 512 binary images 
to 32 terminals. The refresh memory was a 32 track rotating digital drum, with one read head per display. 
Scan conversion was performed on an entire image in the CPU, Again P1 and P2 were minimal. A different 
approach to the problem of scan conversion was taken in the Rand Video Graphic System [Uncapher 71]. 
The processor P1 consisted of a microprogrammed graphic display controller, a vector and character generator, 
three vidicon scan-converter tubes, and three 32 position switches. Vector graphic images were written 
as charge patterns onto the faces of the vidicon tubes, then read off the tubes in raster format and 
routed via the switches onto tracks of a 32 track analog video disk. These pictures could be mixed with 
each other and with natural pictures from a television camera by the processor P2 and distributed to 
workstations located throughout the laboratory. A similar system was implemented at the University of 
New South Wales [Macaulay 68; Rose 67,681. Another style of use of an analog video disk is described 
in [Staudhammer 75]. Commercial digital disk systems included the Anagraph from Data Disc (now Ancomp) 
[Ruder 68] and the early models from Comtal, now both obsolete. 3.1.2. Systems with Sh~ft Register Memories 
One early commercial product of this kind was the Computek 300 (circa 1970). This terminal was designed 
as a selectively eraseable replacement for the storage tube. To keep the cost down, it was limited to 
a 256 X 256 binary picture. Possibly because of its low resolution, the product was not successful. A 
successful commercial product (circa 1972) was the Ramtek GX-100. Ramtek was formed by a group of Data 
Disc employees who felt that the future lay with solid state memories. The GX-100 was a clustered system 
like those from Data Disc. P1 contained a vector generator, a character generator, and a number of generators 
for special displays such as rectan- gles and graphs. Each memory bank stored one bit per point; the 
outputs from several banks could be combined to yield gray scale or colour capabil- ities (a feature 
previously introduced in the Data Disc systems). Also as in the Data Disc systems, these banks could 
be purchased at varying reso- lutions from 256 X 256 to 512 X 768. The system had an awkward memory organization, 
where each bank consisted of 16 cycling shift regis- ters, 8 for each TV field, which did however have 
the advantage of reduc- ing the average access time for a point to 1 millisecond. A notable experimental 
system was that designed by Dick Shoup at the Xerox Pale Alto Research Center [Shoup 74]. Shoup's frame 
buffer con- sisted of one very long shift register refreshing a 480 X 640 X 8-bit pic- ture. The average 
time to access an arbitrary point was 16.7 milliseconds. The 256 colours available at any one time could 
be chosen from a total of 1 billion possible colours through the use of a programmable colour map which 
allowed 10 bits of red, 10 bits of blue, and 10 bits of green. PI was a run-length encoder-deeoder which 
transformed pictures between the frame buffer and the CPU. P2 included a video switching network which 
allowed single frames to be routed to one track of a 300 track analog video disk. This disk was used 
for real-time playback of animation sequences and for transferring them to video tape. Another experimental 
system, a 256 X 256 X 8-bit gray scale display implemented with MOS shift regis- ters, is described in 
detail in [McCracken 75]. 3.2. Random Access Frame Buffers By 1973, the availability of 4K MOS semiconductor 
chips made it possible to build large random access frame buffers, whose architecture is depicted in 
Figure 8. These systems were usually configured as a number of memory planes with resolutions such as 
256 X 256 or 480 X 640. 8 bits of 512 X 512 resolution was not uncommon. Modern semiconductor tech- nology 
also often affected processor P1; it could now be implemented as a microprocessor rather than with discrete 
hard-wired logic, and so the entire display could be located remotely from the host CPU. Scan Conversion 
Figure 8 --A Random Access Frame Buffer The major impact of the random accessibility of points is increased 
perfor- mance of the scan converter P1. Scan conversion can proceed in one pass over the data without 
being constrained by the cyclic availability of points in the frame buffer. A secondary impact is manifested 
in P2 in the more sophisticated systems. Because P2, like PI, can access the frame buffer in random fashion, 
it can perform a variety of reformatting and mixing func- tions on several images stored in a very large 
frame buffer. One of the earliest examples of such systems was an experimental display system constructed 
at Bell Telephone Laboratories at Murray Hill, New Jersey [Nell 71; Denas 74,75]. One-, two-, or three-bit 
gray scale or colour pictures were refreshed directly out of the CPU's memory. Software scan conversion 
was aided by a hard wired processor P1 which computed the memory word and bit positions from a pixel's 
X and Y coor- dinates. Commercial random access frame buffers, all with independent semicon- ductor refresh 
memory, are currently made by the following manufactur- ers: Aydin Controls, Calcomp, Child, Chromatics, 
Comtal, DeAnza Sys- tems, Evans and Sutherland, Genisco, Grinnell Systems, Hewlett Packard, Intermedia 
Systems, Interpretation Systems, Lexidata, Matrox, Norpak, Ramtek, and Videographics. Most systems are 
similar to the GX-100, albeit with enhanced performance due to the use of random access memory. Their 
products differ in the number of possible independent displays supported by the same memory and processing 
logic, the available resolutions, the number of possible bits per pixel, the memory organiza- tion, and 
in the vector and character expansion capabilities of their P1 pro- cessors. There is also great variety 
in their P2 processors. They may include programmable colour maps, programmable cursors, zoom and pan 
capabilities, and image overlay capabilties. The Calcomp IGT 100 and the Hewlett Packard 2648A [HP 781 
are single work-station black-and-white displays; most of the other products have colour capabilities, 
and several can handle multiple terminals. One unique feature of the Caleomp is a three-way split-screen 
capability which allows simultaneous display of graphics, a blown-up portion of the graphics, and text. 
The most sophisticated system of the mid 70s was the Evans and Suther- land Video Frame Buffer [Kajiya 
75]. The 512 X 512 X 8-bit multi-ported MOS memory is 8-way interleaved and comes with its own mapping 
hardware so that the entire memory can be addressed by the host CPU. Various kinds of flexibility have 
been provided. "Format control" allows one to vary the number of horizontal and vertical raster elements, 
the kind of interlace desired, and the duration of both horizontal and vertical flyback times. "Memory 
control" allows one to refresh different frames from different sections of memory. "Intensification control" 
provides a programmable colour map with 12 bits of red, 12 of blue, and 12 of green. The system can be 
used to present one high resolution TV frame, to play back low resolution motion sequences, to scroll 
through a large picture, and to display sections of a high resolution frame to a precision film recorder. 
Recently, a few even larger experimental systems have been designed and implemented. [Fischer 73,751 
describes a system which can handle up to 4 images of up to 640 X 480 X 8 bits, can translate and scale 
each image independently, and can compare and create special effects between images through a series 
of programmable priorities between the images. [Entwisle 77] and [Negroponte 77] describe a system which 
drives a variable resolu- tion monitor, which allows a flexible trading off between resolution and the 
number of bits-per-point, and in which memory planes need not be of the same size, proportion, or position. 
Planes may be combined via pro- grammable priorities into images; portions of these images which fall 
51 within rectangular windows can be mapped into rectangular viewports on the screen. [Taylor 77] describes 
a system with a 512 X 512 X 34 bit memory in which various 512 X 256 planes can be flexibly combined 
to form 2 video displays. A scan transfer processor allows the programming of scanning patterns which 
control the order of data transfers between the memory and an external CPU and array processor. At the 
other extreme, [Matherat 78] presents the design of a single LSI chip to implement all the control functions 
of an interesting frame buffer.  3.3. Systems with Coded Picture Definitions Whether frame buffers are 
sequentially or randomly accessible, the speed with which changes to the picture are reflected on the 
screen is limited by the speed of scan conversion. A variety of designs have attempted to pro- vide instantaneous 
appearance of picture changes by refreshing the screen directly from a coded picture definition. The 
picture is constructed "on the fly" from a condensed digital representation. This architecture is compar- 
able to the use of structured picture definitions with vector displays. There, increasing the complexity 
of the structured picture definition causes the refresh process to slow down, introducing flicker. With 
raster displays, the refesh process cannot slow down, so limitations must be placed on the complexity 
of the picture definition to match the capabilities of the refresh- ing (and scan converting) processor. 
Such an architecture is depicted in Figure 9, CODED PICTURE ~~DEFINITION Scan Conversion Figure 9 --A 
System with a Coded Picture Def~ition In practice, a variety of restrictions have been placed on the 
picture definitions. The most common is that of the alphanumeric video display terminal (VDT). The design 
of a well-engineered family of such terminals is documented in [HP 75]. [Irby 74] and [Andrews 74] discuss 
a microprocessor-driven VDT which allows the screen to be divided into a number of independent windows 
for text display, scrolling, and editing. [Baskett 76] presents a novel VDT design in which the memory 
can be used either to refresh a 480 X 640 binary picture or to store 600 80- character lines of text. 
Programs in the controlling microprocessor allow one to move through this text with a variety of scrolling 
and page turning mechanisms. The first commercial system to go beyond alphanumeric characters was the 
Ramtek FS-2000, which could also display a limited number of horizontal and vertical lines and rectangular 
areas. Its display processor P2 executed instructions at a rate of one every 90 nanoseconds. Although 
each scan line could be encoded in a "program ~ of up to 600 instructions, typical scan lines were encoded 
by a very few instructions. Thus Ramtek provided only 16,000 bits of memory to store 256 X 480 X 4-bit 
pictures, a 30 to 1 reduction in storage over a frame buffer, achieved at the cost of generality. Several 
recent systems have been based on run-length coded display files. Run coding provides an et~cient storage 
technique for simple graphic displays, and one which is easily decoded by a raster scanning refresh pro- 
cessor. [Hunter 75a,b] describes a simple run-coded colour video graphics system intended for simple 
cartoon animation. [Laws 75] describes a run- coded gray-scale graphic processor intended for high quality 
text display. [Myers 76] describes a run-coded system intended for storing and playing back digital colour 
video animation sequences. This is achieved via high- speed DMA transfer from a large digital disk to 
double-ported semicon- ductor memory, and from there to a run length decoding system which expands it 
into NTSC format for display. Another experimental design is described in [Barenholtz 76]. The only such 
system that is available com- mercially is a recent product from Three Rivers Computer Corporation. Many 
recent systems have explored encodings based on generalizations of the "characters" that can be placed 
on the coarse grid of the alphanumeric VDT. Jordan and Barrett [Jordan 74] refer to these as cell displays. 
The simplest example of this is the Commodore PET, which has a number of special symbols which allow 
crude graphic images to be assembled. The Exidy SORCERER, and the Intecolor and Compucolor Systems from 
Intel- ligent Systems Corp., provide a programmable character generator to enrich the class of possible 
images. [Jordan 74] describes an ingenious method whereby 104 basic 8 X 8 patterns can be transformed 
and com-bined to produce all possible line drawings. Another cell display, the Tektronix 4025 "gralpha 
terminal" [Tek 78a], allows a mixture of text and graphics. A rectangular graphics region is defined 
anywhere on a large scrollable page; the remainder of the page is left for characters. The page is divided 
into a coarse grid of cells. Each element on the grid contains a pointer; in the case of the character 
region, it is a pointer to a character generation ROM; in the case of the graphics region, it is a pointer 
to a bit map in a graphics memory RAM. Memory is used efficiently because null pointers are included 
for those grid positions where no picture exists. Tektronix calls this a virtual bit map. The Tek-tronix 
4027 is a similarly designed colour display [Tek 78b]. Finally, there exist very expensive high-performance 
systems which pro- duce in real time moving digital raster images from three-dimensional vec- tor graphic 
representations. These are generally pipelined processors which transform an edge and surface description 
of a collection of three- dimensional objects into the viewer's coordinate system, remove hidden surfaces, 
and smooth shade the result. Examples include the General Electric NASA system for space simulation [Rougelot 
69], several systems built by Evans and Sutherland which have never been described in the open literature, 
and two designs described in [Eastman 75] and [Tripp 75]. 3.4. Systems with Coded Picture Definitions 
and Double Frame Buffers In vector graphics, the buffered transformation processor depicted in Fig- ure 
4 allows the transformation and refresh processes to proceed at separate speeds, and a steady flicker-free 
image to be maintained, indepen- dent of the time required to transform the picture. When a change is 
introduced, the old version of the image is displayed until the new one is computed. We can apply the 
same idea to raster displays. The problem with the architecture of Figure 9 is that the system cannot 
perform the scan conversion in a frame time if the image complexity becomes too great, and so the picture 
will disintegrate in some graceful or ungraceful way. Therefore we introduce a double frame buffer after 
the decoding and scan converting processor P2, yielding the architecture shown in Figure 10. The system 
will switch back and forth between buffers after each new one Scan Conversion Figure 10 - A System with 
a Coded Picture Definition and a Double Frame Buffer 52 is computed. Now new images can be computed 
and displayed, no matter how complex they are, we may only have to wait longer to see the result. This 
is not a solution to be undertaken lightly, because the system now includes both an expensive scan conversion 
processor P2 and three representations of the picture, including a double frame buffer. One example of 
such a system is the Interim Dynabook implemented at the Xerox Palo Alto Research Center [Kay 74; LRG 
76; Baecker 76]. Primitive pictures are defined as 256 X 256 rasters of points, each black, white, or 
transparent. They are stored in a highly compact form, using a hierarchic area encoding scheme. A dynamic 
picture is represented as a tree structure of primitive pictures. The display processor traces the tree 
structure, scan converts, translates, dips, and does transparency-opacity calculations (to determine 
which portions of which layers are visible) in real time, approximately 3 to 10 frames per second. The 
results of these calculations are double buffered to enhance the perception of movement. In fact, the 
CPU-P1 and P2 are the same processor running different tasks, and the coded picture definition and the 
two scan converted frames are stored in the same memory. A recent development of this kind is the Lektromedia 
LEK 330 Series [Burtnyk 77]. Here the CPU is a remote host, P1 is non-existent, the coded picture definition 
is actually a vector format display file, and the scan converting processor P2 the rather limp Motorola 
6800 microproces- sor. Systems can be configured either with a single black-and-white image buffer, thus 
adhering to the architecture of Figure 8, or with dual image buffers, as is shown in Figure 10. Although 
no systems of the following kind exist, a cost-effective design might incorporate cyclic memories (such 
as MOS shift registers or CCDs) to implement the double frame buffer. P3, which simply translates memory 
chunks into display intensities, will not be affected by this. P2 will slow down, but may be able to 
compute fast enough for simple pic- tures appropriately coded. 4. DYNAMIC GRAPHICS Animation has been 
defined as: "The art of giving apparent movement to inanimate objects. The word is also used for the 
sequence of draw- ings made to create the movement, and for the move-ment itself when seen on the screen." 
[Halas 71] Animation, and all motion pictures, are made possible by the persistence of vision of the 
human eye [Madsen 69]. The retina retains the image of an object for a brief instant after the object 
has been removed. Thus a sequence of still pictures presented rapidly enough will blend together into 
a single continuous image. If the stills depict progressive phases of a single movement, the eye will 
perceive continuous motion. The object will be animated, that is, "come to life". Computer animation, 
therefore, consists of the rapid presentation of com- puter graphic images to create the illusion of 
movement. Often, these images will have been computed from an algnrithmie description, although the computations 
may consist of elementary combinations of hand-sketched images. Often, the computation will occur concurrently 
with the presentation, although images that cannot be computed in real-time may still be played back 
in real-time under computer control [Tilson 76]. Early work in interactive computer-mediated animation 
[Baecker 69a,69b,74] formalized a set of basic primitives for achieving efficent implementations of simple 
cartoon animation. The animator sketches static images (eels), descriptions of movement of portrayed 
objects (move- ment descriptions), and descriptions of methods for portraying these objects .using the 
eels (selection descriptions). The computer combines these elements in real time into an animated sequence. 
Although early work was based on vector graphic technology, the same concepts have been realized successfully 
in the Interim Dynabook raster scan system described in Section 3.4. More recent work in computer animation 
has tended to emphasize the process of key-frame animation, a technique which attempts to automate the 
in-betweening process of classical animation production. This tech- nique is very expensive, and we shall 
not consider it further in this paper. Computer animation is the most dramatic and effective of the forms 
of dynamic graphics. But there are also other forms which have relevance to the future of the home terminal. 
Some techniques commonly used in cinematography include [Madsen 69]: the cut, an instantaneous change 
from one scene to another; the fade-in(out), the gradual appearance (disappearance) of a scene from (to) 
a darkened screen; the dissolve, consisting of a fade-in superimposed on a fade-out over the same interval; 
the double exposure, combining two separate images, one appearing as a translucent phantom before the 
other; superimposition, combining two or more separate images, in which some appear opaquely before others, 
as a fore- ground placed before a background; the pop-on, an instantaneous appearance of a new image 
within a scene already on the screen; the wipe, an optical effect whereby the scene on the screen is 
apparently physically displaced by the following scene; the flip, an effect in which a still scene begins 
to revolve on its centre axis in acute perspective, and a new scene or a new title is introduced with 
each half revolution; the spin, the rotating of a scene around its own centre point; the zoom-in(out), 
a continuous approach (retreat) by the camera to (from) a subject; the pan, a horizontal scan of the 
subject by the camera; and, the close-up, an enlargement of a detail within a larger picture. Dynamic 
graphics includes the structured use of these techniques to enhance visual communication. Many people 
mistakenly assume that dynamic graphics and animation are only relevant to the production of car- toons 
or to dynamic simulations of complex three-dimensional objects. On the contrary, dynamic graphics can 
enhance and enrich any dialogue with a computer; it can fruitfully be applied to computer-aided instruction, 
com- puter simulation modelling, data base browsing and retrieval, and com-puter teleconferencing, to 
mention only a few examples. 5. DYNAMIC COMPUTER GRAPHICS 5.1. Dynamic Computer Graphics on Vector Displays 
We begin by reviewing how dynamic graphics has been achieved with ran- dom scan displays. We shall concentrate 
primarily on true animation, and make only brief mention of the other cinematographic techniques listed 
in the preceding section. However, the same basic principles apply to most types of dynamic imagery. 
Consider first the simple refreshed display depicted in Figure 2. Typically the display file is segmented, 
with distinct components of the picture hav- ing distinct representations. Thus, to move or transform 
a component, we need only recompute it, and then insert it into the display file in place of the original. 
Double buffering the segment means that the process of computation is not visible; if the replacement 
occurs quickly enough, con- tinuous motion is achieved. This is almost always the case with the basic 
animation primitives of movement and selection, for they can be com-puted trivially, the former by replacing 
the segment origin which controls the absolute position of a picture otherwise specified in terms of 
relative coordinates, and the latter by switching pointers in the display file, thus causing one picture 
to be shown in place of another. 53 Similar principles apply to the more sophisticated systems depicted 
in Fig- ures 3 and 4. Typical display processors of the former class include hard- wired three-dimensionai 
transformations which operate on tree-structured display files. This extends the ciass of possible real-time 
animation capa- bilities to include three-dimensionai translation, rotation, and scale changes, and usually 
perspective computations. The buffered transforma- tion processor of Figure 4 achieves the same result, 
but also provides a mechanism for trading off image update rate against image complexity. Some processes 
of animation and dynamic graphics are not well handled by this technology. Key-frame animation must generally 
be carried out by the host CPU. Zooms and pans can be handled by the display processor pro- vided that 
they have good windowing and clipping capabilities; otherwise these calculations must also be done by 
the CPU. Fades and dissolves depend upon use of the display's intensity control, which is usually very 
limited. Nonetheless, because images can be added, moved, and removed essen-tially instantaneously, dynamic 
computer graphics as we know it has become the exclusive province of this technology. It is a goal of 
this paper to show that this need not be so. 5.2. Dynamic Computer Graphics on Digital Video Displays 
5.2.1. Technological Constraints Any attempt to achieve dynamic computer graphics on digital video displays 
must deal with the technological constraints imposed by the raster scan. Conventional television images 
are displayed at 30 frames/second. Each frame is composed of two interlaced fields to reduce flicker. 
For a system with 480 X 640 resolution on a conventional 525 line monitor, each scan line must be fetched 
in 1/525th of 1/30th of a second = 63.5 microseconds. Of the 525 lines, 480 are visible and 45 occur 
during the vertical fiyback of the electron beam. Since horizontal flyback occurs in 11.4 microseconds, 
each raster point must be fetched or computed in 81 nanoseconds. These figures have several serious implications. 
The first is on memory bandwidth, Refreshing the above picture out of a frame buffer requires a memory 
bandwidth of roughly I00 million bits per second. Reducing the resolution to 240 X 320 lowers this figure 
by a factor of two, because pairs of horizontally adjacent pixels are identical. Successive pairs of 
scan lines are also identical, but, because of interlace, this does not lessen the bandwidth problem, 
although it reduces by 50% the storage required. Of course, storage is a severe problem in itself, for 
a 512 X 512 X 8 bit frame buffer requires 2,000,000 bits of storage. 5.2.2. Systems with Frame Buffers 
Current frame buffers are unsuited to dynamic imagery. Consider the problem of moving a figure across 
the screen. Assume a 512 X 512 ran- domly accessible frame buffer, and a CPU capable of generating a 
new ras- ter point every 33 microseconds, which is typical of the 1979 state-of-the- art. In this ease 
only 1000 of the 250,000 screen pixels can be recomputed in a 30th of a second. This means that 500 points 
on the last version of the figure can be erased, and 500 points can be added to the new version. Furthermore, 
it is difficult to guarantee that each new picture appear correctly, because the computation must be 
synchronized perfectly with the raster scan to guarantee that a change of a pixel value occur after that 
pixel has been displayed and before it is next displayed. This problem would be even worse is we were 
trying to enhance the speed of screen changes with a P1 containing a vector generator. There is also 
another serious problem. Consider a black-and-white picture. Pixels often represent the intersection 
point of two or more picture ele- ments. If we erase one of those elements, for example a line, we leave 
a gap in the others that must be refilled. Although simple in ~oncept, the search for possible intersection 
points between a line to be removed and all other visible lines is a time-consuming process. Nonetheless, 
simple stylized dynamic graphics is possible on random access frame buffers if the required picture changes 
can be localized to a small enough area. These changes can best be implemented by techniques such as 
superimposition, the pop-on, and the wipe. Furthermore, recent conceptual advances in our understanding 
of raster manipulation functions (see pp. 262-265 of [Newman 79]), and work in several laboratories on 
high-speed microcoded processors and on memory organizations that facili- tate the parallel application 
of these functions to small regions era bit map, should soon allow us to update raster points 2 or 3 
orders of magni- tude faster than described above. 5.2.3. Systems with Coded Picture Definitions A digital 
video display with a coded picture definition expands a full raster scan image from a condensed representation 
"on the fiyL Any change in the coded picture definition will immediately be visible on the screen. Hence 
a structured succession of changes to the display file will produce an animated sequence. For example, 
most of the display file of an alphanumeric video display terminal can be recomputed in a 30th of a second. 
To facilitate computer animation on systems with this architecture, several conditions should be satisfied: 
1) Pictures to be animated must be representable in the display file format. This will usually imply 
a significant reduction in generality, for the display file must be simple enough to be scan converted 
in real time by the pro- cessor P2 (see Figure 9). 2) The display file format should allow pictures to 
be stored compactly, as, for example, in the use of a run-coded display file for pictures that have relatively 
few changes along each scan line. The format should also allow easy computation of transformations that 
will result in dynamic sequences. These two conditions make it possible for the CPU to compute a new 
image fast enough to produce the illusion of movement. 3) The display file should be segmented. Thus 
changes to a subpicture can be affected by changing only its representation in the display file. 4) The 
display file should allow double buffering of segments. This will mean that a segment can be recomputed 
without concern for its synchroni- zation with the scan conversion and display process. The new version 
will be made visible when and only when it is fully computed. The coded picture definition architecture 
has one additional advantage. The problem of the restoration of intersection points referred to in the 
pre- vious section disappears, because the full raster image is constructed anew each 30th of a second 
from the latest coded representation. It is always up-to-date, and contains no artifacts that reflect 
the order in which the CPU performed additions and erasures. 5.2.4. Systems with Coded Picture Definitions 
and Double Frame Buffers The problem with the architecture of Figure 9 is the need for the display processor 
to keep up with the raster scan. If it cannot keep up, the picture will degrade, gracefully or chaotically, 
depending upon the sophistication of the design. In fact, if the display is producing animation, it may 
be capable of displaying some frames but not others. This would be particularly annoying. The architecture 
of Figure 10 solves the problem. We separate the image expansion and raster scan refresh processes. Now, 
as the images become more complex, and each one takes longer to compute, the animation no longer degrades 
but merely slows down. This phenomenon was demon- strated on the Interim Dynabook over five years ago. 
The architecture has another less obvious advantage. The coding mechan- ism used with Figure 9 has to 
be scan-line oriented so that scan lines can be decoded in synchrony with the raster scan. Buffering 
the image as in Figure 10 allows us to use other encodings, such as the hierarchic area encoding scheme 
of the Interim Dynabook. This is because it no longer matters in what order pixel values are computed. 
54 The architecture yields one further opportunity. Because two complete more slowly than desired. images 
are buffered, we can include in processor P3 the capability to com- pute cinematographic effects that 
require combinations of two images. These include cuts, fade-ins, fade-outs, dissolves, double exposures, 
superimpositions, pop-ons, wipes, and close-ups. Such capabilities have already been seen in the most 
sophisticated recent frame buffers described in Section 3.2. 6. SOFTWARE IMPLICATIONS 1) There is an 
increasing body of opinion which holds that systems software for raster-scan graphics can be constructed 
in the same manner as that for random scan graphics [Sproull 75]. Primitives for generating and transforming 
line drawings need to be augmented with primitives for con- trolling line thickness, for shading regions, 
and for controlling opacity and transparency. 2) Systems software for simple animation, whether it is 
to be performed on vector displays or on digital video displays, requires a mechanism for organizing 
picture change with respect to a scale of movie time [Baecker 75]. As we have already seen in Section 
4, the most essential picture changes are those of movement and selection. Movement of an image is used 
to portray the movement of the object it represents. Selection among multiple images (eels) is used to 
portray the behavior of the object it represents. Thus rapid and appropriate switching among different 
views of a moving object will animate it, will "bring it to life". To implement such animation, the software 
must contain mechanisms for the storage management of picture segments, that is, for creating and deleting 
them, and for making them visible and invisible. Tools for translating segments are also required. Movement 
of an object is accom- plished by translating its picture segments; selection among various views of 
an object is accomplished by making one segment visible as another segment is made invisible. 3) What 
is required for more sophisticated dynamic graphics is a standard high-level graphics programming language. 
There is currently much con- sensus in the industry about what capabilities are required in such a language, 
as can be seen by the graphics standards efforts now underway [Core 77]. The capabilities include tools 
for applying two- and three-dimensional transformations, for concatenating these transformations, and 
for windowing and clipping. We do not propose that these be carried out in hardware on images in raster 
format. With the exception of two-dimensional windowing and clipping, which could be embedded in the 
scan convening processor as was demonstrated in the Interim Dynabook, these capabilities should usually 
be carried out by software in the CPU. 7. SUMMARY AND CONCLUSIONS 7.1. Summary We have presented a methodology 
for describing digital video displays which clarifies the effect of system architecture on capabilities 
and perfor- manca. The methodology decomposes systems into configurations of pro- cessors with certain 
powers and memories with certain storage capacities and access characteristics. The technique has proved 
adequate to describe all known examples of digital video displays and to suggest design possibil- ities 
for new systems. More specifically, the methodology helps us understand why dynamic graphics is not possible 
on most existing digital video displays, namely, that the method whereby frames are represented requires 
too much com- putation by processors not specialized to the task, and, furthermore, the frames are not 
double buffered to prevent the viewer from perceiving the process of computation. Two other architectures 
were found more useful for dynamic graphics. In the first, a digital video display processor expands 
a picture "on the fly" from a condensed encoded representation. Although limits are placed on the classes 
of pictures that can be handled, animation of simple images is easy to achieve. The other architecture 
separates the computation from the refresh processes by buffering two frames between the two processes. 
This removes the restriction on generality~ complex images can now be represented, although their animation 
may proceed 7.2. Conclusions 1) Dynamic graphics is feasible on digital video displays. 2) The frame 
buffer (Figure 8) is not a desirable display system architec- ture for dynamic graphics. However, animation 
of simple images can be achieved by a display processor which scan converts and expands pictures "on 
the fly" from a condensed encoded representation (Figure 9). Limits on the classes of pictures that can 
be handled by such a system can be relaxed by providing a double frame buffer after the display processor 
(Fig- ure 10). 3) Only movement and selection of images, and possibly two-dimensional windowing and clipping, 
should be carried out in hardware by the scan converting processor (P2 in Figures 9 and 10). Other more 
sophisticated two-and three-dimensional transformations should be carried out in software by the controlling 
CPU. 4) Although our approach clarifies the qualitative behavior of existing and possible systems, it 
does not yield quantitative data in its current form. It should be embodied into a simulation methodology 
which could be used to experiment with and evaluate new designs. This methodology would accept specifications 
of processor instruction sets and execution times, and memory sizes and access characteristics, and produce 
performance meas- ures of the system on randomly constructed and specifically designed pic- tures. Such 
a methodology is currently under development at the Univer- sity of Toronto's Dynamic Graphics Project 
[Galloway 79]. 5) Architectures for digital video display systems that can support dynamic graphics have 
been identified, but few instances of such systems exist. Implementations need to be carried out to refine 
our understanding of the design concepts described in this paper. An example of such a system with the 
architecture of Figure 10 is currently under development at the Dynamic Graphics Project [Miller 79a,b]. 
The system will scan convert into a double frame buffer a segmented display file consisting of relatively 
sparse dot drawings. Since these drawings can be translated and selected with ease, real-time animation 
will be possible. Acknowledgments This paper is based in part on work carried out at the University 
of Toronto under the sponsorship of the National Research Council of Canada, and in part on work carried 
out at Human Computing Resources Corporation under the sponsorship of the Canadian Department of Com- 
munications. I am grateful to Herb Bown, Tom Horsley, Stan Kriz, David Miller, Doug O'Brien, Brian Rosen, 
Dick Shoup, Bob Sproull, Mike Tilson and Walter Vynohrad for helpful comments on various drafts at various 
stages of this work, and to Dave Sherman for editorial, bibliographic, and typographic assistance. References 
 IAndrews 74l Donald I. Andrews, "Line Processor -- A Device for Amplification of Display Terminal Capabilities 
for Text Manipulation', Proceedings of the NCC, 1974, pp. 257-265. IAziz 67l R.A. Aziz, "An Instructional 
Display Terminal', Proceedings of the Eighth National Symposium on lrlformation Display, May 1967, San 
Francisco, pp. 83-90. [Baecker 69al Ronald M. Baecker, Interactive Computer-Mediated Animation, Ph.D. 
Thesis, M.I.T. Dept. of,Electrical Engineering, Project MAC Technical Report 61, April 1969. IBsecker 
691)1 Ronald M. Baecker, "Picture-Driven Animation", Proceedings of the SJCC, May 1969, pp. 773-288. 
IBaeeker 741 Ronald M. Baecker, "GENESYS--Imeractive Computer-Mediated Ani- mation", appears in Computer 
Animation (John Hales, Editor), Hastings House, New York, 1974, pp. 97-115. IBaeeker 75l Ronald M. Baecker, 
"A Computer Animation Facility for Research and Educational Filmmaking: Design and Application", Proceedings 
of the Fourth NRC Man-Computer Communications Corlference, May 1975, pp. 19.1-19.11. [Baeeker 76] Ronald 
M. Baecker, "A Conversational Exteusible System for the Ani- mation of Shaded Images', Computer Graphics, 
Volume 10, Number 2, Summer 1976, pp. 32-39. [Barenholtz 76l J. Barenholtz and C. Dewhurst, "A Run Length 
Encoding Scheme 55 for Real Time Video Animation", Proceedings of the Northwest 76 ACM/CIPS Regional 
Symposium. [Barrett 741 R.C. Barrett and B.W. Jordan, Jr., "Scan Conversion Algorithms for a Cell Organized 
Raster Display", Communications of the ACM, Volume 17, Number 3, March 1974, pp. 157-163. [Baskett 76l 
Forest Baskett and Leonard Shustek, "The Design of a Low Cost Video Graphics Terminal", Computer Graphics, 
Volume 10, Number 2, Summer 1976, pp. 235-240. {Bown 78{ H.G. Bawn, C.D. O'Brien, W. Sawchuk, and J.R. 
Storey, "A General Description of Telidon: -- A Canadian Proposal for Videotex Systems", CRC Techni- 
cal Note No. 697-E, Communications Research Centre, Canadian Department of Communications, Ottawa, December 
1978. [Burtnyk 771 N. Burtnyk, P. Carey, K. Steele, and M. Wein, ~A Video Terminal for Interactive Graphics', 
Proceedings of the F:h Man-Computer Communications Confer- ence, May 26-27, 1977, Calgary, pp. 31-44. 
 {Core 77] Graphics Standards Planning Committee of ACM/SIGGRAPH, Status Report, Computer Graphics, Volume 
11, Number 3, Fall 1977. [Denes 74{ Peter B. Denes, "Computer Graphics in Colour", Bell Laboratories 
Record, Vol. 52, May 1974, pp. 138-146. {Denes 751 Peter B. Denes, "A Scan-type Graphics System for 
Interactive Comput- ing', Proceedings of the Conference on Computer Graphics, Pattern Recognition, and 
Data Structure, IEEE Computer Society, May 14-16, 1975, pp. 21-24. {Eastman 75{ Jeffrey F. Eastman and 
David R. Wooten, "A General Purpose, Expandable Processor for Reel-Time Computer Grapbrics" , Computers 
and Graphics, Volume 1, Number 1, 1975, pp. 73-77. [Entwisle 771 Jeffrey Entwisle, "An Image Processing 
Approach to Computer Graph- ics', Computers and Graphics, Volume 2, Number 2, 1977, pp. 111-117. [Fischer 
731 Michael Fischer, "MAPS -- A Generalized Image Processor", Computer Graphics, Volume 7, Number 3, 
Fall 1973, pp. 1-9. {Fischer751 Michael A. Fischer and Robert E. Nunley, "Raster Graphics for Spatial 
Applications", Computer Graphics, Volume 9, Number 2, Summer 1975, pp. 1-8. {Galloway 791 David R. Galloway, 
The Modelling of Dynamic Digital Video Display Systems, M.Sc. Thesis, Dept. of Computer Science, University 
of Toronto, 1979 (forthcoming).  [Grover 71l D.J. Grover, "Low cost graphic display with serial access 
store", Com- puter Bulletin, Volume 15, Number 1, January 1971, pp. 33-37. [Ha[as 71] John Hales and 
Roger Mauve[l, The Technique of Film Animation, Focal Press, 3rd Ed., 1971. [Hendrickson 67a{ Herbert 
C. Hendrickson, "The display/control complex of the Manned Space Mission Control Center', Information 
Display, May/June 1967, pp. 52-  58. [Hendrickson 671)1 Herbert C. Hendrickson, "A high-precision display 
system for command and control', Information Display, July/August 1967, pp. 32-36, IHP 751 Articles on 
the Model 2640A Interactive Display Terminal Family, Hewlett- Packard Journal, June 1975, Palo Alto Ca. 
[HP 78] Articles on the Model 2648A Graphics Terminal, Hewlett Packard Journal, January 1978, Polo Alto 
Ca. {Honey 711 Francis J. Honey, "Computer Animated Episodes by Single Axis Rota- tions', Proceedings 
of the Tenth Annual Meeting of UAIDE, 1971, pp. 3-210--3-226. {Hunter 75o{ Gregory M. Hunter, "Fuil-colour 
Television from the Computer, Refreshed by Run-length Codes in Main Memory', Technical Report Number 
182, Computer Science Laboratory, Princeton University, April 21, 1975. {Hunter 75h{ Gregory M. Hunter, 
"Computer Animation and Run-length Codes', Technical Report Number 199, Computer Science Laboratory, 
Princeton University, February 25, 1975. [Irby 74{ Charles H. Irby, "Display Techniques for Interactive 
Text Manipulation', Proceedings of the NCC, 1974, pp. 247-255. {Jordan 73[ B.W. Jordan, Jr. and R.C. 
Barrett, "A Scan Conversion Algorithm with Reduced Storage Requirements", Communications of the ACM, 
Volume 16, Number 11, November 1973, pp. 676-682. IJordan 741 B.W. Jordan, Jr. and R.C. Barrett, "A 
Cell Organized Raster Display for Line Drawings", Comanications of the ACM, Volume 17, Number 2, February 
1974, pp. 70-77. IKaJlya 75{ James T. Kajiya, Ivan E. Sutherland, and Edward C. Cheedle, "A Random-Access 
Video Frame Buffer", Proceedings of the Conference on Computer Graphics, Pattern Recognition, and Data 
Structure, IEEE Computer Society, May 14-16, 1975, pp. 1-6. [Kay 74{ Alan Kay, Presentation at the First 
Annual Conference on Computer Graphics and Interactive Techniques, Boulder Colorado, July 1974. [Kubltz691 
W.J. Kubity. and W.J. Poppelbaum, "The Tricolor Cartograph: a display system with automatic coloring 
capabilities', Information Display, November/December 1969, pp. 76-79. {Laws 751 B.A. Laws and W.M. Newman, 
"A Gray-scale Graphic Processor using Run-length Coding", Proceedings of the Conference on Computer 
Graphics, Pattern Recognition, andData Structure, IEEE Computer Society, May 14-16, 1975, pp. 7-10. [LRG 
76{ Learning Research Group, Personal Dynamic Media, Xerox Polo Alto Research Center, 1976. [Macaulay 
681 Malcolm Macaulay, "A Low Cost Computer Graphic Terminal", Proceedings of the FJCC, 1968, pp. 777-785. 
[Madsen 691 Roy Madsen, Animated Film: Concepts, Methods, Uses, Interiand Publishing Inc., 1969. [Malik 
78] Rex Malik, "The TV as a Terminal", Datamation, March 1978, pp. 213- 215. [Matherat 78{ Philippe 
Matherat, "A Chip for Low-Cost Raster.Scan Graphic Display", Computer Graphics, Vol. 12, No. 3, August 
1978, pp. 181-186. [McCracken 75] T,E. McCracken, B.W: Sherman, and S.J. Dwyer HI, "An Economi- cal Tonal 
Display for Interactive Graphics and Image Analysis Data", Computers and Graphics, Volume 1, Number 1, 
1975, pp. 79-94. [Metzger 69{ Richard A. Metzger, "Computer generated graphic segments in a raster display", 
Proceedings of the SJCC, 1969, pp. 161-172. [Miller 79a{ David H. Miller, David R. Galloway, William 
T. Reeves, Ronald M. Baecker, and H. Dominic J. Cowey, "SPIWR1T: A Proposed Dynamic Colour Video Graphics 
Device", Computer Systems Research Group, University of Toronto, revised version, 1979. {Miller 791)] 
David H. Miller, Two Dimensional Video Animation Processors, M.A.Sc. Thesis, Dept. of Electrical Engineering, 
University of Toronto, 1979 (forthcoming). {Myers 76{ Allan J. Myers, "A Digital Video Information Storage 
and Retrieval Sys- tem', Computer Graphics, Volume 10, Number 2, Summer 1976, pp. 45-50. [Negroponte 
771 Nicholas Negroponte, "Raster Scan Approaches to Computer Graphics', Computers and Graphics, Volume 
2, Number 3, 1977, pp. 179-193. {Nelson 77| Theodore H. Nelson, The Home Computer Revolution, The Distributors, 
702 South Michigan, South Band, Indiana 46618, 1977. [Newman 74] William M. Newman and Robert F. Sproull, 
"An Approach to Graph- ics System Design", Proceedings of the IEEE, Volume 62, Number 4, April 1974, 
pp. 471-483. {Newman 79{ William M. Newman and Robert F. Sproull, Principles of Interactive Computer 
Graphics, 2nd Edition, McGraw-Hill, 1973. [Noll 711 A. Michael Noll, "Scanned-Display Computer Graphics', 
Communications of the ACM, Volume 14, Number 3, March 1971, pp. 143-150. [Ophir 68a] D. Ophir, S. Rankowitz, 
B.J. Shepherd, and R.J. Spinrad, "BRAD: The Brookhaven Raster Display', Communications of the ACM, Volume 
11, Number 6, June 1968, pp. 415-416. [Ophir 681)1 D. Ophir and B.J. Shepherd, "ITN -- Data Terminal 
Network Computer System", Nuclear Instruments and Methods 62, 1968, pp. 285-294. [Pearson 75] D.E. Pearson, 
Transmission and Display of l~ctoriaf Information, Ha[steal Press, John Wiley &#38; Sons, 1975. [Preiss 
78{ Richard B. Preiss, "Storage CRT Display Terminals: Evolution and Trends", Computer, Vol. 11, No. 
11, November 1978, pp. 20-26. {Rose 67{ Gordon A. Rose, "Intergraphic -- A Microprogrammed Graphical-Interface 
Computer', IEEE Transactions on Electronic Computers, Volume EC-16, Number 6, December 1967. {Rose 68] 
Gordon A. Rose, "Computer Graphics Commuv_ication Systems', Proceed-ings of the IFIP Conference, 1968, 
pp. 211-220. IRoseman 77] Ellen Roseman, "Video Games Are Back With A New Wrinkle', The Globe and Mail, 
Nov. 26, 1977, p. 4. {Rougelot 691 R.S. Rougelot, "The General Electric Computer Color TV Display", appears 
in Pertinent Concepts in Computer Graphics (M. Falman and J. Nievergelt, Editors), University of Bllnois 
Press, 1969. {Ruder 68{ Don Ruder, "Data Disc Television Display System', Proceedings of the UA1DE Annual 
Meeting, 1968, pp. 338-357. [Saxten 771 William A. Saxton and Morris Edwards, "Data Base Access Through 
Home 'IV Is Now A Reality", Canadian Datasystems, December 1977, pp. 56-57. [Shoup 741 Richard Shoup, 
Presentation at the First Annual Conference on Com- puter Graphics and Interactive Techniques, Boulder 
Colorado, July 1974. [Spmull 75] Robert F. Sprout[ and Wdliam M. Newman, "The Design of Gray-scale Graphics 
Software', Proceedings of the Conference on Cor,~uter Graphics, Pattern Recognition, and Data Structure, 
IEEE Computer Society, May 14-16, 1975, pp. 18-20. IStandhammer 75{ John Staudhammar and Deborah J. Ogden, 
"Computer Graphics for Half-tone Three-dimeusional Object Images", Computers and Graphics, Volume 1, 
Number 1, 1975, pp. 109-114. {Taylor77] M.M, Taylor and J.A. Norton, "A Versatile Colour Raster Display 
Sys- tem for Visual Psychophysics and Image Processing', Proceedings of the Digital Equip- ment Computer 
Users Society (Canada), February 1977, pp. 923-929. [Tek 78a] Articles on the Tektronix 4025 Computer 
Display Terminal in Tekscope, Volume 10, Number 1, 1978, Tektronix Inc., Beaverton Or. [Tek 781)1 Articles 
on the Tektronix 4027 Computer Display Terminal in Tekscope, Volume 10, Number 4, 1978, Tektronix Inc., 
Baaverton Or. [Terlet 67l R.H. Teriet, "The CRT Display Subsystem of the IBM 1500 Instructional System", 
Proceedings of the FJCC, 1967, pp. 169-176. [Thornhill 741 Daniel E. Thoruhill and Thomas B. Cheek, "Raster-scan 
tube adds to flexibility and lower cost of graphic terminal', Electronics, February 7, 1974, pp. 95- 
101. [Ttlson 76{ Michael D. Tilson, Editing Computer Animated l~lm, Technical Report CSRG-66, Computer 
System Research Group, University of Toronto, January 1976. [Tripp 751 Edwin R. Tripp HI and Jimmie R. 
Suttle, "An Interactive Three-Dimensional Color Graphics System", Computers and Graphics, Volume 1, Number 
2/3, 1975, pp. 211-214. IUncapher 711 K.W. Uncapher, "The RAND Video Graphics System --An Approach to 
a General User-Computer Graphic Communication System', RAND Report P-753-ARPA, April 1971. 56  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807425</article_id>
		<sort_key>57</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[A response to the 1977 GSPC Core Graphics System]]></title>
		<page_from>57</page_from>
		<page_to>62</page_to>
		<doi_number>10.1145/800249.807425</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807425</url>
		<abstract>
			<par><![CDATA[<p>This paper responds to the 1977 Core Graphics System of SIGGRAPH's Graphic Standards Planning Committee (GSPC). The authors are interested in low-level device-independent graphics for applications doing data representation and annotation. The level structure and bias in the Core System toward display list processor graphics are criticized. Specific issues discussed include display contexts, attributes, current position, 3-dimensional graphics, area filling, and graphics input.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Device-independence]]></kw>
			<kw><![CDATA[GSPC core graphics system]]></kw>
			<kw><![CDATA[Graphics standards]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P329836</person_id>
				<author_profile_id><![CDATA[81100323682]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Deborah]]></first_name>
				<middle_name><![CDATA[U.]]></middle_name>
				<last_name><![CDATA[Cahn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332595</person_id>
				<author_profile_id><![CDATA[81100571028]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nancy]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Johnston]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14197805</person_id>
				<author_profile_id><![CDATA[81100571045]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Johnston]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>988454</ref_obj_id>
				<ref_obj_pid>988451</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chappell, G., and Boni, P., "Core System Implementations&#8212;A status Report," Comput. Gr. 12, 4 (Dec. 1978), 53-66.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Committee on Colorimetry, Optical Society of America, The Science of Color, Thomas Y. Crowell Co., 1953.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Graphics Standard Planning Committee, Status Report, Comput. GR. 11, 3 (Fall 1977).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hershey, A., A Computer System for Scientific Typography, Comp. Graphics and Image Processing 1, (1972), 373.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Johnston, N.E., Cahn, D.U., and Johnston, W. E., GRAFPAC, UCID 8094, Lawrence Berkeley Laboratory, Berkeley, California, (Jan. 1979).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356749</ref_obj_id>
				<ref_obj_pid>356744</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Michener, J., and Foley, J.D., "Some Major Issues in the Design of the Core Graphics System," Comput. Surv. 10, 4 (Dec. 1978), 445-463.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Montalvo, F. S., "Color Perception," COMTECH Conference, San Francisco (March 3, 1978).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356746</ref_obj_id>
				<ref_obj_pid>356744</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Newman, W. and van Dam, A., "Recent Efforts Toward Graphics Standardization," Comput. Surv. 10, 4 (Dec. 1978), 365-380.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>988453</ref_obj_id>
				<ref_obj_pid>988451</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Vinberg, Anders "Position Paper on Graphics Standard," Comput. Gr., 12, 4 (Dec. 1978), 46-52.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A RESPONSE TO THE 1977 GSPC CORE GRAPHICS SYSTEM * DEBORAH U. CAHN NANCY E. JOHNSTON WILLIAM E. JOHNSTON 
 LAWRENCE BERKELEY LABORATORY, BERKELEY, CALIFORNIA 94720 ABSTRACT This paper responds to the 1977 
Core Graphics System of SIGGRAPH's Graphic Standards Planning Committee (GSPC). The authors are interested 
in low-level device-independent graphics for applications doing data representation and annotation. The 
level structure and bias in the Core System toward display list processor graphics are criticized. Specific 
issues discussed include display contexts, attributes, current position, 3-dimensional graphics, area 
 filling, and graphics input. Key Words and Phases: computer graphics, device- independence, graphics 
standards, GSPC core graphics system. CR Categories: 8.2 INTRODUCTION This paper was written because 
the authors have an active interest in graphics standards and have been working on low level device independent 
graphics drivers for a number of years. With motivations similar to those of SIGGRAPH and the GSPC, the 
authors feel that work on a graphics standard is important in order to be able to enhance code portability, 
programmer portability, and consistent terminology. The 1977 GSPC proposed Core Graphics System (GSPC77) 
has many good ideas, but it also has some deficiencies which are addressed in this paper. The authors" 
experience in graphics software is based on the development of a device independent graphics system which 
has been in use for approximately eight years. The authors represent the graphics effort at Lawrence 
Berkeley Laboratory (LBL), a national research laboratory, which has users all over the United States 
 *This work was supported by theLawrence Berkeley Laboratory Computer Center, and by the Office of Energy 
Research of the U.S. Department of Energy under contract No. W-7405-ENG-48. &#38;#169; 1979 ACM 0-89791-004--4/79/0800--057 
$00.75 See Copyright Pg. 57 producing approximately 300,000 graphics frames per month. The graphics group 
at LBL supports device independent graphics on some 15 different types of devices representing the spectrum 
of graphics hardware available exclusive of display list processors (including film recorders, pen plotters, 
electrostatic printer/plotters, storage tube terminals, color raster terminals, and frame buffers). LBL's 
device independent graphics system, GRAFPAC (JOHN79A), has recently been strongly influenced by the 1977 
GSPC Core System. This paper is a response to the 1977 report of the GSPC (GSPC77), which was the subject 
of the December, 1978 issue of COMPUTING SURVEYS. The authors are aware that the work of the GSPC has 
 continued, resulting in reports to be published at SIGGRAPH "79. Some of the points made in this paper 
may no longer be relevant to current proposals. However, at the time of this writing, the 1979 GSPC 
reports were not publicly available. This paper is intended to contribute to the dialogue on the 1977 
"Strawman" Core. PHILOSOPHY DESIGN GOALS Newman and van Dam state that "The major design goal was 
to make the system much closer to self-suffficient package than to a "kernel'." (NEWM78, PG.377) Many 
of the points made in this paper stem from the belief of the authors that this goal of a "rich", applications 
programmer-oriented, non-minimal package has not been met in the 1977 proposal. BIAS The authors feel 
that there is a clear bias in the 1977 proposal towards interactive display list processors and the type 
of graphics done in computer aided design. LBL's graphics experience indicates that a large portion of 
computer graphics consists of annotated plots representing data in various ways (E.G., X-Y, scatter, 
histogram, contour, etc.). These graphs may well be viewed, or even designed, in an interactive environment, 
but the interaction, if any, usually limited to simple cursor input for layout and control purposes. 
For the purposes of this paper, let us assign the term "object manipulation graphics" to computer aided 
deslgn/dlsplay llst processor type of graphics, and "data representation and annotation" to the traditional 
scientific and decision support variety which produces plots for distribution, publication, and analysis. 
 The authors feel that the Core Committee has done a good Job of addressing the functions and attributes 
needed for object manipulation, but that data representation and annotation were inadequately or incorrectly 
dealt with. The Core System is too minimal and not self-sufflclent with respect te this important applications 
area. (See also VINB78). It is probably the case that the majority of computer graphics output, on a 
frame by frame basis, is basically non-lnteractive and/or hardcopy plots of data analysis, computational 
scientific models, decision support information display, statistical analysis, cartographic applications, 
engineering models, etc. To confirm this, one has only to consider all of the COM devices throughout 
the world turning out millions of graphics frames monthly. Because of this, it is inappropriate for a 
Core System to be proposed in which the effort put into considering user needs is not at least equally 
divided between the two areas of graphics use (data representation and annotation, versus object manipulation). 
It is explicitly stated that the prototypical device underlying the Core proposal is a display llst processor 
(GSPC77, PG. II-131, as opposed to film recorders, pen plotters, or storage tube displays. Implicitly 
(witness the large emphasis on segments), the Core Committee has focused its attention on only one of 
two types of graphics. Nor is it the case that the manner in which most of the data representation and 
annotation graphics is done is merely outmoded, unstructured, and unsophisticated, and ripe to be converted 
to the use of retained segments, highly interactive graphics terminals, etc. The differences are more 
fundamental than that. LEVELS It is the belief of the authors that there was a basic mistake made by 
the Core Committee in approaching the idea of a standard as a set of hierarchical capabilities. Rather, 
the standardization effort should be directed towards standardizing graphics functions. Thus, if a particular 
system, advertised as an implementation of the "standard", offers a function, then it is guaranteed to 
offer a standard implementation of that function. A given implementation should not be regarded as a 
dialect, but rather as a subset appropriate to the implementator's particular needs. This does not defeat 
the concept of standardization because functions may be added or simulated as needed. This facilitates 
program portability because an applications programmer needs only to know what functions hls/her program 
requires and can compare them with the advertised functions of any standard system in order to evaluate 
the difficulty in transporting the code. Potentially the "status" routine could return those functions 
which have been implemented on any given system.  In any event, the evidence which follows will show 
that the particular hierarchical structure proposed in GSPC77 is inadequate. As pointed out in MICH78, 
PG. 460, the Core Committee originally came up with twelve possible subsets of graphics functions. The 
authors feel that the selection of the four levels from the possible subsets was inadequate. The sections 
on 3-dimensional graphics, area filling, and graphics input, below, elaborate on this. The rationale 
given in MICH78 for the specification of levels was to prevent the proliferation of "dialects" of the 
standard. In fact, a large number of dialects or "flavors" have already occurred because persons attempting 
to implement the standard naturally have selected those functions they consider most important and/or 
feasible. This is clearly illustrated in CHAP78. Of the ten installations reporting, at most two implementations 
seemed to correspond exactly to one of the Core levels. The others all had different "flavors" of the 
standard. For the Core to be successful as a standard, it is essential that it be possible for the Implementors 
to be able to define a subset which meets their basic needs for a fast, efficient low-level graphics 
system. The 1977 level structure does not meet this need for the LBL graphics community. Modifying the 
1977 proposal to allow more implementation "flavors" will help legitimize many of the Core dialects, 
but the authors feel that a different philosophical approach, namely, the standardization of graphics 
functions, would be a better solution. SPECIFIC ISSUES BASIC DISPLAY CONTEXTS The experience of the 
LBL graphics users indicates that graphs divide naturally into two parts, data display and annotatlon. 
The llne drawing and area fill primitives are predominately used for data display, and the text or character 
string primitive for annotation. A logical model of the user's graphical output, then, is that it consists 
of two contexts. The first is data display, within which there are two basic functions, llne plotting 
(including markers) and area filling. The second context is annotation of the graph, within which the 
basic function is text display. It is very useful to duplicate certain attributes for each of the basic 
functions and/or two contexts in order to assist the user. In this mode, two independent coordinate 
systems exist for the two contexts. It is not commonly useful (in data representation and annotation 
graphics) to maintain two sets of world coordinates (one for each context); because annotation is usually 
more conveniently done in a normalized coordinate system, rather than in an arbitrary world coordinate 
system. Therefore, it is adequate to provide one set of world coordinates (user-deflned) and one set 
of normalized coordinates (which could be normalized device coordinates). The user can then allow 58 
 both contexts to use either of these two coordinate systems. The natural defaults are to associate data 
display with world coordinates, and text display with normalized coordinates. To illustrate one of the 
potential problems of doing everything in a single coordinate system, a user (doing data display and 
annotation) who is zooming in on data usually does not want the annotation character size to change as 
a function of the limits of the world coordinates. World coordinate limits are frequently dependent upon 
data about which there is no previous knowledge. In the Core System, to avoid this problem, one would 
have to be constantly switching among different world coordinate systems in order to do annotation. 
A similar argument leads one to associate separate clipping control with each context. Experience indicates 
that reasonable defaults for clipping control are "on" for the data display context and "off" for the 
annotation context. The Core attributes that could he duplicated in order to associate them independently 
with the three basic functions of line-drawing, area fill, and text display are intensity, llne width, 
and color. Replacing these three attributes would be line-drawlng-lntensity, area-fill-intenslty, text-lntenslty, 
llne-drawing-color, etc. The natural default values are different in the two contexts. For example, in 
the case of color, data display and annotation typically use color independently, even With different 
modes of color specification. For example, if vectors or raster data were being displayed using color 
to convey information content (for example, hue (of hue, saturation, intensity) being used to indicate 
the level value in a contour plot) annotation would likely want to be done via a named color (one of 
a small set, e.g. "green"). This capability of multiple contexts is an example of a feature which could 
be excluded from a Core System on the grounds of non-mlnimallty, and included instead in a higher- level 
system. However, the authors strongly feel that the multiple context model is so powerful and useful, 
 even to users of a low-level core graphics system, that it should be considered seriously for inclusion 
in a standard. ATTRIBUTES This section describes some of the attributes that the authors feel have 
been inadequately treated or not included in the 1977 Core proposal. FILTER BANDWIDTH The authors propose 
an additional (optional) attribute "filter bandwidth". This attribute allows the user to set a spatial 
resolution filter bandwidth for the output of the device driver. This is useful from a practical point 
of view for several reasons. One of the most common uses for a filter algorithm is to limit the data 
 that is transmitted over low speed communication lines to remote graphics terminals. If a quick preview 
is desired, or if there is a lot of data sent over very low speed (e.g., 300 baud) lines; this mechanism 
is frequently used. Other uses include to help in debugging programs that generate large amounts of 
graphics data (e.g., movies); certain mapping applications, where the large number of short vectors to 
be plotted causes problems with paper tearing and wetting, etc.; and to reduce file sizes when the graphics 
data is to be stored. GLOBAL SCALING A powerful, general image transformation capability is available 
at level 4 in the 1977 Core System. The authors feel that a more limited capability, global scaling alone, 
would be a practical addition to implementations of the Core System which do not provide the full transformation 
capability. Graphics users would use this feature to scale hardcopy output (generated by a device-independent 
program) to a particular device-dependent format. For example, a 36-inch pen plotter at LBL is used to 
produce 10-inch, 8-inch, etc. plots as well as full-size ones. DATA ARRAY INCREMENT Another useful 
addition would be an attribute which allows the user to specify the spacing of data in the vector passed 
to the polyllne routine. It would he provided as a user convenience to allow some generality in the structuring 
of the data to be plotted. Common uses include plotting of the real or complex parts of data whose type 
is "complex". Also, it is not uncommon for users to have data stored in an alternating "X-Y-X-Y" sequence. 
This feature obviates having to copy the data to scratch storage in order to display it. DENSITY,INTENSITY, 
AND LINE WIDTH In evolving what the authors consider to be a basic set of device independent graphics 
attributes, one of the considerations has been some vision and perception research (MONT78). That work 
has indicated that the mechanisms used for visual distinguishability are fairly equivalent. The authors 
choose "density" to be the basic attribute associated with visual distinguishability. The virtue of density 
is its device-independence. The user would specify a value for "density" (ranging from O. to I.) and 
the device driver would use the most suitable function of intensity and line width for the particular 
device to achieve the desired visual impact. Line-width and intensity may also be set directly by the 
user for specialized purposes. COLOR There seem to be three basic uses for color in graphics data display. 
The authors recommend an 59 approach to color attributes which reflects these. First, color is used 
to simplify a visually complex plot, in which case it is used like markers, line style, etc. For example, 
if one were plotting many functions on a single x-y plot, lines could be distinguished with different 
colors. For this usage, it is desirable to have access to a fairly small list of named colors, consisting 
of, say, three primary (or orthogonal) colors (red, green, blue) three secondary colors (cyan, magenta, 
yellow), black, white, and the complement of the background color. Secondly, color is used for annotation 
(axis labels, titles, etc.). For this purpose, the named colors are also appropriate. The third use 
of color is to explicitly encode information. In this situation there are two natural divisions. The 
first is the case in which the user is assigning color to convey something about the data. A typical 
example might be the making of a contour plot using color to represent the data levels. One needs to 
be able to produce color variations which may be controlled, in some sense, "intuitively", and which 
will adequately distinguish the data values in question. In this and similar situations, it is most natural 
to specify color in terms that the human brain is equipped to deal with. The authors suggest the use 
of "psychological" or "psychophysica!" color variables (COMM53, pg. 67) to control the specification 
of color. One set of psychological color variables are hue (dominant wavelength), saturation (purity 
or the amount of white light mixed with the color), and intensity (brightness or radiant flux). In practice, 
varying the hue while holding saturation and intensity fixed frequently satisfies the user's need for 
an intuitively (predictably) varying, distinguishable color change. (Since hue varies the dominant wave 
length, varying hue from the minimum to the maximum causes the colors to vary through the visable spectrum 
of red through violet.)  The second usage of color to encode information is that situation which typically 
arises in remote sensing applications. The scene color is represented by encoding it as a number of raster 
 scanned displays (i.e. files containing intensity information), each done through different color filters 
(or some mechanism yielding intensity data in different spectral bands). This type of data is most easily 
displayed by specifying the intensities of three primary colors, and "RGB" specification is suggested 
for these purposes. Again, it is possible to argue that it is not necessary to include both HSI and 
RGB in a Core System. The authors feel that the advantages in  naturalness of use to a wide variety 
of applications outweigh the (small) additional overhead. FONT Specification of "font" alone is inadequate 
to reference a reasonable number of characters. If one is restricted to referencing characters in a 
font by using computer character codes (the only practical way from the users" point of view), then 
Fortran limits one to 48 characters, "FIPIS" to 64, "ASCII" to 96, etc., and many machines represent 
characters in 6 bits (64 characters). The authors feel that all of these are overly restrictive. There 
needs to be a mechanism for accessing more characters than exist in the computer character code. It is 
preferable for "font" to refer to the total number of characters available (at a particular time). Multiple 
fonts are possible. Fonts are organized into groups called "cases" whose sizes are determined, typically, 
by the mechanism used to access them. Case is an additional attribute which is referred to by number 
or other descriptor ("lower roman", "math", etc.). Intra-string cases changes can be accomplished by 
the use of escape characters. This mechanism is widely used and not at all unsuccessful. (see HERS72, 
for an historical note). CHARACTER STRING ROTATION The Core method of specifying character string rotation 
is very confusing. A more intuitive way for most users (doing annotation) to specify rotation would be 
to give an angle in degrees, counterclockwise from horizontal, about a local origin at the plot point 
of the character string. The authors suggest that the standard could include both the charsize, charspace, 
and charplane attributes, and an additional "character string angle" attribute, which would be no more 
powerful than the existing attributes in specifying typing line orientation, but would be much easier 
to use for that particular purpose. CURRENT POSITION The concept of always drawing from an implicitly 
defined current position ("CP") originates from the manner in which certain hardware devices operate. 
It is frequently not an advantage to the user. The Core could offer a choice between plotting primitives 
which assume a current position, and primitives which require passing explicit starting coordinates. 
 The authors feel that an argument based on good programming techniques can be made for explicit specification. 
The concept of always plotting from the current position makes it more difficult to write robust programs. 
The deletion or moving of a single graphics call will potentially change large parts of the output. In 
addition, programs using CP may not be as easily readable, since some of the information necessary to 
understand the action of each primitive is a side-effect of a previous primitive and not necessarily 
obvious. These "programming technique" disadvantages of CP can be overcome by always using "move" primitives 
to explicitly establish the starting position of the next primitive (such as "line" or "text"), but then 
the program become cluttered and less readable. The Core System  60 could easily provide "high-level" 
primitives which combine a "move" with "line", "text", "polyline", etc. 3-DIMENSIONAL GRAPHICS It 
is unreasonable to classify 3-D graphics as a basic low level graphics function. If a particular hardware 
device supports 3-D graphics function, fine. If not, a higher level module may be used to perform this 
function. The amount of code required in a low level system to correctly handle the problems associated 
with layout, titling, labeling, providing automatic scaling, etc. for 3-D graphics is considerable. 
(It is necessary to put this in the low level system if the 3-D to 2-D transformation is going to be 
done there, since it is sometimes necessary to deal with certain of these aspects after the transformation 
to 2-D. In many cases these problems relate to visibility.) In the data representation and annotation 
environment a fairly small percentage of users routinely make use of 3-D graphics, certainly not enough 
to justify its inclusion in a low level system when it can easily be added as an additional function. 
 The authors agree that the 2-D and 3-D versions of the graphics functions should be specified in such 
a way that 2-D graphics would be a special case of 3-D, but feel that in no way does this imply that 
the 3-D functions should necessarily be implemented along with the 2-D functions. AREA FILLING The 
authors consider area filling to be a basic graphics function. The reason for this is that it is fairly 
difficult to do area filling correctly on those types of hardware that are most suited to this function, 
namely, devices capable of operating in a raster mode. (The difficulties arise from the fact that the 
output to fill an area needs to be done in raster mode, and, among other things, this tends to generate 
large amounts of graphics data.) Many such devices, however, have hardware instructions to perform this 
function. A Core System could provide the area filling function simulated in software, optionally, for 
those devices which don't provide it in the hardware. The drivers for devices which implement area fill 
in hardware can always provide the function. GRAPHICS INPUT The authors feel that graphics input is 
a basic function for any system that supports graphics terminals. This idea is supported by the fact 
that most interactive graphics programs at LBL make use of nothing more than line-drawing, character 
display, and simple graphics input (cursor or erosshair location). A standard system should be able 
to implement either low-level graphics input or higher level input functions, depending on need. The 
1977 Core System, however, assumes that graphics input is a high-level function, and that, when implemented 
 at all, will be fairly sophisticated. Additionally, the 1977 Core places graphics input above the level 
of retained segments in the implementation hierarchy. This is not acceptable to installations like LBL 
which would like to have its low level graphics system conform to the Core Standard. The overhead in 
the driver for handling retained segments is simply too high a price to pay for the ability to read a 
cursor location. This is especially true in a heavily used timesharing environment where even a small 
increase in the amount of memory used can make a big difference in the response time of an interactive 
program. CONCLUSION The point of view presented in this paper is that of a data representation and 
annotation or "passive" graphics system. While the authors have no desire to eliminate or impede the 
capabilities important to object manipulation, or "active" graphics systems, equal effort should be devoted 
by the GSPC to the problems faced by users of data representation and annotation graphics. Formulating 
a standard as a set of standard graphics functions rather than as a hierarchical set of capabilities, 
would facilitate a system usable by everyone. Much effort has been put into the 1977 GSPC Core System, 
and much of that work will be useful in formulating a graphics standard. However, there is more work 
to be done, and modifications to be made to the 1977 Core Proposal before it will be generally acceptable. 
It is expected that the 1979 proposals will be a significant improvement, and, hopefully, can be accepted 
by everyone in the graphics community as a useful common tool. REFERENCES CHAP78 Chappell, G., and 
Bonl, P., "Core System Implementations --A status Report," Comput. Gr. 12, 4 (Dec. 1978), 53-66. COMM53 
Committee on Colorimetry, Optical Society of America, The Science of Color, Thomas Y. Crowell Co., 1953. 
 GSPC77 Graphics Standard Planning Committee, Status Report, Comput. GR. II, 3 (Fall 1977). HERS72 Hershey, 
A., A Computer System for Scientific Typography, Comp. Graphics and Image Processing i, (1972), 373. 
 JOHN79 Johnston, N.E., Cahn, D.U., and Johnston, W. E., GRAFPAC, UCID 8094, Lawrence Berkeley Laboratory, 
Berkeley, California, (Jan. 1979). MICH78 Michener, J., and Foley," J.D., "Some Major Issues in the 
Design of the Core Graphics System," Comput. Surv. I0, 4 (Dec. 1978), 445-463. MONT78 Montalvo, F. S., 
"Color Perception," 61  COMTECH Conference, 3, 1978). San Francisco (March NEWM78 Newman, W. and van 
Dam, A., "Recent Efforts Toward Graphics Standardization," Comput. Surv. I0, 4 (Dec. 1978), 365-380, 
VINB78 Vinberg, Anders "Position Paper Graphics Standard," Comput. Gr., 12, (Dee. 1978), 46-52. on 4 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807426</article_id>
		<sort_key>63</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Aspects of quality in the design and production of text]]></title>
		<page_from>63</page_from>
		<page_to>70</page_to>
		<doi_number>10.1145/800249.807426</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807426</url>
		<abstract>
			<par><![CDATA[<p>The problem of quality in printed text produced by computer has received little attention. Three pieces of recent work at Cambridge which relate to different aspects of the problem are presented in this paper. The first is a letter design system, which enables the typographer to exploit not only the power of the computer but also the freedom which modern printing technology has made available. The second is an attack on the problem of high quality text for television transmission, especially where the text is itself computer generated. Third, is a system which enables the user to set and correct tabular text easily and flexibly.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Character design]]></kw>
			<kw><![CDATA[High quality text]]></kw>
			<kw><![CDATA[Raster scan typography]]></kw>
			<kw><![CDATA[Table making]]></kw>
			<kw><![CDATA[Text composition]]></kw>
			<kw><![CDATA[Text handling]]></kw>
			<kw><![CDATA[Typesetting]]></kw>
			<kw><![CDATA[Typography]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.6.4</cat_node>
				<descriptor>Quality assurance</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003507.10003510</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->System management->Quality assurance</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P328955</person_id>
				<author_profile_id><![CDATA[81351598492]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alison]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pringle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031553</person_id>
				<author_profile_id><![CDATA[81350590377]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Robinson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP55041795</person_id>
				<author_profile_id><![CDATA[81100597963]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Neil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wiseman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cambridge]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Campbell, C.I.C. Show. Rainbow memo 113. University of Cambridge Computer Laboratory. 1976.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chyron II-operating instructions. A-200-0036, Chyron Telesystems, New York. 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Coueignoux, P.J.M. Generation of Roman printed fonts. Ph.D. thesis. MIT. June 1975.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dobson, D.B. (Chairman). Transcript of panel on technical composition. IEEE Trans. on Prof. Comm. pc 18, 4 (Dec. 1975). 327, 334.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Freeman, H. On the encoding of arbitrary geometric configurations. IRE Trans on Electronic Computers 10, 2 (June 1961) 260-268.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hart's Rules for Compositors and Readers at the University Press Oxford.# 38th edition, Oxford University Press, London, 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kindersley, D.G., and Wiseman, N.E. Letter Spacing British Patent Application 27266/77.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Knuth, D.E. Mathematical typography. Stan-CS-78-648, Stanford University. 1978.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lesk, M.E. Tbl-a program to format tables. Computing science technical report #49 Bell Laboratories 1976.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Robinson, P. Computer assisted graphic design. Ph.D. thesis Cambridge University 1979.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wiseman, N.E. A computer based graphics system written in BCPL. IRIA Journe&#233;s Graphiques 1973, 77-86.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wiseman, N.E., Campbell, C.I.C. and Harradine, J. On making graphic arts quality output by computer. Comp. Journal 21,1 (Feb. 1978) 2-6.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wiseman, N.E., and Robinson, P. An operating system for interactive terminals. Software P. &amp; E. 7, 4 (July 1977). 507-510.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ASPECTS OF QUALITY IN THE DESIGN AND PRODUCTION OF TEXT Alison Pringle, Peter Robinson, Neil Wiseman 
University of Cambridge Abstract: The problem of quality in printed text produced by computer has received 
little attention. Three pieces of recent work at Cambridge which relate to different aspects of the problem 
are presented in this paper. The first is a letter design system, which enables the typographer to exploit 
not only the power of the computer but also the freedom which modern printing technology has made available. 
The second is an attack on the problem of high quality text for television transmission, especially where 
the text is itself computer generated. Third, is a system which enables the user to set and correct tabular 
text easily and flexibly. Key words: Typography, typesetting, text handling, text composition, high 
quality text, character design, raster scan typography, table making. CR categories: 3.40 5.57 8.2 
Introduction Recently concern has been expressed in various quarters about the decline in the general 
quality of text presented to readers. It is a matter for some concern that the reason which is frequently 
given for this decline is the advent of the computer in printing. We not only dispute this, but also 
believe it can be shown that judicious use of computers can result in a rise in standards. It is often 
forgotten that much of the problem arises from changes in printing technology which are independent 
of the use of computers. For example, film setting and computer composition are often spoken of as 
equivalent monsters, but there have been computer systems which set hot metal, as well as film setters 
driven by conventional means. In addition there are This work was supported in part by the Science 
Research Council and the British Broadcasting Corporation. Authors' address: Computer Laboratory, Corn 
Exchange Street, Cambridge, England CB2 3QG now ways of presenting text which do not directly involve 
printing. An important example is tele- vision, which with the growth of teletext systems will become 
an even more common medium for textual communication. It is therefore arguable that some of the problem 
arises from the attempt to apply the techniques of traditional technology in an environment for which 
they are unsuitable. It is also fortunately true that too many computer systems have been built by people 
with inadequate feel for and knowledge of the traditional values of printers, and that comparatively 
little imagin- ation has been applied to the problem of new and valuable ways in which computers might 
be applied to the design and production of text. A final snag which may have disastrous consequences, 
is that the world at large approaches computers demanding cheaper rather than better results, a demand 
to which we as a profession have often acceded all too readily. When We talk about quality in text there 
are three main levels of quality to be considered and these are to some extent reflected by the three 
pieces of work reported here. At the lowest level it refers to the fineness and consistency with which 
 image features are rendered. This involves both the resolution of the reproduction and the accuracy 
with which the characters are stored. Next, quality refers to the similarity between the reproduced letter 
forms and the designer's intentions. To reproduce a type face with two techniques may require different 
letter models to achieve identical results. Finally, the letters must be assembled into text, and here 
quality refers to the overall pattern, texture and readability. In Cambridge we have been working 
for several years on various aspects of the problem of quality. In all our work we have tried to approach 
problems with a typographer's or printer's eye, and we have worked closely with members of each profession. 
We have not, in general, tried to develop a mathematical formulation of the problems, but have chosen 
a more intuitive approach. Many of our systems operate interactively and can take advantage of any traditional 
skills possessed by the user. In this way we hope to gain insight into the craft in which we are dabbling 
so that we may make use of this in future systems. As far as we know the only other academic research 
in progress which is similarly motivated is that which Knuth has recently reported from Stanford. &#38;#169; 
1979 ACM 0-89791-004--4/79/0800--063 $00.75 See Copyright Pg. 63 His approach is more mathematical than 
ours; this is particularly evident in his Metafont system. A letter design system We have built an 
interactive computer graphics system to experiment with digital typography by providing letter designers 
with an environment in which they might work. All stages are supported, from playing with initial sketches 
and comparing ideas qualitatively to encoding the finished  letterforms into founts for distribution. 
The program, which is called ELF, runs under a special operating system for interactive terminals (Wi~eman 
and Robinson 1977) on a PDPII/45 computer with Vector General Series 3 display, key- board and lightpen. 
This operating system is such that ELF could very easily be made to operate with different workstation 
hardware. Fig. i shows the layout of the screen during an ELF session. A command line (top left), message 
line (top right) and a few lightbuttons (right) are  shown, together with two versions of a graphic 
form being worked on by the operator who is pointing the lightpen at the tracking box (lower left) which 
is itself surrounded by a few lightbuttons. Using lightpen and keyboard, images may be created, manipulated, 
measured and copied. Several images may be viewed together and images can be saved and recalled at any 
time. At first sight ELF resembles many an interactive graphics system for handling simple geometrical 
objects. An internal model records details of the objects in a manner chosen to facilitate manipulation 
of geometry. After every alteration to the model a picture compiler regenerates the display for the changed 
object. An interaction language comprising some 30 commands is provided. Curve generators, interpolation 
and smoothing operations, view control, and so on, are included. These might all be said to be typical 
of interactive graphics systems of this sort. There are, however, a few unusual features and these will 
be described in more detail. Some commands are obeyed continuously until a certain key is typed or the 
"end conm~and" lightbutton is hit. The rest are executed once as they are issued, either by typing them 
in or pointing at their respective light-buttons. In many cases commands of the second sort can be done 
while a co,and of the first sort is in progress. Thus for example an on-line HELP file can be consulted 
(using a command of the first sort) while the system is being used (entering commands of the second sort). 
Sketching and dragging are commands of the first sort, deleting a point is a command of the second sort. 
Multi-tasking is used to implement facili- ties such as this, to provide surveillance and break-in, and 
to maintain the input tools in a ready state to allow the graphics equivalent of "typing ahead". The 
system is therefore very responsive and is rarely deaf to a user's action whether prompting that action 
or not. It is a feature of the special operating system mentioned above that co--ands can be logged 
in  textual form to a file, as they are executed. The log file can subsequently be executed by ELF 
as an indirect command file to repeat the sequence of  actions. This facility can be used to replay 
earl- ier events in a design session, to recover a previous state or to review progress to date. Different, 
but similar, effects can also be got by editing the log file first, and, since this can be done from 
within ELF, an extensive range of facilities for repeatedly modifying the pictures in view can be set 
up by the operator as he works. Though a trackball or stylus-tablet might have seemed preferable for 
some ELF operations, a light- pen was the tool available and was pressed into service with rather pleasing 
results. The pen service routine is tunable by the operator to suit personal preference and drawing style. 
Several parameters may be specified - vernier, handshake tolerances, sample rate etc., and a wide range 
of effects can be obtained. Even a totally unskilled operator can quickly find a set of parameters which 
allows him to work comfortably. Several commands are specifically intended for letter designing functions. 
Space computation is an example. By arranging a few characters together on the screen the designer is 
able to judge their match and fit while still developing their details. Commands are provided to carry 
out area computations on an object to help fix its spacing. The method (Kindersley and Wiseman 1978) 
is quite different from that used in conventional text setting in which each character is inscribed in 
a rectangle and spacing between letters comes from butting these rectangles together. The method is based 
on a computation on the letterforms themselves using high order moments and a simple interpreter for 
carrying out such calculations is contained in ELF. The basic idea is to find a position for each letter, 
known as its "optical centre" about which the 4th moments (or some other power) of area of the letterform 
balance. An "intrinsic width" is then determined in propor- tion to the total moment of the character 
about its optical centre and characters are spaced at distances, measured along lines joining their optical 
centres, related to these intrinsic widths. By having the facility to determine these centres and widths 
as he goes along, the designer is therefore aware of the fit and match of his letters from the beginning, 
and the method allows the shape of letters and their arrangement into strings to influence the placement 
of individual features. ELF represents a filled area image as a sequence of concatenated trapezia. The 
base of each trapezium is either horizontal or vertical or at a fixed inclination to the horizontal or 
vertical. The trapezia are distributed along a line chain on a series of points each recorded as a 4-tuple 
 (x, y, amplitude, mode). View control permits the display of centre-lines only, trapezia outlines, or 
a fully filled in image. Command expresssions can be set up to move any corner of a trapezium in a permitted 
direction or points along the line chain in any direction with continuous feedback of coordinate values. 
The screen shows one or more images of which one is selected (active) and the rest passive. Commands 
may be directed at the active image and to facilit&#38;te this, two cursors are normally positioned in 
it. The point cursor is a small square surrounding a selected point. The line cursor is a small circle 
at the mid-point of a selected line. A command given by a single keystroke steps the cursors. Commands 
may be offered for execution either character by character 64 or line by line and command lines can 
be submitted (here re-submitted) in an order different from that in which they were prepared. Individual 
operators use these facilities in different ways - one convenient use is when recovering from an error 
in an indirect command file because new commands can be easily introduced to repair the mistake in mid- 
sequence. Typography for raster-scan displays. For several years now television studios have used special 
electronic "character generators" to produce textual captions for inclusion in transmitted programmes. 
Later versions of these devices incorporate a computer to control their operation. More recently, "graphics 
generators" have been built that feature a general purpose raster-scan colour display driven by a computer, 
with which any pictures can be shown -and lines of text are just a particular kind of image. How- ever, 
there are difficulties in matching an elect- ronically synthesised type fount to a conventional fount 
(for example, lettering on the background set of a studio) and in designing a fount that will withstand 
the distortions inherent in tele- vision transmission. This section describes research work in this 
field undertaken in conjunction with the British Broad- casting Corporation in London. The BBC has an 
experimental television graphics computer compris- ing a mini computer with the usual peripherals together 
with a graphics tablet and two Icon displays. The Icon display was designed by Logica and built by DEC's 
special systems group in England to generate a television signal that can be mixed with other sources 
in the studio. Programs have been written to assist the television cover- age of current iaffairs (showing 
graphs and~ histograms for budgets and elections) and sport (showing maps of golf courses) - both requiring 
schematic diagrams with overlaid text (Fig. 4). Effectively the display presents a bit map 1024 pixels 
across by 576 deep, with each pixel coloured with one of 30 colours whose exact definitions in terms 
of the three additive primaries are specified in a separate look-up table. Each display requires a dedicated 
small PDP-II computer, whose main memory is used to store the picture in a run-length encoded form. The 
processor of this computer also serves to manipulate the display file according to instructions passed 
down a link from the host computer; in this way pictures are sent for dis- play. Pictures are transferred 
from the host computer to the small PDP-II using a high-level protocol which describes a picture in terms 
of areas bounded by polygons, rather than in a run-length encoding. This models the picture as a series 
of areas across the screen, and each area can be sub- divided into a series of areas down the screen, 
and these can be subdivided again and so on. Each elementary unit is, therefore, a rectangle which can 
be either a block of colour or a line of characters (Knuth 1978 has subsequently adopted a~ similar model 
for describing pages of text). Special generating functions can be attached to  the rectangles to produce 
regular polygons and approximations to circles. The monitor program in the dedicated PDP-II handles character 
genera- tion specially, converting strings into the appro- priate run-length encoded picture according 
to fount descriptions stored as part of the monitor. This fount description records the run-lengths 
composing each character, together with any symm- etries, the latter being used to compress the amount 
of information stored. A different descrip- tion is required for each different size of the same type 
face. There are many thousands of type faces available in the repertoire of conventional typesetters, 
and the problem is to generate the appropriate descriptions so that these are avail- able to graphics 
designers using the computer system. It should be noted that the problem here is to reproduce existing 
type faces rather than to design new ones(as described in the previous sec- tion) or to synthesise type 
faces according to purely mathematical rules (as Coueignoux 1975 and Knuth 1978 have proposed). Clearly, 
a flying-spot scanner can be used to digitise characters from a piece of artwork. This even produces 
a bit map, which is almost the form required by the display; indeed, the Chyron television character 
generator reads new founts in just this way (Chyron, 1976). However, there are further complexities. 
Firstly, there may be substantial differences in the resolution of the various devices used to scan and 
display pictures. Also the resolution of the Icon display is rather coarse for typography -small characters 
may be composed on a grid only 25 pixels square -so care must be taken in preparing the founts. This 
suggests that the resolution of the model should be much higher than that of the display. Secondly, when 
a picture is digitised, it is unlikely to be correctly oriented -a small rotation will cause a supposedly 
horizontal line to cross several scan lines, introducing a jagged edge (the effect known as aliasing). 
 Scaling and rotation are not easily performed on images in pixel form, arguing against the use of such 
a model. The obvious alternative is a model such as that described in the previous section, or to record 
the outline of a character as a sequence of points joined b~straight or simple curved lines (Freeman 
1961). ~hese are both easy to manipulate in the required way, and the latter form has been used in 
this part of the research. Routines have been written to convert images from pixel form to this chain 
encoding, to write run-lengths from it, and to manipulate images stored in this way. These are described 
in detail elsewhere (Robinson, 1979). This scheme means that a type fount can be digit- ised and converted 
into chain encoding just once. Then the image can be edited in this form to correct any errors introduced 
during digitisation - typically this would involve rotation to correct the alignment and scaling to a 
standard size. Then the run-length code for a variety of display sizes can be generated ready for incorporation 
in the monitor program of the display. The method of interpolation between the points in the chain encoding 
can be chosen to suit the resolution at which the fount is to be reproduced; for television, linear interpolation 
is usually adequate. 65  It is also useful to perform a further sequence of amendments to the image 
in run-length form. Domestic television blurs sharp images, causing  characters to "fill in" rather 
in the way that ink spreads in conventional printing, and this can be prevented by cutting away pixels 
in critical areas (Figs. 5 and 6). A second editor, operating on pixels, is necessary to make these 
corrections separately to each different size of lettering derived from the single chain encoded version 
of the fount.  Graphic designers are loath to allow their art to be automated, and therefore value 
this last stage as allowing them to make the final aesthetic judge- ments on a fount. However, it would 
be interesting to continue this research by investigating an auto- matic scheme for detecting the parts 
of the images that are susceptible to distortion and performing these corrections. This might draw on 
modern techniques of image analysis together with the grammar that describes the construction rules for 
letters (Coueignoux, 1975). The comp6sition and correction of tables  Over recent years increasing 
numbers of publishers have adopted computer based composition systems. It is interesting to note in which 
areas such systems have gained general acceptance, though perhaps more instructive to note where they 
have not. The most common areas to be omitted are tables and mathematics. This kind of copy (knownto 
printers as 'penalty copy') is notoriously difficult to get right whether it is set by hand or by computer, 
and furthermore, the cost of corrections in such text is high. Users of computer based systems claim 
that it is extremely difficult to get good results in these areas, and that the cost of corrections is 
so high that these areas should be left unautomated. Thus table composition is net, in general, well 
understood, and very little attention has been given to the correction problem. In fact most current 
systems do very limited table makeup and provide a system for "editing in" corrections by hand. At Cambridge 
 we now have a system capable of generating tables in a wide range of styles and incorporating changes 
into them. A common problem of particular difficulty for table-makers is the wide range of house styles 
 employed by publishers. For this reason we have  taken care to provide a table description language 
which can encompass a wide range of formats and have combined this with a default description which provides 
the user with reasonable results for a minimum Of effort. We were anxiouS to avoid two extreme approaches 
which are often found in type setting systems. Systems of the first kind have style built into the 
program in such a way that  the user has very little control over the final appearance of his document. 
This is particularly unfortunate as many printing houses do work for more than one publisher. Under the 
other extreme the system is incapable of making any unassisted decisions so that although the user can 
achieve almost any desired result he has to work hard to do so and needs all the skills of a compositor. 
 Selecting the right balance of power between user and system is one of the hardest decisions to be made 
when designing such a system. The system we have built is capable of making tables in a wide range of 
styles, as Figs. 7 to 9 illustrate. The style of a particular table is defined by a format description 
using English key- words. The only mandatory items in this are the number of columns and their widths. 
This require- ment enables the user to emphasise a particular column and control the overall character 
of the table. Apart from this he may, if he wishes, define further aspects of the format. Parameters 
are available (among others) to define how far rows and columns of entries are to be separated from each 
other, what rules are to be added, what proportion of the table constitutes a heading and whether it 
is to be treated differently from the rest of the table, how entries are to be aligned in the columns 
and whether text is to be Justified. This format description is handed to the tabler together with a 
definition of the table entries. The clear distinction between these two sections in the input has certain 
advantages. In particular it is very easy to experiment with alternative formats. The tabler performs 
line makeup within the entries and arranges the entries suitably in relation to each other. When makeup 
is complete the table is output to file entry by entry in a form which can be interpreted by the program 
which drives the type-setter. At present we are using a Laser-Scan HEDI display which plots on diaso- 
film as output device using a program described elsewhere. Once a table (or any text) has been set, 
proofs are taken and read for correctness. Errors will usually be found which may result from incorrect 
keying or from errors of judgement by the tabler (e.g. incorrect hyphenation). More seriously it may 
be found that the choice of format was imper- fect and alterations to the format are desirable. To incorporate 
changes the user makes corrections in the output from the tabler and hands it back to the program. This 
detects that the table has been processed before and thus has presumably been correct (in the sense of 
conforming to the format definition). The program endeavours to restore the table to correctness while 
maintaining a maximum nilmber of the decisions implicit in the text. This last condition is essential 
since otherwise it will restore any errors which were due to its own shortcomings. In order that it 
may carry out subsequent correct- ions the tabler heads its output with a complete format description. 
This includes explicitly any default options used and a description of the dimensions of the made up 
table. If after edit- ing this conflicts with the format implicit in the directives to the typesetting 
program, the explicit description is paramount. To enable the program to incorporate changes efficiently, 
the format description is augmented by a series of 'tolerance' definitions. These specify how far the 
normal rules for makeup may be bent in order to limit the effects of change. For small changes the tolerances 
which are usually most useful are those describing word spacing and loose space in a line. A more serious 
limitation for large changes is imposed by the overall size of the table. Once the table has been made 
and related to the associated text, it is likely to be cons- 66 trained to remain the same size. However, 
if variation is possible, tolerances may be added to the dimensions output by the tabler. Usually more 
latitude is available horizontally than vertically. To make use of this, tolerances may be applied to 
the column widths. The program accepts all the available information and does its best to oblige. If 
it is unable to absorb the changes it will suggest a complete remake - an option which is always available. 
Figure i0 illustrates the diff- erence between the two processes. After the first table was made up, 
alterations were made to it and the tabler told first to absorb the change and then to remake it. This 
is, obviously, an exaggerated case, since such deviation from the norm would not usually be acceptable, 
but it is hoped it will make the difference clear to the non-expert. We are enthusiastic about the 
results we have achieved using these methods and are confident that the general purpose system now being 
built will yield similarly good results. Conclusion We believe we have demonstrated that the computer 
can be used by printers and typographers in a way which will enhance rather than detract from their 
craft. We do not claim to have produced any definitive solutions but hope that our work may indicate 
a way ahead. This account of our work is, of necessity, brief, but we hope it serves to convey the 
flavour and direction of our research. Further details of these and other related projects in progress 
in Cambridge can be obtained from the authors. We would like to thank everyone who has taken time 
to discuss the problems involved with us, whether they did so as craftsmen showing us their skills or 
readers describing their personal preferences and reactions. We are particularly grateful to Charles 
McGhie of the BBC, David Kindersley and Lida Lopes-Cardozo for their help and assistance. References 
 Campbell, C.I.C. Show. Rainbow memo 113. University of Cambridge Computer Laboratory. 1976. Chyron 
II-operating instructions. A-2OO-OO36, Chyron Telesystems, New York. 1976. Coueignoux, P.J.M. Generation 
of Roman printed fonts. Ph.D. thesis. MIT. June 1975. Dobson, D.B. (Chairman). Transcript of panel on 
technical composition. IEEE Trans. on Prof. Comm. pc 18, 4 (Dec. 1975). 327, 334. Freeman, H. On the 
encoding of arbitrary geometric configurations. IRE Trans on Electronic Computers iO, 2 (June 1961) 260-268. 
 Hart's Rules for Compositors and Readers at the University Press Oxford. 38th edition, Oxford University 
Press, London, 1978.  Kindersley, D.G., and Wiseman, N.E. Letter Spacing British Patent Application 
27266/77. Knuth, D.E. Mathematical typography. Stan-CS-78- 648, Stanford University. 1978. Lesk, M.E. 
Tbl-a program to format tables. Computing science technical report #49 Bell Laboratories 1976. Robinson, 
P. Computer assisted graphic design. Ph.D. thesis Cambridge University 1979. Wiseman, N.E. A computer 
based graphics system written in BCPL. IRIA Journ~es Graphiques 1973, 77-86. Wiseman, N.E., Campbell, 
C.I.C. and Harradine, J. On making graphic arts quality output by computer. Comp. Journal 21,1 (Feb. 
1978) 2-6. Wiseman, N.E., and Robinson, P. An operating system for interactive terminals. Software P.&#38; 
E. 7, 4 (July 1977). 507-510. 67   Mommy Iml~ct d Van/m~ Tec~nololpeS on Layau~ ~,~ems WELCOME -INTRODUC'q'KM",I 
COFFEE PRCK~,RAM OVERVIEW LUNCH Oa Yam" C, we Smmnt ~moaz Semm~ 3 I~ Truing Medmdcal Deign  COFFEE 
.S~ti~ t ,T~mm~ z Smma3 C.ont'd cem'd Com'd HOST ~AIL PARTY ACM ~IGDA Figure 9 ~ nf Utilitb.1(?) -M~*y7S 
Utility Audmr Current C,.mtme~ Venom BURPS AIIQ *.A If ye~'l] ri~ this" you'U mE mydling q(ED ZEK 8. 
3 worlu tJSTSYS ABQ 9.3 New vermin:  m~mt~ w~ vet t-6: Bdk.ved tn w~ QUERK PJ$ t. 3 E,pmenul SPLOI') 
ABQ 3-7 S~meonm w(',r~ ZILCH fails TWrTCH HAH S.z Blu~s now deemed rn be fi~es ZILCH ??? Thc ~me OM hi'hful 
a,.,:l,rely Figure 10  T,,,'-~y Pm,bq'mnnnnng Techniques in !~ A, mommmim~ Tutmid ~mion 4 S~mon s 
FaultTo~nmt .Demig~Aumma-I/Ctaye~ ODFFEE S~ion 6 1 Semou 5 [~/B I~y,]ut Cont'd CONFERENCE LUNCHEON t 
 st=a,, roLL READ. Dnct~ of Tdev~n. .~mulmon Arc~,~.~_ ,ral ~ md D=q~ Am,,mm,. COFFEE  cont'd c..~m 
'd Design Rule Vm~ackm NO HOST CX'~C~r&#38;IL PARTY IEEE DATC ~" u~t~ - Ju,e 7s Utility Authm C.mm~ Comments 
Version BURPS AIIQ 4.$ M(~e .r Ic~ OK  FRED Z/~ II. 3 W.~ks LJSTSYS ABQ 7.7 New venture: in~wnpmlde 
with vet t*6 QUERK PJS z.t ~ e~pmmentzl SPIED ABQ 4.z WoHtt when ZILCH hik TWITCH HAH 5.2 Bub~ m~w deemed 
t,~ he features ZILCH ??? The ,me OM Faithful -but' ~1 ,mlyl ~y SPL~I) Wedm~y T~ Tutoml ~mon tt ~ tz 
SeWm t~ DA Sy~..ms I ~ Vetifir~m l~cumentamo~ COFFEE Se,,mmt, 1Se,mmttz [ Serum'3 com" d Cont'd C.~n 
d CONFERENCE LUNCHEON z CONTEST &#38;WARDS  ~ei0m t4 Semi.n ts DA S~ II An LSI Tat Sy~m COFFEE t4 ~ 
IS C,~'d C.~'d NO HOST COCKTAIL PARTY Surf ,X Utilitles -ju~ -~ Udlity Aud~w (~,u','em ~n V*r,ao. BURPS 
AItQ 4-S Mo,'c ,',*" Io~ OK ;FRED ~ &#38;J W,,rh L.I~YS A~ ?.7 New vet~m: inc(~nrIpa~lg~ with V~ I-'6 
~UERK" PJS *.t tm E xlx",nn'~nul SPLOD AI]Q 4.z Worb wl~n ZILCH Fails TWlT(:H HAH Lz Bug, n,,w tx~be 
(eatureJ iZIL(:H 7?? The ,WW old hithful - a.d,.d U'y SPLOD 70  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807427</article_id>
		<sort_key>71</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[An interactive documentation system]]></title>
		<page_from>71</page_from>
		<page_to>82</page_to>
		<doi_number>10.1145/800249.807427</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807427</url>
		<abstract>
			<par><![CDATA[<p>Most chronic users of time sharing computer systems are familiar with programs that allow the creation and manipulation of text files. Less often they have at their disposal programs that will format the document described by a text file, generating output such as a typist might produce. Rarely is there any mechanism by which graphics can be integrated with text. Lawrence Livermore Laboratory has a powerful, flexible and interactive computer-based documentation system that will format a source document description according to user specifications and incorporate illustrations to produce online documents, offset reproduction masters, 35mm color slides, movie titles, or viewgraphs. The flexibility of the system is greatly enhanced by the use of a device independent graphics library. Text may be plotted using the hardware characters specific to a device (when possible), or may be drawn as Hershey characters or polygonally outlined symbols. Illustrations may be defined in a simple 2d graphics language, and graphical output from application programs may also be incorporated directly into a document.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color graphics]]></kw>
			<kw><![CDATA[Documentation graphics]]></kw>
			<kw><![CDATA[Printing]]></kw>
			<kw><![CDATA[Text processing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.7.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Documentation</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P142871</person_id>
				<author_profile_id><![CDATA[81100324790]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Beatty]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Waterloo, Waterloo, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331290</person_id>
				<author_profile_id><![CDATA[81339494145]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Janet]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Chin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tymshare, Incorporated, Cupertino, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330771</person_id>
				<author_profile_id><![CDATA[81332516584]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Moll]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360684</ref_obj_id>
				<ref_obj_pid>360680</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. W. Kernighan and L. L. Cherry, "A System for Typesetting Mathematics," Comm. ACM 18, 151-156, (1975).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Moll, TRIX - An Interactive, Interpretive Language for Manipulating Strings of Characters, Lawrence Livermore Laboratory, Livermore, CA, UCID-30100 (1974).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Cecil, TRIX AC: A Set of General-Purpose Text Editing Commands, Lawrence Livermore Laboratory, Livermore, CA, UCID-30040 (1974).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Moll, The TRIX Report Editor, Lawrence Livermore Laboratory, Livermore, CA, UCID-30142 (1978).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. C. Beatty, PICTURE - A Picture-Drawing Language for the TRIX/RED Report Editor, Lawrence Livermore Laboratory, Livermore, CA, UCID-30156 (1977).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Blair, The UXDD80 Graphics System, Lawrence Livermore Laboratory, Livermore, CA, UCID-30146 (1977).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Storch, TV80: Device-Independent Graphics Routines for the CDC 7600 Computer, Lawrence Livermore Laboratory, Livermore, CA, LTSS 305 (1978).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. C. Beatty, REDPP - A Postprocessor for the TRIX/RED Editor, Lawrence Livermore Laboratory, Livermore, CA, UCID-30125 (1977).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Schneider, D. Thompson, and G. Whitten, User's Guide to the Octopus Computer System (The SHOC Manual), Lawrence Livermore Laboratory, Livermore, CA, UCID-30048 (1975).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>365270</ref_obj_id>
				<ref_obj_pid>365230</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. N. Mooers, "TRAC, a Procedure Describing Language for the Reactive Typewriter," Comm. ACM 9, 215-219 (1966).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095600</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. E. Griswold, J. F. Poage, and I. P. Polonsky, The SNOBOL4 Language, 2nd ed., Prentice-Hall, Englewood Cliffs, NJ (1971).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. E. Nielsen , Jr., Three Dimensional Electromagnetic Particle Simulation of Fusion Plasmas, Ph.D. Thesis, Stanford University, Stanford, CA (to be published).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095594</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. V. Aho and J. D. Ullman, Principles of Compiler Design, Addison-Wesley Publishing Company, Reading, MA, pp. 219-224 (1977).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. V. Hershey, Computer Graphics and Image Processing, 1, 373-385 (1972).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[N. M. Wolcott and J. Hilsenrath, Tables of Coordinates for Hershey's Repertory of Occidental Type Fonts and Graphics Symbols, NBS Special Publication 424, U. S. Government Printing Office (1976).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. C. Beatty, "Two Iteration Theorems for the LL(k) Languages", Dept. of Computer Science, University of Waterloo, Technical Report CS-78-24. To appear in Theoretical Computer Science.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[K. S. Booth and G. S. Leuker, "Testing for the Consecutive Ones Property, Interval Graphs, and Graph Planarity using PQ Tree Algorithms," JCSS 13 (1976) 335-379.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. W. Kuhn, Development and Implementation of New Character Fonts at LLL, Lawrence Livermore Laboratory, Livermore, CA, UCID-17653 (1977).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN INTERACTIVE DOCUMENTATION SYSTEM 'I John C. Beatty :~ University of Waterloo Waterloo, Ontario, Canada 
 Janet S. Chins Henry F. Moll Tymshare, Incorporated Lawrence Livermore Laboratory Cupertino, California, 
USA Livermore, California, USA ABSTRACT  Most chronic users of time sharing computer systems are familiar 
with programs that allow the creation and manipulation of text files. Less often they have at their disposal 
programs that will format the document described by a text file, generating output such as a typist might 
produce. Rarely is there any mechanism by which graphics can be integrated with text. Lawrence Livermore 
Laboratory has a powerful, flexible and interactive computer-based documentation system that will format 
a source document description according to user specifications and incorporate illustrations to produce 
online documents, offset reproduction masters, 35mm color slides, movie titles, or viewgraphs. The flexibility 
of the system is greatly enhanced by the use of a device independent graphics library. Text may be plotted 
using the hardware characters specific to a device (when possible), or may be drawn as Hershey characters 
or polygonally outlined symbols. Illustrations may be defined in a simple 2d graphics language, and graphical 
output from application programs may also be incorporated directly into a document. CR Categories: 4.12, 
4.22, 8.2. Keywords and Phrases: Documentation graphics, text processing, printing, color graphics. 
INTRODUCTION The preparation of a document which excels both in content and in presentation is invariably 
an iterative process, requiring repeated editing and retyping, followed by interaction with an illustrator. 
The use of computer-based systems such as the one we describe here substantially facilitates documentation 
preparation by providing the author with clean, nicely formatted copy whenever it is desired. This has 
a number of advantages; clean copy is easier to edit, new errors are not introduced by retyping and the 
typography and layout can be altered at any time. Generally the machine representation of a document 
is easily constructed and modified by means of an online text editor. Such a source representation is 
itself easier to read and to edit than the traditional hand-written and/or hand-annotated draft. Systems 
that manipulate English text are now quite common. A few (notably the TROFF/EQN system [1]) are able 
to typeset mathematics. We describe here a flexible system, in use at Lawrence Livermore Laboratory for 
some time, that handles text and mathematics in a variety of fonts, in color or black and white, and 
that directly incorporates pictures into a document. Color slides and viewgraphs are easily obtained 
as well. It is an important feature of the system that the author can work with a draft of his document 
that contains all the symbols and diagrams so far incorporated; it is not necessary to leave holes for 
either. This is important for two reasons. Firstly, it is harder to read and edit a document which is 
incomplete. If an illustration is to contribute to a document, then its contribution must be evaluated 
during the editing process. This is difficult to do if the illustration is not present. Secondly, adding 
special symbols and illustrations to an otherwise finished document generally reduces the quality of 
the typography. t This work was performed under the auspices of the U.S. Department of Energy by Lawrence 
Livermore Laboratory under contract No. W-7405-Eng-48. Former employees, and now consultants, at Lawrence 
Livermore Laboratory. &#38;#169;1979 ACM O-8979%004--4/79/0800--071 $00.75 See Copyright Pg. 71 display. 
Approximately 30 color television monitors are also available on the Octopus network for previewing color 
output. Each requires three TIvIDS channels (one red, one green, and one blue) for operation. Channels 
-and their associated storage on the refresh disks -are allocated on demand. Any of 37 Versatec electrostatic 
plotters, located throughout the Laboratory, provide hardcopy output in minutes. There are also two Honeywell 
electrostatic Non-Impact Printing Systems (NIPS) on the Octopus network (200 points per inch), nIPS produces 
text at the rate of 18,000 lines per minute and is capable of putting out graphics. Output from this 
system is adequate for most uses and is available in a few hours. The Tektronix, the Versatecs, and the 
NIPS all produee black-and-white output incorporating both text and graphics. Color hardcopy is obtained 
from either a Xerox 6500 color copier connected to a color television monitor or from color film. We 
have three Information International FRg0 COM recorders (16,384 x 16,384 points), which can be used with 
16mm, 35mm, i05mm, or 10"x12" cameras. The latter allows us to directly print black on white offset reproduction 
masters (these are essentially photographic prints of high contrast and quality). One of the FR80"s is 
equipped for color. We also have a Dieomed D48 color COM recorder, which can be operated as either a 
4,096 x 4,096 raster display or as a 32,568 x 32,568 vector display. All four film recorders return very 
high quality output in some 12 to 24 hours. This environment impacted the development of the documentation 
system in several ways. The presence of substantial computational power makes it reasonable to trade 
efficiency for flexibility, which is made desirable by the variety of output devices available. The large 
number of terminals and TMDS monitors already in place, nearly all of which lack any kind of graphical 
input, severely restricts the manner in which pictures may be supplied to the documentation system. No 
equipment was purchased for use in the documentation system. It was necessary to design the software 
around existing equipment. '['I{IX -the Editor and Compositor The TRIX language is a hybrid of TRAC 
[10] and SNOBOL [11], on top of which is superimposed a conventional macroprocessor. It is designed for 
the purpose of manipulating strings. The TRIX processor is an interactive interpreter; that is, commands 
entered at the terminal are executed as they are received. TRIX programs in general, and the text editor 
AC [3] in particular, are written as a set of macros. For example, while editing a file one might type 
fp(1,],fv8Oib) p rp(cl,cl,fvSOib,fvSOl|b) rp(linel,line2,<a LCCS>,<an LCCS>) The first of these finds 
(fp), displays (p) and replaces (rp) the first occurrence of a pattern, while the second replaces every 
occurrence of a pattern in lines line1 through line2. In order to make common editing operations as painless 
as possible, there are a number of carefully constructed conventions for shortening and simplifying input, 
so that the above example would, in fact, probably have been entered by typing fp!fv8OibJp rp!fv8Oib!fv8Olib! 
rplinel,line2!a LCCS!an LCCS! Irrespective of whether or not they use the documentation system, programmers 
generally write their programs using TRIX/AC. The editor is normally used in conjunction with a TMDS 
monitor, which in text mode displays fifty 80-character lines. Most simple text editing can be performed 
with existing AC macros, which provide a far simpler and more user-oriented human interface than does 
TRIX itself. Indeed, many users are unaware that they are using macros, It is a particular virtue of 
TRIX, however, that the more knowledgeable user with unusual or special purpose requirements macros using 
existing commands. A simple following: can implement additional macros and primitive TRIX example of 
this is the ep(patl,pat2)=< rp(cl,cl,<patl>,<????>) u rp(cl,cl,<pat2>,<patl>) u rp(cl,cl,<????>,<paf2>) 
q >t Entering these lines from a terminal or disk file will define a macro ep, invoked by typing ep(arga,argb), 
which makes use of the pre-existing AC commands rp (replace pattern), u (update file) and q (redisplay 
the current page of text on TIV[DS) to exchange oeeurences of arga and argb in the current line of text 
(cl) and display the result (q). Essentially the same macro could be implemented in pure TRIX, rather 
less intelligibly, by entering ep(patl,pat2)=< cl;~<pafl>=<????>t #fur cl;~<paf2>=<pafl>t #fur cl;~<????>=<pof2>t 
#fu #ps(cl;)t >t New macros defined as above are used just as the old ones were, and in this way the 
user can construct for himself a more hospitable environment. After the text file describing a document 
has been created and edited by TRIX/AC, a second TRIX program called the RED dialect [43 performs page 
layout under the control of format commands such as the following (which are interspersed with the source 
text): #linespacing 2 #paragraph If this condTtion is satisfied then we may write #skip 1 #center Z = 
U V W X y #skip 1 where  Of course, these commands all have short abbreviations. RED provides the usual 
facilities for filling and right-justifying, indenting, centering, titling, footnoting, page numbering, 
columnating, etc. An index and a table of contents can be created automatically. As page layout can become 
quite complicated, a parameterized macro facility is provided within RED (which is distinct from the 
underlying TRIX macro facility). For example, the RED footnote command #footnote -endfoot- #linespacing 
1 #skip 1 #margin %lmar9+3 %rmorg #Tn -3 text of footnote #margin %lmorg-3 %rmorg #linespacing 2 #-endfoot- 
 formats the footnote contained between #footnote and #-endfoo#-and deposits it when the bottom of the 
page has been reached. One can abbreviate the process by defining the RED macro fnote as follows: def 
fnofe argl #c #footnote -endfoof- #1inespacing 1 #skip1 #margin %lmarg+3 %rmarg #in -3 argl #margin 
%Imarg-3 %rmarg #linespacing 2  #-endfoof- #c #endef and then writing #fnote -endf-  text of footnote 
#-endf- Quite elaborate libraries of such macros have been implemented by a number of users. This saves 
effort, enables novice users to take advantage of the labors of sophisticated users, and allows one to 
enforce stylistic uniformity when desired. Indeed the Technical Information Department at Livermore now 
supplies a standard set of macros which implement its conventions for internal LLL technical reports 
[9]. Finally, space can be reserved by RED during composition for the subsequent incorporation of figures 
by the postprocessor REDPP. PICTURE -a simple 2d Graphics Language PICTURE is a simple but useful illustration 
language. It has very little control structure and only two data types, namely number and string. There 
are four general types of commands. Firstly there are about 20 commands such as line from <Xl,Yl > to 
<x2,Y2>; line from <X3,Y3 > tO <X4,~44, > Iw=0.2 pieces = < dash(l), blank(l) >; arrow from <Xl,yl> to 
<lx2,Y2 > yellow; circle center=<x,y> radius=2 orc=<O,180>; which specify various elementary geometric 
forms, each with a number of attributes, most of these may be omitted, in which case a default value 
is used; the default values may themselves be set with a separate command. Secondly, there are four text 
commands such as fextc <x,y> "A bit of centered text."; textt <x,y> scaling=l.5 red "Left-anchored text.";, 
which allow text to be centered, left-anchored, right-anchored, or transformed into a filled and justified 
paragraph. Thirdly, one may assign the value of either arithmetic or string expressions to a variable 
so that the value may be used in one of the above commands. Finally, there are also a number of control 
statements such as push color red; font uncial; default circle radius=5; As implied above, the user positions 
pieces of his picture in a coordinate system that he specifies. Various intrinsic functions, such as 
sin, cos, floor, and sqrt are available for computing positions. Fig. 3 displays the source text of a 
PICTURE program, together with the figure it describes. An illustration is constructed by interactively 
(1) adding to or modifying its description in the PICTURE language, and (2) plotting the diagram on a 
TMDS with REDPP. In order to make the process as painless as possible, TRIX/AC macros are provided which 
remember from iteration to iteration all the parameters needed to translate and re-display the illustration; 
the user need only type compile and examine, respectively. When a satisfactory picture has been obtained, 
its description may be incorporated directly into the text of a document by means of the RED format command 
#window n p -endw- PICTURE statements describing a figure (n is the vertical size of the picture). #-endw- 
 It is often convenient for editing purposes to have the picture description embedded in the source description 
of the document, but it is not necessary; the picture may instead be stored in a library and a pointer 
to it placed in the document source. In either case TRIX/RED will leave space for the illustration during 
page layout and REDPP will then draw the illustration at the plot time. Two examples of this appear in 
Fig. 4. Alternatively, the picture may be sent directly to an output device such as the Dicomed D48 color 
recorder to obtain, for example, a color slide. Examples of pictures constructed for this purpose appear 
in Fig. 5. #window n f -3- library UXSO.file.in.library frame.in.file Wzmin Wxmax Wymin Wymaz Vxmin Vxmaz 
The picture contained in the specified UX80 frame is clipped to the window boundaries and mapped into 
the viewport, ordinarily with the same aspect ratio (which fixes the height of the viewport), although 
this can be overridden. The vertical position of the viewpor t is determined by RED. Thus the user can 
crop and scale the graphical output from any of his programs and include it in his document -in, for 
example, the document describing his program. Two examples of this appear in Fig. 4. The ability to incorporate 
the graphics generated by application programs into computer generated reports is quite popular, and 
in fact was implemented at the request of several users. There is also, of course, a PICTURE statement 
which allows a window in any UX80 frame to be mapped into a PICTURE generated figure, which may then 
be used to produce a 35mm slide, or may itself be incorporated into a document. UX80 files have quite 
a simple structure, and in principle any program, in any language, which generates such files may be 
used to produce pictures which can be incorporated in documents by the documentation system. In practice 
only FORTRAN generated pictures have so far been used.  The PICTURE language is defined by an LALR(1) 
grammar [13], and the program PCOMP which translates PICTURE statements into REDPP directives is based 
on an LALR(1) parser. This made it very easy to write and maintain the translator. FORTRAN Generated 
Pictures One of the output "devices" available to a program using the graphics library TV80LIB at Livermore 
is a UX80 graphics file. Small, highly interactive utility programs are available for displaying and 
editing the pictures stored in these files. Data may be translated, scaled, cropped and rotated interaetively 
on a TMDS, and one or more frames may be merged to form a new picture which is stored back into the UX80 
file. (This interaction is done under keyboard control, owing to the lack of graphical input devices.) 
An arbitrary rectangular window in any frame of such a UX80 file can then be mapped into a viewport established 
by RED during page layout and incorporated into the document by writing REDPP -a posLproeessor for TRIX/RED 
REDPP [8], a postproeessor for TRIX/RED and PICTURE, merges textual and graphics data into a single output 
stream to produce the final document. This output consists entirely of vector graphics, possibly intermixed 
with text data, even though some of its output devices are raster or have raster capability. By the 
time REDPP processes a file, RED has already performed page layout, leaving space for figures, and PCOMP 
has already translated PICTURE statements into simple, low-level, easily analyzed graphics primitives. 
Under the control of typographic and control directives embedded in the text REDPP then generates calls 
to the device-independent routines in TVSOLIB. Various execution time options are supplied to REDPP to 
cause the device-dependent output processors in TV80LIB to be turned on so as to generate the desired 
output. For the most part REDPP is completely unaware of the output device selected, although in a few 
cases it is necessary to perform device-dependent actions in order to take advantage of specific device 
properties of particular importance or value. REDPP does, for example, know something about the particular 
characteristics of the hardware characters available on various devices. Typographic directives are 
flagged in the input stream by the escape character &#38;. The general scheme is to request a feature 
by typing ax+, and deactivate it with &#38;x-, where x is a single character feature desired. Some available 
are selecting of the the feat particular ures thus underlinin  double underlinin wavy underlining 
S n, S 2, sn2 A variety of fonts are available Roman sans serif A bolder Roman sans serif Roman serif 
A bolder Roman serif  Italic A bolder Italic Nl~rkLelter ~f ~lig~)th) biFFerent ~Iac~Ietter ABFAE 0</376s 
(Greek) ABFAE afi78a (A bolder Greek) ~'~ ~'T~ (Hebrew) gilt,t) c~ul~y uWCI~L Filled Roman sans serif 
l~'llled l:toma,~ serif Additional mechanisms are available for obtaining other special symbols, for 
combining two or more symbols together, for scaling and rotating existing symbols, and for drawing new 
symbols. These mechanisms are fairly difficult to use, and a macro mechanism therefore exists by which 
one writes #pass macro .name symbol ,definition to define a new symbol and henceforth uses the macro 
name wwhenever the new symbol is desired. M Fig. 2. A typical vector character is shown above left. The 
outline of a polygonally defined character appears above middle. At plot time polygonal characters are 
solidly filled, as shown above right. Filled charac- ters are more suitable than vector symbols for preparing 
slides and viewgraphs. All but the Hebrew, uncial and filled Roman fonts are part of the character set 
designed by Allan Hershey [14,15]. These symbols are constructed out of a modest number of vectors, thedetails 
of which are not visible as long as the symbol is not drawn too large (see Fig. 2). Heavier lines are 
obtained by drawing two or more vectors very close together. The filled Roman serif and filled Roman 
sans serif fonts are redigitized, polygonally defined versions of run-length encoded fonts originally 
obtained from the Dicomed Corporation. The Hebrew and uncial fonts, also polygonally defined, were designed 
at Lawrence Livermore Laboratory by one of the system's users [18]. Only the polygonal outline of a 
character in these fonts is stored in REDPP. The body of the character is filled in when it is plotted. 
 One of the advantages of generating output which is ultimately destined for a high resolution vector 
device such as the FR80"s or the Dicomed is that straightforward floating point operations may be used 
to scale, rotate and deform the symbols in REDPP's character sets without any visible deterioration 
in quality. It also makes implementation of such features as wavy underlining quite trivial. Any of 
seven colors (red, green, yellow, blue, magenta, eyan, and white) can be selected in RED source text 
or a PICTURE description. The color directives are interpreted appropriately by REDPP and have effect 
only if the output device chosen has color capability. EQUATIONS Two mechanisms exist by which equations 
may be defined. They may be defined as pictures, and constructed as discussed above, or they may be defined 
in RED. RED equations are built up recursively by means of the RED #qt command. The innermost pieces 
of the equation are defined first, and then combined. For example, we can define the numerator of a fraction 
by typing #qf r fop %]=n 7o8cm2 sum\%%% %i=1 Here fop is a name for the piece of the equation which 
is being constructed, r indicates that the lines are to be formatted flush right, sum is the name of 
a macro which causes a summation sign to be plotted, and % is a user defined space character. The denominator 
is similarly defined by typing #qf c bof (~+b) \-\  (o-b) The c here indicates that the lines are to 
be centered and the \-\ indicates that a horizontal line is to be drawn between the numerator and the 
denominator of this fraction. Finally we assemble these pieces together to obtain the finished equation 
by writing. #qt c eq \ f op2k(n+l )* (n-1) \-\ \bof\ #qf f res sum = \4eq\ Here the 2 in fop2 indicates 
which line of the piece named fop is to appear on the same line as (n+l)*(n-1). The result is ~ i --n 
i:l(n+l )*(n-l) sum =  (a+b ) (a-b) t.]XAMPLNS This paper was, of course, prepared using Livermore's 
documentation system. It was printed on the FR80 using the 10"x12" camera to obtain black and white masters. 
To obtain color the same REDPP output file was replotted on the Dicomed D48 film recorder using a 4"x5" 
camera to obtain a color transparency, which was then printed and glued to the submission forms along 
with the FR80 output. The text of the paper is thus in black and white, rather than in color, because 
the color process still lacks the resolution desirable for text at the size used here, We emphasize, 
however, that there is a single output file, which may be viewed on a TMDS or printed on a film recorder 
either in black and white or in color. Had we chosen not to incorporate color then a single print run 
on the FR80 would have been sufficient to produce the completed document. With respect to the individual 
illustrations included here, Fig. 1 was designed with PICTURE, compiled separately with PCOMP, and a 
pointer to the compiled file placed in the RED source file. Fig. 2 was also designed with PICTURE for 
consistency, though the oversize characters could have been specified directly in the RED source file, 
and the description of the picture was placed in the document source. The caption of Fig. 3 is a small 
picture placed in the RED source file which contains a pointer to the compiled version of the PICTURE 
source file listed in the figure. Pigs. 4 and 5 were both constructed by placing small PICTURE programs 
in the source, which defined the captions and contained pointers to UX80 files in which the document 
pages of Fig. 4 and the slides of Fig. 5 had been placed by a previous execution of REDPP. The scalings 
and (for Fig. 5) rotation were performed by REDPP. SUMMARY The computer tools described in the above 
sections have been used for some time to produce slides and documents at Lawrence Livermore Laboratory. 
Many people make use of RED daily to format documents consisting entirely of text; an average of thirty 
people each week currently make use of REDPP to obtain better typography and/or pictures. The Technical 
Information Department at LLL now routinely makes use of the system in preparing internal LLL computer 
documentation. To design a slide or a diagram, the user describes his figure using the PICTURE language, 
possibly incorporating the graphics output from any of his programs. The TRIX editor is used to modify 
this picture source, which is periodically viewed on a TMDS, until the figure is satisfactory. The picture 
compiler (PCOMP) is then used to produce an intermediate picture file, which REDPP can send to any of 
the output devices. This process is labeled Path A in Fig. 1. To write a document, the user enters text 
and formating instructions into a file using the TRIX editor. His pictures are designed as in Path A 
and and either the PICTURE source itself or a pointer to a compiled version of the picture is incorporated 
into the document's source. TRIX/RED formats the report, producing an intermediate text file in which 
space has been left for figures, and which may contain PICTURE programs, pointers to compiled PICTURE 
programs, or pointers to UX80 graphics files. REDPP invokes PCOMP if there are picture descriptions present, 
as these must be compiled, and then generates a plot file for the selected output device. Path B of Fig. 
1 describes this chain of events. Using Livermore's system, an author designs his document with immediate 
feedback. Text is always accompanied by associated diagrams and pictures. New symbols may be designed 
and added easily. The output is of uniform quality, and an author need not worry about reproducing computer 
printout for insertion into a report. He also need not worry about the communication filter between him 
and an illustrator in the production of his pictures. The spatial relation between text and picture is 
easily specified and modified. Every aspect of document production is handled by the computer, thereby 
allowing quick and easy modification. We emphasize that this does not eliminate the need for technical 
editors and illustrators, or reduce the value of their contribution. What this system does do is make 
it easier for an author and an editor or illustrator to work together. The current system is not, of 
course, perfect. Aesthetically the major deficiency is that although the character fonts we use are variable 
width, text set by RED is monospaced. This difficulty arises for historical reasons; RED was designed 
and written with line printer output in mind, before the availabilty of the fr80"s and the Dicomed. Text 
set by PICTURE and REDPP is, however, proportionally spaced and it is not difficult to do automatic page 
layout in PICTURE, though only a very few of the features available in RED are directly available in 
PICTURE. The submission of Ref. [16], a page of which appears upper left in Fig. 4, was prepared in this 
way. Development efforts are now focused on two aspects of the system. Firstly, a better mechanism is 
needed for handling equations. The RED #qt command is somewhat awkward to use, and as explained above 
is restricted to unit spacing. PICTURE, on the other hand, requires that the user explicitly position 
all the pieces of a figure. For an arbitrary figure this is necessary, but for an equation more information 
is available. One knows, for example, that a numerator is "over" a denominator, and a reasonable system 
ought to position these two pieces automatically. An EQN style mechanism is contemplated. Secondly, a 
more powerful picture description language would be useful. The present language, though simple and straightforward 
to use, sometimes requires distressingly long descriptions for pictures. The availability of an iteration 
statement or procedures would noticeably improve the sample PICTURE program in Fig. 3. We regard the 
interactive nature of our system, and the direct integration of graphics and color, as invaluable in 
the composition of good documentation and a major feature of our system. A primary goal of our efforts 
was to produce a system which was flexible, powerful, and capable of high quality output. We feel that 
we have substantially achieved these goals. Furthermore, the novice user is easily able to produce simple 
documents and pictures. Making use of the flexibility of our system sometimes leads to complexity however, 
but provision of the macro processing capability allows us to hide this complexity inside macro packages 
which we distribute for general use. ACKNOWLEDGEMENTS Many people have contributed over the years to 
the development of this system: we would like to extend our thanks to Mike Archuleta, Mark Blair, Kelly 
Booth, Bob Kuhn, George Michael, Jeff Rowe, Nancy Storch, and to the many users who have taken the time 
to pass along their suggestions. The assistance of Kelly Booth and Don Vickers in preparing this paper 
is also very much appreciated. REFERENCES 1. B. W. Kernighan and L. L. Cherry, "A System for Typesetting 
Mathematics," Comm. ACM 18, 151-156, (1975). 2. H. Moll, TRIX -An Interactive, Interpretive Language 
for Manipulating Strings of Characters, Lawrence Livermore Laboratory, Livermore, CA, UCID-30100 (1974). 
 3. A. Cecil, TRIX AC: A Set of General-P~rpose Text Editing Commands,  Lawrence Livermore Laboratory, 
Livermore, CA, UCID-30040 (1974). 4. H. Moll, The TRIX Report Editor, Lawrence Livermore Laboratory, 
Livermore, CA, UCID-30142 (1978). 5. J. C. Beatty, PICTURE -A Picture-Drcauing Language for the TRIX/RED 
Report Editor, Lawrence Livermore Laboratory, Livermore, CA, UCID-30156 (1977). 6. M. Blair, The UXDD80 
Graphics System, Lawrence Livermore Laboratory, Livermore, CA, ~CID-30146 (1977). 7. N. Storch,TVSO: 
Device-Independent Graphics Routines for ~he CDC 7600 Computer, Lawrence Livermore Laboratory, Livermore, 
CA, LTSS 305 (1978}. 8. J. C. Beatty, REDPP -A Postprocessor for the TRIX/RED Editor, Lawrence Livermore 
Laboratory, Livermore, CA, UCID-30125 (1977). 14. 9. C. Schneider, D. Thompson, and G. Whitten, User's 
Guide to the Octopus Computer 15. System (The SHOC Manual), Lawrence Livermore Laboratory, Livermore, 
CA, UCID-30048 (1975).  I0. C. N. Mooers, "TRAC, a Procedure Describing Language for the Reactive 16. 
Typewriter," Cowan. ACM 9, 215-219 (1966). Ii. R. E. Griswold, J. F. Poage, and I. P. Polonsky, The 
SNOBOL4 Language, 2nd ed., Prentice-Hall, Englewood Cliffs, NJ (1971). 17. 12. D. E. Nielsen, Jr., Three 
Dimensional Electromagnetic Partical Simulation of Fusion Plasmas, Ph.D. Thesis, Stanford University, 
Stanford, CA (to be 18. published). 13. A. V. Aho and J. D. Ullman, Principles of  Compiler Design, 
Addison-Wesley Publishing Company, Reading, MA, pp. 219-224 (1977). A. V. Hershey, Computer Graphics 
and Image Processing, 10 373-385 (1972). N. M. Wolcott and J. Hilsenrath, Tables of Coordinates for Hershey's 
Repertory of Occidental Type Fonts and Graphics Symbols, NBS Special Publication 424, U. S. Government 
Printing Office (1976). J. C. Beatty, "Two Iteration Theorems for the LL(k) Languages", Dept. of Computer 
Science, University of Waterloo, Technical Report CS-78-24. To appear in Theoretical Computer Science. 
K. S. Booth and G. S. Leuker, "Testing for the Consecutive Ones Property, Interval Graphs, and Graph 
Planarity using PQ Tree Algorithms," JCSS 13 (1976) 335-379. R. W. Kuhn, Development and Implementation 
of New Character Fonts at LLL, Lawrence Livermore Laboratory, Livermore, CA, UCID-17653 (1977).   
 ": k...~~i...i ,r~,, T: t~ left-t~t~t ~ mgt ~ .~tly t~t ~ tn Vl~e Is. ~t f~ e and In vl~ of the ImmOrphimm 
3( ~d ~-must be RCC3"I of [~I~T" ~-belv4I obtained in one ~tep f~m X" by rewzqtll~l f(u4), NOW extend 
X" to foe ~ RCC~ ~ in T" by appendJn| to X" (In left-to-right order) all of the [ a~ of 5" which m rlEht 
of t(Ur) (thrum Z*I6). ~ that x(f). saw.. ~lmilarly extend ~, to obtain ~ RCC~ ~. in 5,-- ~eh that M~)" 
a~', sm~ th~ ~ no Internednod~ to the r~ht of u~ In n, thee ~ be no Intenud nod, to the r~ht c~ u In 
x. ~d no tn~maJ mod~ to the rlBht of f(u~) In X'. Sln~ t Is obtained from ~ by Geometry for Mirror Injection 
 feted In a mlni~ a field configuration, has been developed bee*tie of th* desire to ILl,late the buildup 
of dtl~lnetLo currents In the pLa~. These currents ~uld I ad to self fields that. w~en added to ths external 
oonfinllt I mirror field. ~uld cause a net rover.at In the dirsetion of the mqgnetie field in the center 
of the mirror. k typical lea orbit ~uld then have a rtdlus thtL is eomparltble in lie to the pln~ it 
elf, field lines at the plasm~uid than be eh~ged fr~ ~ open to a elo|ed oonftgnrttion, lsadln I to dr~tleslly 
enh~eed plal~ eonfinsmnt. The resulting pla*~ beta (ratio of plalm preHure to nmlgnstic preHnre) ~uld 
also be Ln&#38;#169;reaxed, leadin| to higher Q ratloL Q Is defined as the ratio of require on the order 
of 200 timltep| for the potential to 1427 Ambipolar Potential Buildup in Time ,,,, ~ !11111 i boco~ e|Labllshed, 
~: Figure 34, Beeauue the inns In r~ i~? weigh o, ly tit ties as ~ch a the slsctron , they feel tile 
effects of the potential trytn&#38; to ~ve them LO the endplat , ~eh ~re stronlly th~ do the tone In 
a real expert~nt. The sI~latton Ions try to nsntrall e the potential tom,chat, resuitin| In th oJelllatory 
behavior in Figure ~4. If Instesd of sl~iatth| thl* buildup durst41 efery r~. the SgTUP code ~r to initially 
pl*ee *eertsLn number of electron| on the sndplate| frm the very beli~l1141 of the simtsLlen, it should 
b ponlble to bypass the startup required to establl|h the I~blpolar potential. 'i~nl wee in fur done. 
The quiitbrl~ value for the elsstro=tatle enerly along z i eltr&#38;pslated bselD~rd. In tl~ to the point 
where the leetrolt*Lle ener|y flr|t  Fig. 4. The figures top left [16] and top right [17] demonstrate 
the inclusion of PICTURE illustrations in documents. The bottom two figures [12] demonstrate the incorporation 
of application program generated graphics into a document. In the latter case the application graphics 
is often folded into a simple PICTURE diagram, which adds labeling, and the combination is then inte-grated 
with the document. 81  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807428</article_id>
		<sort_key>83</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Raster graphics for interactive programming environments]]></title>
		<page_from>83</page_from>
		<page_to>93</page_to>
		<doi_number>10.1145/800249.807428</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807428</url>
		<abstract>
			<par><![CDATA[<p>Raster-scan display terminals can significantly improve the quality of interaction with conventional computer systems. The design of a graphics package to provide a &#8220;window&#8221; into the extensive programming environment of interlisp is presented. Two aspects of the package are described: first, the functional view of display output and interactive input facilities as seen by the programmer, and second, the methods used to link the display terminal to the main computer via a packet-switched computer network. Recommendations are presented for designing operating systems and programming languages so as to simplify attaching display terminals.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Computer networks]]></kw>
			<kw><![CDATA[Frame buffer]]></kw>
			<kw><![CDATA[Network graphics]]></kw>
			<kw><![CDATA[Raster-scan display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>D.2.6</cat_node>
				<descriptor>Interactive environments</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.2.1</cat_node>
				<descriptor>Packet-switching networks</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003033.10003106.10011705</concept_id>
				<concept_desc>CCS->Networks->Network types->Packet-switching networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P246551</person_id>
				<author_profile_id><![CDATA[81100302488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Sproull]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie-Mellon University, Pittsburgh, Pa.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1096934</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. M. Birtwistle et al. Simula Begin. Petrocelli-Charter, 1973.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[V. G. Cerf and R. E. Kahn. A protocol for packet network interconnection. IEEE Trans. Commun. COM-22:637, May 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>803338</ref_obj_id>
				<ref_obj_pid>800103</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Davidson, W. Hathaway, J. Postel, N. Mimno, R. Thomas, and D. Walden. The ARPANet Telnet Protocol: Its Purpose, Principles, Implementation and Impact on Host Operating System Design. In Proc. 5th Data Communications Symposium, pages 4.10-4.18. Snowbird, Ut., Sept, 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Goldberg and A. C. Kay. Smalltalk-72 Instruction Manual. Technical Report SSL 76-6, Xerox Palo Alto Research Center, 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360253</ref_obj_id>
				<ref_obj_pid>360248</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. M. Metcalfe and D. R. Boggs. ETHERNET: Distributed Packet Switching for Local Computer Networks. CACM 19(7):395-404, July 1976.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W. M. Newman and R. F. Sproull. An Approach to Graphics System Design. Proc. IEEE 62(4):471-483, April 1974.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. M. Newman and R. F. Sproull. Principles of Interactive Computer Graphics. McGraw-Hill, 1979. Second edition.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>988030</ref_obj_id>
				<ref_obj_pid>988026</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. F. Sproull and E. L. Thomas. A Network Graphics Protocol. Computer Graphics 8(3):27-51, Fall 1974.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. F. Sproull. Interlisp Display Primitives. Technical Report, Xerox Palo Alto Research Center, 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. F. Sproull and W. M. Newman. The Design of Gray-Scale Graphics Software. In Proc. Conf. on Computer Graphics, Pattern Recognition and Data Structure, pages 18-20. 1975.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. F. Sproull and D. Cohen. High-Level Protocols. Proc. IEEE 66(11): 1371-1386, November 1978.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[W. Teitelman. INTERLISP Reference Manual. Technical Report, Xerox Palo Alto Research Center, 1978.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[W. Teitelman. A Display-Oriented Programmer's Assistant. Technical Report CSL 77-3, Xerox Palo Alto Research Center, 1977.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[W. Teitelman. A Display-Oriented Programmer's Assistant. In Proc. 5th Int. Joint Conf. Artifical Intelligence, pages 905-915. 1977.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Raster Graphics for Interactive Programming Environments Robert F. Sproull Carnegie-Mellon Univ~rsity, 
Pittsburgh, Pa. Abstract Raster-scan display terminals can significantly improve the quality of interaction 
with conventional computer systems. The design of a graphics package to provide a "window" Into the extensive 
programming environment of Interltsp Is presented. Two aspects of the package are described: first, the 
functional view of display output and interactive input facilities as seen by the programmer, and second, 
the methods used to link the display terminal to the main computer via a packet-switched computer network. 
Recommendations are presented for designing operating systems and programming languages so as to simplify 
attacnlng display terminals. KeyWords: computer graphics, raster-scan display, frame buffer, computer 
networks, network graphics CR categories: 8.2, 6.35, 4.35 The remaining two sections of the paper describe 
the design of ADIS, the graphics package that supports DLISP. The first shows how good Interactive response 
can be provided In a modest raster-scan system. The pitfall that must be avoided Is exhaustive scan-conVersion 
of the picture whenever a portion is altered. The key idea used to address this problem Is to provide 
mechanisms for copying and manipulating enttre regions of a frame buffer at high speed. The last section 
shows how a graphics terminal can be connected to an application program through a packet-switched network 
without compromising the response of the system. The design builds on issues raised In the ARPA network 
graphics protocol [8], and solves the problem of synchronizing "teletype" and "graphics" information. 
The design shows that shortcomings of Input-output handling by programming language systems and by operating 
systems present thorny obstacles to a clean design. The success of the network connection Is demonstrated 
by routine use of the final system.  1. Introduction Computer graphics has yet to have much Impact 
on Interactive computing as a whole. Several arguments suggest that the frame-buffer raster-scan display 
may substantially enrich the average interactive programming environment. First, a frame-buffer display 
offers virtually limitless opportunities In the range of graphical imagery that can be presented. Seco,ld, 
controlling such a display, even with low-level operations, is straightforward and intuitive for programmers 
and designers of interactive systems. Finally, the displays will be Increasingly economical as prices 
of memory end computing drop. This paper describes a system that extends the Interactive facilities of 
Interlisp[12] to make effective use of a display for communicating with ';:he Lisp programmer. The user's 
view of DLISP, the display-oriented programmer's assistant, is summarized in the first section of this 
paper, and described in detail in [13] or [14]. This work was supported by the Xerox Corporation. 2. 
The DLISP Application DLISP enriches the already copious Interactive programming facilities of Interltsp 
by making effective use of raster-scan displays. The programming environment, developed by Warren Teitelman 
and others, is designed to reduce the tedious mechanical aspects of program development by making generous 
use of interactive exchanges with the programmer and by exploiting information in the programming context. 
Examples of these facilities are: Interactive access to the programmer's manual; a structure-oriented 
editor for modifying LISP function definitions and data; a file package to keep track of function definitions 
In text files, reading In functions as needed, and writing out functions that have been modified; a translator 
that con~erts into LISP any function definitions written In CLISP, a legible Algol-like form; a facility 
for inserting "break points" In functions and for examining and modifying program state when in a break 
or when an error occurs; and the DWIM package that attempts to fix errors by uslng &#38;#169; 1979 ACM 
0-89791-004--4/79/0800--083 $00.75 See Copyright Pg. 83 context to "Do What I Mean." For example, DWIM 
will try to correct misspelled words in a function definition. These facilities were originally designed 
for use on a teletype or character-oriented terminal connected to the Tenex time-sharing system. Consequently, 
they make use of typed input only, and strive to limit the volume of typeout because of the slow speed 
of terminals. The DLISP extension of these facilities is intended not only to use a fast display output 
device, but also to take advantage of other opportunities offered by the display. The spirit of DLISP 
is illustrated in Figure 1: the display shows many "windows," each of which presents Information about 
a programming context. One J (~E~FCH~NG FILE3, L~K~D~ (FL) nil ,3.o. R~adm~l ~dm g 3 i il~.~ ,.1:,-=~ 
,:: i, r, .. ,xl L~ ......... ?!J .... [ ~!oo ] (INFOrUA[L ~E~r " '~,(r t ........................ 
,~.u,i Ft0 rr,c,~, .= ~ e "~.c,E~ ",, rl F ...... r~.;o ........ ^ mrH.z .] FL], Figure 1. Typical DLISP 
displays. The second Image is created from the first by slight rearrangement of some windows, and by 
adding new text to the Work Area window. window contains a function definition being edited, one a selected 
portion of the user's manual, one a message received from a colleague, one a typescript of the user's 
activities, and several contain menus. The user may alter the size and location of windows, and may bring 
partially-obscured windows "o11 top" for a clear view. Commands to DLISP are entered with a keyboard 
and a "mouse" coordinate Input device. The primary objective of the ADIS graphics package is to provide 
a high-performance service to Interlisp programmers. As a consequence, highest priority is placed on 
providing pleasant Interaction and avoiding errors of all sorts. Although the system offers some general-purpose 
graphics facilities, its objectives are focused on the needs of DLISP, which are outlined below. Speed 
and capacity. The context surrounding a working programmer is enormous. DLISP aims to display sizable 
chunks of this context as carefully-formatted text in windows (see Figure 1). Remaining portions of the 
display are devoted to menus, cues pointing to more context, and the like. When the user asks that a 
window be moved, or that an obscured window be placed on top of those hiding It, a considerable portion 
of the display will need to be altered rapidly. For further reference, we shall refer to this as the 
"window update" operation. Control of typein. Part of the "window" idiom requires that typein activity 
appear to take place in arbitrary windows. Because Interlisp terminal facilities are full-duplex, this 
is quite simple: the program will wait for a key to be struck, and will then display an "echo character" 
in the proper window. But typists often make mistakes, and will Want to backspace over characters, words 
or entire lines. As this happens, we want the display to show the current input characters, without extraneous 
editing characters so often seen on teletype paper. Control of typeout. Characters typed with operating-system 
assistance by Interlisp and other programs must be directed to an appropriate window. This requirement 
arises because Interlisp allows a user to initiate "inferior executives" that Invoke arbitrary Tenex 
programs and yet to return to the retained Interllsp context. The display context must likewise be untouched. 
Graphical detail. The flexibility of the raster-scan frame-buffer display should be exploited to use 
graphical details to provide cues to the programmer. Examples are: Italic text, boldface text, different 
character font styles, special Iconic symbols that have mnemonic value, attention-directing forms such 
as white text on black background, different texture patterns, etc. Graphical Input. The user Is provided 
with a "mouse," a coordinate Input device with three pushbuttons. The mouse rolls along a table top and 
Is tracked by a cursor that moves on the screen. The mouse can thus be used to point to objects 84 already 
displayed on the screen, or simply to Identify a coordinate position. The three keys are remarkably versatile, 
provided the software for handling them Is sufficient: for example, combinations of keys can be struck 
as "chords"; a single key action can be distinguished from two key depressions In rapid succession ("double 
clicking"). 3. ADIS --The Graphics Package The ADIS graphics package provides a collection of Interllsp 
functions for controlling graphical output and Input. Consistent with modern graphics system design, 
the facilities for output and those for Input are Independent [6]. This section provides an overview 
of the package; more detail Is presented In [9]. ,3.1. Graphical Output The display Image is represented 
In a frame buffer memory that records, for each plxel on a 606 x 808 display, whether the point should 
be white (0) or black (1). The output functions simply alter values In the memory in order to alter the 
image. The frame buffer could be edited with only two very simple functions, one to read the value of 
the pixel at a particular (x,y) location, and one to write the value. Such an approach would be Intolerably 
slow, and the programmer would Immediately begin to identify common editing operations, and thereby create 
a larger set of functions that perform more specialized editing operations more efficiently. Thus ADIS 
provides functions for drawing lines, for adding text characters to the display, and for moving existing 
portions of the display, all coded to update the frame buffer as rapidly as possible. These are common 
operations In the DLISP application, which depends on the careful presentation of formatted text. Other 
applications might stress other graphical objects. Each output operation Is directed at a particular 
reg/on of the screen. A region Is Identified primarily by a rectangular boundary defined by left, right, 
bottom and top edges. All output requests are clipped so that modifications are made only within the 
region; in this respect, a region Is very similar to a vlewport. For example, region limits may be set 
to the boundaries of a DLISP window, thus ensuring that text will not appear outside the window either 
because too many lines are displayed or because too many characters are placed on a given line. In fact, 
DLISP uses regions to operate within windows as well: to construct the label banner, to provide "scroll 
bars", at a window's left edge, etc. A region Is not just a rectangular boundary, but also contains substantial 
information about how graphical objects are to be displayed within the window. A region is thus like 
an abstract object in an object-oriented programming language (e.g., Simula [1] or Smalltalk [4]) --It 
contains data and routines for producing output on the display. In the description of output functions 
given below, Information marked with an asterisk (*) Is data associated with an Instance of a region. 
This data can be examined and modified by ADIS functions. Each output function Is designed to make specific 
changes to the frame buffer, which Is the ultimate representation of the image. Unlike graphics packages 
for calligraphic displays, these functions build no Intermediate "display file," and retain no data structure 
that contatns Information about characters or lines. ADIS provides only two structures: the frame buffer, 
which describes the Image, and the re qlon objects, which retain information that helps the output functions 
edit the frame buffer contents (e.g., font descriptions). Another concept used frequently in output operations 
is the combination function, which describes how previously-displaYed information is to be treated. A 
typical change to the frame buffer will compute the function F(oldValue, newValue), where oldValue is 
the binary value of the plxel currently stored In the frame buffer, and newValue Is the binary value 
computed by the output function. The value of the function F (either 0 or 1) is stored Into the frame 
buffer. Only a few of the 16 possible binary fundtions are used heavily in graphics applications. The 
functions provided are. "Copy" new to old: F 1(old,new) = new "Paint" by adding black points: F2(old,new) 
= old OR new "Erase" by complement of paint: F3(old,nc:w) = old AND NOT new "Invert" old Image wherever 
new is present: F4(old,new) = old XOR new F5(old,ne'w) =' old F6(old,new) = NOT old FT(old,new) = old 
AND new F8(old,new) = new A function to "draw a line," for example, will compute the coordinates of 
each point that lies on the line. For each of these points, It will store Into the frame buffer the value 
F(oldValue,1). Different choices of the combination function will produce different effects on the screen: 
F 1 or F 2 will cause the line to appear black; F 3 will cause it to appear white, and could be used 
to erase a black line; by changing the value of each pixel along the line, F 4 will cause a line to appear, 
regardless of what Information has been previously recorded In the frame buffer. The output functions 
are summarized in the following paragraphs: Line. This function generates the portion of a line that 
falls within the region limits. The endpoints of the line are specified by a "current position" 8.5 recorded 
In the region, and a "final position," provided as an argument. After the line Is drawn, the current 
position is changed to become the final position. Arguments: final position (x,y); width of the Une; 
* current position (x,y); * combination function; * region limits (left,right,bottom,top). RasterOp. 
This function copies the image In a rectangular area of the screen to another place on the screen, applying 
one of several modifications to the image as It is copied. The two rectangular areas are called the "source 
rectangle" and the "destination rectangle." The function may reduce the dimensions of the destination 
rectangle to fit within the region limits. The RasterOp function computes a new value for each plxel 
In the destination rectangle using the expression destination := Fd(destlnation,Fs(sOurce,pattern)), 
where the destination combination function F d ranges over F 1 to F 4 and the source function F s over 
F 5 to F 8. The "pattern" is a plxel value computed by repeating a 4x4 plxel pattern over the entire 
screen. It Is very useful for filling rectangles with constant patterns, such as black, white, or a gray 
half-tone. Arguments: destination rectangle (left,right,bottom,top); source rectangle (left,right,bottom,top); 
4x4 pattern (16 bits); combination functions Fd, Fs; * region limits (left,right,bottom,top). RasterOp 
is a very versatile function. It allows the programmer to take advantage of Imagery already displayed, 
copying It to new places, altering its appearance, etc. Choosing Fd=F 1 and Fs=F 5, the function will 
copy areas without alteration. A "scrolling" operation uses the copy function to move a window% contents 
upward slightly; the versatility of the RasterOp function makes scrolling down, left, or right equally 
easy. The function can also be used to "invert" part of the screen, changing Images from "black on white" 
to "white on black" (Fd=F 4, Fs=F~,, pattern all l's, source and destination rectangles identical). Inversion 
of this sort Is useful for prnviding feedback to the user (Figure 1 shows the word RSTRING highlighted 
in this way). The reader Is Invited to ponder other combinations as well. More Information on the use 
of RasterOp can be found In [7]. Text. The text output function is by far the most complicated, as It 
must efficiently achieve a variety of effects to support windows. Each character of the output string 
Is looked up In a font, which records a small rectangular bit pattern for each character. This pattern 
Is used to modify the display in much the same way RasterOp does; the combination function governs the 
display of the character. Clipping to the region limits may discard entire characters or portions of 
characters. After each character is displayed, the "current position" Is changed, due either to the width 
of the character just displayed or to its formatting effect (e.g., carriage returns, tabs, line feed). 
A scrolling feature can be enabled to "open up" space between lines or space within a line when text 
is to be inserted. The scrolling Is achieved with RasterOp, as described above. Arguments for text output 
are: text string; * current position (x,y); * region limits (left,right,bottom,top); * combination function; 
* style: font, bold, Italic; * formatting: left margin for carriage return, line spacing for line feed, 
tab spacing, scroll flag for vertical or horizontal scrolling, pattern to clear .~crolled area. Pixels. 
This call specifies values of pixels to store in a rectangular area of the screen. This function is not 
used heavily; it is used occasionally to produce complex patterns that the other functions cannot. Arguments: 
destination rectangle (left,right,bottom,top); array of plxel values; * region limits (left,right,bottom,top). 
Caret. The "current position" In a region may be illuminated with a blinking caret. The facility is normally 
used to Indicate where typed characters will next be displayed. The caret is disabled by setting the 
blinking rate to zero. Arguments: 16x16 pattern to use for the caret; blinking rate; * current position 
(x,y) which will vary; * region limits (left,right,bottom,top). Region data. ADIS includes functions 
for reading and writing all state variables associated with regions. These variables are flagged with 
asterisks (*) In the descriptions above. The region objects of ADIS are thus state-transparent: all state 
can be read and written. DLISP uses this capability frequently. Suppose-that a function is using a region 
to place text and graphics on the display, but that Its computation Is interrupted by a "break point." 
Such a break might occur because the user types a special Interrupt character, or because an error Is 
detected. The BREAK package is Invoked, which Interacts with the user to repair the damage. This package 
uses the display, however, and might disturb the display-generation of the interrupted  Ill I  R1 
~) J RI' R3 R2 j ........ Figure 2. A partially hidden window is moved. 86 function. To prevent this 
disturbance, BREAK saves and restores the state of any regions it uses. Each output function makes changes 
directly in the frame buffer. The "image editing" nat,,re of these functions forces onto the application 
program the burden of managing screen updates. Figure 2 shows an example of a window being moved in DLISP. 
The motion Is achieved in four steps: first R1 Is copied to RI' with the RasterOp function; then R2 Is 
similarly copied to R2'; then the region limits are set to R3, and R3 Is cleared to white using the RasterOp 
function; then whatever graphical material thought to lie within R3 Is re-displayed (i.e., calls to the 
Line, Text, and Plxel functions are performed to alter the frame buffer within R3). The fact that all 
graphical output Is clipped to the region limits greatly aids the last operation. There are other solutions 
to the update problem. By adding considerable hardware to the frame buffer, dynamic "2 1/2 D" effects 
can be provided by the hardware. This technique requires several translatable Image planes and a "color 
map" to resolve priorities. On a simple frame buffer with a single bit per plxel, the update sequence 
can be managed by software (e.g., see PICO [10]), but to do so requires maintaining a large data structure 
describing all potentially-visible graphical objects. In general, updating the screen requires an expensive 
computation much like hidden-st=rface elimination. The sequence described above for moving a window Is 
much faster, but It works well only for a limited number of cases (e.g., rectangular regions of the screen). 
Thus, although responsibility for screen management Is borne by the application program, the technique 
offer.~ advantageous flexibility as well as a burden. Experience with ADI$ suggests that It is reasonable 
to require the application program to assume substantial responsibility for screen updates, as It has 
sufficient contextual information to plan an update sequence using simple frame-buffer editing functions 
that are very fast. Expensive, although general, update schemes such as hidden-siJrface elimination can 
be avoided. This approach is possible only because the notion of a BB II y offset i I I I x offset Figure 
3. Cursor pattern and reference point. frame buffer representation of an image is a simple one that 
no application programmer finds bewildering. Although a plethora of "off by one" bugs crop up (do the 
limits of a region include the points at the edge?), a frame buffer has none of the complexities of display 
file formats for calligraphic displays. 3.2. Graphical Input DLISP's needs for interactive Input are 
divided into two classes: character typeln from a conventional keyboard, destined to be used by the Interlisp 
program with exactly the same conventions as teletype input; and graphical input obtained from the 5-button 
keyset or the 3-button mouse coordinate Input device. An Important objective of the design is to require 
no modifications to the Interllsp functions already provided for processing teletype input. The only 
direct form of Input feedback provided by ADIS Is a cursor displayed on the screen to show the current 
position of the mouse. An ADIS function Is provided to specify a 16x16 pixel pattern that will be used 
as a cursor. In addition, two offsets are specified that Identify the exact point within the pattern 
whose coordinates will be reported when an event occurs. For example, if the pattern is an arrow (Figure 
,'~), the offsets might identify the point of the arrow. Graphical Input is reported to the application 
program In the form of input events generated by explicit user actions. This allows the application program, 
running in a time-sharing system, to suspend execution awaiting the arrival of Input. An event is defined 
to occur whenever one of the 8 buttons makes a transition (from up to down or down to up) that has previously 
been enabled by the application program. For each event, the entire state of the Input devices is recorded 
and placed in an event queue that Is later read by the application program. The state Includes: (1) the 
(x,y) location of the mouse cursor; (2) current states of all 8 buttons; (3) time since the most recent 
event; (4) a specification of the button transition that caused the event. Reporting the entire state 
reduces the likelihood that the application program will misinterpret an event: Some Input techniques 
require careful timing that Is not provided by the event mechanism alone. For example, consider distinguishing 
a "single click" (key goes down, then up) from a "double click" (key goes down, up, down again wtthln 
1/3 second, then up). After observing the first two transition events (down,up), the application program 
needs to wait for either a down transition or 1/3 second, whichever comes first. Because; DLISP runs 
in a time-sharing environment, It cannot perform such accurate timing. ADIS provides an internal timer 
that is started whenever one of a set of "starting transitions" occurs and is stopped whenever one In 
a set of "stopping transitions" occurs. If the timer Timesharing system Minicomputer ;> G.o ~~buffer 
D.a D.g Application ti ADIS graphics package Figure 4. A three-process Implementation: D.a (application) 
and D.g (graphics package) run on the timesharing system; G.o (graphical output) and G.I (graphical Input) 
run on a personal minicomputer. expires before a "stopping transition" occurs, a timeout event is generated. 
Thus the program trying to distinguish single and double clicks will receive one of two Input sequences: 
down, up, timeout (single click); down, up, down, up, tlmeout (double click). Both events and typeln 
characters are queued. A knowledgeable user Is therefore free to work occasionally faster than the application 
program can process Inputs. This technique works only If the application program refrains from changing 
frequently the parameters that govern the reporting of events (e.g., which transitions cause events, 
which transitions start and stop the timer, the length of the tlmeout period, etc.). If such changes 
are made frequently, a difficult synchronization problem arises: events already recorded In the queue 
may no longer be classed as events using the new parameters; other Input actions not queued and forgotten 
should have been recorded as events given the new parameters. ADIS assumes that the application program 
will set these event p~rameters once at the beginning of a session so as to generate events of any sort 
that might be needed by the application. Thereafter, the application can discard unwanted events as they 
are extracted from the queue. It is a necessary consequence of letting the user get ahead (i.e., of having 
a queue) that the criteria for causing an event be more general than the criteria Imposed by the exact 
context of a specific event. 4, Implementing ADIS A graphics package such as ADI$ can be Implemented 
in a number of ways. On a stand-alone computer with a frame buffer, ADIS could simply be a subroutine 
.package linked Into the application program. The DLISP application requires ADIS to be partitioned between 
two computers: Interlisp Is available only on a large time-sharing system that supports dozens of users, 
while display and Input facilities are available only on several dozen personal minicomputers. The machines 
are linked by the Ethernet [5], a packet-switched network. 4.1. Multiple Processes Before exploring 
the way In which ADIS uses the communications network, let us examine the Implications of executing portions 
of the DLISP/ADI$ system as separate processes. The system divides naturally Into three processes (Figure 
4): The DLISP application program D.a, which calls the ADIS functions D.g; G.o, a process responsible 
for graphical output; and G.I, a graphical Input process. Communication from one process to another is 
achieved with streams. These are FIFO queues of 8-bit bytes: the sending process inserts bytes Into the 
stream and may block execution if the queue is full; the receiving process extracts bytes in the same 
order and may block If the queue becomes empty. The processes control each other by means of a "high-level 
protocol" [1:1] encoded as a sequence of 8-bit bytes and transported via the streams. ADIS uses a protocol 
format in which the first byte Is a coded form of a command, followed by argument bytes. Thus D.g might 
use 4 bytes to Instruct G.o to set the left edge of a region: the first byte Is a number that identifies 
the "set left edge" command, the second Identifies a region Instance, and the last two form a lO-bit 
Integer to be used as the new left edge. The majority of the communication among these processes Is of 
a very simple sort that requires no synchronization. For example, communication from D.g to G.o to cause 
changes to the frame buffer does not require synchronization--the flow of Information Is unidirectional. 
The Interllsp portion of the graphics package (D.g) actually saves a duplicate copy of most of the region 
data (font, Italic, bold, scroll flag, etc.) so that the Interlisp program may read this data without 
requiring communication with processes G.o and G.I. A need to synchronize may arise if information Input 
to D.g depends on information recently output from D.g. This need arises because the interprocess communication 
paths have substantial buffering: if D.g completes output to G.o and then reads some Input from G.I, 
was the input actually generated by G.I before or after the output was uninvited I ~--~ text S.to __~ 
S.go echo path E,.a D.g!E S.gl < S.tl Figure ,5. Actual implementation of ADIS. D is the application 
program, T are operating- system processes, and G are processes In the graphics terminal. Communication 
Is achieved with streams (S) transported by a packet-switched network. processed by G.o? For example, 
suppose D.g outputs a command to alter the timeout interval. This command Is transmitted to G.o, then 
to G.i, and the new timeout value Is recorded in a table inside G.h But the path from G.I to D.g may 
contain several buffered event descriptions; as D.g reads them, It may wish to know which events were 
recorded before the change, and which afterward. Clearly, this need can be met by propagating a special 
mark command around the loop: D.g to G.o to G.I to D,g. As D.g reads input, it will first find events 
recorded before the change, then it will find the mark, and final!~/ it will find events recorded after 
the change. Although such a synchronization primitive is technically easy to provide, synchronization 
Is almost never necessary. We observed above that no Information Is returned to D.g from G.o, so no synchronization 
of output Is necessary. The Input process, G.I, does return Information to D.g that depends on parameters 
sent from D.g. However, as we remarked In discussing Input facilities, these parameters are best set 
only during Initialization, thus avoiding synchronization. Although an Implementation of a graphics system 
using several cooperating processes is not complex, care must be taken to avoid needless synchronization 
difficulties. Consider two Implementations of the cursor function described above: 1. D.g transmits the 
1 6x 1 6 cursor pattern to G.I (via G.o), but saves values of the x and y offsets locally. Whenever It 
extracts an input event from the queue being filled by G.I, It adds these offsets to the (x,y) cursor 
position reported by G.I. 2. D.g transmits the pattern and offsets to G.I (via G.o). Whenever G.i detects 
an Input event, It adds the offsets to  the mouse coordinates as it constructs an event description, 
Just prior to entering it In the queue. Only the second method works properly, because It Intrinsically 
synchronizes the offsets and the cursor patterns. Method 1 will not work because it may use offset~s 
for a cursor shape that was not actually being displayed when the user struck the key that caused the 
event. 4.2. Programming environments and operating systems If the diagram of Figure 4 were an accurate 
picture of the processes Involved In the DLISP/ADI$ system, the three-process design could be easily 
and cleanly implemented. Unfortunately, various deficiencies of the Interllsp environment and of the 
Tenex operating system make such a simple Implementation Impossible. The problems stem from the ways 
In which "terminal I/0" is handled by the two villains. This section explains the difficulties in the 
hope that future operating system and language system designs will avoid the problems. The basic problem 
Is that systems make it impossible to funnel aH input and output through the graphics package D.g. Instead, 
two additional streams shown In Figure 5 provide communication to and from a "terminal," In the sense 
that a timesharing system views a terminal. The two processes G.tl and G.to Interact with G.I and G.o 
in very simple ways: when a key Is" struck on the keyboard, ~.i passe.s It to G.tl, which sends it over 
the terminal stream to Tenex. When Tenex generates output characters, the "terminal text" Is sent to 
G.to, which passes It on to G.o, simulating the effect of a Text call. The text characters are displayed 
on the screen by G.o, using parameters supplied by a region: current position, font, scrolling options, 
etc. In this way, text generated In a 89 conventional way by Interlisp modules or by Tenex can be presented 
In a carefully-controlled way on the screen. The ARPA network graphics protocol does not allow precise 
treatment of such "unescorted text"; the DLISP application clearly requires It. The Interlisp programming 
environment, on which the DLISP application Is based, depends critically on the properties of the "terminal 
I/0" streams. These streams are subjected to special processing within the Tenex operating system. For 
example, normally Invisible control characters can optionally be converted to two character sequences 
(e.g., control C Is printed as "1C"). More Importantly, Tenex Implements an echo path on which interlisp 
depends: normally, as each character of terminal Input Is read by Interlisp, Tenex echos the character 
by sending It as output to the terminal. Because It Is Impractical and Inefficient to replicate these 
functions within DLISP, the ADIS design had to continue to use the normal terminal I/0 streams for ell 
character input and output, and use the graphical streams for all other traffic. Unfortunately, the exisiting 
terminal Input and output streams cannot be used reliably to carry graphical traffic. The output stream 
is subject to invasion by "uninvited text" generated by the operating system or the Tenex executive. 
Such text may garble the graphical output .protocol. In addition, the application program may type arbitrary 
characters to the terminal and Inadvertently generate sequences that Interfere with the graphical protocol. 
Graphical Information encoded on the Input stream Is subject to echoing, which may further garble the 
output stream. The prol0;lem faced In the ADIS design is to provide a conceptual view similar to Figure 
4 with the actual configuration of Figure 5. The design requires solving several synchronization problems: 
rather than a single output stream in Figure 4, there are two in Figure 5. Similarly for input. Each 
of these problems Is considered separately below. Input. Input may be generated as graphical events or 
as typed characters. The DLISP application cannot anticipate the kind of input that will be generated, 
and must therefore wait for ect!vity on either of the two Input streams. Tenex does not provide facilities 
to walt for Input from either of two sources. In addition, the Interlisp functions that gather typed 
Input (READ and the like) do not offer much opportunity for Intervention: once READ is called, tests 
for graphical input cannot be performed. The ADIS design uses the S.ti stream to notify the Interllsp 
program that Input has occurred. Thus the program can request Input from this stream, blocking If none 
Is yet present, and receive Information about the next Input. Characters typed at the keyboard are sent 
over this stream, Just as for normal terminal Input. If a graphical event occurs, two actions are taken: 
a full event record Is delivered over the S.gl stream, and a single control character Is sent over the 
S.tl stream. Thus the Inter!lsp program waits for Input on the S.tl stream, reeds the control character, 
and then extracts the event descriptor from the S.gl stream. This design is not arbitrarily chosen, but 
Is a rather delicate path through the turmoil of Tenex and Interlisp character-handling facilities. For 
example, the event description is not transmitted on the S.tl stream because the bytes in tile description 
might be echoed. It turns out that the processing of Input characters In Tenex allows echoing of control 
characters to be selectively disabled, so the single control character transmitted over the S.tl stream 
to herald an event is not subject to echoing. The design Is also delicately fitted into Interllsp. The 
DLISP program cells READ (or one of Its variants) to gather input from the terminal; this function begins 
reading bytes from the S.tl stream. When READ encounters the control character, it Invokes a READ macro, 
which can contain a call to an arbitrary Interlisp function. This function can read the event description 
from the S.gi stream, and then return to READ, where more typed characters can be assembled, This mechanism 
allows a user to Interrupt typeln to generate graphical events with the mouse. This rather Intricate 
design allows the Interllsp program to receive input from several input devices. The control character 
Is used to synchronize the two Input streams: it marks the S.ti stream at each place that input should 
be extracted from the S.gl stream. Thus, although character and graphical Input are forced to flow over 
separate asynchronous streams, the synchronization mechanism allows the Interlisp program to receive 
the Inputs in exactly the same sequence they were generated. Output. Providing output requires synchronizing 
the S.to anc~ S.go output streams. Synchronization Is needed because characters to be displayed flow 
on S.to, while S.go carries information that affects the display of the characters: font changes, changes 
to the "current position" in the region, etc. Consider the following sequence of operations performed 
by D.a: 1. Text string T1 Is sent to the terminal. 2. Protocol P1 changes region parameter to "style 
Italic." 3. Text string T2 is sent to the terminal.  Operations 1 and 3 transmit text characters over 
S.to, while operation 2 transmits protocol on S.go, a stream that Is Independent and asynchronous relative 
to S.to. However, it Is essential that the operations be performed by G.o In proper order (1, 2, ,3) 
to achieve the desired effect. The synchronization necessary to guarantee that these operations are processed 
In the proper order is provided by the ADIS package. Whenever ADIS sends commands over S.go that might 
alter the Interpretation of terminal text output, It first sends a synchronization mark over both streams. 
Over S.to (end thence tO G.o) It sends a special character (control C) followed by a single digit; this 
sequence Is called "SyncSto d," where d is the digit used. Via S.go it sends a "begin synchronization" 
command followed by the same digit, referred to as "SyncBeginSgo d." Then it sends via S.go the commands 
that alter region parameters. Finally, it sends an "end synchronization" command over the S.go stream 
followed by the single digit, called "SyncEndSgo d." The graphical output process G.o uses the synchronization 
marks to process commands from D.g and text from G.to In the proper order using the following algorithm 
(see Figure 6). Initially, G.o processes commands received on S.go and text received from G.to in arbitrary 
order. Whenever a "SyncSto d" sequence Is received from G.to, further processing of bytes from G.to Is 
delayed until a "SyncEndSgo d" command is received over S.goo Similarly, whenever a "SyncBeginSgo d" 
command Is received over S.go, further processing of bytes from S.go Is delayed until a "SyncSto d" sequence 
Is received from G.to. This synchronization scheme is easy to implement and quite robust. If processing 
of bytes from either stream (S.go or from G.to) Is delayed for more than 10 seconds while waiting for 
a synchronization mark, the wait Is terminated, and processing proceeds. The only damage in this case 
is that some terminal text output will not be properly displayed. The "digit" argument to the synchronization 
marks, which is incremented modulo 1 0 for each new synchronization operation, avoids global loss of 
synchronization due to program bugs or restarts that omit synchronization marks or operating-system inserted 
text that garbles the "SyncSto d" marks. Discussion. This section has described the modification of the 
simple view of Figure 4 in which streams S.go and S.gi carry all traffic between the terminal and the 
application program to the more complicated view of Figure 5 in which four main streams are used: S.go, 
S.gl, S.to, and S.tl. This arrangement was necessary because deficiencies In ,the Tenex operating system 
and Interlisp programming environment were too costly to remedy by invading these systems. Instead, ADIS 
was contorted to achieve the desired effect. The contortions were necessary because the existing environment 
contained a view of terminals too thoroughly embedded to change. S.to T1 Sync 4 T2 Sto     I I I 
I I I I J I S.go Begin 4 P1 Er.d 4  ego I sgo I I Figure 6. Sync markers tell when to "switch" Interpretation 
from one stream to the other to assure processing of text and protocol In the proper order. The operating 
system and language environment can be designed to allow the two-stream Implementation of Figure 4. What 
Is required Is a view of "terminals" that allows multiplexing of normal character Input/output and protocol 
messages that are not subject to modification by the operating system (FigrJre 7). The program needs 
several output fac!llties; (1) the ability to output text characters; (2) the ability to output byte 
sequences of arbitrary length that will not be altered by the operating system; and (3) some mechanism 
for dealing with other traffic that is sent to the terminal by the operating system. These "uninvited 
text" messages, such as "System going down In 30 minutes," are lethal Invasions of any formatted communication 
between a computer and a terminal. This is a severe problem with terminals such as storage-tubes: the 
system message may be Interpreted as graphical commands! Facilities needed for Input are: (1) a mechanism 
to allow protocol messages to bypass the echoing machinery; and (2) a design for character echoing that 
echoes characters as they are read by the application program. This last facility is available In Tenex; 
without It, echoed characters cannot be placed carefully on the screen. Users of systems that echo characters 
as they are typed (e.g., DECSystem-lO) are familiar with the result: typeln and typeout are thoroughly 
Intermingled, preventing careful presentation of either. Terminal Input/output facilities In the programming 
environment also need careful attention to support formatted communication ("protocol") with a terminal. 
Although the Ideal solution is to funnel all terminal Input and output through the graphics package, 
almost no programming language systems permit It. Instead, existing facilities for terminal Input and 
output must remain Intact, and additional independent mechanisms can be provided by the graphics package. 
Problems with output are modest, provided the terminal interprets normal text characters generated by 
the system In the proper way. Calls on the graphics package can generate uninvited text _ _ _ ~ $.to 
echo path D.a ~, D.g ~.~ ~ S,tl Figure 7. Terminal and graphical traffic are carefully multiplexed 
on two streams. "terminal output protocol" sequences to display graphical objects or to alter the interpretation 
of text characters. (This is the approach taken by the Tektronix terminals, and is quite successful.) 
Input presents a more Intricate problem: descriptions of graphical Input arriving in the midst of character 
typein will interfere with the character Input expected by the programming system. The use of READ macros 
to solve this problem in the ADIS package is an Idiosyncratic solution applicable only In Interllsp. 
Programming environments that allow careful control of terminal I/0 (e.g, SAIL) present fewer difficulties. 
Manufacturers of graphics terminals have chosen to solve this problem by transmitting graphical Input 
only when demanded by the application program: this guarantees that the program Is In a suitable state 
for accepting graphical Input. Unfortunately, many have taken an additional step as well: the graphical 
Input device is active only when the program is demanding graphical Input (e.g., Tektronix terminals), 
and the appUcatlon program must activate only one Input device at a time. Perhaps the cleanest way to 
solve all of these problems is to solicit assistance from the operating system to Insert processes between 
application programs and the terminal (Figure 8). These processes provide to the application program 
a simple view of the terminal as streams of characters (if that is the view expected by the programming 
envlronrnent), but can communicate with the terminal using carefully formatted protocols. These processes 
may connect with other processes that desire communication with the user (e.g., uninvited text). These 
processes become, in effect, a definition of how the user's single terminal is to be used to communicate 
with many application processes. Most operating systems contain such processes (they are shown in Figure 
5 as T.o and T.I), but prevent their alteration or substitution by the user. The ability to connect uninvitedtext 
1 _ _ _ q, O.to q, ,Ij S.to echo path D,a D.g S.tl  t 0tl I --J Figure 8. User-defined processes control 
the graphics terminal. Any processes wishing to use the terminal (e.g., the application program and the 
operating system, the source of uninvited text) communicate with the terminal-controller processes. the 
terminal streams of an application program to user-defined processes would greatly ease the Introduction 
of new terminal types, would simplify the Implementation of terminal communications In computer networks, 
and would also allow one user-defined process to Invoke another in a simple way. Some operating systems 
Implement "pseudo-teletypes" that attempt to serve this function, but most Implementations are either 
too Inefficient or too awkward to use. 4.3. Network Issues A packet-switched network is used to Implement 
four of the Interprocess communication streams used by ADIS (S.go, S.gi, S.to, S.tt). The network Introduces 
no special problems--it is the introduction of several processes and the confrontation with programming 
language and operating system limitations described In the previous section that complicate the Implementation. 
All four streams are Implemented with a "network stream protocol," similar to TCP [2]. The two streams 
that carry terminal traffic (S.to and S.ti) use a "Telnet protocol" implemented with streams. (Telnet 
is the name of the terminal protocol in the ARPAnet [3].) The Tenex operating system Interfaces the character 
Input/output facilities available to the Interllsp program to the network protocol. This Interface ensures 
that characters output from the Interllsp program are forwarded through the stream In a timely fashion. 
The two streams used for graphical information (S.go and S.gl) simply use the ability to send bytes from 
one process to another. The Tenex network interface for these streams Is rather different than that for 
terminal streams. In particular, bytes output by D.g are not forwarded over S.go in a timely way, but 
are buffered until a sizeable number (roughly 500) are available to fill a packet. This buffering has 
the unfortunate effect of requiring the application program to Issue periodically calls to an ADIS function 
that Instructs the operating system to transmit a buffer even though It is not full. Buffering of this 
sort may be acceptable for streams that access dtsk files, but Is quite unacceptable for streams that 
carry timely Information. This fact Is all too often overlooked when a network interface is designed 
for an operating system: it Is slipped into the "file" machinery of the system, without recognizing that 
a network connects computational processes operating In a timely way. What is needed Is the ability to 
declare that a stream contains timely Information, and that no bytes should be buffered for very long. 
Such a facility Is necessary for terminal and network streams; It also has applications for file streams 
(e.g., transaction recording). The particular network implementation in ADIS seems to Introduce no noticeable 
performance problems. During heavy output use, only about 400 bytes/second are transmitted over S.go 
and S.to combined. Extensive use of the RasterOp function helps to keep this figure low. Input traffic 
is of course lower still. An event report, even though It records the state of all Input devices, requires 
only 9 bytes. This message fits easily In a single packet, and therefore requires no more network traffic 
that does a single character being typed. 5. Conclusion Two aspects of the ADIS graphics package have 
been described In this paper. The functions of the graphics package offer a small set of primitive ways 
to modify rapidly the contents of a frame buffer. These primitives place on the application program the 
burden of managing screen updates. However, this burden is lessened by the ease with which the programmer 
understands and uses the frame buffer and by the power of the primitives (especially RasterOp). One of 
the rewards of this approach Is that the application program can optimize Its screen-updating strategy, 
thereby providing good Interactive response. A second interesting aspect of ADIS is its use of a packet-switched 
network to link a timesharing computer and the display terminal. The important point revealed by the 
design Is that any trickiness in network graphics comes not from the presence of a network, but because 
the system is Implemented by several asynchronous processes. Acknowledgements. ADIS depends on superb 
workmanship contributed by many researchers at the ,Xerox Palo Alto Research Center. Especially helpful 
for this effort was the network software developed by Ed Taft and~ Dave Boggs, and the work on the RasterOp 
function by Dan Ingalls and the Learning Research Group. Of absolutely critical Importance were Warren 
Teitelman and his DLISP application: it was Warrenws ambition for a usable system rather than a mere 
demonstration that spurred me to analyze and solve the more thorny problems. References [1] G. M. Blrtwlstle 
et al. Slmula Begin. PetrocellI-Charter, 1973. [2] V. G. Cerf and R. E. Kahn. A protocol for packet 
network interconnectlon. IEEE Trans. Commun. COM-22:637, May 1974. C3] J. Davldson, W. Hathaway, J. 
Postel, N. Mimno, R. Thomas, and D. Walden. The ARPA,~et Telnet Protocol: Its Purpose, Principles, Implementation 
and Impact on Host Operating System Design. In Proc. 5th Data Communications Symposium, pages 4.10-4.18. 
Snowbird, Ut., Sept, 1977. [4] A. Goldberg and A. C. Kay. Smalltalk- 72 Instruction Manual. Technical 
Report SSL 76-6, Xerox Palo Alto Research Center, 1976. [5] R. M. Metcalfe and D. R. Boggs. ETHERNET: 
Distributed Packet Switching for Local Computer Networks. CACM 19(7):,305-404, July 1976. [6] W. M. Newman 
and R. F. Sproull. An Approach to Graphics System Design. Proc. IEEE 62(4):471-483, April 1074. [z] W. 
M. Newman and R. F. Sproull. Principles of Interactive Computer Graphics. McGraw-Hill, 1079. Second edition. 
[a] R. F. Sproull and E. L. Thomas. A Network Graphics Protocol. Computer Graphics 8(3):27-51, Fall 1974. 
[g] R. F. Sproull. Interlisp Display Primitives. Technical Report, Xerox Palo Alto Research Center, 1977. 
[1 O] R. F. Sproull and W. M. Newman. The Design of Gray-Scale Graphics Software. In Proc. Conf. on Computer 
Graphics, Pattern Recognition and Data Structure, pages 18-20. 1975. [11] R. F. Sproull and D. Cohen. 
High-Level Protocols. Proc. IEEE 66(11 ): 1371-1386, 1978. November [12] W. Teltelman. INTERLISP Reference 
Manual. Technical Report, Xerox Palo Alto Research Center, 1978. [13] W. Teltelman. A Display-Oriented 
ProgrammerWs Assistant. Technical Report CSL 77-3, Xerox Palo Alto Research Certter, 1977. [14] W. Teitelman. 
A Display-Oriented Programmer's Assistant. In Proc. 5th Int. Joint Conf. Artifical Intelligence, pages 
005-915. 1977. 93  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807429</article_id>
		<sort_key>94</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Some principles for the effective display of data]]></title>
		<page_from>94</page_from>
		<page_to>101</page_to>
		<doi_number>10.1145/800249.807429</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807429</url>
		<abstract>
			<par><![CDATA[<p>Since computers can produce output at a high rate, it is often useful for it to put that output in a form that facilitates human analysis. There has been much research on the human factors of displays; from this research, we can evolve principles to guide the effective display of computer output. The two main principles described here are the principle of proportional effect, which guides the encoding of a datum's identity and value, and the principle of least effort, which minimizes the effort needs to scan, and perceive and interpret the display. Some of these ideas are illustrated using data generated by a neural simulation.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Display design principles]]></kw>
			<kw><![CDATA[Effective data displays]]></kw>
			<kw><![CDATA[Human factors]]></kw>
			<kw><![CDATA[Visual data encoding]]></kw>
			<kw><![CDATA[Visual load]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human factors</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14143172</person_id>
				<author_profile_id><![CDATA[81100405229]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Morse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts, Amherst, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ashford, F. The Aesthetics of Engineering Design. Business Books, Ltd., London, 1969.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barmack, J.E. and Sinaiko, H.W. Human factors in computer-generated displays. Institute for Defense Analysis, Research and Engineering Support Division, Study S-234, AD636170, April 1966.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chapanis, A. Man-Machine Engineering. Wadsworth Publishing Co, Inc, Belmont, CA 1965]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chapanis, A. and Lindenbaum, L.E. A reaction time study of four control-display linkages. Human Factors 1(4): 1-7, 1959.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chapanis, A. and Lockhead, G. A test of the effectiveness of sensor lines showing linkages between displays and controls. Human Factors 7(3): 219-229, 1965.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Christ, R.E. Review and analysis of color coding research for visual displays. Human Factors 17(6): 542-570, 1975.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807391</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Donelson, W.C. Spatial management of information. SIGGRAPH'78 Proceedings, August 23-25, 1978, Atlanta, GA (R.L. Phillips, Ed.)]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fitts, P.M. and Seeger, C.M. S-R compatibility: spatial characteristics of stimulus and response codes. J. of Experimental Psych. 48: 199-210, 1953.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Foley, J.D. and Wallace, V.L. The art of natural graphic man-machine conversation. Proc. IEEE 62(4): 462-471, 1974.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goldstein, D.A. and Lamb, J.C. Visual coding using flashing lights. Human Factors 9(5): 405-408, 1967.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hammer, C. and Ringel, S. Information assimilation from coded and uncoded individual and group displays. Hum. Fac. 7(3):245-255, 1965.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hitt, W.D. An evaluation of five different abstract coding methods&#8212;Experiment IV. Human Factors 3(2): 120-130, 1961.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hodge, D.C. Legibility of uniform-strokewidth alphabet: I. Relative legibility of upper and lower case letters. J. of Experimental Psych. 1: 34-46, 1962.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Huntley, M.S. Task complexity and serial performance under steadily increasing input rates. Human Factors 14(1): 65-75, 1972.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jones, M.R. Color coding. Human Factors 4(6): 355-365, 1962.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kanarick, A.F., et al. Multi-source information acquisition with optional stopping. Human Factors 11: 379-385, 1969.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>574884</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Martin, J. Design of Man-Computer Dialogues. Prentice-Hall, Inc, Englewood Cliffs NJ, 1973.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[McCormick, E.J. Human Factors Engineering. McGraw-Hill, 1970.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Meister, D. Behavioral Foundations of System Development. Wiley Interscience, New York, 1976]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Miller, G.A. The Psychology of Communication. Penguin Books, Inc, Baltimore, MD, 1967.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Miller, J. Adjusting to overloads in information. (from) Waggoner, R.W. and Carek, D.J. (Eds.) Disorders of Communication. Research Publications, Assoc. for Research in Nervous and Mental diseases, 42: 87-100, 1964.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Morse, A. and Kilmer, W. A neural net capable of competitive and cooperative computation. Biol. Cybern. 30(1): 1-6, 1978.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Pollack, I. Detection of changes in spatial position: IV. Multiple display fields, display aiding and interference. Human Factors 16(2): 93-116, 1974.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Posner, M.I. Information reduction in the analysis of sequential tasks. Psych. Review 71: 491-504, 1964.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Roscoe, S.N. Airborne displays for flight and navigation. Human Factors 10(4): 321-332, 1968.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Schutz, H.G. An evaluation of formats for graphic trend displays&#8212;Experiment II. Human Factors 3(2): 99-107, 1961.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Schutz, H.G. An evaluation of methods for presentation of graphic multiple trends&#8212;Experiment III. Human Factors 3(2): 108-119, 1961.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Smith, S.L. and Goodwin, N.C. Blink coding for information display. Hum Fac. 13(3):283-290, 1971]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Smith, S.L. and Goodwin, N.C. Another look at blinking displays. Hum Fac. 14(4):345-347, 1972.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Tinker, M.A. Prolonged reading tasks in visual search. J. of Appl. Psych. 39:444-446, 1955.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Vicino, R.L., Andrews, R.S., and Ringel, S. Type, extent and coding of updated information. Hum. Fac. 8(5): 407-416, 1966.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Yntema, D.B. Keeping track of several things once. Human Factors 5(1), 1963.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SO5~ PRINCIPLES FOR THE EFFECTIVE DISPLAY OF DATA Alan Morse University of Massachusetts, Andlerst, 
Massachusetts 01003 ABSTRACT Since computers can produce output at a high rate, it is often useful 
for it to put that output in a form that facilitates human analysis. There has been much research on 
the human factors of dis- plays; from this research, we can evolve principles to guide the effective 
display of computer output. The two main principles described here are the principle of proportional 
effect, which guides the encoding of a datum's identity and value, and the principle of least effort, 
~lich minimizes the effort neede to scan, and perceive and inter- pret the display. Some of these ideas 
are illus- trated using data generated by a neural simulation. CR CATEGORIES: 3.19, 3.29, 3.39, 3.49, 
3.59, 3.69, 3.79, 3.89, 3.9, 8.1, 8.2 KEY WORDS AND PHRASES: visual data encoding, human factors, computer 
graphics, effective data displays, visual load, display design principles. 1. INTRODUCTION Because 
computers calculate rapidly, they are capable of generating data faster than we can assimilate them. 
Initially, we try to cope by poring over pages of numbers, after the computer has finished its work, 
and when we feel free of its intimidating speed. Soon, we find that a lot of this work is unnecessary 
since we are only concerned with a subset of the data, or we need only a few significant digits of accuracy. 
It is thus useful to represent the data graphically, either on CRTs or on some hardcopy plotting device. 
By so representing the data, we make more apparent interesting data points, trends, and relationships. 
Usually, we use graphs modelled after the cartesian coordinate system, which is a proven,, effective 
means of visual data encoding. However, I suggest that current hardware allows us to be more creative. 
Representing data in a variety of ways can make apparent patterns that would otherwise be difficult 
to discern. We are familiar with graphs and so are skilled in reading them. But we are in a position 
to explore other forms. I describe some principles to guide our exploration of effective display representations. 
~nese principles derive from the human factors engineering literature on displays. Many of these studies 
were of instrumentation displays, but I feel that the results carry over. The principles, described in 
the coming section, are organized as follows: I. Principle of Proportional Effect II. Principle of 
Least Effort A. Principle of Display Integration B. Principle of Optimal Scaling C. Principle of Compatibility 
 i. Spatial Compatibility 2. Movement Compatibility  3. Conceptual Compatibility  4. Task Compatibility 
  After the section on principles, there is a discussion of several coding methods in light of those 
principles. Then an example is presented to provide a flavor of their use. Finally, there are closing 
remarks and suggestions for future work.  2. PRINCIPLES FOR EFFECTIVE DATA DISPLAY Effective display 
of data has two aspects: (i) pictorial representation of data (2) in such a way that assimilation of 
the data is easy. These two aspects suggest two high-level principles, which organize the guidelines 
for displays that we find in the human factors literature. ~%ese are the principle of proportional effect, 
pertaining to ways of visually encoding the data, and the principle of least effort, pertaining to factors 
that make the display easy to use. 2.1. The Principle of Proportional Effect ~%e principle of proportional 
effect states that the psychophysical effect caused by the display of a datum should be a monotonic 
function of the magnitude of the datum: digital data should be converted to an analog visual form where 
some humanly perceivable measure of the form is simply related to the value of the data. That analog 
 forms are desirable is based on the hypothesis that they are easier to interpret than number displays. 
Generally, digital displays are only justified in situations where accuracy of several digits is important. 
 In graphically encoding data, we must be aware of &#38;#169; 1979 ACM 089791-004--4/79/0800--094 $00.75 
See Copyright Pg. 94 the two coding functions that we need to perform: to code (i) the data's value 
(or quantity) and (2) its identit[. (The viewer has to be able to tell which datum is being displayed 
if he is to be able to interpret it.) Not every graphic encoding method is equally suited to these 
two tasks, and it is often preferable to use different coding methods for them. There are many ways 
to graphically encode data; we could use position, length, size, angle, color, brightness, texture, 
time, or symbols. ~rtin [17], Foley and Wallace[9] and Barmack and Sinaiko[2] summarize some aspects 
of these codes, which are further discussed in the section on coding methods (section 3). 2.2. The 
Principle of Least Effort The principle of least effort mandates the minimization of the work necessary 
to scan, and perceive and interpret the display. The minimization of scan effort leads to the principle 
 of optimal scaling and the principle of display integration, which are discussed in section 2.2.1. 
 The reduction of perceptual effort involves the principle of compatibility, which is discussed in 
section 2.2.2. 2.2.1. The Principles of Optimal Scaling and Display Integration The principle of optimal 
scaling (after Roscoe[25]) simply requires that we display no more resolution than we need. We can 
reduce the effort needed to scan a display, if we make it simpler. So, the resolution of the display 
should be enough to allow meaningful distinctions without using too much display space. (We can improve 
the effective resolution of a smaller display area if we preprocess the data by truncating it, taking 
its logarithm, or magnifying a subset of it.) The principle of display integration (after Roscoe[25]) 
is an aesthetic principle that guides the coordination of the display components so as to minimize scanning 
effort. To do this, we need to bear in mind the intradisplay relation- ships when assembling the display. 
This means watching things like the scan order we take when viewing and interacting with the display; 
for instance, if we are using a lightpen, we should see to it that the forms bearing on the lightpen 
interaction are not in places that would be obscured by our hand. (We might have a special menu item 
that allows the user to indicate whether he is right or left-handed; then the dis- play could be modified 
accordingly.) Ashford[l] suggests engineering design points that we can apply: we should be aware of 
compo- sition, visual competition, direction, clarity of forms, balance, unity, and the pleasantness 
of the display. It is not surprising that these aesthetic concepts are at the basis of scan effort minimi- 
zation, since it is the business of art to direct our eye and attract our interest. Visual compe- tition 
refers to interference effects among the forms in the display due to their differing characteristics; 
relative size, intensity, contrast, and texture can affect the perceived\priorities of the display 
parts. .\  Direction refers to the effect of lines in the display in establishing inherent scan paths. 
 This is because we find it easy to scan along a displayed line, and difficult to scan in a direc- 
tion perpendicular to displayed lines. (Lines perpendicular to the scan path tend to arrest our eye 
movement.) Schutz[26] describes an experiment that demonstrates this point; he found that bar graphs 
were inferior to line graphs for repre- senting data plotted against time. This makes sense, because 
interpretation of a time plot requires scanning the plot in the time dimension, and the perpendicular 
lines of the bars interfere with that scan. Clarity of form is a related notion; simpler forms are 
easier to scan, because of fewer or more gradual changes in the lines that define them. In general, 
then, avoid unnecessary discontinuous changes in the slopes of a form's lines (unless these carry attention-worthy 
information). Attention-getting devices are also useful for easing the scanning task. Hammer and Ringel[ll] 
 found that conspicuity coding of alphanumeric data greatly reduced search time. If changes in the 
display are important, then we can attract attention to them using devices like blinking, color, brightness, 
and double-cue coding (using two cues to indicate changes in the display). 2.2.2. Perceptual Effort 
Minimization and the Principle of Compatibility One aspect of the principle of least effort requires 
the minimization of the effort needed to perceive and interpret parts of the display. Naturally, we don't 
want to reduce the load too much; some load is necessary to stimulate the viewer's interest. Huntley[14] 
found an inverted-U relationship between performance and stimulus complexity; performance improved with 
increasing stimulus complexity up to a point, after which performance degraded. Nevertheless, the problem 
of displays that are too simple rarely occurs. In any case, our goal is to optimize the transfer of 
information from the display to the viewer. This generally means minimizing the effort per bit of information 
transfer. Success in this direction depends on the principle of compatibility, where the spatial, movement, 
conceptual, and task features of a display are consistent with human expectations [18]. Compatibility 
occurs when the "ensemble of stimulus and response combinations comprising the task results in a high 
rate of information transfer" [8]. Hence, compatibility assures us of close to optimal information trans- 
fer, and it occurs when certain features of the display reading task are compatible with human experience 
and expectation; though one may, with training, benefit from a new style of display. According to McCormick[18], 
spatial compatibility refers to the physical features and arrangement in space of the parts of the display. 
It is most often studied in terms of relations between displays and controls. For instance, Chapanis 
 95  and Lindenbaum[4] analyzed the relationship between controls and burners on a stove to determine 
the combination that resulted in the fewest errors (the criterion of compatibility in this circumstance). 
In a study of the effective- ness of sensor lines, which visually connect controls to corresponding 
displays, Chapanis and Lockhead[5] concluded that making the displays compatible with the controls was 
far more effective than using sensor lines. Intra-display spatial compatibility demands a unifying feature 
for related parts of the display. The parts that are related should be determined on the basis on the 
frequency, sequence, and criticality of the use of the display parts. Related parts may be unified by 
being adjacenct, by having the same color, or by being similar in shape or size. Movement compatibility 
refers to the relationships among the directions of movement of the displays, controls and system responses. 
For instance, a clockwise turn of a control knob is usually com- patible with an increase in some system 
variable and, hence, an increase in its display. (This rule is subject to exceptions depending on the 
posit~on of the display with respect to the con- trol.) If a pick device, like a lightpen, is being used 
to enter data by indicating a point on a scale, then up should correspond to an increase for a vertical 
scale, and the right direction should correspond to an increase in a horizontal scale. But if the control 
and the display have similar forms, the direction of increase for the display and the control should 
match [3]. Naturally, related parts of a display should have similar directions of increase. Conceptual 
compatibility is based on the assoc- iations that people make--green for "go," red for "hot," and facial 
expressions and mood. Pictorial realism in displays is a classic use of this form of compatibility. 
Basically, the requirement here is that the display of the data conform with our intuitive understanding 
of what the data signifies. Task compatibility refers to the suitability of a display for the desired 
perceptual task; the display should make the task easy. For instance, Schutz[27] showed that superimposing 
graphs facilitated comparing data, while separately plotted graphs are better for reading data values. 
 In the same series of experiments, Hitt[12] con- firmed that different displays are most compa- tible 
with different tasks. From our experience with line graphs, we know that we can easily integrate and 
differentiate them "in our head"; whereas this would not be true for a grey scale or blink-coded display. 
 Task compatibility implies that only the infor- mation that the viewer wants to know about should 
be displayed. If there is superfluous information the viewer will have to reduce out the information 
 that he doesn't want. (When there is no reduction in the information transfer from display to human, 
 the task is called a conservation task.) Posner[24] observed that subjects' performance declined monotonically 
with the increase in the amount of information that they had to reduce out. So we complicate the viewer's 
task if we try to show him all the data in all its detail. However, a flexible display should facilitate 
several types of viewing tasks; and what is relevant to one task may not be relevant to another; so it 
may be necessary for the viewer to reduce out the information that is irrelevant to the particular task 
that he wants to perform. In this case, the display should be structured so that the reduction is a gating 
task rather than a condensation task. (Gating requires that the viewer merely ignore irrelevant stimulus 
dimen- sions; this is impossible in a condensation task, where information must be condensed in complicated 
ways--for instance, red triangles and blue squares may have to be grouped together and treated differently 
from the group comprising red squares and blue triangles.) Posner found that perfor- mance in a gating 
task was as good as if no information reduction were required (conservation task); condensation, on 
the other hand, signi- ficantly degraded performance. If the display tasks are complicated enough, we 
may want to display the same data in several forms, or we may find that displaying the raw values is 
inadequate. In the latter case, we should transfer part of the viewing task from the man to the machine 
(as in an animated display in which the changing forms leave tracks that fade over time; thus partially 
automating short term memory). McCormick describes other techniques, such as quickening, where the data's 
derivative is dis- played; predictor displays; and control augmen- tation, where the system figures out 
the control signal on the basis of a simpler control signal specified by the operator. There are miscellaneous 
other strategies for reducing the viewer's perceptual load. These include automating the strategies that 
humans use when they are confronted with stimulus overload (from [19] and [24]). We can queue successive 
frames of a display, or generate a history file of the data, so that it may be displayed at a slower 
pace. We can filter the data, displaying only those data that are above a certain thresh- old (or are 
interesting for some other reason). We can chunk the data by reducing its resolution or representing 
a whole group of data by some statistical measure that characterizes the whole group. We can use multiple 
display channels; perhaps using several CRTs, with one providing a world view and the others providing 
details (as in [7], an excellent example of a well-designed data display system). We can provide for 
the user to escape an animated display of data by providing for optional stopping (the User may stop 
the display and be able to resume it where he left off). Along with reducing load, we should avoid features 
that unnecessarily increase load. For instance, displays of different data should be easily distinguished 
(if stimuli are similar it takes more effort to distinguish them); in animation we should insure that 
the display not change too quickly, and that the display not require several concurrent processing tasks 
from the viewer; and we should not ask the viewer to overly rely on his short term memory, it requires 
more display area per datum. However, it does have a greater psychological impact. 3. DISCUSSION OF 
CODING METHODS In the discussion of the principle of proportional effect, some visual coding methods 
were listed. These are described in greater detail in the sec- tions immediately following. (included 
are com- ments relating the code to the display design principles.) In discussing the display resolution 
of the various encoding schemes, it is important to distinguish between absolute and relative discri- 
mination judgments. The type of judgment required determines the effective resolution of the coding method. 
In [2], [9] and [17], the recommended maximum number of encoding levels (that is, the resolution) is 
based on data on absolute discri- mination judgments; this maximum is about seven, depending on the stimulus 
dimension [20]. However, our ability to detect differences between stimuli is much keener, that is, our 
ability to make relative judgments is more refined. So, including a reference scale or displaying several 
like data at once (so that they may be compared) will increase the coding scheme's effective resolution. 
In this way, we can use the display device to its limit. 3.1. Position Codes Perhaps the most common 
method of graphic display encoding uses position to code the value or identity of data. Examples are 
graphs and maps; in the former, horizontal position codes the identity of the data, and vertical position 
codes the value; in the latter, position codes the value (where the value is the location in some other 
isomorphic surface), and other codes (color, labels, texture) identify the data. In position codes, there 
are usually reference shapes that provide a context for the code (for instance, the axes of a graph). 
The larger that shape, the greater the effective resolution of the code--up to the resolution of the 
device, which resolution is typically nine or ten bits.  3.2. Length Codes The length of a line or 
other form can effec- tively represent a data value, as it does in a bar graph; however, length coding 
is a poor way to represent a datum's identity (unless there are few data to encode--as in the hands of 
a watch). In a bar graph, position identifies the data, along with labels, textures, or colors. Display 
devices permit the same resolution for length coding as for position coding; but the effective resolution 
is less, because we generally compare lines using the ratio of their lengths rather than the differences 
between their lengths.  3.3. Size Codes The size or area encompassed by a shape can also effectively 
represent data values; although, like length, it is a poor stimulus dimension for en- coding data identities. 
The effective resolution of size coding is less than length coding, because  3.4. Angle or Inclination 
Codes The angle that one line makes with another is often used to display data values; for example, 
clocks, dials, and pi charts. The resolution of an angle coded display depends on the lengths of the 
lines, and on the reference scale that is used; the reso- lution can be as good as for position coded 
dis- plays. However dominant use of angle coding can make a display visually confusing. (We can com- 
pensate for this using some of the aesthetic principles mentioned above; we can enhance the balance and 
pleasantness of an angle coded display if we surround each coding with a circle--as in an array of dials.) 
 3.5. Color Codes Research [6,19] indicates that color is a better data identifier than size, angle, 
or shape; and, on balance, it is about as good as alphanumerics. (Colors are easier to locate than alphanumerics, 
but they are harder to associate with a meaning.) When the display of a datum is identified by a color, 
it makes it easier to search the display for the encoding of that datum's magnitude. So, color is an 
effective labelling device, because it greatly reduces search time, especially when used in a redundant 
form (perhaps with alphanu- merics or position coding). (However, when sub- jects were not aware that 
colors were being used redundantly--or when the colors were irrelevant-- their performance was worse 
than for achromatic displays. It seems tha color has some interference effects--see the discussion on 
visual competition above.) What about using color to encode data values? Numbers would naturally be 
more accurate, but we are not concerned with accuracy as much as with ease of interpretation; and there 
are clearly circumstances in which color coding would aid data interpretation. An infrared photograph 
is an example where color from a cold-to-hot spectrum is used to encode data values (in this case, 
sur- face body temperature); it is certainly a better display than an array of numbers superimposed 
on a picture of the body. Depending on the display device, the resolution of color coding can be 18 
bits or more, but there are many disadvantages that discourage the use of color for encoding values from 
a linear scale. First, we don't know what the significant attri- butes are; is hue more important than 
saturation or brightness? Second, color-blind people will have a problem interpreting the display properly. 
Third, perception of the display is greatly affected by chromatic and brightness contrasts with the background. 
Fourth, comparison of colors is difficult when they are separated by more than a few degrees of arc. 
Also, colors don't occur in an obvious linear relationship, even in the cold- to-hot spectrum mentioned 
above; when you double the value of a datum represented by green, what color shQuld you get? Finally, 
if the display is to be published, the author will find it expen- sive to reproduce.  3.6. Brightness 
and Texture Codes Brightness, grey scale, and texture codes are the poor cousins of color coding; they 
are what we use when the hardware doesn't allow us to use color. Brightness and grey scale are better 
than color for encoding data a values from a linear scale, because the range of their values has a monotonic 
nature that the color spectrum doesn't have. However, they are of little use as encoders of data identity, 
except in a redundant coding scheme. Vicino[31] gave an example where brightness might be used ih a ~ighlighting 
scheme (in a double-cue code) to attract attention to those elements of a display that have just been 
added, removed, or moved. Since color redundant coding is better than brightness redundant coding of 
data identities, the latter technique is best left for monochromatic displays. On the other hand, texture 
coding is better suited to identifying data; furthermore, it can success- fully imitate grey scale 
in encoding data values (using dithering). For instance, line texture (line type) is useful for distinguishing 
the displays of several data sets in a combined graph, and surface texture is useful for dividing the 
bars of a bar graph into their component parts.  3.7. Time Coding Because of our capacity for remembering, 
we can use time as a coding medium. We are familiar with two examples: blink coding and animation, which 
are discussed below. Time coding is un- suitable for displays intended for publication; although time-coded 
displays may be filmed or videotaped for presentation at lectures. Time coding requires a display device 
with a dedicated computer and a volatile display surface; a timesharing system with slow and variable 
response times would be inadequate, unless the displays were filmed one frame at a time for later viewing. 
 Goldstein and Lamb[10] found that flash rates could be used to identify data, and Smith and Goodwin[28,29] 
found that blink coding was an effective attention-getting tool. However, they also found that blinking 
a message reduced its readability. For this reason, and because flash coding has a very low resolution 
(2-3 bits), it is not promising as a data encoding technique. It can be used as an attention-attracter, 
but there is a caution: instead of blinking a target mes- sage--making it difficult to read--blink an 
ad- jacent symbol. Animation is a powerful way to display time- varying data, which we find, for example, 
in computer simulations. Instead of representing time with a dimension on a graph, we can use real time 
to encode simulation time. (Here real time identifies th~ data.) This makes it easy for the simulator 
to get an intuition for the behavior of his model. There is a tradeoff, however; animation often increases 
the processing 10ad on the viewer (as does any task that taxes short term memory). Meister[19]and Yntema[32] 
evolve similar guidelines for the design of time-varying displays: (1) dif- ferent variables should 
have mutually exclusive sets of possible states; (2) it is better to have few variables with many states 
than to have many variables with few states; (3) a variable should not change state more often than 
necessary; and (4) the display should compensate for short term memory demands by providing mnemonic 
or automatic memory aids. (Pollack[23] found display aiding, one such automatic aid, to be extremely 
effective; it involves displaying a trail of displacements that fade over time, so that a moving object 
leaves a trail of fading "footprints," which indicate its position in the recent past.) Pollack also 
found that the critical variable for detecting change in a series of displays is the blank interval between 
displays. So, if animation is used to display data, there should be no gap between frames; and, if individual 
frames are displayed for more than a second, there should be some type of memory aiding. (We can avoid 
these problems if we create a history file of the data so that successive frames can be displayed quickly, 
and we can avoid the gap between frames using double buffering of the display files.)  3.8. Symbols 
 Although alphanumerics and other symbols can't be used in an analog encoding of values, they are indispensable 
as data identifiers. Judicious use of labels will greatly enhance the readability of any display. Tinker[30] 
found that regular text is more readable than all upper case text, except when words are used as labels; 
then capital letters are more readable [13]. From this we infer the rule: instructions anf other text 
are better dis- played in the regular upper and lower case style, while labels are better printed in 
upper case. Aesthetic issues apply as well; Ashford[l] notes that ~type fonts with serifs (the horizontal 
lines at the bottom of some letters, e.g., r) are more readable because the serifs enhance the horizontal 
directionality of the text; thus they facilitate scanning in the horizontal direction. Some kinds of 
data only make sense if displayed digitally (for instance, correlation coefficients); nevertheless, such 
displays are often best arranged as tables, where the data's identities are analog- encoded using position. 
 4. AN EXAMPLE DISPLAY This section illustrates some of these ideas in the development of displays of 
data generated by a neural simulation. The model that is simulated is a network comprising three groups 
of three cells each (see Fig. i); each cell receives input from every cell (including itself) and from 
outside the net. Connections between cells in the same group are excitatory, and connections between 
cells in different groups are inhibitory. (This model is described in greater detail in [22].) Thus there 
are 18 variables of interest, nine for the input to each cell from outside the net, and nine for the 
output activity of each cell. (There is a 19th variable of interest: the decoupling factor, which determines 
how strongly the cells affect affect each other, and which may change over time.) INPUT  GROUP A 
GROUP B GROUP C Figure I. Diagram of the neural net that is used to generate sample data. Beyond listing 
the values of the variables at various points in the simulation, the natural way of displaying them would 
be to use a graph. Since all the data won't fit on one graph, we can distri- bute the data among several 
graphs. To avoid using too many graphs (which would result in a cluttered display surface--since its 
size is fixed), we can simplify the data by graphing the average values of the inputs and outputs for 
each group. So the system becomes one of six variables, which we may apportion as follows: (i) two graphs, 
one plotting the inputs from outside the net over time, and one plotting the outputs (Fig. 2); or (2) 
three graphs, each showing the the input and output for one group (Fig.3). (These are the best arrangements, 
since we should avoid more than three plots on one graph, because they would be too confusing-- even 
scheme (i) yields graphs that are a bit con- fusing.) As to which scheme is better depends on the pro 
 cessing task involved. Arrangement (1) is more task-compatible with observing the system behavior (the 
output variables) as a whole, since all the outputs are on the same graph; thus, it is easy to see that 
the system behaves so as to allow only one group to dominate at a time. With arrangement (2), this point 
is not so apparent; although the input- output relation is clearer, because the input and output plots 
for a given group are on the same graph. Furthermore, arrangement (2) is easier to read. We can improve 
on this with the display in Fig. 4. The encoding of the input and the output averages is through a combination 
of texture, length, and brightness (via dithering) coding; the identities of the data are encoded by 
position and color. In the display there are six bands of color, one color for each group; the top three 
bands code the input values, and the bottom three the output values. The thickness of the band and 
the number and density of lines in the band code the value of the variables at different points in time. 
 The display illustrates spatial compatibility in that the input and output displays of the groups 
are in the same order, and that order matches the order of the model description in Fig. i. The dis- 
play combines the advantages of the above two graphing schemes in that it is easy to see the sys- tem 
behavior as a whole, and it is easy to see the input-output relation for a given group (by merely mentally 
gating out the irrelevant colors). This style of display also facilitates comparison among different 
simulation runs, because it is easy to see the inputs and outputs as whole patterns. (Notice that the 
display of the decoupling factor is in the traditional graphical from. Because it is coded in a form 
distinctly different from the other variables, it is easier for the viewer to pick it out--illustrating 
the idea that unlike variables are better displayed in unlike ways.) However, all these displays obscure 
an important aspect of the model's behavior; what are the individual cells within a group doing? How 
can we display all 19 variables? We can use the data to drive an animated display, so that real time 
would code for simulation (clearly a conceptually com- patible coding). Figure 5 is a snapshot of such 
 a display, where the data is coded by a three-by- three array of shapes. The size of the shape is 
proportional to the value of the datum, and the shape's form indicates whether the input or the output 
of the cell is being displayed. The position of the shape identifies which datum is being dis- played 
(the three-by-three array is clearly spatially compatible with the model description in Fig. i). The 
squares encode the output values and the L-shapes encode the input values from out- side the net. (The 
L-shapes are supposed to give the impression of pushing and pulling at the edges of the squares--an 
attempt to make the coding conceptually compatible with the relationship of the inputs to the outputs.) 
The decoupling factor (not pictured in the figure) is displayed in the animation by a blinking line 
on a vertical scale, adjacent to the array of shapes. The rectangles that surround the shapes have 
a primarily aesthetic purpose (compare Fig. 6). They organize the cells into the three groups; they make 
the display more pleasing by providing a stable background for the changing shapes; and they accentuate 
the psychological impact of the shape sizes by providing a reference. (Since the maximum value an output 
could have would result in a square that would touch the rectangle's boundary, it becomes more evident 
when a the cells in a group are dominating the net, because they would be the only ones "filling up" 
the rectangle.) In order for the animation to move quickly, it is generated from a history data file, 
rather than by the simulation directly. This allows the modeller to re-view the display, play it at 
dif- ferent speeds, or look at one frame at a time. The effect of the animation is to see the shapes 
 swell and shrink in response to changes in the inputs; the result is a.clear intuition of how the 
model behaves. 5. CONCLUSION The purpose of this paper has been to give a feel for what makes a display 
effective. With such an understanding, we can iteratively follow a display design procedure that should 
result in higher quality displays. The procedure: (i) conceive of as many ways of visually encoding the 
data as possible; (2) use principles like those put forth in this paper to select and organize the ideas 
from (i) into an integrated display; (3) use and eval- uate the display to see if it satisfies our needs; 
 (4) if it doesn't, go back to step (1). If we find that no one display works, we can use a set of dis- 
plays (perhaps, different ones for different pur- poses). There are two main areas for future research. 
The first is based on the finding that as the cost of consulting an information source increases, our 
desire to use it decreases, even if it is a high quality information source. We need to be able to set 
up displays easily, so that we can explore a variety of ways of representing data. So, we need to continue 
development of easy-to-use computer graphics systems tuned to the data representation task. The second 
area of research revolves around the use of such a system. We should develop a repertoire of good display 
design examples (perhaps certified by experiment to be effective), which can suggest to programmers how 
they might attack their particular display problems. AC}[NOWLEDGES~NTS I wish to acknowledge the help 
of Michael A. Arbib in developing and expressing the ideas in this paper. REFERENCES i. Ashford, F. 
The Aesthetics of Engineering Design. Business Books, Ltd., London, 1969. 2. Barmack, J.E. and Sinaiko, 
H.W. Human factors in computer-generated displays. Institute for Defense Analysis, Research and Engineering 
Support Division, Study S-234, AD636170, April 1966.  3. Chapanis, A. Man-Machine Engineering. Wadsworth 
Publishing Co, Inc, Belmont, CA 1965  4. Chapanis, A. and Lindenbaum, L.E. A reaction time study of 
four control-display linkages. Human Factors 1(4): 1-7, 1959.  5. Chapanis, A. and Lockhead, G. A test 
of the effectiveness of sensor lines showing linkages between displays and controls. Human Factors .7(3): 
219-229, 1965.  6. Christ, R.E. Review and analysis of color coding research for visual displays. Human 
Factors 17(6): 542-570, 1975.  7. Donelson, W.C. Spatial management of infor-< mation. SIGGRAPH'78 Proceedings, 
August 23-25, 1978, Atlanta, GA (R.L. Phillips, Ed.)  8. Fitts, P.M. and Seeger, C.M. S-R compati- bility: 
spatial characteristics of stimulus and response codes. J. of Experimental Psych. 48: 199-210, 1953. 
 9. Foley, J.D. and Wallace, V.L. The art of natu- ral graphic man-machine conversation. Proc. IEEE 
62(4): 462-471, 1974.  i0. Goldstein, D.A. and Lamb, J.C. Visual coding using flashing lights. Human 
Factors 9(5): 405-408, 1967. ii. Hammer, C. and Ringel, S. Information assimi- lation from coded and 
uncoded individual and group displays. Hum. Fac. 7(3):245-255, 1965. 12. Hitt, W.D. An evaluation of 
five different abstract coding methods--Experiment IV. Human Factors 3(2): 120-130, 1961.  13. Hodge, 
D.C. Legibility of uniform-strokewidth alphabet: I. Relative legibility of upper and lower case letters. 
J. of Experimental Psych. i: 34-46, 1962.  14. Huntley, M.S. Task complexity and serial per- formance 
under steadily increasing input rates. Human Factors 14(1): 65-75, 1972.  15. Jones, M.R2 Color coding. 
Human Factors '4(6): 355-365, 1962.  16. Kanarick, A.F., et al. Multi-source informa- tion acquisition 
with optional stopping. Human Factors ii: 379-385, 1969.  17. Martin, J. Design of Man-Computer Dialogues. 
Prentice-Hall, Inc, Englewood Cliffs NJ, 1973.  18. McCormick, E.J. Human Factors Engineering. McGraw-Hill, 
1970.  19. Meister, D. Behavioral Foundations of System Development. Wiley Interscience, New York, 1976 
 20. Miller, G.A. Th 9 Psychology of Communication. Penguin Books, Inc, Baltimore, MD, 1967.  21. Miller, 
J. Adjusting to overloads in infor- mation. (from) Waggoner, R.W. and Car~k, D.J.  (Eds.) Disorders 
of Communication. Research Publications, Assoc. for Research in Nervous and Mental diseases, 42: 87-100, 
1964.  22. Morse, A. and Kilmer, W. A neural net capable of competitive and cooperative computation. 
Biol. Cybern. 30(1): 1-6, 1978.  23. Pollack, I. Detection of changes in spatial position: IV. Multiple 
display fields, display aiding and interference. H~im~n Factors 16(2): 93-116, 1974.  24. Posner, M.I. 
Information reduction in the analysis of sequential tasks. Psych. Review ~i: 491-504, 1964.  25. Roscoe, 
S.N. Airborne displays for flight and navigation. Human Factors 10(4): 321-332, 1968.  26. Schutz, H.G. 
An evaluation of formats for graphic trend displays--Experiment II. Human Factors 3(2): 99-107, 1961. 
 27. Schutz, H.G. An evaluation of methods for present&#38;tion of graphic multiple trends-- Experiment 
III. Human Factors 3(2): 108-119, 1961.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807430</article_id>
		<sort_key>102</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[The Number Wheel]]></title>
		<subtitle><![CDATA[A tablet based valuator for interactive three-dimensional positioning]]></subtitle>
		<page_from>102</page_from>
		<page_to>107</page_to>
		<doi_number>10.1145/800249.807430</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807430</url>
		<abstract>
			<par><![CDATA[<p>A logical valuator device which provides interactive graphical input of numeric values is presented. This device, called the <italic>Number Wheel,</italic> was developed for interactive control of highly dynamic three-dimensional displays but is not limited to this use: It is a general purpose valuator device. The implementation of the Number Wheel described here is based upon a digitizer tablet as the physical input device.</p> <p>The character of the Number Wheel is best explained by developing an analogy with a hypothetical physical device. The Number Wheel can be thought of as a wheel which has a portion of its circumference, or tread, protruding through a slot on the surface of the tablet, somewhat like a giant thumb wheel. Each value in the desired range of the valuator is represented by a point on the circumference of the wheel with the value of the device at any given time being the point at the top of the wheel. The valuator is changed by putting the pen on the wheel where it protrudes through the tablet and moving it back or forth in the direction of rotation. Whenever the pen leaves the rim of the wheel while still moving, the Number Wheel maintains the same speed of rotation until the pen returns to the wheel in order to change or stop its movement.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3-D dynamic graphics]]></kw>
			<kw><![CDATA[Graphic display]]></kw>
			<kw><![CDATA[Graphic input]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
			<kw><![CDATA[Interactive input]]></kw>
			<kw><![CDATA[Logical input device]]></kw>
			<kw><![CDATA[Numeric value input]]></kw>
			<kw><![CDATA[Real-time graphics]]></kw>
			<kw><![CDATA[Tablet input]]></kw>
			<kw><![CDATA[Valuator input device]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333472</person_id>
				<author_profile_id><![CDATA[81100443001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Thornton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie-Mellon University, Pittsburgh, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Brenner, A. E. and de Bruyne, P. A sonic pen: a digital stylus system. IEEE EC-19, 6 (June 1970), 546.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807394</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Britton, E. G., Lipscomb, J. S., and Pique, M. E. Making nested rotations convenient for the user. Proceedings SIGGRAPH 78: Fifth Annual Conference on Computer Graphics and Interactive Techniques, ACM - SIGGRAPH, August, 1978, pp. 222-227.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906996</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burton, R. P. Real-time measurement of multiple three-dimensional positions. Ph.D. Th., University of Utah, 1973.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360329</ref_obj_id>
				<ref_obj_pid>360303</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H. Designing surfaces in 3-D. Comm. ACM 19, 8 (August 1976), 454-460.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[English, W. K., Englebart, and D. C., Berman, M. L. Display-selection techniques for text manipulation. IEEE Transactions on Human Factors HFE-8, 1 (1967), 5.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. A graphical technique for numerical input. Computer Journal 11 (May 1968), 63-64.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Thornton, R. W. MODEL - Interactive modelling in three dimensions through two-dimensional windows. Master Th., Cornell University, January 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563739</ref_obj_id>
				<ref_obj_pid>563732</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Trambacz, U. Towards device independent graphics systems. Proceedings SIGGRAPH 75: Second Annual Conference on Computer Graphics and Interactive Techniques, ACM - SIGGRAPH, Spring, 1975, pp. 49-52.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>804734</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wallace, V.L. The semantics of graphic input devices. Proceedings ACM Symposium on Graphic Languages, ACM - SIGGRAPH/SIGPLAN, Spring, 1976, pp. 61-65.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Number Wheel. A Tablet Based Valuator for Interactive Three-Dimensional Positioning Robert W. Thornton 
1 Carneg,e-Mellon Umverslty Pittsburgh, Pennsylvania A logical valuator device which provides interactive 
graphical input of numeric values is presented. This device, called the Number Wheel, was developed for 
Interactive control of highly dynamic three-dimensional displays but is not limited to this use: It Is 
a general purpose valuator device. The Implementation of the Number Wheel described here Is based upon 
a digitizer tablet as the physical Input device. The character of the Number Wheel is best explained 
by developing an analogy with a hypothetical physical device. The Number Wheel can be thought of as a 
wheel which has a portion of its circumference, or tread, protruding through a slot on the surface of 
the tablet, somewhat like a giant thumb wheel. Each value in the desired range of the valuator Is represented 
by a point on the circumference of the wheel with the value of the device at any given time being the 
point at the top of the wheel. The valuator is changed by putting the pen on the wheel where it protrudes 
through the tablet and moving It back or forth In the direction of rotation. Whenever the pen leaves 
the rim of the wheel while still moving, the Number Wheel maintains the same speed of rotation until 
the pen returns to the wheel In order to change or stop its movement. Key Words and Phrases~ graphic 
display, graphic Input, Interactive graphics, interactive input, logical Input device, numeric value 
input, real-time graphics, tablet input, valuator Input device, 3-D dynamic graphics CR Categorles~ 3.9, 
4.41, 6.35, 8.2 1. Introduction The Number Wheel Is a graphic Input device whose development was motivated 
by the need for accurate and convenient Interactive control over dynamic displays of three-dimensional 
shapes such as rotation or other animated motion. The Number Wheel Is a logical valuator device (allowing 
Input of a numerical value) whose implementation is based upon a Iocator device (which allows Input of 
locations In a space of one or more dimensions) 2. A group of Number Wheels Is used to control the three-dimensional 
display by associating a particular Number Wheel's value with each of the view parameters under control 
such as angles of rotation, location of viewpoint, angle of view, etc.: as the user changes a Number 
Wheel's value the three-dimensional display Is updated In conjunction with the new value of the associated 
view parameter. As stated before, the Number Wheel Is based on a Iocator device. This Iocator may be 
either the relative positioning type, such as a "mouse" (see [5]), or the absolute type, such as a digitizer 
tablet. Most multi-dimensional Iocators such as two-dimensional tablets, the mostly one-of-a-kind three-dimensional 
digitizers (see [4] for mechanical, [1] for sonic, or [3] for LED based examples), or many-dimensioned 
remote manipulators might be used effectively for controlling sets of Number Wheels. The only additional 
requirements for the Iocator are that updated locations must be available many times per second (60 per 
second is commonly used, 20 per second Is adequate) and there must be a switch for the user to turn this 
stream of locations on or off (such as a function button on a "mouse" or the pen-point switch found on 
many 1Mailing address: Robert W. Thornton, Carnegie-Mellon University, SUPA - Schenley Park, Pittsburgh, 
PA 15213, USA. 2For a discussion of logical graphic input devices and a description of various classes 
of such devices, see, for example, [8, g], &#38;#169; 1979 ACM O-89791-004--4/79/0800--102 $00.75 See 
Copyright Pg. 102 tablets). The description of the Number Wheel as presented here will assume the use 
of a tablet-pen Iocator. This input device has the ability to provide many forms of Input through a single 
physical device and Is available at a relatively low cost. 2. Functionality Figure 1 : Hypothetical 
physical analogy of the Number Wheel The character of the Number Wheel Is best explained with the use 
of a physical analogy: by describing a hypothetical device which operates In s fashion similar to the 
logical Number Wheel device. It Is from this physical analogy that the name "Number Wheel" Is derived. 
The Number Wheel can be thought of as a wheel which has s portion of Its circumference protruding through 
a slot on the surface of the tablet, somewhat like s giant thumb wheel, as Illustrated in Fig. 1. Each 
value In the desired range of the valuator Is represented by a point on the circumference of the wheel 
with the value of the device at any given time being the point at the top of the wheel. The valuator 
Is changed by putting the pen on the wheel where It protrudes through the tablet and moving It back or 
forth In the direction of rotation. Whenever the pen leaves the rim of the wheel while still moving, 
the Number Wheel mslntalns the same speed of rotation (I.e. rate of change In value) until the pen returns 
to the wheel In order to change or stop Its movement. The number of discrete values possible for the 
portion of the Number Wheel's rim which Is accessible through the surface of the tablet at a given Instant 
Is limited by the resolution of the tablet. However, the resolution of the Number Wheel over Its entire 
range Is not limited by the tablet and Is adjustable by varying the size (diameter) selected for the 
hypothetical wheel. Since the wheel has no mass (and hence no momentum) and Is mounted on frlctlonless 
bearings, It Is very easy to push the wheel and start It rotating very quickly. It can also be stopped 
"on a dtme" when a desired value Is reached. Thus It Is possible to make gross changes In a Number Wheel's 
value very quickly yet also perform precise selections of value st the level of the valuator's pre-determlned 
resolution. Figure 2: Analogical Number Wheel with different size and orientation. Where the Number 
Wheel Illustrated In Fig. 1 Is manipulated by moving the pen forward and backward over e narrow window 
on the tablet, the size, shape, and location of the window through which s Number Wheel protrudes may 
vary for different uses. Figure 2 Illustrates a Number Wheel which covers the entire surface of the tablet 
in addition to having a different direction of rotatlon: It is changed by moving the pen left and right. 
Other alternatives might Include several separate Number Wheel's each accessible through separate windows 
on the tablet at the same time, or even more than one Number Wheel available simultaneously through the 
same tablet window, each with a different direction of rotation.  3. Examples An example of how Number 
Wheels might be used will be developed by continuing with the physical analogy Just presented. Going 
back to the original need expressed for developing the Number Wheel, one can be configured for Interactlvely 
controlling the rotation of a three-dimensional object being displayed. Using the Number Wheel Illustrated 
In Fig. 2 and assigning the values from zero to 359 around the circumference of It, the current value 
(the number at the top) of this Number Wheel can be used to Indicate 103 the angle of rotation, In 
degrees, of the three-dimensional object on display about the y-axis. Figure 3: Number Wheel used to 
control rotation of object about y-axis. The hypothetical physical mechanism which we are modeling for 
tills application Is Illustrated In Fig. 3. There Is a three-dimensional object In front of us which 
is connected with the Number Wheel by a flexible cable through Its y-axis. As the wheel Is rotated with 
a left or right movement of the pen, the object rotates In a direction and speed corresponding to the 
movements of the pen. In a similar manner, a Number Wheel with Its axis turned 90 degrees so that it 
rotates with a forward/backward motion might be used to control the rotation of the three-dimensional 
object about the x-axis. Another hypothetical mechanism which illustrates this action Is shown In Fig. 
4. This could be carded further by placing both of these Number Wheels In the same tablet window at the 
same time so that any combination of forward/backward and left/right movements can provide a desired 
combination of rotations about the x and y axes (Illustrated In Fig. 5). Similarly, other Number Wheels 
may be defined which control other parameters of the display transformation, such as translations In 
various directions, angle of vision, positioning of section planes, or for the arbitrary axis rotations 
as presented In [2]. Flgure 4; Hypothetlcal mechanlsm controlllng x-axls rotatlon. Figure 5: Hypothetical 
mechanism controlling combined x and y axes rotations.  4. Implementation This section describes one 
particular way of Implementing Number Wheels which has been found to 104 be capable and flexible. There 
are, however, many other approaches which could be taken to provide different features. A following section 
suggests some of these varlat=ons and extensions. Implementing a particular Number Wheel Is fairly straight 
forward. A procedure to update an active Number Wheel must be performed at each time interval (e.g. 1/60 
second). If the pen Is down on the rim of the wheel (I.e. surface of the tablet) then the incremental 
change for the Number Wheel must be recalculated by taking the relative change In position of the pen 
since the last time period (If the pen was also down last time) and scaling It by a value which provides 
the desired amount of resolution over the Number Wheel's range. The current Incremental change (possibly 
zero) Is then added to the current value of the Number Wheel. At this time the value must also be tested 
to see If It has reached one of the limits of the valuator's defined range. If It has, there are at least 
two possible courses of action: Reset the Number WheePs value to Its opposite limit and allow It to continue 
changing In the same direction (wrap around). This Is similar in result to a continuous-turn rotary type 
potentlometer. This type of action might be used for a valuator which controls the angle of rotation 
about a particular axis of an object on display. The maximum end minimum might be 35g degrees and zero 
degrees so when the Number Wheel Is pushed up to and past 35g degrees, the object will continue rotating 
In the same manner as the valuator wraps around to zero. Simply stop changing the value of the Number 
Wheel; leaving it at the limit until such time that it is turned back In the opposite direction. This 
type of action might be used for a valuator which Is controlling the angle of vision for a three-dimensional 
display. For example, the maximum and minimum values might be 17g degrees and one degree. When the user 
pushes the Number Wheel to zoom in on the object, it stops upon reaching one degree and the only available 
action is to zoom back out. The current value of the Number Wheel may be used as required In calculating 
a display update or otherwise. For most applications, more than one Number Wheel will be used. Additional 
logic must then be provided to determine which Number Wheel (or gang of Number Wheels, If two or more 
are to be controlled simultaneously In the same area of the tablet) the pen Is currently controlling, 
and/or switches to control which set of Number Wheels is available through the surface of the tablet 
at any given time. To make tt ~'asy to Implement Number Wheels for different programs and make It a simple 
process to add Number Wheels or dynamically change existing Number Wheels (perhaps with another Number 
Wheel controlling one of Its parameters!) in a running program, this Implementation has a generalized 
design. A table Is utilized to hold the parameters which define the characteristics of the Individual 
valuators, In addition to the few variables required In the operation of each, such as the current value 
of the Number Wheel, whether It Is currently active (at the surface of the tablet) or not, the Incremental 
change, etc. All that is required to add a new Number Wheel or change the character of an existing one 
Is to add or change an entry In this table. A set of six parameters has been selected which allow simple 
specification of a large class of different Number Wheels. They are: - The minimum value allowed for 
the range of the Number Wheel. - The maximum value In the range.  The number of units of resolution 
In the valuator's range or distinct steps between the minimum and maximum values. It should be noted 
that the resolution of the physical Input device does not limit this parameter or the two previous ones: 
they are only limited by the numerical representation used In the calculations. The number of units of 
resolution on the Input dovlce which are to correspond to one of the above defined units of resolution 
of the logical valuator. This parameter, In conjunction with the previous one establishes the ratio between 
the physical distance the pen Is moved and the amount that the valuator changes. The type of limit condition 
desired. The choices for this are either "wrap around" or "stop", explained earlier In this section. 
 - An indication of whtch controlling variable Is to be used. This variable controls the Incremental 
change used In updating the Number Wheel and will normally be the change In the pen's location, from 
one time period to the next, In either the x or y direction. It might also be desirable to Identify 
a particular window or sub-area of the tablet through which each particular Number Wheel appears. However, 
experience has shown that It Is usually more convenient for each Number Wheel to cover the entire surface 
of the tablet with the added provision of a set of logical buttons with which the user may select one 
or two of a set of Number Wheels to be available on the tablet at any given time. This frees a user of 
the need to put the pen down on a particular area of the tablet while using a Number Wheel; allowing 
one to concentrate on viewing the display as opposed to worrying about the location of the pen on the 
tablet. This might seem a small point but it adds to the ease of use or habitability of the system and 
thus Improves the ability to quickly gain a complete perception of the three-dimensional forms being 
displayed. Additional details and more complete descriptions of use of the Number Wheel may be found 
In [7]. 5. Extensions In addition to Its application to dynamic three-dimensional positioning, the Number 
Wheel will function well for many other uses as a general Interactive valuator device. An even larger 
class of valuators Is possible using the same basic logic described here for the Number Wheel by expanding 
the dimensions of variation described earlier. Examples of these variations are; Use of controlling variables 
other than the change In x or y position of a pen on tablet to calculate the incremental change for the 
valuator. These might Include the absolute pen coordinates (as opposed to relative to the previous position), 
'the change in x or y position modified by some non-linear function to provide a wider range of velocities 
of change, or values obtained from other physical devices such as remote manipulators, rotary potentlometers, 
or Joysticks: providing an extra level of flexibility over the physical devices. An additional definitional 
parameter could be used to apply braking to a freely rotating Number Wheel. This might be thought of 
as specifying the amount of friction In the bearings of the wheel, going back to the previously made 
physical analogy of the Number Wheel. This would control the amount of time required for a Number Wheel 
to slow to a stop when left rotating. In addition to the above friction parameter, It might be des&#38;able 
to have a spring return which pulls the valuator back to a "home" posltlon when released. Additional 
alternative responses to reaching a Number Wheel's range limit might be provided, such as switching the 
direction of change, or "bouncing back" In the opposite direction when a limit Is reached. Finally, for 
some applications It might .even be helpful to be able to define a non-continuous range over which the 
valuator may operate.  6. Summary For the interactive control of three-dimensional positioning, for 
which the Number Wheel was originally designed, It has proven to be a very convenient and flexible device, 
overcoming many of the limitations found in previously used logical valuators (such as logical slide 
potentlometers, rate controls, or the well known "Light Handle" [6]) and physical valuators (such as 
potentlometers or joysticks), Characteristics of the Number Wheel contributing to its success Include: 
-The resolution is limited only by the numerical representation used. -Gross changes In value can be 
made quickly and easily. There is a capacity for easy "fine tuning" of specific values at the level of 
the Number Wheel's resolution. Smooth and continuous change of value many times per second are provided 
for controlling updates of a dynamic display. - There Is s choice of how the limit condition Is handled, 
something not found 106 in most physical devices. A particular rate of change may be set initially 
which Is automatically continued Indefinitely without further action from the user. There ;s a close 
correspondence between the numerical value being changed and the physical movements required by a user 
to control such change. This Is provided In three manners: when the pen Is on the tablet the value changes 
when the pen moves and not when it Is still (as Is done In tablet based valuators which control the rate 
of change), the value can change in a direction which corresponds to the direction of pen movement, and 
the value changes at a speed relative to the speed of the Initiating pen movement. Interactive control 
of a dynamic numeric value does not require the constant attention of the user to the fact that he Is 
controlling a numeric value as such. The use of Number Wheel controls Is easily learned and feels "natural" 
to the user: desired results are obtained with speed and ease. Many uses of computer graphics to display 
projections of three-dimensional shapes are to Impart some additional perception of the actual three-dimensional 
form to a human user. It is common to use several cues In trying to enhance this three-dimensional perception, 
such as perspective projection, decreasing Intensity of lines with their distance from the observer position, 
removing hidden lines, and shaded surface displays. Even with all of these static three-dimensional cues, 
the single most effective aid to spatial perception is a user's ability to Interactively animate movement 
of the object as he might desire. The extent to which the user can accurately and naturally control such 
motion can have a large effect upon the user% complete perception of the three-dimensional space. The 
use of the Number Wheel can help shorten this step to complete perception. References 1. Brenner, A. 
E. and de Bruyne, P. A sonic pen: a digital stylus system. IEEE EC-19, 6 (June lg70), 546. 2. Britton, 
E. G., Llpscomb, J. S., and Pique, M. E. Making nested rotations convenient for the user. Proceedings 
SIGGRAPH 78: Fifth Annual Conference on Computer Graphics and Interactive Techniques, ACM - SIGGRAPH, 
August, 1978, pp. 222-227. 3. Burton, R. P. Real-t/me measurement of multiple three-d/mens/onal positions. 
Ph.D. Th., University of Utah, 1973. 4. Clark, J. H. Designing surfaces In 3-D. Comm. ACM 1 9, 8 (August 
1976), 454-460. 5. English, W. K., Englebart, and D. C., Berman, M. L. Display-selection techniques 
for text manipulation. IEEE Transactions on Human Factors HFE-8, 1 (1967),  5. 6. Newman, W. M. A graphical 
technique for numerical Input. Computer Journal 11 (May 1968), 63-64. 7. Thornton, R. W. MODEL -Interactive 
modelling In three dimensions through two-dimensional windows. Master Th., Cornell Unlversit;y, January 
197F. 8. Trambacz, U. Towards device Independent graphics systems. Proceedings SIGGRAPH 75: Second Annual 
Conference on Computer Graphics and Interactive Techniques, ACM -SIGGRAPH, Spring, 1075, pp. 49-52. 
9. Wallace, V. L. The semantics of graphic input devices. Proceedings ACM Symposium on Graphic Languages, 
ACM -SIGGRAPH/SIGPLAN, Spring, 1976, pp. 01-65.  107  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807431</article_id>
		<sort_key>108</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Graphical human interface to a neutral beam system]]></title>
		<page_from>108</page_from>
		<page_to>112</page_to>
		<doi_number>10.1145/800249.807431</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807431</url>
		<abstract>
			<par><![CDATA[<p>A color graphics system has been designed and implemented as the human interface to a 120KV, 60 amp neutral beam source being built at Lawrence Berkeley Laboratory for Tokamak Fusion Test Reactors. The system is based upon a 64 &#215; 64 touch panel and allows a number of control and high level analysis displays to be brought up on any of three monitors. Included among the displays are a &#8220;Super-oscilloscope&#8221; package, a data acquisition timing package, numerical control displays and pictograms. The system succeeds in being very friendly and easy to learn for the operator. All control is via the touch panel and a set of six knobs and two keypads.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Graphics portability]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
			<kw><![CDATA[Operator interface]]></kw>
			<kw><![CDATA[Process control]]></kw>
			<kw><![CDATA[Touch panel]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309426100</person_id>
				<author_profile_id><![CDATA[81541849356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jerry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fiddler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334187</person_id>
				<author_profile_id><![CDATA[81100397510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Victor]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GRAPHICAL HUMAN INTERFACE TO A NEUTRAL BEAM SYSTEM Jerry Fiddler and Victor Elischer Lawrence Berkeley 
Laboratory Berkeley, California 94720 ABSTRACT A color graphics system has been designed and implemented 
as the human interface to a 120KV, 60 amp neutral beam source being built at Lawrence Berkeley Laboratory 
for Tokamak Fusion Test Reactors. The system is based upon a 64 x 64 touch panel and allows a number 
of control and high level analysis displays to be brought up on any of three monitors. Included among 
the displays are a "Super-oscilloscope" package, a data acquisition timing package, numerical control 
displays and pictograms. The system succeeds in being very friendly and easy to learn for the operator. 
All control is via the touch panel and a set of six knobs and two keypads. Key words and phrases: Computer 
graphics, Touch panel, Operator interface, Process control, Interactive graphics, Graphics portability. 
 CR Classifications: 3.17, 3.24, 3.82, 6.35, 8.2 INTRODUCTION One of the engineering challenges inherent 
in the design of a magnetic confinement fusion reactor is the design for a neutral beam suitable to keep 
the plasma energy high enough to begin and continue fusion. The beam is composed of high energy hydrogen 
or deuterium atoms and is injected through the magnetic field into the contained plasma. LBL is designing 
and testing high power neutral beam sources destined to be used at Princeton in the Tokamak Fusion Test 
Reactor and at General Atomics in Doublet III. An operator control system wasrequired for the beams and 
for the test stand. The operator interface design problem is a common one: how best to present large 
amounts of information about a com- plex system to a haman operator without over- loading him, and to 
receive instruction from the operator about the system's operation. Since the system is a new one, the 
problem is compounded by the fact that the kinds of information the operator will want to communicate 
with the system about are not exhaustively known, so the need for the ability to change the interaction 
is acute. A major factor in the design was that the operators who will use the system are rather "anti-computer", 
having worked with less than friendly systems in the past. To entice these operators, then, it was 
important to make the system responsive, fun, quickly learnable and visually attractive. Since it 
is likely that a number of dif- ferent persons will be writing displays, it was important that applications 
programmers be able to create some analysis displays relatively easily, without worrying about low level 
graphics, data acquisition or unit conversion. The inter- face to the application programs needed to 
be as simple and "bomb-proof" as possible. Finally, the system needed to be fairly transportable and 
easily expandable to include, for instance, multiple CPU's. The end product visible to the user is a 
set of three CRT's, one equipped with touch panel, on which several types of display are available. Control 
displays are available to control both the neutral beam and the display system itself. Pictogram, numerical 
and higher level analysis displays show the operator the state of the beam and its various subsystems. 
The operator need not be concerned at all with the fact that there is a computer handling his interaction 
with the neutral beam. His view of the system is com- pletely graphical, and all his control of the system 
takes place from the touch panel on a set of menu type displays. HARDWARE CONFIGURATION The hardware 
layout breaks down logically into three sections; the main computer, a Modcomp IV/35 with 256K of memory, 
the graphics output hardware, and the graphical input hardware. The three subsystems connect together 
in a simple, standard, modular manner, allowing replacement of any of the three with minimum system 
perturbation. Graphics Output System Graphics output is handled by a Grinnell graphics controller driving 
three CRT's, two B&#38;W and one color. The resolution is 512 x 512 on each, with four shades of grey 
available on the B&#38;W's and sixteen colors selected from a palette of 4096 on the color monitor. The 
Grinnell receives its data from the computer via a simple block transfer. &#38;#169; 1979 ACM O-89791-004--4/79/0800--108 
$00.75 See Copyright Pg. 108 NEUTRAL BEAM SOURCE OPERATOR INTERFACE ~ GRIkJNELL, = OUTPUT ,p OA*A INTE 
R/~[[~ ATE LA~GU/'~E T~KTRONIX4014 fN~O~ S~MULATOR OT*/ER APPtlCAT~V TEKrR'OA/I x "d. coc~ LI L- I 
r~ "C2Ln I INTERACTIVg I r i i APPLICATION I B ON IRO L I~E5 I ~ P~G~ l --/ /'~ --~ _ . 1 I ~*[ Ab40A;~ 
0 I. NPL2T" J I I DEMULT PLEXE, R ,L ~ ------~ I PORT J t ...... I 7RAhtS~.,aT~ R ~ ~~ _ _ _ .J , L 
.... J '~ ~" ..... ER "lP P"--L I C AT I C"~N Ap~ol~CATIOM OISDLAY T~SK KEYBOARD MODCOMP I~/~5  Figure 
1 Graphical Input System  The input hardware was all designed at LBL, except for the Intel 80/20 which 
acts as the input system controller. The Intel microcomputer communicates with the main computer via 
a single 9600 baud RS232 link. This makes debugging either the host computer input or the micro computer 
output quite convenient, since a standard terminal can simulate either when debugging the other. This 
also promotes portability of the input system to any host computer. All operator input devices are attached 
to the micro. Several types of devices have been imple- mented. Calculator-style keypads allow simple 
numerical entry, but are used quite rarely. Knobs are also available. When a knob is turned or a keypad 
pressed, an ASCII string describing the event is sent to the host computer by the Intel Knobs are generally 
used for moving a cursor or display window, or for adjusting numerical values. Associated with each knob 
is a Burroughs Self-Scan display which can be used, by the program currently receiving knob data, to 
label the knob. A string sent from the host computer to the micro causes a label to be written. Although 
the capability to add a keyboard has been built into the system, there is currently none plugged in, 
nor is one anticipated. The most ~mportant input device is the touch panel. This consists of two transparent 
sheets of mylar, each deposited with a thin film of gold and scribed into 32 conductive strips. This 
is placed over a CRT screen, allowing the operator to touch the image and cause an event in the computer. 
When the touch panel is pressed, a string indicating the location of the center of of the hit is sent 
by the micro to the host computer. The micro also provides audible feed- back. Although the capability 
has been built into the system to handle many touch panels, knobs, keypads and a keyboard, we have found 
that a single touch panel and a set of four knobs is adequate for all the control and input for our system. 
By limiting the control to a small set of very powerful devices, the operator's con- fusion can be minimized 
and his interaction with the system made rapid and consistent. Input System Microcomputer While a discussion 
of the internals of the microcomputer's firmware is beyond the scope of this paper, the range of its 
functions should be  109 noted All the complex input functions are trans- lated to simple ASCII strings, 
ready for the Modcomp simply to read. For the touch panel, all the scannfng, debouncing, translation 
and finding the center of a hit are handled by the micro's firmware. Most importantly, all the input 
devices are multiplexed and a single, simple consistent interface is presented to the main computer. 
This allows for simple expansion of the number and types of input devices used. Using ASCII strings as 
the interface mode allows very simple transportability to a different host computer, and allows the use 
of a maximum amount of existing system software for string interpre- tation and manipulation. SOFTWARE 
 The system structure is diagrammed in figure i~ The application task interfaces to the outside world 
through several packages of subroutines. The application programmer need only be concerned with high 
level graphics and graphical input. Graphics Output  The graphics library is an extended form of TCS, 
Tektronix's graphics package. This pack- age provides fairly low level graphics support, allowing one 
to draw lines, points and characters. TCS is well supported and widely used. We have extended TCS to 
take advantage of the added capabilities of the Grinnell graphics controller, such as color. In the future, 
we hope to switch to a more advanced graphics package which will allow more advanced capabilities, such 
as 3-D and segmentation. A major problem with TCS, and with most graphics packages, is the lack of run 
time de- vice independence. At best, many packages allow one to select from among a choice of output 
device types at link time. TCS outputs Tektronix display code To allow run time device selection, and 
to allow us to use the Grinnell controller with TCS, an output symbiont was written. A symbiont is a 
Modcomp artifact, a task to which one can read or write as if it were a device. The function of this 
particular symbiont is to translate some graphics device dependent code to another device dependent code. 
In its present form, it consists of a 4014 simulator on its input, which translates Tektronix display 
code into a more general intermediate language, and a Grinnell output section which translates the intermediate 
language into Grinnell display code. Any number of input simulators and output drivers may be added, 
allowing run time device selection among graphics devices with different properties, even though using 
a device dependent graphics package. Another major advantage of using the symbiont approach is that when 
we change graphics packages we can use the new package's Tektronix output driver, rather than writing 
our own Grinnell dr~ver. Graphical Input  Input from the touch panel, knobs, keypads and/or keyboard 
is all multiplexed over a single RS232 line. This line is read, through the system asynch handler, by 
an input demultiplexor and translation task. This task breaks up the single stream into a number of logical 
streams, one for each input device. Devices are assigned on an individual basis to application tasks 
requesting them. The demultiplexor task communi- cates with the applications tasks through an intertask 
message service over virtual circuits, allowing a much more flexible interface than the standard I/O 
system. Additionally, this task receives self-scan labeling requests from the applications tasks and 
ships them out to the appropriate knob label, via the microcomputer. An input interface library to which 
the applications task links takes care of trans- lation of the message format coming from the input demultiplexor, 
formats and sends self-scan labeling requests to the demultiplexor, and handles general message protocol 
with the de- multiplexor. The applications program is simply told, "Knob 4 was turned 5 ticks to the 
right," or whatever. Buttons The logical button routines comprise a package of higher level routines 
which handles touch panel input translation. The applications code creates a logical button on the screen 
with a call to MAKE BUTTON. This call specifies the location and size of the button, in pixels, and whether 
or not to indicate the button's existence by drawing a border around it, coloring it in or writing some 
text in it. This call also assigns to the button an ID number. When the touch panel is pressed in the 
area defined as the button, the applications task is notified that the button has been pressed. The button 
package returns the assigned ID of the button to the task. By default, the button package also provides 
visual feedback to the operator that the button has been pressed by drawing a thick border around it. 
This can be disabled by the calling program if desired. The micro- computer supplies audible feedback 
using a beeper. The button package also translates between screen pixel coordinates and touch panel coordinates 
using variables stored on disc indicating their relationship. The operator may at any time align the 
touch panel to the screen by changing these variables using a simple "Press the dot" program. EXAMPLE 
DISPLAYS Figure 2 shows the system. By pressing buttons on the central menu, the operator can call any 
display on to any screen, or can call other displays to replace the menu display. Below the CRT's are 
knob panels labeled with self-scan displays. As one can see from the picture, the position of the displays 
currently requires one to reach up to press a button. Hopefully, the CRT's will soon be moved into a 
more convenient arrangement. Two sample display programs are shown in figures 3-8. Figures 3-5 are photographs 
of the Timing Control program. All the system timing is generated by programmable pulse  ii0   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807432</article_id>
		<sort_key>113</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[The semantics of graphical input]]></title>
		<page_from>113</page_from>
		<page_to>120</page_to>
		<doi_number>10.1145/800249.807432</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807432</url>
		<abstract>
			<par><![CDATA[<p>Any graphical input device may be represented by a data structure, modified from time to time by actions in response to certain events, and the ability to cause certain events as part of its repertoire of actions. Portions of a device's state may be made visible to other devices in a controlled way, and the remainder hidden. Conversely, a device may make use of the visible portions of another device's state. Typically, the pattern of device interaction forms a hierarchy, but no device is part of any other. This provides for the interchangeability of a single device with a group of devices, and allows a single device to support the function of several others. Device independence is thus enhanced without the usual sacrifice of human factors considerations.</p> <p>A group of devices defined in this manner can simulate any group of devices defined in the usual manner. Conversely, useful groups of devices may be defined, which cannot conveniently be simulated by the usual input semantics. The proposed semantic is thus more complete, and provides the additional benefit of a uniform language for describing both physical and virtual devices.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Abstract data types]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Device independent graphics]]></kw>
			<kw><![CDATA[Graphics input]]></kw>
			<kw><![CDATA[Graphics input tools]]></kw>
			<kw><![CDATA[Hierarchical systems]]></kw>
			<kw><![CDATA[Human factors]]></kw>
			<kw><![CDATA[Information hiding]]></kw>
			<kw><![CDATA[Modularity]]></kw>
			<kw><![CDATA[Semantics of action]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>D.3.1</cat_node>
				<descriptor>Semantics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011006.10011039.10011311</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Formal language definitions->Semantics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010124.10010131</concept_id>
				<concept_desc>CCS->Theory of computation->Semantics and reasoning->Program semantics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010124</concept_id>
				<concept_desc>CCS->Theory of computation->Semantics and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31071425</person_id>
				<author_profile_id><![CDATA[81100109760]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Anson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anson, E. Some aspects of the design of interactive data structures. Computer Graphics Group technical report, Nijmegen University, Nijmegen, The Netherlands, June 1976.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Anson, E. GPGS-370 device driver specifications. Computer Graphics Group technical report, Nijmegen University, Nijmegen, The Netherlands, July 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Anson, E. GPGS-370 Tektronix driver installation. Computer Graphics Group technical report, Nijmegen University, Nijmegen, The Netherlands, July 1976.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807394</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Britton, E.G., Lipscomb, J.S., and Pique, M.E. Making nested rotations convenient for the user. Proc. SIGGRAPH '78 (Computer Graphics) 12,3 (Aug. 1978), 222-227.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Caruthers, L.C., and Van Dam, A. General Purpose Graphic System: User's Tutorial. Computer Graphics Group technical report, University of Nijmegen, Nijmegen, The Netherlands, 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[DeFanti, T.A. Toward loopless interactive graphics programming. Proc. Conference on Computer Graphics, Pattern Recognition, and Data Structures, IEEE Catalog No. 75CHO981-1C, May 1975, pp. 352-355.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>550359</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dijkstra, E.W. A Discipline of Programming. Prentice-Hall, Englewood Cliffs, New Jersey, 1976.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Foley, J.D., and Wallace, V.L. The art of natural man-machine conversation. Proc. IEEE 62, 4 (April 1974), 462-471.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Geyer, K.E., and Wilson, K.R. Computing with feeling. Proc. Conference on Computer Graphics, Pattern Recognition, and Data Structures, IEEE Catalog No. 75CH0981-1C, May 1975, pp. 343-349.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hoare, C.A.R. Notes on data structuring. In Structured Programming, Dahl, O.-J., Dijkstra, E.W., and Hoare, C.A.R., Eds., Academic Press, New York, 1972, pp. 83-174.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359585</ref_obj_id>
				<ref_obj_pid>359576</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hoare, C.A.R. Communicating sequential processes. Comm. ACM 21,8 (Aug. 1978), 666-677.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Liskov, B.H., and Zilles, S.N. Specification techniques for data abstractions. IEEE Transactions on Software Engineering 1, 1 (March 1975), 7-19.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359789</ref_obj_id>
				<ref_obj_pid>359763</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Liskov, B., Snyder, A., Atkinson, R., and Schaffert, C. Abstraction mechanisms in CLU. Comm. ACM 20, 8 (Aug. 1977), 564-576.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>361623</ref_obj_id>
				<ref_obj_pid>361598</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Parnas, D.L. On the criteria to be used in decomposing systems into modules. Comm. ACM 15, 12 (Dec. 1972), 1053-1058.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360913</ref_obj_id>
				<ref_obj_pid>360881</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Parnas, D.L., and Siewiorek, D.P. Use of the concept of transparency in the design of hierarchically structured systems. Comm. ACM 18, 7 (July 1975), 401-408.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[SIGGRAPH-ACM GSPC. Status report of the Graphic Standards Planning Committee of ACM/SIGGRAPH. Computer Graphics 11, 3 (Fall 1977).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807367</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Van den Bos, J. Definition and use of higher-level graphics input tools. Proc.SIGGRAPH '78 (Computer Graphics) 12, 3 (Aug. 1978), 38-42.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>804734</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wallace, V.L. The semantics of graphic input devices. Proc. ACM Symposium on Graphic Languages (Computer Graphics) 10, 1 (Spring 1976), 61-65.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE SEMANTICS OF GRAPHICAL INPUT Ed Anson ABSTRACT Any graphical input device may be represented 
by a data structure, modified from time to time by actions in response to certain events, and the ability 
to cause certain events as part of its repertoire of actions. Portions of a device's state may be made 
visible to other devices in a controlled way, and the remainder hidden. Conversely, a device may make 
use of the visible portions of another device's state. Typically, the pattern of device interaction forms 
a hier- archy, but no device is part of any other. This provides for the interchangeability of a single 
device with a group of devices, and allows a single device to support the function of several others. 
Device independence is thus enhanced without the usual sacrifice of human factors considerations. A 
group of devices defined in this manner can simulate any group of devices defined in the usual manner. 
Conversely, useful groups of devices may be defined, which cannot conveniently be simulated by tbe usual 
input semantics. The proposed semantic is thus more complete, and provides the additional benefit of 
a uniform language for describing both physical and virtual devices. Key Words and Phrases: computer 
graphics, graphics ~nput, grapbics input tools~ device independent graphics, human factors, semantics 
of action~ abstract data types, hierarchical sys- tems, modularity~ information hiding. CR Categories: 
5.24, 8.2 INTRODUCTION Hardware designers continue to be generous in their production of new devices 
for grapbical 1979 ACM O-89791-004--4/79/0800--113 $00.75 See Copyright Pg. input. available siderable 
to its diversity software the lack The number and variety of devices now provides a system designer 
with con- freedom in adapting a human interface intended users. Unfortunately, this of devices also 
tends to bewilder designers. The difficulty arises from of sufficient formalisms to bring order to the 
description and use of the devices (17). One major aim of current research (16) is to develop the means 
to standardize graphics soft- ware so that applications may be made relatively independent of their hardware 
environment. At present, the ability to transport an application program from one device to another is 
purchased at a great price. That is, the ability to fully utilize specific device benefit of the user, 
is scribes the semantics of describing input devices utilization of all useful characteristics, to 
the lost. This paper de- action, an approach to which allows the full device characteristics and provides 
a high degree of bardware device independence. Most of the subject matter is presented in three parts. 
The first discusses the semantics of graphical input devices. The second part shows how to create hierarchies 
of devices which provide a large measure of hardware inde- pendence. The third part applies these concepts 
 to some typical problems, to demonstrate tbelr completeness. DEVICE CHARACTERISTICS Recent discussion 
of device independent input has centered on the notion of virtual devices or tools as primitive elements. 
According to this approach, the application programmer deals with the small, fixed set of virtual devices 
(8) supported by the system software. Any physical devices with features not covered by this set are 
thus restricted in use; any features not provided by the hardware are simulated in a manner deter- mined 
by the designer of the system software. Problems with Virtual Devices as Primitives One of the problems 
inherent in this approach may be illustrated by the following scenario: An application prograrm~er designs 
a program which allows a user to position a picture on a 2D surface using the joy stick. Although the 
application only requires X and Y values from a 113 joy stick, tbe terminal to be used has a 3D joy 
stick, which also produces a Z value. The presence of excess information is not a great concern, and 
there is an ergonomic preference for the joy stick. Therefore, the programmer selects the particular 
3D locator (16,18) which corre- sponds to the joy stick, and simply ignores the superfluous Z value. 
 The program works fine, and everybody is happy until the need arises to use a different termi- nal. 
The program uses a device independent subroutine package (e.g., GPGS (5)), so it immediately runs with 
the new terminal. However, the new terminal has a 2D joy stick instead of 3D, and the 3D locator is simulated 
by requiring the user to type three values between zero and one. What was once a very useable program 
is now cumbersome at best and probably useless, even though it runs. Possible alternatives to this scenario 
offer no improvement. The programmer could have origi- nally selected the 2D locator called for by the 
application, but only at the expense of using a device less well suited to the manual task. Alternatively, 
one could modify the program by uniformly replacing 3D by 2D locator requests, but this process is tedious 
and error prone and certainly doesn't indicate much device inde- pendence. This sort of problem seems 
inevitable when using systems such as GPGS (5) or the Core system (16), since such systems provide no 
 control over how a virtual device is simulated. It has been suggested (8) that some means might be 
provided to assign alternatlve physical devices to any given primitive (virtual) device. However, no 
adequate formalism has been pub- lished, and none is proposed for the Core Graphics System (16). Indeed, 
none is likely to appear soon which will permit the full and flexible use of useful device characteristics 
within the existing framework. One possible exception is the proposal by van den Bos (17) which would 
permit the 2D device needed in the above scenario to be simulated by the 3D device. Upon changing physical 
devices, the simulation could be replaced by the actual tool. But the problems of a fixed set of primitive 
devices remain. For instance, the dispute over which devices should be regarded as primitive continues. 
If the keyboard is made primitive as suggested in (16), individual key strokes are not useable. If the 
key is primitive as suggested in (17), those terminals which only transmit strings present a problem. 
The semantics of action defines primitives at a lower level, and permits the use of actual device characteristics 
in a device independent manner. Useful Properties of Interaction Semantics An acceptable language for 
describing and con- trolling graphical input will have the following semantic properties: 1. Application 
programmers may exploit any useful characteristics of any physical input device. Some of those character- 
 istics may be the motivation for choosing the device in the first place. 2. Reassignment of devices 
(or terminals) involves, at most, a small amount of reprogramming. This should be true to the extent 
that the devices are similar. Dissimilar devices will inevitably provide different user interfaces. 
 3. Any useful interaction may be described precisely, clearly and succinctly.  4. Sufficient freedom 
exists to easily incorporate new devices, including those which provide feedback under application program 
control (9).  5. The description of a device's behavior is independent of the implementation. In particular, 
no distinction of semantic significance is made between hardware devices and their software equivalents. 
 6. The description of a device is independent of its application.  Only three primitive elements, 
together with suitable composition rules, are required to satisfy these requirements. The remainder of 
this section describes those elements and shows how they are used to compose interactive devices. Elements 
of Graphical Input Devices Any graphical input device may be described using combinations of the following 
elements: i. State 2. Event  3. Action  State. A device's state may be represented by the contents 
of data variables of any type, complexity or structure, and is all that exists between actions. Portions 
of a device's state may be examined freely and at any time by other devices, and thus are called transparent 
(15). Any identifiable portion of a device's state can be transparent, and the rest remains hidden. 
Similarly, any part of the state may be ex- ternal. That is, it may actually be a trans- parent component 
of another device's state. External state may also be transparent or hidden. In the case of transparent 
external state, the device simply makes another device's state available to its own users. The value 
of a transparent external variable may be defined (for convenience) as a function of the external state 
and possibly part of the internal state. Ex- ternal hidden state remains available to other devices, 
but not as part of the present device. Examples of the objective meaning of state include: the position 
of a knob, joy stick or toggle, the contents of a keyboard string being composed, and the state (on/off) 
of the light on a function key. Note that this last example illustrates a form of feedback. Event. Events 
are discrete elements of communi- cation between devices. Each event is caused by an action and may trigger 
an action in one or more other devices. It may also provide parameters to those actions. Examples of 
events include: pressing a function key, touching a light pen to a displayed element, and the com- pletion 
of a time increment. Action. Actions occur in response to events~ and may proceed concurrently with 
each other and with the invoking action. Typically, an action will alter the internal state, signal an 
event and then terminate within a very short period of time. An action may receive parameters from its 
in- voking event. These parameters, together with the device's state, determine the result of the action. 
Since the action (in another device) which signals the invoking event might alter some variables after 
passing them as parameters, all parameters are effectively passed by value. This guarantees that the 
same value is available for the duration of each responding action. This also prevents one action from 
inadvertently altering the state of another. For the same reason, no action may alter its external state. 
That is, one device may influence another's state only by invoking actions in it. This restriction enhances 
modularity by granting each device total control over its own structure. The scope of an action's parameters 
is the single execution of that action. Local variables are also possible, with similar scope. Access 
to external state is such that the present action must be delayed until the referenced device completes 
any on-golng action. This assures that a device may update its state without concern for intermediate 
states being referenced by another device. For a similar reason, the present action must be delayed if 
it signals an event which would invoke an action in a device with any action in progress. These delays 
should not be noticeable to the user, and in general are expected to be rare, due to the brevity of each 
action. Devices with internal state require a special initial action, which is performed once upon creation 
of the device to initialize the internal state. In the examples given below, its parameters are expressed 
as parameters of the device. Other examples of actions include: turning a function key light on or off, 
and adding a character to a keyboard string being composed. Describing Interactive Devices The relevant 
features of any object (e.g., an interactive device) may be represented by a data structure, if those 
features are sufficiently understood. Hoare develops the notion that the axioms governing behavior of 
an object may be represented by analogous axioms governing behavior of a data structure in a program 
(i0). Liskov has demonstrated that the behavior of a structure may be axiomatized entirely in terms of 
the values obtainable after sequences of oper- ations (12). However~ effective implementation in a programming 
language (13) apparently re- quires representation by data as well. (i.e., operatlons)~ its transparent 
state upon completion of any action (i.e., values ob- tainable) and the events caused by each action. 
Indeed, these properties constitute all that is known about a device outside its own definition. It is 
this independence of internal structure which provides the basis for device inde- pendence. The inclusion 
of algorithmic actions and bidden state is to make the description of a device's behavior sufficiently 
procedural to facilitate effective implementation on a computer. To illustrate the use of these elements, 
the next few paragraphs describe some simple interactive devices. For compactness of presentation, a 
notation is used which resembles a programming language fragment. However, the notation is not complete 
and is not formally defined here. It should thus not be regarded as suitable for incorporation into a 
programming language. Function Keys. A function key is a device which responds to the press of a finger 
(an event), or its release (another event), by changing state from up to down or back up. As such, it 
consists of two actions, each of which alters a one-blt state. In addition, one or more of the following 
features are generally available: a. Position of key may be queried by software.  b. Interrupts when 
pressed.  c. Interrupts when released.  Any non-empty combination of these options can be found in 
some function key. In addition, two additional features are often available: d. A light under software 
control.  e. An identifying value (usually an integer) passed with each interrupt.  A completely general 
function key may be de- scribed thus: device FK (id: integer) = state name: integer, lighted: boolean; 
 transparent down: boolean; initial begin name := id; "save identifier for interrupts" lighted := 
false; "light is initially off" down := false; "key is initially up" end; on flnger-press begin down 
:= true; signal press(name); "interrupt when pressed" en___dd; on flnger-release begin down := false; 
 signal release (name); en_~d; on set-llght (value: boolean) begin lighted := value; "turn light on 
or off" end end device In principle, a device could be described en-A much simpler function key is: 
tirely in terms of the events it responds to device SFK = on finger-press signal press; end device 
 Valuators. A valuator is characterized by a transparent state which is a real value. Typi- cally, this 
value varies between zero and one, and correlates with the angular position (ex- ternal state) of some 
device such as a knob. In this form, it requires no driving events and produces none of its own: device 
valuator : external knob-angle: angle; transparent value = (knob-angle / 360): real; end device Alternatively, 
a valuator may be driven by events produced by a cormnand interpreter device, in the following manner: 
 device valuator = transparent value: real; initial value := 0.0; on set-value (X: real) begin if 
X between 0.0 and 1.0 then value := X else signal bad-value (X) fi; end end device Keyboard Strings. 
A keyboard string device causes a string event in response to a transmit event, which is typically caused 
by the return key on a keyboard. The string event passes a character string as its parameter. This device's 
state (hidden in most systems) consists of the string to be transmitted on request. A typical keyboard 
string device is: device keyboard-string = state Value: string; initial Value := "; on key-press (Key-name: 
char) append Key-name to Value; on back-space begin "error correction" if Value = '' then skip else 
delete last character from Value f i; end; on transmit begin signal string (Value); Value := "; "start 
the next string" end end device The reader has probably noticed that, as in the case of FK lights, 
no mention is made here of displaying relevant portions of the state as feedback to the user. This oversight 
could he corrected by introducing "displayed" as an attribute of state variables. However, this would 
raise questions whicb are outside the scope of this paper. The conclusions below provide some indication 
of the manner in which displayed state might be handled. Clocks. One sort of system clock causes an 
interrupt at regular time intervals. It is driven by the completion of fixed time quanta such as may 
be detected by a vibrating quartz crystal. device system-clock (interval: integer) = state time, period: 
integer; initial begin period := interval; time := period; end; on time-quantum begin time := time 
-I; if time = 0 then signal tick; "periodic interrupt" time := period f i; end end device The next 
section illustrates how devices de- scribed in this manner may be arranged into hierarchies which provide 
a good deal of device independence. DEVICE HIERARCHIES Interactive devices such as those described 
above are the basic building blocks of inter- active systems. ~en properly designed, they satisfy the 
modularity criteria proposed by Parnas (14). Typically, they will be arranged into a hierarchical relationship 
to create a system. Such a system can be easy to use and highly adaptable to changes in hardware. This 
 section discusses some of the essential concepts related to the design of hierarchical inter- active 
systems, and provides examples. Concepts of Device Hierarchies To enhance modularity, to accurately 
describe hardware devices, and to provide maximum system adaptability, the semantics of action defines 
each device independently of others. That is, no device is part of another, and no device assumes tbe 
existence of any other specific device. Everything which affects a device from outside is mediated by 
events and transparent state. The linking between events and actions, and between external and transparent 
state variables, is specified separately and may be changed without modifying devices. It is this linkage 
which arranges the devices into a structure. No language is suggested here for specifying structures, 
but some aspects of the problem are considered. A full treatment of the topic would exceed the scope 
of this paper. The name of an event or state variable in one device needn't correspond directly to names 
in any other device. Separately specified rela- tions link device elements. The relation between transparent 
state variables and external variables is potentially one-to-many. The relation between events caused, 
and the actions which result, is potentially many-to-many. Of course, any transparent variable may remain 
unreferenced, and events need not always cause actions. In fact, it is not essential that actions be 
caused. Only those external vari- ables which are used are required to be bound. This flexibility in 
binding permits the unneeded features of a very general device to remain unused. If such a device is 
implemented by an optimizing compiler, the superfluous features can be eliminated automatically to improve 
 efficiency. Organization of devices may be based on abstrac- tion. The most abstract devices are thus 
at the top of the hierarchy; the least abstract are at the bottom. The choice of devices for each level 
affects the adaptability of the system, so a few words on this topic are appropriate. The most important 
consideration is transparency (15). Simply put, a device is transparent to the extent that it passes 
all information available to it which may be useful to other devices. For instance, the function key 
which allows its state to be examined is more trans- parent than one which does not. Similarly, the function 
key which provides an interrupt every time its state changes is more transparent than one which does 
not. Generally, the best description of a physical device at the bottom of the hierarchy is deter- mined 
by the useful features of the device. Basic support software should provide maximum transparency. At 
the other end of the hier- archy, the description of devices should accu- rately reflect the essential 
features of the application (I). If details of the human interface are omitted at the top level, lower 
levels may be changed to alter the dialog structure. Such a change may be required by a change of hardware, 
or by the discovery that the original interface design is inadequate. In either case it is likely that 
only a few modules will require modification or replacement. Between the top and bottom levels, the 
change in abstraction from one level to the next should be fairly small. This tends to improve adapta- 
bility and increase transparency. Devices close to the lower end of the hierarchy should be general purpose 
in nature and kept available in a library for use in several applications. Examples of Device Hierarchies 
 Making nested rotations convenient for the user can involve the use of an unbounded rotational device. 
Such a device is characterized by a transparent state which is an unbounded real value correlated to 
the rotation of a knob or similar object. Since the typical knob is bounded at 360  or less rotation, 
Brltton (4) suggests the use of a "clutch" which allows the user to logically disengage the knob while 
returning it to a more convenient angle. Ideally, the clutch should be implemented as a momentary switch 
such as the general function key described above. Other modular approaches to hlgh-order devices, such 
as in (17), would pressing such a device semantics of action defines have difficulty hierarchy, but it 
simply as: ex-the device unbounded-valuator = state clutch-engaged: boolean, bias: real; external bounded-value: 
real; transparent value = (if__ clutch-engaged then bounded-value + bias else bias): real; initial begin 
 clutch-engaged := true; bias := 0.0 -bounded-value; "value := 0" end; on clutch-disengage begin clutch-engaged 
:= false; bias := bounded-value + bias; end; on clutch-engage begin clutch-engaged := true; bias 
:= bias -bounded-value; end end device The bounded-value in this device is linked to the transparent 
value of the valuator described earlier. The clutch-dlsengage and clutch-engage events are linked to 
the FK events press and release respectively. Now let us suppose that a function key must be used which 
does not provide an interrupt when released. The key's transparent state may be used, with a system clock, 
to simulate the needed general function key thus: device GFK = external transparent down: boolean; state 
was-down: boolean; ~nltial was-down := false; o_n_nFK-press begin signal press; "press event is passed 
on" was-down := true; end; on tick begin if was-down and not down then signal release; was-down 
:= false f i; end end device On the other hand, a function key with only a "press" event and no transparent 
state requires a small change in the user interface if it is to help implement a clutch. For example, 
it may be converted to a lock switch thus: device lock-switch = transparent down: boolean; initial down 
:= false; o_nn SFK-press begin if down then signal release; down := false; 117 else signal press; 
down := true end end device Note that none of these hardware changes re- quires any alteration of unbounded-valuator. 
 SOME TYPICAL PROBLEMS To further illustrate the completeness and expressive power of the semantics 
of action 9 the next few paragraphs illustrate the manner in which it solves some typical problems. In 
particular 9 special attention is paid to issues involving human factors and device independence. Implementing 
Device Independent Software Implementation of a high level general purpose graphic system (such as GPGS 
(5)) typically involves a great deal of programming for each terminal (2). Each termlnal must be provided 
with its own device dependent software to support the device independent system. Since those tools not 
present on a terminal must be simulated, a device driver is (ironically) more complex for the simpler 
terminals. Since no devices are considered primitives, a system based on the semantics of action reverses 
this situation. The only software that is necessarily device depen- dent is that which incorporates each 
physical device's useful features into the system. Device independent software prQvldes any higher level 
 features. Applicability of these concepts to such a system is readily apparent. Indeed, a related method- 
ology was used to implement the simulated tools for the Tektronix 4010 series (3). The concepts presented 
here are a refinement and extension of those developed to facilitate that implementation. User Freedom 
 Another typical problem involves the freedom provided to the user. Consider an interactive application 
in which the following situation arises: A command string is to be entered by the user, including several 
parameters. However, the user doesn't immediately know the proper values for those parameters. Happily, 
they may be discovered (one at a time) by means of some other interaction with the system. Several options 
are thus available to the de- signer of the application program. The simplest is to require that the 
user remember the param- eters, or write them down, as each is dis- covered. A somewhat more friendly 
approach would be to provide a sub-dlalog structure which allows the parameters to be entered one at 
a time. However, the latter approach suffers the dual disadvantages of requiring the designer to anticipate 
the need and of imposing greater complexity on both the programmer and the user. A better solution is 
to allow the user to perform the other interaction (e.g.9 using function keys) in the midst of composing 
the command string. Implementation of this approach is usually simple on terminals which provide string 
buffers. However 9 anomalies may occur if an attempt is m~de to use the application on a different terminal. 
For instance, if the keyboard string device is simulated as suggested in (17) the needed freedom disappears. 
That is, once the system detects the beginning of a string being typed, it will ignore all attempts to 
do anything except complete (or cancel) the string. Other approaches, such as that suggested in (8)~ 
can provide the required freedom for the user hut lack the ability to provide it in a modular, device 
independent manner. On the other hand, the semantics of action provides both the freedom and the device 
inde- pendence. Due to the manner in which the key- board string device is speclfled~ it behaves the 
same regardless of whether it is a software simulation or a hardware device. In partlcular~ no special 
provisions are required to provide overlap between its operation and that of other devices. Equipment 
Shortages Another typical problem involves the availability of equipment. Consider an application which 
provides its user with 24 distinct functions. Since none of these particular functions requires any explicit 
parameters, the designer naturally uses 24 of the 32 available function keys to invoke them. The application 
is then moved to an installation where only 16 function keys are available. The semantics of action suggests 
at least two reasonable adaptations, either of which may be implemented rather simply. Neither of these 
adaptations is tractable within the con- straints of a traditional device independent system. One adaptation 
is to assign alternate functions to some of the function keys, and to assign one key to specify the alternate 
function. That is, a sequence of two key presses may be required. A typical graphics system would require 
con- siderable modification of application program logic, but the semantics of action requires only the 
incorporation (from a library) of one soft- ware device to simulate the larger function keyboard. Another 
adaptation would allow command strings to be interpreted as replacing some of the needed keys. For instance, 
a device could be created which would simulate a function key press upon receiving a keyboard string 
containing the name of the function to be invoked. In the traditional device independent graphics environ- 
ment, this approach would require substantial modification of the application program. CONCLUSIONS 
The semantics of action provides the basis of a meta-language for describing interactive lan- guages 
and systems. Although it is not yet fully developed, it promises to provide the framework for a new class 
of interactive languages. Such languages will be more expressive, less dependent on hardware, and in 
general kinder to the end users. 118 Separation of concerns is the principal advantage of this approach 
over others. It permits an application to be developed without great concern over the interactive devices 
to be used. This in turn reduces the impact of any change in the final choice of devices and dialog structure. 
Separation of the concerns of description, implementation and use of interactive devices permits devices 
to be treated as modular building blocks. Furthermore, the manner in which devices (and thus systems) 
are described promises to improve verifiability of interactive systems. Non- interactive slgorithms are9 
in principle, subject to formal proofs of correctness. Most notable of the proof methodologies is that 
introduced by Dijkstra (7)~ which identifies a program wltb a predicate transformer. It has the added 
ad- vantage of simplifying the discovery of good algorithms. Unfortunately, the methodology is not applicable 
to interactive systems described in the conventional manner. On the other hand~ the semantics of action 
is compatible in that eacb action component of a device may be iden- tified with a predicate transformer, 
and the conditions under which it is invoked are easily demonstrated. Extension of the proof methodology 
 to handle entire interactive systems is an objective of on-golng study. Implementation in software 
of systems described using the semantics of action should be straight- forward and simple. Indeed~ it 
should be more so than with traditional approaches. For instance, the notion of an action being caused 
by an interrupt is directly supported by most computing equipment, whereas the notion of waiting for 
one of a set of interrupts is not. It is worth noting that the semantics of action can be defined in 
terms of a restricted subset of Hoare's semantics of inter-process communication (11). However , the 
semantics of action currently deals only with input to a static structure. It does not yet deal effectively 
with the problem of describing a complete, dynamic system. The next few paragraphs discuss some extensions 
which are needed. A simple means is needed by which the structure of a system may be specified and altered 
dynami- cally. Multiple independent copies of some devices are needed in most applications. Devices must 
be created, linked into their action struc- ture, and then used and deleted. Some means is needed to 
specify groups of devices as modules, if the complexlty of system architecture is to be controlled. Although 
the results are not yet complete, a simple extension of the notion of devices as data types appears to 
permit most of these issues to be resolved by suitable scope rules. Extension of the semantics of input 
to a complete semantics of interaction is another objective of continuing research. It appears that display 
devices may be treated in a manner similar to input devices. Indeed, this appears to he necessary since 
some function keys display lights and since some graphic display devices support input via devices such 
as light pens. It seems simple to include display elements in the state of a device, and such an extension 
would provide a generalization of the loopless programming features of GRASS (6). However, the diversity 
of display technologies causes problems 9 if a useful degree of device independence is desired. Nevertheless, 
solutions are expected in the near future, permitting a complete semantics of interaction to emerge. 
 ACKNOWLEDGEMENTS I wish to thank Jan van den Bos, whose suggestion prompted me to reduce these ideas 
to writing, and whose constructive criticism of the original manuscript led to significant clarification. 
Thanks also to my wife, Gerry, for putting up with my long evenings of labor over the paper, and for 
providing moral support when I needed it most. REFERENCES 1. Anson, E. Some aspects of the design of 
interactive data structures. Computer Graphics Group technical report, Nijmegen University, Nijmegen, 
The Netherlands, June 1976.  2. Anson, E. GPGS-370 device driver specifi- cations. Computer Graphics 
Group technical report, Nijmegen University, Nijmegen, The Netherlands, July 1976.  3. Anson, E. GPGS-370 
Tektronix driver in- stallation. Computer Graphics Group tech- nical report, Nijmegen University, Nijmegen~ 
The Netherlands, July 1976.  4. Brltton, E.G., Lipscomb, J.S., and Pique~  M.E. Making nested rotations 
convenient for the user. Proc. SIGGRAPH '78 (Computer Graphics) 12,3 (Aug. 1978), 222-227.  5. Caruthers, 
L.C., and Van Dam, A. General Purpose Graphic System: User's Tutorial. Computer Graphics Group technical 
report~ University of Nijmegen, Nijmegen, The Netherlands, 1975.  6. DeFanti, T.A. Toward loopless interactive 
graphics programming. Proc. Conference on Computer Graphics, Pattern Recognition, and Data Structures.~ 
IEEE Catalog No. 75CHO981-IC9 May 1975, pp. 352-355.  7. Dijkstra, E.W. A Discipline of Programming. 
Prentice-Hall, Englewood Cliffs, New Jersey, 1976.  8. Foley~ J.D., and Wallace, V.L. The art of natural 
~an-machlne conversation. Proc. IEEE 62~4 (April 1974), 462-471.  9. Geyer, K.E., and Wilson, K.R. Computing 
with feeling. Proc. Conference on Computer Graphics, Pattern Recognition, and Data Structures, IEEE Catalog 
No. 75CRO981-1C, May 1975, pp. 343-349.  119 I0. Hoare, C.A.R. Notes on data structuring. In Structured 
Pro~rammln~, Dahl, O.-J., Dijkstra, E.W., and Hoare, C.A.R., Eds., Academic Press, New York, 19729 pp. 
83-174. Ii. Hoare, C.A.R. Communicating sequential processes. Comm. ACM 21,8 (Aug. 1978), 666-677. 
12. Liskov, B.H., and Zilles, S.N. Specification techniques for data abstractions. IEEE Transactions 
on Software Engineering I,I (March 1975), 7-19. 13. Liskov, B., Snyder, A., Atkinson, R., and Schaffert, 
C. Abstraction mechanisms in CLU. Comm. ACM 20,8 (Aug. 1977), 564-576.  14. Parnas, D.L. On the criteria 
to be used in decomposing systems into modules. Comm. ACM 15,12 (Dec. 1972), 1053-1058.  15. Parnas, 
D.L., and Siewiorek, D.P. Use of the concept of transparency in the design of hierarchically structured 
systems. Con~n. ACM 1897 (July 1975), 401-408.  16. SIGGRAPH-ACM GSPC. Status report of the Graphic 
Standards Planning Committee of ACM/SlGGRAPH. Computer Graphics 11,3 (Fall  1977). 17. Van den Bos, 
J. Definition and use of hlgher-level graphics input tools. Proc. .SIGGRAPH '78 (Computer Graphics) 
12,3 (Aug. 1978), 38-42. 18. Wallace, V.L. The semantics of graphic input devices. Proc. ACM Symposium 
on Graphic Languages (Computer Graphics) 10,1 (Spring 1976), 61-65.
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807433</article_id>
		<sort_key>121</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Human vision and computer graphics]]></title>
		<page_from>121</page_from>
		<page_to>125</page_to>
		<doi_number>10.1145/800249.807433</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807433</url>
		<abstract>
			<par><![CDATA[<p>Is one picture really worth a thousand words? Why do cleverly designed graphic displays make visual information stand out more clearly with strikingly greater impact than numbers buried in pages of computer printout?</p> <p>Graphic output devices shift the burden of integrating information generated by computers onto the human vision system: the sensory channel with the highest capacity for distributed parallel processing. The system consists of hundreds of successive two-dimensional arrays of millions of interconnected parallel computers. Perception seems instantaneous because we are not conscious of the massive amounts of computation that occur. What we consciously &#8220;see at a glance&#8221; is already a highly structured, synthesized, and summarized version of the actual light intensity mosaic that enters the retina.</p> <p>We will demonstrate some results of the visual structuring that occurs in the human visual system, show why some features stand out instantaneously and others do not, and explain why knowledge of the human input device is crucial to the design of effective computer output devices and displays.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.10</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330241</person_id>
				<author_profile_id><![CDATA[81100150701]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fanya]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Montalvo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Berkeley Laboratory, Berkeley CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abramov, I. Further analysis of the responses of LGN cells. J.Opt.Soc.Am. 58, 574-579 (1968).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bajcsy, R. A computational structure for color perception. Moore School of EE Tech. Report, University of Pennsylvania, Philadelphia (1975).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barlow, H.B., Blakemore, C. &amp; Pettigrew, J.D. The neural mechanism of binocular depth discrimination. J.Physiol. 193, 327-342 (1967).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Barlow, H.B., Hill, R.M. &amp; Levick, W.R. Retinal ganglion cells responding selectively to direction and speed of image motion in the rabbit. J.Physiol. 173, 377-407 (1964).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Berry, R.N. Quantitative relations among vernier, real depth, and stereoscopic depth acuities. J.Exp.Psychol. 38, 708-721 (1948).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blakemore, C. &amp; Campbell, F.W. On the existence of neurones in the human visual system selectively sensitive to the orientation and size of retinal images. J.Physiol. 203, 237-260 (1969).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Boynton, R.M. &amp; Kaiser, P.K. Vision: the additivity law made to work for heterochromatic photometry with bipartite fields. Science 161, 366-368 (1968).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cornsweet, T.N. Visual Perception. New York: Academic Press, 1970.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Crow, F.C. The aliasing problem in computer-synthesized shaded images. CACM 20, 799-805 (1977).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[DeValois, R.L. Analysis and coding of color vision in the primate visual system. Cold Spring Harbor Symp.Quant.Biol. 30, 567-579 (1965).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[DeValois, R.L., Abramov, I. &amp; Jacobs, G.H. Analysis of response patterns of LGN cells. J.Opt.Soc.Am. 56, 966-977 (1966).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[DeValois, R.L. &amp; Pease, P.L. Contours and contrast: responses of monkey lateral geniculate cells to luminance and color figures. Science 171, 694-696 (1971).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gregory, R.L. Eye and Brain. New York: McGraw-Hill, 1966.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807362</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Joblove, G.H. &amp; Greenberg, D. Color spaces for computer graphics. Proc. SIGGRAPH-78, Atlanta GA, 20-25 (August 1978).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hamerley, J.R. &amp; Springer, R.M. Perception of raggedness of edge images. Op.Soc.Am.Meeting, San Francisco CA (November 1978).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Harmon, L.D. &amp; Julesz, B. Masking in visual recognition: effects of two-dimensional filtered noise. Science 180, 1194-1196 (1973).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Hubel, D.H. &amp; Wiesel, T.N. Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex. J.Physiol. 160, 106-154 (1962).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hurvich, L.M. &amp; Jameson, D. An opponent-process theory of color vision. Psyc.Rev. 64, 384-404 (1957).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Julesz, B. Foundations of Cyclopean Vision. Chicago: Univ. of Chicago Press, 1971.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Julesz, B. Experiments in the visual perception of texture. Sci.Am. 232, 34-43 (1975).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Julesz, B., Gilbert, E.N., Shepp, L.A. &amp; Frisch, H.L. Inability of humans to discriminate between visual textures that agree in second-order statistics: revisited. Perception 2, 391-405 (1973).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Mansfield, J.R.W. Neural basis of orientation perception in primate vision. Science 186, 1133-1135 (1974).]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[McCollough, C. Color adaptation of edge-detectors in the human visual system. Science 149, 1115-1116 (1965).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908075</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Montalvo, F.S. Aftereffects, adaptation, and plasticity: a neural model for tunable feature space. PhD thesis, Comp. &amp; Info. Sci. Dept. Tech. Report 76-4, University of Massachusetts, Amherst (September 1976).]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Over, R. Comparison of normalization theory and neural enhancement explanation of negative aftereffects. Psyc.Bulletin 75, 225-243 (1971).]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Ratliff, F. Mach Bands. San Francisco: Holden-Day, 1965.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Ratliff, F. &amp; Hartline, H.K. The responses of Limulus optic nerve fibers to patterns of illumination on the retinal mosaic. J.Gen.Physiol. 42, 1241-1255 (1959).]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Riggs, L.A. Visual acuity. In C.H. Graham (Ed.) Vision and Visual Perception. New York: Wiley &amp; Sons, 321-349 (1965).]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807361</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Smith, A.R. Color gamut transform pairs. Proc. SIGGRAPH-78, Atlanta GA, 12-19 (August 1978).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Van Der Horst, G.J.C. Fourier analysis and color discrimination. J.Opt.Soc.Am. 59, 1670-1676 (1969).]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Weisstein, N. Metacontrast. In L.M. Hurvich &amp; D. Jameson (Eds.) Visual Psychophysics. Heidelberg: Springer-Verlag, 233-272 (1972).]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SPECIAL SESSION ON VISION chaired by Fanya S. Montalvo Lawrence Berkeley Laboratory Berkeley CA 94720 
 Is one picture really worth a thousand words? Why do cleverly designed graphic displays make visual 
information stand out more clearly with strikingly greater impact than numbers buried in pages of computer 
printout? Graphic output devices shift the burden . of integrating information generated by computers 
onto the human vision system: the sensory channel with the highest capacity for distributed parallel 
processing. The system consists of hundreds of successive two-dimensional arrays of millions of interconnected 
parallel computers. Perception seems instantaneous because we are not conscious of the massive amounts 
of computation that occur. What we consciously "see at a glance" is already a highly structured, synthesized, 
and summarized version of the actual light intensity mosaic that enters the retina. We will demonstrate 
some results of the visual structuring that occurs in the human visual system, show why some features 
stand out instantaneously and others do not, and explain why knowledge of the human input device is 
crucial to the design of effective computer output devices and displays. PARTICIPANTS Stephen R. Levine 
Lawrence Livermore Laboratory Introductory Remarks Fanya S. Montalvo Lawrence Berkeley Laboratory 
Vision and Computer Graphics Stuart Anstis York University Montion Bela Julesz Bell Telephone Laboratories 
 Preattentive Perception Richard L. Gregory University of Bristol Color HUMAN VISION AND COMPUTER 
GRAPHICS Fanya S. Montalvo I. INTRODUCTION ~y should computer graphics concern itself with human vision? 
The very reason for the rise in the use of graphics in the first place is deeply embedded in the way 
humans perceive. Graphs and pictures convey more information more quickly than pages of numbers. We all 
know this intuitively. Few of us, however, stop to consider why. What is it about visual perception that 
allows this seemingly instantaneous communication from computer to human? Conversely, why does the synthesis 
of concepts or objects from pages of numbers require such time-consuming mental effort? The answer is 
to be found in the way the visual system is structured and in what it was designed to compute. It cannot 
and does not compute everything it "sees." Our unawareness of the enormous amounts of parallel computation 
taking place gives the impression that seeing is simple, that seeing is a one-to-one mapping, and that 
everything on the physical display is transmitted directly to the user's brain. Nothing could be further 
from the truth. Tremendous Inhomogeneitles, distortions and super-acultles exist in the human visual 
system. The system is rich in special parallel hardware designed to detect specific classes of features. 
Neural cells code for specific features, such as the width and orientation of bars, and operate in a 
distributed fashion throughout the two-dimensional visual field. Interactions between cells can make 
some features stand" out more clearly, while obscuring others, and distorting still others. The distinction 
between preattentlve perception, requiring no conscious effort, and that requiring attention or serial 
inspection helps to identify which features are processed by this special visual hardware and which 
require higher cognitive processes. *This Work was supported by the Lawrence Berkeley Laboratory Computer 
Center, and by the Office of Energy Research of the U.S. Department of Energy under contract No. W-7405-ENG-48. 
 1979 ACM O-89791-004--4/79/0800--121 $00.75 See Copyright Pg. 121 We need to know what characteristics 
of visual presentation make information stand out quickly, clearly, without distortion and without conscious 
effort. If we cannot eliminate distortion we should know how to compensate for it. If we cannot duplicate 
a natural image exactly we should know what approximations are close enough to the perception we wish 
to transmit. If we expect a pattern recognition program to make automatic decisions about natural images, 
we need to know about the subliminal decisions made by our brains in processing those images. In generating 
synthetic images, we need to compensate for distortions such as aliasing and staircasing, produced, respectively, 
by our approximations to smooth boundaries and curved sufaces. These devastating distortions occur because 
of the special characteristics of the visual system and not because festering and faceting are poor approximations. 
Other approximations do not cause severe problems, for example, distortions of the color space produced 
by a badly tuned color television. The reasons for these differences in severity can be found in the 
various units of special hardware the visual system uses to detect specific features and in the interactions 
between these units that accentuate some features at the expense of others. 2. SPECIAL HARDWARE Biological 
visual systems possess many specialized processes that enhance contrast, making boundaries sharper [Ratliff 
&#38; Hartline 59] and making gradual intensity changes disappear. Other processes detect symmetry within 
local regions [Julesz 75]. In addition, neural cells have been found that are specifically tuned to line 
orientation [Hubel &#38; Wiesel 62], size or spatial frequency [Blakemore &#38; Campbell 69], binocular 
disparity or depth [Barlow et el. 67], color [DeValois et al. 66], and speed and direction of motion 
[Barlow et al. 64]. All of these special feature detectors presumably operate in parallel, arranged topographically 
over the two-dimensional visual field. They interact with each other, enhancing some of their neighbors 
and inhibiting others. 2.1 LATERAL INHIBITION Lateral inhibition between cells in the retina causes 
an exaggeration of intensity differences at boundaries [Ratliff &#38; Hartline 59]. Math bands, which 
appear as dark an~ light bands at positive and negative discontinuities in the first derivative of light 
intensity, are also caused by lateral inhibition [Ratliff 65]. In computer graphics, contrast enhancement 
of light intensity is known as staircasing when it occurs at boundaries between flat areas of uniform 
intensity, and as scalloping when it occurs in 2D polygonal approximations to 3D curved surfaces. Lateral 
inhibition can also cause the appearance of two areas of equal intensity to differ if the transition 
between them has a sharp intensity discontinuity completely surrounding one of the areas [Cornsweet 70]. 
Areas that actually do differ in intensity may not be discriminated if the transition is too gradual. 
 2.2 FEATURE DETECTORS The visual system contains neural cells selectively sensitive to specific features 
in the visual input. Some of these detect line orientation, bar width, spatial frequency, direction and 
speed of motion, and binocular disparity. For example, pools of cells, each representing a specific degree 
of tilt, map the continuous dimension of llne orientation. Each cell fires maximally to its preferred 
feature along its continuous feature dimension and drops off in response the more the input feature differs 
from the optimal one. In the case of orientation, for example, a cell may fire maximally for a vertical 
bar and drop off to 50% of its maximal response for 15 degrees of tilt away from vertical. The accuracy 
with which we can detect differences between bars of different orientations seems to depend on the density 
of such cells along the feature dimension [Montalvo 76]. The distribution of line orientation cells has 
clusters at vertical and horizontal, and it can be shown that discrimination excels for differences near 
these orientations [Mansfield 74]. Time and space interactions between detectors enhance contrast between 
near neighbors. Space interactions are known as simultaneous contrast and time interactions are known 
as adaptation. Both refer to the exaggeration of differences between adjacent features along a given 
dimension. }~sking, the degradation of one feature by another, often occurs for features adjacent both 
in space and in the feature domain [Weisstein 72]. One example is demonstrated by Harmon and Julesz [73]. 
Face recognition is more effectively impaired by noise that is spectrally adjacent to the picture's 
spatial frequency spectrum, Noise of the sort introduced by digitization need not interfere with the 
information content of the picture if it is spectrally far enough away.  2.3 SPECIAL COMPUTATION Some 
processes cannot be isolated to single cells using neurophysiological methods. However, using psychophysical 
methods we can infer that a given computation must occur if humans can identify particular aspects in 
the visual field. If identification can occur anywhere in the visual field without eye movements or time 
for inspection then we can assume that computation occurs automatically and in parallel over the entire 
field. Julesz has clarified the distinction between preattentive perception and the form of perception 
requiring serial inspection and attention [Julesz et el. 73]. By generating various series of discrimination 
tasks between textures that vary only in their Nth-order statistics, or in minor aspects of their local 
geometry, they were able to isolate crucial factors of preattentive perception. Two preattentive visual 
processes that cannot be isolated to computations occurring in single cells are binocular depth perception 
and a local symmetry operation. Julesz [71] was first to show that these correlation processes occur 
even in the absence of meaningful form cues. If two identical random dot patterns are generated, one 
with a central area of dots slightly displaced, and these patterns are projected binocularly, that is, 
each  to one eye, the central portion will appear at a depth different from the background. This will 
occur even though no edges or meaningful forms are visible to either eye separately. The symmetry perception 
operation can be demonstrated with a similar random dot pattern. Each quadrant of the field is replicated 
with axial symmetry about the x and y axes. The pattern will appear symmetric only in a certain zone 
near the x and y axes on the pattern. Beyond this zone the pattern will appear random. This demonstration 
implies that the symmetry operation is limited by distance. The preattentive property of both the binocular 
and symmetrical correlation operations can be clearly distinguished from other kinds of correlations 
requiring mental effort. For example, if the four quadrants in a random dot pattern are duplicated four 
times without being mirrored, the entire array appears totally random [Julesz 75]. Such demonstrations 
distinguish those operations in the visual system which are "pre-wired" to occur automatically from 
those that require focusing of attention towards producing the necessary operations at the cognitive 
level. The best strategy for producing clear displays that transmit information quickly is to distribute 
the information over the many parallel, automatic processes that exist in the low-level visual system. 
  2.4 VERNIER ACUITY AND ALIASING Aliaslng, the perceived Jaggedness at high contrast edges, has become 
a particularly annoying display problem with the growth of computer-generated, raster scan pictures and 
films. The problem is not necessarily solved by using higher resolution display devices. Individual edge 
discontinuities may become too small to see, but regular patterns of edge breaks may be much more visible 
as global patterns. Thus, beside the added expense of higher resolution, these more offensive problems 
due to sampling may result [Crow 77]. The heuristic solution to aliaslng is a smooth, rather than abrupt, 
intensity transition from one llne segment to the next, computed from the degree of overlap of the desired 
line and the model display grid. The resulting display transforms location information which is finer 
than the display grid into intensity variations. This solution works because of the visual system's peculiar 
tolerance for the replacement of location information by intensity information. The aliasing problem 
can be better understood by examining the visual system's extreme sensitlviy to Jagged edges. This sensitivity 
has been found to be in the same range as vernier acuity [Hamerley &#38; Springer 78]. Vernier acuity 
is the sensitivity to a slight displacement between parallel, almost aligned contours. It is more than 
ten times greater than the spatial resolution of the retina. Spatial resolution is limited by receptor 
spacing and light diffraction onthe retina. Receptor separation is about 30 seconds of visual angle, 
but, remarkably, vernier acuity is on the order of 2 to 3 seconds of visual angle [Berry 48, Riggs 65]. 
Thus, changes in line width or edge location finer than the retinal mosaic can be detected only as variations 
~n intensity. Since long contours involve sampling by many receptors along a straight line or edge, 
some form of signal averaging or comparison over many units must be involved [Riggs 65]. Signal averaging 
of intensity over long contours dramatically increases the system's ability for localization.  2.5 COLOR 
 2.5.1 Cones: The First Layer Color graphics devices can reproduce virtually all colors perceived by 
humans with only three variables. This is because the human eye has only three types of narrow-band light 
receptors, called cones, with peak sensitivities at three different wavelengths on the electromagnetic 
spectrum. Their peak sensitivity corresponds roughly (not strictly) to monochromatic red, green and blue. 
The appearance of any monochromatic color can be simulated by reproducing the excitation it produces 
in these three distinct populations of receptors. Similarly, any color composed of a distribution of 
monochromatic colors across the spectrum can be reproduced with proper proportions of red, green, and 
blue. [See Smith 78 and Joblove &#38; Greenberg 78 for further discussion of the 3D color space.] One 
problem arising from the non-uniformity of the distribution of color receptors over wavelength is a non-unlformlty 
of hue discrimination over wavelength and intensity [Hurvich &#38; Jameson 57, DeValols 65, Gregory 66]. 
Because of the close proximity of red and green cone cells" peak responses and the sharp drop in response 
between their peaks, discrimination of hue differences about yellow is much more acute than discrimination 
near blue. It is because of these non-uniformities that we have to be very cautious about representing 
data by variations in hue. The greatest differences in the data may not correspond to the greatest perceptual 
hue differences unless the color space is corrected for equal hue steps. If we want to be able to pick 
out distinctive features of the data we wish to display, we need to have some idea of how the perceptual 
hue mapping corresponds to the color space of the output device.  2.5.2 Opponent-Color Processes Beyond 
the retina the three color receptors are linked to cells in the lateral geniculate nucleus (LGN) on the 
way to the visual cortex [Abramov 68]. Cells at the LGN are organized into four general populations: 
cells stimulated by red and suppressed by green, cells stimulated by green and suppressed by red, cells 
stimulated by yellow and suppressed by blue, and cells stimulated by blue and suppressed by yellow [DeValois 
et al. 66]. This kind of opponent-color process seems to account for color contrast and adaptation [Hurvlch 
&#38; Jameson 57, Bajcsy 75]. Color contrast is a spatial phenomenon. Gray next to red looks much greener 
than the same gray next to green. Adaptation refers to negative effects over time. After hours of watching 
a color television image with an overall red component, the colors begin to look perfectly balanced. 
This is partly due to the automatic gain control peformed by the retina on each color channel. Other 
forms of color aftereffects are believed to occur in the LGN and visual cortex as well [McCollough 65]. 
In the case of our color TV example above, the perceptual color space is gradually rescaled such that 
the net red component in the red-green system appears white. Rescallng of a continuous feature space 
seems to be involved in many other forms of adaptation as well [Over 71, Montalvo 76].  2.5.3 Color 
Resolution Spatial resolution for color is lower than the resolution for black and white [VanDerHorst 
69]. This fact has implications for anti-aliasing and anti-staircasing algorithms in color. Sharp borders 
between colors of equal luminance tend to disappear [Boynton &#38; Kaiser 68]. (Luminance is a term that 
refers to light intensity corrected for  \the spectral sensitivity of the visual system in order to 
produce equal effectiveness in stimulating the retina.) This means that chromatic edges between areas 
of equal luminance need not be anti-aliased as carefully as achromatic edges. No border enhancement occurs 
between colors of equal luminance, as is true of the black and white domain [DeValois &#38; Pease 71]. 
Thus, the degree of anti-staircasing found necessary for black-white transitions need not be as high 
as for purely chromatic transitions. If a color output device is properly balanced to ensure equal luminance 
between colors at all levels, fewer levels need be devoted to hue transitions than to luminance transitions. 
 3. CONCLUSION We have seen that the existance of parallel, automatic populations of cells and operations 
in the human visual system make visual information stand out quickly and clearly in graphic displays. 
Exploitation of these properties of the visual system allows us to transmit more information to the user 
more quickly. We, in effect, utilize the human channels with the highest bandwidths. Doing so shifts 
the burden of the integration of information onto the visual system and away from higher mental processes 
requiring more time and attention. However, we need to be aware of the idiosyncrasies of the system in 
order to best utilize its full capacity and in order to conpensate for nonlinearities that can seriously 
distort the display output.  REFERENCES Abramov, I. Further analysis of the responses of LGN cells. 
J.Opt.Soc.Am. 58, 574-579 (1968). BaJcsy, R. A computational structure for color perception. Moore School 
of EE Tech. Report, University of Pennsylvania, Philadelphia (1975). Barlow, H.B., Blakemore, C. &#38; 
Pettigrew, J.D. The neural mechanism of binocular depth discrimination. J.Physiol. 193, 327-342 (1967). 
 Barlow, H.B., Hill, R.M. &#38; Levick, W.R. Retinal ganglion cells reponding selectively to direction 
and speed of image motion in the rabbit. J.Physiol. 173, 377-407 (1964). Berry, R.N. Quantitative relations 
among vernier, real depth, and stereoscopic depth acuities. JtExp.Psychol. 3R, 708-721 (1948). Blakemore, 
C. &#38; Campbell, F.W. On the existence of neurones in the human visual system selectively sensitive 
to the orientation and size of retinal images. J.Physiol. 203~ 237-260 (1969). Boynton, R.M. &#38; 
Kaiser, P.K. Vision: the additivity law made to work for heterochromatic photometry with bipartite fields. 
Science 161~ 366-368 (1968). Cornsweet, T.N. Visual Perception. New York: Academic Press, 1970. Crow, 
F.C." The aliasing problem in computer-synthesized shaded images. CACM 20~ 79g-805 (1977). DeValois, 
R.L. Analysis and coding of color vision in the primate visual system. Cold Sprin~ Harbor Symp.Quant.Biol. 
30, 567-579 (1965). DeValois, R.L., Abramov, I. &#38; Jacobs, G.H. Analysis of response patterns of 
LGN cells. J.Opt.Soc.Am. 56, 966-977 (1966). DeValois, R.L. &#38; Pease, P.L. Contours and contrast: 
responses of monkey lateral geniculate cells to luminance and color figures. Science 171~ 694-696 (1971). 
 Gregory, R.L. Eye and Brain. New York: McGraw-Hill, 1966. Joblove, G.H. &#38; Greenberg, D. Color 
spaces for computer graphics. Proc. SIGGRAPH-78~ Atlanta GA, 20-25 (August 1978). Hamerley, J.R. &#38; 
Springer, R.M. Perception of raggedness of edge images. Op. Soc.Am.MeetinR~ San Francisco CA (November 
1978). Harmon, L.D. &#38; Julesz, B. Masking in visual recognition: effects of two-dimensional filtered 
noise. Science 180 r 1194-1196 (1973). Hubel, D.H. &#38; Wiesel, T.N. Receptive fields, binocular interaction, 
and functional architecture in the cat's visual cortex. J.Physiol. 160, 106-154 (1962). Hurvich, L.M. 
&#38; Jameson, D. An opponent-process theory of color vision. Psyc.Rev. 64, 384-404 (1957). Julesz, 
B. Foundations of Cyclopean Vision. Chicago: Univ. of Chicago Press, 1971. Julesz, B. Experiments in 
the visual perception of texture. Sci.Am. 232, 34-43 (1975). Julesz, B., Gilbert, E.N., Shepp, L.A. 
&#38; Frisch, H.L. Inability of humans to discriminate between visual textures that agree in second-order 
statistics: revisited. Perception 2, 391-405 (1973).  Mansfield, J.R.W. Neural basis of orientation 
' -perception in primate vision. Science 186~ 1133-1135 (1974). ~Collough, C. Color adaptation of edge-detectors 
 in the human visual system. Science 149~ 1115-1116 (1965). Montalvo, F.S. Aftereffects, adaptation, 
and plasticity: a neural model for tunable feature space. PhD thesis, Comp.&#38; Info.Sci.Dept. Tech.Report 
76-4, University of Massachusetts, Amherst (September 1976). Over, R. Comparison of normalization theory 
and neural enhancement explanation of negative aftereffects. Psyc.Bulletin 75~ 225-243 (1971). Ratliff, 
F. Mach Bands. San Francisco: Nolden-Day, 1965. Ratliff, F. &#38; Hartline, H.K. The responses of Limulus 
optic nerve fibers to patterns of illumination on the retinal mosaic. J.Gen.Physiol. 42~ 1241-1255 (1959). 
 Riggs, L.A. Visual acuity. In C.H. Graham (Ed.) Vision and Visual Perception. New York: Wiley &#38; 
 Sons, 321-349 (1965). Smith, A.R. Color gamut transform pairs. Proc. SIGGRAPH-78~ Atlanta GA, 12-19 
(August 1978). Van Der Horst, G.J.C. Fourier analysis and color discrimination. J.Opt.Soc.Am. 59~ 1670-1676 
 (1969). Ueisstein, N. ~tacontrast. In L.M. Hurvich &#38; D. Jameson (Eds.) Visual Psychophysics. Heidelberg: 
 Springer-Verlag, 233-272 (1972).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807434</article_id>
		<sort_key>126</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[An algorithm for shading of regions on vector display devices]]></title>
		<page_from>126</page_from>
		<page_to>133</page_to>
		<doi_number>10.1145/800249.807434</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807434</url>
		<abstract>
			<par><![CDATA[<p>The display of shaded polygons by line, cross-hatch, and dot patterns on vector devices is a task frequently used in computer graphics and computer cartography. In applications such as the production of shaded maps polygon shading turns out to be critical with respect to time requirements, and the development of efficient algorithms is of importance.</p> <p>Given an arbitrary polygon in the plane without self-crossing edges (simply-connected polygon), the task at hand is to shade this polygon with one or two sets of parallel lines where for each set a shading angle and a line distance are given. The basic concept of this new algorithm is to decompose the polygon into a set of mutually exclusive trapezoids (in special cases triangles) where the parallel edges of the trapezoids are parallel to the desired shading lines. These trapezoids and triangles are then shaded in a fast procedure. In its present form the algorithm handles regions with up to 300 islands. Possible extensions include the construction of dash and cross patterns.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Cartography]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Line-drawing processing]]></kw>
			<kw><![CDATA[Polygons]]></kw>
			<kw><![CDATA[Shading]]></kw>
			<kw><![CDATA[Software]]></kw>
			<kw><![CDATA[Spatial information]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P331878</person_id>
				<author_profile_id><![CDATA[81100307114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Brassel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[SUNY at Buffalo, Department of Geography, State University of New York at Buffalo, 415 Fronczak Hall, Amherst, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333488</person_id>
				<author_profile_id><![CDATA[81316488036]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fegeas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[U.S. Geological Survey, Geography Program, U.S. Geological Survey, M.S. 710, Reston, VA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baxter, R.S., Choropleth Mapping Program By Computer, Manuscript, Building Research Establishment, Garstom, Watford, U.K., 26 pgs.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>362739</ref_obj_id>
				<ref_obj_pid>362736</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bouknight, W.J., 1970, "A Procedure for Generation of Three-dimensional Half-toned Computer Graphics Representations", Communications ACM, Vol. 13, No. 9, pp. 527 - 536.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brassel, K.E. and J.J. Utano, 1979, "Design Strategies for Continuous-tone Area Mapping", The American Cartographer, Vol.6, No. 1 (forthcoming).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Coleman, P.R., R.C. Durfee, and R.G. Edwards, "Application of a Hierarchical Polygon Structure in Spatial Analysis and Cartographic Display", Harvard Papers on Geographical Information Systems, Vol. 3, 20 pgs.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jarvis, J.F., C.N. Judice, and W.H. Ninke, 1976, "A Survey of Techniques for the Display of Continuous Tone Pictures on Bilevel Displays", Computer Graphics and Image Processing, Vol. 5, pp.13-40.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kern, H., 1978, "Neuere Techniken der Flaechenschraffur und der Herstellung von Farbauszuegen in der automatisierten thematischen Kartographie" (Recent Techniques of Area Shading and Color Separation in Automated Thematic Cartography), Kartographische Nachrichten, Vol. 28, No. 1, pp. 1-11.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Knowlton, K. and L. Harmon, 1972, "Computer-Produced Grey Scales", Computer Graphics and Image Processing, Vol. 1, pp. 1-20.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Laboratory for Computer Graphics and Spatial Analysis, 1976, CALFORM User's Manual. Cambridge: Harvard University.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807380</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lieberman, H., 1978, "How to Color In A Coloring Book", Computer Graphics, Vol. 12, No. 3, pp. 111-116.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Negroponte, N., 1977, "Raster Scan Approaches to Computer Graphics", Computers and Graphics, Vol. 2, pp. 179-193.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Newman, W.M. and R.F. Sproull, 1973, Principles of Interactive Computer Graphics. New York: McGraw-Hill.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Monmonier, M.S., and D.M. Kirchoff, 1977, "Choroplethic Plotter Mapping for a Small Minicomputer", Proceedings of the American Congress on Surveying and Mapping, 37th Annual Meeting, Wash., D.C., pp. 318-338.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, Th., 1978, "Filling Algorithms for Raster Graphics", Computer Graphics, Vol. 12, No. 3, pp. 161-164.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rase, W.D., SRAFOF shading subroutine, private communication.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Rase, W.D., 1978, "Computer-assisted Thematic Mapping for Federal Planning", Nachrichten aus dem Karten- und Vermessungswesen, Series II: Translations, No. 35, pp. 77-83.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A. and V.C. Kak, 1976, Digital Image Processing. New York/London: Academic Press.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Salomon, K.B., 1978, "An Efficient Point-in-Polygon Algorithm", Computers and Geosciences, Vol. 4, pp.173-178.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908431</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Shamos, M.I., 1977, Computational Geometry. Berlin/New York: Springer-Verlag.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Southerland, I.E., R.F. Sproull and R.A. Schumacker, 1974, "A Characterization of Ten Hidden-Surface Algorithms", Computing Surveys, Vol. 6, No. 1, pp. 1-55.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Tobler, W.R., 1971, Choropleth Mapping Programs. Cartographic Laboratory Report No.6, Dept. of Geography, Univ. of Michigan, Ann Arbor.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Tobler, W.R., 1973, "Choropleth Maps without Class Intervals?", Geographical Analysis, Vol. 5, pp. 262-265.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[U.S. Geological Survey, Geography Program: Routine SHADT, personal communication.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Watkins, G.S., 1970, A Real-Time Visible Surface Algorithm, Computer Science Department, University of Utah, UTECH-CSc-70-101.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Waugh, T.C., and D.R.F. Taylor, 1976, "GIMMS / An Example of an Operational System for Computer Cartography", The Canadian Cartographer, Vol. 13, No. 2, pp. 158-166.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Wood, P.M., and D.M. Austin, 1975, "CARTE: A Thematic Mapping Program", Computers and Graphics, Vol. 1, No. 2/3, pp. 239-250.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Wood, P.M., 1978, "Interactive Display of Polygonal Data", Harvard Papers on Geographic Information Systems, Vol. , 20 pgs.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN ALGORITHM FOR SHADING OF REGIONS ON VECTOR DISPLAY DEVICES Kurt E.. Brassel, SUNY at Buffalo and 
Robin Fegeas, U.S. Geological Survey ABSTRACT I. INTRODUCTION The display of shaded polygons by line, 
cross-hatch, and dot patterns on vector devices is a task frequently used in computer graphics and computer 
cartography. In applications such as the production of shaded maps polygon shading turns out to be critical 
with respect to time requirements, and the development of efficient algorithms is of importance. Given 
an arbitrary polygon in the plane without self-crossing edges (simply-connected polygon), the task at 
hand is to shade this polygon with one or two sets of parallel lines where for each set a shading angle 
and a line distance are given. The basic concept of this new algorithm is to decompose the polygon into 
a set of mutually exclusive trapezoids (in special cases triangles) where the parallel edges of the 
trapezoids are parallel to the desired shading lines. These trapezoids and triangles are then shaded 
in a fast procedure. In its present form the algorithm handles regions with up to 300 islands. Possible 
extensions include the construction of dash and cross patterns. Key words and phrases: Software, computer 
graphics, polygons, shading, cartography, llne-drawing processing, spatial information. CR categories: 
3.14, 3.24, 3.30, 3.79, 8.2 Department of Geography, State University of New York at Buffalo, 415 Fronczak 
Hall, Amherst, NY 14260. Geography Program, U.S. Geological Survey, M.S. 710, Reston, VA 22092 The 
shading of regions by a regular line pattern is a common task in various applications of computer graphics. 
Regions (polygons) as defined by a sequence of outline coordinates (xl,yl) ... (xn,yn) are to be shaded 
by sets of parallel lines, where the line width, the line distance, and the angle of shading orientation 
are commonly used as shading parameters. Such a routine allows for the construction of shaded line patterns 
of any shading density. Tobler [21] has proposed a continuous shading scheme for mapping which shades 
geographic areas by grey tones which are visually proportional to a geographic variable to be displayed. 
In practice, however, such a scheme encounters some technical and perceptual restrictions for the construction 
of very light or very dark tones: The human eye is not able to accurately perceive grey tones when shading-lines 
are closely spaced, and in the reproduction process such sets of lines may be modified in an undesirable 
way; also, parallel line shading is not very effective for light grey tones, where the line distance 
is large as compared to the line width or to the size of the region to be displayed. In these instances 
extended shading schemes such as cross-hatching (for dark grey tones) and dash, cross, or point patterns 
(for light tones) are preferably used. Brassel and Utano [3] have developed a scheme to create grey tones 
by continuously varying patterns from a coarse dot pattern to cross-hatch and solid-fill shading. Where 
this procedure fulfils the basic graphic needs, more efficient algorithms for general area shading would 
be desirable. The basic module required is a routine which generates parallel sets of full and dashed 
lines. By appropriate combination of dash length, dash spacing, and rotation such a routine can be used 
for the generation of cross and point patterns as well. The use of various colors further extends the 
potential of such a scheme. The literature on area shading in a raster environment is extensive [5,7,9,10,13,16], 
but is only of secondary importance to our problem. Various vector type area shading routines are in 
use in a broad range of applications [1,4,6,8,12,14,15,20,22,24,25]. In several cases, however, an explicit 
description of the underlying algorithm is missing. It is assumed that several of the above authors use 
the general polygon shading scheme which is discussed by [4] and [12]. &#38;#169; 1979 ACM O-89791-004--4/79/0800--126 
$00.75 See Copyright Pg. 126 Thls paper presents a new and fast algorithm: YO it uses adjacency information 
of the outline \ segments and breaks the polygon down into SHADING trapezoids and triangles prior to 
shading; it uses only one rotation process. / ~S o.. o. , ....." p" ." . .. XO Figure i Given 
a polygon, a rotation angle and a llne spacing, this algorithm first determines the bounding rectangle 
of the polygon parallel to the direction of the shading lines (Fig. i). Within this rectangle shading 
lines are sequentially processed by computing their intersections with all segments of the polygon outline. 
Valid intersections of the outline segments and one shading line are sorted and palrwise connected. Coleman, 
et al.[4] call thls algorithm the "segment-polygon-algorithm'. Note that adjacencies between outline 
segments are of no consideration in thls algorithm. For a polygon of N vertices which is to be shaded 
with M shading lines this algorithm considers N*M line intersections and uses M minor sorts. Considering 
applications in cartography with thousands of polygons and typical values for M and N in the hundreds, 
it is evident that this traditional algorithm (its complexity is of order O(N*M)) is not efficient enough. 
Alternatives are presented by [4], [20], and [26]. Coleman et al. [4] achieve major improvements by 
first stripping the polygon into bands (a window parallel to the shading lines), while applying the segment-polygon-algorithm 
to the intersection boundary of the window and the polygon outline. Efficiency is improved due to a reduction 
of the quantity of points per intersection boundary. Implicitly thls algorithm is equivalent to a 2-step 
recursive use of the segment-polygon-algorithm. Wood [26] sorts th e polygon outline points into a linked 
list. He then sequentially computes the shading lines by keeping an updated list of active boundary segments. 
His algorithm minimizes core memory. Tobler [20] keeps track of all ups and downs of the polygon outlines, 
i.e. he makes use of information pertinent to outline segment adjacencles. Efficiency is thus improved, 
but the fact that he stores all segment-shading llne intersections makes this program excessive for polygons 
of large sets of points and/or shading lines. All the algorithms discussed so far have in con~non that 
they use two rotation steps: rotation of the polygon vertices into a coordinate system parallel to the 
shading lines, and a rotation of the shading llne endpoints back to the original system. 2__~.. BASIC 
CONCEPTS O__FF THE NE___WW ALGORITHM a) Notations and Data Arrays Given is a polygon in the plane defined 
by a string of outline vertices P(xo,yo) as measured in a coordinate system SO (compare Fig. 2); given 
is also a desired llne spacing DIST and an orientation angle ALPHA. Elements of the outline string defined 
by two adjacent vertices are called outline segments. Define a coordinate system S in the plane where 
the origin of S coincides wlth the origin of SO, where DIST is used as unit length, and where the coordinate 
axes are rotated by ALPHA. Compute the coordinates P(x,y) of all polygon outline points wlth respect 
to S (rotation by ALPHA, scaling by DIST). Sort the array of P's in x and y directions (independently) 
and assign a rank to each vertex with respect to both the x- and y-axes (linked lists of x-ranks, y-ranks). 
Also assign pointers to the next vertices in x and y directions relative to each outline vertex. Table 
 I illustrates the various arrays stored for the polygon In Figs. 2 and 3. Based on thls data structure 
the polygon is now subdivided into trapezoids (in special cases triangles), and the trapezoids are independently 
shaded. Table l OUTLINE SEQUENCE A B C D E F G X-RANK (XR) 1 3 4 7 6 5 2 Y-RANK (YR) 5 7 6 3 1 4 2 
 XO/YO COORDINATES ....... X/Y COORDINATES ....... NEXT X G C F D E B NEXT Y C B F G A D  yo l SO 
B C \ A F \ \ Figure 2 0 127 B C '~ E X Figure 3  b) Trapezoid Extraction The process of subdividing 
the polygon into trapezoids and triangles is initiated at the point of lowest rank in a particular direction: 
Assume we want to shade the polygon in Fig. 3 with lines parallel to the x-axis. As our starting point 
we then select the vertex with the minimum y-coordlnate, i.e. point E (compare also with Table i). We 
further define the two outline edges EF and ED as left (segment clockwise of E) and right (segment counterclockwise 
of E) shading limits. Shading limits will he constantly updated. In the starting phase these shading 
limits are left right EF ED From the semi-bounded region DEF a triangle ED'D is extracted for shading. 
Since y-rank(D) < y-rank(F), D" is defined such that y(D')=y(D) and E,D',F collinear. DD" is called the 
upper limit of the triangle to be shaded. At this point, however, it is not known whether the triangle 
ED'D can be shaded entirely or whether there is some insinuation point P within the triangle, as this 
is indicated in Fig. 4. To find a potential insinuation point P a point-in-trapezoid (triangle) search 
is performed. This search makes use of the rank pointers defined above (x-rank: XR(i), y-rank: YR(i)). 
 For all points P: YR(E) ---> YR(D) check for XR(F) < XR(P) < XR(D). A point P which fulfils this condition 
is located within a window defined by E,D (y-direction) and .......... ................... i E Figure 
4  D,F (x-direction). Such a point P has to further he tested against the left and right limits of the 
active trapezoid (triangle). In the illustration example in Fig. 3 obviously no point P fulfils this 
condition. Therefore, the triangle ED'D can be subjected to the shading procedure as explained in section 
2c. In the next step the shading limits are updated as follows: left right update left right EF ED 
...... > D'F exhausted Since the right shading limit is exhausted, we retrieve a new segment from the 
polygon outline. In our example (Fig. 3) this is DC, i.e. the segment next to ED in the counterclockwise 
outline sequence. The shading limits are now defined as: left right D'F DC  Since YR(F) < YR(C) define 
the trapezoid D'FF'D with F" such that y(F')=y(F) and D,F',C collinear. Since no further point is within 
D'FF'D this trapezoid is being shaded. Updating of the shading limits results in: left right exhausted 
F'C To replace the exhausted left shading limit retrieve the next clockwise outline segment FG. Since 
YR(G) < YR(F), however, the segment FG cannot be a left shading limit, but rather a right shading limit 
of some other trapezoid. Therefore, search along the clockwise outline sequence for a local minimum; 
use its two adjacent segments as the two shading limits; and push the old shading limit(s) down into 
a stack. Since G is a local minimum the updated shading limits are as follows: left right GA GF --F'C 
(stack). In the subsequent step F" will he defined and the triangle GF"F will be shaded. Since GF is 
exhausted segment F'C is brought back from the stack: left right F"A F'C It can now easily be seen 
that the shading sequence for the remainder of the polygon is: F"AA'F" AC'CA" and C'BC. So far we have 
not discussed the case where an insinuation point P is located within a preliminary trapezoid (figure 
5). The shading limits in this situation are: left right ~" ED D'F and a point P is found to he within 
ED'D. Eliminate point D', shade the triangle EP'P" and update the shading limits as follows:  128 0 
R YO DI ....... ~.-. ........... ........ ~/ Figure 5 E left right PR P"D P'F(stack) PQ (stack). 
 The polygon is thus broken down into a left and right branch, where the right branch is pursued first 
(PR,P"D), while the left branch (P'F,PQ) is kept in the stack until the right branch is exhausted (Fig. 
6a). The stack may contain two types of records: (I) single left or right shading limits for which opposite 
shading limits have not yet been detected, and (2) pairs of opposite shading limits which initiate a 
new polygon branch. It is reasonable to keep these two types separate in a primary (I) and a secondary 
(2) stack. If point P is the bottom point of an island, the right branch shading is performed until 
the top of the island (T) is reached (Fig. 6b). At this point the search for a valid left shading limit 
follows the left island boundary to find a local minimum. Along this search path P is recognized as the 
bottom of an island; this is the signal to recall the left branch from the secondary stack for further 
processing. T ! F D < 0 p, g E (A) Figure 6 (B) c) Trapezold Shading Given a trapezoid ABB'A'(FIg. 
7) which is to  be shaded by lines parallel to AA" and BB" (AA" and BB" are parallel). The coordinates 
of these points are known in both coordinate systems SO (P(xo,yo)) and S (P(x,y)), where the shading 
lines are to be drawn parallel to the x-axis of the S system. We assume the measurement units in the 
S system to be equal to the llne spacing DIST; then the y-coordlnates rounded to integer values equal 
to  \ ",,_ / ~ P^. \ / A'P~21 P2d \ XO \ X~ Figure 7 the ID-number of the shading lines where llne 
#0 cuts through the system origin. The task at hand is to compute the endpoints Pi~ of the set of shading 
lines within the trapezoid ABB'A'. Given the y-coordinates of points A and B the endpolnts Pi" are located 
on AB at integer coordinate lo~ations of the y-axls. The y-coordinate of PII' for example, equals to 
 y(PII ) = IFIX (y(A) + .99999 ) and the ratio R1 = APII/AB can be expressed as R1 = ( y(Pll ) - y(A) 
) * YAB, where YAB = l./(y(B) -y(A)). Define the ratio R2 as "one shading llne increment as a ratio 
of the distance AB ": R2 = ( y(Pl2 ) - y(pu) ) * YAB = YAB R1 is used to compute the coordinates of 
the first shading llne endpolnt P I' where its computation is directly performed in the original coordinate 
system SO: xO(Pll) = xo(A) + R1 * DX yO(Pll) = yo(A) + R1 * DY,  where DX= xo(B) -xo(A) and DY = yo(B) 
-yo(A). Notice that the above coordinates are measured in the SO system, so that no rotation is required 
here. The increment between subsequent llne endpolnts in the SO system is DXO = DX * R2 DYO = DY * 
R2.  The coordinates of the shading endpoints are thus xO(Plj) = xO(Pl,j_ I) + DXO yO(Plj) = yO(Pl,j_ 
I) + DYO~  where j=2 ...k k = IFIX (y(B) ) - y(Pll ) + I. The shading llne endpoints P~ on A'B" are 
computed in analog fashion, points PIJ and 129 P^. are pairwise connected and the lines pi~tted. The 
computation of the end points of the first shading llne requires thus 14 additions and 16 multiplications, 
where for each subsequent shading llne 4 additions are needed. A necessary condition is that the resolution 
of the binary coordinate representation be higher than the distance between consecutive shading lines, 
 3__=. IMPLEMENTATION AND EVALUATION The algorithm as described has been encoded in FORTRAN IV and implemented 
on an IBM 370/155. An overview of the procedure is given in Fig. 8. First, duplicate adjacent polygon 
outline points are eliminated. Further, polygons consisting of various islands (up to 299 islands are 
allowed) are preprocessed (outline strings are identified as islands). The outline points are then rotated 
and scaled (xo,yo ---> x,y). The transformed values are sorted in both x-and y-dlrections, and duplicate 
points which are non-adj acent in the string sequence are separated by a small distance. These preprocessing 
steps construct the data arrays as shown in table I. The actual shading procedure, i.e. the decomposition 
into trapezoids and triangles is then performed in a single or double call (cross-hatching) to a procedure 
called TRAPEZ. Note that for orthogonal cross-hatching the preprocessing steps have to be performed only 
once (re-use of the values in Table I, with x and y reversed). After completion of the shading, control 
is returned to the calling procedure for handling of a next polygon. ELIMINATE DUPLICATE ADJACENT POINTS 
r-I 1 I BUILD ISLANDS ,I -ROTATE AND SCALE I ' TRAPEZ: DECOMPOSE AND SHADE IN 1ST DIRECTION TRAPEZ: 
DECOMPOSE AND SHADE (ORTHOGONAL CROSS-HATCH) FIGURE 8  Ii= =o==ol ADJUST IF COUNTERCLOCKWISEJ IOEF,NE 
PREL'M'NAR" TRAP"O' J SPLI T PRELIMINARY TRAPEZOIDS NTO THREE PARTS: A) BOTTOM LEFT C) RIGHT BRANCH YEs 
B) SHADE BOTTOM N D ~ INTC PUT LEFT BRANCH iNTO STACK PU] CONTINUE PROCESSING WITH RIGHT BRANCH SHAD 
E TRAPEZOID 1 LIMIT (LEFT OR RIGHT) NO YES PRESENT BRANCH YES EXHAUSTED SEARCH FOR VALID I LOCAL MINIMUM 
NO J~PO INT OF FIGURE 9 ROUTINE TRAPEZ GET BRANCH I~ FROM STACK The procedure for decomposition and 
shading (TRAPEZ) is illustrated in Fig. 9. First, the order of the polygon (clockwise, counterclockwise) 
is determined and some related parameters are initialized. The low point and the first two shading limits 
are established, and a first preliminary triangle (trapezoid) is defined. This preliminary triangle is 
tested for inclusion of any other outline point. If no point is within the trapezoid, it is being shaded, 
and a new valid shading limit (left or right) is searched for. The new pair of active shading limits 
is used again to define a new preliminary trapezoid. If no valid new adjacent shading limit can be found 
--be it that the shading branch is exhausted or that the low point of the newly found shading limit is 
a member of the secondary stack --the present branch is abandoned and a new branch is retrieved from 
the secondary stack. If the search for an outline point within a preliminary trapezoid is successful, 
the preliminary trapezoid is split into three 130 parts: (a) the bottom part (below the newly found 
point) is shaded and eliminated from the list, (b) the left shading branch is entered into the secondary 
stack, and (c) the right branch is used for immediate processing, i.e. its shading limits define the 
next preliminary trapezoid. The procedure terminates when all shading branches are exhausted. The basic 
procedure consists of iterations of  (a) the definition of preliminary trapezoids, (b) the test for 
inclusion of outline points within the preliminary trapezoid, (c) trapezoid shading, and  (d) the search 
for new valid shading limits, where for each outline point within a preliminary trapezoid a branch is 
put on the stack, and each exhausted branch is replaced from the stack.  Figure i0 illustrates the 
shading of a complex polygon, where triangles and trapezoids are labelled in their processing sequence. 
The shading procedure may be compared to the filling of an arbitrarily shaped container with water, where 
the influx pipe is at the lowest point of the container (MIN). The liquid first fills the volume labelled 
1 (Fig. 10) and then flows over into area 2. Whenever the water level reaches some insinuation point 
propagating from the top (TP), then the filling process is artificially interrupted to the left of the 
propagating point. The blocking of the left branches is achieved in the program by using the secondary 
stacks. These blockages are re-opened when either the right branch is entirely filled, or if the water 
overflows the top of the island. The procedure as implemented keeps all arrays in core memory and is 
thus programmed for time efficiency. The stoarge requirements for this version are approximately 15K 
(or 22.6K if not overlaid) + 16N + 8NI + 32NS bytes, where N is the maximum number of outline points 
in any single  polygon, NI is the number of islands, and NS is the number of shading limit stacks. 
For a polygon with N outline points which is to be shaded by M parallel lines, traditional segment-polygon-algorithms 
involve as their major operations M*N computations of line intersections, at least N + 2M rotations, 
and M minor sort steps. For cross-hatching these values are doubled. The order of operations performed 
in the various parts of the trapezoid algorithm is given in Table 2. The present algorithm requires 
two sorts (O(N log N)), the creation of NT = N -i + NI trapezoids (NI = number of islands), and the shading 
of NT trapezoids. The sort steps do not have to be repeated for orthogonal cross-hatching. Non-linear 
behaviour of the present algorithm is observed with the elimination of duplicate points, the sorts, and 
the search for points within the preliminary trapezoids. This search for points within a preliminary 
trapezoid appears to be the most critical step. As a characteristic index for the polygon we use the 
"number of lobes", i.e. the ratio of the y-range of all trapezoids divided by the polygon height. A convex 
polygon would have a lobe number NL = I where for a polygon consisting of two external islands of the 
same height NL = 2; the polygon in Fig. 10 has a lobe number NL = 3.03. For maximally dissected polygons 
NL would approach N/2. In these extreme cases the number of p@ints consulted in the insinuation test 
approaches N~/2. However, this has no practical impact since most of the points can be immediately eliminated 
by a simple check against the two x-limits of the preliminary trapezoids; further, all points which are 
not local minima are eliminated as well, so that the overall number of point-in-trapezoid checks for 
the entire polygon is smaller than the number of local minima NLM in the polygon (NLM < N/2). This point-in-trapezoid 
test is thus linear. MIN 131 OPERATION COMPLEXITY Eliminate duplicate points N * NDP Build island 
N Rotate and scale N Sort and separate N log N Initialize trapez routine C Define preliminary trapezoids 
NT Search for points within prelim, trap.: a) Search for all points within y-range of all trapezoids 
NT*[I+(NL-I)*NL]  b) Point-in-trapezoid search < NLM Split preliminary trapezoid NIP Polygon shading: 
 a) Initialization + first line (all trap.) NT b) Additional lines (all trap.) NL*Hp/SP-NT Get next 
shading limit NT Search for valid local minima <N Retrieve branches from stack <NLM N = Number of outline 
points in polygon NI = Number of internal islands in polygon NE = Number of external islands in polygon 
 NDP = Number of duplicate adjacent points C = Constant NT = Number of trapezoids = N + NI -NE NT 
 NL = Number of lobes in polygon = ~ Hi/Hp i=l NIP = Number of insinuation points (<N/2-1) NLM = Number 
of local minima = number of local maxima (<N/2) Hi Height of the ith trapezoid (y-range) Hp Height 
of the polygon (y-range) SP Line spacing for polygon shading  Table 2. Number of Operations used in 
Trapezoid Shading. The overall performance of the algorithm depends basically on the line spacing, the 
lobe index, the number of outline points and the number of islands. Empirical results comparing the trapezoid 
method with the segment-polygon algorithm are shown in Table 3. Test I and 2 measure the total execution 
time for polygon shading, whereas tests 3 through 8 record only the actual shading work --excluding input 
and plotting. Fig.ll graphically displays the major findings related to tests 3 -8 above. The results 
suggest that the major strength of the trapezoid algorithm lies with high density shading, i.e. the shading 
of polygons for which the ratio R = M / N (M = # of shading lines per polygon) is high. Where both 
the sort and the trapezoid extraction steps are insensitive to M the shading of the trapezoid heavily 
depends on the line density. For polygons with an average of 12 outline points the present algorithm 
is better if R>.3 (i.e. if at least 3.6 shading lines are drawn), for polygons with more points the critical 
values of R is expected to be lower. Further, the efficiency of both algorithms depends on the number 
of outline points in a polygon. The trapezoid algorithm, however, is less sensitive to large numbers 
of outline points. In absolute terms ('CPU total') the trapezoid shading algorithm performs significantly' 
better than the segment-polygon-algorithm, exept in the tests 3 80 - Z --T,a~zoid Algorit hm T/ / Y 
o oo -----Segment -Polygon // Algorithm I I 4o I I z 20 ~-~o W 0. 2 F- (I) uJ ,6 o ~ .~ .6 , ~ ~ ~ 
1o 20 4; golo PROCESSING TIME PER SHADING LINE (IN MILLISECONDS) ~/~{{~ Figure !i # # OF # OF # OF 
PTS./ LNS / CPU CPU/ CPU/ ALG POLY. PTS. LINES POLY. PTS. tot. PT. LINE .......................................................... 
1 1822 44540 6987 24.44 .16 143. 3.21 20.47 TRP 176. 3.95 25.19 SEG  2 3886 169109 22916 43.51 .14 
617. 3.64 26.92 TRP 1284. 7.59 56.03 SEG 3 152 1786 109 11.75 .06 3.22 1.80 29.54 TRP 1.27 0.71 11.65 
SEG 4 152 1786 290 11.75 .16 3.73 2.09 12.86 TRP  2.38 1.33 8.21 SEG 5 152 1786 2254 11.75 1.26 5.18 
2.90 2.30 TRP  14.36 8.04 6.37 SEG 6 152 1786 22129 11.75 12.4 9.38 5.25 .42 TRP 128.6 72.0 5.81 SEG 
7 633 18842 3005 29.77 .16 51.41 2.73 17.10 TRP 157.0 8.35 52.27 SEG  8 633 18842 28526 29.77 1.51 
68.26 3.62 2.39 TRP 1655. 87.8 58.03 SEG ............................................................ 
 Table 3. Results of Test Runs. Tests 1 and 2 measure total execution time, test 3 through 8 do not include 
input and plotting operations. CPU tot. gives the execution time in seconds on an IBM 370/155. CPU/PT 
and CPU/LINE are given in milliseconds. and 4 where both the number of outline points and the number 
of shading lines are small (light shading of simply-shaped polygons). The shading test runs were performed 
with a land cover map file with a multitude of islands (Fig. 12). Figure 12  132 4. CONCLUSIONS We 
have presented an algorithm for shading of polygons on vector display devices. This algorithm disaggregates 
the polygon into a set of triangles and trapezoids parallel to the direction of the shading lines. The 
basic structures used thus are similar to the "slab" methods used in some point-in-polygon algorithms 
[17,18]. Similarities also exist with elements of scan type hidden line algorithms [2,11,19,23]. An implementation 
of the described algorithm on an IBM 370/155 has proven highly efficient. Where the present implementation 
is optimized with respect to execution time, future modifications will reduce storage requirements for 
the implementation on minicomputers. Planned extensions of the method include the shading by systematic 
dash or cross patterns. Further, future efforts will have to be directed towards a systematic comparative 
analysis of the present procedure and various other methods for vector type shading, including the potential 
of elements of scan type hidden line algorithms for area shading. REFERENCES i. Baxter, R.S., Choropleth 
Mapping Program By Computer, Manuscript, Building Research Establishment, Garstom, Watford, U.K., 26 
pgs. 2. Bouknight, W.J., 1970, "A Procedure for Generation of Three-dimensional Half-toned Computer 
Graphics Representations", Communications ACM, ~ Vol. 13, No. 9, pp. 527 -536. 3. Brassel, K.E. and 
J.J. Utano, 1979, "Design Strategies for Continuous-tone Area Mapping", The American Cartographer, Vol.6, 
 No. I (forthcoming).  4. Coleman, P.R., R.C. Durfee, and R.G. Edwards, "Application of a Hierarchical 
Polygon Structure in Spatial Analysis and Cartographic Display", Harvard Papers o__n_n Geographical Information 
Systems, Vol. 3, 20 pgs.  5. Jarvis, J.F., C.N. Judice, and W.H. Ninke, 1976, "A Survey of Techniques 
for the Display of Continuous Tone Pictures on Bilevel Displays", Computer Graphics and Image Processins, 
Vol. 5, pp.13-40.  6. Kern, H., 1978, "Neuere Techniken der Flaechenschraffur und der Herstellung von 
Farbauszuegen in der automatisierten thematischen Kartographie" (Recent Techniques of Area Shading and 
Color Separation in Automated Thematic Cartography), Kartographische Nachrichten, Vol. 28, No. i, pp. 
1-11.  7. Knowlton, K. and L. Harmon, 1972, "Computer-Produced Grey Scales", Computer Graphics and Image 
Processing, Vol. I, pp. 1-20.  8. Laboratory for Computer Graphics and Spatial Analysis, 1976, CALFORM 
User's Manual. Cambridge: Harvard University.  9. Lieberman, H., 1978, "How to Color In A Coloring Book", 
Computer Graphics, Vol. 12, No. 3, pp. 111-116.   i0. Negroponte, N., 1977, "Raster Scan Approaches 
to Computer Graphics"~ Computers and Graphics, Vol. 2, pp. 179-193. II. Newman, W.M. and R.F. Sproull, 
1973, Principles of Interactive Computer Graphics. New York: McGraw-Hill. 12. Monmonier, M.S., and D.M. 
Kirchoff, 1977, "Choroplethic Plotter Mapping for a Small Minicomputer", Proceedings of the American 
Congress o_nn Surveying and Mapping, 37th Annual Meeting, Wash., D.C., pp. 318-338.  13. Pavlidis, Th., 
1978, "Filling Algorithms for Raster Graphics", Computer Graphics, Vol. 12, No. 3, pp. 161-164.  14. 
Rase, W.D., SRAFOF shading subroutine, private communication.  15. Rase, W.D., 1978, "Computer-assisted 
Thematic Mapping for Federal Planning", Nachrichten aus dem Karten-und Vermessun~swesen, Series II: Translations, 
No. 35, pp. 77-83.  16. Rosenfeld, A. and V.C. Kak, 1976, Digital Image Processing. New York/London: 
Academic Press.  17. Salomon, K.B., 1978, "An Efficient Point-in-Polygon Algorithm", Computers and Geosciences, 
Vol. 4, pp.173-178.  18. Shamos, M.I., 1977, Computational Geometry. Berlln/New York: Sprlnger-Verlag. 
 19. Southerland, I.E., R.F. Sproull and R.A. Schumacker, 1974, "A Characterization of Ten Hidden-Surface 
Algorithms", Computing Surveys, Vol. 6, No. I, pp. 1-55.  20. Tobler, W.R., 1971, Choropleth Mapping 
Programs. Cartographic Laboratory Report No.6, Dept. of Geography, Univ. of Michigan, Ann Arbor.  21. 
Tobler, W.R., 1973, "Choropleth Maps without Class Intervals?", Geographical Analysis,Vol. 5, pp. 262-265. 
 22. U.S. Geological Survey, Geography Program: Routine SHADT, personal con~unlcation.  23. Watkins, 
G.S., 1970, A Real-Time Visible Surface Algorithm, Computer Science Department, University of Utah, UTECH-CSc-70-101. 
 24. Waugh, T.C., and D.R.F. Taylor, 1976, "GIMMS / An Example of an Operational System for Computer 
Cartography", The Canadian Cartographer, Vol. 13, No. 2, pp. 158-166.  25. Wood, P.M., and D.M. Austin, 
1975, "CARTE: A Thematic Mapping Program", Computers an___dd Graphics, Vol. I, No. 2/3, pp. 239-250. 
 26. Wood, P.M., 1978, "Interactive Display of Polygonal Data", Harvard Papers o__n_n Geographic Information 
Systems, Vol. , 20 pgs.  ACKNOWLEDGEMENTS This project has been supported by the Geography Program, 
U.S. Geological Survey. Mr. Mike Wasilenko and Ms. Karen Weiss have contributed to the various figures 
in this paper.  133 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807435</article_id>
		<sort_key>134</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[An algorithmic approach to controlling search in three-dimensional image data]]></title>
		<page_from>134</page_from>
		<page_to>142</page_to>
		<doi_number>10.1145/800249.807435</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807435</url>
		<abstract>
			<par><![CDATA[<p>In many three-dimensional imaging applications random shaped objects, reconstructed from serial sections, are isolated to display their overall structure in a single view. This paper presents an algorithm to control an ordered search strategy for locating all contours of random shaped objects intersected by a series of cross-section image planes. Classic search techniques in AI problem solving and software for image processing and computer graphics are combined here to aid program initialization and automate the search process thereafter. Using three-dimensional region growing, this method isolates all spatially connected pixels forming a structure's volume and enters image planes the least number of times to do so. An algorithmic description is given to generalize the process for controlling search in 3-D image data where little core memory is available. Phantom and medical computer tomographic data are used to illustrate the algorithm's performance.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Control theory</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010213.10010214</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods->Computational control theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010213</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P332135</person_id>
				<author_profile_id><![CDATA[81100310739]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M&#236;chael]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Rhodes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles, Los Angeles, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chow, C. K., and Kaneka, T., "Boundary Detection of Radiographic Images by a Thresh. Method," IBM Report RG3203, December 1970.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Ausherman, D. A., Dwyer, S. J., and Lodwick, G. S., "Extraction of Connected Edges from Radiographs," IEEE Trans. Computers, C-21, 1972, pp. 753-758.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ballard, D., and Sklansky, J., "Tumor Detection in Radiographs," Comput. Biomed. Res. 6, 1973, pp. 299-321.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carton, E., Weszka, J., Mohr, J., Rosenfeld, A., "Some Basic Edge Detection Techniques," Univ. Maryland Tech. Rep. TR-277, Dec. 1973.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bullock, B., "The Performance of Edge Operators in Images with Texture," Hughes Air. Co. Tech. Rep., Malibu, CA., Oct. 1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1312083</ref_obj_id>
				<ref_obj_pid>1311926</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Frei, W., Chen, C. C., "Fast Boundary Detection: A Generalization and a New Algorithm," IEEE Trans. Comp., Vol. C-26, No. 10 pp. 988-998.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chien, Y. P., and Fu, K. S., "A Decision Function Method for Boundary Detection," Comp. Graphics and Image Proc., 3, 1974, pp. 125-140.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mazziotta, J. C., Huang, H. K., "THREAD (Three dimensional Reconstruction and Display) with Biomed. Applic. in Neuron Ultrastructure and Comp. Tomography," Proc. Nat'l Comp. Conf. AFIPS 1976, Vol. 45, AFIPS Press, Montvale, N.J., pp. 241-250.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Liu, H. K., "Two-and-Three-Dimensional Boundary Detection," Comp. Graph. and Image Proc., 6, 1977, pp. 123-134.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cohen, P., Livingston, R., Sumners, R., Application Programs for Computer Graphics, "Dynamic Viewing of CT Image Data," 16-mm film, Roch Laboratories Inc., and the Neuroscience Department, Univ. Cal. San Diego, La Jolla, CA., 1978.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Shantz, M. J., McCann, G. D., "Computational Morphology: Three-D Comp. Graph. for Elec. Microscopy," IEEE Trans. Biom. Eng., Vol. BME-25, No. 1, Jan. 1978, pp. 99-102.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Yakimovsky, Y., Cunningham, R., "On the Problem of Embedding Picture Elements in Regions," Jet Prop. Lab. Tech. Report No. 33-774, Pasadena, CA., June 1976.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Rhodes, M. L., Glenn, W. V., Klinger, A., "Interactive Volume and Surface Iso. Using Tomogr. Data," Proc. San Diego Biom. Symp., Feb. 1-3, 1978, pp. 403-411.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321570</ref_obj_id>
				<ref_obj_pid>321556</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A., "Connectivity in Digital Pictures," J. ACM, Vol. 17, No. 1, 1970, pp. 146-160.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jackson, P. C., Intro. to Artificial Intel., Mason/Charter Pub. Inc., New York, 1974.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1098661</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nilsson, N. J., Prob. Solv. Methods in Art. Intel., McGraw-Hill, New York, 1971.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30424</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Winston, P. H., Artificial Intelligence, Addison-Wesley, Menlo Park, CA., 1977.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z. M., Uselton, S. P., "Optimal Surface Reconstruction from Planar Contours," Comm. ACM, Vol. 20, No. 10, Oct., 1977, pp. 693-702.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356573</ref_obj_id>
				<ref_obj_pid>356571</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Denning, P. J., "Virtual Memory," Computing Surveys, Vol. 2, No. 3, Sept. 1970, pp. 153-189.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AN ALGORITHMIC APPROACH TO CONTROLLING SEARCH IN THREE-DIMENSIONAL IMAGE DATA M~chael L. Rhodes University 
of California, Los Angeles Los Angeles, California Abstract suited. In many three-dimensional imaging 
applications random shaped objects, reconstructed from serial sections, are isolated to display their 
overall structure in a single view. This paper presents an algorithm to control an ordered search strate- 
gy for locating all contours of random shaped ob- jects intersected by a series of cross-section image 
planes. Classic search techniques in AI problem solving and software for image processing and computer 
graphics are combined here to aid program initialization and automate the search process thereafter. 
Using three-dimensional re-gion growing, this method isolates all spatially connected pixels forming 
a structure's volume and enters image planes the least number of times to do so. An algorithmic description 
is given to generalize the process for controlling search in 3-D image data where little core memory 
is avail- able. Phantom and medical computer tomographic data are used to illustrate the algorithm's 
per- formance. I. INTRODUCTION There are numerous edge detection algorithms ublished for two-dimensional 
digital images l I-8) but few have been reported for processing three-dimensional data (9). Due to their 
accur- acy and interaction two-dimensional techniques have been appropriate for most applications, including 
those involving three,dimensional data. For example, in microscopy, computer-calibrated tracing pens 
are used to locate structure con- tours for computer graphics display. Tracings are made for each digitized 
photograph made from microscopes focused at regular levels within a transparent specimen. For opaque 
specimens image planes are digitized that show a specimen's newly exposed surface after slices are cut 
at regularly spaced intervals. Dramatic views of the human brain (lO) and neural tissue of the vertebrate 
retina (ll) have been produced using such contour tracing techniques. Edge detection for slow image generation 
systems can use 2-D methods applied manually or interacti-vely without extensive additional cost in compu-ting 
time. Data generated are off-line and ex-cept for a few image processing research facili-ties photograph-to 
scanner-to digital files is so protracted that 2-D edge finding methods are well Whenever digital image 
generation is slow or only a few parallel planes are available for three di-mensional applications, there 
is no need for fast or automatic algorithms to find structure cross-section contours. However, once a 
large volume of image data (comprising several planes) is produced quickly and fast object isolation 
is desired, an automatic, three-dimensional method is needed. Such characteristics describe the environment 
for clinical analysis of image data from computer tomo-graphic (CT) scanners and new ultrasound imaging 
devices. Edge detection for clinical image analysis should be on-line, need little user interaction, 
and exe- cute with speed close to the rate at which images are generated. Work reported here is directed 
to those applications where fast automatic edge de- tection is desired for 3-D image analysis. Our goal 
is to develop an algorithm that will isolate a single structure fast with as little user inter- action 
as possible. Using such a program a 3-D image investigator could start the isolation pro- cess, resume 
his other duties, then return to a display of the object's contours isolated. In section II.l we briefly 
describe planar aspects of our strategy. Though region growing is used in th~s work, we point out changes 
necessary for a contour-following approach that may further speed the isolation process. Section II.2 
presents a plane-to-plane connection strategy that limits search in z-adjacent x~y planes and eliminates 
the need for user interaction when each is examined. In section II.3 we give an algorithmic description 
of our technique to re-enter image planes to find complete structure contours. Using this plane connection 
strategy of section II our plane re- entrance technique enters planes the least number of times to find 
all contours for random-shaped structures. II. MET__HODOLOGY Key three-dimensional aspects of our complete 
iso- lation algorithm lie in its ability to automatic- ally provide connection between planes, enter 
new ones, and re-enter image planes when necessary to find complete object boundaries. This third di- 
mension control of edge detection is presented in Sections II.2 and II.3. In the first section we 1979 
ACM O-89791-004--4/79/0800--134 $00.75 See Copyright Pg. 134 examine two-dimensional aspects of the algorithm 
and its data structures. II,I Planar Algorithm The region growing algorithm introduced below is two-dimensional 
and based on an image segmentation algorithm developed by Yakimovsky and Cunningham (12). We have maintained 
the algorithm's two-di-mensional nature in spite of a three-dimensional data environment. Though 2-D 
region growing can be extended to "volume" growing we have limited the search for structure edges to 
planar data first. By processing as much as possible per plane we ex- ploit the planar arrangement of 
image data and re- duce the frequency image planes are read from au- xiliary storage: I/0 delays are 
reduced. Addi-tional execution speed is made possible by using large I/0 buffers. Due to memory savings 
made possible by the algorithm's data structures larger portions of each image can be core resident during 
execution. Fig., 1 shows major components of the region grow- ing algorithm. A scenario of computer issued 
prompts and user replies determines three inputs interactively: I) AN IMAGE ARRAY: the two-dimensional 
image matrix D(i,j,k), {XMIN<i XMAX, YMIN<j<YMAX, ZMIN<k<ZMAX}, where k=-CK is constant, 2) A REGION 
ACCEPTANCE CRITERION: a decision function DF(i,j,k) to determine region membership and, 3) A SET OF SEED 
PIXELS: SD: {(i,j,CK) 0 ..... (i,j,CK)n}, n>_0. These pixels are the first to be tested for region membership. 
II~PUT OUTPLIT I SbRRAY 2-D P.EGIC~I GP.OWING ~d~T~DP.ITI-~4 AREA ARRAY FUNCTION y Figure I. Region 
Growing Components In addition to input components for the planar al- gorithm, two data structures used 
by the algorithm are illustrated in Fig., I: I) a linked list structure that represents pixels found 
to be region members on plane k=CK and, 2) a queue that stores candidate pixels to be tested for region 
membership. The algorithm produces two results: an area image containing all pixels found to be in the 
region on plane k=CK, and an edge image containing only the structure's surface intersection with the 
plane. The algorithm is a simple ordered search process that examines perimeter pixels of a growing region: 
Every seed pixel tested by the algorithm, and found to be a region member, generates eight (or fewer) 
candidate pixels to be tested for membership. 0nly the eight neighboring pixels are possible candidates, 
and of these, only pixels not already re-gion members are chosen. Pixels chosen as candidates are placed 
in a queue to be tested for membership. Those that fail acceptance are discarded and do not gene-rate 
candidate pixels, those that pass are entered as region members and generate candidate pixels themselves. 
Terminate when the candidate queue is empty and no additional seeds are provided for the plane. The 
algorithm is a breadth-first search that exa-mines all eight same-plane neighbors of each pixel already 
found to be a region member (see (13) for full description), If we add the restriction that only one 
candidate can be accepted for membership (for each pixel al-ready chosen) we form an algorithm that constructs 
paths of one pixel width. Added provisions for ordering the eight candidates for selection, back-tracking 
on dead-end edges, and end-point-start- point identity forms a contour following algorithm that can use 
the organization and data structures of region growing for implementation. (With pro- visions mentioned 
above we have developed a con- tour follower, with auto,backtracking, that is fast and reliable.} Since 
typically far fewer pixels are tested for contour membership than for region membership, the contour 
follower has a clear advantage in execu-tion speed but complicates the connection strategy as the planar 
algorithm advances from one image plane to the next. For example, "bubble" surfaces within an object 
are difficult to detect auto-matically using contoun-following as the planar algorithm. Such surfaces 
are detected as a matter of course using region growing and due to this we have used region growing during 
program develop- nw~nt. In what follows we will confine planar aspects of edge finding.to region growing 
and use terminolo- gy from digital connectivity defined below. Using natural concepts of connectedness 
given here and in (14) we can form an automatic plane-connection strategy for region growing algorithm. 
(The cor-responding strategy for a contour following al-gorithm requires similar pixel testing with added 
provisions to detect "bubble" surfaces.) Let 13 denote the set of all integer triples (i,j,k), which 
are picture elements in three-space. Let A={(il, j l, k]) ..... (iq, jq, kq)} be any q- tuple of (i,j,k)'s, 
q~l. We call A a right-path in space if for each p, where l<_p<q, we have lip -ip+ 1 I + lJp -Jp+l I 
+ Ik k -kp+ l I ~ I: the condition allows (ip+ l, Jp+l' kp+l) to be the same as (ip, jp, kp) or any of 
its six orthogonal neighbors. Similarly, we call A an angle-path in space if for each p t4~X(li p -ip+ll, 
IJp -Jp+l I , Ikp -kp+iI)<_l; this condition also allows (ip+l' Jp+l' kp+l) to be the same as (ip, jp, 
kp), its eight horizontal, vertical, diagonal neighbors on plane kp, or any of the nine neighbors on 
either plane k + l or k -I. The set of twenty-six P P angle neighbors of (i,j,k), is denoted by AN(i,j,k) 
and the set of six right neighbors RN(i,j,k), (Aproper subset of AN~. II.2 Plane Connection As region 
growing proceeds from plane k to k+l, at least one seed pixel is needed for each area in k+l that is 
a structure cross-section angle-conn-ected to a region member on plane k. For some structures one seed 
pixel is sufficient on each plane (consider a sphere intersected by parallel image planes) while other 
structures require mul- tiple seeds (consider a fork intersected by planes normal to its axis). For complete 
isolation of random objects, all pixels angle-connected to re-gion members need examination for region 
member- ship, a requirement that may exhaust core memory. In fact, for our implementation, all candidate 
pixels cannot be core resident (i.e. when stored explicitly, pixels for an area 128x128 need 16K of 16 
bit/word storage; l byte/coordinate). Our solution eliminates the need for extensive core memory. A data 
communication strategy is used to transmit seeds generated from plane k to region growing software operating 
in either neigh- boring plane. Two concurrent subroutines inter- act: one transmits seeds generated from 
the area image of plane k to another receiving routine that tests seeds for acceptance and initiates 
re- gion growing. This method, described below, uses I/0 buffer space to read the plane k area image 
from auxiliary storage: no large candidate queue is needed. Each pixel in the area image of plane k+l 
or -l depending oh direction of advance generates nine seed pixels (the angle neighbors on plane k~l). 
In effect, this action creates the set of candidate pixels shown in the lower right of Fig., 2 from the 
region members shown in the lower left. Seeds angle-connected to area members on the neighboring plane 
(candidate records) are transmitted until all pixels in the area image are exhausted. When a seed is 
accepted for region membership in the new plane, transmission of seeds to the region grower is suspended 
and region growing begins ab- out the accepted seed. During region expansion all pixels examined in plane 
k+l have their right-neighbors in plane k eliminated. This action eli- minates seeds already tested for 
membership from the pool of potential region members (Fig., 3 illustrates the strategy). j "LY ; K I 
.6 -S- ~ / / ---K+I 8 2-D ~IGHI~I~S 26 3-D EI(IiBOI~S VO~ PI~a~LS l:OOIx~)  CANDII~ATE VOL~ PIXEI~ IN 
PlA~IE k k+l A~ k-i I I Figure 2~ Spatial Connectivity K KI ~ TOFI~ IN IN K K+I ,.a~ L~J~ s~mt I~R 
ONCE A CAhB)II~TE IS ~l~ FOR IvIa~BERSHIP  SI.~I~ID ~ RI~GION GROW ~SSION OF ~ LWrlL QUEUE IS CA~II~TES 
EX~ RESUME ONCEA CA~I~TE IS AO~ SUSPI~) I~.GI(IN ~ION Figure 3. Example Showing Connection Strategy 
II.3 Re-entering Image Planes The 'S'~shaped structure in Fig., 4, intersected by 5 parallel image planes, 
illustrates the need for image plane re-entrance to isolate complete structure contours. Table l shows 
five cases where region growing is applied to locate struc- ture surface intersecting these planes. If 
con-trol of the planar algorithm is limited to one examination of each plane, an incomplete set of cross-section 
contours for the structure will be detected. Notice in every case Some contours are not discovered. 
 K-2 K-I K K-,-I K+2 I I lation can now be treated as controlling the crea- tion of a directed graph. 
For example, Fig., 5 shows a directed graph where image planes were re- entered to find all contours 
of the 'S' shaped structure in Fig., 4. Region growing proceeded from plane k, area A, through the states 
labeled I-5, back to node A and then nodes 6-I0. cmew RBGION ~OF smqm~ Oe CONTOURS ~ IN PIA.N~ EXAMIN~ 
~ FOUND MISSED 1 4 (5,5) k,k+l,k+2,k-l,k-2 4,5,2,5 1,A,6,7,8,9,10 2 A (6,1) k,kl,k+2,k-l,k-2 A,I,2,6,7 
5,4,S,8,9,I0 cA.s~ 5 9 (8,10) k,k+l,k+2,k-l,k-2 9,10,8,7 I,Z,3,4,S,6,A 4 2 k+2,k+l,k,k-l,k-2 2,5,1,4,.A,5,6,7 
8,9,10 5 7 k-2,k-l,k,k+l,k+2 7,6,8,A,9,1,10,2 5,4,3 4 3 I I (I I I 9 ,o) I Figure 4. 'S' Shaped Structure 
Intersected by Five Planes Complete contours for many simple structures can be found using a single initial 
seed and one ex- amination per plane. However, for objects of random or unknown shape well-placed seeds 
cannot always be provided. Regardless, 3,D region grow- in9 should find all angle-connected volume members 
given any single pixel as seed, This is possible by re-entering image planes that may have more re- g!on 
members than previously determined. For the ~S' structure, case 4 Table l, this would mean "turning the 
corner" at plane k-2, re-entering plane k-l, k~ and k+l to locate contours 8, 9, and IO. When a graph 
is used to represent states of a pro- cess and the nodes of the graph are labeled by state descriptors, 
the nodes and arcs form a di- rected graph indicating a sequence of state chan- ges. Intuition suggests 
that such a directed graph can be used to represent image plane access by the isolation algorithm. The 
problem of con~ trolling entry to planes for complete object iso- Table I. Contours Found Using Five 
Different Seed Placements K-2 K-I K K,I K2  1-' I i / G l ,, \ / ~, / x Figure 5. Graph Illustrating 
Plane Re-entrance The plane re-entrance algorithm is simple: the algorithm searches in one direction 
from plane to plane finding object cross-sections in each. When-ever a new cross-section can be found 
in the im- mediately preceeding plane, the algorithm inter- rupts its current plane-to-plane advance, 
remem- bers where it is, and turns around to advance in the opposite direction. The algorithm 'remembers' 
where it is by placing the identity of the current plane in a TURNPOINT stack. The process continues 
in the new direction, always 'looking over its 137 shoulder's, as it proceeds. Advance in one direction 
ends when no pixels in the next plane are accepted as part of the target object's volume or, the limit 
of z-axis planes has been reached. This condition returns control to the last turnpoint to be resumed, 
until advance is again halted. The algorithm is a depth-first search since turnpoint nodes (planes) are 
stored in a FILO stack: the most recently interrupted plane-to-plane advance is resumed next. The al- 
gorithm terminates when plane-to-plane advance is halted and there are no nodes in the TURNPOINT stack 
that can be used to resume processing. Note that image planes are entered if and only if a new set of 
area pixels will be found and?all-- possible areas will be found when each plane is entered. Thus image 
planes are entered the least number of times to find all contour cross-sections for a structure. In the 
description that follows two parameters are used to identify nodes visited in a plane-access graph like 
that shown in Fig., 5. Values for S and n are z-axis coordinates that identify x-y planes. When combined 
with n, the value for De{+l,-l} identifies the direction of plane-to-plane advance. These parameters 
allow the nota-tion VISlT(n,n+D) to indicate advance of the pla- nar algorithm into plane n from n+D. 
For example, VISIT(9,8) means region grow plane n=9 using the plane connection strategy to supply seeds 
from plane n+D=9+(-l)=8. The plane re-entrance algorithm is defined by the following Algol-like pseudo-code 
and the flowchart in Fig., 6. /* USERS INTERACTS TO REGICN GR~W ON */ /* PLANE n= Start */ PUSH (TURNPOINT,S) 
; D=-I /* EITHER DIRECTION */ n=n-D /* IF KLON<S<KHIGH */ do vhile |n~=STACKEHPTY) ; D=INVERT(D) ; 
 do while(VISIT(n,n+D) A -,LIMIT) CALL CLOSED (n) ; if EXPAND(n)=BACKSUCCESSOR then do; /* RE-ENTER 
*/ PUSH(TURN~OINT,n) ; n=n+D; D=I NVERT (D) ; od; else if EXPAND(n)=FRONTSUCCESSOR then n=n-D /* 
CONTINUE */ else LIMIT=-TRUE-/* deadend ~/ fi; od; n=POP (TURNPOINT) ; oa; 1~ithput further clarification 
of VISIT(n,N+D), EXPAND(n), and CLOSED cycles appear likely in the algorithm. For example, an area found 
in one plane could be rediscovered repeatedly. Taking CLOSED, VlSlT(n,n+D), and EXPAND(n) in turn we 
show how they cooperate to prevent such senseless process- ing. CLOSED is accessed whenever a new area 
has been START Pb'r S IN ~INT [ ST*=, ~ I  B~l--r;~ ) 'IllIll~OIl~ CALL THIS NODE n D = -I*D V" [ 
VISIT (n, n+D} I NO ~/~-~?i~ Figure 6. Re-entrance I Aim n TO~ I Flowchart HJTn IN NO YES TtPA~OINT 
 I.-.D I  No # I discovered by region growing. Using a table, CLOSED determines whether pixels just 
discovered by region growing should be stored in a new file space or added to previous results for the 
plane. A tab- le entry for each z-axis plane is reserved to in-dicate absence or presence of any earlier 
results and locates edge and area images on auxiliary stor-age. Edge and area images are updated by CLOSED 
when new areas are discovered on planes previously examined. Set nntation, {A(n)) and {C(n)}, is used 
here to represent the set of area and edge (contour) pix- els previously determTned in plane n. Similarly 
{A*(n)} and {C*(n)} is used to represent current results of region growing in plane n. Now the CLOSED 
table can be represented as a list of sets ({A(KLOW)} ..... {A(n)} ..... {A(KHIGH)}) where {A(n)} = NULL 
indicates that no prior results for plane n exist. This formalism allows {A(n)} = {A(n)} U {A*(n)} and 
{C(n)} = {C(n)} U {C*(n)} to represent the task performed by CLOSED(n). We use U here to in-dicate the 
union of sets and later /% to indicate the intersection of sets. VISIT(n,n+D) eturns "True" if new area 
found in plane n,'False' otherwise. Information maintained by CLOSED allows VISIT(n,n+D) to avoid rediscovery 
of pixels already found as part of an objects vol-ume. In addition to the planar region growing al- gorithm, 
VISIT(n,n+D) also represents the plane- to-plane connection algorithm (section 11.2) and a query mechanism 
to prohibit redundant processing.  (Multiple seeds can be user-supplied, but only one is given here 
for our test.) Fig., 9b shows the status of one plane during al- gorithm execution. One disconnected 
area is 'blacked-out', since pixels there have been found earlier, and a new area is about to be discovered 
(using seeds from a neighboring plane shown on the right side of figure). Two files are produced by 
the isolation algorithm. One file is sequence of image planes where only areas are stored: cross-sections 
of the object isolated by the algorithm. Another file stores only the corresponding boundaries for the 
object (see algorithm output in Fig., I). Figs., 9c &#38; 9d show a composite view of contours from all 
planes. Matching lines with the Fig., 8 photograph shows the entire phantom structure iso-lated. The 
algorithm determined the phantom con- tours in 51 min. 40 sec. on a PDP 11/34 using one seed. Using 5 
initial seeds execution time was reduced to 36 minutes. The composite photograph in Fig., I0 shows six 
anatomic structures isolated by re-entrant region growing. Execution times for each structure de-pends 
on structure size, frequency of plane re-entrance (shape complexity), number of seeds first provided, 
and whether filtering operations were chosen to preprocess image data. Contours for the spinal canal 
in lOa were found in 12 minutes (40 z-normal planes with an image window of appro-ximately 64x64). The 
cerebral ventrical contours in lOd took the longest to find due to low pass filtering at each plane inspection 
(43 minutes for 20 z-normal planes with an image window of 160x220). In cooperation with Cohen, Livingston 
(I0) and Shantz (II) we have built surfaces over contours reported by our methods. Fig., lla shows the 
spinal canal contours of Fig., lOa fitted with polygonal tiles using Fuchs algorithm (18). We then shaded 
the polygons for a solid representa- tion of the structure as shown in the two views of Fig., llb. IV. 
Conclusion We have presented an algorithm for controll- ing search in three-dimensional image data and 
have given execution times and results for phantom and patient data. Our technique im- proves on methods 
where search for object contours is unrestrained across planes form- ing the search space. Few computers 
have sufficient core memory to store complete three-dimensional image data for typical CT, ultrasound 
or microscopic applications. A virtual memory organization is a practical and common solution for such 
large core memory re- quirements. In this work, as in (9), a virtual memory is implemented to access 
the cube of image data searched for structure edges. Such techni- ques emulate a core memory of 'virtually' 
infi-nite size similar to that used in operating sys-tems (see Denning (19)). Virtual memories imple- 
ment a "sleight of hand" memory replacement opera- tion using only the actual core memory available. 
When requested data is not core memory resident, a 'page fault' condition is raised. This condi- tion 
causes replacement of data in core with that requested. The switch occurs transparent to the requesting 
program so a virtually large core mem-ory is apparent. Frequent page faults, however, slow algorithm 
execution since each fault initia-tes an I/0 data transfer. In (9) no provisions are made for limiting 
page faults: "the boundary surface grows at about the same speed on all sides" (pp. 131 (9)). A key 
contribution of this work lies in its abi-lity to reduce I/0 costs by finding all structure contours 
possible per plane automatically and en-tering planes less frequently than methods that do not restrict 
processing to planes-at-a-time. Additionally, the plane connection strategy used here can be used to 
automatically tally contour connections for surface building programs (11,18) that operate on multiple 
discrete objects. Our work is now directed to this task. Acknowledgments The author would like to thank 
the Memorial Hos- pital Medical Center Research Foundation of Long Beach, California, and Pfizer Medical 
Systems for their support. Thanks also go to Russell A. Brown for his programming and tutorials for the 
Evans and Sutherland Picture System 2. The aut- thor is grateful to Dr. William V. Glenn for his criticism, 
direction, and infectious enthusiasm. Early comments and suggestions from Allen Klinger (UCLA) are sincerely 
appreciated. Thanks also go to Phil Cohen and Robert Livingston (UCSD) and Michael Shantz (CalTech). 
References I. Chow, C. K., and Kaneka, T., "Boundary De- tection of Radiographic Images by a Thresh. 
Method," IBM Report RG3203, December 1970. 2. Ausherman, D. A., Dwyer, S. J., and Lodwick, G. S., "Extraction 
of Connected Edges from Radiographs," IEEE Trans. Computers, C-21, 1972, pp. 753-758. 3. Ballard, D., 
and Sklansky, J., "Tumor De- tection in Radiographs," Comput. Biomed. Res. 6, 1973, pp. 299-321. 4. 
Carton, E., Weszka, J., Mohr, J., Rosenfeld, A., "Some Basic Edge Detection Techniques," Univ. Maryland 
Tech. Rep. TR-277, Dec. 1973. 5. Bullock, B., "The Performance of Edge Opera- tors in Images with Texture," 
Hughes Air. Co. Tech. Rep., Malibu, CA., Oct. 1974. 6. Frei, W., Chen, C. C~, "Fast Boundary De- tection: 
A Generalization and a New Al- gorithm," IEEE Trans. Comp., Vol. C-26, No. lO pp. 988-998. 7. Chien, 
Y. P., and Fu, K. S., "A Decision Function Method for Boundary Detection," Comp. Graphics and Image Proc., 
3, 1974, pp. 125-140.   8. Mazziotta, J. C., Huang, H. K., "THREAD (Three dimensional Reconstruction 
and Display) with Biomed. Applic. in Neuron Ultrastructure and Comp. Tomography~" Proc. Nat'l Comp. Conf. 
AFIPS 1976, Vol. 45, AFIPS Press, Montvale, N.J., pp. 241-250.  9. Liu, H. K., "Two-and-Three-Dimensional 
Boundary Detection," Comp. Graph. and Image Proc., 6, 1977, pp. 123-134.  lO. Cohen, P., Livingston, 
R., Sumners, R., Application Programs for Computer Graphics, "Dynamic Viewing of CT Image Data," 16-mm 
film, Roch Laboratories Inc., and the Neuroscience Department, Univ. Cal. San Diego, La Jolla, CA., 1978. 
II. Shantz, M. J., McCann, G. D., "Computational Morphology: Three-D Comp. Graph. for Elec. Microscopy," 
IEEE Trans. Biom. Enq., Vol. BME-25, No. l, Jan. 1978, pp. 99-I02. 12. Yakimovsky, Y., Cunningham, R., 
"On the Prob- lem of Embedding Picture Elements in Regions," Jet Prop. Lab. Tech. Report No. 33-774, 
Pasa-dena, CA., June 1976. 13. Rhodes, M. L., Glenn, W. V., Klinger, A., "Interactive Volume and Surface 
Iso. Using Tomogr. Data," Proc. San Diego Biom. Symp., Feb. I-3, 1978, pp. 403-411. 14. Rosenfeld, A., 
"Connectivity in Digital Pic-tures," J. ACM, Vol. 17, No. l, 1970, pp. 146-160. 15. Jackson, P. C., 
Intro. to Artificial Intel., Mason/Charter Pub. Inc., New York, 1974. 16. Nilsson, N. J., Prob. Solv. 
Methods in Art. Intel., McGraw-Hill, New York, 1971. 17. Winston, P. H., Artificial Intelligence , Addison-Wesley, 
Menlo Park, CA., 1977. 18. Fuchs, H., Kedem, Z. M., Uselton, S. P., "Optimal Surface Reconstruction 
from Planar Contours," Comm. ACM, Vol. 20, No. lO, Oct., 1977, pp. 693-702.  19. Denning, P. J., "Virtual 
Memory," Computin 9 Surveys, Vol. 2, No. 3, Sept. 1970, pp. 153-189.  Fig, 9a. Only One Seed provided 
to Test Algorithm Fig. 9b. Plane Shown Nith Intermediate Results III III illll Ill l IIIllI Fig. 9c. 
Contours Found by Re-entrance Test. Fig. 9d. Oblique View Of Phantom Contours.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807436</article_id>
		<sort_key>143</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[A terrain and cloud computer image generation model]]></title>
		<page_from>143</page_from>
		<page_to>150</page_to>
		<doi_number>10.1145/800249.807436</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807436</url>
		<abstract>
			<par><![CDATA[<p>A method is presented that produces a realistic simulation of terrain using source data from the Defense Mapping Agency (DMA). Spatially compact objects are presently modeled with some success at realism. Because terrain is large in extent it exhibits special problems. These problems include: data base size and generation, masking priority, and shading.</p> <p>An array of height values can be created from the DMA terrain file. Height is a single valued function of the array coordinate pair. The pair has implicit positional information. A masking priority algorithm is used which has no restriction on observer geometry. The algorithm searches the height array along the line of sight for the first visible position in the array. This approach requires no clipping or depth sorting of surface representations. The height array indices are used to access the pixel shade from a registered, orthonormal texture array. The use of texture provides a simple way to add nonlinear shading for a realistic representation with flexible data base generation.</p> <p>Atmospheric attenuation is a method used to increase realism. Methods are in use which produce haze or fog with constant attenuation. The line-of-sight search is used to produce realistic clouds with spatially variable attenuation.</p> <p>Terrain and clouds are adequately simulated using this method of modeling. The data structures of height and texture arrays are simple, easily generated, and make good use of storage resources. Resolving masking priority along the line of sight is a visible surface algorithm which has advantages over hidden surface algorithms. Realistic representations such as texture and atmospheric attenuation are used with some success.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Atmospheric attenuation]]></kw>
			<kw><![CDATA[Clouds]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Data base]]></kw>
			<kw><![CDATA[Fog]]></kw>
			<kw><![CDATA[Masking priority]]></kw>
			<kw><![CDATA[Shadows]]></kw>
			<kw><![CDATA[Terrain model]]></kw>
			<kw><![CDATA[Texture]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334393</person_id>
				<author_profile_id><![CDATA[81100442844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dungan]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[Technology Service Corporation, Santa Monica, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Badler, N.I., and O'Rourke, J. A representation and display system for the human body and other three-dimensional curved objects. University of Pennsylvania, Department of Computer and Information Science, Technical Report (February 1977).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Badler, N.I., and O'Rourke, J. Decomposition of three-dimensional objects into spheres. IEEE Pattern Recognition and Artificial Intelligence Workshop, Princeton, N.J. (1978).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807384</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Badler, N., and Bajcsy, R. Three-dimensional representations for computer graphics and computer vision. Siggraph '78 Proceedings, (August 1978), 153-160.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, J.F. Simulation of wrinkled surfaces. Siggraph '78 Proceedings, (August 1978), 286-292.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn, J.F., and Newell, M.E. Texture reflection in Computer Generated Images. CACM 19, 10 (October 1976) 542-547.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bunker, W., and Ingalls, M. Circles, texture, etc., alternate approaches to CIG scene detail. A Collection of Technical Papers, AIAA Flight Simulation Technologies Conference (September 1978), 49-58.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bunker, W., and Heartz, R. Perspective display simulation of terrain. Air Force Human Resources Laboratory, AFHRL-TR-76-39 (June 1976).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. Computer display of curved surfaces. Proc. Conf. on Computer Graphics, Pattern Recognition, and Data Structure, (May 1975), 11-17.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Defense Mapping Agency, Product specifications for digital landmass system (DLMS) data base. PS/ICD (EFG)/100, (July 1977).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807383</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dungan, W., Stenger, A., Sutty, G. Texture tile considerations for raster graphics. Siggraph '78 Proceedings, 12, 3 (August 1978), 130-134.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Faintich, M.B. Digital scene and image generation. Naval Weapons Laboratory Technical Report, TR-3147, (1974).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. On Coons and other methods for representation of curved surfaces. Computer Graphics and Image Processing, 1, 4 (1972), 341-359.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. Continuous shading of curved surfaces. IEEE Transactions on Computers, 20,6 (June 1971), 623-629.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Horn, B. Hill-shading and the reflectance map. Proceedings: Image Understanding Workshop. (April 1979), 79-120.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jancaitis, J.R. Modeling and contouring irregular surfaces subject to constraints. Army Engineer Topographic Laboratories. ETL-CR-74-19 (January 1975).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Phong, B.T. Illumination for computer generated pictures. Graphics and Image Processing CACM 18, 6 (June 1975), 311-317.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Watkins, G.S. A real-time visible surface algorithm. Department of Computer Science, University of Utah, UTEC-CSC-70-101 (June 1970).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Williams, L. Casting curved shadows on curved surfaces. SIGGRAPH '78 Proceedings (August 1978), 270-274.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A TERRAIN AND CLOUD COMPUTER I~GE GENERATION MODEL William Dungan, Jr. Technology Service Corporation 
Santa Monica, California ABSTRACT INTRODUCTION A method is presented that produces a realistic simulation 
of terrain using source data from the Defense Mapping Agency (DMA). Spatially compact objects are presently 
modeled with some success at realism. Because terrain is large in extent it exhibits special problems. 
These problems include: data base size and generation, masking priority, and shading. An array of height 
values can be created from the DMA terrain file. Height is a single valued func- tion of the array coordinate 
pair. The pair has implicit positional information. A masking prior- ity algorithm is used which has 
no restriction on observer geometry. The algorithm searches the height array along the line of sight 
for the first visible position in the array. This approach re-quires no clipping or depth sorting of 
surface representations. The height array indices are used to access the pixel shade from a registered, 
orthonormal texture array. The use of texture provides a simple way to add nonlinear shading for a realistic 
representation with flexible data base generation. Atmospheric attenuation is a method used to in-crease 
realism. Methods are in use which produce haze or fog with constant attenuation. The line-. of-sight 
search is used to produce realistic clouds with spatially variable attenuation. Terrain and clouds are 
adequately simulated using this method of modeling. The data structures of height and texture arrays 
are simple, easily gen- erated, and make good use of storage resources. Resolving masking priority along 
the line of sight is a visible surface algorithm which has advantages over hidden surface algorithms. 
Realistic repre-sentations such as texture and atmospheric atten-uation are used with some success. KEY 
WORDS AND PHRASES: computer graphics, terrain model, atmospheric attenuation, clouds, fog, texture, masking 
priority, shadows, data base. CR CATEGORIES: 3.14, 3.16, 3.41, 4.33, 4.34, 5.12, 8.1, 8.2 There is no 
best method for modeling all objects; indeed, one best model may not be practical or desirable (3). Whereas 
planar polygons are good representations of an object with flat sides and straight edges, such as a building, 
curved surface patches are good representations of an object with curved sides and round edges, such 
as a teapot (9). Spheres are good representations of an object with curved surfaces and movable joints, 
such as a human form (I). Each method has its own valid applica-tions and limitations (7). The problem 
is in find- ing the correct primitive model for the correct application. Considerations for a terrain 
model are based on some form of surface representation. The term surface representation refers to the 
form of the model, such as a curved patch (13), planar polygon (8), polynominal (16), point (12), or 
other (2). Terrain is modeled with a contiguous set of surface representations, each of which must define 
a posi- tion, area, and shade. With realism as a condition, the shade must be dependent on the interaction 
of the illumination source with the orientation and material type of the surface representation. The 
material type defines a coefficient of reflectivity for a given wavelength. The image is conventionally 
displayed in observer space with coordinates (X,Y,Z). In the image plane, the Y-axis increases down the 
rasters, the X-axis increases along the rasters to the right, and the Z-axis increases into the image 
and signifies depth. The coordinates of the data base are (U,V,H). In-terpreting the data base as a map, 
the V-axis points north and the U-axis points east. The H-axis points up and signifies height. Any normal 
vector is represented by N. DATA BASE A terrain model can easily be produced with source data obtained 
from the Defense Mapping Agency (DMA) (i0). An array of height values can be created from the D~ terrain 
file, Fig. I. This array is a set of surface points in which the array indices are (U,V) and the height 
is H. There are methods which fit surface representation primitives to surface points (2,8). The number 
of surface &#38;#169; 1979 ACM O-89791-004--4/79/0800--143 $00.75 See Copyright Pg. 143 representations 
required to adequately model terrain is of major concern because storage, access, and processing are 
all impacted by a data base that is too large. Thus, the nature of terrain causes special problems which 
are not encountered when modeling a spatially compact object. A spatially compact object can be modeled 
at just one level of detail. However, after a perspective transformation, terrain exhibits a problem 
in level of detail. For example, assume a data base of ~ur-face representations modeled at a uniform 
resolution. Many surface representations at the horizon fall into one pixel at the image plane..Depending 
on the resolution of the data base, an observer height can always be found at which several pixels fall 
within the bounds of a single surface representation in the foreground. Both of these extreme conditions 
can occur within the same image. A data base that allows for a hierarchical structure to model level 
of detail has an advantage in the case of terrain. The ideal surface representation at the horizon is 
a point which represents an area similar to any neighboring point. A more complex representation would 
waste vital processing re-sources to distill its infomation down to a point representation. Adoption 
of a point surface representation requires an interpolation scheme or transition to another form of primitive 
when the pixels on the image plane exceed the resolution of the point surface representation. The point 
is only the first logical structure of a hierarchical terrain data base. For the sake of realism, finer 
level-of-detail representations in the hierarchical structure should take on the pattern of: forest, 
tree, leaves, so that each level of detail adds structure to the previous framework (7). The transition 
between levels of detail should not be noticeable (ii). The height array created from the DMA terrain 
file is a set of point surface representations at a uniform resolution. The indices have implicit positional 
information and thus save space in the data base. MASKING PRIORITY Another way to determine the correct 
surface representations is to look at how the image is created from the data base. Most computer image 
generation (ClG) techniques require that the surface representations first be clipped to the viewing 
volume. Since surface repre- sentations that fall entirely outside the viewing volume are detected and 
then discarded, every surface representation at the coarest level of detail must be checked. Projection 
of surface representations onto the image plane gives rise to conflicts of masking priority. Use of a 
Z-buffer allows the surface representations to be taken in any order and added to the image. Conflicts 
of masking priority are resolved by comparing the Z-values (depths) of conflicting surface representations 
(9). This method wastes effort since one pixel may be over- written several times. Use of a scan line 
algorithm does not require a Z-buffer. Conflicts of masking priority are resolved by use of a Z-list 
of segments. Each surface representation is decomposed into a series of edges ordered from top to bottom 
and then left to right on the image plane (4,18). Entry edges add an active segment to the Z-list and 
exit edges remove the active segment. An active segment's position within the Z-list is based upon its 
Z-value. A large number of surface representations must be sorted in this manner and the maximum num- 
ber of edges has proven to be a limitation in existing ClG systems (7). Because these two methods, Z-buffer 
and Z-list, treat masking priority as a hidden surface problem, every surface representation must be 
checked and hidden parts are removed from consideration. Limited geometry considerations, which require 
the transformed data base to have only a single value of Y at each (X,Z), build the image from the fore- 
ground. Although this approach is restricted by the condition that there be no roll or pitch, it has 
the advantage that a scan line from the bottom of the image plane to the top perpendicular to the rasters 
is a monotonic function of Z. Surface representations ordered in Z can be written onto the image plane 
only if the pixel has not been filled by a previous surface representation. The limitation of observer 
roll can be bypassed by rolling the rasters on the image plane; however, pitch conditions still present 
a problem (8). A visible surface approach appears practicable given an ordered data structure, such as 
the height array, in which the observer position within the data base can easily be determined and a 
Z-ordered list of surface representations easily accessed. Since clipping is not required, all surface 
representations need not be accessed. This approach can be advantageous with large data bases, depending 
on how many times the same surface is accessed. The visible surface representation is found by searching 
along the line of sight through each pixel and comparing the height of the data base with the ray. The 
first surface representa- tion that appears at or above the ray is the visible surface. To implement 
this approach the line-of-sight ray and the data base must have a common coordinate system. The ray through 
a pixel can be defined as X = ~Z , Y = BZ where ~ is the tangent of the horizontal angle along the rasters 
and B is the tangent of the vertical angle down the rasters. As Z increases, the position along the line 
of sight penetrates further into the viewing volume. The height array is a data base with the height 
value, H, defined at every array element (U,V). There is one maximum height value, Hmax, and one minimum 
height value, Hmin. A plane is placed at these bounding values (U,V,Hmax) and (U,V,Hmin) to bound every 
value within the height array. If a line-of-sight ray passes through both the top and bottom bounding 
planes, it passes through the height array and a visible surface representation 144 exists, Figure 
2. If the observer position is not between the top and bottom bounding planes and the line-of-sight ray 
does not pass through either bounding plane within the viewing volume, the sky is visible at that pixel. 
Assume that an observer position is above the top bounding plane and that the line-of-sight ray passes 
through the top plane at (Xt,Yt,Z t) and the bottom plane at (Xb,Yb,Zb). The origin of the top plane 
is at (U,V,H) = (~,~,Hmax). The origin transformed to the observer coordinate system by the matrix operator 
T is (~,B,I) T = (Nx,Ny~Nz). Fig. 3 shows a vector drawn from the orlgln to the point of intersection 
(Xt,Yt,Zt). The_components are S x = X t -0 x- Sy = Yt -Oy S z = Z t -0 z This vector is perpendicular 
to the normal vector (Nx,Ny,Nz): N x S x + Ny Sy + N z S z = 0 Substituting the equations for the 
ray yields the Z-coordinate of the intersection: Nx 0 x + Ny Oy + N z 0 z Zt = m N x + B Ny + N z 
 and X t = mZ t Yt : BZt The coordinates for the intersection with the bottom plane (Xb,Xb,Z b) can 
be determined in the same way. The height array indices are (U,V,H) = (Ru,~,~) and (~,Rv,~) where R u 
and R v are the resolutions of the array indices in height units. The transformed components are (Ru,~,~) 
 T = (Ux,Uv,Yz) and (B,Rv,~) T = (Vx,Vv,Vz). The array-indices are determined by fin~ing the vector 
component parts along these two axes: U = S x U x + Sy Uy + S z U z V = S x V x + Sy Vy + S z V z 
 (Ut,Vt) and (Ub,Vb)--the two endpoints of a line segment which is the part of the line-of-sight ray 
bounded by the top and the bottom planes-- can be determined in this manner. The height, H, decreases 
linearly from Hma x to Hmi n as the line-of-sight ray is searched from (Ut,V t) to (Ub,Vb). As a result, 
the first visible array position is found when the search yields a height array value greater than or 
equal to the height of the ray at a particular (U,V). Note also that Z increases linearly from Z t to 
Zb; thus, an image stored in a Z-buffer or produced in parallel with a pixel Z-value can be merged with 
this terrain model approach. TEXTURE Once the visible point is determined, the shade must be calculated. 
By using texture, non-linear shading can be easily added for a realistic effect (5,6,11). The height 
array can be used to create a normal at each array position. A simple approx- imation is Nu = H(U-I,V) 
-H(U+I,V) N = H(U,V-I) -H(U,V+I) v N H = 2 R u + 2 R v The components (Nu,Nv,NH) must be normalized 
to produce a unit vector. The result is an array of surface normal vectors registered to the height array, 
which can be used to create a reflectance map (5), Fig. 4. The image produced is an ortho- normal projection 
with a uniform coefficient of reflectivity over the entire data base. Assigning a material type to each 
surface representation produces a more realistic effect. The DMA cultural file was not obtained for the 
area of the figures; however, a photograph was available. The area is rural with tree cover, soil, crops 
and streams. Feature extraction was accomplished with two different operations: The large flat fields 
were isolated by picking only those points in the height array with nearest neighbors within a 5 ft altitude 
difference, Fig. 5; the streams were isolated by picking points with restricted surface normals Fig. 
6. The features isolated with the second technique include the flat features of the first technique but 
add local maximum and minimum height features such as ridges and ravines. Selectively assigning material 
codes to the different features produces the mask in Fig. 7. Scaling the surface normals with reflectivity 
coefficients derived from the material mask produces the reflectance map of Fig. 8. The reflectance map 
of Fig. 8 is mapped onto a flat plane in Fig. 9 (11). The errors of two- dimensional texture techniques 
are obvious: the far side of the ridges is still visible even though it should be masked. Using the reflectance 
map of Fig. 8 to determine the shade for the three-dimensional, line-of=sight terrain model produces 
the image of Fig. I0. REALISM Texture increases the realism of ClG techniques. Two other techniques are 
considered: shadows (19) and atmospheric attentuation. Shadows are produced from the height array and 
the sun vector. The shadows are processed in order of height array rows or columns starting with the 
edge closest to the sun position. A shadow height is calculated at each array position in order. A height 
is in-terpolated back toward the sun where the sun vector lines up with an array position. Shadow heights 
are kept at array positions in shadow. Fig. 11 shows the final result of adding shadows to the reflectance 
map texture. 145 Surface reflectance has been modeled with variable intensity algorithms (14,17), some 
of which show a dependence on illumination source range. The effect of the inverse square law on sunlight 
illumination is small at the earth's surface. Atmospheric attenuation has a far more noticeable effect. 
Constant attenuation can be used to model fog. The intensity of a surface as seen through the attenuation 
obeys the Lambert-Beer law: dl(r) = -ll(r) dr with the result, I(R) = I@e -~R where ~ is the attenuation 
factor and R is the range to the surface from the observer. With a variable attenuation condition, such 
as clouds, the attenuation factor is a function of range, ~(r). The result of the Lambert-Beer law is 
then, R ( ~(r)dr l(R) = I e-7@ To model the variable attenuation factors, a tech- nique similar to the 
terrain model is used. An array of attenuation factors is constructed, F(U,V). The cloud layer is modeled 
as a region bounded by a top and bottom plane. The top plane is at H+ and the bottom plane is at H_; 
a middle plane is at Hm. The attenuation factor at any position within the bounded region is calculated 
as _R 2 ~(U,V,H) = ?(IU,IV) e where F(IU,IV) is the nearest array position and  R 2 = (H-N,) 2 + R 
(U-IU) 2 + R (V-lV) 2 With this method, attenuation decreases radially from (IU,IV,H@) and can be determined 
for any local point within the bounded volume. The attenuation of light passing through the clouds to 
ground level is calculated with a finite set of sample points along a sun vector. The atten- uation of 
light passing through the clouds from ground level to the observer is calculated similarly. The actual 
intensity of clouds is determined by the scattered light. A line traced from the observer to each sample 
point along the line of sight joins a line along the sun vector. The attenuation calculated along this 
line contri-butes a cloud shade that depends solely on the cloud density. The result is shown in Fig. 
12. CONCLUSION The DMA source is used to simulate terrain. An adequate set of data structures includes 
only two-dimensional arrays that are easy to generate and are relatively small for the amount of realism 
portrayed. The use of texture is a way to portray nonlinear shading with few on-line calculations. Material 
reflectivity and shadows are added to the texture to enhance realism. Masking priority is determined 
along the line of sight, which is also used to generate a cloud layer above the terrain. REFERENCES 
I. Badler, N.l., and O'Rourke, J. A representation and display system for the human body and other three-dimensional 
curved objects. University of Pennsylvania, Department of Computer and Information Science, Technical 
Report (February 1977). 2. Badler, N.l., and O'Rourke, J. Decomposition of three-dimensional objects 
into spheres. IEEE Pattern Recognition and Artificial Intelligence Workshop, Princeton, N.J. (1978). 
 3. Badler, N., and Bajcsy, R. Three-dimensional representations for computer graphics and computer 
vision. Siggraph '78 Proceedings, (August 1978), 153-160. 4. Blinn, J.F. Simulation of wrinkled surfaces. 
Siggraph '78 Proceedings, (August 1978), 286-292.  6. Blinn, J.F., and Newell, M.E. Texture reflec- 
tion in Computer Generated Images. CACM 19,10 (October 1976) 542-547.  7. Bunker, W., and Ingalls, M. 
Circles, texture, etc., alternate approaches to CIG scene detail. A Collection of Technical Papers, AIAA 
Flight Simualtion Technologies Conference (September 1978), 49-58.  8. Bunker, li., and Heartz, R. Perspective 
display simulation of terrain. Air Force Human Resources Laboratory, AFHRL-TR-76-39 (June 1976). 9. 
Catmull, E. Computer display of curved surfaces. Proc. Conf. on Computer Graphics, Pattern Recog-nition, 
and Data Structure, (May 1975), II-17.  i0. Defense Mapping Agency, Product specifications for digital 
landmass system (DLMS) data base. PS/ICD (EFG)/I~, (July 1977). II. Dungan, W., Stenger, A., Sutty, G. 
Texture tile considerations for raster graphics. Siggraph '78 Proceedings, 12,3 (August 1978), 130-134. 
12. Faintich, M.B. Digital scene and image generation. Naval Weapons Laboratory Technical Report, TR-3147, 
(1974). 13. Forrest, A.R. On Coons and other methods for representation of curved surfaces. Computer 
Computer Graphics and Image Processing, 1,4 (1972), 341-359. 14. Gouraud, H. Continuous shading of curved 
surfaces. IEEE Transactions on Computers, 20,6 (June 1971), 623-629.  146 15. Horn, B. Hill-shading 
and the reflectance map. Proceedings: Image Understanding Workshop. (April 1979), 79-120. 16. Jancaitis, 
J.R. Modeling and contouring irregular surfaces subject to constraints. Army Engineer Topographic Laboratories. 
ETL-CR-74-19 (January 1975). 17. Phong, B.T. lllumination for computer gener- ated pictures. Graphics 
and Image Processing CACM 18,6 (June 1975), 311-317. 18. Watkins, GoS. A real-time visible surface algorithm. 
Department of Computer Science, University of Utah, UTEC-CSC-70-101 (June 1970). 19. Williams, L. Casting 
curved shadows on curved surfaces. SIGGRAPH '78 Proceedings (August 1978), 270-274.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807437</article_id>
		<sort_key>151</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[The haloed line effect for hidden line elimination.]]></title>
		<page_from>151</page_from>
		<page_to>157</page_to>
		<doi_number>10.1145/800249.807437</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807437</url>
		<abstract>
			<par><![CDATA[<p>The haloed line effect is a technique where when a line in three-dimensional space passes in front of another line, a gap is produced in the projection of the more distant line. The gap is produced as if an opaque halo surrounded the closer line. This method for approximate hidden-line-elimination is advantageous because explicit surface equations are not necessary. The relative depth of lines, axes, curves and lettering is easily perceived. This technique is especially suitable for the display of finite element grids, three-dimensional contour maps and ruled surfaces. When the lines or curves on a surface are closer than the gap size, the gaps produced close up to produce a complete hidden-line-elimination. A simple but efficient implementation is described which can be used in the rendering of a variety of three-dimensional situations.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Contour maps]]></kw>
			<kw><![CDATA[Finite element]]></kw>
			<kw><![CDATA[Haloed line effect]]></kw>
			<kw><![CDATA[Hidden line elimination]]></kw>
			<kw><![CDATA[Ruled surfaces]]></kw>
			<kw><![CDATA[Three-dimensional space]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31044938</person_id>
				<author_profile_id><![CDATA[81100498632]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arthur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Appel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computing Systems Department, IBM Thomas J. Watson Research Center, Yorktown Heights, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31094350</person_id>
				<author_profile_id><![CDATA[81100462950]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[James]]></middle_name>
				<last_name><![CDATA[Rohlf]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Ecology and Evolution, State University of New York at Stony Brook, Stony Brook, Long Island, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14084095</person_id>
				<author_profile_id><![CDATA[81100214089]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Arthur]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Stein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computing Systems Department, IBM Thomas J. Watson Research Center, Yorktown Heights, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Encarnacao, "Survey of and New Solutions for the Hidden-Line Problem", PROCEEDING OF SYMPOSIUM ON COMPUTER GRAPHICS, Delft, Netherlands, October 1970, pp. 26-28.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[I. E. Sutherland, R. F. Sproull and R. A. Schumacker, "A Characterization of Ten Hidden-Surface Algorithms", COMPUTING SURVEYS, Vol. 6, No. 1, March 1974, pp. 1-55.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Various techniques are discussed in Chapter 5 of Wolfgang K. Giloi, INTERACTIVE COMPUTER GRAPHICS, Prentice-Hall Inc, Englewood Cliffs, N. J., 1978.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Various techniques are discussed in Chapter 14 of William M. Newman and Robert F. Sproull, PRINCIPLES OF INTERACTIVE COMPUTER GRAPHICS, McGraw-Hill Book Company, New York, 1973.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. G. Griffiths, "Bibliography of Hidden-Line and Hidden Surface Algorithms", COMPUTER-AIDED DESIGN, Vol. 10, No. 3, May 1978, pp. 203-206.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Wylie, G. W. Romney, D. C. Evans, and A. Erdahl, "Halftone Perspective Drawings by Computer", PROC. AFIPS FJCC 1976, Vol. 31, 49.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Appel, "Hidden Line Elimination for Complex Surfaces", IBM TECHNICAL DISCLOSURE BULLETIN, Vol. 18, No. 11, April 1976, pp. 3873-3876.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bruce G. Baumgart, "A Polyhedron Representation for Computer Vision", PROCEEDINGS AFIPS NATIONAL COMPUTER CONFERENCE 1975, Vol. 44, pp. 589-596.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[L. I. Lieberman, M. A. Wesley, M. A. Lavin, "A GEOMETRIC MODELLING SYSTEM FOR AUTOMATED MECHANICAL ASSEMBLY," IBM Research Report RC 7089, April 25, 1978.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321330</ref_obj_id>
				<ref_obj_pid>321328</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ruth A. Weiss, "BE VISION: a package of IBM 7090 Fortran programs to draw orthographic views of combinations of plane and quadratic surfaces", JOURNAL OF THE ACM, Vol. 13, No. 2, April 1966, pp. 194-204.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Peter Woon and Herbert Freeman, "A Procedure for Generating Visible Line Projections of Solids Bounded by Quadric Surfaces", PROCEEDINGS IFIP CONGRESS INFORMATION PROCESSING, North Holland, 1971, pp. 1120-1125.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Thomas J. Wright, "A Two-Spaced Solution to the Hidden Line Problem for Plotting Functions of Two Variables", IEEE TRANS. ON COMPUTERS, Vol. c-22, No. 1, January 1973, pp. 28-33.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Appel, S. W. Handelman and A. J. Stein, "Hidden Line Elimination for Semi-Convex Slices", IBM TECHNICAL DISCLOSURE BULLETIN, Vol. 20, No. 7, December 1977, pp. 2917-2920.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807373</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Wm. Randolph Franklin and Harry R. Lewis, "3-D Graphic Display of Discrete Spatial Data by Prism Maps", Computer Graphics, Vol. 12, No. 3, August 1978, Quarterly Report of SIGGRAPH-ACM. pp. 70-75.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360892</ref_obj_id>
				<ref_obj_pid>360860</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Thomas Wright, "Visible Surface Plotting Program", COMMUNICATIONS OF THE ACM, Vol. 17, No. 3, March 1974, pp. 152-155.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Appel and A. J. Stein, "Cellular Automata for Hidden-Line Elimination", IBM TECHNICAL DISCLOSURE BULLETIN, Vol. 17, No. 2, July 1974, pp. 586-589.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[I.E. Sutherland and R. F. Sproull, "A Clipping Divider," Proc. AFIPS FJCC 1968 Conference, Vol. 33, Part I, pp. 765-776.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807398</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn and Martin E. Newell, "Clipping using Homogeneous Coordinates", Computer Graphics, Quarterly Report of SIGGRAPH-ACM, Vol. 12, No. 3, August 1978, pp. 245-251.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806007</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Appel, "The Notion of Quantitative Invisibility and the Machine Rendering of Solids", Proc. ACM National Conference 1967, pp. 387-393.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE HALOED LINE EFFECT FOR HIDDEN LINE ELIMINATION. Arthur Appel Computing Systems Department IBM Thomas 
J. Watson Research Center Yorktown Heights, New York 10598 F. James Rohlf Department of Ecology and 
Evolution State University of New York at Stony Brook Stony Brook, Long Island, New York 11794 Arthur 
J. Stein Computing Systems Department IBM Thomas J. Watson Research Center Yorktown Heights, New York 
10598 ABSTRACT: The haloed line effect is a technique where when a line in three-dimensional space passes 
in front of another line, a gap is produced in the projection of the more distant line. The gap is produced 
as if an opaque halo surrounded the closer line. This method for approximate hidden-line- elimination 
is advantageous because explicit surface equations are not necessary. The relative depth of lines, axes, 
curves and lettering is easily perceived. This technique is especially suitable for the display of finite 
element grids, three-dimensional contour maps and ruled surfaces. When the lines or curves on a surface 
are closer than the gap size, the gaps produced close up to produce a complete hidden-line-elimination. 
A simple but efficient implementation is described which can be used in the rendering of a variety of 
three-dimensional situations. C. R. Categories: 3.69, 8.1, 8.2 Key words: Haloed line effect, three-dimensional 
space, hidden line elimination, finite element, contour maps, ruled surfaces. PRIOR ART: Determining 
which lines should not be drawn in a three dimensional picture is called hidden line elimination. This 
has been of continuing interest (1-5). The essential task of hidden line elimination is to determine 
whether a bounded surface lies between the viewpoint and the line or point being considered for drawing, 
and when this occurs th~ point or line segment is invisible and is not drawn. Most techniques for hidden 
line elimination assume some surface topology. The most common assumption is to consider the scene being 
rendered as being approximated by triangular or rectangular patches (6, 7) or bounded planes (8, 9). 
There has been some work with quadric surfaces (10, 11). The floating horizon technique (12) and variants 
(13, 14) are popular because the format of data storage is the same as that used for other calculations 
and is usually appropriate for most experimental or statistical presentations. Some effort has been made 
toward hidden line elimination where the data is stored in two or three-dimensional raster arrays (15, 
16). Figure 1 -These are three computer renderings of an approxi- mate human head. Each in a different 
style, respec- tively, wire frame, haloed line effect and the usual BASIC TECHNIQUE: surface dependent 
hidden line elimination. The bot- tom picture is the more realistic presentation but the The haloed line 
effect is illustrated in Figure 1 and is a common device in hand drawn technical illustration. For this 
effect, an imaginary region, a halo, is assumed to surround middle picture which appears more like a 
crystal gives some knowledge of all the lines on the object. This style may be preferable for depictions 
of structures or finite element networks. &#38;#169;1979 ACM O-89791-004--4/79/0800--151 $00.75 See 
Copyright Pg. 1.51 three-dimensional lines which can obscure any lines that pass behind the halo. When 
the lines used to describe a surface form a three di-mensional grid and the grid spacing is smaller than 
the size of the halo, then a complete hidden line" elimination results. This is illustrated in Figure 
2. The haloed line effect techni- que offers several advantages: a - It is easily programmed. b - Variation 
of the halo size enables control of transparency. c - There are virtually no rules of topology or surface 
description. Real or implied surfaces are not used and need not be specified. d - The input to the haloed 
line effect processor is almost the same as might be used to draw a wire frame pic-ture, hence this technique 
is easily adapted to programs or systems already making wire frame pictures. e - The haloing tends to 
accentuate surface contours and the dark and the light pattern of ruled surfaces. f - This method is 
tolerant of modelling and computational error in the original data. g - Memory requirements are minimized 
because the space usually required to store surface parameters and boundaries is not necessary. For satisfactory 
results, the haloed line effect can not be rigorously implemented. For example lines parallel or nearly 
parallel to a line with a halo ought not to be obscured by this halo otherwise the apparent contour of 
objects will be de-stroyed. The result of this compromise is that small line segments may, almost at 
random, be left on a rendering as illustrated in Figure 3. These may be eliminated by addition- al processing 
but this extra work may subvert the advantages of the haloed line effect. Another compromise with rigorous 
implementation is that an error tolerance must be used when one line passes behind another line. Accumulated 
calculation errors may cause two lines that intersect in three-dimensional space to halo erroneously. 
Also, if a rigorous determination of halo gapping based upon imaginary haloes is attempted, artificial 
haloes would have to be created which would be a major undertaking and would not be very useful. It is 
the approximate solution to this problem which is of value. DETAILS OF IMPLEMENTATION: There are many 
possible programming tactics suitable for the haloed line effect. The optimum code would have to take 
into account the display technology, the preferred application language, the available storage space 
and the preferred data storage media. The procedure we have devised is satisfactory as implemented in 
FORTRAN, operating on a VM/168 computer with pictures being drawn on varied storage scopes, printer plotters 
and a photo composer. The program was written to be used where the location of points on the display 
and their relative or absolute depth could be determined by any three-dimensional projection scheme. 
There are three entry points. The first initializes the line count to zero; the second stores the end 
points of a line; and the third signals that the last line has been stored and starts the haloing processing 
and generation of drawing Figure 2- Five nested algebraic surfaces rendered with the haloed line effect. 
While some haloing is inconsis- tent, the overall effect is vivid. This picture demon- strates that the 
haloed line effect probably cannot be perfectly programmed. Efforts to reduce penetration of haloes by 
short lines cause other errors or will require topological knowledge which obviate the value of this 
technique. Figure 3 - A picture of three nested algebraic surfaces. Lines parallel to closer lines can 
penetrate through the haloes of the closer lines. 152 commands. The best way to store lines is in picture 
plane display coordinates DX(K,L), DY(K,L), and some measure of depth DT(K,L). Where L is the line count 
and and DX(I,L), DY(1,L), and DT(I,L) are the coordinates of the end point with the greater DY value. 
K is 2 for the other end of the line. Some typical lines as stored are shown in Figure 4. The haloing 
procedure is as follows: 1. Assume some halo gap size G. Assume some depth tolerance TOL. 2. Extend 
each line at both ends a distance G on the pic- ture plane. This is illustrated in Figure 5, and will 
allow a halo gap at the ends of the lines. 3. Take each line one at a time. This is line I. 4. Set 
a counter NE to zero. NE is the number of halo edges the line I crosses. This must be an even number 
equal to twice the number of lines that pass in front of line I that have haloes that influence the visibility 
of line I. 5. Take each other line in the scene one at a time. This is line J. For intersection testing 
on the picture plane use the extended length of line J. This will help preserve the continuity of haloes 
around a surface. Some errors may be caused in open structural drawings such as in Figure 1, but these 
will not be serious. 6. If the DY(2,J) coordinate of line J are greater than DY(1,I) go back to step 
5. 7. If the DY (I, J) coordinate of line J is less than DY (2,I) go back to step 5. 8. If both DX 
coordinates of line J are smaller than the DX coordinates of line I go back to step 5. 9. If both DX 
coordinates of line J are greater than the DX coordinates of line I go back to step 5. 10. If both DT 
coordinates of line J are greater than the DT coordinates of line I go back to step 5.  1 l, Test to 
determine if the projection of line J crosses the projection of line I. If the line projections do not 
cross go back to step 5. 12. Calculate the exact location on each line, I and J, where they cross. Calculate 
the relative depth of lines I and J at this crossing point. If line J is not at least TOL dis-tance in 
front of I go back to step 5. The filtering oper- ations of steps 6 thru 12 which reduce the average 
effort required to determine whether two lines intersect are shown in Figure 6. 13. The halo of line 
J can influence the visibility of line I. Increment NE=NE+2. Store the distance from the starting point 
of line I to where it passes into the halo of line J as TE(NE-I). Store the distance from the starting 
point of line I to where it passes from behind the halo of line J as TE(NE). Set visibility state markers 
IGQ(NE- !)=-1 and IGQ(NE)=I. The halo around line J can be  I +DX TYPICAL DX z ,-- t/YP,eAL Y / ' 
/2/ +DY , /Te..-- J-~/6 /" 5~PICTURE PLANE /~/// ~:_/ ~:J \TYPICAL DT .~3 TYPICAL LINE STORAGE: LINE 
END I END 2 OXl, DYI, DTI DX2,DY2,DT2 DX3,DY3,DT3 DX2,DY2,DT2 DXI, DYI,DTI DX3,DY3,0T3 DX4, DY4,DT4 DXS,0YS,DT5 
DX6,DY6,DT6 DX5,DYS, DT5 DX6,DY6,DT6 OXT, DY7,DT7 DX7, DYT, DT7 DX4,DY4,DT4 Figure 4 - An oblique drawing 
of the projection of a simple scene upon the picture plane and the preferred listing of data. z ~ FOR 
LINE I NEW END POINT ~-~ PROJECTION OFFOR UNE I//~ ~_..~i~-/LINE 2 / /,~, ,~/~ "~PICTURE PLANE LINE 
I OF I TH,SSEG--T ~,.-~ I OF LINE , \ I WILL NOT BE DRAWN NEW SPACIAL e.~~/~ POSITION OF NEW END POINT 
FOR LINE I FOR I HALO EFFECT Figure 5 - An oblique drawing of the projection of two lines onto the picture 
plane. Line 1 which is being tested for gapping must be extended slightly as shown so as to detect that 
it penetrates the halo of line 2. approximated economically by two lines parallel to line J and two circular 
arcs. 14. If NE for line I is zero, just draw line I and go back to step 2. If NE is larger than 2 sort 
TE(NE) and the markers IGQ(NE) on the basis of TE. 15. Sum up the running measure of how many haloes 
ob-scure the line I along its length by adding up the values of IGQ along its length. Only those sections 
of line  153 where the sum of IGQ is zero are visible and should be drawn. Any segment of line I where 
the sum of IGQ is less than zero are hidden by one or more haloes and should not be drawn. This is illustrated 
in Figure 7. 16. Draw only the visible segments of line I that occur with- in its original length. 17. 
Go back to step 2 until all the lines in the picture have been processed.  The sequence of testing described 
above has been found to be optimal for pictures similar to Figure 2. For different types of pictures 
other techniques may be better. This proce- dure is simple and can be easily programmed with some simple 
plane geometry functions. Figure 8 demonstrates some particularly useful capabilities, Specifically the 
haloing of lettering and axis markings. Figure 9 thru 12 are additional demonstrations of the haloed 
line effect. All illustrations were produced with the same haloing program. Some experimental pictures 
have been made where the gap size was made to vary with the difference in depth of lines, but these were 
confusing. Apparently the halo gap size should be constant. //PICTURE PLANE  , \/6 I /1 UNE 6 l LINE 
8 ~~  FINAL / / DISPLAY : : AFTER HALO PROCESSING % Figure 6 - The various filtering tests to determine 
when a line can halo another line. Line 1 is under test for halo- ing. For ease of explanation we can 
ignore the small extensions of line 1. Line 2 is obviously above line 1. Line 3 is obviously below line 
1. Line 4 is obviously too far to the left. Line 5 is obviously too far to the right. Line 6 is behind 
line 1. Line 7 does not cross line 1. Only line 8 can cause a halo gap in line 1. EXECUTION TIME The 
execution time of a hidden line elimination program is determined by several factors. The primary influence 
is the geometrical strategy which takes into account the mathemati- cal character of the objects or scene 
to be rendered and the style in which the picture is to be made. A secondary influ- ence is the specific 
embodiment of the geometrical strategy in a computer program. Hidden line elimination programs can also 
be tuned to take advantage of some geometric properties of objects being rendered and the characteristics 
of the processing computer or ancillary hardware. Most probably the most important factor in the speed 
of a hidden line elimination program is the sophistication and dedication of the programmer. For example, 
the use of optimal sorting algorithms, the measure-ment and minimization of program statement execution 
counts, and the use of optimizing compilers can improve speed by an order of magnitude. When directly 
measuring a hidden line elimination program, the design and orientation of the test shape can bias the 
results. This has been observed to be especially true when measuring the execution time of haloed line 
effect pictures. When generating a typical alge- braic surface, similar to that shown in Figure 3, the 
execu-tion time could vary considerably with a change in viewpoint. The gap size of the halo has an unpredictable 
effect upon execution time. Generally a larger gap size tends to increase the execution time, but some 
objects have been drawn when the reverse has been observed. The gap size should be decid- ed upon aesthetically. 
+7"f i f t P 1S L-- s -~-/7, x.~ G 4-1 5 / -1 FO~ Figure 7 - A typical situation where the value of 
IGQ is used to determine the visible segments of line I. Notice that the halo gap of line J3 is subject 
to an end effect. The numbers along line I are the original TE index. The dimensions are the running 
IGQ counts which are how many haloes obscure a line on a particular segment. 154 Hidden line elimination 
programs are usually evaluated upon the dependence of execution time on picture complexity. The most 
common measures of picture complexity being the line count, or polygonal surface count. Obviously for 
the haloed line effec.t, only the line count, N, is meaningful. For algebra- ic surfaces such as Figures 
2, 3, 10 and 11, the execution time has been observed to be proportional to N**(3/2). Rendering a picture 
of an algebraic surface containing 180 lines required about 1.15 seconds and a similar surface with 1,740 
lines required about 26.07 seconds. J i POTENTIAL ALGORITHMIC IMPROVEMENTS: The techniques described 
in this paper for implementing the haloed line effect are early experimental results and are a compromise 
between complexity and an acceptable quality of graphics. The major calculation task is to detect which 
lines cross and considerable improvement in this regard is to be expected if the lines in the picture 
would be subdivided into smaller groups by clipping (17, 18). The halo entrance and exit marker technique 
used in steps 13 and 14 are similar to the concept of quantitative invisibili- ty described in a previous 
paper on polyhedral hidden line elimination (19). This should suggest that there may be many ways in 
which the haloed line effect can augment or benefit from the usual hidden line elimination techniques. 
One assumption of the implementation is that all the lines used for halo obstruction will be drawn. Additional 
lines can be added to a scene, such as patterns on planes, which are not intended to be drawn but which 
can obscure other lines. The result can be an approximation to complete hidden line elimination. 9PI 
RCqL ON ~ SPHERE Figure 8 -A simple picture containing lettering and axis mark- ings. The haloed line 
effect can be used economically with these graphic elements. }1'""H"},~]~]~.~ It may be interesting to 
compare the haloed line effect with other hidden line elimination techniques, but this is like com- paring 
apples with oranges as the character of pictures and processing are so different. Referring to Figure 
1, the wire frame picture took about .2 seconds of CPU time, the haloed line effect picture required 
about .69 seconds and the com-plete hidden line elimination required about 2.57 seconds. In addition, 
the complete hidden line technique picture needed about 3 seconds set up time for the calculation of 
surface equations, line equations and the usual organizational data structuring which the haloed line 
effect does not need. While these measurements are typical of the programs used, this should not imply 
that the haloed line effect is particularly faster than the usual hidden line elimination techniques. 
Most probably the floating horizon methods of Wright (12) have the same performance characteristics for 
algebraic surfaces. Figure 9 - A series of architectural drawings prepared using the haloed line effect. 
The data consisted only of lines in a three-dimensional space and were not organized in any other way. 
155 CONCLUDING REMARKS: The most important aspect of the haloed line effect is the simplicity and geometrical 
independence of the technique. Scientists and engineers, inexperienced in the special techni- ques of 
three-dimensional computer graphics, are easily taught to use the haloing program because there are virtually 
no rules of topology or organization of the input line set. We would like to thank Cliff Nass for integrating 
the haloed line effect into the United States Military Academy Grat~hics Compatibility System (GCS) and 
for many helpful ideas for improving the quality of the pictures. Thanks are due to Robert O'Hara for 
his architectural data used for Figure 9. Figure 10 - An algebraic surface. REFERENCES: 1. J. Encarnacao, 
"Survey of and New Solutions for the Hidden-Line Problem", PROCEEDING OF SYMPOSIUM ON COMPUTER GRAPHICS, 
Delft, Netherlands, October 1970, pp. 26-28. 2. I. E. Sutherland, R. F. Sproull and R. A. Schumacker, 
"A Characterization of Ten Hidden-Surface Algorithms", COMPUTING SURVEYS, Vol. 6, No. 1, March 1974, 
pp. 1-55. 3. Various techniques are discussed in Chapter 5 of Wolf- gang K. Giloi, INTERACTIVE COMPUTER 
GRAPHICS, Prentice-Hall Inc, Englewood Cliffs, N, J., 1978. 4. Various techniques are discussed in Chapter 
14 of Wil- liam M. Newman and Robert F. Sproull, PRINCIPLES OF INTERACTIVE COMPUTER GRAPHICS, McGraw-Hill 
Book Company, New York, 1973. 5. J. G. Griffiths, "Bibliography of Hidden-Line and Hid- den Surface 
Algorithms", COMPUTER-AIDED DESIGN, Vol. 10, No. 3, May 1978, pp. 203-206. 6. C. Wylie, G. W. Romney, 
D. C. Evans, and A. Erdahl, "Halftone Perspective Drawings by Computer", PROC. AFIPS FJCC 1976, Vol. 
31, 49.  7. A. Appel, "Hidden Line Elimination for Complex Sur-faces", IBM TECHNICAL DISCLOSURE BULLETIN, 
Vol. 18, No. 11, April 1976, pp. 3873-3876. Bruce G. Baumgart, "A Polyhedron Representation for Computer 
Vision", PROCEEDINGS AFIPS NATIONAL COMPUTER CONFERENCE 1975, Vol. 44, pp. 589-596. 9. L. I. Lieberman, 
M. A. Wesley, M. A. Lavin, '~4 GEO-METRIC MODELLING SYSTEM FOR AUTOMATED MECHANICAL ASSEMBLY, " IBM Research 
Report RC 7089, April 25, 1978. 10. Ruth A. Weiss, "BE VISION: a package of IBM 7090 Fortran programs 
to draw orthographic views of combi- nations of plane and quadratic surfaces", JOURNAL OF THEACM, Vol. 
13, No. 2, April 1966, pp. 194-204.  ll. Peter Woon and Herbert Freeman, "A Procedure for Generating 
Visible Line Projections of Solids Bounded by Quadric Surfaces", PROCEEDINGS IFIP CONGRESS INFORMATION 
PROCESSING, North Holland, 1971, pp. 1120-1125. 12. Thomas J. Wright, "A Two-Spaced Solution to the Hid- 
den Line Problem for Plotting Functions of Two Varia- bles", IEEE TRANS. ON COMPUTERS, Vol. c-22, No. 
i, January 1973, pp. 28-33. 13. A. Appel, S. W. Handelman and A. J. Stein, "Hidden Line Elimination 
for Semi-Convex Slices", IBM TECH-NICAL DISCLOSURE BULLETIN, Vol. 20, No. 7, De- cember 1977, pp. 2917-2920. 
 14. Wm. Randolph Franklin and Harry R. Lewis, "3-D Graphic Display of Discrete Spatial Data by Prism 
Maps", Computer Graphics, Vol. 12, No. 3, August 1978, Quarterly Report of SIGGRAPH-ACM. pp. 70-75. 
15. Thomas Wright, "Visible Surface Plotting Program", COMMUNICATIONS OF THE ACM, Vol. 17, No. 3, March 
1974, pp. 152-155. 16. A. Appel and A. J. Stein, "Cellular Automata for Hidden-Line Elimination", IBM 
TECHNICAL DISCLO-SURE BULLETIN, Vol. 17, No. 2, July 1974, pp. 586- 589. 17. I. E. Sutherland and R. 
F. Sproull, "A Clipping Divider," Proc. AFIPS FJCC 1968 Conference, Vol. 33, Part I, pp. 765-776. 18. 
James F. Blinn and Martin E. Newell, "Clipping using Homogeneous Coordinates", Computer Graphics, Quarter-ly 
Report of SIGGRAPH-ACM, Vol. 12, No. 3, August 1978, pp. 245-251. 19. A. Appel, "The Notion of Quantitative 
Invisibility and the Machine Rendering of Solids", Proc. ACM National Conference 1967, pp. 387-393. 
 156 Figure 11 -An algebraic surface. Figure 12 -A series of pictures based upon statistical data. 
All haloed line effect pictures in this paper were processed by the same program. 157  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807438</article_id>
		<sort_key>158</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Transparency for computer synthesized images]]></title>
		<page_from>158</page_from>
		<page_to>164</page_to>
		<doi_number>10.1145/800249.807438</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807438</url>
		<abstract>
			<par><![CDATA[<p>Simple transparency algorithms which assume a linear transparency over an entire surface are the type most often employed to produce computer synthesized images of transparent objects with curved surfaces. Although most of the images created with these algorithms do give the impression of transparency, they usually do not look realistic. One of the most serious problems is that the intensity of the light that is transmitted through the objects is generally not proportional to the amount of material through which it must pass. Another problem is that the image seen behind the objects is not distorted as would naturally occur when the light is refracted as it passes through a material of different density.</p> <p>Use of a non-linear transparency algorithm can provide a great improvement in the realism of an image at a small additional cost. Making the transparency proportional to the normal to the surface causes it to decrease towards the edges of the surface where the path of the light through the object is longer. The exact simulation of refraction, however, requires that each sight ray be individually traced from the observer, through the picture plane and through each transparent object until an opaque surface is intersected. Since the direction of the ray would change as each material of differing optical density was entered, the hidden surface calculations required would be very time consuming. However, if a few assumptions are made about the geometry of each object and about the conditions under which they are viewed, a much simplier algorithm can be used to approximate the refractive effect. This method proceeds in a back to front order, mapping the current background image onto the next surface, until all surfaces have been considered.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Image synthesis]]></kw>
			<kw><![CDATA[Refraction]]></kw>
			<kw><![CDATA[Shading]]></kw>
			<kw><![CDATA[Transparency]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P329962</person_id>
				<author_profile_id><![CDATA[81545290756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Douglas]]></first_name>
				<middle_name><![CDATA[Scott]]></middle_name>
				<last_name><![CDATA[Kay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sundance Productions Inc./Acme Cartoon Co., Inc., 7141 Envoy Ct., Dallas, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68460</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>807403</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Atherton, Peter, Weiler, Kevin and Greenberg, Donald Polygon shadow generation. Proc. SIGGRAPH (1978), 275-281]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. Models of light reflection for computer synthesized pictures. Proc. SIGGRAPH (1977), 192-198]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807364</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. A scan line algorithm for displaying parametrically defined surfaces. Proc. SIGGRAPH (1978)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. and Newell, Martin E. Texture and reflection in computer generated images. Comm. ACM 19, 10 (Oct. 1976), 542-547]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. A. Computer display of curved surfaces. Proc. Conf. on Computer Graphics IEEE Cat. No. 75 CH 0981-1c (May 1975), 11-17]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C. Shaded computer graphics in the entertainment industry. Computer Magazine (March 1978), 10-22]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C. Shadow algorithms for computer graphics. Proc. SIGGRAPH (1977), 242-248]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>905323</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gouraud, Henri Computer Display of Curved Surfaces. Thesis, Univ. of Utah (June 1979)]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kay, Douglas Scott Transparency, Refraction and Ray Tracing for Computer Synthesized Images. Thesis, Cornell Univ., Ithaca, N.Y. (January 1979)]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Newell, M.E., Newell, R.G., and Sancha, T.L. A new approach to the shaded picture problem. Proc. ACM (1973)]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807419</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner An improved illumination model for shaded display. Proc SIGGRAPH (1979)]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807363</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner A scan line algorithm for computer display of curved surfaces. Proc. SIGGRAPH (1978)]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359848</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wu, S.C. An interactive computer graphics approach to surface representation, Comm. ACM 20, 10 (Oct. 1977)]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TRANSPARENCY FOR COMPUTER SYNTHESIZED IHAGES Douglas Scott Kay* and Donald Greenberg Program of Computer 
Graphics Cornell University ABSTRACT Simple transparency algorithms which assume a linear transparency 
over an entire surface are the type most often employed to produce computer synthesized images of transparent 
objects with curved surfaces. Although most of the images created with these algorithms do give the impression 
of transparency, they usually do not look realistic. One of the most serious problems is that the intensity 
of the light that is transmitted through the objects is generally not proportional to the amount of material 
through which it must pass. Another problem is that the image seen behind the objects is not distorted 
as would naturally occur when the light is refracted as it passes through a material of different density. 
Use of a non-linear transparency algorithm can provide a great improvement in the realism of an image 
at a small additional cost. Making the transparency proportional to the normal to the surface causes 
it to decrease towards the edges of the surface where the path of the light through the object is longer. 
The exact simulation of refraction, however, requires that each sight ray be individually traced from 
the observer, through the picture plane and through each transparent object until an opaque surface is 
intersected. Since the direction of the ray would change as each material of differing optical density 
was entered, the hidden surface calculations required would be very time consuming. However, if a few 
assumptions are made about the geometry of each object and about the conditions under which they are 
viewed, a much simplier algorithm can be used to approximate the refractive effect. This method proceeds 
in a back to front order, mapping the current background image onto the next surface, until all surfaces 
have been considered. COMPUTING REVIEWS CLASSIFICATION: 8.1, 8.2 KEYWORDS: Transparency, Refraction, 
Shading, Image Synthesis, Computer Graphics I. INTRODUCTION a) The intensity of the light which is transmitted 
through the objects is generally not One aspect of computer graphics that has proportional to the amount 
of material through received much attention is the production of which it must pass. shaded images of 
mathematically defined objects b) The image seen behind the objects is not (3),(5),(12). Computer synthesized 
images are now distorted as would naturally occur when the light appearing that are difficult to distinquish 
from is refracted as it passes through a material of photographs of real objects. This added realism 
different density. is largely the result of new techniques that consider the surface properties of common 
Most of the existing algorithms for the materials and simulate such detail as texture, simulation of 
transparency deal only with the reflections and shadows (I),(2),(4),(7). modification of a background 
image intensity and are not concerned with simulating refraction An area of image synthesis that is still 
effects. Recent work in ray tracing has produced somewhat lacking is the simulation of transparent systems 
that accurately simulate the effects of materials. Although most of the images created refraction but 
at an excessively high computation with existing algorithms do give the impression of cost (9), (II). 
The next section contains a brief transparency (I0), they usually do not portray discussion of the simplified 
transparency convincing realism due to two factors: algorithms. This is followed by a discussion of the 
problems associated with the simulation of refraction and a proposed modification to the * current address: 
simple algorithm which approximates the Sundance Productions Inc. / refraction effects and improves the 
intensity Acme Cartoon Co., Inc. function without a dramatic increase in 7141 Envoy Ct. computation time. 
Dallas, TX 75247 &#38;#169; 1979 ACM O-89791-004--4/79/0800--158 $00.75 See Copyright Pg. 158 Figure 
3. Sight rays from the observer (0) pass through the picture plane (pp), refract through the object and 
strike the background (b) at points A,B and C. C blblb~ PP Figure 4. Perspective distortion is applied 
to the object causing the A sight rays to strike the background at the incorrect locations B' and C' 
PP Figure 5. Compensating for the perspective distortion to produce the correct angles of refraction 
A still causes the rays to strike the>o background at the incorrect locations B" and C". PP b Note that 
the additional computation is minimized by using the known Z component of the normal which is also required 
to compute shading values. If necessary NORMZ should be adjusted so that it is always positive. With 
a typical exponent value of two or three, this function produces a relatively constant transparency over 
most of the object and quickly reduces to zero near the edges. Regardless of the environment configuration, 
the transparency is ultimately controlled by the direction of the surface (Figure 2). Different exponents 
can be used to simulate the transparency of various typesof material. For a very thin glass, a thin line 
of lower transparency along the edge can be obtained by using a larger exponent. Note that the specular 
reflections improve the realism and, in t~salgorithm, are always added to the final value after the transparency 
is found. They do not directly influence the transparency function. 3. REFRACTION The realism of these 
simulated images can be improved by modeling refraction effects. An algorithm is needed that distorts 
the background image and maps it onto the surface of the object consistent with the laws of refraction 
and without a drastic increase in computation time. Such an algorithm should also determine the correct 
intensity for each pixel based on the amount of material through which the light travels. To determine 
the color for any pixel in a computer generated shaded image, it is necessary, at least conceptually, 
to pass a sight ray from the observer through that pixel location in the picture plane and to determine 
where it intersects the environment. If all the objects in the environment are opaque, the closest element 
intersected determines the color of the pixel, all other surfaces being invisible to the observer. If 
some of the surfaces are transparent, the cumulative effect of the various objects along the path of 
the sight ray should be considered. For the simulation of refraction, the difficulty is that all hidden 
surface algorithms assume that the sight rays always travel in straight lines. a) Perspective space A 
standard procedure employed by most hidden surface algorithms is to pass each of the objects through 
a perspective transformation so that all points seen by a single sight ray have the same X and Y coordinates. 
Therefore, to determine the color for each pixel, it is only necessary to compare the Z values of all 
the surfaces for each pixel location. Usually the normal vectors remain untransformed so that they will 
yield the correct shading values in relation to the light sources. When refraction is being simulated, 
the direction of each sight ray must be modified whenever it strikes a new transparent surface. The angle 
between the sight ray and the normal to the surface controls this direction (Figure 3). However, most 
perspective transformation first distort the object in perspective space and then create the images using 
an orthographic projection. Thus, the angles the sight rays form with the distorted surfaces will be 
wrong and, consequently, so will the new ray directions (Figure 4). If enough information is maintained 
so that the new directions can be determined 160 b correctly, the distances between surfaces will 
still be incorrect. This can cause the intensity function, which is based on the amount of material through 
which the rays pass, to be in error and possibly to Cause the sight ray, with its new direction, to strike 
the wrong location (Figure 5). Most of these errors can be avoided either by performing the hidden surface 
computation using a more costly object space algorithm or by transforming between image space and object 
space so that the proper directions can be maintained. b) Ray tracing When a sight ray strikes a transparent 
 surface, its direction is modified. To simulate refraction, it is then necessary to determine what the 
sight ray can see, given the new direction. This essentially requires a new hidden surface computation 
to be performed every time the sight ray changes direction. The process must continue until the ray reaches 
an opaque surface or the background (Figure 6). The first hidden surface computation that is performed 
is relatively easy because all the sight rays have the same point of origin and their directions are 
all related. However, unless all transparent objects in the environment are of the same simple geometric 
shape, no one transformation will be able to predict the direction or location of any sight ray once 
it is refracted. Thus, for an accurate simulation, a complicated hidden surface procedure will have to 
be performed for each sight ray every time its direction changes. c) Diffuse and specular reflections 
Not all the color seen on a transparent 161  PP Figure 6. Sight rays change direction at every refracting 
surface requiring a new hidden 0 surface computation every time a direction change occurs. Figure 7. 
Specularly reflected rays must also be traced away from the surface requiring additional hidden surface 
computations. surface is due to the transmission of light through the surface. Surfaces that are not 
one hundred percent transparent generally reflect some portion of light diffusely. The models used with 
this type of reflection usually assume that the light sources can be 'seen' by the surface of an object 
directly. Probably more critical for the production of realistic images is the consideration of specular 
reflections. To determine correctly the specular reflection value for a particular point on the surface, 
the direction of the sight ray and the location of the light sources must be considered. It cannot be 
known if the reflected ray can see the light source unless the sight ray is traced to the surface and 
then back out again in the reflected direction. Of course, the refractive properties of the interveninq 
surfaces between any point and the light sources will affect the specular reflections (Figure 7). Essentially 
then, a hidden surface computation must be performed for every specularly reflected ray just as if it 
were a transmitted one. 4. A SIMPLE REFRACTION ALGORITHM Although a correct refraction simulation is 
computationally excessive, it should be possible to obtain a reasonable approximation at a much lower 
cost. The algorithm presented here makes certain simplifying assumptions about the environment but produces 
images of transparent objects that appear to exhibit refraction. The algorithm will be described in relation 
to its implementation in a smooth shading system using a Z-buffer hidden surface method. It can be generalized, 
however, to any type of shading system. 4.1 Assumptions The greatest computational burden associated 
with correct refraction simulation is determining where each sight ray intersects each surface for each 
of its direction changes. Therefore, two major simplifying assumptions will be made. The first assumption 
is that a sight ray travels parallel to the Z axis whenever it is not within a medium. This allows the 
object to be distorted by a perspective transformation which gives the significant advantage that a ray's 
current X,Y location determines which surface it will next intersect. The second assumption is that all 
surfaces can 'see' the light sources directly although they, in fact, may be shadowed by other transparent 
surfaces. Thus, the tracing of diffuse and specularly reflected rays away from the surfaces is completely 
avoided. 4.2 The algorithm Once the two assumptions have been made, the refraction problem is reduced 
to a slight modification of the simple transparency algorithm previously discussed. The difference between 
the two methods are: I) The OLD value from the background image which already exists in an image buffer 
is not necessarily the one at the same X,Y location as the NEW value. 2) The transparency value, t, is 
not a constant but is a function of how much material through which the light ray actually travels. This 
method thus requires: A) a means of determining the direction of the refracted ray, B) a procedure to 
find which X,Y location is to be used for the OLD value, and C) some rules for deciding the order in 
which surfaces are to be processed. A) Algorithm for refraction of vectors When a sight ray strikes 
a surface at a particular point, both the unit vectors describing the direction of the normal to the 
surface and the vector direction of the ray itself are known. The problem is to determine the new direction 
of the sight ray consistent with Snell's Law. This law describes the change in direction of a ray as 
it passes through the boundary between two materials of differing density and is defined as follows: 
n I sin O 1 = n 2 sin 0 2 (3) where n I = index of refraction of the first medium n 2 = index of refraction 
of the second medium 81 = angle between the incident ray and the normal vector 8 2 = angle between the 
refracted ray and the normal vector With the refraction algorithm a difficulty occurs in determining 
the new direction of a refracted ray because each vector can be arbitrarily located in three-space. Conceptually, 
to find the new direction of the refracted ray, both vectors are rotated so as to lie in a plane, the 
angle between the two vectors modified according to Snell's Law and then rotated back to their original 
orientation. The following method determines the direction of the refracted ray easily and avoids specific 
references to the angles involved. Assume that the incident vector (I) is traveling from air (index of 
refraction equal to I) into a material with an index of refraction of n and all vectors are of unit length. 
To find the refraction the refract vector (R), ion vector first by: compute the sine of S = I/n (I -(I" 
N) N) (4) where S = vector whose magnitude is the sine of the refraction vector I = incident vector 
N = normal vector The refraction vector (R) is then found by:  R;s,v Isl 2 , (5) where ]]= indicates 
the magnitude of the vector B) Distortion of the background The effect of refraction is that of the light 
ray changing direction as it enters a medium, traveling for some finite distance and then changing direction 
again as it emerges. Since the refraction algorithm assumes that the sight rays are always parallel to 
the Z axis except when they are within a material, it is only necessary to determine where a ray emerges 
from a medium, given its entering location and direction. To be able to trace the path of a ray as it 
travels through a material requires that each surface have a defined thickness. This algorithm assumes 
that this thickness is constant in the normal direction from any point on the surface and is measured 
in the direction away from the observer (Figure 8). This effectively creates a discontinuous surface. 
The units of thickness are arbitrary, but once they are defined, the transparency of a material must 
be specified in terms of those units. The process is as follows: I) Find a unit vector that defines the 
new direction of the sight ray after it has entered the medium as previously described. 2) Find the distance 
the sight ray must travel within the medium before emerging from the other side. 3) The components of 
the new unit vector are multiplied by this distance to provide the shift in the X and Y directions. 4) 
These incremental values are added to the current X,Y location to yield the location of the sight ray 
as it emerges from the medium. The intensity of a transmitted ray can be found from the following equation: 
162 / \~ I : Y h > I1! I]]~ implied \\\ ,/L surface \\ ,'/ ~" original ~ _ ~~/ surface V Figure 8. 
The refraction algorithm always defines the additional surface in the direction away from the observer. 
This effectively creates a discontinuous surface. d t = T (6) where t = transparency for the total path 
of the current ray T = transparency for one unit distance d = units of distance of the path through the 
medium Since the distance that the ray must travel through a material is determined in step (2) above 
this can be substituted into equation (6) to give a transparency value for the current pixel. C) Implementation 
considerations The implementation of this refraction algorithm is discussed in the context of an image 
buffer where the background image is first placed into the buffer and then each new surface is placed 
on top of the existing image, modifying it as required. To produce images of consistent quality, certain 
specific procedures must be followed. I) Surfaces must be processed in back to front order. This is necessary 
because each surface has the current background image mapped onto it. Unfortunately, the standard Z-buffer 
algorithms process surfaces in a random order and retain only the information depicting the front-most 
surfaces. Therefore, several passes through the object environment may be required, each pass finding 
the next back-most surface until every surface has been processed (Figure 9). 2) As each surface is processed, 
values for each pixel must be stored temporarily until the entire surface is complete. All the new values 
should then replace the ones in the background image. This ensures that remaining surfaces will see an 
image that has already been refracted by the previous ones. It is useful to note that many transparent 
objects typically displayed are of simple geometric form which are often defined by convex b I1 12 13 
14 Figure 9. Surfaces must be processed in back to front order. The background image (b) is first mapped 
onto the back half of Surface 1 producing Image 1 (II). The new image is mapped onto the front half of 
Surface 1 producing Image 2 (12). The process continues with the remaining surfaces until the final view 
seen by the observer, Image 4 (14) is produced. polyhedra. In such cases it may be possible to perform 
a very simple Z-sort on the objects themselves and then use the Z-component of the normal vectors to 
process each rear facing surface before the front facing surface of each object.  4.3 Evaluation The 
assumptions that this algorithm makes about the environment greatly reduce the amount of work necessary 
to simulate refraction without creating excessive errors (Figures 10,11,12). Since all the light rays 
are considered parallel to the Z axis when they are not inside a medium, the error caused in the final 
simulation is largely a function of the severity of the actual perspective view. If the observer is significantly 
far away from the object, all of the sight rays will be nearly parallel. Similarly, if the background 
is very close to the object, divergent sight rays emerging from the object will immediately hit the background 
objects before traveling any significant distance. The assumption that the direction of the surface where 
the sight ray emerges from a medium is the same as where it entered does not provide severe limitations. 
More information could be maintained about the characteristics of the object, but this would greatly 
complicate the process. Clearly, if the medium is very thick, the emerging surface could be at a different 
orientation than that of the entering surface. Fortunately, clear glass and plastic containers, the objects 
most frequently the subjects of these types of computer synthesized images, have thin surfaces and are 
usually regular. For these cases, the errors are minor. Another advantage of this method is that the 
intensity model is much more accurate, since it is based strictly on the distance through which the light 
travels. Although this distance is still an approximation, the relative discrepancy is small when compared 
to the actual ray tracing and is thus rarely a problem even under nonoptimal conditions. 163  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807439</article_id>
		<sort_key>165</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[ATOMLLL]]></title>
		<subtitle><![CDATA[ATOMS with shading and highlights]]></subtitle>
		<page_from>165</page_from>
		<page_to>173</page_to>
		<doi_number>10.1145/800249.807439</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807439</url>
		<abstract>
			<par><![CDATA[<p>The ATOMS program, written at Bell Telephone Laboratory, is capable of determining the visible portions of a scene consisting of interpenetrating spheres and cylinders, put together to represent &#8220;space-filling&#8221; or &#8220;ball-and-stick&#8221; molecular models. The Lawrence Livermore Laboratory version contains enhancements to add shading and highlights, and to render the spheres on film as ellipses, so they will appear round when projected in various wide-screen formats.</p> <p>The visible parts of each sphere or cylinder are shaded by a minicomputer controlling the film recorder, thus releasing the main computer from transferring the millions of intensity values for each frame. The minicomputer is microprogrammed with an efficient algorithm for the intensities, which uses the color look-up tables in the film recorder to store the reflectance as a function of angle of incidence.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer animation]]></kw>
			<kw><![CDATA[Highlights]]></kw>
			<kw><![CDATA[Raster graphics]]></kw>
			<kw><![CDATA[Shading]]></kw>
			<kw><![CDATA[Space-filling molecular models]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Shading</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15033556</person_id>
				<author_profile_id><![CDATA[81100480335]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nelson]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Max]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. Models of light reflection for computer synthesized pictures. Computer Graphics Vol. 11, no. 2 (1977), pp. 192-198.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359432</ref_obj_id>
				<ref_obj_pid>359423</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. E. An incremental algorithm for digital display of circular arcs. Communications of the ACM Vol 20, no. 2 (1977), pp. 100-106.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[IMAX. Promotion brochure, November 1977, available from IMAX Systems Corporation, P.O. Box 224 Cambridge, Ontario Canada N1R5T8.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[OMNIMAX. Promotion brochure, September 1977 available from IMAX Systems Corporation, ibid.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Knowlton, Ken and Cherry, Lorinda. ATOMS, a three-d opaque molecule system. Computers and Chemistry Vol. 1, no. 3 (1977) pp. 161-166.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson. ATOMLLL - a three-d opaque molecule system, Lawrence Livermore Laboratory version, UCRL-52645, Lawrence Livermore Laboratory 1979.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson. DNA with ethidium. 5 minute color silent computer animated film, available on loan from the author.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>639789</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Porter, Thomas. Spherical shading. Computer Graphics Vol. 12, no. 3 (1978) pp. 282-285.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807385</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Staudhammer, John. On display of space filling atomic models in real-time. Computer Graphics Vol. 12, no. 3 (1978) pp. 167-172.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ATOMLLL: -ATOMS with Shading and Highlights Nelson L. Max Lawrence Livermore Laboratory Abstract The 
ATOMS program, written at Bell Telephone Laboratory, is capable of determining the the visi- ble portions 
of a scene consisting of interpene- trating spheres and cylinders, put together to represent "space-filling" 
or "ball-and-stick" mole- cular models. The Lawrence Livermore Laboratory version contains enhancements 
to add shading and highlights, and to render the spheres on film as ellipses, so they will appear round 
when projected in various wide-screen formats. The visible parts of each sphere or cylinder are shaded 
by a minicomputer controlling the film recorder, thus releasing the main computer from transferring the 
millions of intensity values for each frame. The minicomputer is microprogrammed with an efficient algorithm 
for the intensities, which uses the color look-up tables in the film recorder to store the reflectance 
as a function of angle of incidence. Key Words and Phrases Computer animation, shading, highlights, ras-ter 
graphics, space-filling molecular models CR Catagories 8.2, 3.13 1. Introduction The ATOMS program (5), 
by Kenneth Knowlton and Lorinda Cherry at Bell Telephone Laboratory, com-putes the visible regions of 
a scene consisting of potentially intersecting spheres or cylinders, called parts. The ATOMLLL version 
runs on the CDC 7600 at~ence Livermore Laboratory. Its input is a list of atomic coordinates, radii, 
and colors, and a connection table for the bonds, if any. Its output is a binary tape containing shading 
informa- tion for each part, followed by a list of "trape-zoids" into which the part has been divided, 
as described in Sec. 2. This tape is read by a Varian V-75 minicompu- ter, which controls a Dicomed D-48 
color film recorder. The Varian divides each trapezoid into vertical raster segments, and uses an efficient 
algorithm described in Sec. 3 to find the shading values along each segment, which are then plotted by 
the Dicomed. The most complex figures shown here took about 2 seconds on the 7600 to compute and output 
the visible surface parts, and 2 minutes on the Varian -Dicomed system to compute and plot the shading 
at 1536 x 2048 pixel resolution. Users can view the outlines of each part on a black and white TV monitor 
in their offices, while composing a sequence on the CDC 7600, before committing it to film (See Fig. 
17). similar pictures have been produced by Thomas Porter (8), and John Staudhammer (9), using color 
video output. Porter's system can create pictures on a stand-alone PDP-11 minicomputer. Because it uses 
a depth buffer algorithm, several Z computa- tions and comparisons may be required for each pixel. Staudhammer's 
system uses special purpose hardware to generate shading and highlights on the fly at video rates, from 
a previously prepared list of visible segments. His shading algorithm is based on a table, and is similar 
to the method re- ported here, although the actual table is quite different. Both these systems currently 
output at the re-solution of the standard color TV monitor. The ATOMLLL system can plot on wide format 
film at up to 4096 - 4096 resolution, giving much higher qual- ity at the cost of extra plotting time, 
and can plot bonds as well as atoms. It is also capable of rendering the spheres on film as ellipses, 
as described in Sec. 4, to compensate for the distor- tion introduced by various wide screen projection 
lenses. "Work performed under the auspices of the U.S. Department of Energy by the Lawrence Livermore 
Laboratory under contract number W-7405-ENCr 48." &#38;#169; 1979 ACM O-8979"1-004--4/79/0800--165 $00.75 
See Copyright Pg. 165 YTR YTL "~ XCT, YCT YBL YBR XL Figure 1 XR 2. The Hidden Surface Algorithm As described 
in (5), the ATOMLLL program keeps track of the visible portions of each part in terms of a list of "trapezoids". 
Each such trapezoid, as shown in Fig. 1, has two straight vertical sides. The other two sides may be 
straight lines or arcs of circles. The circular arcs can be convex down, as is the top arc in Fig. i, 
or convex up. In addition, each arc must be monotone, with y either non-increasing or non-decreasing. 
Thus, a sphere is initially represented as two trapezoids, each having one degenerate vertical side, 
as shown in Fig. 2a. Figure 2a Figure 2b If this sphere is intersected, or "truncated," by a second sphere, 
as in Fig. 2b, the intersection curve is approximated by a circular arc, and the trapezoids of the first 
sphere are chopped or sub- divided into their visible pieces. They are fur- ther subdivided in Fig. 2c 
by a third atom in front of the other two. In general, the trapezoids in the currently visible list for 
a part can be com- pared one by one to the trapezoids defined for a potentially occluding part, and reduced 
or subdi-vided appropriately. A new modification may remove the reason for an earlier subdivision, as 
seen in Fig. 2c, where some of the vertical lines are no longer required. Thus, after any occlusion changes 
the list, it is compacted to amalgamate adjacent trapezoids if possible, as in Fig. 2d. Further details 
on the hidden surface algorithm can be found in (5) and (6). 3. Shading and Highlights The shading algorithm 
is closely tied to sever- al hardware features of the Dicomed D-48 film re-corder. It contains a computer 
controlled color filter wheel, with six colors, and a seventh clear position. There are also eight loadable 
look-up tables, one to be used for each of the seven filter positions, and an eighth for black and white 
expo- sures. These tables translate an eight bit input intensity into another intensity for output onto 
the film, and were designed to compensate for film characteristics. In raster mode, the Dicomed gets 
a stream of bytes by direct memory access of an output buffer on the Varian, and plots the compen- sated 
values across a scan line. Meanwhile, the Varian may be filling a second buffer of intensi- ties. The 
atoms are shaded as if the light came from a point infinitely far behind the viewer. Thus the reflected 
intensity is a monotone decreasing func- tion f(e), of the incidence angle e, shown in Fig. 3. For diffuse 
lighting, an appropriate intensity function might be f(e) = A + D cose ... 1) Figure 2c Figure 2d Figure 
3 166 The color of the diffusely reflected light is the color of the surface. For highlights, representing 
specular reflec- tion concentrated at small incidence angles, an appropriate function might be g(e) = 
C(cose) n ... 2) for some large n. The color of the highlight is white. The functions f(e) and g(e) 
are entered into the color and black-white look-up tables, respectively, so any reflection law may be 
used. More sophisticated functions are given in Blinn (I). The func$ions f and g are actually tabHlated 
in terms of cos~e. We now demonstrate how cos~e can be computed very efficiently using finite differences. 
\ \ \ \ \ \ \ \ C \\ \ \ \ \ \ \ \ \ \ \ \ \\\\ Q Figure 4 Figure 4 shows the projection of a sphere 
onto the picture plane, The point P=(X,Y,Z) is on the surface, C=(XC, YC, ZC) is the center, and R is 
the radius. Figure 3 shows a section of this sphere, in a plane perpendicular to the dotted line. From 
triangle PDC in Fig. 3, we find P--C2D _ (Z-ZC) 2 cos2e -pcZ~ R2 ... 3) Solving the equation of the 
sphere, (X-XC) 2 + (Y-YC) 2 + (Z-ZC) 2 = R 2 ... 4) for (Z-ZC) 2, and substituting in Eq. 3 we get cos2e 
= R 2 -(X -XC) 2 (Y -YC) 2 R2 .., 5) Since the trapezoids have vertical sides, they are colored in vertical 
raster scan segments. Along a vertical segment such as the one shown in Fig. 4, the quantities R, X, 
XC, and YC are con- stant, so Eq. 5 represents a quadratic polynomial in Y. This polynomial is evaluated 
at successive points along the scan segment, using finite differ- ences. The second difference for any 
quadratic polynomial is a constant, equal to its second deri- vative. Therefore, the exact value can 
be accumu- lated using two additions per cycle of the difference loop. If N is the number of raster points 
to be plotted, the second difference is added effectively (N-1)(N-2)/2 times, so double precision integers 
are required on a 16 bit machine. Since the as- sembly language of the Varian does not permit more than 
one double precision operand to be retained in registers, the coding for the difference loop would be 
quite inefficient in memory access. Fortunately, a writeable control store was available, so the whole 
loop was replaced by a new machine instruction written in microcode. Eight registers are ~oaded with 
N, the double precision values for cos:e and its first and second differ- ences at the bottom point Q 
of the scan segment, and the starting address of the output buffer. The microcode then does the two double 
precision adds, loads t~e high order byte of the accumulated value for cos~e into the proper byte of 
the output buf- fer, tests for completion, and loops, all in eight 195 ns microinstruction cycles. For 
atoms which fill up a substantial area of the screen, it can generate the intensity values faster than 
the Dicomed can plot them. For smaller atoms, the square roots required for computing the upper and lower 
boundary arcs for the trapezoids become the bottleneck. They could be removed by using Bresenham's algorithm 
(2), as suggested in (8). A B C Y i' V.I eQ Figure 5 Ideally, the shading for a cylinder can also 
be determined from a quadratic polynomial along a ver- tical scan segment. However, after the perspective 
transformation, cylinders become cones, and the shading is no longer so simple, especially when the directions 
of the projected edges lie in different quadrants, as in Fig. 5. Let Q be the "vanishing point" for these 
edges, so that QA and QC, the extentions of the projected edges, and QB, the projected center line, all 
meet at Q. Assume QA has negative slope, while QB and QC have positive slopes. Then the part of the bond 
lying in AQB will be shaded using quadratic poly- nomials on horizontal segments, and the part in BQC 
will be shaded using different polynomials on vertical segments. These polynomials are adjusted to have 
their maximum value (which depends on the angle between the bond axis and the plane of view) along the 
line QB, and to be zero along QA and QC. Thus they agree smoothly along QB, and give a close approximation 
to the true shading. The usual method of color rendition represents the combined diffused and specular 
reflection as the sum of red, green, and blue components, painted in three separate passes through three 
colored fil- ters. The present algorithm renders the diffuse reflection through one of the seven coIRred 
fil- ters, using the look up table for f(cos~e) and then adds the highlights through the clear filter, 
getting g(cosLe) from the black and white table. In this way, only two passes are required, each with 
exactly the sam~ data. In summary, the combination of the finite difference technique for cos e, with 
the look-up tables for the shading functions, results in a very efficient shading algorithm. 4. Wide 
Screen and Dome Projections In early 1978, Lawrence Livermore Laboratory was approached by a group which 
proposed to produce computer animation in the IMAX(3), and OMNIMAX(4) wide screen movie formats. The 
film used is 70 mm wide, projected in a horizontal orientation, so that the larger dimension of the picture 
runs along 15 perforations of the film. Figure 6 shows a frame in full scale. It has more than 10 times 
the area of a 35 mm movie frame, permitting excellent resolution even when projected on a very wide screen. 
The IMAX format uses a 90  field-of-view wide angle lens to project onto a huge slightly curved screen, 
while the OMNIMAX uses a 180  field of view fisheye lens to project onto a hemispheri- cal dome. Both 
these systems introduce their own distor- tions, which must be compensated for when plotting on the film. 
In the IMAX format (see Fig. 15), the image on the screen is a direct magnification of the image on the 
film. Nevertheless, because of forshortening, a sphere viewed from the center of the theatre must be 
represented as an ellipse, whose long axis points toward the center of the screen. Near the corners of 
the screen, the elon- gation factor (ratio of long axis to short axis) may be as great as 1.6. In the 
case of the OMNIHAX lens, which must distort a flat picture to cover the dome, the projection was chosen 
to concentrate the high resolution near the center of the image, Figure b An IMAX movie frame. and spread 
out a relatively small film area to co-ver the peripheral edges of the image, where human perception 
is not as precise. As a result, a sphere near the edge of the dome must be repre- sented on film as an 
ellipse whose short axis points towards the center of the image, and whose elongation factor may be as 
large as 4.8 (see Fig. 16.) We may put both these projections in the same conceptual framework by imagining 
a "dome of view", a unit hemisphere, with center at the projector and observer (assumed to coincide) 
which intercepts the rays headed for the screen. The characteristics of the projection lens determine 
the mapping between points P on the film, and their corresponding images Q on the dome of view. Suppose 
P is represented, as in Fig. 7a, by the polar coordinates (r,e), while Q is represented as in Fig. 7b, 
by the spherical coordinates (~,@). Then B will equal e, and the lens characteristics are represented 
by the function @=@(r). For the IMAX lense, @(r)= arctan (r/ro). For the OMNIMAX lens, @(r) is as plotted 
in Fig. 8, and was approx- imated by a polynomial in the computer.  Figure 7a 168 0 C Figure 7b 1.0 
0,8 0,6 0.4 0,2 0 , , I , , I , , 0 30 60 90 ~(r) in degrees  Figure 8 Now a small sphere in space 
will project onto a small round disk on the dome of view, with equal angular extents (CQ and QD) in the 
lattitude and longitude directions. Expressing these lengths in terms of the infinitesimals d and de, 
we get the equation d@= sin @de ... I0) To first order, the inverse image of this disk will be an ellipse 
in the film plane, with a semi-axis PB in the tangential direction, of length rde, and one in the radial 
direction, PA, of length dr. Their ratio, PB/PA=rde/dr is the elongation e(r). Solving Eq. I0 for de 
and subsituting, we find the elongation e(r) : rde = r d@ = r@'(r) ii) dr sin @ dr sin "'" If the function 
@(r) = cos-l[(l-r2)/(1+r2)] is sub-stituted into Eq. ii, the elongation turns out to be identically i, 
and circles on the sphere map to circles (or straight lines) in the plane. This particular function is 
called stereographic projec- tion, and is often used to map regions around the earth's poles, since it 
preserves the shape of land masses. In the case of the OMNIMAX projection, e(r) will be greater than 
one, since the ellipse is squashed in the radial direction by the inverse of the lens projection. For 
the IMAX lens, e(r) will be less than i. A sphere of finite size should usually have an egg shaped film 
image, since the general projection is non linear. However, the first order elliptical region, with orientation 
and elongation computed as in the infinitesimal case, is adequate. Inside such a region, the shading 
function cos2e can be repre- sented as a quadratic polynomial in X and Y, which vanishes at the boundary 
ellipse. Thus the shading can again be computed by finite differences along vertical scan segments. Note 
that e here measures the direction of the normal vector to the atom be- fore the distortion, so the shading 
Will be correct after projection, and is not the correct shading for an ellipsoid. The shading of the 
ellipses is simple enough, but the hidden surface algorithm is another ques- tion. Four person-years 
went into the algorithm of (5), which depends in two essential ways on circular arc boundaries. The first 
is in a quick test to see whether two parts can interact in the picture plane. For exam- ple, two atoms 
do not interact if the sum of their projected radii does not exceed the distance between their projected 
centers. The structure of these quick tests was retained, by conducting them in sterographic coordinates, 
where spheres do project to circles. Even these quick tests must be done N(N-I)/2 times f~r N parts, 
which would make the algorithm of order N ~. For large structures, the parts are therefore first sorted 
into lists corresponding to an array of film plane windows, so that parts which could possibly interact 
with a given part can be found in an appropriate subset of the lists. The second dependence on circular 
arcs is in the algorithm which compares two trapezoids, and modifies one if it is occluded by the other. 
Here, elliptic boundaries could add substantial complica-tion. For example two ellipses can intersect 
in as many as four points, while two circles can intersect in at most two. Since the ellipse only approximates 
the egg shaped sphere projection, it was decided to approx-imate the ellipse boundary in turn by four 
circular arcs. The quadratic polynomial for the shading be- comes negative for points outside the boundary 
el- lipse. In order to avoid wraparound in the color look-up tables, the approximating arcs must thus 
remain inside or tangent to the ellipse, as shown in Fig. 9. The basic problem is to find the best approximation 
to the standard ellipse x 2 y2 ... 12) may be generated. This process, which applies for (o, 1) =G 
l the non-distorted projections as well, removes the corners seen in Fig. 2b. (X, Y) (-A, O) = E U 5. 
The Film "DNA With Ethidium" (0, -D) = P Figure 9. (Circular arcs distorted for clarity) T J   /// 
~l M B Figure 10 of elongation A>I. The approximation can then be rotated, translated, or magnified 
as required. A solution for the best approximation, which may be of use in other computer graphics applications 
re- quiring ellipses, is given in the Appendix. Once the approximation is found it can be divided up 
into trapezoids, as shown in Fig. 10. Since the top and bottom points, T and B, need no longer have the 
same X coordinate, and we have introduced four new points of division, the ini- tial subdivision will 
in general have seven trape- zoids instead of two. After the trapezoids for a part are created, they 
may be modified as before by the trapezoids from a potentially occluding part. Further complications 
are caused by the "trun- cation" arcs (see Fig. 2b), which are projections of the circles where two parts, 
say two spheres, intersect each other in space. The linear part of the perspective projection from space 
to the dome of view will turn such a circle into an ellipse. The linear part of the inverse projection 
from the dome through the lens onto the film, which we have just discussed, will then turn this ellipse 
into another ellipse. The equation for this "trunca-tion" ellipse can be found by composing the linear 
parts of these two transformations. It can then be approximated by four circular arcs as before. In general, 
three of these arcs will be required to "truncate" an atom, and as many as 15 trapezoids The public presentation 
includes a five minute computer animated film (7), produced at Lawrence Livermore Laboratory, illustrating 
the interaction of DNA with the drug ethidium bromide. Ethidium is used as a fluorescent stain for DNA 
in cytological research. It is known to cause "frame" mutations in bacteria by being mistaken in its 
intercalated position (Fig. 12) for a base dur- ing DNA replication. The film opens with six base pairs 
of DNA, ro- tating about the double helix axis. The computer simulates the "CPK space-filling molecular 
models," interlocking plastic spheres invented by Pauling and Corey to study chemical structure, and 
now in widespread use. Carbon atoms are dark blue rather than black, to stand out against the black back- 
ground, but the other colors are standard: red for oxygen, white for hydrogen, blue for nitrogen and 
yellow for phosphous. The rotation stops, and the DNA changes its conformation. The center two base pairs 
open up to twice their normal separation, and the other bases adjust by partially untwisting the helix 
(Fig. 11). The ethidium ion then moves into the gap that has been created i.e., "intercalates" (Fig. 
12). The coordinates of the atoms during the interaction were calculated at Case Western Reserve University 
by Nelson Max and Deepak Malhotra. The CAMSEQ pro- gram, developed by Anton Hopfinger and his stu- dents, 
calculated the total interaction energies (including the effects of the surrounding water) for a large 
number of different positions, created to satisfy certain initial constraints, and the ones of minimum 
energy were chosen. Work is continuing at Case-Western Reserve to refine these coordinates, and to calculate 
the in- teractions of DNA with other small molecules. The goal of this research is to learn to predict 
the mutagenicity and carcinogenicity of an arbitrary chemical compound, in order to select those com- 
pounds which are high priorities for expensive biological testing. Interactive computer graphics with 
space-filling models to show Van der Waals contacts could be a useful tool in this effort. The next scene 
shows a dissolve between two different representations of the center two base pairs: the space-filling, 
and the ball-and-stick. When seen rotating, an intermediate stage in this dissolve gives the impression 
of a transparent outer electron shell, revealing the inner bond structure (Fig. 13). The final scene 
shows a ball-and-stick repre- sentation of another local energy minimum for the DNA-ethidium interaction 
(Fig. 14), this time with the ethidium outside the "narrow grove." Figure 15 shows in IMAX projection 
several unit cells of the structure of antimony thio-iodide, which has the largest known photoconductivity 
ef- fect, and a number of other interesting physical  properties. If viewed from a distance of half 
the picture width (possible only if you are very near-sighted) the ellipses will be forshortened into 
circles. Figure 16 shows the OMNIMAX image of the same structure. Note that the spheres now undergo the 
reverse distortion. Figure 17 shows the outlines of the visible regions of Fig. 16, as they would appear 
on the one-bit-video TMDS screen in a user's office. 0 0 Figure 17. Outlines for Fig. 16, in one-bit 
video. References 1. Blinn, James F. Models of light reflection for computer synthesized pictures. Computer 
Graphics Vol. 11, no. 2 (1977), pp. 192-198. 2. Bresenham, J. E. An incremental algorithm for digital 
display of circular arcs. Communica-tions of the ACM Vol 20, no. 2 (1977), pp. 100-106. 3. IMAX. Promotion 
brochure, November 1977, available from IMAX Systems Corporation,  P.O. Box 224 Cambridge, Ontario 
Canada NIR5T8. no OMNIMAX. Promotion brochure, September 1977 available from IMAX Systems Corporation, 
ibid. 5. Knowlton, Ken and Cherry, Lorinda. ATOMS, a three-d opaque molecule system. Computers and Chemistry 
Vol. 1, no. 3 (1977) pp. 161-166. 6. Max, Nelson. ATOMLLL - a three-d opaque mole- cule system, Lawrence 
Livermore Laboratory version, UCRL-52645, Lawrence Livermore Laboratory 1979. 7. Max, Nelson. DNA with 
ethidium. 5 minute color silent computer animated film, available on loan from the author. 8. Porter, 
Thomas. Spherical shading. Computer Graphics Vol 12, no. 3 (1978) pp. 282-285.  9. Staudhammer, John. 
On display of space filling atomic models in real-time. Computer Graphics Vol. 12, no. 3 (1978) pp. 167-172. 
APPENDIX Here are the details for approximating the el- lipse of Eq. 12 by the four circular arcs NJ, 
JL, LM, and MN, shown in Fig. 9. One of these, NJ, has center at P=(O,-D) and radius R, and another, 
JL, has center Q=(C,O) and radius S. If W=(X,Y) is a point on the approximation, then the "relative radial 
error" X2 y2 E=--+ -1 ... 13) A 2 represents the radial distance from the dome pro- jection of W to the 
closest point on the circle which is the projection of the ellipse. We wish to determine the four numbers 
C, D, R, and S, as func- tions of the elongation A, to minimize the absolute value of E over all points 
W on the approximation. Since our shading scheme will overflow if the approximation lies outside the 
true ellipse, we re- quire E to be non-positive. This makes the approx- imation tangent to the ellipse 
at eight points of two types, represented in Fig. 9 by G and H respec- tively. The relative radial error 
E is worst at eight points of two other types, represented by U and V respectively. We can get four equations 
in the four unknowns C, D, R, and S, as follows. By the pythagorean theorem in triangle POQ, we have 
C 2 + D 2 = (R-S) 2 ... 14) since the length of the hypotenuse PQ is the dif- ference in the radii of 
the two circles. Next, since the large arc is tangent to the ellipse at G, we get two equal expressions 
for the distance PG: R = D + 1 ... 15) Now as we continuously adjust the four parame- ters, keeping the 
two arcs tangent to each other, and to the ellipse, the two relative errors E 1 and E 2, at U and V, 
respectively, will change. A de- crease in one will be compensated by an increase in the other. Thus 
the overall minimum will occur when E 1 and ~2 are equal. Now, the error E 1 at U = (C+S,O) Is easy to 
compute: (C+S) 2 E I = A2 1 . ... 16) To find the error at V, we note that V repre- sents a local minimum 
of the error E along the arc GVJ. Let W=(X,Y) be a point on this arc, and e be the angle between the 
radius PW and the X axis. To minimize E, we express it as a function of the angle a. Along the arc GVJ, 
X and Y are given by X = R cos B Y = R sin o -D 172 Substituting in Eq. 13, we must minimize E(e) = 
(R cos e) 2 + (R sin e -D) 2 -I ... 17) A 2 which can be written in terms of sin e alone as E(e)=R2(1 
) sin2e -2 DR sine +~+D 2 -i ...18)  - 1A2 R2 This is a quadratic function of sine, and takes on the 
minimum value: R 2 D 2 = -i ... 19) E2 A2 A2_1 Since the largest error is a minimum when E 1 and E 2 
are equal, We combine Eqs. 16) and 19) to get R 2 D 2 _ (C+S) 2 ... 20) A 2 A2-1 A 2 To find the fourth 
equation, note that the tangency at H occurs at the point on the arc JHU where the error E takes on its 
maximum value, zero. Along this arc X = S cos e + C , and Y=Ssine so we have E(v) = (S cos e + C) 2 
+ (S sine) -1 ... 21) A 2 which, written in terms of cose alone, becomes E(e)=S2(~-I) cos2e + 2SCAcose 
+ A~ $2 -1 ... 22) Note that the coefficient of S 2 is negative, when A 1, so this quadratic function 
has a maximum. Computing this maximum value and setting it to zero, we get C 2 C 2 --+ S 2 -1 + -0 ... 
23)A 2 A2(A2.1) Thus, our four equations in the four unknowns are equations 14), 15), 20) and 23). These 
equa- tions can be manipulated algebraically to give a single fourth degree polynomial for S, whose coef- 
ficients depend on A. The appropriate root S of this polynomial was tabulated for 21 non-uniformly spaced 
values of the elongation A, from 1 towards infinity, and then approximated by a least squares fit polynomial 
in powers of 1/A. The result was .62934 .06592 .0399_~2 + .0113__~5 S(A)= .33333 +~+ A 2 A 3 A 4 ... 
24) which approaches 1 when A approches 1, and approches 1/3 when A approches infinity. If A and S are 
known, C, D, and R can be determined from Eqs. 23), 14) and 15). Reference to a company or product name~ 
does not imply approval or recommendation of the product by the University of California or the U.S. 
Department of Energy to the exclusion of others that may be suitable. NOTICE "This report was prepared 
as an account of work sponsored by the United States Government. Neither the United States nor the United 
States Departmentof Encrgy, nor any of their employees, nor any of their contractors, subcontractors, 
or their employees, makes any warranty, express or implied, or assumes any legal liability or respon- 
sibility for the accuracy, completeness or usefulness of any information, apparatus, product or process 
disclosed, or represents that its use would not infringe privately-owned rights." (0, I)=G (-A, O) = 
E/f ~ / o (O, -D) = P 173 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807440</article_id>
		<sort_key>174</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[A fast scan-line algorithm for rendering parametric surfaces]]></title>
		<page_from>174</page_from>
		<doi_number>10.1145/800249.807440</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807440</url>
		<abstract>
			<par><![CDATA[<p>An algorithm for rendering shaded pictures of parametric curved surfaces is presented. The algorithm recursively subdivides each surface element on the basis of its screen-space parametric curvature until it is sufficiently close to bilinear to be scan-converted by conventional polygon rendering techniques. The mathematical basis chosen to carry out the subdivision process yields the curvature criterion as a coefficient so that the tests for termination of the subdivision process are extremely simple. In addition, a surface is subdivided only in the parametric direction in which its curvature deviates from the tolerance. The algorithm incorporates a very simple solution to the problem of separations between sibling subpatches.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39074904</person_id>
				<author_profile_id><![CDATA[81332493735]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Clark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807441</article_id>
		<sort_key>175</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Predetermining visibility priority in 3-D scenes (Preliminary Report)]]></title>
		<page_from>175</page_from>
		<page_to>181</page_to>
		<doi_number>10.1145/800249.807441</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807441</url>
		<abstract>
			<par><![CDATA[<p>The principal calculation performed by all visible surface algorithms is the determination of the visible polygon at each pixel in the image. Of the many possible speedups and efficiencies found for this problem, only one published algorithm (developed almost a decade ago by a group at General Electric) took advantage of an observation that many visibility calculations could be performed without knowledge of the eventual viewing position and orientation&#8212;<underline>once for all possible images</underline>. The method is based on a &#8220;potential obscuration&#8221; relation between polygons in the simulated environment. Unfortunately, the method worked only for certain objects; unmanagable objects had to be manually (and expertly!) subdivided into managable pieces.</p> <p>Described in this paper is a solution to this problem which allows substantial a priori visibility determination for all possible objects without any manual intervention. The method also identifies the ( hopefully, few) visibility calculations which remain to be performed after the viewing position is specified. Also diescussed is the development of still stronger solutions which could further reduce the number of these visibility calculations remaining at image generation time.</p> <p>The reduction in overall processing and memory requirements enabled by this approach may be quite significant, especially for those applications (e.g., 3-D simulation, animation, interactive design) in which numerous visible surface images are generated from a relatively stable data base.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010213</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10011254.10011258</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Algorithm design techniques->Dynamic programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39071971</person_id>
				<author_profile_id><![CDATA[81339500019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fuchs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P310588</person_id>
				<author_profile_id><![CDATA[81100539349]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zvi]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kedem]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mathematical Sciences, University of Texas at Dallas, Richardson, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39081064</person_id>
				<author_profile_id><![CDATA[81100625208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Naylor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mathematical Sciences, University of Texas at Dallas, Richardson, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>578775</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aho, A.V., Hopcroft, J.E. &amp; Ullman, J.D. (1974) The Design and Analysis of Computer Algorithms, Addison-Wesley]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1096893</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Berge, C. (1973) Graphs and Hypergraphs, North Holland]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>260999</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Knuth, D.E. (1973) The Art of Computer Programming; Volume 1/Fundamental Algorithms, (Second Edition), Addison Wesley]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578799</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Preparata, F.P. &amp; Yeh, R.T. (1973) Introduction to Discrete Structures, Addison-Wesley]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Schumacker, R.A., Brand, R., Gilliland, M. &amp; Sharp, W. (1969) "Study for Applying Computer-Generated Images to Visual Simulation", AFHRL-TR-69-14, U.S. Air Force Human Resources Laboratory]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., Sproull, R.F. &amp; Schumacker, R.A. (1974) "A Characterization of Ten Hidden-Surface Algorithms", ACM Computing Surveys, 6 (1):1-55]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 PmEDETEERINING VISIBILITY PBIORITY IN 3-D SCENES (Preliminary Report) Henry Fuchs Computer Science 
Department University of North Carolina Chapel Hill, NC Zvi M. Kedem Bruce Naylor Mathematical Sciences 
University of Texas at Dallas Richardson, TX  _A bst_a!~&#38;_t The principal calculation performed 
by all visible surface algorithms is the deter,ination of the visible polygon at each pixel in the image. 
Cf the many possible speedups and efficiencies found for this problem, only one published algorithm (developed 
almost a deca]e ago by a group at General ~lectri) took advantage of an observation that many visibility 
calculations could be performed without knowledge of the eventual viewing position and orientation --q~.9~f_9 
n ~ ~!s_i~!~ i~a_.qSs. The method is based on a "potential obscuration-relation between polygons in the 
simulated environment. Unfortunately, the method worked only for certain objects; unmanagable objects 
had to be manually (and expertly!) subdivided into ~anagable pieces. Eescribed in this paper is a solution 
to this problem which allows substantial a priori visibility determination for all possible objects without 
any manual intervention. The method also identifies the ( hopefully, few) visibi~ty calculations which 
remain to be performed after the viewing position is specified. ~lso discussed is the development of 
still stronger solutions which could further reduce the number of these visibility calculations remaining 
at image generation tire The reduction in overall processing and ~emory reguirements enabled by this 
approach may be quite significant, especially for those applications (e.g., 3-D simulation, animation, 
interactive design) in which numerous visible surface images are generated from a relatively stable data 
base. Introduction The basic ideas in Shumacker et al (1969) are succintly described in Sutherland, 
Sproull, and Schumacker {197q), from which we quote here. (Note that polygons are referred to as "faces", 
and objects or parts of objects are referred to as "clusters".) The notion that face priority within 
a cluster can be computed independent of the viewpoint is extremely important. Consider the top view 
of an object, as shown in figure I. If, for any viewpoint, we eliminate the back faces (relative to 
that viewpoint), the numbers assigned to each face in the figure are the priority numbers. &#38; cluster 
is a collection of faces that can be assigned a fixed set of priority numbers which after back edges 
are re=owed, provide correct priority from any viewpoint. The computation of face priority requires 
computing whether face A can, from any viewpoint, hide face B. If so, face A has priority over face B. 
these computations are performed for all faces of a cluster, and a priority graph is constructed. If 
there are any circuits in the graph (e.g., face A has priority over face B, and face B has priority over 
face A}, the races cannot be assigned priorities that will produce a correct image. In this case, the 
cluster will have to be split manually into smaller clusters. &#38;#169; 1979 ACM O-89791-004--4/79/0800--175 
$00.75 See Copyright Pg. 175 "'''''-''''I  13 L ! I I 2 2~I \l 1 L Figure I: Face priority, a) Top 
view of an object with face priority numbers assigned (the lowest number corresponds to the highest priority), 
b) The same object with a specific viewpoint located. ~he dashed lines show back faces. Face 1 takes 
priority over facs 2. [From Sutherland, Sproull, and Schumacker (197,) ]. Although it is at first encouraging 
That viewpoint-independent visibility priority can be determined for many objects, it is rather discouraging 
that objects for which this cannot be done are so easy to find (e.g., figure 2). This lack of "dependability" 
of the approach, we believe, has kept it from widespread use. ~e present in this paper a solution to 
this problem which allows, without ~al in~rvention, the generation of priority structures which exhibit 
minimum variance under viewpoint modification. l I  Figure 2: Simple object with no viewpoint- independent 
priority. are visible "from outside the object"  nd if r i and r~ are both "facing" toward the viewer, 
then Jf(ri) ~ f(rj) if and only if ~ cannot obstruct ~. Further, for any point P outside the ohJeot (see 
figure 3) if there is a ray from P which intersects both r i and r~ and if ri and "face" P, then % o~scures 
r~ (along t%is ray) if and only if f(ri) < f]~ ). ,i 3 81 L. l l" 12 "I 4 .5, l c ' I 4 e I 71 ' I 
 p " + Figure 3: Visibility along a viewing ray (with an associated f(r i ) beside each polygon r i. 
} Ne now formally describe our interpretation of Schumacker's method as partially based on Sutherland, 
Sproull and Schumacker (1974) and on personal communication with him (Schumacker). As above, we define 
a relation < on the set fl: r. < r. if and only if there exists a ray ifrom3 some viewing position P 
which pierces the "front sides" of both r. and r. and whose point of intersection l with ~ is closer 
to P than its point of ersection with ~. (See the &#38;ppendix for a more formal discussion of how this 
relation is calculated.)This relation is modeled by a (directed} graph G which we will refer to as a 
"priority graph". If this graph is acyclic then one can define a function f:R --> Z + satisfying the 
"visibility" conditions described above. Se differ slightly from Schumacker's approach in that we shall 
re guire f to be one-to-one. This variation does not restrict the generality of the method, but will 
be useful in the subsequent development. ~e borrow a term used in the context of a partial order and 
will refer to such a function as a consistent enumeratio_n of {R,<) (see, e.g., Preparata and Yeh {1973)). 
(This is also sometimes called a ~ sorting; see, e.s. , Knuth [1973~) ~et then ~ = {I: l,r2,..,r 
hI" be the set of (convex) polygons to be considered. This set may be first considered as describing 
a single object, or possibly later the entire scene of objects. Schumacker e~t a ! attempted construction 
of a function f:R --> Z+,Z  = {1,2...}, hav~ng the prop~erty that if both ~ and We give two examples 
of objects (for simplicity in 2-space), one object whose associated graph is acyclic and has a consistent 
enumeration (figure 4) and one whose graph contains a cycle and thus does not have a consistent enumeration 
(figure 5) - 176 rj% r f(r) 1 I  object with polygon identifiers 2 ' 2 3 6 4 7 5 8 6 3 7 5 
 8 9 9 1 4 I consistent priority graph enumeration  Figure q: An object which admits consistent enumeration. 
 If the graph was not acyclic Schumacker manually attempted to split the object into several Fieces, 
with each of which an acyclic graph could be associated. The difficult7 with this approach was that no 
general Eethod was found to split up co~plicated objects, and thus ~any of the more interesting cases 
could not be handled without manual intervention. @e propose a two-stage approach for solving this problem: 
 I. Extraction of as much viewpoint - independent visibility information as possible from an object's 
visibility priority graph. (This involves analysis of the graph and isolation of "difficult" subgraphs.) 
 2. ~urther analysis of these remaining difficult subgraphs with the intent of either a. assigning a 
~ore complex visibility code than a partial ordering, or r 9 object with polygon identifiers priority 
graph  Figure 5: An object which does ~_~ admit consistent enumeration. b. automatically splitting 
some of the object polygons to simplify these difficult subgraphs.  The first stage involves isolating 
the ,,difficult", cyclic subgraphs in our priority graph. To do this we partition the priority graph 
into s_~/.q/Lqlv .qP.~g.~f~ ~S~2S~S~-(&#38; subset of vertices of a graph spans a strongly connected 
component if and only if it is a maximal subset of vertices such that any vertex in the subset is reachable 
from any other vertex in %his subset. See, e.g. Berge (1973).) let UI,U2,...,Um be the (pairw!se disjoint) 
subsets of vertices spanning the strongly connected components of the priority graph G. (Each U i is 
a set of polygors.) We define a new "partial priority" graph G' whose vertices are ...,Um, and there 
is an arc to frOmvert~cesU,  ~l'if and only if there are two In G, r a 6 U i and r h Uj, such that 
there is an arc in G from r a to r b. ~here are well-known efficient methods for calculating the graph 
G' from the original graph G.~See, e.g., ~ho, Bopcroft 8 UllKan 177 (1974).) ~s G' is acyclzc there 
exists a consistent enumeration f: {UI,U2,...,Um} - -> Z +. This consistent en~eration of Ui's can be 
extended to a Dart~ enumeration of R by defin~g a fanction h:R --> Z + where h(r} = f(U~) for r ~ U 
4. We present G', for the previous unworkable case (figure 5) if figure 6ao This graph G', as any "partial 
priority" graph, is always acyclic and thus admits consistent enumeration (figure 6b}. (r)  a) b) Figure 
consistfigure 6: Pent 5). artial enume priority ration graph (compare and its with Thus we have assigned 
some enumeration h:R --> Z + whose meaning is as follows: For any vies, if r and r_ are both "front facing" 
and areapiercedDby a ray from the viewing position, then if h{ra} < h[rb) then r a is visible and may 
obscure r along this ray. (Note that the meaning ~f h(ra} = h(rh} for r a # r b is different here from 
the one in SchumackerSs approach. In our case h{ra} = h r b meams that it is not possible {tb } decide 
relative visibility of r and r. using h only, and some a~ditional  calculations will be necessary.} 
 This completes the first stage of our solution. We note that even if the analysis process is stopped 
here that substantial reduction in the number of visibility calculations is likel~. To illustrate this, 
let us consider the "innermost" level of a visible surface algorithm --that of visibility calculation 
for one pixel. There may be several polygons potentially visible. Let then S ~ {Sl,.,.,Sa} ~ R be the 
set of polygons potentially visible at this pixel. {A polygon s I is "potentially visible" if and only 
if it covers the pixel but is not necessarily the nearest one to the viewing position.) Let ~ = min{h[si) 
li= ! .... ,~ and let = {siJh(si} = h}. To find the polygon visible at this pixel it is sufficient to 
consider ~ the ele~nts of ~. If [~[ << ISJ = q then the visible polygon can he determined efficientl~. 
(In particular, if |S[ = I then there is a single polygon with highest priority and no further visibility 
processing is needed.} Discussion and Extensions He are currently i~plementing the above-described 
solution and are studying the feasibility of still more powerful technigues. Clearly the actual implementation 
will answer some significant questions --~st inportantly the percentage of pixels in images for w~ich 
ISI = I, the percentage for which |SJ << JS[, and the distribution of these pixels throughout the i~age 
and the distribution among ~any "si .~lar- images. Several additional enhancements may reduce still 
further the numbers of calculations needed to generate each ~age. Let us consider, for instance, the 
situation in which one polygon A obscures only a part of another polygon B (figure 7a). E could be split 
along the plane of A into two polygons (say, B 1 and B2) such that A can n~o3 obscure ~ [figure 7h). 
Conversely, if the plane of B splits A (figure 7c) then ~ can he split into tso pieces such that only 
one piece potentially obscures B (figure 7d). Thus in some cases strongly connected components can he 
entirely broken up by this Eethod (figure 8a ~und 8h). Still more efficiencies may be arrayed by generalizing 
the original goal of a priori visibility calculations. Until now we have discussed only techniques whose 
results are valid for all possible viewing positions P and all possible viewing rays r. A mere generous 
view of visibility priority requirements my be useful as so~e derived information may only be valid within 
some limited scope. Some possible scopes of visibility priority information: I. All P's and all r's: 
This is the most useful information, one to which the above discussion has so far been lib/ted. 2. Some 
P's and all r's: This may be information whose validity is limited to certain regions in 178 A  2 
 Q  a) a) b) A A 1 A 2 t  S S <D  c) d)  Figure 7: Splitting polygons. the 3-space environment; 
we may wish to utilize such information by subdividing the environment space and making modifications 
in the priority ordering whenever P crosses from one subspace to another.  3. One particular P and all 
r's: This may correspond to information valid for all the images generated from one particular viewing 
position. When the viewing position is moved, such information would have to be modified {b~ ,perhaps, 
altering parts of the priorit~ graph.) One particular P and one particular r: ~his is information valid 
only for certain pixels within~certain image. In this situation, the useful ness of our general "a priori~ 
approach will depend on the specific number of calculations remaining to this stage, as compared with 
the number of calculations needed by the standard distance com[u rations used in most visible surface 
algorithms. A h)  Figure 8: a) Original polygons and strongly connected component graph, b) Split 
polygons and resulting (acyclic) priority graph. (Other scopes, of course, may also prove useful.) 
Cne approach we are currently develc~ing for this last situation is to assign more sophisticated enumerations 
to the elements of strongly connected components. Let us consider, for instance, the simple strongly 
connected components of figure 9a, consisting of a ring of four vertices. The lack of arcs between nodes 
A and C and between nodes B and D i~plies that one node {polygon) in each pair can never obscure the 
other An the pair, from an x point in space. {That is, there is no relation between A and C and between 
~ and E.) ~his implies that at any given pigel in the image, at most one (but not both) of the pair AC 
and one of the pair BD may he potentially visible. Thus all the pixels which have more than one potentially 
visible polygons belong to one of four classes: A 8 B {potentially visible), E ~ C, C ~ D, D 6 k. In 
all the cases the priority assignment is easy to determine. The various cases are summarized in figure 
9h. Left yet to be resolved are strongly connected components with more complex structure than a simple 
cycle. For these situations it may be possible to show that for certain (most?) geometric 179 a) Potentially 
Visible Highest Priority at a Pixel: (i.e., visible) A B C D Y Y N N  N Y Y N N N  Y Y N N Y b) 
 Figure 9: a) Strongly connected component. b) The only possible conflicting cases. configurat~ns there 
is no point P with viewing ray r which can pierce all polygons of any complete subgraph. Should this 
prove to be the case, then a calculation deterni~ng which polygon(s) are ~ potentially visible at a pike1 
(by backfacing or not falling onto the pixel) will be sufficient to det~ermine the priority of the renaining 
potentially visible ones. These and ether techniques are currently being investigated. ~termininq the 
Priozitv Graph We assume for the following discussion that each polygon in our set a. is oriented, 
in that it has two faces: a front face and a back face, b. does not interpenetrate another polygon, c. 
is convex. Consider now that the plane in which a polygon lies naturally divides the rest of the three-di~ensional 
space ~to two half-spaces associated with the two sides of the polygon: the front half-space, a~d the 
back half-syace, for a polygon r they will be denoted by FHS(r} ~d BHS(E), respectively. We now wish 
to analyze the following situation: Bet there he two non- intersecting oriented polygons r and r I in 
the space. Under ~hich clrcu~stances can we say that from some viewing position ~ (partially) obstructs 
r2? We shall denote such "potential" obstruction of ~ by writing r I < ~- It is easy to see that r obstructs 
 fro~ a viewing position ~ along the ray ~ if and cnly if the follow~g conditions are satisfied: I. 
P lies in PHS(r I) ~ EHS(~), and 2. A point travelling from P along a. travels fur some distance in 
a region of the space which is in both PHS(r I } and FHS(~ ) until it ,,pierces" ~ then --  b. travels 
in a region which is in BHS (rl) and in FHS(~ } until it plerces ~ , then  c. travels in a region which 
is   in both BBS(rl) and BHS(r2). This informal discussion leads to %he following characterization: 
 L_~e~: r I < r 2 if and only if I. r I n FHS(r 2} # ~, and 2. r 2 n BHS(rl) # ~- (Here r and r^~ are 
treated as planar Iregion~ in the three- dimensional space.)  ~r~G~: Is not presented here. It is a 
straightforward formalization of the previous discussion, m It is worthwhile to examine the situation 
deeper. The two planes on which the pclygcns r I and r2 lie divide the rest of the space into four "cones". 
(We are excluding here, for simplicity, the case where the two planes are parallel.) These four cones 
are simply: FHS(r I ) ~ ~HS(re ), FI~S(r 1 ) h BHS(r 2 )  B~S(r I) n ~s(r e) BHS(r 1 ) h BHS(r 2 ). 
 We can now .tate: r I < r 2 <=> both r I and r 2 have non-empty intersections with the boundary of BHS(E 
I) 6~ YBS(r2)- For a polygon r we shall denote by CONVEX(r) the smallest subset of the vertices of r 
that spans the {convex) hull of r. We can now state a computationally 180 attractive condition for (potential) 
obstruction: h2_hss~e~:r I ~ r 2 if and only if there exist Pl CONVEZ(rl) and P2 6 CONVEX(r2) such that 
P1 ~ FHS(r2) and P2 e BHS(rl)- 2~: From the above it follows that r I < r~ if and only if there exist 
 inslde or on the boundary of rl, and P2 inside or on the ~oundary of r 2 such that P1 ~ FHS(r2) and 
P2 ~ BHS(rl)" let now ~ E FHS(r~). Intersect [I with a ~ime in t~e plane of rl; this line must cross 
the boumdary of the enclosing convex hull defined hy CONVEX(rl) in exactly two places; call these points 
QI and Q2" Since P1 lies between Q1 and Q2" one easily see~ that either Q( ~ FHS(E2) or Q2  ~HS(r2)" 
 Wathou% loss of generality, assume QI E FBS(r2). Ol lies between tic points in CONVEX (r2) ; call these 
Pi and P4" Si~ila fly since QI e FHS(~) either P (FHS(~) ok ~ ~ )US (~). T~us there exists so~e ~ E 
CONVEX (r I ) such that P~ ~ EHS |r 2 ). The treatme_nt of  1 ~s analag~uso n Me can thus easily check 
whether r I < r 2 using O(CONVEX(rl)  CONVEX(r2} ) operataons. In the case where %he polygons are defined 
in terms of a list of vertices one has an O{#(r I)  #(r~)) algorithm, where #(r) demotes the num&#38;#169;er 
of points in the vertex-list defining r. (Simply examine all the vertices of a polygon r without limiting 
consideration to CCNVEX(r) only.) With the additional observation that the distance between the vertices 
of r I (respectively r2) and the plane defined by r 2 {respectively r I) is bi~odal, an O(log(#Crl) + 
#(~)) algorithm can he designed; it is probably not worthwhile to do so as #(rl) + #(~) is rather small 
 (Simply examine all the vertices of a polygon r without limiting consideration to CCNVEX|r) only.) 
Aho, A.V., Hopcroft# JoE. 8 Ull~an, J.Do {1974) ~ s~ an__~d ~nalysis of o ~ , Addison-Wesle~  Berge, 
C. |1973) ~ add Hype=qravhs , North Holland  Knuth, D.B. (1973) ~he Art of Co~9$er F_K.q.q~gm~ng:~ 
Y?l~e ~i/Fundamental Algol, (Second Edition), Addison- Wesley  Preparata, FoP. 8 Yeh, R.T. (1973) Addison-Wesley 
 Schumacker, R.A., Brand, R., Gilliland, M 8 Sharp, W. (1969) " Study for Applying Computer-Generated 
Xmages to Visual Simulation", AFHR-TR-69-14, U.S. Air Porce Human Besources laboratory  Sutherland, 
.I.E., Sproull, R.F. 8 Schu~acker, ~.A. (1974) "A Characterization of Ten Hidden-Surface Algorithms", 
~ u_~ ~om u~, (1):1-55 --end -- 181 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807442</article_id>
		<sort_key>182</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[ISOSRF&#8212;an algorithm for plotting Iso-valued surfaces of a function of three variables]]></title>
		<page_from>182</page_from>
		<page_to>189</page_to>
		<doi_number>10.1145/800249.807442</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807442</url>
		<abstract>
			<par><![CDATA[<p>Given a three-dimensional array containing values of a function of three variables, the algorithm presented here draws an approximation of the surface or surfaces where the function attains a specified value. This is done by contouring two-dimensional subsets of the three-dimensional array and suppressing the invisible parts of the contours. The union of all the contour line parts approximates the desired surface. The suppression of the invisible lines is the most complicated part of the algorithm and is done by forming a silhouette of the processed subset of the array and testing lines against this structure.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Contouring]]></kw>
			<kw><![CDATA[Hidden line problem]]></kw>
			<kw><![CDATA[Visible surface algorithm]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Data terminals and printers</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010594</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Printers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31100890</person_id>
				<author_profile_id><![CDATA[81450594467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISSCO, 4186 Sorrento Valley Blvd., San Diego, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331503</person_id>
				<author_profile_id><![CDATA[81100411529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Humbrecht]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The National Center for Atomspheric Research, PO Box 3000, Boulder, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360971</ref_obj_id>
				<ref_obj_pid>360924</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cline, A., "Scalar and planar-valued curve fitting using splines under tension." Comm ACM, 17, 4 (April 1974) pp 218-223.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321453</ref_obj_id>
				<ref_obj_pid>321450</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kubert, B., Szabo, J., and Giulieri, S., "The perspective representation of functions of two variables." Jnl ACM, 15,2 (April 1968) pp 193-204.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Loutrel, p., "A solution to the hidden-line problem for computer drawn polyhedra." IEEE Trans Comp, C-19, 3 (March 1970) pp 205-213.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ricci, A., "A constructive geometry for computer graphics." Comp Jnl, 16,2 (May 1973) pp 157-160.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Schweikert, D., "An interpolation curve using a spline in tension." Jnl Math and physics, 45, 3 (September 1966) pp 312-317.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Warnock, J., "A hidden-line algorithm for halftone picture representation." Dept. Comp. Sci., Univ. Utah, Tech. Rep. 4-5, May 1968.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>905548</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Watkins, G., "A real-time visible surface algorithm." Ph.D. dissertation, Dept. Comp. Sci., Univ. Utah, June 1970.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>361264</ref_obj_id>
				<ref_obj_pid>361254</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Williamson, H., "Hidden-line plotting program." Comm ACM, 15, 2 (February 1972) pp 100-103.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "A two-space solution to the hidden line problem for plotting functions of two variables." IEEE Trans Comp, C-22, 1 (January 1973) pp 28-33.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "A one pass hidden line remover for computer drawn three-space objects." Proc 1972 Summer Simulation Conference, pp 261-267.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360892</ref_obj_id>
				<ref_obj_pid>360860</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "Visible surface plotting program." Comm ACM, 17, 3 (March 1972) pp 152-155.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ISOSRF --An Algorithm for Plotting Iso-Valued Surfaces of a Function of Three Variables by Thomas Wright, 
ISSCO*, San D~ego, California and John Humbrecht, NCAR**, Boulder, Colorado ABSTRACT INTRODUCTION Given 
a three-dimensional array con- taining values of a function of three variables, the algorithm presented 
here draws an approximation of the surface or surfaces where the function attains a specified value. 
This is done by con- touring two-dimensional subsets of the three-dimensional array and suppressing the 
invisible parts of the contours. The union of all the contour line parts ap- proximates the desired surface. 
The sup- pression of the invisible lines is the most complicated part of the algorithm and is done by 
forming a silhouette of the processed subset of the array and testing lines against this structure. 
Keywords and phrases: hidden line prob- lem, visible surface algorithm, contour- ing. CR catagories: 
8.2, 4.41 *Author's current address: ISSCO, 4186 Sorrento Valley Blvd., San Diego, Cali- fornia, 92121. 
This research was carried out while the author was at NCAR. **The National Center for Atomspheric Re- 
search (NCAR), PO Box 3000, Boulder, Co- lorado, 80303, is sponsored by the Na- tional Science Foundation. 
 various scientific problems suggest the need for an algorithm that can dis- play a constant-valued surface 
of a func- tion of three variables. Such a surface is the three-dimensional analogy of a contour line, 
which displays a constant-valued curve of a function of two variables. Thus, we might say the algorithm 
described here draws an approx- imation of a contour surface of a func- tion of three variables. It 
could be used for displaying the "wave function", to show where electrons spend most of their time 
about a particular nucleus, or the displaying of the surface of a cloud produced by a thunderstorm 
simulation. By drawing an isothermal contour surface, this algorithm can display the three-dimensional 
shape of phenomena such as the gulf stream or cold air volumes near the vents in a room. Figure I, 
for example, shows the cloud of carbon-dioxide produce d by the simulation of a Space Shuttle ignition. 
 Other well-known hidden-line algor- ithms are either incapable of producing the desired type of picture 
for this problem [2, 8, 9] or would require so much preprocessing of the data as to make the use of 
these algorithms extremely ex- pensive [3 ,6 ,7 and others using this type of database]. Two other 
algorithms [4, 10, (also described in ii)] operate directly on this type of database. Ricci's algorithm 
is a very elegant ma- thematical approach to the problem; it works correctly but at the present stage 
 of development is too slow to be used for practical problems. The previous algor- ithm by this author 
requires a high reso- lution representation of the function (eg., 80 x 80 x 80 which is often expen- 
 sive to create and store) and draws very unsmooth lines that some viewers find oh" jectionable. The 
new algorithm presented here represents a revision of that old algorithm to allow lower resolution 
input arrays (eg., 20 x 20 x 20) and produce more pleasing contours from a bigger &#38;#169; 1979 
ACM O-89791-004--4/79/0800--182 $00.75 See Copyright Pg. 182 class of eye positions. The arrays need 
not be integer valued as was the case in [ii]. These changes required that the method for suppressing 
the invisible lines be replaced by a more sophisticated algorithm. OVERVIEW OF THE ALGORITHM The function 
of three variables t=f(u,v,w) is approximated in the com- puter as a three-hyphened dimensional array, 
T, which is NU x NV x NW. For some given t, say t(0), the desired sur- face or surfaces, S, is defined 
by all (u,v,w) such that t(0)=f(u,v,w) . Theoretically, a point in S is visible if a straight line from 
the point to the eye position, E=(ue,ve,we) , contains no other points in S, that is, no other parts 
of S obscure the point in position. To sim- plify the computation of visibility on the computer and to 
define what is to be done at the boundaries of T, in addition to specifying t(0), a flag is defined in- 
dicating whether values greater than t(0) or values less than t(0) are considered to be inside the surface. 
 In the following presentation of the algorithM, we assume that the eye posi- tion his large positive 
coordinates and that NU=NV=NW=N; the values of t larger than t(0) are inside the surface. i. The procedure 
is given a real array, T, which is N x N x N, and a value, TO. The picture produced approximates the 
sur- face or surfaces where the func- tion approximated by T is equal to T0. In addition, the follow- 
 ing work spaces are used: SLAB which is N+2 x N+2, SCREEN1 which is M x M bits, SCREEN2 of the same 
size, and CURVES which is 2 x L. A suitable resolution for the screen model has been found to be 128 
x 128. Contours are stored in CURVE, which can hold L points. Refer to Figure 2, which displays the 
operations involved for one step in a typi- cal exection of the algorithm. 2. Initialize by setting 
all the bits in SCREEN2 to 0.  3. We will do the lines with integ- ral u values first. For the eye positions 
in question the side of T where I=N is closer to the observer than I=l. For I=N to 1 by -I, do the following 
steps 4 through 7.  4. Set all the bits in SCREEN1 to  0. 5. Put a slice of T into SLAB by setting 
SLAB(J+I,K+I) to T(I,J,K) for J=I,...,N and K=I,...,N. Set the edges of SLAB to minus infinity  (SLAB(I,K) 
and SLAB(N+2,K) for K=I,...,N+2 and SLAB(J,1) and SLAB(J,N+2) for J=I,...,N+2 are set to a very large 
negative number).  6. Set CURVES to the result of SMO- OTHing the T0-valued CONTOURs of SLAB. DRAW the 
VISIBLE parts of the CURVES. Use CONTOUR STORING to enter CURVES into SCREEN1. Set SCREEN1 to FILLIN 
of the CURVES. These operations are  described in more detail in the later sections of the paper.  
7. Set SCREEN2 to SCREEN20Red with SCREEN1 for each bit. (As stat- ed in step 3, I is now incre- mented 
and steps 4 through 7 are repeated until I is zero.)  8. The lines of integral v and w are done in the 
same manner.  CONTOUR(ARRAY,VALUE) constructs the VALUE contour of the two-dimensional array ARRAY. 
 SMOOTH densifies a line by ad- ding points using (in this im- plementation) splines under ten- sion. 
 VISIBLE(LINES) constructs a sub- set of LINES which are visible by testing SCREEN2. If a bit is set 
in SCREEN2 at the position corresponding to a given line segment, that segment is invisi- ble because 
it is within the silhouette of those parts previ- ously processed. CONTOUR STORING(LINES, STORED LINES) 
constructs a set of shad- ing flags, STORED LINES, from LINES which are stored in SCREEN1 to be used 
by FILLIN. FILLIN(STORED LINES) constructs a silhouette from a set of STORED LINES. The following can 
be determined from the algorithm: i. Fdr large values of N the algor- ithm' s timing is 0 (N*N*N) +N* 
(timing of FILLIN) . When the resolution of the screen model is fixed, this be- comes 0(N*N*N) . 2. 
Because of the boundary of minus 183 infinity added around each SLAB, all contour lines found by CON- 
TOUR are closed. 3. After the contour lines are gen- erated, a third coordinate, u=I, must be included 
before the po- ints in the curves are translat- ed from three-space to two-space, tested for visibili- 
ty, and plotted.  4. Values for L and M must be suit- ably chosen.  IMPLEMENTATION The methods used 
in CONTOUR are standard contouring techniques for data stored in two dimensional arrays. Data values 
are known at the intersections of orthogonal grid lines. In this case, be- cause we want to smooth the 
lines, a point on a contour line is found, and then the entire line is constructed by generating the 
segments in order until the line is closed. (Other methods exist that generate contour lines in a piece- 
meal fashion.) The contour lines are densifled by adding points in between the points along the contour 
line in such a way as to el- iminate the sharp corners that can occur at the grid lines. This is done 
by using splines under tension [i, 5], a method that can produce a smooth curve passing through the input 
points. Much experi- mentation at NCAR has shown that this is an excellent way to smooth contour lines; 
proper setting of the tension fac- tor prevents the smoothed lines from crossing while keeping a smooth 
appear- ance. The implementation of CONTOUR STOR- ING, FILLIN, and VISIBLE are described in the next 
sections. The three-space to two-space transformation is due to Ku- bert, et al.[2] and therefore is 
not dis- cussed here except to note that points are projected onto a picture plane per- pendicular to 
the line of sight. VISIBILITY COMPUTATIONS The following is a description of the overall method for 
solving the visi- bility problem for this type of data structure (see also [i0]). We will con- sider 
only lines of integralu, the other types of lines being done similarly and independently. Consider an 
eye position which has ue<<u(1)<u(nu) . All lines drawn in the u=u(1) plane will be visible since, with 
respect to the viewer, the entire three-dimensional array is on the far side of this plane. We wish to 
draw the edge of the intersection of the vo- lume of critical values with the plane u=u(1). The edge 
of this intersection is a set of contour lines; the interior is that which hides other lines from view, 
The projection of the interior onto the picture plane is the area where, for this eye position, lines 
should not be drawn for any u>u(1). The projection of the contour lines onto the picture plane con- stitutes 
the edge of that area. Thus, if the contours of T(l,j,k) are translated onto the picture plane and a 
representa- tion of their interiors is recorded, ex- amination of this record will show which lines are 
hidden for u=u(2). Similarly, the union of the interiors for u=u(1) and u=u(2) shows which lines are 
hidden for u=u(3). In general, the ordering of the processing of the cuts is adjusted in ac- cordance 
with the eye positiml. Two models of the picture plane are used to store the representation of areas 
on the screen where lines should not be drawn. Both are orthogonal grids of the same resolution; 128 
by 128 bits has been found to be satisfactory for most practi- cal problems. (Higher resolutions will 
not greatly increase picture quality be- cause the inaccuracies caused by solving independently for the 
lines in each di- rection are greater than those caused by the coarseness of the model. Examples of these 
inaccuracies can be seen in Figure 1 along the lower edge of the plume for the curves in the planes parallel 
to the Space Shuttle's wings.) The first model is u~sed to store a representation of the contour lines 
for a given two-dimensional slice of the data. Plotter coordinates for points along the curves are mapped 
onto the model, and a bit is set to one in the model at the lo- cation corresponding to ce=tain coordi- 
nates (a discussion of the specific plotter coordinates set is ~resented in the CONTOUR STORING section). 
Parameters in the densifying and smoothing routines are selected to force the model's bit pattern representing 
a curve to be con- tinuous for those subsets of the curves that are stored. After all the contour lines 
for one slab have been drawn, a filling-in process is used to form the required solid area. This will 
be des- cribed in the next section. The second model is used to store the accumulated information from 
all the slabs processed by the algorithm thus far. As the filling-in process is per- formed on the first 
model, the result is ORed into the second model. The first model is then filled with zeros and is ready 
to store the contours for the next slab. The visibility of each point to be plotted is determined by 
testing the sec-  184 I00.0 km CUBE CENTERED AT 400.0 km ALTITUDE TIME AFTER RELEASE: 10.2 sec COz 
CONCENTRATION AT SURFACE: 4.9[7] cm -~ F,~ i:Sin=~ s,m.ATm, (P~. ~m, ~m~ ~i~s,~) ond model. If the model 
contains a one at the locations corresponding to the coordinate being tested, the point is in- visible. 
 FILLING Filling consists of scanning across each row of SCREEN1 and setting bits in SCREEN2 corresponding 
to the interiors of the contours found in SCREEN1. Bits set in SCREEN1 represent on/off flags. At the 
start of each row scan, the shading flag is clear. The first bit, set in SCREEN1' while scanning, sets 
the shading flag. The next bit set clears the flag. This process is repeated across the en- tire row. 
While the shading flag is set the corresponding bits in SCREEN2 are set. The contour storing routine, 
dis- cussed in the next section, is not exact and occassionaly an on/off flag pair may be incomplete. 
This condition produces a runaway effect where the bits in the screen model are set to the opposite of 
the desired value. This is signaled by the shading flag being set at the end of a row scan. At no other 
time can the shading flag be set when a row scan has been completed. This is assured because ISOSRF prevents 
contour lines from reach- ing the border of the screen model. When a runaway is detected (which happens 
less than 1% of the time), the SCREEN2 rows above and below are logical- ly ORed together and entered 
in place of the anomalous row. The error correction is quick and effective. In the examples processed 
it gave accurate results. CONTOUR STORING For the filling routine to work, on/off flags must be properly 
set in SCREEN1. The contour storing requires information regarding the interior and exterior of each 
contour while it is being drawn. All nonhorizontal line seg- ments are entered into SCREEN1 with bits 
representing the entire line segment being set. Certain conditions may exist at a later time that may 
cause a llne segment to be erased. This topic will be discussed later in this section The filling process 
performs a hori- zontal scan and therefore, to preserve on/off flag integrity, horizontal llne segments, 
HLS, must be entered in SCREEN1 differently than all other line segments. Both screens assume an x,y 
coordi- nate system with x being horizontal change and y vertical change. The origin is in the upper 
left hand ~orner with x increasing to the right and y increasing  185 .,Ill m ,  illI " lllliililliiilli,,,, 
Iilllllll . ~h ~l, .I, ~t, .1, .I. 1/~t, .I, ~1~ ~1..i..I.d. A: SC~E]~(2 AT THE START OF THIS STEP B: 
T~ CONtoURS FOR ~IS i, "~ i, fJ el o i i m ] ,' I"' ' I ,"'l e m Jo e' ~o j lie, Ij I, sI Ij C: 
VISIBLE PARTS OF THE ~ ADDED TO THE PICTURE D: ~ FOR THE SET OF ool, rrouRs "" ,jllrlj! pdJlllrllJ, 
' E: THE UI:5~I'ED VERS]QN OF S~E]~ F: TIlE OB, JECT WITH ALL THREE TYPEs OF LINES F~e.~z 2: STEPS zs 
THE ~smrn.u 186 downward. In the discussion below, assume a solid is being drawn with positive values 
representing the solid and negative va- lues representing empty space. Our im- plementation of ISOSRF 
will handle the reversing of the values representing sol- ids and space. These variables are con- trolled 
by user-set parameters. Basically the contour will be traced keeping the solid always to the right. 
With this fact in mind determination of the interior and exterior of the contour can be made at coordinate 
entry time. This knowledge is only required for cer- tain HLS conditions. An HLS is interpreted as two 
or more successive points with no y change. Two HLS classes are distinguished: horizontal turning points 
and horizontal steps. A horizontal turning point is defined by HLS with different entering and exiting 
y-directions. This class has two subc- lasses. In the first subclass, the turn- ing point forms a concave 
surface with respect to the contour. No points on the HLS are entered into SCREEN1. Below is an example 
of a concave surface entry into SCREEN1. Assumme the dashed lines form the contour area not under consider- 
ation now. The asterisk string repre- sents the plotter points. The one and zero string shows how the 
asterisk string would be stored in SCREEN1. ~iii!iiiii!iiiiiiiiiiiii!i!iiiiiii~ [iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii] 
 [::::::~:~:~:~!:i:i:ili~ 0 0 0 0 :<.,.. ........ -:*:*:* ~e:*:~ 1 1 1 1 I i PLOTTER POINTS SCREEN1 
 The second subclass, horizontal turning points, forms convex surfaces. Only the endpoints of the HLS 
are set in SCREEN1. In the example below assume the same character conventions as before. *:iiii!iii~ 
1 1 **** i 0 01 PLOTTER POINTS SCREEN1 D To decide which subclass of horizon- tal turning points has 
been found, a count of all turning points succeeding a reset event is kept. Odd numbered turn- ing points 
are convex surfaces and even numbered ones are concave surfaces. A reset event is a change in x-direction 
or a vertical turning point, to be discussed later. When a reset event is detected the count is set 
to zero. The second HLS class is the horizon- tal step. It is detected by entering and exiting y-directions 
that are the same. Only enter the outermost endpoint in this class (this condition requires interior/exterior 
computation). In the example below assume the contour is being drawn from the bottom toward the top. 
The interior will be to the right side of the line. #r. -:<.l<': i <. -.....-.. :.:.:<-:....- *ji!ii~!iii 
1 ~ * *. ~.*** .~:i:i:!:i$i 10 0 0 0 0 0 &#38;i i i ~ ~ i i ! i{iiii:!:i:i i { i i { PLOTTER POINTS 
SCREEN1 Vertical turning points are not e'n- tered into SCREEN1. They are defined as a single point 
where the entering and ex- iting y-directions are different. At times, the coarseness of the screen 
model will cause two parts of the same line to be projected into the same place in SCREEN1. A redraw 
indicates that there is no interior area to the contour in this case. No filling is re- quired so no 
on/off flags should be set. So, the contour storing algorithm recog- nizes a redrawing situation and 
erases the bits from the screen model. The contour storing routine imple- mented at NCAR produced approximantly 
0.2% errors (incorrect on/off flag pairs in each row scanned) for the examples processed. All errors 
occurred while at- tempting to plot intersections in con- tours which projected into 2-space figure 8 
shapes; however, not all such contours caused errors. These errors were cor- rectly repaired by the filling 
routine. CONCLUSION An algorithm was presented for draw- ing an approximation of the iso-valued surfaces 
of a three-dimensional array of real numbers. This algorithm has been used to help display the output 
from var- ious three-dimensional simulations at NCAR. Figure 3 shows a volume of high potential vorticity 
and its coupling with surface pressures. 187 12 HOLR PREDICTION FROM 73031317.ZDATA FmURE 3: WEATHER 
SIMLILATION (RAINER BI_ECK, UNIVERSITY OF MIAMI) The algorithm is practical for these types of problems. 
Processing of a typi- cal 30 by 30 by 20 array took less than one second of central processor time on 
NCAR's Control Data 7600 computer using a FORTRAN implementation of the algorithm. The time was divided 
up for a typical ex- ample as follows: 1% executive routine 3% 3 to 2-space transformations 33% contouring 
 11% smoothing 29% checking vivibility and drawing 23% filling in screen models A portable FORTRAN 
implementation of the algorithm is available to the public without charge. (Contact Software Dis- tribution, 
NCAR, P.O. Box 3000, Boulder, Colorado 80307.) REFERENCES i. Cline, A., "Scalar and planar-valued curve 
fitting using splines under tension." Comm ACM, 17, 4 (April 1974) pp 218-223. 2. Kubert, B., Szabo, 
J., and Giul- ieri, S., "The perspective re- presentation of functions of two variables." ~nl ACM, 15,2 
(April 1968) pp 193-204.  3. Loutrel, p., "A solution to the hidden-line problem for computer drawn 
polyhedra." IEEE Trans Comb, C-19, 3 (March 1970) pp 205-213.  4. Ricci, A., "A constructive geo- metry 
for computer graphics." ComP Jnl, 16,2 (May 1973) pp 157-160.  5. Schweikert, D., "An interpola- tion 
curve using a spline in tension." Jnl Math and physics, 45, 3 (September 1966) pp 312-317.  6. Warnock, 
J., "A hidden-line al- gorithm for halftone picture re- presentation." Dept. Comp. Sci., Univ. Utah, 
Tech. Rep. 4-5, May 1968.  188 7. Watkins, G., "A real-time visi- ble surface algorithm." Ph.D. dissertation, 
Dept. Comp. Sci., Univ. Utah, June 1970.  8. Williamson, H., "Hidden-line plotting program." omm ACM, 
15, 2 (February 1972) pp 100-103.  9. Wright, T., "A two-space solu- tion to the hidden line problem 
for plotting functions of two variables." IEEE Trans Comp, C-22, 1 (January 1973) pp 28-33.  i0. ..... 
, "A one pass hidden line remover for computer drawn three-space objects." Proc 1972 Summer Simulation 
Conference, pp 261-267. ii. ....., "Visible surface plotting program." omm ACM, 17, 3 (March 1972) 
pp 152-155.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807443</article_id>
		<sort_key>190</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Computer drafting of stones, wood, plant and ground materials]]></title>
		<page_from>190</page_from>
		<page_to>198</page_to>
		<doi_number>10.1145/800249.807443</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807443</url>
		<abstract>
			<par><![CDATA[<p>Architectural presentation drawings frequently require the drafting of stones, wood patterns, plants and ground materials, which, contrary to the majority of drafting tasks, cannot rely on repetitious procedures. This paper discusses and illustrates computer implemented algorithms which generate graphic representations of the above materials.</p> <p>Simulating a process known to be applied in practice is certainly a sound approach, and one such algorithm, applicable for the derivation of stone walls, is presented, But the majority of the algorithms discussed are based on a technique which introduces randomly generated disturbances on initially regular patterns. The latter algorithms in particular have produced highly satisfactory graphic representations, which include frequently hand-made qualities.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Architectural drafting]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Ground representations]]></kw>
			<kw><![CDATA[Intelligent drafting]]></kw>
			<kw><![CDATA[Plant representations]]></kw>
			<kw><![CDATA[Stone walls and pavements]]></kw>
			<kw><![CDATA[Wood patterns]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P46432</person_id>
				<author_profile_id><![CDATA[81100311091]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Yessios]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Architecture, The Ohio State University,   Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Eastman, Charles M.: Use of computers instead of drawings in building design, in the Journal of the American Institute of Architects, April 1975.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Eastman, C.M. and Yessios, C.I.: An efficient algorithm for finding the union, intersection and differences of spatial domains, Research Report No. 31, Institute of Physical Planning, Carnegie-Mellon University, 1973.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[George, Janges (Ed.): SIGGRAPH '77 Proceedings, San Jose, Cal., July, 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>270146</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Knuth, Donald E.: The Art of Computer Programming (Vol. 2/Seminumerical Algorithms), Addison-Wesley Publishing Company, 1969.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Negroponte, Nicholas: New qualities of Computer interactions, in Proceedings of IEEE International Conference on Cybernetics and Society, Tokyo and Kyoto, Japan, November 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Phillips, Richard L. (Ed.): SIGGRAPH '78 Proceedings, Atlanta, GA, August 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[White, Edward T.: A Graphic Vocabulary for Architectural Presentation, University of Arizona, Tucson, Arizona, 1972.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Yessios, Chris I.: Formal languages for site planning, in Spatial Synthesis in Computer-Aided Building Design, C.M. Eastman (Ed.), Applied Science Publishers, 1975.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 COMPUTER DRAFTING OF STONES, WOOD, PLANT AND GROUND MATERIALS Chris I. Yessios Department of Architecture 
The Ohio State University Columbus, Ohio 43210 ABSTRACT Architectural presentation drawings frequently 
require the drafting of stones, wood patterns, plants and ground materials, which, contrary to the majority 
of drafting tasks, cannot rely on repetitious procedures. This paper discusses and illustrates computer 
implemented algorithms which generate graphic representations of the above materials. Simulating a process 
known to be applied in prac-tice is certainly a sound approach, and one such algorithm, applicable for 
the derivation of stone walls, is presented, But the majority of the algorithms discussed are based on 
a technique which introduces randomly generated disturbances on initially regular patterns. The latter 
al-gorithms in particular have produced highly sat-~Sfactory graphic representations, which include frequently 
hand-made qualities. KEY WORDS AND PHRASES: architectural drafting, intelligent drafting, computer graphics, 
stone walls and pavements, wood patterns, plant repre-sentations, ground representations. CR CLASSIFICATION: 
3.29, 3.49, 3.69, 8.1, 8.2. INTRODUCTION From the point of view of architectural design, computer graphic 
techniques have already proven efficient when applied to repetitious tasks. We have also seen a variety 
of drafting systems doing a satisfactory job with working drawings~ Yet they remain short of gaining 
the architec- tural profession. There is a variety of reasons, some of them relating to cost-effectiveness 
con-siderations. But a major complaint has been that whatever is drafted by the computer looks too mechanical, 
and, therefore, too "dry", when compared to the quality of the lines drawn by a "good" human hand. This 
does not seem to be much of a problem with working and construction drawings, which, by definition, ought 
to have a highly technical appearance. But when it comes to presentational drawings, where the aesthetic 
quality of the drawing itself is traditionally taken to hint the quality of the final product, drawings 
done by the computer are missing the "warmth" of the hand-made. On the other hand, we have recently seen 
truly spectacular developments in such computer graphics areas as animation, color and even 3-D texture 
[3,6]. These techniques will undoubtedly be util- ized by the architectural profession, at some fu- ture 
date. As suggested, they will certainly re-quire some change in attitudes and work-patterns [I, 5). But 
before we reach such a date, the architectural profession is still looking for com-puter systems which 
would satisfy their conven-tional but current needs. One such need is the tedious task of two dimensional, 
black and white (hence cheaply reproduceable) drafting. It is believed that any computer drafting system 
which would satisfactorily accomplish the task will find its way into architectural practice, at no time. 
There is, of course, a major requirement. This is the quality of the computer lines and how do they compare 
with those drawn by hand. This paper deals with some of the "drafting" pro-blems of architectural design; 
namely, stone walls and pavements, wood grain, plant and ground mater- ials. Algorithms generating and 
drawing represen- tations of the above materials, are discussed and examples of graphic outputs are presented. 
While the whole range of distinct drafting tasks is not exhaustively covered, those dealt with are possibly 
the most common and typical. But most important, the sequence of experiments presented here, aimed at 
developing a technique of general applicability. This technique is first discussed in the next sec-tion. 
THE APPROACH: RANDOMLY DISTURBED REGULAR PATTERNS The first algorithms developed for some of the drafting 
tasks presented in this paper were based on the assumption that at least some degree of machine intelligence 
is required. That is, the overall process was based on a tree-like sequence of decision making which 
depended on both local and global relational conditions and constraints. The global conditions were known 
from the begin- ning and remained more or less constant throughout the execution of the task. The local 
conditions could not be known in advance. They depended on the output of a previous step and they varied 
throughout the process. Thus the overall approach was based on heuristic searches and locally ap-plied 
adjusting rules. From the few such algo- rithms which were actually developed, the best &#38;#169;1979 
ACM O-89791-004--4/79/0800--190 $00.75 See Copyright Pg. 190 example is possibly the stone-by-stone algo-rithm, 
which is outlined in the next section. These algorithms tend to be complex, relatively slow, and not 
always stable. But the most im- portant disadvantage is that they have to be specialized towards a particular 
drafting/design task. Contrary to the initial heuristic approach which was essentially based on a simulation 
of the step-by-step process encountered in practice, the approach ultimately pursued aims at simulating 
the results and not necessarily a known practiced procedure. It is based on a technique of random disturbances. 
That is, a regularly laid out pattern is derived first and is next disturbed by randomly moving its points 
left or right and up or down. Such a sequence of disturbances, when applied to what may initially look 
like a regularly laid out brick-wall, changes it to a stone wall. Or, by applying the proper distur- 
bances to a set of concentric circles, wood pat- terns can be derived. This technique has been found 
to derive excellent graphic representations which frequently include hand-made qualities. But its main 
advantage is that a single algorithm can derive numerous variations, by simply re- gulating the extent 
of the disturbances. A decisive part of the latter algorithms is the random numbe [ 9enerator, which 
determines a variety of structural details, as well as the degree of disturbances. The one used is based 
on the linear congruential formula Xn+ 1 = (aXn+C) mod m where, the "magic numbers '~ X, a, c and m are 
as- signed values in accordance with D.E. Knuth's advice [4]. STONE WALLS AND PAVEMENTS Stones vary, 
depending on the type of rock they come from. They also vary in size and by the ways they are treated. 
They may be cut with power tools at a plant, they may be manually carved at the construction site, or 
they may be left completely uncut. Stones cut at a plant may be given exact rectangular dimensions, in 
which case they are no different from bricks or concrete blocks. Consequently, they do not concern this 
paper. Stones which come in rectangular shapes but with arbitrary dimensions, as well as stones which 
are of arbitrarily irregular shapes, cannot be constructed in a straight forward manner and are the focus 
of this presentation. Typically, loads of stones are delivered at the construction site. The mason picks 
one or a few at a time and positions them in the wall under construction. In building a stone wall the 
mason follows an overall pattern and/or style. He also has to make local decisions, referring to the 
positioning of each individual stone. The over- all pattern is determined by the way the differ" ent 
sizes of stones are to be mixed, by whether the stones are to be cut or not, by the amount of mortar, 
and by such rules of good practice as the interruption of vertical mortar joints. As the building of 
a stone wall proceeds, the position to be taken by the next stone may impose no par- ticular restrictions. 
In such a case the mason simply picks the stone closest to him, or he may look for a relatively large 
stone. Whatever the case, the stone is picked after a minimal search. But a certain position on the wall 
may require a stone within a limited range of dimen- sions and/or shapes. In such a case, the mason has 
to search the pile of stones more extensively. In practice, such searches are never exhaustive. They 
are limited, instead, to a portion of the stones on the surface of the pile. How extensive the search 
is, depends upon the overall pattern guidelines, which really means the construction costs projected 
(or allowable) for the particular wall. Restricted positions can be fitted in any one of three ways: 
(1) the search persists until a stone which fits is found; (2) a stone with shape and dimensions close 
to those required (but a bit larger) is picked and is then carved to fit the restricted position; (3) 
a number of smaller stones are picked and combined to fit the posi- tion. The first of the above alternatives 
results in better and more expensive walls, while the last leads to the least quality and cost. Commonly, 
in practice, a combination of the three methods is pursued, with none carried to an extreme. Independently 
of the building procedure followed, what counts at the end is the result. That is whether or not the 
wall produced is both struc- turally sound and aesthetically pleasing. For the computer to generate a 
"good" wall, it first appears logical that one would have to develop a model simulating the process known 
to derive good results. But work in the general area of computer implemented problem solving has also 
demonstrated that good solutions can also be de- rived by taking advantage of certain manipula- tive 
capabilities of the computer which lend themselves to techniques distinct from those practiced by humans. 
Finally, methods which com- bine both of the above are frequently most ap- propriate. The three stone 
wall building algorithms, pre- sented in this section, correspond roughly to the above distinctions. 
The first algorithm is essentially simulating the stone building process known to be pursued by either 
masons, when they construct a wall, or by designers, when they draft representations of walls. It has 
been labeled the stone-by-stone algorithm, indicat- ing that it constructs a wall by dealing with one 
stone at a time. The second algorithm makes no attempt to simulate any known construction process. Instead, 
it aims at deriving a graphic output which is a good representation of a stone wall. It has been labeled 
the joint-by-joint algorithm because the lines it manipulates cor-respond to the joints of the wall. 
While each of the above'algorithms derives excellent results for relatively simple shapes of walls, more 
com- plex walls, such as those which include windows, arcs or non-vertical edges, can best be con- structed 
by a combination of the two. Conse-quently, a third combined algorithm, labeled the stone-and-joint algorithm, 
has also been devel- oped. The latter has been found to be the most appropriate for stone pavements, 
too. 191 !  r Imm FIT-IF Figure l L | ~ -4 , I _,, r l- ,-FT c ~', ,--ff-I Q b Figure Figure 3 
The stone-by-stone algorithm, ~vhich is illustrated in Figures l and 2, constructs one row at a time. 
These rows are of three types: (1) the first or initial row, (2) the middle row, and (3) the top or closing 
row. The first row is the easiest to derive as all positions, except the last, are totally unre- stricted. 
The stones are randomly generated and laid out left to right as they come. For the last stone, a search 
(a random number generator) derives a few candidate stones, from which the one closest to the required 
dimensions is re-tained. If these dimensions are not close enough, the stone is cut. Each of the middle 
rows is built on top of the previous, from left to right. For each next position, a stone is randomly 
gen- erated. It may or may not fit in the position. If it does (case (a) in Figure l), it is laid on 
the wall. The stone does not fit when it goes beyond a concave (case (b) in Figure l), or a convex edge 
(case (c) in Figure l~-. In the lat- ter cases, the stone is retained and laid after the respective position 
on the wall is first prepared to accept it. The position is prepared by first picking and laying stones 
which fit in the position or are made to fit through some cutting. The top row is constructed essentially 
as the middle rows with the additional restric- tion that the height of the stones should not go beyond 
the top line of the wall. With a few differences in the test procedures, the basic stone-by-stone process 
applies equally well to walls built by rectangular (Figure 2) as well as irregular stones (Figure 3). 
No-tice that the stones are initially constructed without mortar joints, which are introduced by a second 
pass. After the basic structure of a well is derived and the individual stones are positioned, straight 
lines or even clear cut angles can be either "disturbed" or "rounded". That is, randomly generated devia- 
tions from the straight line can be introduced, and the points of angles can be randomly broken. Such 
disturbances can certainly be programmed to imitate the surface characteristics of the stones which depend 
on the type of rock they come from. The joint-by-joint algorithm is illustrated in Figure 4. A first 
step generates straight hori- zontal joint lines. Their vertical distances are determined randomly from 
within a predefined range (Figure 4a). Secondly, the algorithm de- rives the vertical joints. Their horizontal 
distances are again randomly generated from with- in a predefined range. This step of the algo- rithm 
also checks for the proper mixture of the joints and makes sure that continuous vertical lines are avoided. 
It then introduces the first set of disturbances to the junction points (points where the vertical joints 
meet the hori- zontal). These are moved left or right. Both the direction and the magnitude of the distur- 
bances are randomly determined (Figure 4b). A third step of the algorithm introduces distur- bances which 
move the junction points up or down. This completes the structure of the stone wall. (Figure4c). A final 
pass delineates the stones and introduces mortar joints of slightly var-iable widths (Figure 4d). By 
regulating the degree and extent of the dis- turbances, variable types of walls can be de- rived. This 
is illustrated by the distinct types of walls shown in Figure 5, which were derived by the same code, 
after changing the values of only a few parameters. These particular examples 192 a b d Figure 4 explore 
structural variations for the edges of the wall. From the practical point of view, case 5b is possibly 
the most useful, as it takes spe- cial care of the stones at the vertical edges, which are structurally 
the most sensitive parts of a wall. As with the stone-by-stone algorithm, further manipulation of the 
disturbances can lead to the definition of distinct "styles" and to the imitation of surface characteristics 
of variable types of rock. The stone-and-joint algorithm, which is a com- bined version of the previous 
two, is illustrated in Figure 6. Examples of stone wall elevations derived by the algorithm are shown 
in Figure 7, and examples of stone pavements in Figure 8o The stone-and-joint algorithm reflects the 
fact that certain features of a stone wall necessi- tate special treatment due to their particular structural 
requirements. These are the vertical edges of the wall, and the perimeters of such openings as windows, 
doors and arcs. The algo- Figure 5 rithm accepts as input the perimeter of a wall (Figure 6a) which 
is drawn by the user on a tablet or through a graphic cursor. It then ap- plies stone-by-stone procedures 
and constructs those parts of the wall which require special treatment (Figure 6b). In doing so, it also 
de- rives the perimeter of those parts (Figure 6c), which it consequently "subtracts" from the ori- ginal 
shape of the wall (Figure 6d). The latter operation is executed by an union-intersection- difference 
of shapes deriving algorithm, a discussion of which can be found in [2]. Having derived the portion of 
the wall which re- quires no special treatment, the algorithm pro- ceeds and builds it up by applying 
a joing-by- joint procedure (Fibure 6e). Finally, the por- tions built by steps b and e are combined 
to derive the complete wall. The version of the algorithm which derives stone pavements is iden-tical, 
except that it applies different struc- tural rules in constructing the edge portions of the pavement, 
and it generates more "round" shapes for the irregular stones. Figure 6 193 Figure 7 Figure 8 194 WOOD 
Architectural drawings frequently require repre- sentation of objects which are made of wood. Contrary 
to the patterns of the stone walls and pavements, which are hand-made, wood grains are generated by the 
natural process of plant growing. Consequently, designers have no control of the resulting patterns, 
except for the way in which a tree trunk is cut. Wood grains, of course, vary from one tree to another, 
and the type of wood to be used in a particular project is fre-quently selected on the basis of the desired 
grain pattern. The latteris primarily true in furniture designs, where it is usually required that the 
construction drawings indicate the dir- ection and combination of the wood patterns. But for the majority 
of the architectural drawings, it suffices to show some type of grain which will distinguish wood from 
other materials. The algo- rithm discussed in this section draws what may be called an average type of 
a wood grain. No attempts have yet been made to draw special types of wood. But, as previously discussed, 
properly regulated disturbances lead to distinct styles and types of patterns. Consequently, representa- 
tions of special types of wood can be accom- plished. The wood-grain deriving algorithm is again based 
on the technique of introducing disturbances to a regular shape, in this case an ellipse. The pro- cess 
is illustrated in Figure 9. The ellipse used is actually a stretched circle, which is initially derived 
through a set of rotations of variable angles. These angles are randomly gen- erated from within a pre-specified 
range. When the initial ellipse is sequentially scaled, a pattern of concentric ellipses, which constitutes 
the basic structure of the wood grain, is derived (Figure 9a). If the initial ellipse is first disturbed 
and then scaled, a graphic pattern which looks like wood grain is derived (Figure 9b). The points of 
the basic ellipse are dis- turbed in the X and/or Y directions. Relatively small disturbances are introduced 
to all points. A few randomly selected points are disturbed at higher rates. The basic ellipse, after 
it has been properly disturbed, constitutes the tree Figure 9 195 i I a 61 a2 a3 ,,,,,,-. . b Figure 
I0  knot around which the wood grain evolves. The scaling factors which derive the grain around the 
initial knot are also randomly generated. The factor for one of the directions is always higher than 
the other. For example, if the wood grain is positioned with its length towards the Y direction, the 
Y factor should be larger than the X. To derive a more realistic representation of wood grain, the initial 
knot and consequently the whole grain pattern are slightly tilted left or right (Figure 9c). Further, 
given the perimeter of a plank, the basic knot is randomly positioned inside or outside that perimeter 
and the algorithm sequentially scales it and retains only those portions of the grain which lie within 
the plank perimeter (Figure 9d). This completes the basic wood pattern where wood grain is represented 
by single lines. These lines can further be re- placed by line strokes, leading to the represen- tation 
shown in Figure 9e. The single line representation is more realistic for some types of wood, while the 
stroke repre- sentation for others. But the distinction is also one of scale, the first being suitable 
for small drawings, while the second for more detailed representations. Complete sets of wood grain re-presentations 
are shown in Figures lO and II. For both types of representations, the density of the grain can be regulated, 
by regulating the magnitude of the scaling factors. For an example, compare al, a2 and a3 in Figure lO. 
For the stroke representation the grain density can fur- ther be manipulated by regulating the density 
and the length of the strokes. For an example compare al with a2 in Figure II. ,I', al A al I Figure 
12 ~ B b ~'~ O ~ D  Figure II Figure 1 ~ 196 fact the codes which generate A and B are almost identical.. 
They differ in the way points are PLANT AND GROUND MATERIALS Using the same basic technique of disturbing 
more or less regular patterns a variety of graphic representations for plant and ground materials can 
be derived. Some examples are shown in the Figures of this section. Those readers who are not familiar 
with architectural drawings should be warned that no attempt has been made to derive "naturalistic" pictures 
of trees and ground. The aim has been to imitate the drawing conven- tions as executed by hand on architectural 
and landscape designs. Examples of such conventions can be found in architectural Journals and in drawing 
manuals such as [7]. The criteria used in evaluating the results have been the degree of "imperfection" 
achieved and whether the drawings can fool somebody as having been done by hand. The principle of progressively 
increased dis- turbances is well illustrated by the type A representations in Figure 12. They have all 
been derived by the same code, each after changing the values of a few parameters. They are all fine 
plant representations, yet each designer can choose to use one or the other, depending on his/her personal 
style or tastes. Additional types of plant representations are shown in Figure 13. Type B is based on 
the same initial pattern with type A (Figure 12), which is a set of concentric circles. As a matter of 
connected and by the density of the intervals at which those points are generated. Most involved are 
the basic patterns generated for types C and D, which are literally "tree" structures. Applying a different 
set of disturbances in each case, either type C or type D can be derived. In all cases, the input required 
by the user is the type of the plant representation, the length of its diameter, and the location of 
its center. All other details, such as number and length of branches, angles of deviation, number of 
concentric circles, etc., are determined by the random number generator, each from within a pre-specified 
range. Samples of graphic representations for ground are shown in Figure 14. What appears to be a variety 
of six different representations are actually derived by only two distinct algorithms. Representations 
a, b, c, and d are derived on the basis of a pattern which consists of a set of parallel lines. Tracing 
these lines, and introducing random disturbances at random in- tervals produces the shown representations, 
where, say, a and c differ by the way the points are connected and by the magnitude of the disturbances. 
Representations e and f are derived on the basis of a grid pattern and they again differ by the way of 
the connections and by the magnitude of the disturbances.  lem je _ INN1 -N  Figure 14 197  Figure 
CONCLUDING REMARKS In spite of recent spectacular advancements in such areas of computer graphics as 
color, 3-D texture and animation, the architectural pro-fession is still looking for computer aids capable 
of accommodating its basic and current needs. One area where architects would happily allow the computer 
to do the work for them is black and white drafting; working as well as presentation drawings. While 
a variety of drafting systems are currently in use and are proving quite successful with working drawings, 
they remain short of satisfying the qualitative requirements of the presentation drawings. The ultimate 
goal of the experimental work pre- sented in this paper has been the development of a site design oriented 
drafting system capable of producing drawings at a level of graphic quality comparable with that achieved 
by a "good" human hand. A partial version of such a system has very recently been implemented and early 
examples of its output are shown in Figure 15. Its level of graphic quality is already satis- factory. 
As a colleague put it, it drafts as well as a junior architecture student. A variety of extensions and 
improvements are cur- rently at the planning stage which will hopefully raise its capabilities to a graduate 
level. The system requires as input the perimeter of the spatial domains, which the user sketches on 
a tab- let. An indication of which pattern should be derived in what domain is also required. The user 
may also call the union-intersection- difference algorithm to operate upon the ori- ginal shapes of the 
domains. For the plants the user needs to enter its position and in- formation about its type and size. 
The system has currently no ambitions for automated design, but this is certainly a long range goal which 
would make it an extension of SIPLAN, an earlier site planning oriented system developed by the author. 
[8]. All algonithms discussed in this paper have been I0 written in Fortran IV. They run interactively 
on an AMDAHL 470V/6 Computer through a Tektronix 4014 Graphics Terminal. All the illustrations were derived 
through an on-line Tektronix Hard Copy Unit. REFERENCES [I] Eastman, Charles M.: Use of computers in- 
stead of drawings in building design, in the Journal of the American Institute of Architects, April 1975. 
[2] Eastman, C.M. and Yessios, C.l.: An effi- cient algorithm for finding the union~ intersection and 
"differences of spatial domains L Research Report No. 31, Institute of Physical Planning, Carnegie-Mellon 
University, 1973. [3] George, Janges (Ed.): SIGGRAPH '77 Proceed- ings, San Jose, Cal., July, 1977. [4] 
Knuth, Donald E.: The Art of Computer Programming (Vol. 2/Seminumerical Algorithms), Addison-Wesley Publishing 
Company, 1969. [5] Negroponte, Nicholas: New qualities of Computer interactions, in Proceedings of IEEE 
International Conference on Cybernetics and Society, Tokyo and Kyoto, Japan, November 1978. [6] Phillips, 
Richard L. (Ed.): SIGGRAPH '78 Proceedings, Atlanta, GA, August 1978. [7] White, Edward T.: A Graphic 
Vocabulary for Architectural Presentation, University of Arizona, Tucson, Arizona, 1972. C8] Yessios, 
Chris I.: Formal languages for site planning, in Spatial Synthesis in Computer-Aided Buildinq Design, 
C.M. Eastman (Ed.), Applied Science Publishers, 1975. 198  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807444</article_id>
		<sort_key>199</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Automatic extraction of Irregular Network digital terrain models]]></title>
		<page_from>199</page_from>
		<page_to>207</page_to>
		<doi_number>10.1145/800249.807444</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807444</url>
		<abstract>
			<par><![CDATA[<p>For representation of terrain, an efficient alternative to dense grids is the Triangulated Irregular Network (TIN), which represents a surface as a set of non-overlapping contiguous triangular facets, of irregular size and shape. The source of digital terrain data is increasingly dense raster models produced by automated orthophoto machines or by direct sensors such as synthetic aperture radar. A method is described for automatically extracting a TIN model from dense raster data. An initial approximation is constructed by automatically triangulating a set of feature points derived from the raster model. The method works by local incremental refinement of this model by the addition of new points until a uniform approximation of specified tolerance is obtained. Empirical results show that substantial savings in storage can be obtained.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3-d surfaces]]></kw>
			<kw><![CDATA[Cartography]]></kw>
			<kw><![CDATA[Computational geometry]]></kw>
			<kw><![CDATA[Data structures]]></kw>
			<kw><![CDATA[Digital terrain models]]></kw>
			<kw><![CDATA[Mapping]]></kw>
			<kw><![CDATA[Representation conversion]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor>Distributed/network graphics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.1</cat_node>
				<descriptor>Cartography</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10010479</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Cartography</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14032359</person_id>
				<author_profile_id><![CDATA[81100062192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Fowler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Geography, Simon Fraser University, Burnaby, B.C., Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42053715</person_id>
				<author_profile_id><![CDATA[81100061479]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Little]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Geography, Simon Fraser University, Burnaby, B.C., Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bauhuber, F., Erlacher, V. and Gunther, P. A programming system for the manipulation of digital terrain models (in German). Organ der Deutschen Gesellschaft fur Photogrammetrie 43, (1975), 104-107.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Delaunay, B. "Sur la sphere vide", Bulletin of the Academy of Sciences of USSR, VII, Classe. Sci. Mat. Nat. (1934), 793-800.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Douglas, D.H. and Peucker T.K. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. Canadian Cartographer 10, 2 (December 1973), 112-122.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Duda, R.O. and Hart, P.E. Pattern Classification and Scene Analysis, New York, (1973).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fowler, R.J. Approaches to multi-dimensional searching, in Dutton, Geoffrey (Ed.), Harvard Papers on Geographic Information Systems 6, Addison-Wesley, Reading, Ma., 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fowler, R.J. DELTRI: An efficient program for producing Delaunay triangulations. Technical Report 18, ONR Contract N00014-75-c-0886, Dept. of Geography, Simon Fraser University, Burnaby, B.C., Canada, 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gates, W.E. and Associates, Inc. A land-based modelling system for water quality management studies, Report for Virginia Electric and Power, 1974.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563887</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gold, C.M., Charters, T.D. and Ramsden, J. Automated contour mapping using triangular element data structures and an interpolant over each irregular triangular domain. Proceedings of SIGGRAPH '77, San Jose, California (1977), 170-175.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mark, D.M. Computer analysis of topography: a comparison of terrain storage methods. Geografiska Annaler 57, (1975), 179-188.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Peucker, T.K. and Douglas, D.H. Detection of surface-specific points by local parallel processing of discrete terrain elevation data. Computer Graphics and Image Processing 4, (1975), 375-387.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Peucker, T.K., Fowler, R.J., Little, J.J. and Mark, D.M. Digital representation of three-dimensional surfaces by triangulated irregular networks (TIN). Technical Report 10, ONR Contract #N00014-75-C-0886, Dept. Geography, Simon Fraser University, Burnaby, B.C., Canada, 1977.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Peucker, T.K., Fowler, R.J. and Little, J.J. The triangulated irregular network. Proceedings of the ASP-ACSM Symposium on DTM's. St. Louis, Missouri, October 1978.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pike, R.J. and Rozema, W.J. Spectral analysis of landforms. Annals of the Association of American Geographers 65, 4 (1975), 449-516.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Proceedings of ASP-ACSM Symposium on DTM's. St. Louis, Missouri, May 1978.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Ramer, U. An iterative procedure for the polygonal approximation of planar curves. Computer Graphics and Image Processing 1, 3 (Nov. 1972).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Rogers, C. Packing and Covering. Cambridge University Press, Cambridge, 1964.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Shamos, M.I. and Hoey, D. Geometric intersection problems. Proc. 17th Annual IEEE Symposium on the Foundations of Computer Science, (October 1976), 208-215.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Warntz, W. The topology of a socio-economic terrain and spatial flows. Regional Science Association Papers 17, (1966) 47-61.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Automatic Extraction of Irregular Network Digital Terrain Models Robert J. Fowler and James J. Little 
Department of Geography Simon Fraser University Burnaby, B.C., Canada AB STRACT For representation 
of terrain, an efficient alternative to dense grids is the Triangulated Irregular Network (TIN), which 
represents a surface as a set of non-overlapping contiguous triangular facets, of irregular size and 
shape. The source of digital terrain data is increasingly dense raster models produced by automated orthophoto 
machines or by direct sensors such as synthetic aperture radar. A method is described for automatically 
extracting a TIN model from dense raster data. A~ initial approximation is constructed by automatically 
triangulating a set of feature points derived from the raster model. The method works by local incremental 
refinement of this model by the addition of new points on til a uniform approximation of specified tolerance 
is obtained. Empirical results show that substantial savings in storage can be obtained. KEY WORDS AND 
PHRASES: cartography, computational geometry, data structures, digital terrain models, mapping, representation 
conversion, 3-d surfaces. CR CATEGORIES: 3.14, 3.23, 3.63, 5.13 INTRODUCT ION If we partition the 
work of computer graphics into three phases, data input and construction of graphic databases, transformation 
of the database, and output of pictures and images, we find that a large portion of the research in the 
field is , in general, focussed on the latter two phases. In automated cartography, the first phase, 
data input, occupies a large part of the time and interest of the developers of graphic systems, and 
has been automated with varying success. This paper describes an automatic method for the construction 
of a graphical database for the representation of terrain surfaces. The input data are in the form of 
a digitized image which contains height information over the extent of a given region. The result of 
the construction process is a terrain model which may be used both for analysis in engineering and planning, 
as in route-flnding, and for cartographic purposes, such as prgductlon of contour maps end block diagrams. 
 DIGITAL TERRAIN MODELS For the purposes of this paper a Digital Terrain Model (DTM) is defined to be 
a computer data structure which represents the shape of some region of planetary surface. (An overview 
of the state of the art of Digital Terrain Models can be found in (14)). Applications of these models 
arise in resource management, civil engineering and military operations. The most common form of DTM 
is the regular grid. In this approach a coordinate system (e.g. latitude and longitude or tmiversal transverse 
Mercator grid) is chosen, and the terrain is sampled at a uniform rate in both of the coordinates. The 
result is a series of samples at regular intervals, which is easily represented /n a computer by a two-dlmensional 
array. Two considerations motivate the development of an alternate concept of a DTM. First, topographic 
surfaces are non-statlonary (13), i.e., the roughness of the terrain is not periodic but changes from 
one landtype to another. A regular grid therefore must be adjusted to the roughest terrain in the model 
and must be highly redundant in smooth terrain. It is apparent that, if one is to model these non-statlonary 
surfaces accurately and efficiently, one must use a method which adapts to this variation. Second, different 
uses of terrain models demand different representations. For computations such as intervisibility (determining 
whether ~n observer at a given point on the surface c~n see another point on the surface), certain features 
of the surface (ridges, peaks, landmarks) have special importance and symbolic significance. It is desirable 
to use a representation which is suited to the phenomenon under study and is not imposed by a sampling 
regime. Because the structure of topographic surfaces is not regular, the representations of these surfaces 
need not be regular. In the conceptualization which m~derlies the TIN model, terrain is seen to be characterized 
by a set of "surface-speciflc" points and lines. "Surface-speciflc" means that the selection of these 
elements is governed by the detail of the surface rather than by external considerations. These sample 
points are irregularly distributed about the surface, adapting to the roughness of the terrain. The inclusion 
of these points in the 1979 ACM O-89791-004--4/79/0800--199 $00.75 See Copyright Pg. 199 model guarantees 
its "structural fidelity". The capability of the model to represent the terrain surface within a certain 
error tolerance we call "statistical fidelity" To these considerations, we have added the further constraint 
that the resulting system be computationally efficient. In particular, it should be possible to reconstruct 
the neighborhood of a sample point without searching the database. Unlike a regular grid which provides 
an implicit neighborhood through the mechanism of array indexing, an irregular point system must include 
 the neighborhood explicitly. THE TRIANGULATED IRREGULAR NETWORK The resulting model is the triangulated 
irregular network (TIN). The surface is modelled as a set of contiguous non-overlapping triangles whose 
vertices are located adaptively on the surface. (For a more complete discussion see(12)). Within each 
of the triangular regions, planar ~nterpolation is used to estimate the surface. Several other systems 
have bean implemented using a similar triangular surface tesselation (1,8,7). Figure 1 shows a triangular 
network, while figures 2 and 3 depict the contour map and block diagram for that model. The tiling of 
the surface in these irregularly shaped triangles can be modelled as a planar graph; by duality, we can 
represent this either as the triangular facets and their adjacency relation (using about 12N pointers 
where N is the number of vertices), or as the network of vertices end edges of the facets (using about 
6N pointers). This latter form was chosen because of its storage advantages. The vertex adjacency matrix 
is sparse and can be stored as a llst structure; the triangular regions are implied by the adjacency 
relationships of the vertices. The structure of a terrain surface can he characterized by a set of surface-specific 
points, the peaks, pits and passes, and a set of lines, the ridges and channels, which connect them. 
The sample points in the TIN are chosen so that these features are contained as subgraphs of the model. 
These features can be thought of as the backbone of the surface. Peaks, pits and passes form the major 
portion of the set of surface-specific points. Peaks are points that are relative maxima, i.e., higher 
than all neighbors. Pits, likewise, are relative minima. Passes are saddle points on the surface. There 
are two alternate definitions of ridges and channels. Warntz (18) defined a ridge as a line on the surface 
that connects two adjacent peaks, following a path at the highest altitude. Similarly, he defined channels 
as lines connecting adjacent pits along paths of lowest altitude. Passes are the points at which ridge 
and channel lines intersect. These ridges and chennels connect the peaks end pits into a network in which 
ridges bound watersheds, and channels bound hills. While they connect into a network, they do not necessarily 
follow significant relief features in all areas. Ridges and channels can also be defined as lines of 
divergent and convergent slope, respectively. These correspond well with intuitive notions of ridges 
and channels, ~m~cludlng spur ridges end tributary channels~ and should be represented with high accuracy 
for cartographic purposes. Besides these structural points end lines, further "support points" must 
be added to the triangulation in order to ensure that the statistical fidelity criterion is met, that 
is, that the heights at arbitrary points are modelled with an error within the tolerance. CONSTRUCTION 
OF IRREGULAR MODELS Until recently, the principal method of creating a TIN has been manual selection 
of the points and links which constitute the triangular network. The source of terrain data has most 
often been a topographic map. The sample points are selected by hand and then digitized; the edges in 
the network are specified by their endpoints. This method can be directly extended to use aerial stereo 
photography by employing a stereo plotter connected to an on-line minicomputer. The existence of efficient 
programs for the triangulation of an arbitrary set of points under a variety of optimality criteria (8,5,17) 
makes an approach based on manual point selection and automatic triangulation both attractive and quite 
feasible. More nodes must be recorded in order to ensure that structural components are properly connected. 
However, this cost is more than offset by the ease of creation and the speed of data entry. The increasing 
availability of terrain data in the form of dense raster DTM's produced by automated orthophoto machines 
or by direct sensors such as synthetic aperture radar has made it desirable to develop procedures to 
transform these data into the TIN format. The procedures described below are a response to this situation, 
and result from the merging of several independent processes, including: I) automatic detection of surface 
features 2) efficient automatic triangulation methods 3) procedures for comparison of a TIN with a 
 grid DTM and progressive refinement of the TIN. COMMENTS ON CONSTRUCTION The construction process 
transforms the input elevation grid into a triangulated irregular network in two phases. In the first, 
points of structural importance are selected from the grid model, and are connected into an initial triangulation. 
The second phase compares the triangulated model with the grid and introduces "support points" to reduce 
the maximum error below a specified tolerance. The division of the construction process into two phases 
is motivated by several considerations. In our approach, the structural points and their interconnections 
are a necessary part of the model . Their eventual inclusion during the refinement process cannot be 
 guaraneed, so they must be included at the outset. As a consequence, the approximation process is 
not allowed to eliminate existing points, since the structural points must be preserved. By triangulating 
the structural points into a first-approximation TIN, the search time is reduced for the comparison 
process, as the individual regions are relatively small in size. There is a further adventage in this 
as the extraction of all relative maxima and minima in the surface simplifies the character of the residual 
surface, thereby facilitating the use of a simplified and less expensive hill-climbing algorithm for 
identifying the points to add. SUBDIVIDING GRIDS Our procedures are designed to operate on very dense, 
very large grids, and these must be partitioned into manageable sections (in our examples, 128 x 128). 
Adjacent subregions share a row or column of the grid with their neighbors. To ensure that the adjoining 
regions will fit at their edges, all points included in these rows or columns in the final model are 
chosen when the grids are subdivided. These points are selected by a procedure for approximating a cartographic 
line. There have been many published solutions to the problems of filtering or generalizing (in the 
cartographic sense) polygonal lines by deleting the "non-significant" points along the curve (3,4,15). 
We say "problems" because different applications have conflicting requirements and therefore need different 
algorithms. ~n algorithm for generating or characterizing a boundary vector has the requirements that 
a) the extrema (maxima or minima) of the data must be represented and b) the results be a uniform approximation 
of the original data. The method used is an adaptation of a method suggested by J.F. O'Callaghan (personal 
communication) optimized for this problem domain. The rules for the selection of points are : a) The 
endpoints of the botmdary curve become part of the model. b) A local maximum or minimum is selected 
if its altitude differs from at least one of its adjacent extreme by at least the predefined tolerance 
for the model. c) Other points are added to the model to ensure that the approximation is within tolerance. 
 Informally, the method for implementing rule c works as follows. Referring to figure 4, A is a point 
which has been selected, and B is a point which has been provisionally selected. C A/// figure 4 
To add the next point to the model: I. Integrate the area of the region betwdeen the chord Joining B 
with successive points along the curve end the curve itself. Keep separate sums for the positive and 
negative contributions. 2. When the product of either sum (positive or negative) with the chord length 
exceeds twice the model tolerence, stop (at point X in the figure).  3. Provisionally select the point 
in the region BX which is farthest from the chord BX. This point is labelled C in the figure.  4. Construct 
the chord AC and permanently accept the local extrem,-, from the chord in the neighborhood of B (labelled 
B'). Note that B" is usually the same point as B. This adjustment locates B" at a local extremum of curvature. 
 5. Repeat steps I-4 starting the integration process at C.  Points which satisfy conditions a and 
b are automatically selected as soon as they are found. While not guaranteed to produce an optimal sampling, 
this process is fast, accessing each point along the curve at most three times. EXTRACTING SURFACE FEATURES 
FROM THE GRID The first phase of generating a TIN from a very dense raster DTM is the extraction of 
the skeleton of surface-specific points and lines. To derive these features, we use a local geometric 
operator, similar to many used in edge extraction in image processing, to identify possible points on 
ridge or channel lines (I0). For each point in the square grid, the heights of the three cells adjacent 
to it on the right and below are compared with the height of the central cell. If the cell is at grid 
location (l,J), the cells at (l,J+l),(l+l,J) and (l+l,J+l) are examined. The lowest and highest cells 
of the four are marked as not being ridge and channel candidates, respectively. Intuitively, these operators 
select, for ridges, the cell or cells to which water ~uld flow from the central cell. The insight is 
that cells which are not marked are potential ridge (or channel) candidates. This procedure is faster 
than checking all eight neighbors of a point, and does not omit potential ridges or channel points. It 
does leave fear possible candidates, which makes the next step more efficient. These potential surface-speciflc 
points lie on or around the ridges and channels; before they can be used, they must be connected into 
lines. The following "is a description of the ridge finding process; a similar procedure with the operators 
inverted is used to construct channels. The connection process starts at pass points and climbs to the 
neighboring ridge candidate at the highest altitude. Passes are foumd by examining all candidates and 
accepting as "passes" all those which are lower than all neighboring candldates. From these starting 
points, the neighboring candidate at the highest altitude is added to the growing ridge, continuing 
until the ridge terminates at a peak or joins an existing ridge. The strings of cells extracted in this 
manner form the ridges, and a similar procedure constructs the channels. The denseness of the sampling 
of the source DTM results in many redundant points along these lines. If these were all included, there 
would be little saving in the TIN. To yield a more simple characterization of the surface graph, a line 
approximating or generalizing procedure is used to drop those points within a small multiple of the model 
tolerance. The method used is an extension to three-dimenslons of REDUCE (3), an algorithm for generalizing 
cartographic lines. The set of points which are left after simplification include the peaks and pits 
, which are necessarily included as the endpoints of surface lines, and those points which are "significant" 
in the definition of the surface lines. These essentially lie at ridge or channel Junctions and at slgnifie~mt 
bends in the surface lines. Together with the points selected on the border, these form the input to 
the triangulation step. AUTOMATED TRIANGULATION In systems using triangular tesselations it is necessary 
to have a triangulation which is based upon a well-defined criterion and which is inexpensive. The Delaunay 
triangulation (2) is used in this system. This triangulation is defined in terms of another structure 
called the Voronol diagram, the graph whose edges are the boundaries of the Voronol polygons of the set 
of input points. A Voronoi polygon (16), also kno~ as the Thlessen polygon or the proximal polygon, of 
a point, p, in a set of points P, delimits that region in the plane which is closer to p than to any 
other point in P. The straight-line planar dual of the Voronoi diagram of a set of points is called the 
Delaunay triangulation of those points. In other words, the Delaunay triangulation is formed by linking 
each point to its Voronoi neighbors by straight line segments. The Delaunay triangulation has two related 
properties which make it attractive for our efforts (6). First, it is a "local" definition for triangulation. 
The insertion of a new point need only examine that region in the plane which is closer to the new point 
than any other point. Second, it is known that a given existing triangle is affected only if a new point 
is added within the circle circumscribed through its vertices. This prescribes a well-defined local search 
area for new points which can improve the fit of the terrain model to the region inside the triangle. 
 The algorithm for constructing this triangulation is built around a routine which can add a new point 
to an existing triangulation (5). This method is used rather than an asymptotically optimal divide-and-conquer 
algorithm (17) because of the need to be able to refine the digital terrain model incrementally. ADAPTIVE 
SELECTION OF SUPPORT POINTS Once the border points and structural points have been processed by the 
Delaanay triangulation program, there exists a triangulated network which can be thought of as a first 
approximation to the DTM. The next stage is to add to this model a set of support points in order to 
ensure the statistical fidelity of the model as well as to force the structural points to be interconnected 
with structurally significant edges. The support points are inserted by progressively adding points 
to the model antil it uniformly fits the original dense grid. The use of the uniform fitting criterion 
in conjunction with the Delaanay triangulation criterion has several beneficial implications : I. If 
a particular triangular facet fails to fit the data adequately then to correct that error an additional 
point must eventually be added. The Delaonay criterion localizes the position of potential points which 
could affect the fit to the circle circumscribed about that triangle. Rather than performing global searches 
for the global "worst-fit" points, it is sufficient to perform a series of domain-limited searches in 
each triangle of the model. 2. The addition of a new point destroys the original triangle and adds new 
triangles of which it is one vertex. If two support points need to be added within a triangle, the addition 
of the first one implies that the triangle no longer exists, and that the second point is within the 
interior of one of the newly created triangles. The order of the local searches is therefore sequenced 
by using an enumeration of the triangles in which the newly added triangles are added at the end of 
the enumeration. The triangle enumeration technique which we use fits this condition; triangles are ordered 
by the maximum vertex index. Since the last points added have the maximum indices, the triangles which 
adjoin these points are handled last. This process terminates when all triangles adjacent to the last 
point added have been searched. 202 For example, assume that it is necessary to include both points 
U and V (Fig. ha) to model the surface uniformly. Suppose that U is added to the model when the triangles 
incident to vertex I are examined (Fig. 5b). Because U has a higher index than I, no further examination 
of the triangles incident on both U and I is made at this time. V will be found later when the triangles 
around U are examined (Fig. 5c). The triangles incident on both U and V will be examined still later 
when the neighborhood of V is tested. l K figure 5a l K figure 5b I K figure 5c METHODS FOR LOCAL 
SEARCH TWo methods of local search can be used to locate the points to be added. The first is to perform 
an exhaustive search of all cells within a given region. This proceeds in two phases: first, examine 
the errors within the triangle. If the errors are within tolerance go to the next triangle, otherwise, 
examine the location of the maximum error. If it is in the interior of the triangle, then it is added. 
Otherwise, the worst-flt is on the boundary and the search region expands to the sector of the circumscribed 
circle adjacent to that portion of the boundary. Because the model at this stage contains the set of 
structurally significant points, the absolute residual error surface is in most cases reasonably well-behaved. 
We therefore customarily use a much faster steepest-ascent search of the residual error surface starting 
at the centroid of each triangle. The first phase of the search is again limited to the interior of the 
triangle. If the maximum error within the triangle is in the interior of the triangle and this error 
exceeds the tolerance then the corresponding point is added to the model. If the maximum is on the boundary 
and exceeds the tolerence, then the hill-climblng is allowed to proceed in a second phase within the 
extended domain of the circumscribed circle. The heuristic of hill-climbing is not guaranteed to find 
all the maximum errQr points. To test the fit of the model, a coherent scan-conversion program for the 
TIN models (II) is used to produce a grid model registered to the input DTM and the t~m grids are exhaustively 
compared. This produces an error histogram as well as a list of those locations at which the error tolerance 
has been exceeded. EMPIRICAL RESULTS The automatic TIN construction procedures have been tested on 
several regions selected from dense digital terrain models supplied by the USGS National Cartographic 
Information Center. These DTM's were produced by digitizing contours from the USGS 1/250000 series maps 
at a resolution of 0.01 inches. The contours ~re then interpolated yielding a grid-structured DTM with 
a sample spacing of 208.3 feet. The sample regions are all in Washington State; the two of lower relief 
are from the Nooksack Valley near Ballingham, and the last is from the foothills of Mount Baker. Each 
grid is 128 x 128 cells. A block diagram of the model with 2730 ft relief is sho~m in Fig. 6; the height 
of the terrain is exaggerated four times. Figure 7 shows a contour map for this region, with a 50 foot 
contour interval, made from the grid model. Figure 8 shows the corresponding contour map made from the 
TIN model of the region. In the table that follows, the number of points needed to reduce the maximum 
error to within tolerance is sho~n, together with the total relief variation, the average error, and 
the percent of the original points used. Tolerance Relief Average Number of Percent Zmax-Zmin Error 
Points of Input 50 2730 22.3 659 4.0 30 2730 9.0 1235 7.5 50 1243 4.1 335 2.0 30 1243 3- 8 358 2.1 I0 
1243 I. 7 539 3.2 50 419 5.1 119 0.7 30 419 4.6 122 0.7 I0 419 1.8 219 1.3 These results indicate that 
a substantial savings in numbers of points in the model ca~ be achieved by using a TIN created from a 
dense raster DTM. Based on the map accuracy for the 1:250000 series contour maps and the accuracy of 
 interpolation of grids from contours (II,9), the grid spacing of 208.33 ft cannot model terrain with 
less than 50 ft rms error. At this tolera%ce, the performance of the TIN models is very good; the models 
have been tested at lower tolerances to determine the sensitivity of the method to the magnitude of 
the tolerance. CONC LUS ION The results shown above indicate that the TIN construction procedures described 
here adequately capture the phenomanon of the surface in the model produced. The development of these 
procedures significantly expands the data sources for the TIN model and other such adaptive systems, 
and enhances their suitability as alternative models for terrain. ACKNOWLEDGEMENTS The authors would 
llke to thank Thomas K. Peucker, whose guidance and support were instrumental in in the development of 
the TIN system and the work described above. The research presented in this paper was supported by Contract 
N0017-75- C-0886 (NR 389-171), U.S. Office of Naval Research. REFERENCES I. Bauhuher, F., Erlacher, 
V. and Gunther, P. A programming system for the manipulation of digital terrain models (in German) Organ 
der Deutschen Gesellschaft fur Photogra~etrle 43, (1975), 104-107. 2. Delaunay, B. "Sur la sphere vide", 
Bulletin of the Academy of Sciences of USSR, Vll, Classe. Scl. Mat. Nat. (1934), 793-800.  3. Douglas, 
D.H. and Peucker T.K. Algorithms for the reduction of the number of points required to represent a digitized 
line or its caricature. Canadian Cartographer I0, 2 (December 1973), 112-122.  4. Doda, R.O. and Hart, 
P.E. Pattern Classification mld Scene Analysis, New York, (1973)  5. Fowler, R.J. Approaches to multl-dlmensional 
searching, in Dotton, Geoffrey (Ed.), Harvard Papers on Geographic Information Systems 6, Addison-Wesley, 
Reading, Ma., 1978.  6. Fowler, R.J. DELTRI: An efficient program for producing Delaunay triangulations. 
Tec~mlcal Report 18, ONR Contract #N00014-75-c-0886, Dept. of Geography, Simon Fraser University, Burnahy, 
B.C., Canada, 1977.  7. Gates, W.E. and Associates, Inc. A land-based modelling system for water quality 
management studies, Report for Virginia Electric and Power,  1974. 8. Gold, C.M., Charters, T.D. and 
Ramsden, J. Automated contour mapping using triangular element data structures and an interpolant over 
each irregular triangular domain. Proceedings of SIGGRAPH "77, San Jose, California (1977), 170-175. 
 9. Mark, D.M. Computer analysis of topography: a comparison of terrain storage methods. Geograflska 
~nnaler 57, (1975), 179-188.  I0. Peucker, T.K. and Douglas, D.H. Detection of surface-speclfic points 
by local parallel processing of discrete terrain elevation data. Computer Graphics and Image Processing 
4, (1975), 375-387. II. Peucker, T.K., Fowler, R.J., Little, J.J. and Mark, D.M. Digital representation 
of three-dlmenslonal surfaces by triangulated irregular networks (TIN). Technical Report 10, ONR Contract 
#N00014-75-C-0886, Dept. Geography, Simon Fraser University, Burnaby, B.C., Canada, 1977. 12. Peucker, 
T.K., Fowler, R.J. and Little, J.J. The triangulated irregular network. Proceedings of the ASP-ACSM Symposium 
on DTM's. St. Louis,Missouri, October 1978.  13. Pike, R.J. and Rozema, W.J. Spectral analysis of landforms. 
Annals of the Association of American Geographers 65, 4 (1975), 449-516.  14. Proceedings of ASP-ACSM 
Symposium on DTM's. St. Louis, Missouri, May 1978.  15. Ramer, U. A% iteratlve procedure for the polygonal 
approximation of planar curves. Computer Graphics and Image Processing I, 3 (Nov. 1972).  16. Rogers, 
C. Packing and Covering. Cambridge University Press, Cambridge, 1964.  17. Shamos, M.I. and Hoey, D. 
Geometric intersection problems. Proc. 17th Annual IEEE Symposium on the Foundations of Computer Science, 
(October 1976), 208-215.  18. Warntz, W. The topology of a socio-economic terrain and spatial flows. 
Regional Science Association Papers 17, (1966) 47-61.  204 figure 1 figure 2 205 figure 3 figure 
6 206 figure 7 figure 8 207 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807445</article_id>
		<sort_key>208</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Special session on large scale applications of computer charting and mapping in industry (Panel Session)]]></title>
		<page_from>208</page_from>
		<page_to>209</page_to>
		<doi_number>10.1145/800249.807445</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807445</url>
		<abstract>
			<par><![CDATA[<p>1. It will demonstrate, with specific examples, the types of planning, justification, expense, and results that are part of the implementation of new computer graphics applications; and,</p> <p>2. It will attempt to bring out the major barriers to implementation of computer graphics in large organizations and how those barriers may be overcome.</p> <p>The session is designed to help developers of the new advances in computer graphics software and hardware technology better understand the environments in which their tools will be used in order to optimize the use of the tools they develop. Too often developers of new tools have little opportunity to &#8220;get inside the heads&#8221; of the managers who will take these new tools and implement them. Through speakers and discussion, the session will draw together the experiences of people who have done the hard work necessary to estimate the costs and benefits and persuade top management that the project is worthwhile, to find the right hardware and software, and to train the staff to work with the new systems.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P328914</person_id>
				<author_profile_id><![CDATA[81100381360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Paller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Urbanetics, Washington, D.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334336</person_id>
				<author_profile_id><![CDATA[81100105468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Walter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[d'Hondt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Urbanetics, Washington, D.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P329755</person_id>
				<author_profile_id><![CDATA[81332495176]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dahl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Urbanetics, Washington, D.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333388</person_id>
				<author_profile_id><![CDATA[81100087330]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Dupree]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Applied Urbanetics, Washington, D.C.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Special Session on Large Scale Applications of Computer Charting and Mapping in Industry Alan Pallet 
Applied Urbanetics Washington, D.C. This panel has two goals: I. It will demonstrate, with specific 
examples, the types of planning, justification, expense, and results that are part of the implementation 
of new computer graphics applications; and, 2. It will attempt to bring out the major barriers to implementation 
of computer graphics in large organizations and how those barriers may be overcome. The session is designed 
to help developers of the new advances in computer graphics software and hardware technology better understand 
the environments in which their tools will be used in order to optimize the use of the tools they develop. 
Too often developers of new tools have little opportunity to "get inside the heads" of the managers who 
will take these new tools and implement them. Through speakers and discussion, the session will draw 
together the experiences of people who have done the hard work necessary to estimate the costs ~nd benefits 
and persuade top management that the project is worthwhile, to find the right hardware and software, 
and to train the staff to work with the new systems. The three panel members are: I. Walter d'Hond~ 
L a senior member of the computer staff at Boeing Aircraft Corporation, who is in charge of the corporate 
effort to integrate computer graphics, word processing, data base management systems and the appropriate 
hardware into a comprehensive system to be used in preparing complete technical brochures for the marketing 
department of Boeing. Mr. d'Hondt's talk will focus on the process that Boeing went through to evaluate, 
justify and implement their system. He will share his findings on how one ultimately justifies such systems 
and will show the results realized by Boeing Aircraft Corporation. 2. David Dahl is a staff member at 
the Los Alamos Scientific Laboratory where he heads the meteorology section. He is a major user of computer 
graphics and was responsible for taking the tools developed and purchased Dy the computer graphics software 
specialists in the computing section of Los Alamos and converting those tools into a system that is now 
regularly used by more than 400 staff members to prepare more than 5,000 maps and charts per month at 
Los AlamOSo &#38;#169;~1979 ACM 0-89791-004--4/79/0800--208 $00.75 See Copyright Pg. 208 Dr. Dahl's 
presentation will focus on the difficulties he had to overcome as a user in trying to take advantage 
of the computer graphics tools that were available and what he did to overcome those problems and make 
computer graphics so widely used at the Laboratory. His user-oriented efforts are very well illustrated 
with a series of color computer-generated slides. 3. Robert 2- Du_~ee is a senior staff systems analyst 
at Standard Oil Company (Indiana). He is responsible for Amoco's mapping system which allows users to 
request maps containing Land Surveys, Counties, Land-gater forms, Leases and other boundaries along with 
wells and seismic information. This information is retrieved using geographic relationships provided 
in a corporate on-line data base. Current usage of the system is in excess of 100 maps per day. Mr. 
Dupree will focus on the shifts in emphasis noted toward improving the quality and quantity of data in 
the data bases as well as a review of and evaluation of the computer graphics hardware and software that 
his organization utilizes. 209 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807446</article_id>
		<sort_key>210</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[A colour display unit for a 21-channel EEG-monitor]]></title>
		<page_from>210</page_from>
		<page_to>217</page_to>
		<doi_number>10.1145/800249.807446</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807446</url>
		<abstract>
			<par><![CDATA[<p>A system for the simultaneous display of several functions of one or two variables has been developed. One-variable functions are represented by their graphs, while two-variable functions are displayed by means of contour maps, with a light intensity proportional to the displayed value. By assigning a fixed colour to each contour map, it is possible to superimpose different maps without losing charity. The display unit is connected with a microprocessor system, which allows the real-time calculation and display of time-changing functions.</p> <p>The primary application of the system is the representation of the distribution of the spectral contents of EEG (electro-encephalographic) signals on the surface of the head.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Colour display]]></kw>
			<kw><![CDATA[Contour maps]]></kw>
			<kw><![CDATA[Digital plotting]]></kw>
			<kw><![CDATA[Electro-encephalography]]></kw>
			<kw><![CDATA[Graphical characters]]></kw>
			<kw><![CDATA[Interpolation]]></kw>
			<kw><![CDATA[Parallel microprocessors]]></kw>
			<kw><![CDATA[Real-time display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Approximation of surfaces and contours</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Real time</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010918</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Approximation algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Measurement</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P333090</person_id>
				<author_profile_id><![CDATA[81100379359]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Paternoster]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IWONL-researcher, Dienst Elektronika en Informatika, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussel - BELGIUM]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331891</person_id>
				<author_profile_id><![CDATA[81100635427]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Bousse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NFWO -researcher, Dienst Elektronika en Informatika, Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussel - BELGIUM]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332655</person_id>
				<author_profile_id><![CDATA[81100244194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[O.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Steenhaut]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vrije Universiteit Brussel, Belgium]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R.H. PATERNOSTER, M.J. GOOSSENS, O.L.STEENHAUT and E.M. VAN OOST : A 21-channel EEG-Monitor with real time colour result display. Euromicro Symposium, G&#246;teborg, Sweden, aug. 79.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[EEG Clin. Neurophysiol. 10 : 372, 1958.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. TIBERGHIEN, L.J. BOUSSE, M.J. GOOSSENS, R.H. PATERNOSTER, A. VAN EYNDONCK and E.M. VAN OOST : A multi-microprocessor system with 2 shared buses. 1ste European Conference on Parallel and Distributed Systems. Toulouse, France, February 79.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. ABRAMOVITCH and I. STEGUN : Handbook of mathematical functions, formulas 25.2.65 and 66.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. DEMIDOVITCH, I. MARON. El&#233;ments de calcul num&#233;rique. Ed. MIR. - Moscou - 1973. pp. 562-564.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. BALME and C. POUPOT; A representational model of the transmission of brain biopotentials from the cortex to the scalp. 11th International Conference on Medical and Biological Engineering,76, Ottawa, Canada.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. UENO and S. MATSUOKA : Topographic computer display of abnormal EEG activities in patients with brain lesions. Ibidem.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359614</ref_obj_id>
				<ref_obj_pid>359588</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. WARD : Real time plotting of approximate contour maps. Comm. ACM, sept. 78, vol 21, no. 9, pp 788 - 790.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A COLOUR DISPLAY UNIT FOR A 21-CHANNEL EEG-MONITOR R.H. PATERNOSTER  L.J. BOUSSE + O.L. STEENHAUT Vrije 
Universiteit Brussel, Belgium. Key words and phrases : colour display, real-time display, contour maps, 
digital plotting, graphical characters, electro-encephalography, interpolation, parallel microprocessors. 
CR categories : 3.34, 3.89, 5.13, 6.22, 6.35, 8.2 ABSTRACT A system for the simultaneous display of several 
functions of one or two variables has been deve- loped. One-variable functions are represented by their 
graphs, while two-variable functions are displayed by means of contour maps, with a light intensity proportional 
to the displayed value. By assigning a fixed colour to each contour map, it is possible to superimpose 
different maps without losing charity. The display unit is con-nected with a microprocessor system, which 
allows the real-time calculation and display of time-cha~ing functions. The primary application of the 
system is the re-presentation of the distribution of the spectral contents of EEG (electro-encephalographic) 
signals on the surface of the head. 1. INTRODUCTION The problem which prompted the development of the 
system presented here is the display of results of EEG (electro-encephalographic) measurements. EEG potentials 
vary with time, and are generally measured at several places of the head with multi- channel x-t recorders. 
The long drawings obtained in this way (typical- ly I00 m for a 1-hour session) are visually ana-lysed 
and some spectral information is extrac-ted by inspection. Considerable savings in analysis time and 
accu- racy can be obtained by displaying the energy content of the EEG signals in selected frequency 
bands, at the different points on the head, and in function of time. This calls for graphs with two independent 
variables (to represent the sur- face of the head), which are implemented using contour maps. In order 
to add the time dimension these maps are displayed on a TV screen. This visual method of presentation 
has the advan- tage of strongly compressing the amount of infor-mation, compared to the classical method. 
Although the system was conceived with one parti- cular application in mind, it has been kept as general 
as possible : the system can display con-tour lines for any twodimensional function. The particular definition 
of the function for an ap- plication is only reflected in the software of the microprocessor system which 
calculates the con-tour maps. 2. DISPLAY UNIT DESCRIPTION The EEG's are recorded with 21 electrodes, 
arran-ged according to the international 10-20 system (2), which is shown in a two-dimensional projec-tion 
in Fig. i. The different incoming analog signals are filtered, amplified, simultaneously sampled and 
digitalised, at a frequency of 200 Hz, in blocks of 4 K length. The FFT, the corresponding power spectrum 
and the integral over six different user definable fre-quency bands (e.g.~, ~I; ~2, ~... waves) are cal-culated 
for each channel.  IWONL-researcher + NFWO-researcher Authors address : Dienst Elektronika en Informa- 
 tika, Vrije Universiteit Brussel, Pleinlaan 2, B-I050 Brussel - BELGIUM. &#38;#169;1979 ACM O-89791-004--4/79/0800--210 
$00.75 See Copyright Pg. 210 1 '3 ~C3 2z .C. ~ P~ ,PA r  Fig. 1 : two-dimensional projection of the 
10-20 recording system. Using two-dimensional interpolation, one is able to estimate the energy content 
of the six frequen-cy bands in any point of the head from the 21 available points. Iso-energetic lines 
for eight different levels are then calculated and displayed on a colour TV-screen, with a light intensity 
pro-portional to the displayed level, together with the numerical value (in uV/Hz) of minimum and maximum 
level. The distance between the levels can be chosen to be constant or logarithmically variable. By assigning 
a fixed colour to each frequency band, it is possible to superimpose different maps on each other, with 
easy recognition of the different pat-terns. The user can select at most three maps for simultaneous 
display, and is allowed to change this selection at any time, with immediate response of the system. 
The FFT and energy-map calculations are perfor-med in real-time by means of a parallel system of 8 microprocessors 
(3). As will be seen in the hardware description of this display unit, one of these 8 processors controls 
the data flow in the machine, necessary for the display. As the data are sampled in blocks of 20 seconds, 
each set of maps can be seen during 20 seconds, and is then replaced by the next set, unless the user 
wants to hold a particular set of results. The user can also obtain the simultaneous visuali- sation 
of the power spectrum of up to ten channels. A keyboard is provided to allow the user to com-m~aicate 
information concerning the patient, and the required display format. Finally, digital in-and output on 
a cassette is also provided for recording and re-display of selected measu- rements. The whole system 
is stand-alone, self-contained and easily transportable. 3. THE INTERPOLATION ALGORITHM Three- and four-point 
linear interpolation algo- rithms are used to estimate the energy contents of the six frequency bands 
in any point (Fig. 2). Fig. 2a : repartition of the projection of Fig. 1 in segments for three-and four-point 
interpolation. YI~ x I -x 0 : h Jo Yl -YO : k YO x--I 0 ~< p;q ~< I (I) f(x 0 + ph,y 0 + qk) = (1-p-q) 
fo0 + p flO + q f01 + 0 (h 2) Fig. 2b : three-point interpolation formula (4). YI~ Xl -Xo = h YO ] 
Y1 " Yo = k x 0 x~ 0 < p;q ~ I f(x 0 + ph,y 0 + qk) : (i-p) (I-q) fo0 + p(l-q) flO + q(1-P)f01 + Pq 
f11 + O(h2) = (1-p-q) fo0 + p flO + q flO + q f01 + Pq(foo-F10-fo1+f11 ) + O(h2).  Fig. 2c : four-point 
interpolation formula (4). The different reasons for this choice are : 1) other research (6) has demonstrated 
that the EEG-potentials in a point on the scalp are mainly influenced by the cerebellum regions just 
below the immediate neighbourhood of that point. Thus it seems to be useless to take account of the far 
situated electrodes, as did Ueno and Matsuoka (7). The main advantage of their method is to produce a 
smooth result. 2) the rapidity of the calculation is essential, because the display must be done in real 
time; complicated algorithms must therefore be discarded in favour of fast ones.(It :should be noted'that 
the formulas of Fig. 2b and 2c are not used in this form; it is in fact pos-sible to eliminate all multiplications 
in the interpolation algorithms (5)). 211 3) there are not yet sufficient physiological data available 
to conclude which interpolation method would be better, thus a relatively simple method has been chosen. 
4. DISPLAY METHOD Using the methods described above, iso-energy maps for six frequency bands of the EEG-spectrum 
are cal- culated, and these have to be displayed in colour. Since graphical terminals in colour are unavailable, 
it is obvious a TV monitor must be used. This means a hardware memory of sufficient size must be pre- 
sent to contain all the video information. In order to minimize the size of this memory, a character 
oriented display method, as described by Ward (8), has been chosen. This has the following advan- tages 
: - when using second-order maps, 25 different cha-racters (including the blank character) are re-quired 
for plotting the curves, which means that five bits of memory are needed to store one cha-racter. On 
the other hand, each character con-tains 144 dots (12 x 12 matrix) which when in- dividually addressed 
would require 144 bits of memory. Thus a large saving of memory is ob-tained, at the price of limiting 
the possibili-ties of the type of characters which are dis-played. - the character-oriented method makes 
it much more convenient and fast to calculate the shape of the curve from the given interpolated function 
values. Since the time factor is crucial in the design, this is a decisive consideration. We use second-order 
maps since this involves no extra multiplications, but considerably smoothens the resulting curve, as 
compared to first order maps. Furthermore, only 25 characters are needed to plot these maps, as compared 
to the 55, needed for third-order maps. Eight iso-lines are displayed with a light inten- sity proportional 
to the displayed level. Defi- ning each character by its shape and intensity, 24 x 8 characters are needed 
to make a complete map (excluding the blank character). Thus, an 8 bit code is needed for the character 
addresses in a character generator (Fig. 3). The remaining 64 codes are used for alphanumerical characters, 
some greek and mathematical symbols, and punctua- tion marks.  LA' IA l A IA !A I IAO I 24 possible 
8 possible display charac-intensities ters exception : OIOXXXXX~used for 64 alphanumerical, IlIXXXXX% 
greek, mathematical and punctuation characters. 11111111 blank character Fig. 3a : address code format 
for the character generator.  yoooooo, iflDn n Fig. 3b : the 24 special display characters with their 
address codes (A7-A3). Only six logical operations and one interpola-tion calculation are needed to deter-mine 
an address code. It should be noted that the ambiguous situation which occurs when a curve passes through 
all four sides of a character is of a very exceptional na-ture. The characters described by Ward (8) 
to cover this case are not implemented, but are re-placed with blanks. Finally, the colour in which the 
map has to be displayed, is determined by the display software. The display image is composed of 67 by 
50 charac- ters, each contained in a matrix of 12 x 12 dots. The image is interlineated, and has a display 
fre-quency of 50 rasters per second. 5. DISPLAY HARDWARE The hardware used is microprocessor-based. 
A 6800 microprocessor and a 6845 CRT controller or-ganise the display of data on the TV-Monitor. They 
allow also data to be brought in by a keyboard. 5.1. Video display principle The information necessary 
for the display of the different energy maps (or energy spectra of dif-ferent channels, etc.) is stored 
in four different 4K x 8 RAM's called video RAM's, in the way as discussed in 5.2. Thus, each video RAM 
contains the 67 x 50 matrix of character codes, represen-ting a complete video image. Three of these 
images are user-selected energy maps; the fourth is the background of the image, i.e. the image of the 
projection of the 10-20 system on the head (see Fig. i). (In case of display of energy spectra, the background 
contains the coordinate axes with appropriate scaling in-dications). 212  We note here that the character 
codes stored in the video RAM's, contain only information about 5.2. Microprocessor hardware of the video 
system (Fig. 6). the kind and the luminous intensity of a character, not of the display colour. This 
colour is fixed for any given frequency band. The colours used are red (R), green (G), blue (B), R + 
G, G + B, B + R for the energy maps, and R + G + B for the background. This means that any (except the 
fourth video RAM can happen to have to be dis- played in any colour (except R + G + B), while the fourth 
video RAM is always displayed in R + G +B. CHARACTER o GENERATOR c > G RAoCuKN-O i CRT CONTROLLER 
 ADD  Fig. 4. From video RAM's to analog video output. The four video RAMS's are continuously and si- 
multaneously addressed by the CRT controller (Fig. 4). The 8 bit output of each RAM is lat-ched, and 
clocked one after the other into the character-generator, which gives a 15 bit output : 12 bit representing 
the 12 dots of one line of a single character are loaded into a shift regis-ter, and 3 bit representing 
the luminous inten- sity are latched. A 12 bit shift register and a 3 bit latch are associated with each 
of the four video RAMS's. The shift registers are used to give the dot output for each map, while the 
latches contain intensity information which is the same for all points of a given character. A colour 
and map selection circuit (Fig. 5) contains the logic necessary to feed the required analog information 
to each of the three video colour inputs. Provi-sion has been made to ensure that composite co- lours.(such 
as R + G) are not brighter than the three primary colours. The contents of the map selection registers 
determine the colour with which each video RAM will be displayed, while the background information is 
always white. The 67 x 50 character matrices for each frequency band are calculated by the parallel microproces- 
sor-system which also performs the FFT and related calculations. These matrices are transferred through 
an adequate interface to the video system. A so-called video bus interconnects a 6800 micro- processor 
with private ROM and RAM, DMA and CRT controllers, the video RAM's, the map selection i COLOUR AND 
z H MAP o .> SELECTION o < z < CIRCUIT MAP SELECTION I REGISTERS registers, the parallel system 
interface, key-board, and cassette interface. 5.2.1. !he pa~a!lel_s%ste~ interface The data transfers 
through this interface are in fact DMA transfers between the video system and one particular processor 
of the parallel pro-cessorsystem. Two types of DMA transfers exist : - from parallelsystem to video RAM's; 
this happens each time a new set of video maps must be trans- ferred to the video RAM's; - from the parallelsystem 
to 6800 processor memo- ries and vice versa; this allows communication of data and commands between 6800 
and parallel system (such as : limits of frequency bands, display mode, alarms, etc.). A description 
of this interface is given in ref. (1). 5.2.2. The 6800 The 6800 controls the proper working of CRTC, 
Dr~C, keyboard and cassette, interfaces and map selection registers. Fig. 5 : The colour and map selection 
circuit The 6800 can load data under control of the DMAC 5.2.5. !h~ yide~ BAM'~ into each of the four 
video RAM's (e.g. user com-mands and data from keyboard), and to the parallel system. The ~PU also controls 
and updates the map selection registers. The selection of the diffe-rent resources of the 6800 is obtained 
by means of the 4 most significant data lines, fed into a 4-to-16 decoder. 5.2.3. !h~ R ! ~oQtco!l~r 
- This unit generates the refresh addresses for the four video RAM's simultaneously, a line address for 
the character generator, and the synchronisation signal for the monitor. The video memory receives its 
addresses either from the CRT controller or from the video bus, as decided by a multiplexer. This means 
the refresh addresses cannot interfere with the working of the processor. The character data can be connected 
for testing purposes to the video bus through a tri-state buf-fer. 5.2.4. !h~ D~ ~oDt~o!l~r - Three 
different DMA transfers are used : from parallel system to the video RAM's; (new con- tour maps are loaded 
into the video RAM's). This DMA is executed during one single raster scan; the CRTC is disconnected from 
the address bus, so that one half image (25msec) is lost. from parallel system to 6800 memory and vice 
versa; - from 6800 memory to video RAM's. These two last DMA transfers are performed during the vertical 
return periods of the CRTC, so that no images are lost. 214 These are dynamic memories which are continuously 
refreshed through the CRTC addressing. The ad- dresses can originate from the CRTC (normal dis-play mode), 
the DMAC (loading of the map), and the MPU (testing the memories). 5.2.6. The ma~ se!ect~o ~ re~isters 
The map selection registers are latches which are addressed by the MPU. They are updated each time that 
the user changes the map display selection. If the user selects a fourth map for display, the corresponding 
code will be written in the register which contained the code of the first map, so that this map will 
be lost. 6. RESULTS Fig. 7 shows hard copies of several EEG maps, ob- tained according the method described 
in this paper. One should note that the graphic copy does not show colours nor different line intensities. 
As already mentioned earlier, the representation of the head with the electrode configuration is displayed 
with low intensity white lines, while the energy maps are displayed in different colours with changing 
luminous intensity for the different contour lines. 7. CONCLUSIONS The system described here has many 
possible appli- cations outside the one for which it was primarily designed. It is suited to cases where 
complex in- formation must be represented in real-time, which means a display method is needed which 
is clear, I PARALLEL SYSTEM I INTERFACE I D , 4DivlDEO DI 6800 ~ ~[~ MPU A A RAM C~ ~ = S DMAC RAM | 
] A + ROM&#38;RAM AI I ~A RAM C~ : ~ KEYBOARD VIDEO iS INTERFACE] _ ~16 ~A RAM C~]---~. --8 | ~ , I 
III CHAR.LINE IAn-All..... I ~ llii ADDRESS ~ CASSETTINTERFACE ~ ~ ~ ~-~ El]S D C ~ AI2-AI II 1111 Fig. 
6 : Microprocessor hardwareof the video system Fig. 7 : Graphic representation of energy contour maps 
of human EEG spectra. The subject is a healthy 46 year old man, who remained very restful during the 
recordings. v u B 21-CHANNEL EEG -MONITOR 03/03/1979 ~ATIENT NAME ]ATE OF BIRTH 5ATIENT NR. ]BSERVATIONS 
 IORMAL PATIENT IN REST THETA 4-? HZ INT 0 = -188.5 DB V/HEINT ? = -I15,5 DB V/HZSTEP 1.0 DB V/HZ Fig. 
7a : Prefrontal en frontal zones emit a e activity which is slightly lower than the ~ activity on the 
sameplace (fig. 7b), indicating the rest state of the subject. EEQ MONITOR - 03/'03/1878 PATIENT NAME 
 DATE OF BIRTH PATIENT NR OBSERVAT IONS NORMAL PATIENT IN REST ALFA 8-12 HZ INT 0 = -120.40B V/MZ 
INT ? = -111.3 OB V/HZ STEP 1,3 OB V/HZ  Fig. 7b : The prefrontal zone (between FPl, FP2 and Fz) generates 
a stable and symmetrical ~ rhythm (peak value about -111 dB V/Hz) V U B 21 -CHANNEL EEg NON I TOR - 03/03/IS79 
=ATIENT NAME ]ATE OF B I RTH =ATIENT NR . )BSERVAT I ONS qORMAL PATIENT I.N REST BETA I 13-10 HZ INT 
O = -189.0 DB VIHZ INT ? = -12~.O OB V/HZ STEP 1.O DB V/HZ Fig. 7c : The right prefrontal zone (FP2) 
emits low frequent waves. 216 but still simple enough to allow real-time calcula- tion. The advantage 
obtained in this way is the introduction of the time axis in the display, sin-ce any changes of the phenomenon 
being studied can immediately reflected. Drawings in perspective of complex surfaces are more attractive 
than the level lines we have used in our apparatus, but are of course impossible to be calculated and 
displayed in real time by an autonomous dedicated system. This type of graphi-cal representation is suitable 
for the display of static results, such as the shape of an object, when calculation time is of no critical 
importance. The display system we have realised is potentially useful in many areas, especially the treatment 
of signals of biomedical origin. In this last case, an extra advantage is that the result obtained can 
be used directly for clinical or diagnostic pur- poses. 8. ACKNOWLEDGMENTS. We are very much thanks indebted 
to Ronny AERENS and Louis ESPAGNET for their long and patient help in the practical realisation of this 
work, and to Elly VAN OOST for the suggestions which lay at the basis of this paper. 9. BIBLIOGRAPHY. 
i. R.H. PATERNOSTER, M.J. GOOSSENS, O.L.STEENHAUT and E.M. VAN OOST : A 21-channel EEG-Monitor with real 
time colour result display. Euromicro Symposium, G~teborg, Sweden, aug. 79. 2. EEG Clin. Neurophysiol. 
10 : 372, 1958. 3. J. TIBERGHIEN, L.J. BOUSSE, M.J. GOOSSENS, R.H. PATERNOSTER, A. VAN EYNDONCK and 
E.M. VAN OOST : A multi-microprocessor system with 2 shared buses, lste European Conference on Parallel 
and Distributed Systems. Toulouse, France, February 79.  4. M. ABRAMOVITCH and I. STEGUN : Handbook 
of mathematical functions, formulas 25.2.65 and 66. 5. B. DEMIDOVITCH, I. MARON. El~ments de calcul 
num~rique. Ed. MIR. -Moscou - 1973. pp.562- 564. 6. L. BALME and C. POUPOT; A representational model 
of the transmission of brain biopoten- tials from the cortex to the scalp, llth International Conference 
on Medical and Biological Engineering, 76, Ottawa, Canada. 7. S. UENO and S. MATSUOKA : Topographic 
computer display of abnormal EEG activities in patients with brain lesions. Ibidem. 8. S. WARD : Real 
time plotting of approximate contour maps. Comm. ACM, sept. 78, vol 21 n  9, pp 788 -790.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807447</article_id>
		<sort_key>218</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Movies from music]]></title>
		<subtitle><![CDATA[Visualizing musical compositions]]></subtitle>
		<page_from>218</page_from>
		<page_to>225</page_to>
		<doi_number>10.1145/800249.807447</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807447</url>
		<abstract>
			<par><![CDATA[<p>A theory of music visualization proposed by Nancy Herman postulates an association between colors and pitches of musical scales. A color raster graphics display is used to generate images of notes, chords, and chord progressions based on this theory. Temporal adjacency of notes or chords is mapped to spatial adjacency of colors, usually in a concentric pattern of squares or circles. By varying certain image parameters, different &#8220;brush stroke&#8221; effects may be obtained. Illustrations of several computer generated &#8220;musical paintings&#8221; are included, along with some original paintings for comparison.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color animation]]></kw>
			<kw><![CDATA[Computer art]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Music]]></kw>
			<kw><![CDATA[Raster graphics]]></kw>
			<kw><![CDATA[Video display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.5.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010475</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Sound and music computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003371.10003386.10003390</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Specialized information retrieval->Multimedia and multimodal retrieval->Music retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P331045</person_id>
				<author_profile_id><![CDATA[81100330079]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Mitroo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P206918</person_id>
				<author_profile_id><![CDATA[81100574132]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nancy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Herman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038212</person_id>
				<author_profile_id><![CDATA[81452608047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Norman]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Badler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer and Information, Science, University of Pennsylvania, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Albers, Josef. Interaction of Color. Yale Yale University Press, New Haven, CT, 1963.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807362</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Joblove, G.H.,and Greenberg, D. Color spaces for computer graphics. Computer Graphics 12, 3 (Aug. 1978), 20-25.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Miller, L.,and Badler, N.I. Towards a formal model for pseudo-color selection. Proc. IEEE Pattern Recognition and Image Processing Conf. 1977, 261-265.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Moorer, J.A. On the transcription of musical sound by computer. Computer Music Journal 1, 4 (1977), 32-38.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Piszczalski, M., and Galler, B.A. Automatic music transcription. Computer Music Journal 1, 4 (1977), 24-31.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807361</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Smith, A.R. Color gamut transform pairs. Computer Graphics 12, 3 (Aug. 1978), 12-19.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MOVIES FROM MUSIC: VISUALIZING MUSICAL COMPOSITIONS J. B.Mitroo* Nancy Herman** Norman I.Badler*** 
 Key words and phrases: Computer art, computer graphics, music, color animation, video display, raster 
graphics. Computing Reviews categories: 3.41, 3.44, 8.2. ABSTRACT opportunity to examine visual relationships 
 A theory of music visualization proposed by Nancy Herman postulates an association between colors and 
pitches of musical scales. A color raster graphics display is used to generate images of notes, chords, 
and chord progressions based on this theory. Temporal adjacency of notes or chords ismapped to spatial 
adjacency of colors, usually ina concentric pattern of squares or circles. By varying certain image parameters, 
different "brush stroke" effects may be obtained. Illustrations of several computer generated "musical 
paintings" are included, along with some original paintings for comparison. INTRODUCTION Since time 
immemorial, music and colors have individuallyenchanted people intheir own special ways. Feeling that 
a color composition which was linked insome basic way to music could have an emotional effect, Nancy 
Herman evolved a painting style linking musical notes to colors. Many well known musical compositions 
were painted, each painting often taking several weeks or even months to complete. Observing a definite 
pattern to these "musical paintings," she sought to automate their creation to permit easier, faster 
production and experimentation. One of the artistic goals isthe visual experience of an entire musical 
composition (as opposed to the normal sequential presentationof sound) and the * 771 E. LancasterAve. 
(c/o Macro International) Villanova, PA 19085 ** 275 N. Latches Lane Merion, PA 19066 *** Department 
of Computer and Information Science, University of Pennsylvania, Philadelphia, PA 19104 ACM 0-89791-004-4/79/0800-218 
$00.75 See Copyright Pg. between musical tones, chords, rhythms, and time. The other goal isto visually 
compare works of several well known composers. To imagine mapping music into visual space, the various 
 characteristics of sound must be considered. We shall discuss the presentation of pitch and time, 
and specifically omit other parameters such as intensity, attack, and timbre since they have not yet 
been fully investigated. The primary tenet inNancy Herman's artistic theory (strongly influenced by 
Josef Albers [1]) isthat the spectral colors can be related to each other in the same way as musical 
tones: the value of the color (relative amount of white [2,6]) varying in the same way as the pitch of 
the musical tone. Ineach octave of twelve tones there are twelve colors (blue, blue-violet, violet, red-violet, 
red, red-orange, orange, yellow-orange,yellow, yellow-green, green, and blue-green) forming a cycle. 
Thus middle C is related to high C as, say, "middle" (value) blue is related to "high" (value) blue. 
It is important to note that there is no implicit claim of emotional association of blue with C (in fact 
any other association would be possible); rather the octave relationships of the twelve-tone scale are 
mapped onto the cycle of twelve colors. For each octave the basic colors are whitened or darkened to 
evoke the same note. The other fundamental notion is the translation of the sequential presentation 
of musical tones over time to a stationary, spatially-adjacentconfiguration inthe painting. Since the 
tones before and after a particular note or chord are the only ones which "touch" it,areas of color representing 
those tones should touch only where the respective tones do. The geometry isfurther defined by assuming 
that the viewer's gaze will initially fix on the center of a symmetrical pattern. Starting at the center 
with the first note or chord, successive notes or chords appear as concentric areas ina basic shape (usually 
squares or circles). As the gaze is drawn outward from the center, each note or chord totally surrounds 
the previous one. Practical limitations in the size of a canvas preclude large musical compositions, 
so the temporal dimension may also be used in itself. The result isa sequence of paintings intime or, 
 218 since we began to use computer graphics, an animation inreal-time synchronized to the music. Inthe 
next section we shall describe the implementation of this theory with the goal of producing such animations. 
 GRAPHIC IMPLEMENTATION A color raster display isused to create "musical paintings" by computer according 
to the above theory. Certain limitations are imposed by this device, such as the resolution of the display 
(240 x 320 on our RAMTEK GX100B), and the available colors (from the 4096 possible). Another difference 
from actual paintings occurred with conversion of pigment color to electronic color. Finally, the order 
of graphical creation of the painting was varied for greater efficiency, even though itdeparted from 
the strict musical order. We shall discuss the graphical processes involved intranslating this theory 
to computer graphics by examining pitch color selection, image format, line appearance, chord representation, 
and chord progression display. Colors to represent the 24 pitches ina two octave range were (laboriously) 
selected to match the original pigment colors using a color selection program [3]. Once obtained, these 
colors were used throughout the examples illustrated here. The colors may be seen in Figures 1 and 2: 
Figure 1 is an actual painting of a major scale of eight pitches beginningwith blue-violet inthe center 
and progressing to a lighter (higher) blue-violet; Figure 2 isa computer generated major scale based 
on redorange progressing from light (high) to dark (low). The organization of the scales illustrates 
a square format for the painting. Other formats are possible. For example, actual paintings have been 
executed in a rectangular format (Figure 3). Inthe graphic implementation a rectangular format ispossible 
(Figure 4) but less pleasing than a square format (Figure 5). Ultimately, a circular format (Figure 6)became 
the most flexible geometry. Part of the motivation for this decision came from the choice of radial sectors 
for the notes, so that the sectors maintained the same width along the entire circumference of the circle. 
 The appearance of Figures 4 and 5 varies inthe way lines are drawn as well as the format. InFigure 
4 lines are drawn one by one in clockwise fashion, thus the center tends to "fill up" with raster points. 
InFigure 5, however, each line iserased prior to being drawn and no such filling can occur. Both techniques 
have been found useful and are therefore under control of the artist. By changing the angle between successive 
radial lines, different textures are obtained: Figures 6, 7, and 8 show the result of increasing the 
separation. Displaying a single note yields an image similar to Figure 6, 7 or 8. To draw chords the 
separate colors of the notes inthe chord are repeated innarrow radial sectors around the circle. Figures 
9 and 10 each show a two note chord. (By electronic serendipity, Figure 10 contains white --a color 
not inthe chord -because itwas displayed by passing the RGB video signal through an RGB-to-composite 
converter.) Given a sequence of consecutive chords (a chord progression), each isdisplayed in concentric 
rings about the center. Figures 11 through 16 show various chord progressionswhich may be compared to 
an actual painting of "Frere Jacques" by Nancy Herman. Display resolution effectively limits the number 
of chords inone image, so either short sequences appear inone picture or a number of progressions are 
linked together as an animation. THE "PAINTING" PROGRAM The FORTRAN program which creates the computer 
displays incircular format requires the following information: 1. Number of chords or notes (as for 
a melody).  2. Number of notes for each chord.  3. Notes inthe chord.  4. Length of radius (to outer 
boundary) of each chord.  5. Number of lines ineach color sector.  6. Angle of separation between adjacent 
lines.  The notes themselves are coded as numeric values although a simple translator could be written. 
The first three items should be self-explanatory. The last three produce different effects which were 
alluded to in the preceding section. The length of the chord radius defines the duration of the chord 
relative to the succeeding chord. Since present program draws the chords outside in (Contrary to their 
actual temporal order), the next chord erases that part of the preceding chord which itoverlaps. The 
width of the band for each chord is therefore implicitly defined by the difference inradii of each chord 
inthe progression (Figures 18 through 27). When there isa "rest" inthe music, itmust still be specified 
and appears as a gap (Figures 20 through 27). This progression consists of 11 chords from Gershwin's 
"Our love is here to stay." (Figure 27). The number of lines ineach color segment affects the thickness 
of the sector devoted to each color. Ingeneral, the more lines, the wider the sector. The appearance 
isalso affected by the angle of separation between adjacent lines (Figures 6, 7, and 8). With the other 
parameters constant, varying the angle results ineither a "brush stroke" effect for larger values (Figures 
11 and 13), or a solid color effect for smaller values (Figures 12 and 14). The final image may utilize 
different values for each chord since the appearance is also dependent on the radius: the larger the 
radius, the more pronounced the line separation for any given angle. InFigure 11 the outermost chord 
uses a separation angle of 1.0 degree, and the innermost 2.5 degrees; while in Figure 12 the outermost 
uses 0.5 degree and the innermost 1.0 degree. 219 FUTURE EXTENSIONS There are unlimited possibilities 
for extending these experiments inthe visualization of music. Among the most feasible are: more efficient 
animation of a sequence of musical progressions --the present hand editing of video images isquite tedious. 
visualization of other musical variables such as intensity, attack, and timbre -for example, intensity 
might be related to the width of a sector. improved interactive input, utilizing an interactive program 
and command parser. As synchronizationwith music isdesirable for animation, itwould be exciting to bypass 
the note and chord input and transcribe the actual audio signal. This is a non-trivial task and is unlikely 
to be available to us for some time [4, 5]. Finally, we might propose the composition of music based 
on visual or temporal relationships between colors, inverting the mapping process and experiencing the 
painting inan audible performance. REFERENCES [1] Albers, Josef. Interaction of Color. Yale Yale University 
Press, New Haven, CT, 1963. [2] Joblove, G.H.,and Greenberg, D. Color spaces for computer graphics. 
Computer Graphics 12, 3 (Aug. 1978), 20-25. [3] Miller, L.,and Badler, N.I. Towards a formal model for 
pseudo-color.selection. Proc. IEEE Pattern Recognition and Image Processing Conf. 1977, 261-265. [4] 
Moorer, J.A. On the transcription of musical sound by computer. Computer Music Journal 1, 4 (1977), 32-38. 
[5] Piszczalski, M., and Galler, B.A. Automatic music transcription. Computer Music Journal 1, 4 (1977), 
24-31. [6] Smith, A.R. Color gamut transform pairs. Computer Graphics 12, 3 (Aug. 1978), 12-19.   
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807448</article_id>
		<sort_key>226</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Interactive color map displays of domestic information]]></title>
		<page_from>226</page_from>
		<page_to>233</page_to>
		<doi_number>10.1145/800249.807448</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807448</url>
		<abstract>
			<par><![CDATA[<p>Governmental decision makers require an increasing variety and volume of information in order to formulate effective policies, plans, and legislation. Moreover, rapid access to this broad body of information is critical to timely and effective governmental action. This paper describes a recent joint project undertaken by the NASA/Goddard Space Flight Center and the Bureau of the Census at the request of the Executive of the President to demonstrate the potential of graphic information display technology for the rapid delivery and effective display of Federal statistics. This project resulted in the development of a prototype Domestic Information Display System which was demonstrated to President Carter, members of Congress, and their respective staffs in June 1978.</p> <p>The Domestic Information Display System is an interactive, menu-driven software system which produces single and bivariate choropleth maps of socio-economic data by county at the national and state level, and by census tract for Standard Metropolitan Statistical Areas (SMSA's). Selected subareas of national and SMSA maps may be dynamically enlarged to show greater detail. Histogram displays may be selected to show statistical as well as geographic structure.</p> <p>The system is minicomputer-based and utilizes the image manipulation capabilities of a raster-scan color graphics terminal designed at NASA/Goddard as part of the Atmospheric and Oceanographic Information Processing System (AOIPS) which was adapted to demonstrate the potential of a Domestic Information Display System. The system is highly interactive and can produce a color map display within seconds of the selection of a data item from a menu.</p> <p>This paper discusses the operation of the Domestic Information Display System, presents sample output products, and describes in detail the software and hardware organization through which the system flexibility and rapid response were achieved.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color raster displays computer cartography]]></kw>
			<kw><![CDATA[Geographic displays]]></kw>
			<kw><![CDATA[Interactive computer graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P330949</person_id>
				<author_profile_id><![CDATA[81100572280]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dalton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA/Goddard Space Flight Center, Greenbelt, Maryland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14019402</person_id>
				<author_profile_id><![CDATA[81332490241]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Billingsley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA/Goddard Space Flight Center, Greenbelt, Maryland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331076</person_id>
				<author_profile_id><![CDATA[81100210855]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Quann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA/Goddard Space Flight Center, Greenbelt, Maryland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31070927</person_id>
				<author_profile_id><![CDATA[81332491010]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bracken]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA/Goddard Space Flight Center, Greenbelt, Maryland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Harden, R. The Presidency in the Information Age: A Philosophy for Managing Information, Bulletin of the American Society for Information Science, Vol. 5, No. 2, (Dec. 1978), p. 13.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Zimmerman, E., The Presidency in the Information Age: Planning and Outreach, Bulletin of the American Society for Information Science, Vol. 5, No. 2, (Dec. 1978), pp. 19-21.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Meyer, M. A., Broome, F. R., and Schweitzer, R.H. Color Statistical Mapping by the U.S. Bureau of the Census, The American Cartographer, Vol. 2, No. 2, (1975), pp. 100-117.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bracken, P. A., Dalton, J. T., Quann, J. J., and Billingsley, J. B., AOIPS-An Interactive Image Processing System, National Computer Conference, (1978), pp. 159-171.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563873</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brassel, K. E., Utrano, J. J. and Hanson, P.O. The Buffalo Crime Mapping System: A Design Strategy for the Display and Analysis of Spatially Referenced Crime Data, SIGGRAPH-ACM Computer Graphics, Vol. 11, No.2, (July 1977), pp. 78-85.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 INTERACTIVE COLOR MAP DISPLAYS OF DOMESTIC INFORMATION J. Dalton J. Billingsley J. Quann P. Bracken 
 NASA/Goddard Space Flight Center Greenbelt, Maryland ABSTRACT Governmental decision makers require 
an in- creasing variety and volume of information in order to formulate effective policies, plans, and 
legis- lation. Moreover, rapid access to this broad body of information is critical to timely and effective 
governmental action. This paper describes a recent joint project undertaken by the NASA/Goddard Space 
Flight Center and the Bureau of the Census at the request of the Executive of the President to demon- 
strate the potential of graphic information display technology for the rapid delivery and effective display 
of Federal statistics. This project re- sulted in the development of a prototype Domestic Information 
Display System which was demonstrated to President Carter, members of Congress, and their respective 
staffs in June 1978. The Domestic Information Display System is an interactive, menu-driven software 
system which pro- duces single and bivariate choropleth maps of socio-economic data by county at the 
national and state level, and by census tract for Standard Metropolitan Statistical Areas (SMSA's). Selected 
subareas of national and SMSA maps may be dynam- ically enlarged to show greater detail. Histogram displays 
may be selected to show statistical as well as geographic structure. The system is minicomputer-based 
and utilizeE the image manipulation capabilities of a raster- scan color graphics terminal designed at 
NASA/ Goddard as part of the Atmospheric and Oceano- graphic Information Processing System (AOIPS) which 
was adapted to demonstrate the potential of a Domestic Information Display System. The system is highly 
interactive and can produce a color map display within seconds of the selection of a data item from a 
menu. This paper discusses the operation of the Domestic Information Display System, presents sample 
output products, and describes in detail the software and hardware organization through which the system 
flexibility and rapid response were achieved. Key Words and Phrases: interactive computer graphics, 
color raster displays computer cartogra- phy, geographic displays. CR Categories: 8.2, 3.53 INTRODUCTION 
 In Fall 1977, Richard Harden, Director of the Office of Administration within the Executive Office of 
the President (EOP), and Edward Zimmerma~ his Special Assistant, came to Goddard Space Flight Center 
to investigate the image analysis work being performed with remotely sensed data for earth resources 
and meteorology. Their objective was to identify information processing and display tech- nology applicable 
to the domestic policy informa- tion needs of the EOP staff (1,2). On a previous visit to the Bureau 
of the Census, they had been impressed by the quality and information content of choropleth maps produced 
by the Bureau showing the geographic dependence of various census sta- tistics (3). At Goddard, they 
were extremely interested in the interactive image display and analysis capabilities of the Atmospheric 
and Oceanographic Information Processing System (AOIPS) (4). Consequently, in March 1978, they asked 
NASA and the Census Bureau to join in a coopera- tive effort to demonstrate the potential of Goddard's 
image handling technology for the display and analysis of census statistics. Following a three month 
effort by six people, the Domestic Information Display System (DIDS) was developed and demonstrated to 
President Carter, Members of Congress, and their respective staffs. The remainder of this paper describes 
the capabili- ties and operation of this system. D!DS Capabilities The main purpose of the system is 
to produce color map displays of Census Bureau statistics. Unlike the Census Bureau's high quality hard 
copy products described in (3) which take days to weeks to produce, the DIDS map displays are produced 
in- teractively in seconds in response to user selec- tions on the AOIPS image analysis terminal shown 
in Figure i. (While other systems have been de- veloped to produce shaded statistical maps (see reference 
5 for example), DIDS is unique in its interactive use of color for this application.) An example of 
a DIDS choropleth map display is the US map of the unemployment rate in 1977, shown in Figure 2. In this 
map, the range of unem- ployment, i.i to 28.1 percent, is divided &#38;#169;1979 ACM 0-89791-004--4/79/0800--226 
$00.75 See Copyright P9-226 into five class intervals, and each class inter- val is assigned a color. 
Each county in the map is then displayed in the color corresponding to its value. The statistical distribution 
of the data may also be shown in histogram form as the number of counties vs the unemployment value (Figure 
3). Another example of a US map, in this case the average property tax per capita in 1967, is shown 
in Figure 4. Note that the top class in this map corresponds to a rather broad range, from $172 to $1088. 
This is due to the class interval assign- ment algorithm, which attempts to give the map a balanced appearance 
by choosing class interval boundaries such that each class contains approxi- mately the same number of 
counties. In Figure 5, the range $150-$1088 has been expanded into six classes (again using the equal 
class algorithm), and the remaining counties within the range $3- $150 have been compressed into a single 
class. Due to the highly interactive nature of the system (single variable maps are typically displayed 
with- in four seconds), the user/analyst may easily mod- ify class assignments in this manner to study 
and highlight relationships. The system may also be used to display Stan- dard Metropolitan Statistical 
Areas (SMSA's) by census tract. Fifteen SMSA's are currently in- stalled on the system. As an example, 
Figure 6 shows the 1970 unemployment in Chicago. Since the definition of census tract boundaries is based 
on population, the more highly populated urban areas have smaller census tracts and are thus difficult 
to interpret at the resolution shown. The system was therefore designed to interactively expand or zoom 
selected areas. SMSA areas may be expanded by a factor of 2 or 4. (Figure 7 shows a factor of 4 expansion 
of Chicago.) Portions of the U.S. map may be expanded by a factor of 2, 4, or 8. After selection of an 
ex- panded area, additional statistics may be displayed (Figure 8). Bivariate displays modelled after 
the Census Bureau products described in (3) may also be produced showing the geographic dependence of 
two variables. Figure 9 shows the U.S. population change by county from 1960 to 1970 vs the estimated 
population change from 1970 to 1975. In reading this map, the slanted axis on the color diamond legend 
corresponds to the top title on the display, in this case the population change from 1960-1970. The vertical 
axis on the legend corresponds to the bottom title, population change from 1970-1975. This map is shown 
in simplified form in Figure i0. In this example, both variables have been displayed in two classes 
with a breakpoint at zero. The resulting four-color map shows counties that lost population in both periods 
in red. Counties shown in green lost population from 1960 to 1970, but gained from 1970 to 1975. Conversely, 
counties shown in yellow gained population from 1960 to 1970, but lost from 1970 to 1975. Individual 
states may also be displayed by county, as shown in Figure ii. This bivariate map of population change 
in North Carolina shows an additional capability, the overlay of Congressional District boundaries (shown 
in white). While both examples of bivariate maps discussed here involve trends in a single statistic, 
this medium is equally effective in showing the relationship be- tween two different statistics. Other 
system features include color change and computation capabilities. In using the color change feature 
for single variable displays, the user is presented with a pallette (Figure 12) of 56 available colors 
identified by numbers. The current class interval color assignments are shown to the right of the pallette 
and identified by letters. By typing an assignment statement (for example, F=39), the user can change 
the color of any class interval to any of the 56 colors and immediately see its effect on the display. 
This feature is extremely useful for highlighting inter- esting ranges of the data and for locating anoma- 
lies or errors. The computation capability enables the user to add, subtract, multiply, or divide, any 
two variables to create a new variable. This feature is frequently used to determine percentages or to 
convert county totals to per capita values. Oper- ations may be chained to display more complex relationships. 
 Finally, it is important to note the user interface to the system. One of the foremost design criteria, 
second only to the interactive speed requirement, was ease of use by the policy analyst not trained in 
computer use. The entire system is menu-driven. At each point in a session, the user is prompted with 
a numbered list of appropriate options and asked to select the de- sired option by number. (An example 
is shown in Figure 13.) The result is a system that can be used effectively by the casual user or by 
the novice with a few minutes of orientation. In the next sections, the AOIPS hardware, particularly 
the image analysis terminal, will be discussed in greater detail, followed by a des- cription of the 
structure and operation of the bIDS software. AOIPS Hardware AOIPS is an interactive system developed 
to aid in the extraction and analysis of information from satellite and aircraft imagery for meteoro- 
logical and earth resources applications. The major components of the system are two image analysis terminals 
(Figure i) controlled by PDP-II/70 minicomputer. One 176 megabyte RP06 disk drive and three 88-megabyte 
RP04 drives pro- vide on-line storage capacity. Three standard 800/1600 bpi tape drives and one High 
Density Digital Tape drive (20,000 bpi, 14 track) are also interfaced to the computer. The image analysis 
terminals are extremely flexible and perform a variety of image manipula- tion operations at TV-refresh 
rates (i/30th second). Each terminal consists of five digital refresh memories, mapped through digital 
matrix switches to look-up tables and high resolution TV displays. Each refresh memory consists of 512 
lines of 512 8-bit picture elements, or pixels.  A schematic diagram of the terminal components is 
 shown in Figure 14. By configuring the various matrix switches, lookup tables, and other terminal registers 
under computer control, the terminal can be used to perform the following operations: [11!116111: 
o False color displays I o Time lapse displays t SELECTS.SA o Image translation -vertical and horizontal 
offsets o Image scrolling  o Split screen displays -rectangular subareas  I of different refresh 
memories may be composited into a single display o Iterative processing -the output of any lookup table 
may be re-recorded back into a re- USE~SELeCT=ONa~EMPLOY~ENXPATXeRNS~ USERSeLeCTION fresh memory for 
further processing, and ~J o Graphic overlay of boundaries and annotatio~ These image analysis terminal 
capabilities FIGURE 13. MENU SELECTION SEQUENCE USED TO REQUEST DISPLAY will be discussed further in 
the next section in OF UNEMPLOYMENT IN CHICAGO AS SHOWN IN FIGURE 6 the context of DIDS operation. The 
AOIPS system, the image analysis terminals, and other applica- tions are described more fully in (4). 
 CONTROL INPUTS/ OUTPUTS GRAPHICS INPUTS ..... .... .... S o,::lTT.r._ [ 0BIT FACE LINE DRIVERS Ill]i 
..... 75~Z COLOR VIDEO OUTPUTS 111-2 ~ TABL~ j FADE CONTROL I. I SYNC. CO~(I~JTE R TO DtSC VIDEO 
DISC RECORDER 75~Z RECORDER INPUT IMAGE DATA RETURN TO COMPUTER OR RE-RECORD VIDEO CAMERA ICONVERTERI" 
VARIABLE GAiN &#38; OFFSET AMP.  ~ B-W TO TV REFRESH MON-OUTPUT TO &#38; FROM ITOR SYSTEM I LIGHT PEN 
BW MON ITOR B-W MON,ITOR TIMING SIGNALS TO MANIPULATION HARDWARE ~ 8.w MON ~ CONTROL INPUT/OUTPUT ITOR 
FIGURE 14. Block Diagram of Image Analysis Terminal Components DIDS STRUCTURE AND OPERATION shown in 
Figure 16. Choropleth map generation For the US and each of the SMSA maps, the Census Bureau provided 
(a) the county/census tract boundary definitions and (b) the data values: 256 variable values for each 
of 3106 counties and 443 variable values for each census tract. The primary design goal was to display 
any selected variable value on any selected map within i0 seconds of a request. In order to achieve this 
goal, the sys- tem was designed such that as much work as possible was performed in the image analysis 
terminal described in the previous section.  Previous experience had shown that by storing 512x512 8-bit 
raster images in contiguous disk files on an RP04 and by double buffering multiple line transfers, a 
image could be displayed in less than one second. The basic concept chosen, there- fore, was to represent 
the geographic maps (US by county and SMSA's by census tract) as raster images, with each geopolicical 
unit identified by a unique gray level. A lookup table could then be computed based on a selected statistic 
or variable, and, by passing the geography image through the 8-bit lookup table in the terminal hardware, 
a gray level variable map could be produced, with the brightest value (255) corresponding to the highest 
variable value, and the darkest value (6) corresponding to the lowest variable value. (Values 0 through 
5 were reserved for background and boundary defini- tions.) The resulting gray level map could then be 
configured through color lookup tables in the terminal to produce the choropleth map display. This process 
is shown conceptually in Figure 15. DATA COLOR VALUES TABLE IMAGE TERMINAL ! ANNOTATION GENERATION CLASSINTERVALASSIGNMENT 
DEC POP11/70 _ ~ COLOR ASSIGNMENT COMPUTATIONALFUNCTIONS -MENUCONTROL USER MENU SELECTION I CENSUS DATA 
BASE  FIGURE 15. DOMESTIC INFORMATION DISPLAY SYSTEM OPERATION While this straightforward approach was 
suf- ficient for state images, the 3106 counties of the US (and the census tracts of each SMSA) cannot 
be represented in the 8-bits of a single image memory. The US and SMSA maps were therefore represented 
in two 8-bit images, and an iterative algorithm was developed to process the 3106 gray levels 255 at 
a time using an 8-bit lookup table, and using the re-record feature of the terminal to compose inter- 
mediate results in a third memory. This process is ,i,,, stEP2 t~E PAR,,AL MAP ~Or Z~ COUnt,~S FIGURE 
16 GRAY LEVEL VARIABLE MAP GENERATION THE STEPS SHOWN ARE REPEATED 13 TIMES TO PROCESS 3106 COUNTIES 
Legend Display Once a gray level variable map has been pro- duced, the default class interval limits 
(based on the equal county distribution algorithm) are translated into gray level map values, and color 
lookup table values are generated for the red, green, and blue components of the desired map colors. 
The legend is formed in the following steps: a. A gray level wedge is generated in the fourth memory 
with one block for each class, con- taining the highest gray level in that class. b. The gray level 
map is shifted left, the wedge is shifted right, and the split screen function of the terminal is used 
to combine the two into a single image. (This results in an effective display width of 704 pixels.) 
 c. The split screen image is routed through the red, green, and blue color tables to the monitor.  
d. Finally, the image title and color wedge annotation are written to one of the bit planes of the fifth 
memory and inserted in the image using the graphic overlay function.  This color image formation process, 
shown in Figure 17, is typically performed within four seconds. Bivariate map generation The bivariate 
map displays are produced by first generating two single variable gray level maps, and then combining 
them using the lookup tables and the re-record function. A diamond legend is transferred from disk to 
the fifth mem- ory, and a color composite image is formed as described above.  231 Data Structures 
 COLOR LOOKUP MEMORY 3 TABLES G~y~EvEIp s .... ' l L~FT T MEMORY 4 COLOR MAP R CLASS INTERVAL GRAY 
LEVEL WEDGE N SHIFT RIGHT MEMORY 5: ANNOTATION DtSPLAY TITLE LEGEND = SHIFT RIGHT  FIGURE 17, COLOR 
MAP DISPLAY GENERATION Zoom Operation The zoom process is shown in Figure 18. Each of the higher resolution 
maps (i024xi024, 2048x 2048, and 4096x4096 for the U.S., i024xi024 and 2048x2048 for SMSA's) is stored 
in TV sized (512x 512) segments for rapid access. The user identi- fies an area to be expanded by positioning 
a box cursor over the area on an overview map of the entire US (or SMSA), and by selecting the desired 
expansion factor. The required four map segments are transferred from disk to the terminal memories, 
and as shown in Figure 18, are shifted to form a complete map at the higher resolution, centered on the 
selected area. The selected TV-sized area thus formed is re-recorded back into one of the memories and 
saved on disk. This process is re- peated for both 8-bit portions of the 16-bit geo- graphic base image. 
Finally, the two 8-bit zoom segments are restored to memories i and 2, and the color map display is produced 
exactly as described earlier. The entire process is com- pleted in less than 15 seconds. FOUR HIGHER 
RESOLUTION QUADRANTS 1 3 2 4 AREA TOBE DISPLAYED EXPANDED~ AREA FIGURE18. ZOOM PROCESS In order to provide 
rapid access to the sta- tistical data for merging with the map base as previously described, census 
data was preprocessed into an optimized internal format. Each statis- tical variable is stored in a file 
under the RSX- liD operating system as a list of floating point numbers, one value for each county or 
census tract displayed. A corresponding list of scaled gray level values (a da~a value lookup table) 
was also created and stored in the file for rapid process- ing by the image analysis terminals. The data 
selection menus are disk resident. Each record of the menu file describes a statistical variable available 
for display and identifies the name of the file containing that variable. Current Work The DIDS system 
is currently being utilized by 15 Federal agencies through September 1979 in a one-year evaluation of 
its effectiveness in an analysis and policy-making environment. Data bases and analytical tools are being 
added to increase the system's utility and the range of its applications. Because the system as described 
here was developed for demonstration purposes, maximum use was made of existing hardware and software. 
Con- sequently, part of the system development effort during the evaluation period is directed toward 
developing improved techniques and algorithms specifically for the interactive display of color choropleth 
maps. For example, during the demonstrations of the system at the White House and the Capitol, a high 
resolution color monitor at the demonstration site was driven by separate red, green, and blue sig- nals 
transmitted over three 13 MHz video microwave/ video cable links from the image analysis terminal at 
Goddard. Because of the high cost of video communications, consideration is being given to the requirements 
and functional characteristics of low cost remote terminals. The use of raster images to represent geo- 
political boundaries is extremely inefficient. For example, storage of the US map in this form at four 
levels of resolution requires 42.5 mega- bytes. Optimized rapid access compression tech- niques are therefore 
being developed to reduce the on-line storage requirements. Preliminary results are very encouraging 
and indicate that the current interactive rates can be maintained with a ten- fold reduction in geographic 
storage requirements. Acknowledgements The authors would like to acknowledge the outstanding software 
development efforts of Mr. Roy Borgstede (Bureau of the Census), Dr. Jeffrey Chen (General Software Corporation), 
Mr. Gene Cyprych, and Ms. Martha Szczur (Computer Sciences Corporation). Without their hard work and 
unselfish commitment, the successful and time- ly demonstration of this system would not have been possible. 
 232 The authors would also like to acknowledge the substantial contributions of Mr. Fred Broome (Bureau 
of the Census), Mr. Joseph Johns, Mr. Chris Bock, and Mr. Phil Yu (NASA/Goddard Space Flight Center),and 
Ms. Dolly Helfer (Computer Sciences Corporation). REFERENCES i. Harden, R. The Presidency in the Information 
Age: A Philosophy for Managing Information, Bulletin of the American Society for Infor- mation Science, 
Vol. 5, No. 2, (Dec. 1978), p. 13. 2. Zimmerman, E., The Presidency in the Infor- mation Age: Planning 
and Outreach, Bulletin of the American Society for Information Science, Vol. 5, No. 2, (Dec. 1978), pp. 
19-21.  3. Meyer, M. A., Broome, F. R., and Schweitzer, R~H. Color Statistical Mapping by the U.S. Bureau 
of the Census, The American Cartographer, Vol. 2, No. 2, (1975), pp. 100-117.  4. Bracken, P. A., Dalton, 
J. T., Quann, J. J., and Billingsley, J. B., AOIPS-An Interactive Image Processing System, National Computer 
Conference, (1978), pp. 159-171.  5. Brassel, K. E., Utrano, J. J. and Hanson, P.O. The Buffalo Crime 
Mapping System: A Design Strategy for the Display and Analysis of Spatially Referenced Crime Data, SIGGRAPH-ACM 
Computer Graphics, Vol. ii, No.2, (July 1977), pp. 78-85.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807449</article_id>
		<sort_key>234</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[The shaded surface display of large molecules]]></title>
		<page_from>234</page_from>
		<page_to>236</page_to>
		<doi_number>10.1145/800249.807449</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807449</url>
		<abstract>
			<par><![CDATA[<p>The complexity of computer generated images is often restricted by the storage requirements of the data and the processing time in keeping it sorted. A method is presented which alleviates the burden of storing and sorting for one previously published hidden surface algorithm.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Data structures]]></kw>
			<kw><![CDATA[Hidden surface removal]]></kw>
			<kw><![CDATA[Molecular graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334069</person_id>
				<author_profile_id><![CDATA[81100437425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[K]]></middle_name>
				<last_name><![CDATA[Porter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ampex Corporation, Redwood City, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Clark, J.H. Hierarchical geometric models for visible surface algorithms. Communications of the ACM 19, 10 (October 1976), 547-554.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[De Meyts, P., Van Obberghen, E., Roth, J., Wollmer, A., and Brandenburg, D. Mapping of the residues responsible for the negative cooperactivity of the receptor-binding region of insulin. Nature 273, 5663 (15 June 1978), 504-509.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Feldmann, R.J., Bing, D. H., Furie, B.C., and Furie, B. Interactive computer surface graphics approach to study of the active site of bovine trypsin. Proceedings of the National Academy of Science 75, 11 (November 1978), 5409-5412.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907365</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Newell, M. The utilization of procedure models in digital image synthesis. Ph.D. Thesis, University of Utah, Salt Lake City, Utah, 1975.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Perutz, M. F. Hemoglobin structure and respiratory transport. Scientific American 239, 6 (December 1978), 92-125.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>639789</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Porter, T. K. Spherical shading. Siggraph 1978 proceedings.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 THE SHADED SURFACE DISPLAY OF LARGE MOLECULES Thomas K Porter Ampex Corporation Redwood City, CA Abstract 
 The complexity of computer generated images is often restricted by the storage requirements of the 
data and the pro- cessing time in keeping it sorted. A method is presented which alleviates the burden 
of storing and sorting for one previously published hidden surface algorithm. KEY WORDS AND PHRASES: 
computer graphics, hidden surface removal, data structures, molecular graphics. CR CATEGORIES: 3.12, 
8.2 Introduction Several bottlenecks serve to limit the complexity of scenes computed by hidden surface 
algorithms. Newell (4) cites storage capacity, processing requirements, and restrictions on the scene. 
The. increased detail of the data base describ- the scene must be stored appropriately and sorted as 
needed in the hidden surface computation. Clark (i) encourages the development of more structured methods 
for managing the increased data. In this short note, we shall examine the method used by one algorithm 
to alleviate the storage and processing restrictions in order to accommodate truly complex images over 
the limited environment of spheres. Work described in this paper was per- formed while the author was 
employed at the National Institutes of Health, Bethesda, MD. Background A computer graphics system 
at the National Institutes of Health is used for research in molecular structure. Stick figure diagrams 
representing the molecular bonds are created and rotated on a three dimen- sional vector display. Transformed 
coordinates may then be passed along to a routine for displaying spheres on a frame buffer. The frame 
buffer is a static 512 by 512 memory, with 8 bits of information at each picture element used as an index 
into a table of colors. Several researchers (2,3,5) have used the system for visualizing and investigating 
the surface characteristics of protein structure. The thrust of their activity is the development of 
heuristics governing the surface interactions of macromolecules with substrates and inhibitors. Research 
 into i0,000 atom macromolecules has been hindered because the surface display routine was limiting the 
data to less than 2000 primitives. Many images have been produced of clipped subsections of mole- cules; 
in other pictures, spheres are used to represent whole amino acids. This was the motivation for returning 
to the pro- blem of structuring-the data in the sur- face display routine. Method The shaded surface 
algorithm (6) proceeds scan line by scan line, using a compact representation for spheres. Five words 
 (x,y,z,radius,type) are required for each sphere, and five more (link,xleft, deltaleft,xright,deltaright) 
are retained for linking each active sphere and track- ing its perimeter throughout the hidden surface 
process. Spheres are initially bucket-sorted into lists of spheres which become active at the same scan 
line. At each scan line, we must add these spheres to the list of already active spheres. Our technique 
for reducing storage restrictions is the use of the frame buffer itself for intermediate storage of the 
bucket-sorted sphere information. The &#38;#169;1979 ACM 0-89791-004--4/79/0800--234 $00.75 See Copyright 
Pg. 234 transformed data is written onto the scan line where it will enter the hidden surface process. 
The 512 bytes of a scan line can accommodate fifty-one (51) five- word packets of sphere information. 
The remaining two bytes are used to point to the next available space as the bucket sort progresses. 
Only 480 of the 512 lines of the memory are visible, with three lines allotted for the color table. This 
leaves twenty-nine (29)lines of overflow area in case individual scan lines are not sufficient. With 
this strategy, we are able to give consideration to a maximum of 26,000 spheres. Given the uncertain 
distribution of atoms within molecules, the fixed nature of this storage technique makes it practical 
for molecules of somewhat lower complexity. For globular proteins of 16,000 atoms, we expect about fifty 
(50) atoms entering at the most congested scan lines(see Appendix). A molecule of this structure and 
size should not exhaust the available overflow area. We must consider the sorting problems encountered 
in our attempts to handle such data. The initial bucket sort is linear in the total number of atoms, 
so it does not grow disproportionately relative to the timing of the rest of the algorithm. As we process 
each scan line, we retain a list of active spheres, sorted from back to front. This is necessary to ensure 
that overwriting of the silhouette edges occurs in proper sequence. This list is traversed at each scan 
line in order to update positional information about the perimeters and compute the image. Com- pleted 
spheres are dropped from the list and the new spheres are added. This is the problem of merging a small 
number of unsorted keys into a large list of sorted ones. The problem is simplified because the list 
is to be traversed. Our solution is to sort the new spheres into their own linked list and merge that 
list in during the traversal. The sorting of small lists is relatively cheap, and the merge is almost 
free. Note that a horizontal chain of collagen provides a worst case through this algo- rithm. A 3000-atom 
structure small enough to intersect the picture at only ten scan lines would force 300 new primi- tives 
at each scan line. That would exhaust the intermediate storage capacity of those scan lines and the overflow 
area. A more general approach to handling over- flows could relieve this problem. However, the sorting 
costs for these long lists of new spheres would dominate the computation of the image anyway. This indicates 
why diagonal displays of collagen molecules are preferred. Conclusion We are able to produce molecular 
images of far greater complexity. The sorting pro- blem does not burden us in our attempts to compute 
complex scenes. We are able to handle 20,000 primitives per scene and retain 1800 active primitives per 
scan line in core. The technique of using the frame buffer as auxiliary memory is exploited to manage 
the data. Acknowledgements The author would like to thank Gary Knott for discussions about the algorithm 
and Richard Feldmann and Benes Trus for providing the molecular coordinate area. Appendix Assume random 
distribution of N atoms of radius R throughout a displayed spherical volume. The probability that an 
atom is centered at a scan line is the fraction of the sphere visible on that scan line. This is approximately 
 u (M 2 - y02) ~ M 3 3 where y0 is the distance in y between this scan line and the center of the sphere. 
The number of atoms P centered here is 3 (M 2 - y02) N 4M 3 This attains a maximum at y0=0, where 
 p~ 3N 4M For 16,000 atoms covering the whole screen (N = 16,000, M = 240), P = 50. References I. 
Clark, J.H. Hierarchical geometric models for visible surface algorithms. Communications of the ACM 19,10 
 (October 1976), 547-554. 2. De Meyts, P., Van Obberghen, E., Roth, J., Wollmer, A., and Brandenburg, 
D. Mapping of the residues responsible for the negative cooperactivity of the receptor-binding region 
of insulin. Nature 273,5663 (15 June 1978), 504-509.  3. Feldmann, R.J., Bing, D. H., Furie, B.C., and 
Furie, B. Interactive computer surface graphics approach to study of the active site of bovine trypsin. 
Proceedings of the National Academy of Science 75,11 (November 1978), 5409-5412.  235 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807450</article_id>
		<sort_key>237</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[A network graphical conferencing system]]></title>
		<page_from>237</page_from>
		<doi_number>10.1145/800249.807450</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807450</url>
		<abstract>
			<par><![CDATA[<p>A network-oriented color graphical conferencing system is being built by the Information Sciences Dept. of the Rand Corporation. This system is designed to allow several people to confer simultaneously over a network. Users share a common display, which is divided into sections: an individual section (or &#8220;window&#8221;) for each user, and a common graphical &#8220;blackboard&#8221; window where the users may take turns sketching out and modifying a graphical display in full color. The display uses bit-map color raster-scan technology.</p> <p>Each user's private window is identified with that user's name and location. Text typed by a user appears in his window as he types it. Several users may be typing text simultaneously. A special symbol appears in the window of a user who is sketching to indicate who is drawing the picture.</p> <p>Several conferences may be going on at the same time; users may request a menu page showing who is participating in which conferences. Conferences may be &#8220;locked&#8221; to prevent others from joining.</p> <p>The system makes use of other Rand-developed utilities for the design and display of arbitrary characters, as well as Rand's Virtual Terminal UNIX (TM) operating system.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color graphics]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Computer networks]]></kw>
			<kw><![CDATA[Interactive graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.4.3</cat_node>
				<descriptor>Computer conferencing, teleconferencing, and videoconferencing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003282.10003286.10003291</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web applications->Internet communications tools->Web conferencing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P332465</person_id>
				<author_profile_id><![CDATA[81406599560]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[O'Brien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Rand Corporation, Santa Monica, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A NETWORK GRAPHICAL CONFERENCING SYSTEM Michael T. O'Brien The Rand Corporation Santa Monica. CA 90406 
Key words and phrases: computer networks, computer graphics, color graphics, interactive graphics Computing 
Reviews categories: 3.81, 4.9, 8.2 ABSTRACT as Rand's Virtual Terminal UNIX (TM) A network-oriented color 
graphical operating system. conferencing system is being built by the Information Sciences Dept. of the 
Rand Corporation. This system is designed to allow several people to confer simultane- ously over a network. 
Users share a common display, which is divided into sections: an individual section (or "window") for 
each user, and a common graphical "black- board" window where the users may take turns sketching out 
and modifying a graph- ical display in full color. The display uses bit-map color raster-scan technology. 
Each user's private window is identi- fied with that user's name and location. Text typed by a user appears 
in his window as he types it. Several users may be typ- ing text simultaneously. A special symbol appears 
in the window of a user who is sketching to indicate who is drawing the picture. Several conferences 
may be going on at the same time; users may'request a menu page showing who is participating in which 
conferences. Conferences may be "locked" to prevent others from joining. The system makes use of other 
Rand- developed utilities for the design and display of arbitrary characters, as well IThis work is being 
supported under the ACCAT (Advanced Command and Control Archi- tecture Testbed) program of the Department 
of Defense Advanced Research Frojects Agency. &#38;#169; 1979 ACM O-89791-004--4/79/0800--237 $00.75 
See Copyright Pg. 237
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807451</article_id>
		<sort_key>238</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[A building block approach to color graphics]]></title>
		<page_from>238</page_from>
		<page_to>245</page_to>
		<doi_number>10.1145/800249.807451</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807451</url>
		<abstract>
			<par><![CDATA[<p>Graphics and imaging are important in scientific, academic and industrial environments. In the past graphics systems have been used with large computers and were only available to a minority of users. The relatively small and specialized use of graphics has inhibited sharing of software and prevented standardization necessary for widespread use. Dense semiconductor memory has recently become easily available in large quantities and makes high resolution graphics and imaging systems feasible. The concepts leading to the design of the present system come from the need to provide a large number of graphic and imaging functions, in a compact form, to a commonly used microprocessor bus. Three fundamental functions are implemented: a video frame digitizer, an image memory, and an output video generator. Video images can be digitized in one frame time with a precision of 1, 2 or 4 bits per pixel. The video generator can display the images in gray levels or in color. The software selectable system parameters include a variety of image formats, video output controls, digitization commands, addressing modes, vertical image offset, and lightpen controls. A novel contouring digitization mode is useful to reduce images obtained in gray scale to outline form. Such real-time preprocessing reduces memory and bandwidth requirements. Photographic illustrations demonstrate various operating modes.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color graphics]]></kw>
			<kw><![CDATA[Frame buffer]]></kw>
			<kw><![CDATA[Imaging]]></kw>
			<kw><![CDATA[Lightpen]]></kw>
			<kw><![CDATA[Photo trigger]]></kw>
			<kw><![CDATA[Rasterscan display]]></kw>
			<kw><![CDATA[S-100 bus]]></kw>
			<kw><![CDATA[Video digitizer]]></kw>
			<kw><![CDATA[Video display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P122511</person_id>
				<author_profile_id><![CDATA[81100537902]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[Robert]]></middle_name>
				<last_name><![CDATA[Flexer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Video Systems, 595 Matadero, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136470</person_id>
				<author_profile_id><![CDATA[81339536137]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wiederhold]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, Stanford University, Stanford, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alan Kay: A Personal Computer for Children of All Ages, Proceedings of the 1972 ACM Conference, August 1972, Boston.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Warren A. Teitelman: A Display Oriented Programmers Assistant, XEROX Palo Alto Research Center report CSC-77-03.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H.S. McDonald, W.H. Nink, D.R. Welle: A Direct View CRT Console for Remote Computing, Digest of Technical Papers, 1967 International Solid State Circuits Conference, Vol. 10, pp. 68-69.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. J. Agin: An Experimental Vision System for Industrial Applications, Proceedings of the 5th International Symposium on Industrial Robots, Soc. of Manufacturing Engineers, Dearborn, Mich. 1975, pp. 135-148.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>892176</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Tom McWilliams: SCALD, Structured Computer-Aided Logic Design, Stanford University CSD report 78-665, May 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M.L. Dertouzos: Character Generation from Resistive Storage of Time Derivatives, Proceedings of the 1969 FJCC, AFIPS Vol. 35, pp. 561-568.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ivan C. Sutherland: SKETCHPAD: A Man-Machine Graphical Communication System, MIT Lincoln Laboratory TR 296, May 1965.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[W.J. Sanders, G. Breitbard, D. Cummins, R.F. Flexer, K. Holtz, J. Miller, and Gio Wiederhold: An Advanced Computer for Medical Research, Proceedings of the 1967 FJCC, AFIPS Vol. 31, pp. 497-509.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gio Wiederhold: Setting Up a General Purpose Data-Acquisition System, Proceedings of the IBM Symposium on Computers in Chemistry, IBM DPD 1967, pp. 249-264.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C.M. Theiss: Computer Graphics Displays of Simulated Automobile Dynamics, Proceedings of the 1969 SJCC, AFIPS Vol. 34.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Robert L. Beckermeyer: Interactive Graphics Consoles, Environment and Software, Proceedings of the 1970 FJCC, AFIPS Vol. 37, pp. 315-323.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. Levinthal: Molecular Model Building by Computer, Scientific American, Vol. 214, 1966, pp. 42 ev.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A.M. Tometsko: Computer Approaches to Protein Structure, Viewing Models of Proteins from the Inside, Computers and Biomedical Research, Vol. 5, No. 5, 1972, pp. 460-472.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ronald R. Resch: The Topological Design of Sculptural and Architectural Systems, Proceedings of the 1973 FJCC, AFIPS Vol. 42, pp. 643-650.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mitch Model: Monitoring of Programming Systems, Stanford University CSD, Ph.D. Thesis.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[D.L. Vickers: The Sorcerers Apprentice: Head Mounted Display and Wand, Utah Univ. CSD report UTEC CSC 74-078, 1974.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[W.M. Newman and R.F. Sproull: Principles of Interactive Computer Graphics, McGraw-Hill 1973.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>365258</ref_obj_id>
				<ref_obj_pid>365230</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. Narasimhan: Syntax Directed Interpretation of Classes of Pictures, Comm. of the ACM, Vol. 9, March 1966, pp. 166-173.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ronald R. Morrison: Graphic Language Translations with a Language Independent Processor, Proc. 1967 FJCC, AFIPS Vol. 31, pp. 723-731]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Pierre J. Lebeux: Frame Selection Systems and Languages for Medical Applications, Univ. of Calif., San Francisco, Lab. for Medical Information Science Tech. Report 7, 1974.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Norwood: Introduction of a User-Oriented Total Hospital System into a Community Hospital, Introduction and System Description, Proceedings of MediInfo 1974, IFIP, pp. 295-298.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A BUILDING BLOCK APPROACH TO COLOR GRAPHICS J. Robert Flexer, Digital Video Systems, 595 Matadero, Palo 
Alto, CA 94306 Gio Wiederhold, Computer Science De~ari~nent, Stanford University~ Stanford~ CA 94305 
 ABSTRACT Graphics and imaging are important in scientific, academic and industrial environments. In 
the past graphics systems have been used with large compu- ters and were only available to a minority 
of users. The relatively small and specialized use of graphics has inhibited sharing of software and 
prevented standardization necessary for widespread use. Dense semiconductor memory has recently be- come 
easily available in large quantities and makes high resolution graphics and imaging systems feasible. 
The concepts leading to the design of the present system come from the need to provide a large number 
of graphlc and imaging functions, in a compact form, to a commonly used microprocessor bus. Three fundamental 
functions are implemented: a video fnamedigitizer, an image memory, and an output video generator. Video 
images can be digitized in one frame time with a precision of l, 2 or 4 bits per pixel. The video generator 
can display the images in gray levels or in color. The software selectable system parameters include 
a variety of image formats, video output con-trols, digitization commands, addressing modes, vertical 
image offset, and lightpen controls. A novel contouring digitization mode is useful to meduce images 
obtained in gray scale to outline form. Such real-time preprocessing reduces memory and bandwidth requirements. 
Photographic illus- trations demonstrate various operating modes. KEY WORDS: color graphics, imaging, 
frame buffer, video digitizer, video display, S-IOQ bus, rasterscan display, lightpen, photo trigge~ 
CR categories 8.2, 6.35, 3.81. INTRODUCTION The adage that "a picture is worth a thousand words" is well 
accepted by the computing community, although only a fortunate few have had access to devices which provide 
adequate graphic interaction. Visitors to laboratories where facilities for graphics are available leave 
with the distinct impression that if such tools would become avail- able to them their productivity and 
enjoyment of computing would increase significantly. An example of an environment where such activity 
takes place is XEROX Research in Palo Alto where convincing educational (1) and programming projects 
(2) are supported using distributed computers which have bitmap display devices using the computer's 
main memory. The cost of storing images that way has been one factor in the slow dissemination of graphics 
capability in commonly availabe computers. Older systems used bit maps stored on tracks of drums (3), 
and these have been used in situations where digitized images are analyzed for robot con-trol (4) and 
in advanced circuit design (5). The use of drum tracks for picture storage makes the storage support 
per display economical if there is justification for at least several dozen displays in close proximity, 
which will share the storage drum. Less storage is needed if vectors are stored since then only the coordinates 
of the end points are placed in memory. A vector generator trans-lates the coordinates into a signal 
which is then drawn on a high quality X-Y CRT screen (6). This mode of operation was already available 
in 1958 (7). Certain graphics applications lend themselves very well to vector displays. We have had 
good experiences with interactive curvefitting (8,9). Applications in interactive design (lO,ll), anal-ysis 
of three dimensional objects as molecular structures (12,13), and architectural drawings (12) have been 
well served by these devices. These applications distinguish themselves by the fact that the original 
source of the data to be dis- played is given as coordinates in spaoe, and the transformation to an image 
is relatively straight- forward. When the source of the data is an image, as obtained by a camera or 
a scanner, then vector-oriented dis- plays are of little help until the image is reduced to a much simpler 
abstraction composed of lines or contours. In order to effectively display images a matrix of picture 
elements has to bedisplayed, and each picture element (pixel) has to be dis- played at a particular brightness. 
Any matrix-like image will present diagonal' lines by a staircase- like approximation. More pixels per 
image improve the quality. Commercial TV technology provides a standard here, even though pictures as 
seen on broadcast television rarely reach the desired level of quality. The specifications for TV include 
the use of 480 horizontal raster lines, which are dis- played using two successive fields of 240 inter- 
laced lines each. The signal being displayed is an analog signal, but we can derive from the aspect ratio 
(width/height, 4/3) of the TV picture frame that 640 pixels per line will be appropriate. The number 
of levels of brightness or gray scale per pixel is not specified, although 256 levels, as can be produced 
using eight bits per pixel, make the result indistinguishable from an analog image, In practice, most 
computer-based equipment @ 1979 ACM O-89791-004~4/79/0800--238 $00.75 See Copyright Pg. 238 attempts 
to reach that level in terms of raster or gray scale resolution. Useful and pleasing images can in fact 
be generated using half of the raster lines (one field) and only 4 bits per pixel to re-present 16 levels 
of gray scale+ Similar relationships exist for color display. Whereas true color has high requirements 
for proper representation, the addition of simple color cues can often greatly enhance the presentation 
of data. EFFECTIVENESS OF GRAPHICS The power of graphics to communicate can be consid- ered as being 
due to the ability to create symbols with deep semantic meaning. Pictures of faces, structures, cress-sections, 
etc. are perceived as having few, but significant, symbols and convey complex concepts. If we trust the 
rule that human short-term memory is limited to seven plus or minus two symbols, then it becomes clear 
that a represen- tation using fewer symbols is advantageous (15). At a high level of abstraction a certain 
amount of information becomes much easier to manipulate con- ceptually by the viewer at the display terminal 
than the same information when it is represented by a greater number of simpler symbols. An obvious example 
is a function represented by a line versus a list of numbers; a more interesting example is the use of 
Chernov-faces, where multi-dimensional data is represented by the degree of a smile, the roundness of 
the face, the angle of the eyebrows, etc.; color might add yet more information. A further dimension 
of information can be added if the display can be varied over time. Significant computing resources are 
needed to rotate even a simple picture, but the effect of interaction with a three-dimensional image, 
due to the high rate of information transfer, is spectacular (16). Graphics hence represent the potential 
for an increase of several orders of magnitude of bandwidth in man-machine communications. BARRIERS TO 
USING GRAPHICS We believe that the main cause for the low level of graphics use is due to the high entry 
cost. Where graphic facilities are justifiable they have been effective, but such justification has rarely 
existed in educational institutions. Facilities to compute with numbers and characters are avail- able 
at every level of computer education, but only a few computer science and engineering graduate students 
have had reasonable access to graphics. The use of a printer to display Snoopy can only discourage the 
use of graphic methods, especially when the image has to be entered with keypunched cards. Graphic manipulation 
is hence rarely taught within a regular computer science curriculum, there are few good textbooks (17), 
and because of the lack of broad interest formalization of graphic tasks has not had the attention that 
other computer science topics have enjoyed. Since the community which was able to justify graph-ics is 
more specialized, no graphic-oriented soft- ware has achieved the broad acceptance of FORTRAN or even 
of FORMAT statements, or the simple elegance of a PASCAL, although certainly many efforts have been made, 
e.g., (18,19). Only some manufacturers, notably CALCOMP, have provided support packages which would allow 
applications to run on more than one machine type. The lack of standards has inhib- ted sharing of software 
and hence scientific pro-gress. Nearly every site which wishes to support graphics begins at the most 
basic level and develops its own conventions. Systems that use interactive displays for menu selection 
form a sub-area which has seen some high-level efforts. The design of the menu presentation has been 
aided by frame- oriented programming languages, e.g., ref. (20), but frequently these languages are limited 
to tables of coordinates, text, and references to procedures or successor frames. A factor which adds 
to the cost of graphics is the demand on processor time and communication bandwidth when graphics are 
supported from centralized com-puters. To drive even a limited number of menu selection terminals at 
a rate acceptable to physician users requires all resources of powerful computers and high speed (50Kbits/sec) 
communication lines (21). It is even more difficult to support real- time graphic input. If the subject 
to be imaged can move then the image has to be entered into the system at video speeds, which implies 
that the equivalent of 480*640*8 bits have to be transmitted in 1/30th of a second, that is a rate of 
74Mbits/sec. In order to transmit color graphics, two or three times this capability is needed to take 
care of the three components: luminance, hue, and saturation. Commerical TV broadcast equipment actually 
uses only an analog bandwidth of 3.5 MHz; to get studio quality, 5-15 MHz are needed. Much less demanding 
have been input devices such as lightpens, joysticks, trackballs, or tablets, which only enter a point 
at a time and may move a cursor on the display screen. These devices however collect data at rates which 
are not much higher than a typist generates on a keyboard, so that complex images become nearly impossible 
to construct. Most of the technical problems become surmountable as the technology progresses. The important 
barrier of entry cost can be attacked now, and we will describe the methods used in our attempt to make 
a graphic support device which makes a breakthrough in the cost barrier. TECHNOLOGICAL FACTORS The equipment 
cost to support graphics is composed of the cost of the buffer memory needed to store graphic data, the 
actual display cost, the cost of internal and external transmission of the signals, and the cost of miscellaneous, 
but significant, logic and control functions. At high price levels for memory, it was prohibitive to 
store an entire image as a frame of disdrete points and to use the television technique of raster scan 
to display the image. Recent dramatic price reductions for semi-conductor memory make the frame buffer 
economically possible. For a very high quality picture within the TV image (for instance 454*576*8 bits), 
256K bytes of memory are needed; this amount can now be purchased on circuit cards for as low as $4000. 
At these rates, it is no longer economical to use an X-Y CRT and a vector generator. For many applica- 
tions less resolution will be adequate. If for instance no gray scale is required then 32K bytes will 
suffice. A modular approach to the image memory can hence reduce this cost to match the needs. When raster 
scan techniques are used, the existing 239 TV standards are adequate. A system which is able to accept 
and generate standard video signals can directly interface to a~ing piece of TV equipment. All the technological 
goods developed and mass-produced for the TV industry can become peripheral equipment for such a digital 
system. The availability of microprocessors makes it rea-sonable to provide processing capability close 
to the place where the image is used. Microprocessors bring the possibility to carry out economically 
the functions needed for the image processing`, "and are available at various performance levels. When 
the processors are close to data sources the pro- blems due to high external data communication bandwidth 
are reduced; image-processing functions are controlled through the processor and can be initiated through 
standard remote-terminal access mechanisms. A number of bus conventions for micro- computer connections 
have become popular, and a competive market exists where many types of devices are available from a wide 
selection of manufactur- ers. Devices to support graphics should hence be designed to exploit this situation~ 
so that a full range of complementary components becomes available, since the use of graphics spans the 
entire range of computer applications. There are three immediate consequences if current technology is 
exploited as we have outlined; I. The initial cost and the maintenance costs of the available TV input 
and output equipment are relatively low. 2. If the system is also capable of accepting and converting 
TV signals then standard TV cameras can be used as input devices. If a video pro- cessor has both full 
speed input and output capability then video disk or tape recorders are available to greatly extend the 
!/0 capabilities of digital video systems, 3. If the equipment is sufficiently modular then digital 
computer-controlled graphic process~ ing equipment can be used as a building block for professiona.l 
digital TV studio equipment, This will allow more innovation in computer- controlled image generation 
and processing than is available within the more rigid systems now available to TV stations and laboratories 
where image data are processed,  Given these design conditions we can formulate the overall design 
and the performance objectives for the system components, An imagining system should perform the functions 
shown in Fig, I I fd ,~DEo I o~.xc L vxD~ L, Video Input Real-time image digitizers, or frame buffers, 
which are capable of digitizing black-and~white video information (luminance) in l or 2 field times (I/60th 
or 1/30th of a second), are a recent devel- opment. Fast analog to digital conversion techni- ques have 
begun to make them possible. Since 8-bit converters are yet quite costly, 4-bit and 6-bit converters 
should also be available; indeed, 16 or 64 levels are quite satisfactory for many applica- tions. In 
order not to visibly degrade a video signal in the digitization process, a pixel time of about 75 nanoseconds 
is necessary. Image Buffer The parameters for the design of the image buffer which holds the image frame 
are access speed and capacity. If 8-bit pixels arrive at a rate of one every 75 nanoseconds the access 
speed capability of MOS memory chips is exceeded. It becomes necess- ary to place successive bytes of 
graphic information in parallel into separate banks of memory. With full interlace and 8 bits per pixel 
of digital resolution (256 levels) a monochrome image requires 256K bytes, but buffers of 32K, 64K, and 
128K must be available. Since a variety of uses is foreseen, there must be facilities for a variety of 
image formats when the buffer size places constraints on a 32K buffer may wish to process images of high 
resolution using one level of gray scale (454"576"I), or may wish to give up some resolution in order 
to gain 16 gray levels (227*288*4). Video Output Video output has to provide the possibility of dis- 
playing the following choices: the direct video input (to aid in focusing the camera and setting up the 
scene), the full contents of the graphic buffer, and also partial results only. Since pixels are composed 
of multiple bits it can be desirable to view the contributions made by individual bit com-ponents and 
displaying them together as color components. It may become useful to separate the image components and 
to display them in color, so that auxiliary access to the individual fixed bits should also be possible. 
System Interaction An imagining system only becomes an interactive tool when it can interface with the 
user in variety of ways, suitable to the particular application. A general way to achieve this is to 
allow for full control of the imaging system by a processor. Processor activity should not interfere 
with the acquisition and display of images. The high speed of video graphics requires careful design 
of the interface to ensure that images are complete and not disturbed. For instance when the processor 
initiates a request for image digitization, the imaging unit should wait until the be- ginning of the 
image frame and set a flag when the new image is available for pro- cessing. When photographs of the 
dis- played image are to be taken a similar synchronization is needed so that one 240 and only one image 
is recorded on film. In order to select a point or a subsection of an image it is necessary to be able 
to identify a pixel on the screen. While it is possible to pro-gram a cursor in the image that moves 
on commands from a terminal or joystick, much more rapid inter- action is provided by a lightpen. System 
Configuration It is desirable to have a basic computer-assisted television system complete on as few 
boards as possible. Such a basic system for us is comprised of: I. a four-bit A to D converter, capable 
of full speed video input acquisition; 2. two banks of image memory (32K bytes total) to support the 
resulting maximum data rate; 3. a complete set of image representation choices to support various combinations 
of line resolution and gray scale; 4. a video output capability which matches the video input; 5. an 
interface to a popular microprocessor bus in order to provide access for processing of the graphic image 
and control the operation of the imaging system; and 6. a number of important features such as  lightpen 
and photography support. Other functions in the present design include a mode for the processing of text 
data which allows a denser utilization of the buffer memory, and a facility to digitize contours of the 
image rather than its gray scale levels. It is essential to the building block concept that all the signals 
necessary to increase buffering or functional capacity be available from the basic unit. This includes 
the data and address paths needed for 8-bit conversion, for buffer extension up to 256 K bytes, for auxiliary 
functions, and also the synchronization signals necessary to operate multiple units within one system. 
In order to allow flexibility in processor access the S-lO0 bus was chosen. Only the basic signals from 
that bus are used, so that compatibility with a wide range of processors and peripherals is assured. 
We can now present the actual design of a video imaging system, the CAT-IO0, which was derived from the 
above considerations. ARCHITECTURE OF A VIDEO IMAGING SYSTEM Within the small space limit of two S-lO0 
boards, the system provides a number of interesting inno- vations. It features input capability from 
video signals with a real-time analog to digital con-verter, local image storage in a 32K dedicated buffer 
accessible from the microprocessor for image generation or processing, and a variety of output capabilities 
for video displays. Video Input and Synchronization There are two ways of quantizing incoming video signals. 
Conversion into gray-level pixels is one way, .and the other is via a contouring circuit. The operation 
of the contouring circuit is des- cribed later with the pictorial illustrations. Both the contouring 
circuit and the A to D conver- ter have a maximum output rate of 26Mbits/sec, which yields pixel resolutions 
of 1,280xl bit, 640x2 bits, or 320x4 bits per visible TV line. The system can either accept video synchronization 
(sync) from external video components, or generate it for both internal and external use. The system 
can also extract sync from an incoming video signal. If standard negative composite sync is available, 
it may be fed into the board separately. In both cases, the system is completely synchronized to an external 
source. Buffer Organization Another innovation is the choice of software-con- trolled image formats which 
are provided, in order to optimize memory utilization for various types of imaging applications. Three 
image aspect ratios are offered. Within each aspect ratio, three other parameters can be specified: the 
number of pixels per raster line, the number of raster lines (inter- laced or not interlaced), and the 
number of gray- level bits per pixel. Serial Data Flow In order to easily manipulate pixels of variable 
length and resolution (l, 2 or 4 bits of gray scale) and also to economically integrate both video input 
and video output functions into the same machine, a closed-loop internal serial data path has been implemented 
as shown in Fig. 2. One half of the path is used during digitization, to route the data from the A to 
D into the image buffer via the main shift register. The other half is used during dis- play to route 
the data from the image buffer into the pixel register via the main shift register. Processor Access 
to the Image Buffer Another aspect of the system is the addressing scheme of the 32K image buffer. Since 
the basic unit is designed to be a building block for larger video processing systems, it must allow 
easy ex- pandability of buffer capacity. If the minimum 32K buffer were made directly addressable on 
the S-lO0 bus, it would already consume one half of the available 64K bus address space, and it would 
not be possible to address a 256K buffer. A conven- ient and practical solution has been implemented 
with a fixed address window in the bus space and a movable page in intern~ image buffer space (Fig. 3). 
A 2K-byte window is first defined in the address space of the CPU, to communicate with the image buffer. 
The window's location may be specified on any 2K boundary. In the buffer's internal address space, a 
corresponding page of identical size is also defined. Its internal location is defined by a page address 
specified in an instruction register of the CAT-IO0. Thus, a page of the image buffer appears to the 
CPU as normal RAM located in the window. Any other page may be accessed through the same window in the 
CPU address space; for that purpose, only the internal page address has to be changed. This way, a buffer 
as large as 256K can be made to occupy 2K of bus address space, with a minimal amount of software to 
take care of page changes. 241  ' r" Ic~o ~ c-71 Digitizer #,. s *  Serial 32K Path BUFFER IXSI 
Sw. of  DSW3A/1 xs, %--7 xs, ~ l,e,< VB3 Serial I ~ ~ %~L Idirect ml rXl 3 auxiliary I '-i ss, I .i,/" 
~ vl video outp.ts I Figure 2. ,~&#38;-.... o Buffer Extension window Window Position: S-100 Bus I 
32K Image Buffer Page Position: Software Selected. Switch Selected. I Figure 3. Two-Port Operation The 
image buffer is built with two ports: the three auxiliary outputs. Each of these four out- external port 
for bus access, and the internal puts delivers a standard composite video signal, port for fast video 
digitization or display. and may display an independent image from the This internal video port is given 
priority for buffer. guaranteed access when it is needed; as a result, the displayed images are totally 
clean, stable and The main output is driven by a three-source video free from any processor interference. 
Bus access mixer which allows any combination of up to three to the image buffer is invisible to the 
user. simultaneous images to be superimposed: the direct, unmodified video input; the real-time contoured 
video input; and a digitized image stored in the Video Outputs buffer. The video paths are shown in Fig. 
4. Four video outputs are available: one main and  777I i L OONTO~RL.,-- EXTRACTOR  SYNC I l'i CIRC"IT 
I I .~!aELECTI ~ZD~O II  | v--r-I 'AtD II SYNC SYNO GENERATOR, . . I PZXEL ~ VQ o A I I ..... I 
32K-BYTE I-I ' I GNAr.IC ~ CHARACTER I I BUFFER i-I GENERATOR I ADDRESSING CONTROL AND TIMING Figure 
4. 242  For the main video output, the digitized image always goes through a D to A converter which 
is controlled by five bits, four of which mask the pixel register bits; the last one is the gray-scale 
control bit. When the gray-scale bit is off, the pixel register bits are summed with equal weights. When 
the gray-scale bit is on, the summing weights of the same pixel bits are l, I/2, I/4, and I/8, respectively. 
This yields a 16-1evel digital to analog conversion. Color Output The system can generate a standard 
NTSC color com- posite video signal on the main video output, in- stead of the monochrome B&#38;W signal 
previously described. Eight palettes of 16 colors are avail- able. The leading bit of each pixel controls 
the luminance and the three remaining bits control the hue. It is important to realize that, according 
to NTSC standards, the luminance information reaches the CRT with a relatively wide bandwidth, whereas 
the chrominance information (hue and saturation) is limited to about l MHz. Hence, on a color monitor, 
good resolution can be achieved by acting only on the luminance bit from one pixel to the next one; on 
each TV line; the three chrominance bits should be allowed to change slower in order to obtain best results, 
typically every other or every third pixel only. In other words, fine detail can be obtained within a 
given color by using its intensity to carry the information. When the COLOR switch is on, the display 
aspect can be manipulated in any of the ways available for B&#38;W displays. In particular, each pixel 
bit can be individually selected and weighted by software via the instruction registers. Bits l, 2 and 
3 of the pixel register are also made directly available as composite video signals on video outputs 
l, 2, and 3, respectively. In order to control a TTL-interfaced RGB monitor, or for special digital processing, 
all four output bits of the pixel register are also made available as standard TTL levels at an auxiliary 
connector. Text Mode In text mode the data from the buffer is routed to an on-board ASCII character generator, 
whose output is displayed on the main channel. The three fun- damental system clock speeds yield 64, 
72, and 80 alphanumeric characters per line of text. The text stored in the CAT-IO0 may be up to 32,768 
characters in length. Since a frame can display to to 33 lines of 80 characters, or 2640 characters, 
text editors will appreciate the possibility of rapicly access- ing a very long text stored in the buffer. 
The CAT-IO0 is capable of smooth scrolling through such text, since the position of the displayed text 
page can be controlled at the raster line level. A variety of scrolling actions may be obtained, which 
cover the range from an extremely slow and smooth motion, to an instantaneous display of another section 
of the text. System Control In order to control the video input, the image memory, and the video output, 
there are five in- struction registers which may be set by the user's software. Three other registers 
are available for interrogation of status. At the microstep level, the timing signals for the various 
modes are gener- ated by two Schotty PROMs which considerably simplify timing logic design. Photographic 
Trigger Control The photographic mode is another innovation of the CAT-IO0. It was used to take the black 
and white photographs which illustrate the present article. By using the closure of the X flash contacts 
of a photographic camera to trigger the display of a single and complete TV frame, it solves the usual 
problems of multiple uneven exposures (banding) en- countered when one attempts to directly photograph 
the screen of a raster-scan display. Lightpen A lightpen can be directly connected to the system. When 
lightpen operation is enabled and a pulse appears on the lightpen input, a "hit" flag is set in status. 
The interaction is extremely precise and the 18 bits of X-Y coordinates provided by the system actually 
resolve one pixel in the 480x512 format. ADDITIONAL BUILDING BLOCKS The basic CAT-IO0 has 32K bytes of 
image buffer on- board. The design allows the buffer capacity to be extended up to 256K bytes. This is 
achieved by connecting two types of buffer extension boards to the basic CAT-IO0 and the S-IO0 bus. The 
first buffer increment is always 32K, in order to bring buffer capacity to a total of 64K. This capacity 
allows for instance the use of 8-bit pixels. The 32K extension provides the following functions: I. An 
8-bit display D to A which yields 256-1evel monochrome images or 256-coior pictures through the main 
video output channel of the system. 2. A control register extension which makes multi- format video data 
multiplexing possible up to the maximum capacity of 256K bytes. In parti- cular, it allows selection 
of l, 2, 4 or 8 bits per pixel. 3. A parallel input path designed to accept data from an 8-bit A to 
D converter. 4. Parallel and serial TTL outputs which are useful to drive high-quality RGB color displays. 
 Any further buffer increments are in multiples of 64K bytes and can bring the total buffer capacity 
to 128K or 256K. In any of these configurations, the design flexibility of the basic system is entirely 
retained. In particular, each pixel bit, up to a total of 8 bits per pixel, can be individ- ually enabled 
for display in monochrome or in color through the main video output channel of the system. Up to four 
independent single-bit pixel images or two four-bit pixel images can be stored together at the same time 
in the buffer, and selected for dis- play via the control registers. Finally, the expanded configurations 
can accept or provide TTL data at video speedswith the maximum possible number of bits per pixel allowed 
by the total system capacity: 128 K systems can handle 16-bit 243   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807452</article_id>
		<sort_key>246</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Implementation of an interactive computer graphics environment at NASA/JSC]]></title>
		<page_from>246</page_from>
		<page_to>252</page_to>
		<doi_number>10.1145/800249.807452</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807452</url>
		<abstract>
			<par><![CDATA[<p>The implementation of visually-oriented software for graphics support on the high-performance computer graphics hardware at NASA's Johnson Space Center is the latest step in the evolution of an interactive computer applications technology being developed by the Computer Graphics Group at The Applied Research Laboratory of Penn State University. This technology is designed to aid the typical scientist or engineer in learning and using computer graphics productively, including writing his own programs and interfacing to software specialists who will write and maintain his programs. Key aspects of the current development include the creation and incorporation of a visually-oriented learning package for graphics geometric perception and graphics programming, as well as a sophisticated control environment which aids the user in obtaining a quick understanding of and access to the system. Preliminary results indicate that this software support can substantially reduce the startup time for a novice graphics user with some background in Fortran.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Analysis tool]]></kw>
			<kw><![CDATA[Dynamic visuals]]></kw>
			<kw><![CDATA[Geometric perception]]></kw>
			<kw><![CDATA[Interactive computer graphics]]></kw>
			<kw><![CDATA[Learning packages]]></kw>
			<kw><![CDATA[Macro command]]></kw>
			<kw><![CDATA[Man/machine interface]]></kw>
			<kw><![CDATA[Menu]]></kw>
			<kw><![CDATA[Procedure file]]></kw>
			<kw><![CDATA[Programming support]]></kw>
			<kw><![CDATA[Training]]></kw>
			<kw><![CDATA[Visual library]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>D.2.6</cat_node>
				<descriptor>Graphical environments</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011069</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Integrated and visual development environments</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P332196</person_id>
				<author_profile_id><![CDATA[81541576756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Lang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University, State College, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332998</person_id>
				<author_profile_id><![CDATA[81332493899]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University, State College, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331716</person_id>
				<author_profile_id><![CDATA[81332497619]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Eschenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University, State College, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39076779</person_id>
				<author_profile_id><![CDATA[81430646382]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Ochs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University, State College, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P330238</person_id>
				<author_profile_id><![CDATA[81100460244]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[F.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Stocker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Pennsylvania State University, State College, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P331078</person_id>
				<author_profile_id><![CDATA[81332522519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Raney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Aeronautics and Space Administration, Houston, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P329136</person_id>
				<author_profile_id><![CDATA[81100132461]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Stuckey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Aeronautics and Space Administration, Houston, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Applications of computer graphics in acoustic research I and II. (Special Sessions) 93rd Meeting of the Acoustical Society of America (June 1977)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807368</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Frei, H.P., Weller, D.L., and Williams, R. A graphics-based programming-support system. Computer Graphics 12, 3 (1978), 43]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Machover, C. A brief, personal history of computer graphics. Computer 11, 11 (November 1978)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Meads, J.A. Letter to the editor. Computer Graphics 11, 4 (March 1978), 37]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563735</ref_obj_id>
				<ref_obj_pid>964963</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Stocker, F.R., Johnson, G.G., and McKinstry, H.A. The development of a dynamic interactive computer graphics research and educational support environment. Computer Graphics 9, 1 (1975), 20]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Stocker, F.R. and Minsker, T. Graphic geometric perception and communication. Journal of Computers and Graphics 1, 2-3 (1975), 161]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Implementation of An Interactive Computer Graphics Environment at NASA/JSC M.S. Lang, R.L. Cohen, K.E. 
Eschenberg, J.B. Ochs, and F.R. Stocker The Pennsylvania State University, State College, PA J.L. Raney 
and B.F. Stuckey National Aeronautics and Space Administration, Houston, TX ABSTRACT The implementation 
of visually-oriented soft- ware for graphics support on the high-performance computer graphics hardware 
at NASA's Johnson Space Center is the latest step in the evolution of an interactive computer applications 
technology being developed by the Computer Graphics Group at The Applied Research Laboratory of Penn 
State Univer- sity. This technology is designed to aid the typical scientist or engineer in learning 
and using computer graphics productively, including writing his own programs and interfacing to software 
specialists who will write and maintain his pro- grams. Key aspects of the current development include 
the creation and incorporation of a visually-oriented learning package for graphics geometric perception 
and graphics programming, as well as a sophisticated control environment which aids the user in obtaining 
a quick understanding of and access to the system. Preliminary results indicate that this software support 
can substan- tially reduce the startup time for a novice graphics user with some background in Fortran. 
 KEY WORDS AND PHRASES: interactive computer graphics, man/machine interface, programming support, 
training, learning packages, visual library, menu, dynamic visuals, analysis tool, geometric perception, 
procedure file, macro com- mand CR CATEGORIES: 1.0, 3.20, 3.21, 4.13, 4.22, 4.31, 4.35, 4.40, 4.9, 
8.2 INTRODUCTION The benefits of computer graphics in certain well-defined or heavily-supported areas 
such as drafting, circuit layout, and aircraft design are well known. These benefits, coupled with the 
in- creasing availability of affordable graphics de- vices, have been used to argue that graphics has 
 This work was performed under the auspices of The Materials Research Laboratory at The Penn- sylvania 
State University, with supervision by J.L. Raney and B.F. Stuckey at NASA's Johnson Space Center (NASA 
Contract NAS9-15427). The PSU investigators have since formed the Computer Graphics Group of The Applied 
Research Laboratory at the University. finally come of age (3,4). Nevertheless, the ex- perience of 
the authors of this paper indicates that a great many scientists and engineers feel that computer graphics 
is neither a practical nor profitable tool for "typical" engineering problems; that is, for the small 
scope development problems which dominate the working schedule of most pro- grams. More troublesome yet, 
a large proportion of those who have investigated computer graphics find the time (and costs) required 
to learn and use the tool to be disproportionate to the results. For the past several years members 
of the Computer Graphics Group at The Applied Research Laboratory of The Pennsylvania State University 
 (ARL/PSU) have been examining methods for making the computer and computer graphics an effective tool 
for general-purpose analysis in a research and development setting. The potential benefits of this tool 
are widely recognized and acknowledged. The main obstacles to realization of this potential are the difficulties 
of graphics programming and the lack of a standard base of techniques and pro- grams. Thus, practical 
considerations almost al- ways dictate that specialists be used for graphics software development. The 
broad gap between the "languages" of engineers and software specialists precipitates a degree of mistrust 
in the results and frequently leads to software products which meet the stated specifications but nevertheless 
do not provide the capabilities desired. For these reasons, the ARL/PSU approach has been to enhance 
both the interface between engineer and computer and the interface between engineer and computer specialists. 
This enhancement encourages engineers to develop and use their own software, either di- rectly or through 
informed interaction with soft- ware specialists. This paper will describe the overall usage philosophy, 
give a brief history of the way it has evolved, and then detail the char- acteristics of the latest implementation 
of this approach at the National Aeronautics and Space Administration's Johnson Space Center (NASA/JSC). 
 PHILOSOPHY In order to understand the difficulties en- countered in the use of computers and computer 
graphics as engineering analysis aids, it is en- lightening to break down the procedure that must be 
 followed. For the engineer, it looks something like this: EVALUATE HOW TO USE I REFORMULATE PROBLEM 
PROGRAMMER ! COMPUTER RELIABILITY? J ENGINEERING VALUE? He must first reformulate the problem into 
a form which, to the best of his understanding, is appro- priate for computer solution and is consistent 
with the level of effort he wishes to expend. Then, he must communicate this information to either the 
computer or a programmer. Only at the end of this long procedure is he able to evaluate the results. 
 The interface to the computer itself by the programmer (shown in the heavy black box) is even more complex: 
 FORMOLA 0EST APPROACH I WR TEAN0 0EBU0 P OORAM I 0ENERA AN0'0R PR0CESS I OUTPUT DATA  -I I Here, 
it is necessary to complete the very cumber- some procedure of writing and debugging a program or locating 
and studying one which has previously been written. Interactive graphics can be added at the "output 
data" stage to make interpretation of the results easier, but this requires that the en- tire procedure 
be repeated for additional graphics software. Furthermore, the main forms of available assistance are 
previous experience (which varies greatly with the application and the individual) and seemingly endless 
racks of manuals. The basic philosophy of the authors is to apply the power and directness of graphics 
as the basis of communication both in the interface between engineers and programmers and in that between 
programmers and computers. Thus, graphics-based support would be included to aid all steps in the computer 
usage procedure and to fold that linear procedure into a triangle of mutually interacting elements: 
 ENGINEERDESIGN i / PROGRAMMER COMPUTER The areas of graphics-based support may be cate- gorized for 
purposes of discussion as training, li- brary, debug, and output. In addition, an overall method of control, 
augmented by graphics, should be included to tie the individual support elements together so that the 
user interacts with a single, broad support system instead of a multitude of individual support programs. 
It is unfortunate that, despite the recognized potential, the concept of using graphics to aid such 
activities as train- ing, debugging, and ope~rating system response has been considered only rarely 
in the current literature (2,5,6). HISTORY The various features of the work described in this paper 
originally evolved over several years of working with people using the Adage Model 30 Graphics System 
at the PSU Computation Center. Many students and researchers from various depart- ments expressed an 
interest in using the graphics facilities as an aid to their research or studies. However, with the exception 
of a few computer enthusiasts, most of the people quickly lost inter- est as the complexity of the programming 
procedure became apparent--even when there was a definite promise of noticeable benefit. In order to 
reverse this trend, a program package was developed which used the Adage hardware to explain the concepts 
of geometric perception and graphics primitives re- quired for a user to program the same Adage hard- 
ware (6). This training package was used very successfully by its developers to expedite the early progress 
of novice users both in graphics Courses and in individual sessions with researchers (5). In the fall 
of 1976, the most recent training package was used in a class of graduate students in the PSU Acoustics 
Program. This represented a new 247  classroom test of the support developments since these students 
were interested solely in using graphics to aid their individual research interests rather than learning 
about graphics in general. None of the class participants had any graphics experience. The reduced training 
time resulting from instruction utilizing the support package did allow the twelve participants (some 
working in pairs) to produce eight individual programs involv- ing various acoustic problems and to generate 
eight color, computer-animated films averaging ten min- utes in length for showing at a national conference 
(i). Although the formal instruction was very successful, it was noted that the users had some difficulty 
working with the support package on their own when attempting to progress beyond the level presented 
in class. Following this acoustics conference, NASA/JSC arranged a small contract to attempt an implementa- 
tion of the methods developed at PSU on the graph- ics hardware at NASA's Houston facility. This required 
a significant advance in the human engi- neering of the support approach, since the develop- ers would 
not be around to explain the concepts. The remainder of this paper will describe the system implemented 
there as the latest of the authors' development efforts, and it will discuss the degree of success encountered 
to date. SYSTEM ENVIRONMENT AT NASA/JSC  The graphics hardware used for the authors' work at NASA/JSC 
consists of two Adage Model 340 Graphics Systems with accompanying graphic input and hardcopy peripherals. 
Each of the Adage 340 units is a high-performance, stand-alone graphics system consisting of a microprogrammable 
digital graphics processor and vector generator implement- ing full dynamic 3-D transformations and an 
asso- ciated 30-bit local minicomputer host. The two systems are owned and used respectively by the ISAS 
(Integrated Structural Analysis System) and EDIN (Engineering Design Integration System) projects which 
are using them to develop major software design packages. They are also used by other NASA engineers 
and support contractors on a variety of NASA projects. General software maintenance and development 
support for NASA engineering projects is provided by outside contractors. During the period of this project, 
a new support contract for operating system maintenance on both Adage systems  was accepted by Computer 
Science Corporation. CSC then brought ten new programmers into the environment, eight of whom had no 
previous experience with Adage hardware or software. This provided an unexpected opportunity to immediately 
 test the effectiveness of the PSU support system outside of its academic birthplace. The conclu- sions 
that are presented here are based on discus- sions with the CSC group as well as NASA engineers and support 
contractors who were using the Adage hardware during this project. Their experience at the time of these 
discussions included use of an incomplete, prerelease PSU system delivered at NASA's request in September 
1978, as well as eval- uation of the completed PSU system delivered in March 1979. THE PSU SUPPORT SYSTEM 
 APPROACH: The approach taken for this project was to examine closely the target environment at NASA/JSC 
from the point of view of its users to find areas of greatest difficulty. Past work of the authors has 
shown this overall approach to be much more productive than choosing an area of need in advance and working 
exclusively in that area. Two of the basic user needs identified correspond to those noted previously 
in the academic environ- ment at PSU (5). First, the support system should allow a new or continuing 
user to interact with the hardware without having to know the details of the system. This is especially 
important for situa- tions where users operate the equipment on a sched- uled basis with no operator 
assistance. Second, the system should help users to rapidly gain skills in both graphicsperception and 
graphics program- ming (the former is frequently the biggest hurdle to overcome). In addition, the more 
production oriented user community at NASA/JSC, with its pro- fessional engineers and support programmers, 
pre- sents additional basic requirements. The support system should minimize the inconvenience experi- 
enced users encounter due to the extensive amount of support included for beginners. Finally, it is very 
important that the system be self-explanatory for unassisted usage. Although there is a fair amount of 
sharing between users, no formal consult- ing for training or problems is available. This final need 
has proven to be the most difficult to satisfy, and it has forced an extensive reworking of previously 
developed programs for smoother flow and more consistent organization. MENU CONTROL: The basic method 
of control common to all elements of the PSU support system is function switches. The hardware includes 
32 light- ed switches arranged as four groups of eight, two monitor control switches, and a large manual 
inter- rupt button (PULSE l) in a single box, as well as two footpedals. These switches are used with 
on- screen menus structured to look like the switch box in a method conceptually similar to previous 
PSU implementations. However, to provide room for sufficient text with the larger number of switches, 
the switch box is actually presented as the left side (Fig. i) or right side (Fig. 2). The appro- priate 
menu frame is designed to zoom out of the complete box when invoked to force the user to vis- ually orient 
to the proper side. Experience with this arrangement has shown that the function switches, when oriented 
for "sightless" selection and used with structured menus, are significantly faster and more comfortable 
than light pens or data tablets to use as selection devices for experienced users, and they are only 
slightly more difficult for beginners. (Function switches may not be pre- ferable when the data tablet 
is concurrently in use for program input.) MACRO CONTROL SUPPORT: The large set of system operations 
and disk file storage can be overwhelm- ing to a new user and uncomfortable to an experi- enced one. 
Thus, the PSU support system redefines and extends the standard operating commands to provide operator 
aids at both passive and active levels. One good example of this is the DL or Disk  also how sensitive 
it is to various image elements. Other tests allow the user to exercise the function switches, analog 
input devices (control dials), and keyboard. Finally, an additional test provides a graphical pattern 
which can be used to set the gain and positioning controls on the scope itself to known values. GRAPHICS 
SKILLS: The first necessity for the system user is to be brought up to a productive level of capability. 
One of the most successful aspects of the PSU support system is the training package, which goes a long 
way toward fulfilling training needs with respect to graphics program- ming. The actual graphics language 
provided by Adage, as an extension to Fortran, is elegant and versatile, so much so that assistance in 
under- standing it conceptually is necessary to realize its full usefulness. The programs provided to 
explain graphics concepts and programming tech- niques are conceptually the same as those develop- ed 
earlier at PSU (5,6). They have, however, been extensively reworked to provide the level of con- sistency 
needed for the package to be used unas- sisted, Because of the importance of the training pro- grams, 
a brief description of their features is included in Figs. 4-7. More information is pre-  sented in 
Ref. 6. The sequence follows a top-down approach to training, where an overview is first presented 
to develop understanding and then suc- cessive levels of detail are added. Thus, SCOPE  presents basic 
ideas of three dimensional geometric perception in a totally graphical form  (Fig. 4). NUMBERS (formerly 
named FRS) then adds numerical scales and scale units for the basic transformations (Fig. 5). Finally, 
INTRP intro- duces a dynamic interpretation of the Fortran syntax required juxtaposed with a representation 
 of the program's block-flow and the actual image  produced. LIBRARY (formerly named LI) provides a 
 collection of commonly used images.  One major addition to LIBRARY is a study of the standard mathematical 
functions provided by Adage. This feature provides aid in understanding the domain and range characteristics 
and other id- iosyncracies of those functions. An example is shown in Figs. 8 &#38; 9. Figure 8 shows 
a function plotted in the normal range of the image viewing space, while Fig. 9 shows the same function 
expand- ed over its full range. It is clear that the func- tion is a logarithm, but the numerical implementa- 
tion differs from the analytical form by a reflec- tion into the negative domain. Although manuals and 
person-to-person instruc- tion are always necessary, learning graphics pro- gramming can be made easier 
with the aid of example programs which demonstrate basic coding constructs. The idea of training programs 
was included in early PSU implementations, but the programs were not readily accessible to all users. 
The situation has been remedied in the NASA implementation by includ- ing a cohesive set of eight graphics 
training pro- grams. Using a structured function switch menu, one can alternately view the source code 
and the execution results of each program. Printed copies of both the image and source code provide 
the user with a model for his own applications. Having simple examples which include all detail required 
for execution has proved to be a much faster way of teaching basic programming skills than manual-style 
lists of language syntax forms. The first graphics training program simply produces the transformed 
coordinate system and cube image common to all training and comprehension support. Later programs add 
features such as sub- images, use of external variables, function switch handling, character handling, 
and structured menu production. The complexity of the code increases in a controlled manner as one steps 
through the sequence of programs. Additional features such as using multiple statements in a single line 
and ob- taining hardcopy plots are included as a natural addendum to the concepts under study. CONCLUSIONS 
 Most of the work of the NASA/JSC project ad- dresses the human factors of man/machine inter- action 
through interactive computer graphics. A key element in the successes achieved is the use of dynamic 
visuals. The coupling of man and machine which occurs when a user interacts in real time with graphic 
images simply cannot be captured or duplicated even on motion pictures. In addition, top-down learning 
is used for clarity throughout the support environment by first presenting an overview then adding detail. 
Graphic images have proven to be ideal for this because a user tends to ignore the detail in favor of 
an overview when initially exposed to a new, uncluttered picture. The system works best initially in 
a one-on-one situation with a knowledgeable programmer there to lead the new user through the facilities 
provided. As confidence is gained, the new user will typical- ly become the knowledgeable programmer 
for the next user. One of the most important points noted in the NASA/JSC development is the overriding 
need for the support system to exhibit total consistency. Interactive, visual communication proceeds 
at a remarkable rate, and this process is totally dis- rupted by even minor inaccuracies in the presenta- 
tion. This is especially true when there is no knowledgeable programmer immediately available to provide 
assistance. Thus, a considerable amount of time was expended verifying the consistency of each image, 
identifying and defining a determinate response to unusual or confusing program opera- tions, and insuring 
that identical or similar options appear in consistent patterns in the menus. The NASA/JSC users reported 
that these improvements made the final system much more comfortable to use than previous versions. They 
also expressed a desire to include the PSU support as part of the standard operating environment on both 
Adage systems. Original projections of the possible training benefits of the PSU developments have 
been real- ized. Based on earlier experience, the NASA super- visors had estimated that approximately 
two years would be needed to bring novice employees up to full production at the high level of sophistication 
  required for their projects. However, CSC reported that it trained several of its new employees in 
three to four months using the PSU support under the guidance of a knowledgeable programmer. This makes 
the initial estimate of a 75% savings appear conservative. Encouragement for future extensions of this 
work has been provided by several additional obser- vations. Both new and continuing users not only learn 
faster but appear to develop a better under- standing of the concepts than has been noted after standard 
verbal or written explanations. They themselves feel more comfortable with the newly learned techniques, 
and they are generally able to modify and extend the ideas without additional training. In addition, 
concepts learned on the fully interactive system are then transferred to work done on storage tube and 
other plotter-like hardware--once a visual representation of an idea is fixed in the mind, then it is 
retained and used. Finally, the image support in the training system is utilized by NASA users as an 
aid to discuss and formulate approaches to graphics software currently under development. Thus, the 
visuals do appear to enhance the man/computer interface in normal pro- duction programming. In summary, 
experience with this NASA/JSC im- plementation does indicate that the philosophy represents an extremely 
beneficial approach, dif- ferent from current practice, that can be extended along recognized paths to 
complete a truly people- oriented (as opposed to user-oriented) computer environment. The current implementation 
supports training in graphical concepts and provides some help in hardware confidence support and system 
con- trol. However, the adaptability of the macro sys- tem needs considerable improvement, and much more 
graphics should be utilized throughout. Further- more, support for normal computational problems of overlays, 
efficiency, applications software main- tenance, etc. will be required. The authors are currently attempting 
to expand the support toward a complete computational environment (as resources permit), and it is hoped 
that others will adopt and expand the same methods in an attempt to make com- puter graphics and computers 
themselves finally come of age. ACKNOWLEDGEMENTS The authors would like to acknowledge the pro- gramming 
contributions of R.L. Kulp and M.R. Hoover, as well as the helpful discussions and overall support of 
G.G. Johnson and H.A. McKinstry. We would also like to thank the NASA RTOP Program for its support under 
contract NAS9-15427 and the Materials Research Laboratory for accepting respon- sibility for the contract 
on behalf of Penn State University. Finally, we would like to recognize the continuing facilities support 
provided by the PSU Computation Center, with thanks to D.T. Laird and C.G. Wissinger. REFERENCES i. 
Applications of computer graphics in acoustic research I and II. (Special Sessions) 93rd Meeting of the 
Acoustical Society of America (June 1977) 2. Frei, H.P., Weller, D.L., and Williams, R. graphics-based 
programming-support system. Computer Graphics 12, 3 (1978), 43  3. Machover, C. A brief, personal history 
of com-  puter graphics. Computer ii, ii (November 1978)  4. Meads, J.A. Letter to the editor. Computer 
Graphics ii, 4 (March 1978), 37  5. Stocker, F.R., Johnson, G.G., and McKinstry,  H.A. The development 
of a dynamic interactive computer graphics research and educational sup- port environment. Computer Graphics 
9, 1 (1975), 20 6. Stocker, F.R. and Minsker, T. Graphic geome- tric perception and communication. 
Journal of Computers and Graphics i, 2-3 (1975), 161  252 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807453</article_id>
		<sort_key>253</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[On the rendering of surfaces]]></title>
		<page_from>253</page_from>
		<page_to>259</page_to>
		<doi_number>10.1145/800249.807453</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807453</url>
		<abstract>
			<par><![CDATA[<p>Despite the relative sophistication of modern surface design systems, many graphical renderings of surfaces are rather crude. The paper discusses several possible renderings, including various line drawings methods, realistic and functional shading, and combinations of line drawings and smooth shading. It concludes that a good choice is the superposition of contours or sections on either realistic or Gaussian curvature shading.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Computational geometry]]></kw>
			<kw><![CDATA[Computer graphics]]></kw>
			<kw><![CDATA[Computer-aided geometric design]]></kw>
			<kw><![CDATA[Hidden-surface removal]]></kw>
			<kw><![CDATA[Raster graphics]]></kw>
			<kw><![CDATA[Sculptured surfaces]]></kw>
			<kw><![CDATA[Smooth shading]]></kw>
			<kw><![CDATA[Visualisation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Smoothing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP48025401</person_id>
				<author_profile_id><![CDATA[81100609818]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Forrest]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of East Anglia, Norwich NR4 7TJ, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B&#233;zier, P.E. Numerical Control - Mathematics and Applications. Wiley, London, 1972.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807364</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J.F. A scan line algorithm for displaying parametrically defined surfaces. Proc. ACM SIGGRAPH Conference, 1978.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H. Applications of continuous tone computer generated images in structural mechanics. In Structural Mechanics Computer Programs - Surveys, Assessments and Availability, Eds.Pilkey, Saczalski and Schaeffer, University Press of Virginia, 1974.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Coons, S.A. Surfaces for computer aided design of space forms. M.I.T. Project MAC, TR-41, June 1967.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. Curves and surfaces for computer-aided design. Ph.D. Thesis, University of Cambridge, July 1968.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Forrest, A.R. A computer peripheral for making three-dimensional models. Automatisme 19, 6/7 (June/July 1976).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lane, J.M. and Carpenter, L. A scan-line algorithm for the computer display of parametrically defined surfaces. Boeing Commercial Airplan Company, 1978, submitted for publication.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lang, C.A. A three-dimensional model making machine. Cambridge University Computer-Aided Design Group Doc. 74, September 1972.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Newman, W.M. and Sproull, R.F. Principles of Interactive Computer Graphics (2nd Edition). McGraw-Hill, New York, 1979.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Phong, B.T. Illumination for computer generated images. Comm. ACM 18, 6 (June 1975).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563896</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Weiler, K. and Atherton, P. Hidden surface removal using polygon area sorting. Proc. ACM SIGGRAPH Conference, 1977.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807363</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. A scan-line algorithm for computer display of curved surfaces. Proc. ACM SIGGRAPH Conference, 1978.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. GINO-F User's Manual. Computer-Aided Design Centre, Cambridge, England, 1975.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ON THE RENDERING OF SURFACES A.R. Forrest University of Utah* Salt Lake City, UT84112 ABSTRACT Despite 
the relative sophistication of modern surface design systems, many graphical renderings of surfaces are 
rather crude. The paper discusses several possible renderings, including various line drawings methods, 
realistic and functional shading, and combinations of line drawings and smooth shading. It concludes 
that a good choice is the superposition of contours or sections on either realistic or Gaussian curvature 
shading. KEY WORDS AND PHRASES: Computer graphics, raster graphics, computational geometry, computer-aided 
geometric design, visualisation, sculptured surfaces, hidden-surface removal, smooth shading. CR CATEGORIES: 
3.26, 5.13, 8.2 1. INTRODUCTION One of the classic problems in computer graphics (4,5) is the modelling 
and rendering of surfaces in three-dimensional space the so-called sculptured surfaces. A fundamental 
reason for the considerable amount of research carried out in the 1960's was the ambiguity of conventional 
engineering drawings when applied to arbitrary surfaces. It is impossible, in general, to define doubly-curved 
surfaces in terms of a finite number of planar line drawings (although particular doubly-curved surfaces 
such as ellipsoids, surfaces of revolution, etc. can be defined uniquely in terms of planar line drawings); 
the problem may be overcome by the use * Current address: University of East Anglia, Norwich NR4 7TJ, 
England. This research sponsored by NSF Grant MCS 78 01966: Computer Aided Geometric Design, Principal 
Investigator R.F. Riesenfeld, University of Utah, Computer Science. of analytic models for surfaces. 
Here the pioneer work of Coons and others is well-known. It is now cormnon practice to represent a surface 
in terms of a mathematical model (usually analytic equations), and to use the model to derive drawings 
of various forms. The ability rapidly to generate complex drawings from a computer model and to display 
these drawings on a c.r.t, or plotter has proved of great use in practice. Nevertheless, it is the contention 
of the author that the methods used to display arbitrary surfaces are still ambiguous, uninformative, 
and imprecise. In this paper we survey some of the methods conmnonly used, highlighting their drawbacks, 
and suggest more meaningful methods which exploit recent advances in raster graphics technology. In 
particular we concentrate on the presentation of surfaces for engineering design and manufacture, rather 
than for animation, simulation, etc.  2. CONVENTIONAL TECHNIQUES - LINE DRAWINGS We shall consider 
rendering of surfaces in the context of c.r.t, displays, calligraphic or raster, since most of the techniques 
are applicable to other devices (such as plotters) in some form or another. Before doing so, two methods 
of display must be mentioned: dynamic display and solid model generation. With the availability of high-performance 
displays with transformation hardware, it is relatively simple to cause a three-dimensional line-drawing 
image to rotate, etc. in real time. Leaving aside consideration of what kind of line drawing we should 
display, there is no doubt that dynamic display considerably enhances our understanding of the shape 
of a three-dimensional object. We obtain a "vivid impression of the three-dimensional shape, but the 
very nature of the image -dynamic -makes it difficult to obtain precise knowledge of that shape. We cannot 
measure a dynamic image, so the insight we gain into the shape is transient and somewhat subjective. 
This is not to decry the utility of dynamic display, but to point out that it is of limited scope in 
the precise delineation of shape. The author and others (],6,8) have pointed out on several occasions 
the benefits of solid model generation. Figure ] shows a B-spline surface cut by the author on a computer-controlled 
model-making machine at the University of Cambridge. It is sometimes useful to consider numerically-controlled 
machine tools as &#38;#169;1979 ACM 0-89791-004--4/79/0800--253 $00.75 See Copyright Pg 253 three-dimensional 
plotters which have 'pens' of finite thickness and geometry, but a relatively slow drawing speed. At 
Cambridge and the University of E ast Anglia, model-making machines are regarded as graphical devices 
and are programmed as such: code-generators for the GINO-F device-independent graphics package (13) 
have been written. The main benefits of solid output -three-dimensional hard copy -are: lack of ambiguity, 
precise depiction of shape, automatic generation of all possible hidden-surface removed images, with 
or without shadows, and the ability to handle the model (the sense of touch reveals aspects of a shape 
which are, at first, invisible to the eye). The disadvantages of such output are the speed of generation 
(approximately |0 minutes for Fig. ! on the current Cambridge machine), and the inability to interact 
with the model. Turning now to static c.r.t, images, consider Fig. 2. Here we display a single parametric 
bicubic surface patch as a 9x9 mesh of lines of constant parameter. Parametric lines are the easiest 
lines to compute, and the parametric wire-frame mesh is probably the most con~nonly used method for displaying 
such a patch. Unfortunately, parametric lines are generally of limited use since they convey little geometric 
information. It is possible to draw many parametric families on a surface, but unless we can attach some 
geometric meaning to them, they remain simply tracks on the surface, aid in the sense that a street plan 
gives little indication of topography, so parametric meshes give little indication of surface shape. 
This is particularly true of the surface in Fig. 2.  Hidden line elimination serves to reduce the clutter 
and increase our understanding of an image, but it will not materially aid our perception of a mesh of 
parametric lines. Similarly, perspective is of little use, since unless we can relate a perspective image 
of the surface to a perspective image of an object of known sbape, we cannot tell whether we are viewing 
in perspective or merely viewing an orthogonal projection of some distorted shape. Stereo images, like 
dynamic images, yield a vivid impression of shape, but are non-metric in the sense that the images cannot 
readily be used to convey precise information regarding shape. Since parametric lines can wander meaninglessly 
over a surface, one technique used to overcome the lack of geometric information is to plot surface normals, 
Fig. 3. In many circumstances, surface normals, which have a precise geometric interpretation, substantially 
aid visualisation, particularly where the surfaces are not highly contorted. In such cases, subtle variations 
in shape are amplified (see Newman and Sproull (9) for a good example). For our sample surface, normals 
merely add to visual clutter since the surface is highly contorted. A more useful type of line drawing 
to generate is a set of sections or contours, as in Fig. 4. Here we draw plane sections parallel to the 
screen and at equal intervals in depth. The surface patch is rendered with boundary curves and silhouette 
lines in white and contours in pink. We can now begin to gain some precise information as to the shape 
of the surface. Contour lines have an exact, unambiguous, geometric interpretation: they relate directly 
to the shape of the surface. Figure 4 could have been made clearer either by colour coding the contour 
or otherwise identifying the levels. It is arguable that of all the line drawings possible, a set of 
surface sections is the most useful in determining shape. The main drawback is that, compared to lines 
of constant parameter, sections are difficult to compute; nevertheless, the additional computational 
effort appears well worthwhile. Figure 5 is a blend of Figs. 2 and 4, demonstrating that the parametric 
lines give no indication of the 'cliff' running top to bottom across the middle of the surface, or of 
the saddle region at the bottom centre of the patch. 3. CONVENTIONAL TECHNIQUES -SMOOTH SHADING With 
the reduction in cost of raster displays, there has been a renewed interest in efficient algorithms for 
generating realistic smooth shaded images (2,7,12). In contrast to earlier methods where the surface 
first had to be approximated, rather crudely, by a somewhat random collection of planar polygons and 
the discontinuities in the planar approximation were 'ironed outut' by smooth shading, the recent algorithms 
approximate the surface in a geometrically sensible manner and the smooth shading is a close approximation 
to the true shading. Figure 6 is a smooth shaded image which involves no approximations except those 
inherent in pixel resolution, with highlights computed according to the method suggested by Phong (10). 
The surface is yellow on one side and cyan on the reverse. Figure 6 is certainly realistic, and gives 
a good notion of shape. On the other hand, it is subject to more than one interpretation, with hollows 
sometimes being seen as hilltops and vice versa. As with all other smooth shaded images which attempt 
to give a realistic image, what we obtain is an impression of the shape rather than a precise, quantifiable 
image - we cannot measure the image and hence we cannot obtain accurate information regarding the surface 
shape: that is to say, we cannot pass Fig. 6 to a machine shop and expect it to be manufactured. We can 
overcome the ambiguity of interpretation by more sophisticated shading techniques. In Fig. 6 the light 
source is coincident with the eye point; in Fig. 7, the eye point is the same, but the light source is 
above the surface and to the left and below the image. (The shading in Fig. 7 is rather crude due to 
the quick-and-dirty algorithm employed.) Despite recent advances, it is probably too expensive to contemplate 
generating multiple shaded images of a single surface merely to remove some latent ambiguities. 4. LINE 
DRAWINGS AND SHADED IMAGES The great merit of smooth shading is that we display information relating 
to the surface at every visible point on the surface, to device resolution, rather than at discrete intervals. 
Line drawings, on the other hand, provide metric information, but are open to variou~ interpretations 
between the lines. It seems logical, therefore, to explore the combination of  line drawings and smooth 
shaded images. Figure 8 E=P .P demonstrates the effect of overlaying a parametric mesh on a shaded image. 
We see, as we might have predicted, that parameter lines add little, if anything, to our comprehension. 
In Fig. 9, however, the combination of smooth shading and contours does aid our understanding. The smooth 
shading interpolates the contour lines in a sensible manner, with the two methods of rendering conbining 
synergically. One of the motivations for the research behind this paper was the observation, made by 
many others, that it is possible to generate line drawings of surprisingly high quality on a raster display. 
Time did not permit the development of anti-aliasing or anti-rastering techniques for the lines, silhouettes 
and outlines in the Figures here; the problem is complicated by the continuous tones of the background 
on which the lines are to be drawn, and a more sophisticated approach is necessary. Despite these current 
limitations in image quality, the author is encouraged to continue the approach of combining shaded and 
line images. 5. NON-REALISTIC SHADED IMAGES In Fig. I0, we add to the shaded image with parameter lines 
and contour lines, highlighting of a non-realistic kind. The bright red spots indicate regions on the 
surface where the use of a spherical cutter of specified radius would interfere with the surface and 
cause goudging - we depict such regions by 'drawing blood'. (The model in Fig. 1 has some goudged regions 
which may be visible in the photograph.) We can think of other modifications of shading to highlight 
similar regions of importance to the user. On the other hand, we might consider employing other shading 
rules which aid our comprehension of shape or display other information regarding the properties of our 
design. Here one must cite the pioneering work of Christiansen at Brigham Young University who used colour 
shading to display variations in the stress and strain of engineering structures (3). Figures II and 
12 show the sample surface painted with shading which is related to the curvature of the surface, and 
which therefore has a strictly geometric interpretation. A standard result in differential geometry 
shows that the normal curvature of a surface (the curvature measured in a plane containing the curvatures). 
The mean curvature of the surface, H, normal to the surface) has a minimum value k . .ml and a maximum 
value k (the prlnclpa~ max is given by: H = 2(kmi n + kma x) and the Gaussian or total curvature K 
is given by: K = k . .k mln max If the surface patch has the vector-valued equation ~(u,v), then we 
can compute the curvatures as follows. Let E be the dot product of the u tangent vectors:  Similarly, 
let F=P .P  and  G=P .P --V --V  Let N denote the surface normal vector: N = P xP  then: L = P 
.N --BU --  M = P .N --UV --  and N = P .N --vv--  The mean and Gaussian curvatures are then: 
EN + GL -2FM H= 2 (EG - F 2) LN - M 2 K= (EG-F 2)  In Fig. 1 I, a shading function based on mean 
curvature is used. Blue regions are regions where the mean curvature is positive, with a shading towards 
white for high values of curvature. Red regions are regions where the curvature is negative, again with 
high mean curvature shading towards white. Green regions are regions where the mean curvature is approximately 
zero. Mean curvature, to some extent, measures how highly curved the surface is, but regions of high 
curvature where the principal curvatures are of opposite sign will have a mean curvature effectively 
of zero. It is instructive to a mathematician to examine mean curvature plots, and possibly they provide 
a useful way of highlighting subtle variations of shape which might be of interest to those concerned 
with surface smoothness or fairness. In Fig. 12, Gaussian curvature is plotted as a colour function. 
The sign convention and shading law of Fig. 11 is used but the interpretation of the colour plot is easier. 
In blue regions, both principal curvatures are of the same sign: the surface is locally ellipsoidal in 
nature, and blue regions are therefore hilltops or hollows. Red regions depict areas where the principal 
curvatures are of opposite sign: the surface is hyperboloidal in form and red regions are saddle areas. 
In green regions, one or more of the principal curvatures is effectively zero. Green regions are ridges 
or valleys, or, if both principal curvatures are effectively zero, planes. Gaussian curvature, therefore, 
is a good indication of surface shape, being somewhat more precise than realistic shading in terms of 
conveying geometric information. We can tell, for example, that the hollow to the left centre of the 
patch is much less highly curved than the peak at right centre, and that the saddle at bottom centre 
is highly contorted. Figures |I and 12 also demonstrate once more the combination of line drawings with 
shaded images.  6. PRODUCING THE FIGURES  We have already discussed how Fig. I was generated. The remaining 
Figures were produced by an experimental hidden surface program written by the author for the Grinnell 
frame buffer at the University of Utah. This frame buffer has 512x512 resolution with 27 bits per pixel 
(24 bits for colour and 3 overlay bits). The algorithm employed is crude but effective, and is based 
on a technique proposed by the author in 1970 for hidden surface elimination using a silicon target storage 
tube as a Z-buffer. Since the author never had access to such a device, the algorithm was never published. 
Briefly, a surface patch P(u,v) is scanned in raster fashion in the u-v plane. A z value is stored at 
the corresponding x-y pixel if it represents a point nearer to the viewer than the current z value stored 
in that pixel. If a new value of z is written, a bit is set in one of the overlay planes at the corresponding 
u-v pixel. After one pass through the surface, the overlay plane contains a u-v map of points on the 
surface which are visible or which will be overwritten if the surface is scanned out in the same u-v 
order. If desired, a second scanning pass will eliminate points which will be overwritten, leaving a 
u-v map of visible regions of the surface. One advantage of the algorithm is that apart from the overlay 
bits the entire pixel storage can be used for z comparisons rather than devoting half of the pixel storage 
to z and half to shading information. Shading is then generated using the u-v map to look up visible 
points. Just as the Weiler and Atherton hidden line algorithm (]I) generates as output a marked data 
structure which can be scanned subsequently to produce a picture, so the author's algorithm outputs a 
marked surface data structure rather than a picture. Other u-v maps may be constructed to represent 
shadow information. The u-v map is subsequently used in scanning out the surface, again in u-v order, 
to determine which pixels to paint. Smooth shaded images are generated on the first pass, if required, 
and line drawings are generated by a second pass. The resolution of the u-v map is chosen to be similar 
to that of the eventual image in terms of pixels. Occasionally a miss-match occurs, leaving one-pixel 
holes in the image, but these holes are filled most effectively by a simple averaging technique. The 
algorithm was selected for its ease of implementation, and is not as fast as recent algorithms for shaded 
rendering. However, output of the u-v map is essential for generating combinations of shaded and line 
images. On a PDP 11/34, the u-v map takes approximately 4 minutes to compute for the sample surface. 
Given the u-v map, the time to generate a Figure varies from 20 seconds for a line drawing to 2 minutes 
for a curvature plot which involves a fair amount of numerical computation. For the purposes of this 
paper, the algorithm suffices; a more sophisticated algorithm would be selected for a production system. 
 7. CONCLUSIONS The pros and cons of various methods for curved surface rendering have been discussed. 
It is suggested that the best form of line drawing is a set of planar sections through a surface rather 
than a mesh of parameter lines. Realistic smooth shading gives a good impression of shape, but there 
are advantages in using Gaussian curvature shading if a more exact presentation of shape is required. 
The main conclusion, however, is that there is a lot to be gained by combining the positionally precise 
but discrete information of a line drawing with continuous information provided by shading. In the past, 
engineers have tended to employ line drawings because they can be constructed precisely in a constrained 
manner using drafting instruments. Smooth shading previously has been the prerogative of the artist, 
free-form in nature. Raster displays allied to computers open up possibilities for the use of constructive, 
constrained, functional shading which, apart from the examples of Christiansen (3), are little exploited. 
 8. ACKNOWLEDGEMENTS The author is grateful to the Computer Science Department, University of Utah, 
for support and the use of facilities in preparing this paper, and to Brian Barsky and Spencer Thomas 
for frame buffer software and advice. Photographs were the responsibility of Mike Milochik. The research 
was partially sponsored by the U.K. Science Research Council Grant GR/A 845]6: Investigations in Computational 
Geometry and Computer-Aided Geometric Design. 9. REFERENCES (]) B~zier, P.E. Numerical Control - Mathematics 
and Applications. Wiley I, London, 1972. (2) Blinn, J.F. A scan line algorithm for displaying parametrically 
defined surfaces. Proc. ACM SIGGRAPH Conference, 1978.  (3) Christiansen, H. Applications of continuous 
tone computer generated images in structural mechanics. In Structural Mechanics Computer Prosrams -Surveys, 
Assessments and Availability, Eds.Pilkey, Saczalski and Schaeffer, University Press of Virginia, 1974. 
 (4) Coons, S.A. Surfaces for computer aided design of space forms. M.I.T. Project MAC, TR-41, June 
1967.  (5) Forrest, A.R. Curves and surfaces for computer-aided design. Ph.D. Thesis, University of 
Cambridge, July 1968.  (6) Forrest, A.R. A computer peripheral for making three-dimensional models. 
Automatisme 19, 6/7 (June/July 1976).  (7) Lane, J.M. and Carpenter, L. A scan-line algorithm for the 
computer display of parametrically defined surfaces. Boeing Commercial Airplan Company, 1978, submitted 
for publication.   (8) Lang, C.A. A three-dimensional model making machine. Cambridge University Computer-Aided 
Design Group Doc. 74, September 1972. (9) Newman, W.M. and Sproull, R.F. Principles of Interactive Compute 
F Graphics (2nd Edition). McGraw-Hill, New York, 1979.  (io) Phong, B.T. Illumination for computer 
generated images. Com. ACM 18, 6 (June ]975). (11) Weiler, K. and Atherton, P. Hidden surface removal 
using polygon area sorting. Proc. ACM SlGGRAPH Conference, 1977.  (12) Whitted, T. A scan-line algorithm 
for computer display of curved surfaces. Proc. ACM SIGGRAPH Conference, 1978. (13) ...... GINO-F User's 
Manual. Computer-Aided Design Centre, Cambridge, England, ]975.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807454</article_id>
		<sort_key>260</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Generating smooth 2-D monocolor line drawings on video displays]]></title>
		<page_from>260</page_from>
		<page_to>269</page_to>
		<doi_number>10.1145/800249.807454</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807454</url>
		<abstract>
			<par><![CDATA[<p>One of the major drawbacks of video display systems for line drawing applications has been the poor image quality they usually produce&#8212;&#8220;jaggy&#8221;, &#8220;staircased&#8221; line edges, moire patterns in regions of closely spaced lines, even, with some systems, lines disappearing (&#8220;falling in&#8221;) between pixels. Correcting these effects, with appropriate area-sampling techniques, has generally been too computationally expensive to adopt.</p> <p>A new algorithm is presented which generates precise, smooth images of line drawings and solid polygonal-shaped objects on multi-grey-level pixel-mapped video systems. The method is based on an analysis of boundary conditions at each pixel affected by one or more lines. With this method a number of previously needed steps can be quickly eliminated. The commonality of boundary conditions between adjacent pixels and the coherence of such conditions in a raster-scan ordering of such pixels allows efficient generation of these boundary conditions. A recursive subdivision approach allows handling of arbitrarily complex cases by a simple boundary-analyzing technique. Compared with current line-drawing systems, a video system with this algorithm would also display an improved image with respect to certain common visual effects&#8212;e.g., distance modulation of line intensity (which may be desirable), artificial small bright clusters of detail (which is undesirable).</p> <p>Since the software interface to the algorithm may be handled through already-standard graphical subroutines, adoption of the algorithm may be accomplished without burdening graphic system users or graphic system-utilizing software.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Video (e.g., tape, disk, DVI)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Image display</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Smoothing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Line and curve generation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010248</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Video segmentation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010230</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Video summarization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP14191923</person_id>
				<author_profile_id><![CDATA[81544191556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jose]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barros]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mathematical Sciences, University of Texas at Dallas, Richardson, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39071971</person_id>
				<author_profile_id><![CDATA[81339500019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fuchs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>807360</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Catmull, E.(1978), "A Hidden-Surface Algorithm with Anti-Aliasing" Proceedings of 1978 ACM-SIGGRAPH Annual Conference on Computer Graphics and Interactive Techniques, (Vol. 12, (3):6-11, Computer Graphics)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Crow, F.C.(1977), "The Aliasing Problem in Computer-Generated shaded Images", Communications of the ACM, 20 (11):799-805]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807359</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Crow, F.C.(1978), "The Use of Grayscale for Improved Raster Display of Vectors and Characters", Proceedings of 1978 ACM-SIGGRAPH Annual Conference on Computer Graphics and Interactive Techniques, (Vol. 12, (3):1-5, Computer Graphics)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Genisco Computers(1977) GCT3/GCT3a Programming Reference Manual, Irvine, California]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Newman, W.M. &amp; Sproull, R.F.(1973), Principles of Interactive Computer Graphics, McGraw-Hill]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shoup, Richard G. (1973), "Some Quantization Effects in Digitally Generated Pictures", Digest of Technical Papers of 1973 International Symposium of the Society for Information Display, 58-59.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E. (1973), "Polygon Sorting by Subdivision: A Solution to the Hidden-Surface Problem", unpublished]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E., Sproull, R.F. &amp; Schumacker, R.G.(1974), "A Characterization of Ten Hidden-Surface Algorithms", Computing Surveys, 6, 1]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GENERATING SMOOTH 2-D NONOCOIOR LINE DRAWINGS ON VIDEO DISPLAYS Jose Barros Mathematical Sciences University 
of Texas at Dallas Richardson, TX 75080 Henry Fuchs Department of Computer Science University of North 
Carolina Chapel Hill, NC 27514  ABSTRACT One of the major drawbacks of video display systems for line 
drawing applications has been the poor image quality they usually produce --"jaggy", "staircased" line 
edges, moire patterns in regions of closely spaced lines, even, with some systems, lines disappearing 
 ("falling in") between pixels. Correcting these effects, with appropriate area- sampling techniques, 
has generally been too computationally expensive to adopt. A new algorithm is presented which generates 
precise, smooth images of line drawings and solid polygonal-shaped obJect~n multi-grey-level pixel-mapped 
video systems. The method is based on an analysis of boundary conditions at each pixel affected by one 
or more lines. With this method a number of previously needed steps can be quickly eliminated. ~he commonality 
of boundary conditions between adjacent pixels and the coherence of such conditions in a raster-scan 
ordering of such pixels allows efficient generation of these boundary conditions. A recursive subdivision 
approach allows handling of arbitrarily complex cases by a simple boundary-analyzing technique. Compared 
with current line-drawing systems, a video system with this algorithm would also display an improved 
image with respect to certain common visual effects --e.g., distance modulation of l~ie intensity (which 
may be desirable), artificial small bright clusters of detail (which is undesirable). Since the software 
interface to the algorithm may be handled through already- standard graphical subroutines, adoption of 
the algorithm may be accomplished without burdening graphic system users or graphic system-utilizing 
software. This research was partially supported by the National Science Foundation under grant MCS77-03905. 
 &#38;#169; 1979 ACM O-89791-004--4/79/0800--260 $00.75 INTBODOCTION The use of video graphic terminals 
has increased significantly in recent years due to their inherent flexibility and virtually limitless 
display capacity. They are unsurpassed in generation of realistic, continuous-tone and color images, 
for example. They have not been widely utiized, however, for interactive line drawing applications, for 
which refresh line-drawing systems and storage tube displays have traditionaly been used. Refresh systems 
have much more convenient mechanisms for ,oving already drawn graphical entities and both these systems 
and storage tubes generally have higher spatial resolution than current video displays. This paper presents 
a method of using the video display's variable grey- level capability to alleviate some of its deficiencies 
due to its limited spatial resolution. (Although we focus in this paper on the application of this algorithm 
to video terminals, the basic ideas also apply to other output devices (printers, CRT's, even weaving 
looms) which can control the grey level of each picture element in the field of interest.) Current methods 
of digital vector generation (see, e.g., Newman and Sproull(1973)) generally assume only a binary value 
for each picture element (pixel); the resulting line drawing invariably exhibits jaggy, staircase effects 
(fig. I). If a s~all region of the screen is examined closely, the reason for these jaggy lines becomes 
apparent (fig. 2) o The "ideal" edge of a line (now having considerable width in this close- up) may 
often go through the area of a pixel but not cover it completely. The line-drawing algorithm, however, 
makes a binary decision for each pixel, implying that it is either all covered by the line or nut covered 
by it at all. This is sometimes done by sampling the point at the center of the pixel; if that point 
is covered, the pixel is considered covered: if that point is not covered, the pixel is considered not 
covered. In the above example, even a simpler, ~ore direct algorithm was utilized. Since such an algorithm 
(a symmetric DDA in this case) simply generates a sequence of pixel positions which should be set to 
a "I", its decision to put a I at a particular pixel is somewhat more difficult to analyze. The obvious 
solution is to allow a greater range of choices for the line-  See Copyright Pg. 260 drawing algorithm 
than 0 or 1 and have the final value reflect the percentage of the pixel's area covered b7 line (fig. 
3). At first glance the solution would appear to be one of simply adding more precision to the line 
drawing algorithm which calculates the sequence of pixels affected by a given line segment; not simply 
setting them to I or 0, "covered" or "not covered" but calculating a value between 0 and I for each such 
pixel. The futility of any such sequential algorithm, however, is easily demonstrable. In these algorithms 
the line-segments are handled sequentially, i.e. all the affected pixels of one line segment are determined 
and appropriately set (even if to variable grey levels) before the next line segment is considered. Let 
us consider two cases composed of the lines in fig. q: a) the picture consists solely of line segments 
I and 2; or b) the picture consists solely of line segments 1 and 3. In either case, after the first 
line segments had been processed the value of pixel (47, 72) would be 0.5 (on a 0 to I scale). On processing 
the second line segment the algorithm would find 0.5 at (qT, 72} but could not possibly decide (without 
knowing about the previous lanes which caused the 0.5 value} how to alter the pixel. In case a} the pixel 
should, of course, be set to 1.0; in case b) At should be left at 0.5. Thus, An order to determine the 
proper value for a pixel, a!! the line segments affecting it have to be considered together. This suggests 
an algorithm which saves all the line segment information, then calculates the approximate pixel intensity 
values for every pixel in the image in some convenient (e.g., raster-scan) order, and indeed, our solution 
adopts this general approach. PREVIOUS WORK ON THE PEOBLEn In the past few years, with the increased 
availabiity of multi-grey-level vldeodisplays and inexpensive LSI micro- processors, a number of researchers 
have focused on this problem, with encouraging results. Some early work at Xerox Palo Alto Research 
Center on this topic ks described in Sho,p (1973). Crow(1977) explains the undesirable visual effects 
in terms of alias ing phenomena inherent in sampled signals, and suggests a pre-sampling filter as a 
way to eliminate higher frequencies than the sampling one. 8ore recent work is reported in Crow (1978). 
 ca(mull(1978) of NI Institute of Technology described a visible surface algorithm for 3-D scenes which 
precisely calculates the value at each pixel by considering all the visible polygons there. This algorithm 
comes closest to our method. It's generality, however, prevents it from taking advantage of the simplifying 
observations central to our approach. PROPOSED SOLUTION As mentioned above, the overall structure 
of our solution is a raster-scan type algorithm, sirilar to Natkins(1970). Within a single pixel, a recursive 
subdivision approach is utilized (si=ilar to Narnock(1969) and Sutherland(1973}) to calculate the grey-level 
value for this pixel's intensity, which is, of course, related to the fraction of its area not covered 
by polygons. (Of course, we could Just as well have chosen to determine the fraction of its area covered 
by polygons, since the sum of these two values must reach unity; At turns out that the former may 
be just slightly =ore efficient to calculate than the latter.} Before presenting the detailed algorithmic 
structure, we'll first discuss some of the basic elements of our approach. ~SLs: A line-drawing image 
consists of a  set of lime seg=ents on the screen. In our algorithm each such line segment is converted 
into a (long, thin} polygon whose boundary is defined by (fig. 5}. (In general, our algorithm can accept 
any convex polygon.} An edge is oriented, in that it has two sides, an ~S~ i~ (toward the outside 
of the polygon) and a col sid___~ (toward the inside of the polygon). BoundaEx__~ijt__s: The basic 
processed entity in our syste= is a bun~ list of edge intersections for a given area (e.g., pixel} of 
interest (fig. 6). In general an S~ ~rs~ is one free of any polygon coverzng; a clos___ed area is one 
covered by one or more polygons. As will be seen below, significant geometric information concerning 
the enclosed area can be deduced from such a boundary list, thereby avoiding more costly geometric calculations. 
(Note the difference between the boundary of an area and the boundary of a polygon.} Considering now 
the boundary of an area of interest, a (polygon} edge crossing a boundary of such an area is considered 
to be either a e~ (fig. 6). A ~qa~ inter_____!ectio______pq is one through which a counter~clockwise 
traversal at the boundary enters a polygon. A ~Eailinu intersection is one through which such a traversal 
ea~ a polygon. 261 A vertex of a polygon is marked on its two defining edges, each of which is extended 
to the nearest area boundary (fig. 7). An edge extended in this way forws a ~i! ~%e~on. ~/~.9~_~S!XHSD_ 
C__owe~: A solid edge covers a boundary- defined area between its leading and trailing intersections 
--this coverage extending around the ~oundary until the appearance of another edge of the same polygon 
(fig. 8). The only enhancement needed to always be able to calculate the extent of polygon coverage 
from the boundary list is in the situation when an area is completely surrounded (and thus completely 
covered) by a polygon. ~his situation is always detectable in our raster-scan processing order in that 
before reaching a completely covered pixel the processing encounters at least one of the left edges of 
the surrounding polygon (fig. 9). The solution adopted is to detect if the right edge of a pixel is completely 
covered and save the identification number(s) of the polygon(s) completely covering this edge. A fictitious 
edge of this polygon is then inserted at this right edge of the pixel so that the coverage of the next 
pixel can ~e deduced from its own boundary list (fig. I0). No special additional processing is required 
as a result of this enhancement since the desired effect on this new pixel is exactly the same as the 
effect achieved by a "normal" edge being in this same position cowering the entire pixel's area. We note 
also that this fictitious edge will automatically propagate until a right edge of the polygon is encountered. 
  ~!~i~a_L~: We recall that the overall goal of processing a pixel is to calculate the fraction of 
its area left uncovered by polygons. We adopt a divide-and-conquer approach to processing a single pixel, 
in that, if the situation inside the pixel (as reflected in its boundary list) is sufficiently simple 
|in our case this means 0 or 1 polygons present) then we calculate the remaining area directly. Otherwise 
we recursively subdivide the area until we reach sufficiently simple cases. We always attempt splitting 
an area in two along a solid edge in hopes of being able to discard the closed side subarea. We can discard 
the closed side subarea if it is entirely covered by the splitting edge (fig. 11). (@e can simply throw 
away any completely covered area since the final computation we seek is simply the percentage of the 
pixel area left open (i.e., uncovered by any polygon).) newly split .area such as this is completely 
covered if an only if there is no edge in it from the same polygon as the splitting edge (see again 
fig. 8 a and b). Dote, this implies that in the case where the splitting edge is "virtual" at one or 
both ends, the "closed" subarea is never immediately discarded (fig. 12 a and b). The boundary lists 
increase the efficiency cf the splitting process in two ways: a. identifying a ~ost advantageous edge 
along which to split the area,  b. identifying precisely those edges which need to be split in two as 
a result of this area splitting.  We identify a most advantageous edge along which to split the area 
by calculating a "depth count" for each edge along the boundary; this process, similar to parenthesis 
depth calculation, is easily achieved in a single scan of the boundary (fig. 13). A best edge is one 
with minimum depth count and one which completely covers its closed side subarea. We note that the two 
ends of a splitting edge partition the boundary list into two contiguous pieces. The edges which are 
split are si~ply those with one end in one group and the other end in the other group. Again a simple 
parentheses- match type process identifies these edges. The boundary llst for the splitting edge --which 
will now become part of the boundary in each of the two subareas --is constructed out of these edges 
just identified as crossing this line. The complete boundary list for each of the new subareas is constructed 
out of one of the two parts of the old boundary list appended, in the proper order, to the newly computed 
boundary list of the splitting edge (fig. lq). Since a virtual intersection is but a marker for an enclosed 
vertex, its edge need not be extended across any splitting boundaries (fig. 15). Thus these edges' intersections 
are eliminated from one of the two new subareas (the one which does not contain a vertex of that edge). 
 This property also implies that a virtual edge need not be considered until processing reaches the pixel 
in which its vertex (vertices) lies (fig. 16a), and also implies that virtual edges do not need to be 
carried along froK one scan line to the next (fig. 16b).  SYSTE~ OGANIZ ATIOH cur method was designed 
to fit easily into existing video graphic systems. These syste=s almost always use a full-image memory 
buffer {a "frame buffer") from which the screen rust be constantly refreshed in order to maintain the 
image on the video screen (fig. 17). Drauing lines on the screen usually  262 consists of a number 
of MOVE(X,T) and we begin processing of a me, scan  D~AW(I,Y) calls to low level procedures line by 
taking the old XBOTTOM list and which, for a single line segment, removing all virtual edge intersections 
 determine and set the affected pixels in from it --these are precisely those edges the image buffer. 
 whose bottom vertices were located in the previous scan line. The overall organization of our  proposed 
solution involves storing away (say, on disk) each [ (XI,YI), (E2,Y2} ] line-segment pair as it is encountered 
for processing by the current low level procedure. Then, after all the line segments for an image have 
been processed, this file of saved information is input to our algorithm, which calculates the more accurate 
value for each of the pixels on the screen which is affected by one or more line segments. It is interesting 
to note that adoption of our solution will be completely transparent to the user. A subtle visual effect 
may be noticed, however, a few seconds after normal ("old fashioned") processing has finished; this should 
be something of an "ephemeral scan-moving down the screen, adjusting the intensity of certain pixels 
in its path. ALGORITHM DESCRIPTION  We now proceed with a description of the overall algorithm. I. 
Creating y Buckets on Disk As described previously each original llne segment (or other elementary symbol) 
is converted into one or more convex polygons, each polygon being defined by the sequence of edge intersections 
forming its boundary (see again, fig. 5). We established (usually on disk) a buffer for each scan line 
and as each polygon is processed, each one of its edges is put into the 'Y' bucket accordimg to its top 
vertex. When the entire picture has been generated in the standard ("old fashioned) way all the edges 
will have been put into the proper 'Y, buckets on disk. 2. Scan Line Processing The overall processing 
is done in the standard raster scan basis, proceeding from top to bottom on the screen, and in each scan 
line from left to right (as in Watkins(1970}). As Catmull(1978) properly notes, a scan line iS really 
a finite strip of area the width of a pixel. (Although we continue to use the accepted term "scan line", 
we want to keep in mind that the term refers to an arsa.) Por each scan line we keep two ordered lists 
of polygon edge intersections, sorted on X; one for the intersections with the top edge --'XTOP, --and 
another for the intersections with the bottom edge -- 'XBOTTON' --(fig. 18). (as will be described below, 
the XBO~TOM list of one scan line becomes, with winor updates, the XTOP of the next scan line.) The 
new XBOTTOM is composed of the  extensions of the (new) XTOP list and the new entries at this scan 
line. (This kind of updating is utilized in several raster- scan visible surface algorithms --see 
Sutherland, Sproull, and Schumacker(1974) for a good exposition.) Some extensions of the XTOP edge 
intersections may intersect the XEOTTON llne outside the image area --off the left or the right sides 
of the screen. Por these edges, the intersections with the edges of the screen (instead of intersections 
with the XBOTTOM line) are used. The LEFT LIST, which forms the left boundary of the first pixel on 
this scan line, is composed of all those entries of the XBOTTOM list with X values of 0.0. These operations 
are summarized in the following statements: SCAN LINE PROCESSING: BUCKET ~ edges in bucket for this 
Y value (probably from disk); XTOP ~ REMOVE_VIRTUALS( XBOTTOM ); XBOTTOM ~ MERGE(XSORT(EXTEND(XTOP)),XSORT(BUCKET)); 
 LEFT ADJUST(LEFT_LIST,XBOTTOM); XMIN~ MIN(LEFTMOST(XTOP),RIGHTMOST(XBOTTOM)); XMAX~ MAX(RIGHTMOST(XTOP),RIGHTMOST(XBOTTOM)); 
 for X=O to 511 do if (X(X~I~ or X;XMAX) then output(BACKGROUND_COLOR) else PIXEL_PROCESSING; end; 
 We now describe the processing at each pixel position.  PIXEL PROCESSING   ~.~_.~_~ ~_~_~.~.: As 
described previously we need to form the pixel boundary list, which is composed of a counterclockwise 
traversal of the pixel. This boundary is actually the concatenation of four lists: 'TOP', 'LEFT*, tBOTTOM*, 
and 'RIGHT0. We note that: I. 'TCP' and 'BOTTOM' are already defined between the two pointers carried 
along the 'XTOP' and 'XBCTTOM' lists; 2. The 0RIGHT, list of one pixel becomes the 'LEFT' list of the 
next (except for "virtual-edge intersections which are dropped, and "fictitious-covering edges  263 
 which are added --as described above). In this fashion only one quarter of the overall pixel houndar~ 
list needs to be computed, the 'BIGHT' list (fig. 19). The computation of this list can be easily accomplished 
by first scanning the already existing 3 lists: 'TOP', 'LEPT*, and 'BOTTOB'. Then, since each edge has 
two intersections in a closed boundary l~st (the area is a convex polygon), the entries for the 'BIGHT' 
list are exactly those intersections of *TOP', 'LEFT' and 'BOTT08* which do not have matches ~Ii that 
remains to form the 'RIGHT' list is the calculation of these edge intersections with the right edge of 
the current pixel. at this point there is a complete boundary list for the current pixel which is made 
of four separate boundary lists, all of them linked in a counterclockwise order and ready for the actual 
poly9on cover processing. The overall pixel processing, then, can be summarized as follows: PIXEL PROCESSING: 
 if X~0 then LEFT LISTs MODIFY RIGHT(RIGHT LIST); PIXEL LIST ~ FINISHBOUNDARY( XTOP, XTOPPOINTERS, 
 XBOTTOM, XBOTTOMPOINTERS, LEFT LIST ); output( AREA(PIXEL LIST)) ; AEE~ calculates the extent of 
polygon cover for the area described by the PIIELLIST as mentioned previously, it does this either by 
direct calculation (if the list contains either 0 or 1 polygons) or by recursively splitting the area 
until sufficiently simple subareas are encountered. Recursive Punction IRES(boundary_list) if SIMPLE(BOUNDARYLIST) 
then return CALCULATEAREA(BOUNDARY_LIST) else SELECT (BOUNDARY LIST, SPLITTINGEDGE) ; CUT ( BOUNDARY_L 
I ST, SPLITTING EDGE, OPEN SIDE LIST,CLOSED SIDE_LIST) ; if UNIQUE EDGE (SPLITTING_EDGE, CLOSED SIDE 
LIST) ~hen return AREA(OPENSIDELIST) else return AREA(CLOSED_SIDELIST) + AREA(OPENSIDE_LIST) ;  END 
AREA; SINPLE is a predicate (Bool~an function) which determines whether or not the area represented by 
"boundary-list" is sufficientl7 simple to calculate the extent of polygon cover directly. &#38;n affirmative 
answer is reached if a) there are no polygons at all in the area or b) there is only a simple polygon 
or fraction thereof in the area . CALCULATE_ABEl directly calculates the area of pol~gon cover (in absolute 
pixel units) of a si, ple boundary-defined area. SELECT determines a best edge to be used for splitting 
the area into two subareas. CUT divides an area into two new areas creating a new boundary list for each 
subarea. It splits the initial list into two non-closed lists and then concatenates each non-closed list 
with the boundary list found for the splitting edge. UNIQUE EDGE determines whether or not the "splitting 
edge"'s polygon has another edge which is in the "closed side_list". (If it doesn't, then the entire 
closed side area is covered by the "split~ing_edqe"'s polygon.) Be present in fig. 20 exa~ples of the 
results cf the just-described algorithm, as co=pared with the sa=e data displayed on the sa~e system 
~Genisco GCT3) using the standard line-drawing software. CONCLUSION ~e have presented a method for creating 
precise, s~ooth line drawings on multi-grey level video displays. The method determines the proper pixel 
values even in extreme cases in which many lines appear within a single pixel Geometric calculations 
such as line intersections are uiniKized by reliance on si~ple analyses of ordered boundary lists. With 
co~ronly available video monitors being limited at present to about 1024 x 1024 pixels, ,ethods such 
as the one Just presented may provide the least expensive ways to achieve higher quality images on these 
displays.  REPEEERCE5 Catmull, E.(1978), "A Hidden-Surface Algorithm with Anti-kliasing",  ~c~n~ 
~ ~ ACN-SIGGa~PU Ann~al C on~ereng.e on C om~.~.~ G~ics and ~sac~ .T.s.~.~.i.q.~s.~, (vol. 12, (3):6-11, 
~ GraFhipS) Crow, P.C.(1977), "The Eliasing Problem in Computer-Generated shaded Images", (11):799-805 
Crow, F.C.(Ig78), "The Use of Grayscale for Improved Baster Display of Vectors and Characters", Proceedin~ 
of 197__8 ACN-S~R_A PH &#38;~nual CqnfeEence o_n. CoEpute~ Gra~ and Interactive T~es, (Vol. 12, (3):I-5, 
 264 Genisco Computers (1977) GCT~GC~!a P_.ro~rammin~ ~erence ~anual, Irvine, California Newman, W.8. 
&#38; Sproull, R.F.(1973) , P__rlD~i~!S~ of Interactive Com~ ~hi~c~, McGraw-Hill Stoup, Richard G. (1973), 
"Some Ouantization Effects in Digitally Generated Pictures", ~S~___u~ Sutherland, I.E. (1973), -Polygon 
Sorting by Subdivision: ~ Solution to the Hidden-Surface Problem", unpublished Sutherland, I.E., Sproull, 
B.F. g Schumacker, R.G.(1974), "A Characterization of ~en Hidden-Surface Fig. 3 75 72 i 71 46 72 71 46 
47 48 line segment 1 (line segment 3 is similar) line segment 2 Fig. @ Fig. I b ~ d line segments J /N 
N a edges k m h 1-4: from application program a-m: internally generated by system Fig. 2 Fig. 5 265 
trailing  open area polygon boundary of area .... | leading t Iosed area Fig. 6 boundary-__ A~'" 
"; ..... ''"''"",, .  defined ~ ~ ! po.~ygon .jr,,,,,,,,,,,,, ~..... ,  /~----~ over of polygon edge 
I V  2" J extends through area ~ Fig. 8 splitting edge ~ ....~ ""~, INTO / /--\ -,~,-~ ---~/ T --\ 
"'z':ZZ~,i ', ,',1 virtual edge intersections Fig. 7 //llllllllllll Illllllllll~ no edge of the polygon 
in this (completely covered) pixel Fig. 9 "'b111~1ILll 1111111| i b "fictitious" edge induced by edge 
A Fig. 10 kept / ,/" / any ,, Fig. 11 266 splitting edge /" best splitting edge split into Fig. 12 (both 
kept) Fig. 13 Jj K t2 M IN-' ~ ~ ~ B splitting G F i, E D C edge J I ! H B E "D Original boundary list: 
Boundary lists after splitting: MNABCDEFGHIJKLM MNABCDEFGHP OHIJKLM Fig. 14 HI ~ splitting edge F E, 
A I B I c original boundary list: new boundary list: Pig. JAB CDE F GH I J 3 A B C D E F L K and 15 ~ 
267 scan line/strip I I I , I scan line/strip --" --"-A~--~ ,'t- pixel: i i+l i+2 i+3 i+4 solid edges 
virtual edge (advanced) (not advanced) (edge A not considered until i+4) (a) Fig. 16 (b) Video l aster-Sca~] 
Host ~Graphics L ~ CPU qProcessorl- l Memo~z_[ I Display ~I Generator Scan ~(Tv) 3] (optional) Fig. 
17 XBOTTOM / XTOP (scan line/strip) XBOTTOM XTOP / (extended)e Fig. 18 XTOP f- p~nters-~ I --XTOP 
li@~ ~' ~ II4~-RIGHT LIST ' LEFT LIST-----~ ~, ~ (to be determined) (converted RIGHT LIST of i: II previous 
pixell --XBOTTOM list pointers Fig. 20a: Standard processing Fig. 20b: New processing (same as Fig. 
i; placed here for comparison) [All parts of Fig. 20 are 256 x 256-pixel images] 268    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807455</article_id>
		<sort_key>270</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Smoothly shaded renderings of polyhedral objects on raster displays]]></title>
		<page_from>270</page_from>
		<page_to>275</page_to>
		<doi_number>10.1145/800249.807455</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807455</url>
		<abstract>
			<par><![CDATA[<p>The appearance of raster-scan renderings of polyhedral approximations to curved surfaces can be enhanced greatly by shading them in a manner that varies smoothly across each polygon and which matches the correct shade at each vertex. Henri Gouraud and Bui Tuong-Phong have previously described two methods of computing such shading functions. While the computations in Gouraud's method are quite quick to perform, the renderings produced often exhibit pronounced Mach bands, and animated sequences tend to have annoying fluctuations in intensity. Phong's method tries to cure these problems, but is much more expensive computationally. We will show a new, faster method of computing Phong shading, and discuss the relationship of this method to Gouraud shading. We will also exhibit representatives of a class of surfaces for which Phong shading surprisingly produces worse Mach bands than Gouraud shading.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Shading</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.1</cat_node>
				<descriptor>Smoothing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31063954</person_id>
				<author_profile_id><![CDATA[81539299356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Duff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Laboratory, New York Institute of Technology, Old Westbury, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Models of Light Reflection For Computer Synthesized Pictures, by James F. Blinn, SIGGRAPH '77 Proceedings pp. 192-198, July 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Computer Display of Curved Surfaces, by Henri Gouraud, Department of Computer Science, University of Utah, UTEC-CSc-71-113, June 1971.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Illumination for computer-generated images, by Bui Tuong-Phong, Department of Computer Science, University of Utah, UTEC-CSc-73-129, July 1973.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Smoothlv Shaded Renderings of Polyhedral Objects on Raster Displays by Tom Duff Computer Graphics Laboratory 
New York Institute of Technology Old Westbury, New York, 11568 Abstract The appearance of raster-scan 
render- ings of polyhedral approximations to curved surfaces can be enhanced greatly by shading them 
in a manner that varies smoothly aoross each polygon and which matches the correct shade at each vertex. 
Henri Gouraud and Bui Tuong-Phong have previously described two methods of com- puting such shading functions. 
While the computations in Gouraud's method are quite quick to perform, the renderings produced often 
exhibit pronounced Mach bands, and animated sequences tend to have annoying fluctuations in intensity. 
Phong's method tries to cure these problems, but is much more expensive computationally. We will show 
a new, faster method of computing Phong shading, and discuss the relation- ship of this method to Gouraud 
shading. We will also exhibit representatives of a class of surfaces for which Phong shading surprisingly 
produces worse Mach bands than Gouraud shading. ~. Introduction Henri Gouraud has shown, in [Gouraud 
71], that the appearance of raster-scan renderings of polyhedrally ap- proximated curved surfaces can 
greatly be enhanced by shading each point on the sur- face with a colour computed by linear in- terpolation 
of "exact" shading values at the vertices of the polygon containing the point. Bui Tuong-Phong, in [Phong 
73], noted several problems with Gouraud shad- ing, and proposed a new shading method which in some measure 
remedied those dif- ficulties. The nature of some of these problems, and the extent to which Phong was 
successful will be discussed below. As a byproduct of this investigation, we will demonstrate an improved 
method of calculating the Phong shading function. 2. Terminology We will use the letters P, Q, and 
R to designate the normals to a surface at three given points. L will denote a vec- tor which indicates 
the direction of a light source which is considered to be ar- bitrarily distant (or "at infinity"), so 
that L is independant of the point upon which the light shines. E is used for the vector in the direction 
of the viewer's eye, which is also at infinity. E, L, P, Q and R are always taken to be unit vec- tors. 
That is E-E = L-L = P.P = Q.Q = R-R = 1 Note that this means that, for example, L'P = cos@, where ~ 
is the angle between L and P. 3. Illumination m Any method for rendering surfaces must somehow model 
the way in which the light which impinges on the surface is re-directed toward the viewer's eye. One 
of the simplest lighting models is Lambert's Law for diffuse reflectors, which states that the intensity 
perceived by an observer is independant of the observer's position, and varies directly with the cosine 
of the angle between the lighf direction and the normal to the sur- face at a given point. That is, 
i = kL-P, (i) where i is the amount of reflected light, and k is a value which depends on the in- tensity 
of the light and the reflectance of the surface. Most surfaces are not perfect diffusers, and exhibit 
a certain amount of specular reflection. The specular com- ponent is greatest when the surface re- flects 
the light directly at the observer's eye, and drops off as the light moves away from that direction at 
a rate which depends on the properties of the surface being modelled. For surfaces with isotropic reflectance 
properties (not, for &#38;#169; 1979 ACM O-89791-004--4/79/0800--270 $00.75 See Copyright Pg. 270 example, 
brushed aluminum or hair), the rate at which the specular reflection drops off may be expressed as a 
function of the cosine of the angle between the normal P and the direction of maximum highlight H. This 
cosine is just H.P. H is defined by E+L  H = ]~L~-- [Phong 73] proposes the illumination function 
 i = dL'P+s(H-p)b+a, (2) where d and s are the maximum intensities of the diffuse and specular components, 
b is related to the "shininess" of the sur- face (large values of b give pinpoint highlights, small values 
give broader ones), and a is the contribution of the ambient light in the environment. This, and several 
other illumination models are discussed in [Blinn 77], which is a good detailed introduction to the whole 
subject of Illumination. 4. Gouraud and Phong Shading I-~ d-~ta~, Gouraud's shading method is as follows: 
We are given a collection of polygons with shading values associated with each vertex. The vertex shading 
values may of course be assigned by any means whatever, but for our purposes, let us assume that we are 
given the normal vector at each vertex, and can compute a shading value from it. At the points at which 
a given scanline intersects the edges of a polygon, we compute a shading value by linearly interpolating 
the shad- ing values at the endpoints of the edges. Shading values for the interior points of a polygon 
are determined by linear inter- polation along scanlines of the values computed where the scanlines meet 
the edges of the polygon. Phong's shading procedure is similar to Gouraud's, except that instead of 
in- terpolating shading values, we interpolate the normals given at each corner, and evaluate the illumination 
function at each point. This is considerably more expen- sive, since three normal components must be 
computed, rather than one shading value, and the vector at each point must be normalized before evaluating 
the shad- ing function. There are several problems with these shading methods. First, if an object should 
have a highlight at any point but a vertex, Gouraud shading will misplace the highlight, or omit it altogether, 
since the shading values at interior points must interpolate those at the corners. This problem is so 
severe as to render Gouraud shading unusable when a non-Lambert's Law lighting model is used, unless 
a large number of polygons are used in the object definition. Figures la and b show a high- ly specular 
sphere, approximated by a small number of polygons, Gouraud and Phong shaded, respectively. Since Phong's 
method interpolates normals rather than shading values, the intensity values at each point need not lie 
between those at the corners. It should be clear that any polygon on which we expect to see a highlight 
(i.e. those polygons for which the normals at the corners surround the H vector), will in fact exhibit 
a highlight. A problem shared by Phong and Gouraud shading is that if an object and its light source 
are rotated together in the image plane, the shading of the object can change, contrary to expectation. 
For ex- ample, if the polygon ABCD in Figure 2 is viewed from an angle such that 1 is a scanline, the 
shading value at point P will depend only on the values at points A, B and C. In particular, moving point 
D will not change the shading value computed at P. If, however, the viewer is rotated 90 degrees, so 
that i' is a scanline of his view, moving D can change the shading value, since the ratio in which i' 
cuts AD can change as D moves. This problem can be ameliorated by interpolating shading values (or normals) 
in a rotation-independant manner. Such an interpolator can be constructed as fol- lows: let A~,(l<i<n) 
be the points of a polygon, and let S~ be the shading value (or normal) at A=. Further, let T be any 
point inside the~polygon, and let f~ (T) be any function which is non-zero at A i and zero at all other 
Aj. Then i=~ifi(T)Si n Z f.(T) i=l 1 is an appropriate interpolator. One pos- sible choice for fi(T) 
is (I-D i(T)) ~ D. (T), j/i ] where Di(T) is the distance from A i to T. Of course, in the Phong shading 
case, the vector computed by this formula must be re-normalized. For all but the simplest of applications, 
this function is probably too slow to use --it is certainly out of the question for high-resolution 
animation applications. A quicker scheme, which works only for quadrilaterals is as follows: Let 
A~,(l<i<4) be the four corners of the qua- d~ilateral, and let S~ be the shading values (or normals) 
at t~e four corners. Compute a linear transformation of homo- geneous co-ordinates which maps A 1 into 
 (0,0), Ap into (I,0), A 3 into (l,l)-and A~ into (0,I). Use this transformation t~ transform each 
point T of the quadrila- teral into a point (u,v) 0<u,v<l. Then, an appropriate shading value ~or normal) 
 is  271 (l-v) ((l-U)Sl+US 2) + v((l-u)S4+uS 3)  This is relatively cheap, compared to the more general 
scheme discussed above, but is still quite expensive in the absolute. 5. MachBands  ~ot~er problem 
with Gouraud shading which Phong hoped to overcome is the Mach bands which appear where adjacent Gouraud 
shaded polygons meet. Mach bands are light or dark lines which the eye per- ceives at places where the 
spatial derivi- tive of the shading function is discon- tinuous or changes quickly. The eye enhances 
these discontinuities in order to make it easier to see the edges of ob- jects. Mach bands are readily 
apparent in Figure 3, which shows a Gouraud shaded display of a sphere approximated by 72 po- lygons. 
(Note: because Mach bands are an optical illusion whose presence depends on the spatial derivative of 
the image inten- sity being large, they tend to disappear on close examination, since as your eye approaches 
an image, the apparent spatial frequencies in the picture decrease. Thus, paradoxically, Mach bands are 
more visible when pictures are viewed from a greater distance.) Phong's thesis discusses the Mach band 
problem, and a casual reading might lead one to believe that he had solved it. An informal survey of 
the staff of the Computer Graphics Lab revealed that the majority of those aware of the problem thought 
he had, in fact, solved it, although a little reflection will convince the reader that it is not so. 
The illus- trations in Phong's thesis do show that in general the Mach bands are much improved by Phong 
shading. It is interesting to compute the size of the shading derivative discontinuities at the edges 
of a Phong shaded polyhedron. For simplicity, we will use the Lambert's law illumination model, and consider 
the shading of a scan line which has three un- iformly spaced edges crossing it. The normals at these 
edges we will call P, Q and R, from left to right. Let Son(a) be the shading function between ~ and Q. 
Spn(0) is the shading value at P, and SPA(1) is the shading value at Q. By equation 1 above, and remembering 
that P-P = Q-Q = I: aQ+(l-a)P (3) SpQ(a) = L-laQ+(l_a)p I = L-aQ+(l-a)P ~(aQ+ (l-a) P) taQ+(l-a) 
P) aQ+ (l-a) P = L  ~a2Q-Q+2a(l-a)P-Q+il-a)2p-p aO+(l-a)P = L ~/a2+2aP.Q-2a2p-Q+l-2a+a 2  = L" 
aQ+(l-a)P (4) ~/2 (i-P- Q) a2-2 (l-P- Q) a+l For the sake of compactness, let B=2(i-P.Q). The derivative 
S'pQ(a), ob- tained after much calculation, is S'pQ(a) =  2Ba-B (Q-P)qBa2-Ba+i-(P+a(Q-P)) 2qBa2-Ba+l 
 L. Ba2-Ba+l The left derivative of the shading func- tion at Q is just S'pQ(1) = L-((P'Q)Q-P)  The 
right derivative, obtained similarly, is S'QR(0 ) = L" (R-(Q.R)Q)  Clearly, in general the left and 
right derivatives are different. Let Dp be the size of the discontinuity in the Phong derivative at 
Q. Dp = S'QR(0)-S'pQ(1) = L-(R-(Q" (P+R))Q+P)  NOW, let us consider the analogous Gouraud shading function 
GpQ(a). GpQ(a) = (i-a)L.P+a(L'Q)  = L-P+aL-(Q-P) (5) G'pQ(a) = L" (Q-P) D G = G'QR(0)-G'pQ(0)  
= L. (R-Q)-L" (Q-P) = L-(R-2Q+P)  If Phong shading is to produce uniformly less severe Mach bands than 
Gouraud shad- ing, then ID_I must be smaller than ID I. Certainly, t6is is usually the case. HEw- ever, 
it is possible for ~DDI to be larger than IDol, indicating tha% Phong shading can produce worse Mach 
bands than Gouraud shading. Consider, for example, sets of vectors of the following form, which might 
easily appear when rendering spheres or cylinders: L = [0 0 i] P = [.6cos(-O) .6sin(-8) .8] = [.6cos(8) 
-.6sin(8) .8] 272 Q = [.6cos(0) .6sin(0) .8]  = [.6 0 .8] R = [.6cos(8) .6sin(O) .8] Now : D G = 
[0 0 i]-(R-2Q+P) = .8-1.6+.8 = 0 and Dp = [0 0 i].(R-(Q.(P+R))Q+P)  = .8-.8([.6 0 .8]-[1.2cos(8) 
0 1.6])+.8 = I. 6-. 8 (. 72cos (8) +i. 28)  = . 576-. 576cos (8) Thus, except in the trivial case where 
8=0, Dp is non-zero, and a Phong shaded surface will show a Mach band where the same surface Gouraud 
shaded will show none. Figures 4a and 4b, which illustrate an extreme case of this phenomenon, were 
generated from the following (admittedly pathological) set of vectors: P = [0 .8 .6] e : [~/Vgf 0 .3] 
 R = [0 1 0]  L = [0 0 l], For this set, the value of D_ is 0, and D_ is .546. Figure 4a shows ~ surface 
with these normals Phong shaded, and Figure 4b shows the same surface Gout aud shaded. Every scanline 
of these surfaces has nor- mal P at the left, Q in the middle and R on the right. As expected, the Phong 
shaded version evinces a pronounced Mach band, while none is visible in the Gouraud shaded version. To 
help show what occurs in more usual circumstances, Figures 5a and b show Phong and Gouraud shaded spheres, 
approximated by 800 polygons (40 around the equator by 20 from pole to pole). Slight Mach bands can be 
discerned near the right edge of both the Phong and Gouraud shaded versions. Figures 5c and d, included 
for comparison, show the same surface, first shaded using the exact nor- mals for a sphere, and secondly 
using the actual normals to the polygons to produce a faceted rendering. 6. Speed of Rendering  The 
usual method of computing the Phong shading function involves evaluating the right hand side of equation 
3 at each point inside each visible polygon in the scene. This can be computed with 6 multi- plications, 
7 additions, a square root and a division, if finite differences are used to eliminate the multiplications 
which ap- pear to be needed to evaluate aQ+(l-a)P. Note, however, that equation 4 can be re- written 
as SpQ(a)_ = --aL.Q+(l-a)L-P  (6) k J2 (l-P- Q) a2-2 (l-P. Q) a+l Notice that the numerator of the 
right hand side is just the Gout aud Shading function (equation 5), and the denominator is the square 
root of a quadratic in a. Because P and Q are unit vectors, i-P.Q is constrained to be between 0 and 
2. Thus, the denominator cannot range lower than 0 or higher than 1 when 0<a<l. One rather surprising 
result of this observation is that, at least when using Lambert's Law, Phong shading always produces 
a brighter rendering than Gouraud shading --indepen- dant of the shape and orientation of the surface, 
and independant of the light direction. Occasionally it has been sug- gested (although not, to my knowledge, 
in print) that Phong shading can be sped up at the expense of image quality by omit- ting the step of 
normalizing the normal vector at each point. Since this leaves us with a slow method for doing Gouraud 
shading, the merit of this suggestion is somewhat dubious. The right hand side of equation 6 is computable 
much more quickly than the form in which the Phong shading function is usually given, is usually given; 
at each interior point we need do only 3 addi- tions, a square root and a division, if differencing between 
adjacent pixels is used to best advantage. This saves 6 mul- tiplies and 4 adds over the usual method. 
It should also be noted that the square root in the denominator can be computed to sufficient precision 
for display use by linear interpolation from a small table, since the denominator polynomial is guaranteed 
to be between 0 and I. Use of a 64 element table gives 12 bits of preci- sion, which is more than adequate 
for modern raster displays. It should be noted that while the above algorithm is stated only for the 
Lambert's Law case, it is applicable to most other illumination schemes, since al- most all of them compute 
the dot product of the normal vector to the surface with one or two other vectors (usually L and H), 
and compute some function of the resulting values. The following table shows the actual execution times, 
in seconds, of the pro- gram used to generate the pictures of fig- ure 4, executing on a PDP-Ii/70. The 
first column shows times obtained when us- ing Lambert's law shading; the second column shows times for 
Phong's rule (equa- tion 2, above). The row labelled "Slow Phong" is for Phong's interpolation scheme, 
not using the finite difference speedup mentioned above; "Fast Phong" is for Phong"s algorithm with finite 
dif- ferencing, "Eqn. 6" is for the new method derived from equation 6, and "Gouraud" is for Gouraud 
shading. Lambert Eqn. 2 Slow Phong 81.7 177.2 Fast Phong 46.7 146.8 Eqn. 6 31.0 125.8 Gouraud i0.0 
10.2 7. Conclusions We have noted several difficulties with two important and well-known smooth- shading 
algorithms, particularly the prob- lems of rotation variance and Mach bands. In the course of the investigation, 
we have devised a new method of implementing  273    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807456</article_id>
		<sort_key>276</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Tint fill]]></title>
		<page_from>276</page_from>
		<page_to>283</page_to>
		<doi_number>10.1145/800249.807456</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807456</url>
		<abstract>
			<par><![CDATA[<p>To fill a connected area of a digital image is to change the color of all and only those pixels in the area. Fill algorithms for areas defined by sharp boundaries (e.g., a white area surrounded by a black curve) have been implemented at several color computer graphics installations. This paper presents an algorithm for the more difficult problem of filling areas with shaded boundaries (e.g., a white area surrounded by a curve consisting of several shades of gray). These images may arise from digitizing photographs or line drawings with a scanning video camera, or they may be generated by programs which produce antialiased line segments or dekink black-and-white images. When an area in such an image is to be filled with a new color, it is desirable to have the fill algorithm understand the shaded edges and maintain the shading with shades of the new color instead of the old. The tint fill algorithm presented here accomplishes this task. Its name arises from its ability to change only the tint (hue and saturation) of a pixel, leaving the value (blackness) unchanged. Although the algorithm was motivated by and is written in terms of color, it has a more general interpretation, which is also presented.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Color]]></kw>
			<kw><![CDATA[Fill]]></kw>
			<kw><![CDATA[Flood]]></kw>
			<kw><![CDATA[Gradient]]></kw>
			<kw><![CDATA[Hue]]></kw>
			<kw><![CDATA[Matte]]></kw>
			<kw><![CDATA[Saturation]]></kw>
			<kw><![CDATA[Tint]]></kw>
			<kw><![CDATA[Value]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P15765</person_id>
				<author_profile_id><![CDATA[81100078209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alvy]]></first_name>
				<middle_name><![CDATA[Ray]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[COmputer Graphics Lab, New York Institute of Technology, Old Westbury, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Kenneth C. Knowlton, "The Beflix Movie Language", in Proceedings of the Spring Joint Computer Conference, 1964. (See also, Kenneth C. Knowlton and Lorinda L. Cherry, "Fortran IV Beflix", in Proceedings of the UAIDE Annual Convention, San Diego, 1969.)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[W. J. Kubitz and W.J. Poppelbaum, "The Tricolor Cartograph: A Display System with Automatic Coloring Capabilities", in Information Display, November/December, 1969, pp.76-79.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807380</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Henry Lieberman, "How to Color in a Coloring Book", in Proceedings of the Fifth Annual Conference on Computer Graphics and Interactive Techniques (Siggraph 78) August 21-25, 1978, pp. 111-116.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Joan E. Miller, personal communication, Bell Labs, Murray Hill, N.J., July 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Theodosios Pavlidis, "Filling Algorithms for Raster Graphics", in Proceedings of the Fifth Annual Conference on Computer Graphics and Interactive Techniques (Siggraph 78), August 21-25, 1978, pp. 161-166.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Craig Reynolds, "Filling Polygons", in Architecture Machinations, Department of Architecture, Massachusetts Institute of Technology, Room 9-518, May 3, 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>321570</ref_obj_id>
				<ref_obj_pid>321556</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Azriel Rosenfeld, "Connectivity in Digital Pictures", in JACM 17:146-160, January 1970.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807361</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Alvy Ray Smith, "Color Gamut Transform Pairs", in Proceedings of the Fifth Annual Conference on Computer Graphics and Interactive Techniques (Siggraph 78), August 21-25, 1978, pp. 12-19.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Alvy Ray Smith, "Paint", Technical Memo No. 7, Computer Graphics Lab, NYIT, Old Westbury, NY 11568, July 1978.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807457</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Garland Stern, "SoftCel - An Application of Raster Scan Graphics to Conventional Cel Animation", in these Proceedings.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TTNT FILL Alvy Ray Smith COmputer Graphics Lab New York'Institute of Technology Old Westbury, NY 11568 
 ABSTRACT To fill a connected area of a digital image is to change the color of all and only those pixels 
in the area. Fill algorithms for areas defined by sharp boundaries (e.g., a white area surrounded by 
a black curve) have been implemented at several color computer graphics installations. This paper presents 
an algorithm for the more difficult prob- lem of filling areas with shaded boundaries (e.g., a white 
area surrounded by a curve consisting of several shades of gray). These images may arise from digitizing 
photographs or line drawings with a scanning video camera, or they may be generated by programswhich 
produce antialiased line segments or dekink black-and-white images. When an area in such an image is 
to be filled with a newcolor, it is desirable to have the fill algorit~n understand the shaded edges 
and maintain the shading with shades of the new color instead of the old. The tint fill algorithm presented 
here accomplishes this task. Its nsme arises from its ability to change only the tint (hue and saturation) 
of a pix- el, leaving the value (blackness) unchanged. Although the algorithm was motivated by and is 
written in terms of color, it has a more general interpretation, which is also presented. Key words: 
fill, flood, tint, gradient, hue, sa- turation, value, color, matte. CR categories: 8.2, 3.41. INTRODUCTION 
 We reinvent the wheel in the first half of this pa- per by solving the following simply stated problem: 
 Given a connected set A of points on the 2-dimensional integer grid, all of the sane color c, and bounded 
by points, none of color c, and given a color c' ~ c, find an algo- rithm for changing all and only the 
points of A from color c to c'. We shall call an algorit~ which solves this prob- lem a fill algorithm. 
Fill algorit~s have been presente~-~veral times before in various guises (e.g., [1,2,3,6]). We present 
one here not only to document it thoroughly but also to serve as a basis for generalization, in the second 
half of the pa- per, to a more sophisticated algorithm to be called the tint fill algorithm. It will 
be easier to ex- plain---~nt--fil Iing after (simple) filling is &#38;#169; 1979 ACM 0-89791-004--4/79/0800--276 
$00.75 See Copyright Pg. 276 described, so a detailed definition is postponed until then. Tne filling 
described here is indepen- dent of information external to the integer grid, so is not to be confused 
with the rendering of an external data set [5]. Our bias is toward color computer graphics as evi- denced 
by use of the word "color" in the problem statement above. By the color of a point we simply mean a mapping 
of the po~-~nto a set C, which we choose here to call the set of colors. Hence the intuitive model has 
each point represented by a small square centered on the point and painted some color. C might be the 
set M={0,1,...,255} where 0 is interpreted as black, 255 as white, and all oth- er "colors" as grays. 
Or C might be the set MxMxM where each triple is interpreted as the red, green, and blue (RGB) primary 
components of a color. A rectangular subset of these squares forms a picture, and each square is therefore 
called a pixel, from picture element. Changing the color of an area, a connected set of pixels, in a 
picture is called fillinc~ the area. By connected we shall mean 4-connected in the sense of Rosenfeld 
[7]. Two pixels are 4-connected if they share exactly an edge, 8-connected if they share at most an edge 
or at least a corner. For I the integers, a set A of points in IxI is 4-connected if and only if for 
any two points P and P' in A there is a subset B of points in A, B={P0,Pi,...,Pn }, such that Pi is 4-connected 
to P.. for 0<i<n, P-=P, and P =P'. B is said to be a 4!~nnected path ~n A. n The boundary of a 4-connected 
set A of points in IxI is the set B of all points 4-connected to points in A but not in A. Thus the boundary 
of a 4-connected set is only 8-connected (and vice ver- sa). We shall describe the filling of 4-coP~ected 
areas and only briefly mention the filling of 8-connected areas. For presentation of the fill algorittml 
it is con- venient to think of a picture as stored in a digi- tal memory where a location has address 
(x,y) and the value stored there is c. Such special purpose memories do exist and are called frame buffers. 
It is the presence of several of these frame buffers at NYIT (New York Institute of Technology) which 
was the motivation for a fill progr~m~ and hence for this paper. More specifically, a frame buffer is 
a random ac- cess digital computer memory designed to hold two- dimensional information, where its contents 
is con- tinually displayed on a standard color video moni- tor. At NYIT a typical frame buffer has 243K 
bytes of memory (3x243K bytes for RGB frame buffers) ar- ranged to display 486 lines of 512 pixels each. 
Thus there are 8 bits of storage for each pixel (24 bits for RGB), and the contents is called a ~_alue 
 (pixel value). Thirty times a second, the video circuitry of a frame buffer displays the memory, in 
standard video interleaved scanline order, by doing a table lookup on each successive pvalue along a 
scanline. The three values returned from the table directly control the three gun voltages of the mon- 
itor. Hence the table is called a colorma p. Be- cause of this indirection, the association of a given 
pvalue with a color - and hence the tint and value of this color [8] - is completely arbitrary to within 
the gamut, or range, of colors which the video monitor can display. There are many ways to create arbitrarily 
shaped areas in a frame buffer. Two common ways at NYIT are by handpainting [9] or by automatic entering 
of animated cartoon characters [i0]. Using the fill algorithm, every pvalue in such an area may be changed 
automatically by first selecting the new pvalue desired and then indicating anypoint in the area to be 
filled. Because of the table lookup described above, changing every pvalue in an area is equivalent to 
changing the color of the area. The fill algorithm described below assumes a user has selected an area 
to fill with a new pvalue he has selected. He passes the area information to the algorithm by specifying 
only a seedpoint to it. This point - i.e., an (x,y) pair - might be select- ed by typing at a key~x)ard 
or by pointing with the stylus of a tablet, for example. The area to be filled is, of course, the set 
of points 4-connected to the seedpoint and of the same pvalue as that originally held by the pixel there. 
 First a basic fill algorithm is presented. Then it is made faster by a simple observation. The exten- 
sion of fill to RGB, or 24-bit, frame buffers is discussed briefly. Finally a more sophisticated fill 
algorithm is presented which can fill areas bounded by antirastered, or "smooth", edges (see below). 
This algorithm, called tint fill, is used extensively at NYIT for coloring animated cartoon characters 
entered into a frame buffer by digitiz- ing the output of a scanning video camera. CONVENTIONS In the 
sequel there is a set of routines which de- fine the fill algorithm and variations on it. We will use 
the following conventions: A variable in a routine is assumed global to all subroutines called from it. 
The symbols $right, $1eft, Stop, and $bottom represent the maximum and minimum values which x and y may 
ass~ne in a given frame buffer. For example, for the frame buffers at NYIT $1eft=0, $right=511, $bottom=0, 
and Stop=485. The data type ~value holds the information contained in one pixel in a given frame buffer. 
For ex~nple, a pvalue holds 8 bits for an 8-bit frame buffer or 24 bits for a 24-bit frame buffer. Finally, 
upper case names are procedure names and underlined terms in procedure statements are assumed to be reserved 
words of the language used. BASIC FILL ALGORIT~  All the algorithms to be presented are scanline oriented. 
That is, each algorithm tries-~fill along a scanline before it changes y, the vertical coordinate. The 
basic notion is that FILL fills all pixels 4-connected to the seedpoint on the first scanline. Then it 
looks at the scanline above and below for points 4-connected to the scanline segment just filled (and 
of the same color as the seedpoint pixel before it was filled). A n~ber of these points sufficient to 
guarantee con- nectivity go on a stack maintained by FILL. When the scans are finished, a point is popped 
from the stack and this becomes a new seedpoint. Only one point per scanline segment to be filled need 
be pushed. Fig. 3 shows the filling of five scanline segments. The black dots are points pushed onto 
the stack. The variables ix and rx used in the formal algorithm statement below are the left and right 
x coordinates of a scanline segment. procedure BASICFILL (seedx,seedy,newpv) ; integer seedx ,seedy; 
pvalue newpv; inte~jer x,y,lx,rx; pvalue new,old; x :=seedx; y: =seedy; new: =newpv; old :=GET; 
if old=new then return; PUSH; while STACKNOTEMPTY d_o q begin POP; if GET=new then continue; FILLINE; 
 SCANHI ; SCANLO;  end end The utility subroutine GET returns the pvalue stored at frame buffer location 
(x,y). Its comple- ment SET sets frame buffer location (x,y) to pvalue new. The utility subroutine PUSH 
pushes x and y onto the stack. POP pops the top two locations from the stack into x and y. STACKNOTEMPTY 
returns true if the stack is not empty or false if it is but does not alter the stack. We will assume, 
until a later section, an infinite stack. Utility SAVEX saves the current value of x in tem- porary 
storage. It is retrieved by RESTOREX. SAVEXY and RESTOREXY serve the sane purpose for (x,y). The other 
subroutines are defined by these pro- cedures. procedure FILLINE; begin FILLRIGHT; FILLEFT; end procedure 
FILLRIGHT; begin SAVEX; while GET=old and x<$right do begin SET; x:=x+l;  end rx :=x-l; RESTOREX; 
 end 277 procedure FILLEFT; SAVEX; x:=x-l; while GET=old and x>$1eft d_.o begin SET; x:=x-l; end 
 ix:=x+l; RESTOREX; end  The shadow of a scanline segment is the set of pix- els -~-- under (or just 
above) the pixels in the segment. A scanline segment of length n pixel~ has two shadows (except, of course, 
one that lies in line Stop or $bottom), each of length n. SCANLO (or SCANHI) below stacks only one point 
from each scanline segment which is 4-connected to the scan- line segment just filled with FILLINE. This 
point is the lefbaost point in each scanline segment, or subset of a scanline segment, in the shadow. 
 procedure SCANHI; i fy+l>$top return; SAVE~; x:=ix; y:=y+l; while x<rx do beg while G~idi~nnd x<rx 
do x:=x+l; ~x>rx then break; PUSH; while GET=old and x<rx do x:=x+l; end RESTOREXY; end procedure 
SCANLO;  -~-~f y-l<$bett~ return; SAVEXY; x:=ix; y:=y-l; while x<rx do beq~_ while GE--T~d and x<rx 
do x:=x+l; "~x>rx then break; PUSH; while GET=old and x<rx do x:=x+!; end RESTOREXY; end IMPI~)VED 
FILL ALGORIT~4  The speed of the fill algorithm above can be im- proved by noticing that when neighboring 
scanline segments are being filled, one of the procedure calls to SCANHI or SCANLO may be redundant. 
For example, consider filled scanline segments b and c where c falls completely in the shadow below b, 
and c was filled after b. There is no need to scan along the scanline above c for new seedpoints. In 
general, there can be no new seedpoints in a scan- line segment already filled unless that segment in- 
cludes pixels more than distance one outside the shadow (on either end) of the segment just filled. Thus 
the improved fill algorithm below checks for the cases when it can skip one of the scans above or below. 
The criteria are sLm~marized in the two new subroutines HINEIGHBOR and LONEIGHBOR. procedure FILL(seedx,seedy,newpv); 
intecjer seedx,seedy; a~ newpv; ~nteger x,y,lx,rx,yref,lxref,rxref; ~value new,old; x:=seedx; y: =seedy; 
 new:=newpv; old: =GET; if old=new then return; yref: =y; PUSH; while STACKNOT~MPTY d__o begin POP; 
 if GET=new then continue; FILLINE; if HINEI(~BOR then SCANHI else if LONEIGHBOR then SCANLO else 
begin SCANHI; SCANLO; end; yref:=y; ixref:=Ix; rxref:=rx; end end procedure HINEIGHBOR; begin i fy=yref+l 
and ix>ixref-i and rx<rxref+l then return true else return false; end Replace yref+l in HINEIGHBOR with 
yref-i to get LONEI(~BOR. VARIATIONS ON FILL Programs realizing several variations on the simple fill 
algorithm just presented have been written and run at NYIT. ~his stmmlary does not include tint fill 
which is more than a simple variation and will be presented subsequently. The most important variation 
is the extension of the 8-bit fill pro- gram to the 24-bit version. In this case the algo- rithm is not 
changed. Only the definition of the data type pvalue changes. The 24-bit pvalue has three fields called 
red, green, and blue. Two 24-bit pvalues are equ~'~-f and only if the red fields are equal, the green 
fields are equal, and the blue fields are equal. Another variation is the so-called "boundary fill" 
algorithm. Here an area is assumed to be surround- ed by an 8-connected curve of pixels all of the same 
pvalue, called the boundary pvalue. The algo- rithm is designed to fill the area enclosed by this boundary 
regardless of what colors the enclosed pixels have (see Fig. 2). The basic test in the fill algorithm 
becanes in this case if GET/boundarypvalue then SET instead of if GET=old then SET (see FILLINE above). 
Tnis boundary fill algorithm has the restriction that the color used to fill the area must not already 
exist at any pixel in the area (unless the filling color is that of the boun- dary pvalue). Tne GET=new 
test after i~OP may fail otherwise. An easy solution is to boundary fill with a reserved color then refill 
with simple fill and the desired color. Another variation is called "texture fill". In- stead of filling 
an area of constant color with a single new color, it is filled with a pattern ei- ther algorithmically 
generated or contained in another frane buffer. In this case the restriction is that no color in the 
pattern can be the original  278 color of the area being filled. The texture fill program fell into 
disuse at NYIT after 1975. Regular fill with a matte color and then a one-pass copy of one frame buffer 
contents to another based on the matte so generated is com- putationally cheap and fast and does not 
suffer from the restriction of texture fill. The extra frame buffer is not needed if the texture is algo- 
rithmically generated. Another approach is presented in [3] which uses more computation in- stead of 
more memory to avoid the problems of tex- ture fill. Another variation, which has not been implemented 
 at NYIT, is the fill of 8-connected areas instead of 4-connected areas. All that is required to adapt 
BASICFILL to the 8-connected case is a more elaborate neighborhood check in the routines SCANHI and 
SCANLO. TINT FILL  Line drawings digitized into a frame buffer from pen or pencil drawings via a scanning 
video camera have the appearance of white areas enclosed by "shaded" curves. That is, the curves are 
not sharp black lines but are composed of many shades of gray. They tend to be black or almost black 
near the centerline of the curve and shade to white near its edges. When one of these areas is to be 
filled, it is desirable to have the fill algorithm understand the shaded edges and maintain the shad- 
ing with shades of the new color instead of the old. The tint fill algorithm was created to accom- plish 
this task. Another increasingly common practice in computer graphics also creates areas with shaded 
edges. This is the process of antialiasin 9 edges. A two- color digital approximatfon to a straight line 
in a frame buffer has the appearance of stairsteps. This is called the "jaggies" or "aliasing". A hu- 
man can be fooled into seeing a amooth rendering of a line by techniques called antialiasing. One of 
these techniques consists of laying down a ramp of gray shades (assume a black-and-white line with jaggies 
for this explanation) along each stairstep. All of the antialiasing techniques introduce shades into 
the edges. Here too the tint fill algorithm is useful. The basic notion of the tint fill algorithm below 
is this. Suppose white is high and black is low. Then a scanned-in image or an antirastered line drawing 
may be thought of as a physical terrain where the white areas have high elevation and the black lines 
are valleys of low elevation. The shadings of the lines are represented in this ter- rain by the slopes 
of the valley walls. To fill a pixel with tint fill means to change the hue and saturation, i.e., the 
tint, of the pixel color on- ly, not its value, or blackness [8]. Tint fill fills along a scanline under 
the rule that it can never go uphill. It can fill along level ground or downhill only. A scanline segment 
for tint fill consists of all the pixels proceeding from the seedpoint right (and left), which have the 
same tint as the seedpoint and a value which is either the same or less than the pixel just left (right). 
Thus a scanline segment is a section of a hill or mesa. The shadows of a scanline segment are as before: 
all the pixels just below (a~x~ve) the pix- els in the scanline segment. Three scanline seg- ments are 
tint filled in Fig. 4. A formal statement of the problem in the style used for simple fill is: Given 
a 4-connected set A of points on the 2-dimensional integer grid, all of the same tint t, and a distinguished 
point P in A of value v, such that the value of any other point P' in A is a monotonically decreasing 
function of distance from P along at least one 4-connected path of points in A from P to P', and given 
a tint t'~t, find an algorithm for changing all and only the points of A from tint t to t'. The TINTFILL 
procedure below resembles the FILL procedure above in organization, with TFILLINE, TSCANLO, and TSCANHI 
corresponding respectively to FILLINE, SCANLO, and SCANHI. We continue to use the terrain analogy to 
indicate how the shadows of a scanline segment are scanned for tint fill. Two points P and P' on the 
same scanline will be said to be monotonically connected if the values for all the pixels from P to P', 
inclusively, monotonically increase with x or monotonically decrease with x. Briefly, we stack the hilltops 
which are in the shadow, or at least the highest point on a hill which falls in the shadow. These points 
are later popped from the stack and used as new seed~ints. Specifically, a point in a shadow is pushed 
if: I) Its tint is that of the original seedpoint before filling, and 2) its value is less than or 
equal the value of the pixel above (below for TSCANHI), and  3) there is no monotonically connected 
pixel to the right of higher value which also satisfies i) and 2) and is in the shadow, and 4) there 
is no monotonically connected pixel to the left of higher value which has al- ready been stacked. Fig. 
1 illustrates which pixels would be stacked under these rules. They are indicated by upper case letters. 
 The algorithm below assumes the user supplies the coordinates of the initial seedpoint and the desired 
new tint. We will employ two new data types, tint and value, to hold color tint and color value. For 
the purposes of this presentation, we need not be more specific about them. In the current implementation 
of tint fill at NYIT for 8-bit frame buffers, both of these data types con- tain four bits. Special colormaps 
are asstm~ed which map the low four bits of a pvalue into the value and the high four bits into the tint 
of the color of the pvalue. For RGB frame buffers, tint and value are algorithmically computed [8] from 
the RGB primary components. procedure TINTFILL (seedx,seedy,newtint) ; seedy; int; begin int~x ,y,lx 
,rx,yref,lxref,rxref; tlnt newt,oldt;  279 "value oldv; x:=seedx; y:=seedy; newt:=newtint; oldt:=GEXT; 
oldv:=GETV; if oldt=newt then return; yref:=y; PUSH; while STACKNOT~4PTY~__~gin POP; if GETT=newt then 
continue; TFILLINE; if HINEIGBBOR then TSCANHI else if LONEIGHBORthen TSCANLO else be~ TSCANHI; TSCANLO; 
end; yref:=y; ixref:=ix; rxref:=rx; end end  These procedures ass~e utility subroutines GETT, GETV, 
and SETr as well as the stack maintenance utilities used above. GETT and GETV return the tint and value 
of the pvalue at current location (x,y). SETrchanges the pvalue at current location (x,y) to one with 
a tint of newt. procedure TFILLINE; value lastv; lastv :=oldv; TFILLRIGHT; lastv: =GETV; TF ILLEFT; 
end ~_[ocedure TFILLRIGHT; begin SAVEX; while GET~-oldt and GETV<lastv and x<$right do begin ~ - SETf; 
lastv:=GETV; x:=x+l; end rx:=x-l; RESTOREX; end procedure TFILLEFT; beg,in SAVEX; x:=x-l; while GETT=oldt 
and GETV<lastv and x>$1eft begin SE~T; lastv:=GETV; x:=x-l; end ix : =x+l; RESTOREX; end procedure 
TSCANHI; ~n if y+l>$top return; SAVEXY; x:=ix; y:=y+l; while x<rx do while G~ET~idt and x<rx do x:=x+l; 
if x>rx break; TPUSHHI; x:=x+l; end RESTOREXY; end procedure TSCANLO; ~in fy-l<$bottom return; SAVEXY; 
 x:=Ix; y:=y-l; while x<rx do beq~q while GETT/oldt and x<rx do x:=x+l; if x>rx break; TPUSHLO; 
x:=x+l; end RESTOREXY; end The following two routines are the most complex of this presentation. 
They are designed to stack all points in the shadow of the current scanline seg- ment which meet the 
four criteria listed above. It should be noted that correct tint filling would oc- cur if only criteria 
i) and 2) were satisfied. The set of points satisfying only these two criteria is the largest set of 
points which could be stacked for correct operation of the algorithm. The set of points satisfying all 
four criteria is the smallest set of points which must be stacked for correct filling. For ease of presentation, 
the routines specified below stack a set of points falling between these two extremes. Fig. 1 shows the 
set of points actually stacked. The upper case letters indicate points in the smallest set, which must 
necessarily be stacked, and the lower case letters denote the additional points stacked by these routines. 
 In the following routines, v is the color value of the current pixel, and vup (vdn) is the value of 
the pixel just above (below). Four flags are used: Vover is true only when a shadow pixel has a value 
larger than that of the corresponding pixel in the scanline above (below). Oldvover is the state of vover 
at the location considered just pre- viously to the current location. Uphill is true only when, proceeding 
left to right along the sha- dow, the color values increase monotonically. Stackready true implies points 
are to be pushed onto the stack. False implies replacement of the top of the stack. In words, the highest 
points on hillsides which satisfy i) and 2) are stacked. Three more utility routines are assumed. These 
are GETVDN and GETVUP which return the value of the pixel i~ediately below, respectively above, the current 
pixel. Routine RETOP replaces the top ele- ment on the stack with the current location. prpcedure TPUSHHI 
  "~-~nt~er vover,oldv~er,uphill,stackready; value v,vdn; comment initialize flags; v:=GETV; vdn:=GETVDN; 
 vover:=if v>vdn then true else false; if x=rx and not vover then begin PUSH; return; end stackready:=true; 
 uphill:=false; comment stack the firs valid point; if not vover then begin stackready:=false; PUSH; 
 end eise whil ~ x<_rx do begin 280  x:=x+l; mented in 1977 and 1978, respectively, at NYIT. if x>rx 
o_~GETP/oldt then return; Most recently, Marc Lavoy has implemented a 10-bit GETDNFLAC~; version of 
tint fill at Cornell under the name if not rover then be@in PUSH; stackready:=false; break; end end 
 conment main loop; ~le x<rx do begin X:=X+I; if x>rx o rGETI~oldt then return; GETDNFLAGS; if uphill 
and not vover then be@in if not stackready then RETOP; else begs PUSH; stackready:=false; end end else 
if not uphill hen beqin --i[not vover and oldvover then PUSH; stackready:=t~; end end end  GETDNFLAGS 
is the following flag maintenance routine: procedure GETDNFLAGS begi~ vlast:=v; v:=GETV; vdn:=GETVDN; 
oldover:=vover; vover:=if v>vdn then true else false; if v~vl~t then begin uphill:=ifv>vlast then true 
else false; end end  Procedure TPUSHLO is the same as TPUSHHI above if vdn is replaced everywhere with 
vup, GETVDN is re- placed everywhere with GETVUP, and GETDNFLAGS is replaced everywhere with ~TUPFLAGS. 
GETUPFLAC~ is GETDNFLAGS under the same set of replacements used to obtain TPUSHHI. HISTORICAL NOTE 
 The earliest version of the fill algorithm as stat- ed here of which I am aware is that of Ken Knowlton 
[i] in 1964. A less sophisticated algorithm was the foundation of a fill program implemented on the "tricolor 
cartograph" in 1969 [2] and of a similar program implemented by Joan Miller on a 3-bit frame buffer at 
Bell Labs in 1969-70 ~4]. These two pro- grams could fill only convex simply-connected areas. The first 
complete frane buffer program was apparently that implemented by Patrick Baudelaire and Dick Shoup at 
Xerox Palo Alto Research Center in 1973. Programs realizing the fill, tint fill, and boundary fill algorithms 
have been in service at NYIT since 1975. A similar program, called "flood" however [3,6], was implemented 
at the Mas- sachusetts Institute of Technology shortly thereafter. More recently, Marc Lavoy progranmned 
an 8-bit fill at Cornell University. A 24-bit, or RGB, version of fill and the tint fill program at 
NYIT were certainly the first of these varieties with only tint fill being a truly novel program. The 
RGB versions of fill and tint fill were imple- "gradient flooding". IMPLEM~NTATIONNOTES The actual 
implementation of any of the algorithms of this paper has to deal with several practical matters glossed 
over by the presentation thus far. The stack, for example, is unfortunately finite. It is possible to 
make pictures the filling of which, even with the careful stack usage described, requires a stack to 
grow so large as to exceed memory size. Since great speed is highly desirable in a fill program, elaborate 
stack checks are un- desirable. Fortunately, it has been our experience at NYIT that pictures which require 
such inmnense stacks are pathological cases, created for the sole purpose of exceeding the limits and 
of little in- terest artistically. Since speed is so important, all fill programs at NYIT have been 
implemented as in-line assembly code, subroutine calls being too costly. The much used 8-bit simple fill 
was implemented to fill two pixels (a word) at a time instead of just one (a byte) to exploit the speed 
advantage of the Digital Equipment Corporation PDPii family of processors and the Evans and Sutherland 
frame buffers in word mode. Although the connectivity checks are quite a bit more elaborate in word mode, 
the resulting speedup was worth the ceding trouble. Tne tint fill program was speeded up substantially 
by check- ing for the case where it must fill large full- value areas and doing the highly optimized 
simple fill in that event. CONCLUDING REMARKS Tint fill is called by that naae because of its original 
use at NYIT. However, tint and value are only one possible interpretation of the two quanti- ties checked 
by the algorithm. Hue and brightness or hue and saturation are two other color-related interpretations. 
But any two quantities, such that one is changed if the other "only goes downhill" from the initial seedpoint, 
form another interpre- tation. For exanple, the contents of one fraae buffer A is matted into another 
frame buffer B just for those points in a third frame buffer C with ab- solute ntmleric contents (weights) 
which only go downhill (decrease aritF~etically) from an initial seedpoint in C. The matting is done 
as a weighted combination of the corresponding pixels in frame buffers A and B, the weight being the 
pvalue in C at the same (x,y) location. A less colorful name for the algoritha, derived from its terrain 
model explanation, would be "hill fill". As another example, consider an area of colorl in an RGB frame 
buffer surrounded by an antirastered boundary of color2. We desire to fill the area with color3 while 
maintaining the antialiasing at the edges. Tne hill fill algorithm can be used under this interpretation: 
"Colorlness" is changed to "color3ness" if "not-color2ness" only goes downhill from the initial seedpoint. 
In fact, an RGB tint fill results if color2 is taken to be black.  281  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807457</article_id>
		<sort_key>284</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[SoftCel - an application of raster scan graphics to conventional cel animation]]></title>
		<page_from>284</page_from>
		<page_to>288</page_to>
		<doi_number>10.1145/800249.807457</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807457</url>
		<abstract>
			<par><![CDATA[<p>The system described uses frame buffers to provide digital analogues to the traditional processes of copying pencil drawings onto cels, painting them, and photographing them. The copying process is replaced by scanning the pencil drawings with a television camera and digitizing the video signal. Several image processing operations are performed on the digitized drawings to condition them for the next step, interactive painting of the drawings mediated by a computer program. The painted drawings are then combined with each other and painted backgrounds for frame by frame recording on film or video tape.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Cel animation]]></kw>
			<kw><![CDATA[Image scanning]]></kw>
			<kw><![CDATA[Paint]]></kw>
			<kw><![CDATA[Raster scan graphics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39079695</person_id>
				<author_profile_id><![CDATA[81332530000]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Garland]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stern]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Lab, New York Institute of Technology, Old Westbury, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin, Personal communication, Spring 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Diment, A. R., "Computer Animation", Systems, December/January 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kitching, Alan, "Computer Animation - Some New ANTICS", British Kinematography Sound and Television, December 1973.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908714</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Stern, Garland, GAS - A System for Computer-Aided Keyframe Animation, PhD Dissertation, University of Utah, Spring 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Wein, M., and L. Bertnyk, "Computer Generated Key-Frame Animation", Journal SMPTE, March 1971.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray, "Fill and Tint Fill", NYIT Graphics Lab Technical Memo No. 6, July 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray, "Paint", NYIT Graphics Lab Technical Memo No. 7, July 1978.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578095</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, Azriel, and Avinash C. Kak, Digital Picture Processing, Academic Press, New York, 1976.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SoftCel - An Application of Raster Scan Graphics to Conventional Cel Animation Garland Stern Computer 
Graphics Lab New York Institute of Technology Old Westbury, NY 11568 Abstract The system described 
uses frame buffers to provide digital analogues to the traditional processes of copying pencil drawings 
onto cels, painting them, and photographing them. The copying process is re- placed by scanning the pencil 
drawings with a television camera and digitizing the video signal. Several image processing operations 
are performed on the digitized drawings to condition them for the next step, interactive painting of 
the drawings mediated by a computer program. The painted draw- ings are then combined with each other 
and painted backgrounds for frame by frame recording on film or video tape. Keywords: cel animation, 
paint, raster scan graph- ics, image scanning CR categories: 8.2, 3.41 Introduction Of the many steps 
in the process of conven- tional animation, the animation proper is performed by two levels of artists 
- animators, who prepare rough sketches showing the extremes of motion of a character or object; and 
assistants, who clean up the rough sketches and provide inbetween sketches to fill in the motion. The 
results of the assis- tants' work is a collection of pencil and paper drawings. Before these drawings 
can be combined with others and photographed, they must be copied onto clear acetate cels and painted. 
Unpainted areas of acetate allow the background or characters from other levels of cels to show through 
giving a fully colored image when the cel/background sandwich is photographed. SoftCel, the system described 
in this paper, does not attempt to provide assistance to the crea- tion of animation proper, but rather 
a replacement for the phase of conventional animation known as 'ink and paint' wherein animation is 
copied onto cels and painted. It also provides means to com- bine painted drawings and backgrounds for 
recording on either film or video tape. A common approach to providing computer assis- tance to animators 
had been interpolation based in- betweening systems (Refs. i, 2, 3, 5). These sys- tems are useful when 
large n~bers of inbetweens are to be generated, but if only one or two, or worse, no inbetweens are to 
be produced they become impractical due to the length of time necessary to diaitize the lines comprising 
key frame drawings. SoftCel derives partly from the authors prior at- tempt to automate the digitization 
process by ex- tracting contours from digitized video images (Ref. 4). It also derives partly from a 
form of filling algorithm, described below, which was used in an early version of Catmull's Tween system 
(Ref. i) to provide coloration of machine generated inbetweens. Scanning Drawings The conventional 
step of copying an animator's drawing onto a cel is replaced in SoftCel by scan- ning it with a television 
camera and digitizing the resulting video signal. Other methods of image di- gitization could provide 
more resolution and/or precision but at the cost of either longer digiti- zation time or fixed drawing 
size. Ideally, image input to the system should be as fast as the con- ventional step of copying pencil 
drawings onto ace- tate cels via xerography. Frame buffers are used throughout SoftCel for temporary 
storage and viewing of images. The form of frame buffer used at NYIT is an array of 8-bit pixels 512 
wide by 480 high which produces red, green, and blue video signals for a color televi- sion monitor. 
The values of the three color com- ponents are determined from the 8-bit pixel values by lookup in three 
256-element tables, known col- lectively as the color map. When a pencil drawing is initially digitized 
it may contain the full range of pixel values and the color map used is a linear ramp from zero to maximtmn 
value in all three components, thus produc- ing a black and white image. In order to provide for interactive 
painting of a drawing it is neces- sary to reduce the nt~ber of pixel values used for representation 
of lines. In the extreme, a single pixel value could be used to indicate presence of a line leaving the 
other 255 values available to represent distinct colors. Practically, however, this would result in a 
line that was ragged or 'jaggy'. To prevent jagginess it is necessary to represent lines by several shades 
of gray or color. It simplifies implementation if the n~ber of gray shades retained is a power of two 
in which case the 8-bit pixel may be partitioned into some n~ber of bits, say n, representing 2n-i colors 
available for painting and.^l .transparent 'non-color' each of which has 2 to-n) different shades of 
gray. A tra- &#38;#169;1979 ACM O-89791-004--4179/0800--284 $00.75 See Copyright Pg. 284 fl~off is involved 
here - using more bits for gray shades reduces the n~nber of colors available for painting, and using 
less bits for gray shades in- creases the ragged appearance of lines. The compromise taken in SoftCel 
is to use 4 bits for each -the 4 least significant bits of each pixel represent gray shade and the 4 
nDst significant color. Ordinarily, the 16 color map values for each paint color are constructed by componentwise 
interpolation from the red, green, and blue values for the desired color to zero. If colored lines are 
desired, the interpolation may go to the com- ponent values for the desired color of the line rather 
than zero. Color maps constructed in this fashion are called tint fill type color maps. All lines in 
any given drawing must be of the same color, but as noted already, several drawings with different colored 
lines may be combined into a sin- gle frame at record time. Enhancing Image Quality Drawings scanned 
with a vidicon can be pro- cessed to improve the quality of the lines and to make them more suitable 
for painting. Fig. la shows a digitized pencil drawing with a gray scale color map. The strip at the 
top of Fig. la is a linear ramp of pixel values from 0 at left to 255 at right. Fig. ib shows the same 
image displayed with a tint fill type color map. The ramp at the top of the picture clearly shows the 
16 separate ranges of pixel values corresponding to 15 colors and a transparent range. It can be seen 
that the background area of the image exihibits shading from purple to black to orange producing irregular 
con- tours. The shading and contours indicate that the background white of the paper is represented by 
a wide range of pixel values. This undesirable ef- fect can be produced by uneven lighting of the drawing 
or by nonuniformity of response over the surface of the camera's vidicon tube. Video cam- eras provide 
adjustments to reduce the amount of this error, called shading error, but it is not necessary to eliminate 
it in the video signal. Shading error can be compensated for by scanning a blank sheet of paper of the 
same kind used for the drawings and at each pixel calculating a correction factor equal to 255 divided 
by the digitized value. Each drawing scanned subsequently then has each pixel value multiplied by the 
corresponding correc- tion factor in the blank reference scan. Figs. 2a and 2b show the image of Fig. 
1 after this shading correction is applied. The effect of the correc- tion is more noticable in Fig. 
2b which uses the tint fill type color map. Inherent in the use of video as image input is a certain 
amount of blurring of the image. To com- pensate for this effect the next operation per- formed on each 
drawing is an edge enhancement operation, in particular, subtraction of the image's Laplacian from itself 
(Ref. 8). The effect of this operation is shown in Figs. 3a (before) and 3b (after). 2The ~p~acia~ is 
a derivative operator defined as d f/dx +d f/dy . In discrete form, if the neighborhood of a pixel, a, 
appears as bcd eaf ghi then the value of the Laplacian at a is c+e+f+h-4a. The value of the enhancement 
operation performed in Fig. 3b at pixel a is 5a-c-e-f-h. It can be seen that in addition to enhancing 
lines, the Laplacian operation also enhances salt and pepper background noise. Before the drawing is 
ready to be painted, this noise must be removed and the range of pixel values must be reduced from the 
initial 256 to 16. It is also possible and desir- able at this point to increase contrast of the lines 
and to make sure that the regions to be filled are as flat as possible. Our intent is to find two pixel 
values, pl and p2, pl < p2, to de- fine a function, f(p), which will map the pixel values 0-255 onto 
the 0-15, transparent, range as (0, if p.< pl f(p) =~ 15(p-pl)/(p2-pl), if pl < p ~< p2 ( 15, p > 
p2. Fig. 4 shows histograms of the image of Fig. 1 taken at each stage of processing. Fig. 4a is the 
histogram of the original scanned image. The clear, single peak corresponds to the pixel values of blank 
white paper. Fig. 4b is the histogram of the image after the shading correction is per- formed. The peak 
has shifted to the right and has become narrower reflecting the fact that the pixel values of the blank 
white paper have become more uniform over the image. In Fig. 4c, the histogram after the Laplacian operation, 
the peak is seen to widen, reflecting the enhancement of the background noise. If the areas to be filled 
are to be flat then p2 must fall to the left of the peak. The al- most monotonic nature of the histogram 
from 0 to the maximt~nof the white peak indicates that a con- dition on the slope of the histogram might 
provide a criterion for choice of p2. Experimentation has shown that a reasonable way to choose p2 is 
to start at the top of the White peak and search left until the slope of the histogram is less than 8 
for 16 consecutive pixel values. Since the value of the histogram at p2 gives an indication of how dense 
the paper is with lines it seems reasonable to relate pl to it. Accordingly, pl is taken to be the pixel 
value at Which the ntmnber of pixels with value less than or equal to pl is equal to the value of the 
histogram at p2. Painting the Drawings The interactive coloring of a drawing is medi- ated by a specialized 
painting program which Offers the user 3 basic tools - tint fill, tint paint, and eraser or value paint. 
Tint fill is a filling al- gorithm developed by Alvy Ray Smith at NYIT (Ref. 6). The operation of the 
algorithm may be described briefly as follows. Given one of the 16 colors for filling and a 'seed' or 
starting pixel I) change the color bits of the pixel to the fill color, 2) for each neighboring pixel 
left, right, above, or below, if the color of the neighbor is the same as the original color of the seed 
and the value of the gray shade bits is less than or equal to the value for the seed, then recursively 
apply the algorithm with the neighbor as the new seed. In effect the tint fill algorithm fills 'downhill' 
to the darkest pixel in the center of a line but will not proceed 'uphill' to the region beyond the iine. 
 285 Occasionally, gaps are present in lines which would cause the tint fill algorithm to appear to 
leak into a neighboring region. Tint paint is pro- vided for the user to apply a different color on one 
side of the gap thus creating a boundary that tint fill will not cross. Tint paint is implement- ed as 
a digital paintbrush that changes only the color bits of a pixel. Eraser or value paint is provided for 
the erasure of stray marks, animators notes, or noise that may have escaped the process- ing performed. 
It is complementary to tint paint in that it changes only the gray shade bits of a pixel. The limitation 
of 15 colors is unacceptable for assembly of frames ready for recording. For this reason finished frames 
are assembled into a set of three frame buffers, each frame buffer sup- plying only one color component. 
As a result, the final assembled image can contain an arbitrary n~ber of colors, while each individual 
cel is lim- ited to 15. When the painted drawing is restored into three frame buffers, the transparent 
range of pixel values is treated specially to avoid a jagged edge effect. Pixel values of 15 in the painted 
im- age correspond to completely transparent areas and thus do not result in any modification of the 
result image. Pixel values less than 15 correspond to parts of lines at various densities and the corresponding 
pixels of the result image are changed by interpolation of the existing value to- wards black, the interpolation 
paraneter depending on the density. Pixel values greater than 15 sim- ply replace the corresponding pixel 
in the result image. In conventional animation, there is a prac- tical limit to the ntmlber of cel levels 
used due to the fact that an unpainted cel is not completely transparent. With digital cel assembly, 
this limi- tation does not exist. Fig. 5 shows the image of the previous figures in final, painted form, 
and Fig. 6 shows this image combined with a background. Summary SoftCel has been in use for well over 
a year in several productions. Its design was intended to have no unnecessary impact on the production 
of an- imation up to the point at which it is scanned into the system. This is largely the case, however 
as- sistants and inbetweeners are encouraged to use a uniform line, and not to leave breaks in lines, 
be- cause of potential leaks using tint fill. The ma- jor problem with the system is the 15 color per 
cel limitation. This problem has led animators to work with more levels and to restrict the number of 
colors used in the design of characters. Several approaches are available for solution of this prob- 
lem, the most readily available being reduction of the n~ber of bits per pixel allocated for gray scale. 
It may be that 8 gray shades are adequate for line representation, although this may also necessitate 
other enhancement operations. Acknowledgements I wish to express my appreciation to my col- leagues 
at NYIT for their help and encouragement in this research and preparation of this paper, in particular 
Alvy Ray Smith and Ed Catmull. For the illustrations used in this paper I would like to thank Earl James 
and Lance Williams. I also wish to express thanks to Dr. Alexander Schure for sup- porting this research 
in particular, and computer animation in general. References [i] Catmull, Edwin, Personal commLmication, 
Spring 1977. [2] Diment, A. R., "Computer Animation", System s, December/January 1976. [3] Kitching, 
Alan, "Computer Animation - Some New ANTICS", British Kinematography Sound and Television, December 1973. 
 [4] Stern, Garland, GAS - A System for Computer- Aided Keyframe Animation, PhD Dissertation, Univer- 
sity of Utah, Spring 1978. [5] Wein, M., and L. Bertnyk, "Computer Generated Key-Frame Animation", Journal 
SMPTE, March 1971. [6] Smith, Alvy Ray, "Fill and Tint Fill", NYIT Graphics Lab Technical Memo No. 6, 
July 1978. [7] Smith, Alvy Ray, "Paint", NYIT Graphics Lab Technical Memo No. 7, July 1978. [8] Rosenfeld, 
Azriel, and Avinash C. Kak, Digital Picture Processing, Academic Press, New York, 1976. 286  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807458</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Towards an interactive high visual complexity animation system]]></title>
		<page_from>289</page_from>
		<page_to>299</page_to>
		<doi_number>10.1145/800249.807458</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807458</url>
		<abstract>
			<par><![CDATA[<p>A computer animation system is discussed which employs interactive techniques and presents a unified approach to the graphical display of complex three dimensional data. The system facilitates the generation, manipulation and display of highly detailed data with the aid of interactive devices and a video interface to a standard color TV monitor. The system enables the animator to create a variety of objects (including texture) and to specify the necessary transformations for animation sequences. A run length processing technique combined with a brute force Z-buffer algorithm has been newly designed and implemented that can handle the intersection of several million faces, lines and points. This makes possible a full range of visual cues to simulate fire, smoke, water and complex 3-D texture such as grass, hair and bark. Basic concepts and approaches are described. The display algorithm and the procedure model to generate texture are presented and the implications of the system for computer animation are discussed. Extensions to the system are outlined which include a unique graphics display processor currently under construction that includes a partial implementation of the display algorithm in hardware.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14139807</person_id>
				<author_profile_id><![CDATA[81100394889]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Csuri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Group, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333028</person_id>
				<author_profile_id><![CDATA[81332502731]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hackathorn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Group, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39076964</person_id>
				<author_profile_id><![CDATA[81100414668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parent]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Group, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31071692</person_id>
				<author_profile_id><![CDATA[81100379189]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carlson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Group, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P332186</person_id>
				<author_profile_id><![CDATA[81543037056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Howard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Group, The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., Simulation of Wrinkled Surfaces, SIGGRAPH, 1978.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brooks, J., et al., An Extension of the Combinatorial Geometry Technique. NTIS Report AD-782-883, August, 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. A., A Subdivision Algorithm for Computer Display of Curved Surfaces, Univ. of Utah, UTEC-CSC-74-133, Dec., 1974.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360354</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Clark, J. H., Hierarchical Geometric Models for Visible Surface Algorithm, CACM, October, 1976.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C., The Aliasing Problem in Computer Synthesized Shaded Images, UTEC-CSC-76-015, Dept. of Computer Science, Univ. of Utah, 1976.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hackathorn, R., The ANIMA II System, SIGGRAPH '77.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>804727</ref_obj_id>
				<ref_obj_pid>800143</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Jones, B., An Extended ALGOL-6, for Shaded Computer Graphics, Proc. ACM Symp., 1976.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Myers, A. J., "An Efficient Visible Surface Program," Grant No. DCR 74-007 68AO1, Tech. Rep., National Science Foundation, 1975.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E., The Utilization of Procedure Models in Digital Image Synthesis, Computer Science, Univ. of Utah, UTEC-CSC-76-218, 1975.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>642094</ref_obj_id>
				<ref_obj_pid>642089</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Staudhammer, J., and Eastman, J. R., Computer Display on Colored Three-Dimensional Object Images. Proc. Annu. Symp. Comput. Arch., 1975.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E., Sproull, R. F., and Schumacker, R. A., A Characterization of Ten Hidden-Surface Algorithms, Comput. Surv., 1974.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wein, M., and Burtnyk, N., A Computer Animation System for the Animator, UAIDE, 1971.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Towards an Interactive High Visual Complexity Animation System by C. Csuri, R. Hackathorn, R. Parent, 
W. Carlson and M. Howard Computer Graphics Research Group The Ohio State University ABSTRACT A computer 
animation system is discussed which employs interactive techniques and presents a unified approach to 
the graphical display of complex three dimensional data. The system facilitates the genera- tion, manipulation 
and display of highly detailed data with the aid of interactive devices and a video interface to a standard 
color TV monitor. The system enables the animator to create a variety of objects (including texture) 
and to specify the necessary transformations for animation sequences. A run length processing technique 
combined with a brute force Z-buffer algorithm has been newly designed and implemen- ted that can handle 
the intersection of several million faces, lines and points. This makes possible a full range of visual 
cues to simulate fire, smoke, water and complex 3-D texture such as grass, hair and bark. Basic concepts 
and approaches are described. The display algorithm and the procedure model to generate texture are presented 
and the implications of the system for computer animation are discussed. Extensions to the system are 
outlined which include a unique graphics display processor currently under construction that includes 
a partial implementation of the display algorithm in hardware. INTERACTIVE SYSTEMS AND HIGH VISUAL COMPLEXITY 
an IBM 360/65 computer to display this image at 500 x 500 resolution, Crow (5), with a visible Computer 
animation has advanced to the surface algorithm and a technique of object in- stage where systems have 
been implemented which stancing that he developed for Information can routinely handle the 3-D display 
of objects International Inc., displayed pictures consisting or scenes involving several thouSand faces 
( 6, of several hundred thousand polygons. His pic- 7, i0)o We now need to develop interactive ture of 
multiple copies of the ABC logo took systems that can facilitate the generation and over 30 minutes 
of calculation time on a PDP-10 display of more complex data. This is espe- witha KA-10 processor. The 
emphasis in his cially true for representing detail such as system is on image quality and he uses a 
3000 textures of hair, feathers, grass or the dis- line display for producing pictures which repre- 
sent the state of the art in computer graphics. play of smoke, fire and liquids. Early work in this 
area demonstrated that computers can Catmull (3) produced complex pictures of bottles generate and display 
pictures requiring and glasses (142 bottles and glasses where each bottle required 32 hi-cubic patches). 
Newell patches. These pictures weredeveloped for several hundred thousand polygons or surface (9) also 
displayed high complexity pictures; the most notable of which is entitled "Pawns" in the most part in 
the context of a batch pro- cessing environment. MAGI's unique algorithm which he used instancing to 
generate the data and produced a color picture in 1974 (2) of a decid- a display processor that incorporated 
a hardware uous tree that had several thousand leaves. implementation of the Watkins algorithm. Using 
Using a procedure model to generate or "grow" the a PDP-10 computer and this graphics processor tree; 
it took three hours of calculation time on the picture took approximately twenty minutes of calculation 
time. *This work is supported in part by National Science Foundation Grant Number MCS76-18659. All of 
these efforts were important steps towards high visual complexity animation systems. Even though we now 
have improved technology which helps in some aspects of the display problem, there is more work to be 
done with interactive techniques and color raster scan displays, data generation (especially for images 
such as texture and smoke), the specification of complex creature motion, display algorithms and image 
quality. We must find methods that w111 enable us to easily generate, manipulate and display the intersection 
of several million faces, lines and points in three dimensional space. Although there are interactive 
two and two and one half dimensional systems that employ a TV color display ~2), there are not many exam- 
ples of interactive 3-D systems. Jones (7) implemented an interactive black and white system with extensions 
to ALGOL-60 in Case Western Reserve's high performance graphics display pro- cessor built by the Evans 
and Sutherland Corpora- tion. It is an animation system that handles several thousand edges in real time. 
An inter- active 3-D graphics system involving TV displ@y was developed by Staudhammer C0) at North Carolina 
State University which refreshes a 3-D image from an analog disk. Other systems have been built for the 
military, such as flight simulators developed by E and S and G. E. Corporation. These are special purpose 
systems built at great cost and designed exclusively for flight training that have many of the interactive 
features required for an animation system. While they perform well for their intended pur- pose, there 
is a limitation as to the amount of data that can be displayed in real time; this is usually around 3000-3600 
edges. Although better hardware implementations are possible, the display algorithms do not seem well 
suited for high complexity data. There has been some interesting exploratory work by Clark ~) that may 
overcome some limitations. His techniques involve a hierarchical organization of large data bases that 
has significant implications for highly complex data and the visible surface calculation. In his scheme 
the requirements for the display of detail at any instance in time is, in part, determined by one's viewing 
position in 3-D space or one's position within a tree structure. Unnecessary edges are not processed 
by the algorithm, thus reducing the calculation time. ANIMA II ( 6 ), which was one of the first attempts 
at an interactive 3-D color raster scan animation system was designed and imple- mented by the CGRG at 
the Ohio State University. It enables the user to generate, manipulate and display 3-D images and it 
has a real-time playback capability for animation. The ani- mation sequences can be recorded onto video- 
tape. This system has been used to produce over two hours of storyboard animation for science, education 
and commerical TV. The strengths of the system include its interactive capabilities with the data generation 
subsystem and the relatively easy to use director's lang- uage. Another attractive feature is a fast 
visible surface algorithm for the rapid display of animation which provides users with the spon- taneity 
necessary to make visual judgments. The run-length encoding scheme used as final output to a video interface 
designed for us by Staud- hammer makes this particular combination of soft- ware and hardware work for 
the real-time playback of animation. There are limitations to the ANIMA II system that are primarily 
related to image quality. The data transfer rate from disk of the playback scheme limits the number of 
run- lengths available per frame which affects the image quality attainable. While complex creature motion 
has been created with the system, the specification of transformations, especially the positioning of 
sub-parts, tends to be time con- suming. There is no smooth shading, transparency, highlights or shadows 
and aliasing is a problem. It should be noted that an earlier version of the Myers' ( 8 ) Z-buffer algorithm 
implemented in 1974 at CGRG handled smooth shading and trans- parency, but that these features were eliminated 
because greater value was placed upon user inter- action and a real-time playback capability. The primary 
focus of this paper will be upon our new animation system which seems to grow naturally out of our previous 
work with ANIMA II. A later unpublished version of the Myers' algo- rithm (an efficient implementation 
of a brute- force Z-buffer algorithm) was designed to process data directly off a mass storage device. 
While Myers' work has produced good preliminary results, we have found it to have certain limitations. 
The type of internal data structures used and the requirements of separate copies of data limits the 
speed of calculation and the variety of visual results that can be displayed. Recently, Hackathorn of 
CGRG has extended this previous work by introducing features and techniques that represent a modest improvement 
for the display of high complexity data. The display algorithm incorporates a unified approach to the 
display problem where one can combine not only polygonal surfaces but also points, lines and hi-cubic 
patches. A new animation system called ANTTS has been implemented on our PDP-ii/45. It is an experi- 
mental system with a language that involves interactive techniques and a unified approach to the display 
of high complexity data including textured objects and smoke. This system is being redesigned for implementation 
on our VAX/780 com- puter with a unique graphics display processor under construction by the CGRG. The 
final system will exploit the display algorithm with a partial implementation in hardware and it should 
signifi- cantly improve response time for interactive capabilities. DESIGN CONSIDERATIONS An interactive 
high visual complexity ani- mation system should have several basic features: i. Ideally it should be 
a real-time system, but with available technology and associated cost an interactive capability seems 
like a reasonable goal. 2. A language is required to specify the transformations to control the object's 
 290 position and movement through space. There is a need for a facility where the moving human figure 
can be digitized and a motion file created. 3. Techniques such as procedure models are necessary to 
generate and store complex data. Data generation could be an algo- rithm to "grow" a tree, instancing 
or solids of revolution, including the triangulation between slices. One should be able to specify different 
resolutions for the ob- Ject, for example, displaying an object having up to one million faces as a simpli- 
fied object having only ten faces. This is important if one hopes to achieve an inter- active design 
capability.  4. The system should have facilities for the digital editing of animation sequences from 
a mass storage device. It should allow for the random access of sequences and the dynamic changing of 
color in real-time play- back mode without recalculating the sequences.  5. The display algorithm should 
be able to handle the intersection of lines, points and surfaces in three dimensional space. Data should 
be processed in a stream (as opposedto pre-sorting), either by reading in data directly from a disk or 
by creating data "on the fly."  6. The display algorithm should lend itself to a simple hardware design. 
A hard- ware implementation of the entire display algorithm, or at least an implementation in microcode, 
would overcome computational constraints. The level of effort in hard- ware seems to be more a function 
of what one can afford rather than what one can conceptualize. Anti-aliasing is part of the display problem 
and it seems like the real solution belongs in the realm of hardware.  VISIBLE SURFACE ALGORITHM In 
general we can characterize two classes of visible surface algorithms: those which directly calculate 
all visible surfaces keeping them intact entities, and those algorithms in which the visible surfaces 
are indirectly found as a result of calculating the image at the pixel level. To the first class belong 
the subdivision algorithms of Weiler and Warnock that calculate the visible polygons (or polygonal areas) 
in a surface and which must be separately converted to a raster scan format. Also in this first class 
are the scan line algorithms such as those designed by Romney, Bouknightand Watkins. These algorithms 
directly determine a visible surface in terms of its visible segments (in image space) and each of them 
uses raster scan conversion as an integral process. All algorithms of the first class have one characteristic 
in common: they have at least one nonlinear sorting step which makes them seem inappropriate for images 
with more than about i0,000 polygons. Several of these algorithms use some form of coherence to "hedge" 
against the inevitable calculation explosion, but few coherence schemes work well with the varied and 
detailed data descriptions in a complex scene (with the possible exception of pixel coherence run lengths). 
 The algorithms in the second class are typified by the use of a frame buffer to indirect- ly determine 
which surfaces are visible. This technique makes them more suitable for the pro- cessing of high complexity 
image data. A frame buffer, usually used for video display, is nothing more than a two dimensional array 
of memory that stores all the picture information necessary to describe one complete frame. Frame buffers 
can be distinguished by whether or not they allow a full 2-dimensional bucket sort in both 'X' and 'Y', 
of if they only allow a 1-dimensional bucket sort in just 'Y'. This last type of frame buffer is called 
a run-lensth frame buffer and it uses a fixed length block of memory at each scan line in order to hold 
a list of run lengths which are visible on that scan line. The other frame buffer type is usually organized 
as 512 rows (scan lines) with each row containing 512 fixed blocks for pixel (picture element) storage. 
This type of frame buffer is characterized by the size of the pixel blocks, i.e., how much information 
each pixel contains. The simplest of this type is called a 2-D color frame buffer and has either i, 4, 
or 8 bits per pixel which indicate the pixel's color (often by pointing into a palette look-up table). 
The type known as a Z frame buffer or depth buffer is a more sophisticated one. Here, enough bits to 
adequately store the pixel's position along the 'Z' axis is kept along with the color bits for each 
pixel. This enables brute force comparison techniques to retain only the pixels closest to the observer. 
A third type of frame buffer in this categorization scheme is what we call a pixel buffer. A pixel buffer 
not only has the ability to be a 2-D color frame buffer or a Z-buffer, but it can also hold addi- tional 
information (all optional) about the pixel. This could include: original object identifica- tion number, 
object geometric type (curved, planar, line, or point), object image type (solid, transparent, shadowed, 
etc.), positional pixel skewing in 'X' and 'Y', pixel transmittance, pixel reflectance, and additional 
color information which could be used for transparency or shadows. Data is moved into the frame buffers 
in one of two methods, either unconditional overwrite or conditional overwrite. Newell is the best known 
advocate of unconditional overwriting and he has written two such algorithms. Both his algorithms depth 
sort a list of polygons (divid- ing where overlapping occurs) and then simply write the polygon into 
a frame buffer starting with the most distant face from the observer. His first algorithm used a run-length 
frame buffer, but this was abandoned for a simple 2-D frame buffer in his second algorithm because of 
the extra time spent ordering (merging) the run- lengths in 'X', and because the number of run- lengths 
associated with each scan line severely limits the image complexity. Conditional overwriting is found 
with the frame buffers which store 'Z' information at each pixel. Here a brute force comparison is made 
at a new pixel's 'Z' position, and that pixel is overwritten into the frame buffer only if it is closer 
to the observer than whatever was in there previously, or else it is ignored. Catmull, Myers and Crow 
have used the conditional overwrite approach as the heart of their visible surface algorithm. A variation 
of unconditional and conditional overwrite is unconditional and conditional modi- fy. Again, these techniques 
are used with frame buffers but instead of a direct replace F ment, a third pixel is formed as a result 
of two pixels (the current one in the frame buffer and the new pixel) combining and modifying each other. 
This condition is common when the effect of trans- parency is desired. When one deals with very high 
complexity data, a consideration that becomes almost as important to a display algorithm as its visible 
surface al- gorithm, is the manner in which the data is ar- ranged and presented to the visible surface 
rou- tines. There are two basic approaches. One approach converts an incoming list of object space data 
into one or several other lists of image space data in an attempt to make the data more "digestible" 
by the visible surface routines. The other approach is to treat each patch, face, llne or point of the 
incoming list as an isolated element, where the surface routines work directly on it in a "stream processing" 
manner. THE DISPLAY ALGORITHM R. Hackathorn of our group has approached this problem by choosing to 
process data in a stream, either by readin~ in data directly from  GENERAL OVERVIEW OF POLYGONS PROCEDURAL 
LINES (e.0. SOLIDS OF REVOLUTION ) DISK RESIDENT DATA BRING IN (PART)DATA TO SYSTEM L AND TRANSFORM~ 
~ Y~UCKET SORT RON- LENGTH INTO END OF UNORDERED (IN X) UST OF RUNS AT EACH SCAN LINE a disk or by creating 
data "on the fly" with pro- cedural algorithms. In order to do this stream style of processing, his display 
algorithm relies heavily on two large memory arrays called a run- lensth buffer and pixel buffer (frame 
buffer), respectively. The run-length buffer always exists in main memory while the pixel buffer is always 
kept in disk memory with large blocks brought in and out of main memory as needed. Our choice to internally 
represent all data as run lengths is not only a very efficient and fast method to store data, it also 
allows for a unified aproach to the display of data. In this process, triangles and lines break down 
into run lengths, and points and patch points are merely run lengths of length i. T1~eans that all these 
data types can exist together naturally within a scene description without the need to deal with special 
cases (see Figure i). While the display algorithm is very simple (i.e., run-lengths buffer to 'XY' 
pixel buffer using brute force 'Z' comparisons), it has traded off capabilities, primarily the ability 
to compare a face against other faces before making a deter- mination of their visible parts. This has 
tra- ditionally been required for such features as shadows, transparency, reflections and anti- aliasing. 
However, solutions exist for these cases, and though they may not yield the most optimal results, their 
output is a close enough approximation to be useful. Since animation in a video environment re- quires 
thirty frames per second, it is only natural to want as little information in the test  ALGORITHM POINTS 
PATCHES PIXEL BUFFER DISK MEMORY MAIN MEMORY SECTION OF PIXEL BUFFER TO BE UPDATED BUFFER I I I II IFA 
BUCKET IN THE RUN-LENGTH BUFFER BECOMES FULL, THEN EMPTY IT AND THE NEXT SEVERAL ROWS OF BUCKETS INTO 
DISK RESIDENT PIXEL BUFFER USING BRUTE FORCE "Z S COMPARISON AT EACH PIXEL LOCATION AND RESET BUCKET 
COUNTERS TO ZERO. FIG.I 292 frames as is feasible. To achieve variable com- plexity, an object consists 
of a number of differ- ent representations. At the lowest level, an ob- ject can exist as a skeleton 
made up of points and lines. A final complexity level can consist of smooth, curved or textured surfaces 
mapped onto the skeletons' positions. Variable image quality can range from very low resolution (64 x 
64) up to high resolution (1024 x 1024 averaged to 512 x 512) and include options for image en- hancements. 
 FLOW OF PROCESSING FOR THE DISPLAY ALGORITHM Assuming polygons as the data type, the flow of processing 
is as follows: l) Get a single triangle from disk or generate one using a procedure model algorithm. 
2) Update the triangle's 3 points with position, rotation and size trans-formations. ~) Determine face 
color from angle of incidence between the light source, triangle and observer. 4) Convert the triangle's 
points from an object space coordinate system to one of image space using a per- spective projection. 
5) Orient the triangle definition with respect to its highest 'Y' value. 6) Raster-scan convert the 
triangle into run-lengths with one for each scan line the face crosses. 7) Pass each run length to the 
buffer by adding it to the end of an un- ordered list of previous run-lengths found at the same Y scan 
line. 8) When all triangles have been pro- cessed for one frame, the run lengths are decomposed into 
3-D pixels and have their 'Z' values compared against a pixel with the same 'XY' values in the pixel 
buffer, effecting brute force hid- den surface removal. The pixel buffer is then read into main memory 
(one section at a time) and encoded into video run lengths for display on a TV. ADVANTAGES OF THE DISPLAY 
ALGORITHM The combination of a run length buffer and 'XY' pixel buffer eliminates three common "growth 
pains" found in algorithms processing over i00,000 polygons (or the equivalent with patch algorithms): 
 i) There are no non-linear sorts by doing a 'Y' bucket dump into the run length and, when needed, doing 
a combination 'X' bucket dump and brute force 'Z' comparison into the pixel buffer. 2) There are no 
internal image space data lists which grow in length with the number of polygons. Variable image lists 
such as active faces/ edges per scan line or depth ordered faces or the dual list out- put of subdivision 
algorithms must be stored in disk memory when the image complexity gets too high. The use of disk storage 
distracts from the advantages of procedural model data generation, and com- petes with disk-resident 
object data descriptions for space, thereby limiting maximum complexity. 3) The use of a run-length 
buffer virtually eliminates the timecosts in randomly accessing a disk- resident 'XY' pixel buffer by 
spreading the cost of disk trans- fers among many pixels. For example, if each scan line in the run length 
buffer holds i00 run lengths and 20 scan lines are moved to the pixel buffer when a scan line is full, 
and if each run-length describes an average of 3 pixels, then there is a po- tential of up to 6,000 pixels 
involved with each disk access. This translates into a cost per pixel of only a few micro-seconds for 
each memory access. Another advantage of this combination is that it provides a simple and flexible 
approach to high complexity image synthesis. This allows the dis- play algorithm to operate in a variety 
of modes and interface to a variety of external programming tasks. By using run lengths as the primitive 
data type, an internal image space data structure can be built which is common not only to simple images 
such as lines and large planar polygons, but also to complex imagery made of surface patches or millions 
of small triangles or points. Such a feature greatly facilitates interactive- ness in an animation environment 
by allowing ob- jects to be seen at various levels of detail. While the use of a run length buffer provides 
a common (fixed size) internal data structure, using a disk resident 'XY' pixel buffer provides a common 
sharable image. This makes possible a more flexible approach to generating video images" than we have 
used in the past. Using our run length encoded video interface for output we have written a 2-D color 
"painting" routine, a "star generation" routine (for producing interacting galaxies), and various random 
background genera- tion routines. But none of these programs could mix their image output with that produced 
by the display algorithm of ANIMA II, nor could ANIMA II mix in the output of any of these routines. 
By using a disk resident sharable image such as that found in the 'XY' pixel buffer, these incompar- 
ability problems are overcome simply by storing a common disk resident directory and status block, and 
allowing various routines to access any one of several 'XY' pixel buffers using tech- niques of conditional 
or unconditional overwrite or modify overwrite. This approach makes possible a variety of useful interactive 
animation techniques as well as post processing techniques for special effects and image enhancement. 
One interactive technique is to store several pixel buffers on a disk, but use Just one to process the 
video image. At the start of each frame, the separate pixel buffer can either be cleared (restarted to 
background color), simply reused as it was left from pre- vious calculations causing multiple images 
to be successively built up, or reset by unconditionally overwriting one of the other pixel buffers, 
or conditionally overwritten by several of the pixel buffers (using brute force 'Z' comparisons), effectively 
merging the 3-D surfaces together. The interactive advantages of resetting and merg- ing pixel buffers 
together can be shown in an animation example: A bird could be interactively flown around in a forest 
by precalculating a view of all the trees and storing the 2-D surfaces in a pixel buffer for a background 
image a bird could be interactively animated with a very quick re- sponse time between frames, because 
only the bird would need to be recalculated each frame. Yet the bird would be subject to all the same 
3-D cues as if the trees were also being recalculated. The bird could fly around the trees, disappearing 
as it goes behind them, or it could fly through grass or leaves, becoming only partially ob- scurred. 
Further, just as in conventional anima- tion, the background landscape of trees and mountains could be 
precalculated much larger than the actual 512 x 512 TV viewing resolution so that the field of view could 
be moved around the scene, only showing part of it at a time. Using this technique, the animator can 
enjoy the benefits of animating with complex imagery without losing the benefits of interactiveness as 
a result of slow response time. A variation of merging pixel buffers is to store only as much of the 
pixel buffers as need- ed to contain a single object (or object group). Using this technique an animator 
can not only interactively manipulate an object around a com- plex 3-D background, but can now manipulate 
parts of the background also. This is done by cal- culating an object at 512 x 512 but only using a pixel 
buffer just big enough to hold it (such as 136 x 120 or 250 x 74, etc.). Then for each frame, these pixel 
buffer sections can be inter- actively moved around with a very rapid response time while benefiting 
from 3-D cues like overlap and intersection. Precalculating several views of an object and storing them 
in this manner also has advantages for object instancing and high complexity data generation techniques 
in which the user can interactively work on part of a detailed object while the rest of the ob- Ject 
has been precalculated. SOME PROBLEMS AND POSSIBLE SOLUTIONS One problem in our approach is that all 
sur- faces are treated as visible, so that a fair amount of processing is done to each polygon whether 
it is ultimately visible or not. In a low complexity environment this problem has generally been solved 
by not using a frame buffer, but in- stead depth sorting all the polygons and finding the visible surfaces 
using segment overlapping or image subdivision techniques. The problem with this approach is that with 
a very complex scene, such as a view of a city, the time spent sorting can easily be far longer than 
the time spent using a brute force apprQach. A more acceptable way of modeling the city example is to 
use a hierarchical approach such as Clark (ii) used. However this method also suffers from non-linear 
 sorting/searching steps. A simple linear solu- tion does exist using a pixel buffer, but re- quiring 
extra bits per pixel. Using this approach the city example could exist as a very simple block model 
and as a very detailed (win- dows, doors, interiors, etc.) model. The simple model would be scanned first, 
using a brute force algorithm to find visible surfaces and storing an object number with every pixel 
indi- cating where it came from. Then the pixel buffer could be searched, making up a list of objects 
which had some visible pixels in the rouch scan. Then the detailed model could be scanned but with only 
those objects which showed up on the visible list. Thus for a small preprocessing cost, a huge number 
of polygons can be eliminated. Another problem with using a pixel buffer is that only two surfaces can 
be involved when pixels are being modified. Many situations, notably scanning a mixture of transparent 
and solid surfaces and using the anti-aliasing techniques of Catmull and Crow, require not only three 
or more surfaces to interact but also need an ordering of the surfaces from back to front. In an environment 
where the production of real- istically simulated still photographs are de- sired, there is no easy solution 
to this problem. However in an animation environment in which simplicity and speed are more important 
than accurately simulating a physical phenomenon, we believe this problem can be minimized so as to produce 
acceptable results. In the case of transparency, a lot of the problems with mixing solid and transparent 
surfaces can be avoided by scanning all solid objects first, and then transparent ones. This avoids the 
problem that occurs when a solid pixel lies between two trans- parent pixels that have already interacted 
and modified each other. The problems of trying to modify a set of randomly positioned colored transparent 
surfaces can be minimized by keeping a separate color value at each pixel for a trans- parent pixel which 
lies in front of a solid pixel or background. This, plus keeping transmittance bits and extra bits indicating 
whether a pixel is solid or transparent and whether it's been modified or not (and by how much), will 
result in an image that is merely a simulation of trans- parency, but which will be consistent and produce 
an adequate effect. Solutions to the aliasing problem require a great deal of computer time making a 
software implementation impractical for highly complex data. It can take two to five times longer than 
the visible surface calculation. We plan to im- plement, partially in hardware, a special case solution 
to this problem. Our scheme involves 294 calculating pictures at 1024 x 1024 resolution and averaging 
the intensities (not colors) of four pixels into one pixel (using dominant chroma) into a normal 512 
x 512. We also plan to experiment with various low pass filters implementing them in microcode. TEXTURE 
 In our attempt to handle visually complex objects, we are concerned not only with objects possessing 
hundreds of thousands of polygons to define smooth surfaces but also with the pro- cessing necessary 
to give the surface of an object the appearance of a particular texture. By "tex- ture" we mean the visual 
properties associated with a surface when that surface is made of a certain material, e.g., plastic, 
wool, plaster, hair, etc. To date, there have only been a few signifi- cant attempts known to us at 
accomplishing this. The most recent, and most successful, was pre- sented at SIGGRAPH '78 by Blinn. Blinn's 
paper describes a technique using a quadrilateral patch defining a normal-vector perturbation function. 
This patch is stretched to fit each surface patch and new normal vectors are computed at each sur- face 
point on the patch. Although very effective in certain situations and as a demonstration, the technique 
has three major drawbacks. First, because the texture patch is repetitively mapped onto every surface 
patch in a uniform manner, it is subject to forming undesirable patterns on the object when the actual 
texture possesses no such pattern (due to the pattern formed by the surface patches themselves, such 
as in a crater texture mapped onto a sphere consisting of eight uni- form surface patches). On the other 
hand, the technique is also capable of destroying an over- all pattern of the texture if the surface 
patches are not appropriately aligned (as in the case of mapping a brick texture onto an irregularly 
shaped object). Second, because the visible surface portion of the display processing is performed without 
regard to the texture, the image calculated when using certain textures will not appear to be "reasonable." 
Not only will a silhouette of an object not reflect the texture on the surface (e.g., bumps, bricks, 
hair), but relatively deep textures will not hide adjacent features (e.g., deep holes, craters, mountains). 
 Third, because of the simplification used in calculating the perturbed normal vector (i.e., that the 
value of the bump function is negligably small) in order to make the calcu- lation tractable, patterns 
with relatively large texture features (e.g., long hair, deep depressions, large bumps) are not correctly 
cal- culated. We have taken a different approach to repre- senting a textured object in that we define 
a three-dlmensional perturbation of the object's surface (i.e., surface detail) as well as varia- tions 
in reflectance and color properties along the surface. Because our high complexity data consists of 
hundreds of thousands of small poly- gons we can rearrange their position as well as assign individual 
color and reflectivity in order to more realistically model "physical" texture on an object. Instead 
of simulating the reflectiv- ity of craters on the surface of an object (a la Blinn) we can actually 
"create" craters on the surface. Our efforts up to this point in time have been a relatively simple repetitive 
replace- ment of a physical texture onto an arbitrary solid of revolution. To specify a texture, the 
user interactively selects the rectangular size of the patch, and the displacement, color and reflectivity 
for each point on the rectangular patch. The size of the patch is controlled by two dials. The user se- 
lects a point on the patch using two additional dials. The user specifies the displacement, color and 
reflectivity by pressing the appropriate function button and adjusting the input-value dial. At all times 
the texture rectangle is dis- played on the TV monitor with each point's value of the attribute the user 
is currently concerned with encoded in color. Thus the user can create, modify or view the attribute 
values of a texture. The user can also request a visible surface dis- play, with a modeled light source, 
of a texture patch on the monitor. Additionally he can re- quest the display of the texture on a primitive 
shape, for example, a sphere or cube. In order to specify a textured object, the user selects a contour 
llne and a texture patch (or makes hi own). At the time the object is to be displayed, a routine is called 
which gener- ates the solid of revolution defined by the con- tour line while simultaneously applying 
the per- turbation function to the surface being generated. This procedurally based object definition 
results in a flexible and straightforward representation as well as a great savings in space allocated 
to such representations. In our current implementation of processing texture, the texture specification 
contains the number of ohject slice points to be replaced as a group (call it k) and an n x m array of 
x, y, z displacements. As each object slice is gener- ated (by rotation of the object contour line) each 
k points of the slice are replaced by the n points of the appropriate column of the texture array. The 
number of the appropriate column is the number of the object slice modulo m+l. The replacement is performed 
by using the first and kth points of the group to be replaced to d4ter- mine the rotation, scale and 
translation opera- tions necessary for the first and nth points of the texture column to coincide with 
the positions of the first and kth points of the object group. The n transformed texture column points 
are then substituted for the k points of the untextured object. This process is repeated for each succes- 
sive group of k points in the object slice. When the next object slice is generated, the next column 
of the texture array is used for the re- placement. Once we have a good understanding of the re- suits 
obtainable by our method, we hope to devel- op techniques by which we can impart a texture onto an irregularly 
shaped object. This is a   GRAPHICS DISPLAY PROCESSOR The VAX 11/780 Graphics System is a hardware/ 
software interface designed to aid in the creation, calculation, and output phases of computer anima- 
tion. The main objective behind the hardware/soft- ware design is to reduce the time between object description 
and final animation output while at the same time increasing the artists' control over the process. 
The graphics system consists of three main parts. They are the Z buffer, the 2-D color frame buffer(s), 
and the run length animation port (see Figure 2). The purpose of the Z buffer is to take in 3-D run length 
formatted data and to produce, on a frame by frame basis, 2-D run length data which describes the visible 
surfaces of the orig- inal 3-D information. The Z-buffer sorting algo- rithm is implemented by a bit-slice 
microprocessor because of the relative ease with which the algo- rithm may be modified. For example, 
adding anti-aliasing or trans- parency processing requires making changes to the microprocessor' s writeable 
control store (micro- program). This approach also gives the capability to process a higher resolution 
1024 x 1024 image space and to do intensity averaging in microcode. Operation of the algorithm involves 
transla- ting the 3-D run length data into a pixel format. Each generated pixel is Z value sorted into 
the core memory. After all the runs for a frame have been processed, additional processing (such as low 
pass filtering) may occur. Then the pixel representation of the image is translated into the 2-D format 
that the run-length port recog- nizes and sent back to the VAX 11/780 for storage. The purpose of the 
2-D color frame buffer(s) is to provide a static 512 x 512 pixel image. These will be used for operator 
interaction dur- ing the object definition phase. vAx ] VAX GRAPHICS SYSTEM  I ,,,',80 | II ;~ ALL 
SUBSYSTEMS #__reef:q,, ..... ! a:: I ~'U"~-L~L~ L ~ Ja_v-~' ---I' I fIN FHlli B MEGABYTE El ' CORE MEMORY 
 FRAME BUFFER ~ DATA + ADDRESS + CONTROL ------~ TO OTHER The run-length port is the animation port of 
the system. It takes in 2-D run-length formatted data and produces real-time NTSC video suitable for 
tape recording. The run-length port accepts 2-D run-lengths data from the VAX DMA interface and translates 
this data into the appropriate real-time NTSC video. The inclusion'of the core memory in the data path 
also allows for the playback of multiple frame (less than 6 metabytes in length) sequences of high complexity. 
These sequences are of such high data band widths that the DMA interface might not be able to supply 
data fast enough. CONCLUDING REMARKS The details of the graphics language for ANTTS is the subject 
of another paper but it is important to note some of its basic capabilities. It can handle various arithmetic 
and transforma- tional commands which are either unscheduled or scheduled (of a type similar to those 
of ANIMAII) as well as incorporating commands used to modify the flow of control. Variables can be set 
either programmatically or interactively which allows great flexibility in controlling the animation. 
 BIBLIOGRAPHY Blinn, J. F., Simulation of Wrinkled Surfaces, SIGGRAPH, 1978. Brooks, J., et al., An 
Extension of the Combina- torial Geometry Technique. NTIS Report AD-782-883, August, 1974. Catmull, 
E. A., A Subdivision Algorithm for Com- puter Display of Curved Surfaces, Univ. of Utah, UTEC-CSC-74-133, 
Dec., 1974. Clark, J. H., Hierarchical Geometric Models for Visible Surface Algorithm, CACM, October, 
1976. Crow, F. C., The Aliasing Problem in Computer Synthesized Shaded Images, UTEC-CSC-76-015, Dept. 
 of Computer Science, Univ. of Utah, 1976. Hackathorn, R., The ANIMA II System, SIGGRAPH '77. Jones, 
B., An Extended ALGOL-6, for Shaded Compu- ter Graphics, Proc. ACM Symp., 1976. Myers, A. J., "An Efficient 
Visible Surface Pro- gram," Grant No. DCR 74-007"68AO1, Tech. Rep., National Science Foundationp 1975. 
 Newell, M. E., The Utilization of Procedure Models in Digital Image Synthesis, Computer Science, Univ. 
of Utah, UTEC-CSC-76-218, 1975. Staudhanmner, J., and Eastman, J. R., Computer Dis- play on Colored 
Three-Dimensional Object Images. Proc. Annu. Symp. Comput. Arch., 1975. Sutherland, I. E., Sproull, 
R. F., and Schumacker, R. A., A Characterization of Ten Hidden-Surface Algorithms, Comput. Surv., 1974. 
 Wein, M., and Burtnyk, N., A Computer Animation System for the Animator, UAIDE, 1971. FIG.2 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>807459</article_id>
		<sort_key>300</sort_key>
		<display_label></display_label>
		<article_publication_date>08-01-1979</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Parallel processing techniques for hidden surface removal]]></title>
		<page_from>300</page_from>
		<page_to>307</page_to>
		<doi_number>10.1145/800249.807459</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=807459</url>
		<abstract>
			<par><![CDATA[<p>Previous work in the hidden-surface problem has revealed two key concepts. First, the removal of non-visible surfaces is essentially a sorting problem. Second, some form of coherence is essential for the efficient solution of this problem.</p> <p>In order to provide real-time simulations, it is not only the amount of sorting which must be reduced, but the total time required for computation. One potentially economic strategy to attain this goal is the use of parallel processor systems. This approach implies that the computational time will no longer be dependent on the total amount of sorting, but more on the appropriate division of responsibility.</p> <p>This paper investigates two existing algorithmic approaches to the hidden-surface problem with a view towards their applicability to implementation on a parallel machine organization. In particular, the statistical results of a parallel processor implementation indicate the difficulties stemming from a loss of coherence and imply potentially important design criteria for a parallel configuration.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Graphics]]></kw>
			<kw><![CDATA[Hidden-surface removal]]></kw>
			<kw><![CDATA[Microprocessors]]></kw>
			<kw><![CDATA[Parallel processing]]></kw>
			<kw><![CDATA[Raster displays]]></kw>
			<kw><![CDATA[Real-time graphics]]></kw>
			<kw><![CDATA[Special purpose computers]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Parallel processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sorting and searching</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010033</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Sorting and searching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14064119</person_id>
				<author_profile_id><![CDATA[81553410956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaplan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I., Sproull, R. and Schumacher, R., "A Characterization of Ten Hidden Surface Algorithms," ACM Computing Surveys, Vol. 6, No. 1, (March 1974).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Watkins, G.S., "A Real-Time Visible Surface Algorithm," Computer Science Department, University of Utah, UTECH-CSC-70-101, June 1970.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Romney, G.W., "Computer Assisted Assembly and Rendering of Solids," Department of Computer Science, University of Utah, TR-4-20, 1970.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563895</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hamlin, G., Jr., and Gear, C.W., "Raster-Scan Hidden Surface Algorithm Techniques," Computer Graphics, Volume 11, No. 2, Summer 1977.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Warnock, J., "A Hidden Surface Algorithm for Computer Generated Halftone Pictures," C.S. Tech. Report 4-15, University of Utah, June 1969.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 PARALLEL PROCESSING TECHNIQUES FOR HIDDEN SURFACE REMOVAL by Michael Kaplan and Donald P. Greenberg 
Program of Computer Graphics Cornell University Ithaca, New York 14853 ABSTRACT Previous work in the 
hidden-surface problem has revealed two key concepts. First, the removal of non- visible surfaces is 
essentially a sorting problem. Second, some form of coherence is essential for the efficient solution 
of this problem. In order to provide real-time simulations, it is not only the amount of sorting which 
must be reduced, but the total time required for computation. One potentially economic strategy to attain 
this goal is the use of parallel processor systems. This approach implies that the computational time 
will no longer be dependent on the total amount of sorting, but more on the appropriate division of responsibility. 
 This paper investigates two existing algorithmic approaches to the hidden-surface problem with a view 
towards their applicability to implementation on a parallel machine organization. In particular, the 
statistical results of a parallel processor implementation indicate the difficulties stemming from a 
 loss of coherence and imply potentially important design criteria for a parallel configuration. COMPUTING 
REVIEWS CLASSIFICATION: 3.80, 5.25, 5.31, 6.22, 8.2 KEYWORDS: Graphics, Hidden-Surface Removal, Parallel 
Processing, Special Purpose Computers, Real-Time Graphics, Raster Displays, Microprocessors I. INTRODUCTION 
 It is obvious that if the computer synthesis of One method for reducing the total sorting time is realistic 
images in real-time is to be attained, a to apply parallel processing techniques to the reduction in 
the time required to compute the vis- hidden-surface problem. A system consisting of ible surfaces must 
occur. To quote Sutherland, many loosely coupled processors connected in par- "The hidden-surface problem 
is mainly one of sort- allel could have many advantages. Parallel sys- ing. The various surfaces of an 
object to be tems offer redundancy and, therefore, reliability. shown in hidden-surface or hidden-line 
form must They are flexible and can be reconfigured for mul- be sorted to find out which ones are visible 
at tiple uses. As individual processor and memory various places on the screen. Surfaces may be costs 
decrease, these systems will become more sorted by lateral position in the picture (xy), by cost-effective. 
Perhaps more importantly, data depth (z) or by other criteria. The order of separability is inherent 
in the hidden-surface sorting and the types of sorting used form differ- problem, which means that only 
low processor in- ences among the existing hidden-surface algor-tercommunication is necessary. This 
reduces the ithms."(1) high cost of interconnection and the problems as- sociated with high data transfer 
between proces- To reduce the work of sorting (and implicitly the sors. Furthermore, for the hidden-surface 
prob- sorting time), each algorithm capitalizes on some lem, all processors can run the same code, vastly 
 form of coherence, such as object, area, or scan-simplifying the programming effort. line. The performance 
of the algorithm is rela- ted to a number of factors, including: There is, however, a difference in the 
algorithmic performance between uniprocessor and multiproces- i. the effectiveness of the coherence 
rela- sor systems. For sequential systems, the use of a tionships, priori knowledge in the form of image 
or object coherence has been found crucial to the efficiency 2. the complexity of the object environment, 
of hidden-surface algorithms.(2) In the case of  and parallel processor implementation of hidden-sur- 
face removal, much of this coherence information  3. the complexity, size, and resolution of will be 
lost when independent parallel calculation the image. tasks are distributed across a network of proces- 
  &#38;#169;1979 ACM O-89791-004--4/79/0800--300 $00.75 See Copyright Pg. 300 sors. Thus, total computation 
time will depend more on the distribution of the image/object data and division of responsibility among 
the processors than in the case of a sequential implementation. Algorithms which perform efficiently 
on sequential systems may not be optimal for parallel systems. This paper describes two existing image 
space algo- rithms which have been taken as the basis for par- allel implementations. Statistics regarding 
the parallel processing-coherence tradeoffs for each have been collected for images of varying visual 
complexity. The behavior of a parallel scan-line image space algorithm has been studied by dividing the 
image into n groups of m scan-lines, with each set assigned to a separate task. An area subdivi- sion 
image space approach has also been modelled by assigning a specific region of the image to each task. 
Graphic results of these assignment strate- gies are presented. The results indicate poten- tially useful 
design criteria for the eventual im- plementation of real-time hidden-surface generation systems. II. 
RESEARCH BACKGROUND AND ASSUMPTIONS It is recognized that the design of a parallel pro- cessor hidden-surface 
system involves tradeoffs be- tween performance goals, hardware implementation, and software development. 
Each of these complex factors is dependent on a large number of interre- lated variables, creating an 
extremely difficult design problem. No effort was made to simulate the actual operation of a parallel 
processor, in- cluding the problem of scheduling and data trans- mission. In view of the above, many 
simplifica- tions were made regarding the parallel processor configuration. Thus, the following assumptions 
 were made: i. The system consists of a control proces- sor and an arbitrary number of processing elements 
connected by a time-shared bus (Fig. i). Each processing element consists of a 16-bit central processing 
unit and an unspecified amount of local memory. The time-shared bus was selectedbecause of its flexibility 
and low relative cost. One disadvantage of this interconnection stra- tegy is its limited bandwidth. 
Therefore low processor intercommunication was a prime consideration in our studies. 2. The workload 
is divided into tasks based on scan-line groups or image areas, de- pending on the algorithm used. These 
tasks are then distributed to the individ- ual processing elements as they become free, with task scheduling 
being performed by the control processor. Therefore, the processing elements need not communicate with 
each other or with the control pro- cessor, except for signaling completion to it.  3. The processing 
elements execute their tasks independently and completely.  4. Each processing element has an adequate 
amount of local memory, eliminating shared memory considerations.  5. The processors send pixel information 
 (x,y, color) to the image buffer, but may not retrieve any information from it.  6. The image store 
is partitioned so that refresh and update of display rates are separable.  7. The display is generated 
by reading the completed contents from the appropriate partition of the image buffer (512 x 512 x 8). 
  Computer programs were written such that an arbi- trary number of processing elements could be spec- 
 ified for each of the algorithms. Counters were inserted to measure specified arithmetic opera- tions 
and memory references. Rough timing esti- mates were calculated from these counts based on the following 
timings: memory references -400 nanoseconds comparisons -500 nanoseconds additions, subtractions -500 
nanoseconds multiplications, divisions -3000 nanoseconds  The programs were written in RATFOR and implemen- 
ted on a VAX 11/780. Object descriptions and sta- tistical results were created on an Evans and Sutherland 
Picture System I, and the color displays were rendered on a Grinnell frame buffer. ! main bus control 
I  processor E~ mpletin j image store 1 image store 2  V7 S Figure i. Schematic Parallel Processor 
Configuration 301 III. RESULTS AND COMMENTS The scope of the investigations was limited to de- termining 
the behavior of two hidden surface algo- rithms, chosen because of their inherent data sep- arability 
and the opportunity to easily separate the processing into independent tasks. For each algorithm, a 
set of environments and images with widely varying characteristics was selected to illustrate the statistical 
performance of a paral- lel machine organization. The first measurements were of a scan-line hidden- 
surface algorithm. All such algorithms exploit scan-line and point-to-point coherence(2,3). Scan- line 
coherence is the property that adjacent scan- lines intersect nearly the same set of edges. Point-to-point 
coherence is the fact that the order- ing of the edges in both x and z in adjacent scan- lines is nearly 
the same. The particular algorithm used was an efficient approach restricted to scenes composed of non-intersecting 
convex polygons(4). For this algorithm, one shaded halftone image and three charts are presented for 
each of four object environments. Statistics of these object environ- ments are summarized in Table I. 
Each of the fig- ures of the results on the scan-line case consists of three graphs. The graphs, from 
front to back on the z-axis, correspond to simulations involving 8, 32, and 128 scan-line groups per 
image. The verti~ cal axes of the charts for the different images are not to scale, although comparisons 
between them can be performed by referencing the maximum value label on each chart. Comments on the specific 
figures are; A. Halftone image of environment being evaluated. B. Total time/scan-line group. The vertical 
axis corresponds to the total processing time for all scan-lines within the group. This value decreases 
with an increase in the number of scan-line groups, but at less than a linear rate. This results from 
a loss of coherence at the begin- ning of each scan-line group, as illustrated by charts C and D. It 
is also apparent that the total processing time/group is highly dependent on the Image Image Edge Area 
Complexity* Complexity Isotropy MULTIPLE PLANES COMPLEX IMAGE High High Medium Low Figure 1 MULTIPLE 
High Low Medium Low HORIZONTAL PLANES Figure 2 CYLINDER** Medium Low Low Medium Figure 3 ARCHITECTURAL 
SIMULATION Low High High High Figure 4 *Complexity is measured by the number of surfaces at a given 
image location. **Back planes have been culled. Table I - Image Characteristics portion of the image 
being computed. Thus, tasks based on scan-line groups will vary widely in total computation times. For 
the Cylinder (Fig. 4), very low processing times were encountered. This is due to the fact that the particular 
scan-line algorithm used was optimized for surfaces consisting of pla- nar polyhedra. C. Total memory 
references/scan line. The verti- cal axis shows the total number of memory refer- ences (both reads and 
writes) to the POLYGON, EDGE, and SEGMENT blocks performed for each scan-line, including both segment 
generation and visible seg- ment determination. The display of information by scan-line, rather than 
by scan-line group, clearly indicates the loss of coherence inherent in the division of the image into 
groups. In each graph, coherence is lost for the first scan-line of each group, since new segment lists 
and depth compari- sons between relevant polygons must be regenerated. This results in the greatly increased 
number of memory references for these scan-lines. D. Comparisons/scan-line. The vertical axis re- presents 
the total number of new (previously un- performed) depth comparisons calculated for the segments on the 
scan~line. Again, data is given for each scan~line so that coherence losses are more visible. At the 
beginning of each scan-line group, the visible segment generator is unable to refer to previously calculated 
polygon depth com- parisons. Since most of the algorithms's multi- plications and divisions occur during 
this ranking process, the loss of coherence here can have a large overall effect on the total time/scan-line 
 group. A second set of statistics on the same object and image environments was collected for an area-sub- 
division algorithm (5). This hidden-surface pro- cedure also calculates depth priority in image space 
and relies primarily on area coherence in the image plane (x,y). When the algorithm encoun- ters a simple 
area (which is empty, surrounded by a front-most polygon, or has the size of a single pixel~,the area 
is rendered. Otherwise the algo- rithm recursively subdivides the area. For com- parison purposes, two 
different meshes of areas were superimposed on the images for statistical evalua- tion. E. Halftone 
image with coarse mesh. F. Predictor/total time. The x-axis of this chart corresponds to area number 
in the coarse mesh (Figs. E). The front~most graph shows the number of polygons processed by the area. 
The mid- dle graph shows the total length of all edges in- tersecting the area. The third graph is the 
total time/area. All graphs and charts are scaled to a constant value, so interchart comparisons are 
valid. These charts clearly demonstrate that both of the easily calculated parameters of the first two 
graphs are good predictors of the total time. G, &#38; H~ Total time/area. The base plane for these 
charts represent a grid overlayed on the total image area. The coarse mesh contains 256 areas, each one 
being 32 pixels square. The fine mesh contains four times as many areas, each one being 16 pixels on 
a side, All meshes have their verti- cal axes displayed to the same scale, so intermesh 302   and 
interimage comparisons are valid. For all images, it is apparent that total time/area de- creases with 
an increase in the number of areas. Because the processing complexity of an area is directly related 
to the length of crossing edges, the minimum decrease is approximately a factor of two (Figs. F). These 
charts also demonstrate the wide variance of total time/area depending on the complexity of the image 
portion processed. IV. CONCLUSIONS The design of a parallel processor system for hid- den-surface removal 
involves tradeoffs between the goals, hardware, and software of the proposed sys- tem. Each of these 
categories contains a large number of interrelated variables, and their global interactions form an extremely 
complex overall de- sign problem. These variables include the types of images to be processed, along 
with their orien- tation-dependent behavior under transformations, the type of algorithm used, the division 
of respon- sibility and data among the processors, as well as processor configuration and interconnection 
stra- tegy. Fortunately, certain aspects of the hidden-surface problem make it particularly suitable 
for imple- mentation on a parallel system. For most algor- ithms, the necessary computations can be easily 
 and naturally partitioned into separate tasks. Correspondingly, the data processed by these tasks can 
also be separated into self-contained groups, with the final collection of results occurring in a buffered 
raster-display memory. In this way, processor interconnection requirements can be kept to a minimum. 
The fact that many tasks can run the same code further reduces the complexity of the software development 
process, In addition, heuristic scheduling of the individual tasks may be simplified by the fact that 
their run-time char- acteristics may be predictable through reference to the algorithm and the data segment 
on which they operate. In choosing a hidden-surface algorithm for para- llel implementation, the major 
consideration must be the "partitionability" of its computation into independent tasks with a minimum 
of intercommuni~ cation requirements. A second important consid- eration involves the maintenance of 
the use of coherence in reducing the visible-surface computa- tions. The computational efficiency of 
a parallel processor system may also be affected by the algor- ithm used to schedule its tasks. Preliminary 
research has investigated the behavior of two image-space algorithms on a simplified, hypothetical parallel 
processor configuration. A consideration of even these limited results yields some important conclusions 
and directions for future research. Some of the facts that have emerged from the studies performed on 
the scan- line and area subdivision algorithms include the following: i. The image characteristics particularly 
impor- tant to parallel processor hidden-surface implementations appear to be image area, image complexity, 
edge complexity, and the relation of the class of images to the particular algorithm. 2. In real-time 
image production, the behavior of the object environment under transformation can have an important effect 
on the necessary throughput o'f the hidden-surface system.  3. In order to obtain the maximum efficiency 
of the parallel system, it is necessary to keep all processors busy as much as possible. This can be 
done by utilizing a heuristic task scheduling algorithm based on task complexity. Results show that such 
a predictor is avail- able in the case of both of the algorithms studied.  4. Although some coherence 
is lost when data is distributed to independent tasks, results show that the increased processing necessary 
to compensate for this loss is more than offset by the benefits of processing the tasks in parallel. 
 5. In both the scan-line and area subdivision cases, low task intercommunication was re- quired for 
the images studied. In the area subdivision algorithm, the number of polygons passed to the tasks created 
as the result of a subdivision decreased exponentially with the number of levels traversed.  Although 
the scope of the investigations is rather limited, this preliminary research has shown great promise 
for the application of parallel processing techniques to the hidden-surface problem. Alter- nate algorithms 
and configurations are currently under investigation. V. REFERENCES i. Sutherland, I., Sproull, R. 
and Schumacher, R., "A Characterization of Ten Hidden Surface Algorithms," ACM Computing Surveys, Vol. 
6, No. i, (March 1974). 2. Watkins, G.S., "A Real-Time Visible Surface Algorithm," Computer Science 
Department, Uni- versity of Utah, UTECH-CSC-70-101, June 1970.  3. Romney, G.W., "Computer Assisted 
Assembly and Rendering of Solids," Department of Computer Science, University of Utah, TR-4-20, 1970. 
 4. Hamlin, G., Jr., and Gear, C.W., "Raster-Scan Hidden Surface Algorithm Techniques," Computer Graphics, 
Volume ii, No. 2, Summer 1977.  5. Warnock, J., "A Hidden Surface Algorithm for Computer Generated Halftone 
Pictures," C.S. Tech. Report 4-15, University of Utah, June 1969.  ACKNOWLEDGEMENTS The work was performed 
at Cornell's Laboratory of Computer Graphics which is partially sponsored by the National Science Foundation. 
 The authors would like to thank Mark Spitzer and Eliot Feibush for their help in preparing the manuscript. 
 307  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1979</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

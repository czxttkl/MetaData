<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date></start_date>
		<end_date></end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Dallas]]></city>
		<state>TX</state>
		<country>USA</country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>97879</proc_id>
	<acronym>SIGGRAPH '90</acronym>
	<proc_desc>Proceedings of the 17th annual conference</proc_desc>
	<conference_number>17</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-344-2</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1990</copyright_year>
	<publication_date>09-01-1990</publication_date>
	<pages>452</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3.3</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
		<other_category>
			<cat_node>I.3.0</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
		<other_category>
			<cat_node>I.3.5</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
		<other_category>
			<cat_node>I.3.7</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
			<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10003752.10010061</concept_id>
			<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010352</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010396</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10003752.10010061.10010063</concept_id>
			<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010372</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010382</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Algorithms</gt>
		<gt>Design</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP39092447</person_id>
			<author_profile_id><![CDATA[81100515727]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Forest]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Baskett]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1990</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>97881</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Curved surfaces and coherence for non-penetrating rigid body simulation]]></title>
		<page_from>19</page_from>
		<page_to>28</page_to>
		<doi_number>10.1145/97879.97881</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97881</url>
		<abstract>
			<par><![CDATA[A formulation for the contact forces between curved surfaces in resting (non-colliding) contact is presented. In contrast to previous formulations, constraints on the allowable tangential movement between contacting surfaces are not required. Surfaces are restricted to be twice-differentiable surfaces without boundary. Only finitely many contact points between surfaces are allowed; however, the surfaces need not be convex. The formulation yields the contact forces between curved surfaces and polyhedra as well. Algorithms for performing collision detection during simulation on bodies composed of both polyhedra and strictly convex curved surfaces are also presented. The collision detection algorithms exploit the geometric coherence between successive time steps of the simulation to achieve efficient running times.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39038146</person_id>
				<author_profile_id><![CDATA[81100334025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baraff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., "Analytical methods for dynamic simulation of non-penetrating rigid bodies," Computer Graphics (Proc. SIGGRAPH), vol. 23, pp. 223-232, 1989.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., "Determining frictional inconsistency for rigid bodies is NP-complete," Technical Report TR 90-1112, Department of Computer Science, Comell University, 1990.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barzel, R. and Barr, A.H., "A modeling system based on dynamic constraints," Computer Graphics (Proc. SIG- GRAPH), vol. 22, pp. 179-188, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>11790</ref_obj_id>
				<ref_obj_pid>11783</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Canny, J., "Collision detection for moving polyhedra," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 8, no. 2, pp. 200-209, 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cundall, P.A., "Formulation of a three-dimensional distinct element model -- Part I. A scheme to represent contacts in a system composed of many polyhedral blocks," international Journal of Rock Mechanics, Mineral Science and Geomechanics, vol. 25, no. 3, pp. 107-I 16, 1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>576516</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Featherstone, R., Robot Dynamics Algorithms, Kluwer, Boston, 1987.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578659</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Forsythe, G.E., Malcolm, M.A., and Moler, C.B., Computer Methods for Mathematical Computations, Prentice Hall, Inc., Englewood Cliffs, 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gilbert, E.G., Johnson, D.W., and Keerthi, S.S., "A fast procedure for computing the distance between complex objects in three space," IEEE Journal of Robotics and Automation, vol. 4, pp. 193-203, 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Goldstein, H., Classical Mechanics, Addison-Wesley, Reading, 1983.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>866403</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goyal, S., "Second order kinematic constraint between two bodies rolling, twisting and slipping against each other while maintaining point contact," Technical Report TR 89-1043, Department of Computer Science, Cornell University, 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[L6tstedt, P., "Mechanical systems of rigid bodies subject to unilateral constraints," SIAM Journal of Applied Mathematics, vol. 42, no. 2, pp. 281-296, t 982.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[LStstedt, P., "Numerical simulation of time-dependent contact friction problems in rigid body mechanics," SIAM Journal of Scientific Statistical Computing, vol. 5, no. 2, pp. 370-393, 1984.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Moore, M. and Wilhelms, J., "Collision detection and response for computer animation," Computer Graphics (Proc. SIGGRAPH), vot. 22, pp. 289-298, 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Murty, K.G., Linear Complementarity, Linear and Nonlinear Programming, Heldermann Verlag, Berlin, 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nelmark, Ju.I. and Fufaev, N.A., Dynamics of Nonholonomic Systems, American Mathematical Society, 1972.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Taylor, A.E. and Mann, R.M., Advanced Calculus, John Wiley &amp; Sons, Inc., New York, 1983.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Tomlin, J.A., "Robust implementation of Lemke's method for the linear complementarity problem," Technical Report SOL 76-24, Systems Optimization Laboratory, Department of Operations Research, Stanford University, 1976.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Curved Surfaces and Coherence for Non-penetrating Rigid Body Simulation David Baraff Program of Computer 
Graphics Cornell University Ithaca, NY 14853 Abstract A formulation for the contact forces between 
curved sur- faces in resting (non-colliding) contact is presented. In contrast to previous formulations, 
constraints on the allowable tangential movement between contacting surfaces are not required. Surfaces 
are restricted to be twice-differentiable surfaces without boun- dary. Only finitely many contact points 
between surfaces are allowed; however, the surfaces need not be convex. The formula- tion yields the 
contact forces between curved surfaces and polyhe- dra as well. Algorithms for performing collision detection 
during simulation on bodies composed of both polyhedra and strictly convex curved surfaces are also presented. 
The collision detec- tion algorithms exploit the geometric coherence between succes- sive time steps 
of the simulation to achieve efficient running times. Categories and Subject Descriptors: 1.3.5 [Computer 
Graphies]: Computational Geometry and Object Modeling; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics 
and Realism Additional Key Words and Phrases: dynamics, constraints, simu- lation  1. Introduction One 
of the most difficult behaviors to simulate in rigid body dynamics is the non-penetration constraint 
between solid bodies. The two problems involved in simulating non-penetrating rigid bodies are (1) detecting 
collisions and contact between pairs of bodies and (2) determining the contact forces present between 
contacting bodies. The force determination problem can be solved by analyti- cal and non-analytical methods. 
Both Barzel and Barr[3] and Baraff[1] give motivations for preferring analytical methods over non-analytical 
methods in rigid body simulation. Analytical for- mulations for the contact forces that arise between 
polyhedral bodies have been presented in [1,6, 11, 12]. These formulations are the most general possible 
in that they express the contact forces between bodies that are completely unconstrained in their tangential 
(sliding) movement. For curved surfaces, formulations for the contact forces that arise to prevent inter-penetration 
have only been realized for certain cases of constrained tangential movement. For example, if two curved 
surfaces are restricted to roll without slipping, the contact force between them is easily determined[10, 
15]. Similar restrictions such as rolling with a specified slip velocity also have simple analyttieal 
solutions. The Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publicationand its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
ix~rmission. general case of non-penetration between curved surfaces without any constraint on the tangential 
movement poses a much more difficult problem; the extension from polyhedra to curved surfaces is not 
straightforward. We present a formulation of the contact forces between curved surfaces that are completely 
unconstrained in their tangential movement. We have not encountered a formu- lation for this problem 
in any previous literature. We restrict our- selves to the case of twice-differentiable curved surfaces 
without boundary that contact at only finitely many points. Configurations that result in one- or two-dimensional 
contact regions are not dealt with. The surfaces need not be convex in the neighborhood of a contact 
point and may be defined by either implicit or parametric equations. A formulation of the contact forces 
between curved surfaces and polyhedra is derived as a special case of contact between two curved surfaces. 
The collision detection problem has an extensive literary background in the fields of computational geometry 
and robotics. Computational geometry focuses on problems posed in terms of a static environment. Robotics 
generally focuses on problems posed in terms of a dynamic environment; the movement of bodies is known 
in terms of some function of time. In both cases, the emphasis is on developing the best algorithm for 
solving a sin-gle problem, either static or dynamic. In contrast, dynamic simu- lation involves the solution 
of a sequence of static problems, one per time step. Although each problem of the sequence can be solved 
separately using previous collision detection methods, algorithms specifically designed to solve a sequence 
of related problems are more efficient. We present efficient collision detec- tion algorithms for polyhedra 
and convex closed curved surfaces by exploiting the geometric coherence between successive colli- sion 
detection problems of the simulation. Surfaces can be defined either implicitly or parametrically. 2. 
Overview Simulation of non-penetrating rigid bodies by analytical methods involves the basic flow of 
control shown in figure 1. At every time step, bodies are examined pairwise for possible inter- penetration. 
If two bodies are found to inter-penetrate, the simu- lator backtracks to the point in time immediately 
before the inter- penetration occurred. Once a configuration without inter-penetration is achieved, the 
contact points between all the bodies are found. Finally, a system of constraint equations based on the 
contact points yields the analytically correct contact forces and impulses at every contact point. After 
the contact forces and impulses are applied to the bodies, a new time step is begun. We group this series 
of steps into two phases: contact determination (steps A-D of figure 1) and force determination (step 
E of figure 1) For curved surfaces, both the inter-penetration check and the backtracking steps of the 
collision determination phase make use of the same mathematical derivations used in the force deter- 
mination phase. Accordingly, we will deal first with extending &#38;#169;1990 ACM-0-89791-344-$00.'/5 
2/90/008/0019 Initial configuration A (backup to t) geometrical tdvance t) comparison B ~ @ ~ (apply 
Predict forces)intersection time t D ~/no E Find Form/solve [  contact force points equations Figure 
1. Simulator control flow. the force determination model to curved surfaces. 3. Analytical Force Determination 
Featherstone[6] gives a complete derivation of the system of constraint equations used to find contact 
forces between rigid bodies. We present a brief review of the mathematical structure of the problem. 
At some time to we are given a collection of non-penetrating perfectly rigid bodies that contact at some 
number of points and asked to calculate the forces between the objects that would naturally arise to 
prevent inter-penetration. Contact points at which bodies are colliding give rise to contact impulses. 
Methods for calculating the contact impulses between bodies of any geometry are given in [1,6, 9]. Contact 
impulses are calcu- lated and applied prior to considering contact forces. Accordingly it is assumed 
that the configuration of bodies being analyzed has no colliding contacts. Consider a contact point Pc 
between two bodies A and B at time t o (figure 2). Let the unit surface normal at the contact point be 
h (see Baraff[l] for the case when h is not well defined). In the absence of friction, the (as yet) unknown 
contact force F is writ- ten F = f~ with fthe unknown (scalar) contact force magnitude at time to. ^ 
F =f~ n Figure 2. Contact between two objects. The primary consideration for calculating the unknown 
contact force magnitude f at each contact point lies in the non-penetration constraint between bodies. 
At every contact point Pc between two bodies A and B at time to, a geometrical constraint that prevents 
A and B from inter-penetrating near Pc is con-structed. Each constraint is converted by a differentiation 
opera- tion into a constraint on the contact force magnitude f at Pc. The geometrical constraint is expressed 
by a constraint function (or characteristic function ) X(t). A characteristic function Z(t) is a function 
of time that characterizes the geometric relation of A and B close tope at times near to .1 Z takes on 
values as follows: i > 0 ifA and B are separate nearpc or Eft) = = 0 if A and B are touching near pc 
or (1) < 0 if A and B are inter-penetrating near Pc- Given Z, we can express the constraint that A and 
B not inter- penetrate near Pc as X(t) _> 0. (2) For example, consider a potential vertex-face contact 
between two planar polygons (figure 3). A A X(t) > 0 X(t) = 0 Z(t) < 0 Figure 3. Vertex-face contact. 
Let po(t) be the position of the vertex of A, pb(t) be the position of any fixed point on the contact 
face of B and let ~(t) be the out- wards unit normal of the contact face. The characteristic function 
for this situation is X(t) = n(t)" (pa(t) -pb(t)). (3) From figure 3, X(t) is positive, zero, or negative 
according to whether p~(t) lies above, on, or below the contact face of B at time t. Intuitively, Z may 
be regarded as a measure of the distance between A and B, with negative distance indicating inter-penetration. 
Similarly, Z may be regarded as a measure of the relative velocity between A and B. If X(t0) < 0 then 
X is decreas- ing and the bodies are colliding; however, it was assumed that the configuration had no 
colliding contact points. Likewise, if Z(t0) > 0 then Z is increasing and the bodies are separating; 
in this case the contact force is automatically zero and the contact point may be disregarded. Thus, 
the only contact points con-sidered are those for which X (to) = 0. In order to convert the geometric 
constraint Z(t) _> 0 (equa- tion (2)) into a constraint on the contact forces, we take the second derivative 
of Z with respect to time and require that 2(to) -> 0. (4) Informally, we have constrained the relative 
"acceleration" ~, between A and B, to be non-negative. (Strictly speaking however, is not a physical 
measure of acceleration). Analytically, since Z(t0) = ~(t0)= 0, ~(t0) < 0 would make X a decreasing function 
at to. This would violate the constraint of equation (2). We stress the fact that Z is a local function 
and need only be valid for an arbitrarily small open neighborhood of to. ~ How does ~(t0)-> 0 constrain 
the contact forces? While Z(t0) and ~(t0) are independent of any internal or external forces, ~(to) is 
a linear expression of the contact forces at time to. Intui-tively, the contact forces must be "strong 
enough" to satisfy equa- tion (4), and thus prevent A and B from accelerating towards each other at Pc. 
Appendices A and C show that equation (4) is a linear inequality constraint on the contact force magnitudes. 
In addition to the geometrically motivated constraint ~(t0)-> 0, there is an additional relationship 
between Z(t0) and f that must be satisfied. If ~(t0) > 0, then Z is an increasing func- tion at time 
t o and A and B are separating at Pc. In this case the contact force is zero. However, if ~(t0) = 0 then 
A and B are not separating and fneed not be zero. The relationship between fand ~(to) is known as a complementarity 
condition; it is written as f~(to) = 0 (5) to express the fact that either f or ~ is zero. If we impose 
the res- triction that f be non-negative, so that objects can "push" but not "pull" on each other, then 
a configuration with N contact points must satisfy the system of equations Zi(to) >- O, fi Zi(t0) = 0, 
f/_> 0 (1 _< i _<N) (6) where f~ and Zi are the contact force and constraint function for the ith contact 
point. In a previous paper, we proposed a heuristic method for solving equation (6). For the case of 
frictionless con- tact, equation (6) forms what is known as a positive semidefinite (PSD) linear complementarity 
problem. Equation (6) can also be viewed as a PSD quadratic programming problem. Efficient numerical 
algorithms exist that solve PSD linear complementarity problems 2 and PSD quadratic programs[14], and 
we advocate their use over the heuristic solution method. However, in the presence of friction, it is 
known that equation (6) is no longer necessarily PSD. Finding the solution of a non-PSD linear com- plementarity 
problem or quadratic program is NP-hard[14]. A recent result[2] shows that finding a solution to equation 
(6) in the presence of friction is also NP-hard. Thus, heuristic solution methods may indeed be necessary 
for practical simulations. For both PSD and non-PSD systems, coherence based methods can be exploited[12, 
14] to reduce the computational expense of solving equation (6). See Lrtstedt[1 1,12] and Featherstone[6] 
for further discussions on the properties of this constraint system and methods for solving it.  4. 
Analytical Forces between Curved Surfaces In the case of polyhedral objects, the characteristic function 
and its second derivative ~ are readily available. Additionally, contact between polyhedra may result 
in line segments or polygons of contact. Although this results in an infinity of contact points, constraint 
functions need be formulated only for the finitely many vertices of the convex hull polygon of the contact 
line or area[l]. For curved surfaces however, the convex hull of the contact area may not be a polygon. 
For example, a cylinder standing upright on a plane has a circular area of contact points. The convex 
hull of this contact region is a circle and cannot be described by a finite number of vertices. We have 
not developed a constraint for contact regions of dimension one or higher. Although discretization of 
the boundary of the contact area is one possibility, we would rather deal with an analytical formulation 
over the entire boundary. For curved surfaces, we will restrict our attention to situations in which 
the number of contact points is finite. We will construct a characteristic function Z for each con- tact 
point. 2 Our simulator uses an implementation of Lemke' s algorithm described in [ 17]. Computer Graphics, 
Volume 24, Number 4, August 1990 I I iii The difficulty in formulating a geometric constraint func- 
tion for curved surfaces in contact is the need to construct a for- mula specific enough to be differentiable. 
How can we formulate the geometric constraint that all points on surface A near a point Pc remain on 
or outside surface B? Furthermore, how can we write this as a scalar-valued differentiable function that 
is posi- tive, zero, or negative according to whether A and B are disjoint, contacting, or inter-penetrating? 
One possible start is to let Z be the minimum distance between A and B near Pc, and require that Z always 
be non-negative. The minimum distance is positive when A and B are separate and zero when they are contacting. 
How-ever, as figure 4 shows, the minimum distance is not negative when A and B initially inter-penetrate; 
it is zero) Additionally, the minimum distance is not differentiable at the time that A and B first contact 
at Pc. Closely related to the minimum distance however is the concept of an extreme distance. The extreme 
distance between A and B nearpc is defined as follows. IfA and B are disjoint nearpc then the extreme 
distance between A and B is just the normal minimum distance between A and B (near Pc). If A and B are 
in contact at Pc, then the extreme distance is zero. If A and B have inter-penetrated near Pc, then the 
extreme distance is the max-imum distance between A and B (near Pc). The extremal points of A and B are 
the two points pa and Pb on A and B that realize the extremal distance (figure 4). extreme dist. = min. 
dist. rain. dist. = 0 F ....___.~.j/ extreme dist. = 0 \ P~ extreme dist. = max. dist. Figure 4. The 
extremal distance and extremal points. Given the above definitions, we can construct a constraint function 
by letting X(t) be a positive multiple of the extreme dis- tance when A and B are disjoint or contacting. 
When A and B have inter-penetrated, we will let X(t) be a negative multiple of the extreme distance. 
In the next section we will show how Pa and Pb can be used to construct such a formula. The restriction 
to situations where only finitely many contact points arise guarantees that the extreme distance (and 
the extremal points) of A and B sufficiently near Pc will be unique.  5. Deriving We still must construct 
an explicit formula for Z so that it may be differentiated to find ~. Although the Z we develop in this 
section yields an impractical result (computationally speak- ing), we feel its presentation is necessary 
to clearly understand the final form 6f ~ and ~ derived in section 6. The derivation of and ~ will assume 
implicit definitions of the curved surfaces; however, the end result depends solely on the derivatives 
of the surfaces at the contact points. As a result, parametric definitions of the surfaces can be used 
as easily as implicit definitions for determining contact forces; see appendix D for details. We model 
the two curved surfaces of A and B as implicit time-varying functions F(p,t) and G(p,t) where p is a 
point in world space. At time t, a point p is on the surface of A iff 31f one shape lies completely inside 
the other, the minimum distance between them is positive, but intersection between the surfaces must 
occur first. F(p,t) = 0. (We will refer to F and G as both functions and sur- faces). Furthermore, if 
F(p,t)< 0 then p is inside A, and if F (p,t) > 0 then p is outside A. The function G similarly defines 
the shape of B. We will use the notation F(p,t) = f (p,t) = VF(p,t) , (7) where VF(p,t) is a column 
vector (and F'(p,t) a row vector). If F(p,t) = 0, then VF(p,t) is the outwards directed surface normal 
ofF at point p at time t (figure 5). extremal points ~ F(p) > 0 Figure 5. Implicit surface description 
of A and B in terms of F and G. Given these definitions, we can express Z as Z(t) = VG(pb,t)" (pa(t) 
- pb(t)) (8) where p~ and Pb are the two extremal points between A and B at time t. From figure 6, we 
see that VG(pb,t) is colinear with the vector Pa - Pb. F .~ VG(pb,t) VG(pb,t)  V G~ ,t ) I p~ Pb G 
p. X(t) > 0 X(t) = 0 X(t) < 0 Figure 6. X expressed in terms of the extremai points. When A and B are 
disjoint, VG(pb,t) is pointed in the same direc- tion as Pa -Pb; hence Z(t) is a positive multiple of 
the distance IlPa--Phil. Similarly, when A and B inter-penetrate, VG(pb,t) points in the opposite direction 
of Po -Pb and X(t) is a negative multiple of the distance liPs-Phil. Thus, Ix(t)l is the extreme distance 
at time t scaled by [IVG(pb,t)ll and equation (8) defines a valid characteristic function ~. The derivative 
of equation (8) requires the derivatives ofpa and Pb- Although the curved surface characteristic function 
appears similar to the polyhedral characteristic function (equation (3)), the latter is easily differentiated 
while the former is not. In the polyhedral characteristic function, the points Pa and Pb denote fixed 
points of A and B. The derivatives of a fixed point of a rigid body are simply expressed in terms of 
the motion of the body[3, 9]. However, in the case of curved surfaees, pa andpb are not fixed points 
of A and B. p~ and Pb change positions in two ways. First, po and Pb move according to the rigid body 
motion of A and B. Second, p~ and Pb change positions in the body space of A and B (figure 7). In order 
to differentiate p~ and Pb, they must be redefined in such a way that they can be differentiated. I X 
I ! k Pa I t Pb i ,t Figure 7. Movement of p~ and Pb in both world and body space. We define the extremal 
points Pa and Pb at time t as the (unique) pair of points near Pc that satisfy the conditions f El: VF(p,,t) 
+ ~,2VG(pb,t) = E2: F(pa,t) = 0 E3 : G(pb,t) = 0 (9) E4: (fib --Pa) + ~'I ~TG(pb, t) = ~" ~,1 and ~ 
are unconstrained scalar values. Condition El guaran-tees that the surface normals at the extremal points 
are colinear. Conditions E 2 and E 3 guarantee that Pa and Pb are points on A and B, and condition E4 
guarantees that pb'S displacement from Pa is colinear to the surface nonnals. A formal justification 
of conditions El thru E4 as a definition of the extremal points may be found in any advanced calculus 
text; see for example Taylor and Mann[16]. Figure 6 shows the geometric intuition behind equation (9). 
Equation (9) is closely related to the Lagrange mul- tiplier formulation for constrained minimization 
(hence our choice of X as a symbol for the multipliers of VG). For the case of contact between a polyhedron 
A and a curved surface B, equation (9) is modified depending on whether Pc is coincident with a face, 
edge or vertex of the polyhedron. If Pc lies in a face, then F is the implicit function of the plane 
embedding the face. Otherwise, if Pc lies on an edge and VG(pb,to) is not perpendicular to any adjoining 
face, pa is con- strained to be the extremal point on the edge. If Pc lies on a ver- tex, and VG(pb,t0) 
is not perpendicular to any adjoining edge (and hence any adjoining face), Pa is defined to be coincident 
with the vertex. In the above two cases, a system of equations similar to (9) is formed and used in place 
of equation (9). Conditions E t thru E4 are used to derive expressions for the derivatives of Pa and 
p#. (We will consider numerical solu- tions of equation (9) to find Pa and pv when we deal with collision 
determination in section 7.) Given extremal points p~ and Pb, we can find/b a and/~o by making use of 
the implicit function theorem for simultaneous equations from calculus[16]. This theorem asserts that 
under proper conditions, Pa and Pb may be regarded as functions of time; the theorem also gives an analytic 
expression for the derivatives of p, and Pb (with respect to time). We will write the Jacobian determinant 
of a set of vector functions H l (~) thru H~(~) as ~H 1 ~Xl ,9(H~, ... ,n.) (IO) a~,,"',~) ah. bxl @ 
~ If we are dealing with 3-space, then pa and Pb are each three (scalar) functions of time: p,~ (t), 
Pay (t) and pa~ (t) and simi- larly for Pb. The implicit function theorem, applied to equation (9) yields 
K ha, (t) = -7 (11) where O(E] ,E2,E3,E4) K-(12) 3(t,p,y ,p~ ,Pbx ,Pby ,Pbz, ~'1, ~'2 ) and ~(EI,E2,E3,E4) 
J = 3Q)a x ,Pay ,Paz ,Phi,Pby ,Pb= ,~l ,~k2) " (13) Similar expressions give the derivatives for pay, 
Paz, Pox, Pbr and Pbz. Appendix E discusses possible ill-conditioning of the Jaco- bian matrix J. If 
we are given the extremal points p, and Pb, ~l and L2 are easily determined and/~a and/~b are easily 
calculated (assuming the needed derivatives of F and G are at hand). How-ever, an expression for ~ involves 
the symbolic computation of~3, and /~b; these in turn require derivatives of K and J. Unfor-tunately, 
a symbolic expression for the determinant of K or J is impractical. Although K and J have considerable 
block structure, block structure cannot be exploited in computing determinants. In its present form, 
the Jacobian determinant contains more than 1,000 terms of seven factors each; the derivative would contain 
far more terms. A transformation of coordinate systems and func- tions is presented in the next section 
that yields more tractable expressions.  6. Coordinate Transformations The formulation for/~ and/~b 
in the last section involved derivatives of determinants of 8 ×8 matrices. By choosing an appropriate 
coordinate system and transforming the representation of the surface functions F and G, we can find a 
tractable represen- tation for/~ and/~b. First, we assume a rotated coordinate system in which VF(pa,to) 
and VG(pb,t0) are colinear with the z axis at time to, with VG(pb,t0) directed positively along z. (We 
will employ the standard right-handed coordinate system used to depict functions z=h(x,y), with z the 
vertical axis). The effect of this rotation on derivatives of F and G is discussed in appendix B. Next, 
we explicitly model A near Pa as a time-varying scalar function f of x and y. Where F was a function 
F(x,y,z,t), f is a function f(x,y,t). The justification for the existence of f is the implicit function 
theorem of calculus. The formal definition of f is F(x,y,f(x,y,t),t) -- 0. (14) Thus, the point (x,y,f(x,y,t)) 
is a point on F at time t. A function g is chosen similarly for G. In this new coordinate system, the 
extremal points p~ and Pb share the same x and y coordinates at time t 0. At times t near t 0, A and 
B do not penetrate as long as the z value of Pa is greater or equal to the z value of Po (figure 8). 
This can be expressed as Z(t) = f(p,~,p,y,t) -g(Pb~,Pby ,t). (15) The condition ~ _> 0 is simply d~2 
f(pax,Pay,tO) _ d2~-g(Pb x ,Pby ,lo) --> O. (16) The extremal points are then expressed in terms of f 
and g, without the use of the multipliers ~.l and Lz (see appendix C, ComputerGraphics, Volume 24, Number 
4, August 1990 IIIII z =f(x,y) ~Y t/ ,Pby ,gQ~b~ z =g (x,y) Figure 8. Side view of the implicit surfaces 
F and G expressed explicitly by fand g. equation (42)). This change of coordinate systems and functions 
reduces the number of variables from 8 to 4; this allows a formu- lation in terms of 4 x 4 matrix determinants 
as opposed to the 8 x 8 matrices of the previous section. While this is an improvement, calculating the 
derivatives of the determinants constructed from equation (42) is still a formidable challenge; however, 
they are no longer needed. The real advantage of the new formulation is that the second derivatives of 
Pax, Pay, P#~ and pay are not required when computing ~. Equation (47) of appendix C shows how the second 
derivatives of Pa and Pb drop out of the expression for d 2 d 2 ,o~-f and -~t~-g. The final result is 
a fairly simple symbolic expression for ~.  7. Contact Determination Given the vast literature on collision 
detection in the com- putational geometry and robotics fields, it is with some trepidation that we present 
new algorithms for collision detection and deter- mination of contact points. The algorithms presented 
are very basic; nonetheless we have found them to be extremely efficient for our simulations. In a dynamic 
simulation, a series of collision detection problems is encountered. Each problem is similar to the collision 
detection problem posed and solved during the previous time step. The focus of the algorithms presented 
in this section is using information from the previous time step to solve the colli- sion detection problem 
for the current time step. The collision detection problems addressed in computational geometry and robotics 
are of a different nature. In the field of computational geometry, collision detection algorithms are 
by and large restricted to static geometrical configurations. Algorithms are typically developed to solve 
a sin- gle instance of a problem involving fixed objects in the smallest asymptotic time complexity. 
The use of algorithms of this nature for collision detection during simulation essentially ignores any 
information discovered in previous time steps. Gilbert et al.[8] present an algorithm that efficiently 
computes the minimum dis- tance between convex objects. Additionally, the algorithm can use information 
from previous time steps for fast initialization, and would appear to be an attractive candidate for 
detecting colli- sions. However, we are not interested in the value of the minimum distance per se. and 
we feel that the algorithms presented below are better suited to our simulation environment. For the 
simpler problem of determining the disjoinmess of two convex polyhedra with a total of n vertices, algorithms 
with asymptotic time complexities of O(nlogn) and even O(n) have been achieved; however, it is not clear 
that these algorithms are practically useful for reasonable values of n[8]. In the field of robotics, 
algorithms are developed for geometric problems involving objects with specified continuous motions over 
some time period; for example, determining the first collision between polyhedral objects[4]. These algorithms 
presuppose known paths for the objects and detect collisions over the length of the paths. In our case, 
the paths of the objects are not known. We have found that the geometric relationship between objects 
in our simulations does not change very much between successive time steps. As a result, collision detection 
algorithms for our simulation environment should be structured to take max- imum advantage of the geometric 
coherence between successive time steps. Our simulator uses contact determination algorithms that assume 
a high degree of coherence between time steps. If the relative displacements of objects between successive 
time steps are large, this assumption breaks down. However, our experience has been that numerical considerations 
in solving the differential equations of motion limit the size of the time step. We choose not to treat 
the case where an object passes completely through another object in one time step; one solution to this 
problem is 4D space-time swept volume algorithms to detect collisions [ 13]. In this paper we limit our 
objects to the union of convex polyhedra and strictly convex closed surfaces. We will refer to these 
polyhedra and curved surfaces as primitives. The first geometric problem we consider is the pairwise 
comparison of primitives to determine inter-penetration. 4 Our primary mechan- ism for exploiting coherence 
will be through the use of witnesses to the decision problem of inter-penetration. A witness is some 
piece of information that can be used to quickly answer a decision problem. We will utilize coherence 
by caching witnesses from one time step to the next; hopefully a witness from the previous time step 
will be a witness during the current time step. Since primitives are convex, a pair of primitives do 
not inter-penetrate if and only if a separating plane between them exists. 5 A separating plane between 
two objects is a plane such that each object lies in a different half-space of the plane. A given plane 
can be verified to be a separating plane between two convex polyhedra in time O (n) where n is the total 
number of vertices of the two polyhedra. Cundall[5] performed pairwise collision detection during simulation 
by initially finding separating planes that were approximately equidistant from each polyhedron of the 
pair. At later time steps, numerical techniques were used to quickly update the separating planes so 
that they maintained their equidistant relationship between pairs of polyhedra. A simpler solution exists 
however; for disjoint or contacting convex polyhe- dra, it can be shown that a separating plane exists 
which either embeds at least one face of one of the polyhedra or embeds an edge from each polyhedron. 
If a pair of polyhedra are shown not to inter-penetrate by one of these separating planes, we cache the 
face or two edges embedded in the separating plane as a witness. At the next time step, we use the cached 
face or edges to form a new separating plane. In this manner the new separating plane is obtained simply 
from the old one without the need for any numer- ical computations. Even better, by caching the nearest 
face or edge to the separating plane from each polyhedron, disjointness can usually be verified in sublinear 
time (figure 9). If two polyhedra are inter-penetrating, it is almost always the case that either a vertex 
of one polyhedron is inside the other, or an edge of one polyhedron has intersected a face of the other. 
In this case, the inter-penetrating vertex, or intersecting edge and face are cached as a witness to 
the inter-penetration. In subse- 4 Initial techniques such as hierarchical bounding volumes and spatial 
subdivision can be used to limit the number of pairs of primitives considered by this step. This initial 
step also benefits greatly by exploiting coherence. 5Note that convexity is crucial as this argument 
does not hold for concave objects. The collision detection problem for concave objects is a considerably 
more difficult problem than for convex objects. cached ve~ex separating plane '~ Figure 9. Sublinear 
time verification of disjointness based on cached witnesses. quent comparisons, the witness is used to 
quickly check for inter- penetration. When it is necessary to initially find a witness, a sophisticated 
computational geometry algorithm such as Gilbert et al.[8] might be employed. Currently we use exhaustive 
search to initially find a witness; we have found the added expense, amor- tized over the length of the 
simulation, to be negligible. The use of separating planes also makes the contact deter- mination step 
simple. Contact points between a pair of polyhedra separated by a plane P can only occur on the plane 
P. Given the separating plane, the contact points are quickly and efficiently determined by comparing 
only those faces, edges or vertices coin- cident with the separating plane. This determination can itself 
be performed quickly by caching information from the previous time step. For comparing two curved surfaces, 
we must employ numerical techniques to determine disjointness. We make use of the concept of extremal 
points from section 5 in determining dis- jointness. Given two disjoint convex curved surfaces, the extremal 
points are the points of minimum distance and are a wit- ness to the disjointness of the surfaces. Otherwise, 
the extremal points near the intersection of the surfaces are a witness that the surfaces do inter-penetrate 
(figure 6). To find these extremal points, a non-linear equation solver may be used to solve equation 
(9) for Pa and pbr; see Forsythe et al.[7]. However, equation (9) admits multiple solutions of Pa and 
p~,; we are interested in the solution that globally minimizes [[Pa--Pb[] -7 Non-linear equation solvers 
proceed from some initial estimate of the solution to an exact solution (within numerical tolerances). 
If we are initially finding the extremal points between the surfaces, we require some rough estimate 
ofpa and Pb, so that the solver will converge to the proper solution. For implicit surfaces, we can initially 
estimate pa and Pb by intersecting the two surfaces with the line connecting the centroids of the two 
surfaces. For parametric surfaces, we can generate and store a coarse mesh of surface points for each 
sur- face and use the parametric coordinates of the minimum distance pair of points as an initial estimate. 
Using the initial estimate as a starting point, the solver converges to the proper solution of the extremal 
points. Once the extremal points Pa and Pb are determined, they are cached for the next time step. In 
subsequent time steps, the cached extremal points are used as an initial estimate and the solver converges 
in a few iterations to the new extremal points. Furthermore, the accuracy of this initial estimate can 
be significantly improved as follows. If in addition to caching the extremal points Pa and po at time 
t o we cache/~a and/)b, we can estimate Pa and Po at time t o + At by 6For parametrically defined surfaces, 
we replace equation (9) with a non-linear equa- tion that defines the extremal points in terms of parametric 
coordinates; see appendix D for details. 7The points po and Pb that maximizethe distance between the 
surfaces satisfy equa- tion (9), but they are not the solution we are interested in. Parametric surface 
have multiple solutions of equation (56) for po and Pbin terms of their parametric coordi- nates. pa(to 
+ At) =Pa(t0) + Atfia(to) (17) and similarly for Pb. (See appendix D for the parametric case). Improving 
the accuracy of the initial estimates of p~ and Pb adds to the speed and robustness of the algorithm. 
The derivatives of fia(to) and fib(to) can be calculated in terms of determinants of 4 × 4 matrices as 
described in appendix C. Once two curved sur- faces have been found not to inter-penetrate, the contacl 
determi- nation process consists of merely comparing the distance between the extremal points to some 
numerical threshold. Comparisons between a polyhedral primitive and a curved surface primitive are handled 
in an analogous manner to contact between a polyhedron and a curved surface (section 5). 8. Determining 
the Collision Time The last problem in the collision detection phase is back- tracking to the point of 
a collision (step E of figure 1). During a simulation, it may happen that two objects A and B come into 
col- liding contact at some time t c. Suppose that to was the time of the previous time step when the 
objects had not yet collided, and at time t I (t 0<t, <tl) it is found that A and B have inter-penetrated. 
When this occurs, the simulator makes a prediction tp of the time t, at which the initial collision occurred, 
backs up to time to and then moves forward to time t e. If the simulator finds that A and B have not 
yet collided at tp, it assumes that tp < tc and makes a larger prediction for t c. Conversely, if the 
simulator finds that A and B have inter-penetrated at tp, it assumes that t,, < tp, and makes a smaller 
prediction for to. Otherwise, the simulator has found t~ to within numerically accepted tolerances and 
may proceed. Conceptually, this can be viewed as a root finding problem. Previous papers have solved 
this root finding problem by using bisection[13] or regula falsa[1]. The bisection method is extremely 
robust, simple to implement, and independent of geometry; however, it has relatively slow convergence, 
especially where great accuracy is required. The regain falsa method linearly interpolates the distance 
between A and B at to and the amount of inter-penetration at t l to predict t~. The regula falsa method 
handles any geometry as long as measures of separation and inter-penetration are available; additionally, 
the method con- verges faster than bisection, regulafalsa is not as robust as bisec- tion but a hybrid 
bisection-regulafalsa algorithm[7] works well in practice. An alternative to regain falsa is Newton's 
method. Newton's method requires both a measure of separation between A and B at to and the relative 
approach velocity at time to. These quantities however are exactly modeled by X and Z. Newton's method 
for solving h (t) = 0 near the point to is based on the Tay- lor series expansion hC~(to)h(t)=h(to)+ 
~ n! (t-t°)"" (18) n=l By throwing out terms for n > 1 and replacing h with Z, we obtain the linear approximation 
X(t0) t =t o ~(t0 ) . (19) While Newton's method gives better convergence than the regula falsa method, 
both regulafalsa and Newton's method consistently either under-estimate or over-estimate tc for constant 
(non-zero) acceleration. Since constant acceleration occurs frequently, it makes sense to predict t~ 
by using a quadratic model as opposed to the linear model used by Newton's method. The quadratic model 
requires Z, Z and ~; section 5 and appendix C show how X, and ~ are calculated for polyhedral and curved 
objects. Fol-lowing the derivation of Newton's algorithm, we predict t c by ~(t) = Z(t0) + ~(to)(t -to) 
+ (t - to) z. (20) Solving for t we obtain -X (t0) -+ ~ (t0) 2 -2~(to)X(to) t = to + (21) ~(t0) We set 
tp to be the smallest real root of equation (21) greater than t 0; if no such root exists, or ~ (to) 
is zero (within numerical toler- ance), we use Newton's method. The method is made robust by incorporating 
a bisection step whenever convergence is slow[7]. For constant acceleration, equation (21) gives an exact 
result as long as X is a linear measure of the distance. 8 For non-constant acceleration, the quadratic 
model still converges faster than Newton's method, close to t c. 9. Conclusion Table 1 gives a rough 
indication of the running time of two simulations (figures 10 and 11) on a Hewlett Packard 835 work- 
station. A "cache miss" means that a new witness was computed from scratch, while a "cache hit" means 
that a previously cached witness was successfully updated to a witness for the current time step. The 
first simulation had 97 polygons and 6 curved surfaces and encountered 60 discontinuities while time 
stepping. The second simulation had 89 polygons and 102 curved surfaces and encountered 343 discontinuities 
while time stepping. Figure Total No. Cache Cache CPU Time S.tePs Hits M_!sse s Minutes 10. Jack 1,475 
5,243 42 2.1 11. Dice 4,162 345,793 1,384 78.6  Table 1. Running times and caching effectiveness. 
 Acknowledgements This research was funded by an AT&#38;T Bell Laboratories PhD Fellowship and two NSF 
grants (#DCR8203979 and #ASC8715478). Simulations were performed on equipment gen- erously donated by 
the Hewlett Packard Corporation. Some displays were computed using an AT&#38;T Pixel Machine, donated 
by AT&#38;T. Appendix A: Rigid Body Motion of Surfaces The formulation for the constraint function Z 
between curved surfaces models the surfaces as time-varying implicit func- tions F(p,t), F :R 3 xR -->R. 
A point p is on the surface of F at time t if F(p,t)= 0. We will represent the shape F(p,t) in terms 
of a rest function Fr(p) and a rigid body transformation T(p,t). Let Fr(p) be a time-invariant function 
from R 3 to R; Fr defines a rest shape by the equation Fr(p)= 0. Let a rigid body motion be defined by 
the affine transformation T :R 3 x R ~ R 3 by T(p,t) = c (t) + R (t)p (22) where /~(t) is a 3x3 rotation 
matrix and c(t) is a point in R 3. Define T as T(p,t) = Rr(t)(p -c (t)) (23) 8For polyhedral contact, 
Z of equation (3) is a linear measure of distance, and equa- tion (21) converges in one step to t,. for 
constant accelerations. For curved surfaces, of equation (8) is weighted by IIVGII. For reasonably scaled 
functions, IIVGII does notvary much over the range of the prediction. so that T(T(p,t),t) = T(T(p,t),t) 
=p. (24) If the linear and angular velocities of the rigid body motion T at time t are v (t) and co(t) 
then c(t) = v(t), l~(t) = m*(t)R(t) (25) where co*(t) is the dual[3,9] of O(t).9 Define the point-velocity 
function V(p,t) as V(p,t) = v (t) + cO(t) × (12 - c (t)). (26) Then . T = -R (t) r [cO(t)x (p-c (t)) 
+ v (t) 1 = -R (t)rV(p,t). (27) We can represent the movement of Fr by the rigid body motion T(P,t) 
by defining F(p,t) = F~(7"(p,t)). (28) If q is some point on F r then at time t the point T (q,t) is 
a point of F since r(T (q,t),t) = Yr(7"(T(q,t),t)) = rr(q) -- 0. (29) Using the above definitions and 
the relations VF(p,t) = R(t)VFr(T(p,t)) (see appendix B) and Fr 'r = VFr, F(p,t) = Fr (T(p,t))T(p,t) 
= Y/ (T(p,t))(-R (t)*rV (p,t)) ~ T =-IR(t)F~ (T(p,t)) r] V(p,t)=-VF(P,t)'V(p,t). (30) By differentiating 
equation (30) with respect to p and using VV (p,t) = to* (t) VF(p,t) = -F" (p,t)V (p,t) -VF (P,t)" VV 
(p,t) = -F"(p,t)V(p,t) -VV(p,t)r~7F (p,t) = -F"(p,t)V(p,t)- cO*(t)TVF(p,t) (31) = -F"(p,t)V(p,t) + to(t) 
× VF (p,t). Differentiating equation (30) with respect to time,  + (32) S.ince V(P,t) is the point 
velocity of p in its rigid body frame, V(p,t) is the point accelerati.on ofp and is a linear function 
of the forces in the system Thus, F is also a linear function of force. Appendix B: Rotation of Coordinate 
Systems In section 6, the coordinate axes were rotated so that VG(p~,to) would be colinear with ~, the 
unit z axis vector. Let R be the change of basis matrix; R is a rotation matrix such that RVG(pa,to) 
= [[VG(p~,t0)ll~. (33) Note that R is constant with respect to time. Let VGo and G~" be the derivatives 
of G in the original coordinate system. In the rotated coordinate system, the derivatives become VG=RVGo, 
VG=RVG 0 and G "-°rz'°r .... 0,, (34) The derivatives G and G are invariant under rotation See Gold- 
stein[9] for further discussion 9 Given a vector a ~ R 3, a* is the 3×3 (anti-symmetric) matrix such 
that for any vector b ~ RO,a'b =a×b. Appendix C: Derivation of In section 6, a change of functions is 
introduced by writing the implicit functions F and G in terms of explicit functions f and g near the 
extremal points Pa and Pb. This change of functions is made in a coordinate system where both VF(pa,to) 
and VG(pb,t0) are colinear with the z axis. The explicit functions f and g are defined by F(x,y,f(x,y,t),t) 
=0 and G(x,y,g(x,y,t),t) = 0. (35) The existence of f and g is seen by the implicit function theorem. 
By differentiating equation (35) we obtain OF OF OF 0f=_ 0x 0____x_. 0f_ OF' 0y 0z 0y OF Oz and 0f=_ 
0t 3t OF ~z (36) and similarly for g. Second derivatives of f and g are obtained by repeated differentiation 
of equation (35). Using fand g, condition E 4 of equation (9) may be written componentwise as Pby --P~, 
= (37) g(Pb~,Pby,L f(Pa~,Pay,( [_~_(pb,t) A from which we obtain f(Pay 'Par' t) -- g (Pox ,Pb~, t ) 
~1 = (38) 0G 0z (pb,t) Multiplying equation (37) by -1 and using equation (36) allows us to rewrite 
E 4 as " (39)   IPax- p,] [ ~Xg (Pbx'PbY 't) Lpay- PbrJ + (f(Pa~ ,Pay, t) - g (Pb~ ,Pby, t)) ] 0g = 
~" LTy eb,,Pb,,') This new condition has one less equation than E 4 because of the reduction of variables 
from F to f. In a similar fashion, L2 of con- dition E 1 is eliminated and condition E 1 is rewritten 
as Of ,t)" [-~-(Pbx,Pby,t) I.~x (pa~,pay " Og [~YIOf(Pax'P"Y't ) -~y (Pb~'Poy 't) =0~"[ 0g (40) Conditions 
E2 and E 3 are no longer required since f and g give explicit definitions of the surfaces. Using the 
notation ( Of Of .~ r' vF = (41) Pax, P,~, Pb~ and Pb~ may be defined as the solution to fD t: if(P~"Pi 
"'t)- Vg(pb~'pby't)= Pb~ (42)- 21 LPaY-- PbyJ -b if(Pax,Pay ,t)--g(Pb~ ,Pby ,t))Vg(pb~ ,p% ,t) = -~. 
 The implicit function theorem for simultaneous equations gives the result O(D i,D2) c)(D 1,D 2) O( t,p 
ay ,Pbx ,Pb r ) O(P ax ' t,pbx ,Pby ) b~ = j , b,y = j (43) (and similarly for/~b~ and/~by) where O(D 
i,D 2) J = (44) O(Pa~ ,Pa r ,Pbx ,Pby ) " The derivatives of Paz and Pb~ are simply f(Pa~,Pay,t) and 
(Pb, ,Pby, t). Since D 1 and D" 2 do not involve p~ and Pbz, let Pa and Pb denote (only for the remainder 
of this appendix) the column vec- tors (par,pay) r and (pb,,Pbr) T at time t. Similarly, let /)a = ~a~,Jbay)T 
and /~b = ~b,,/~by)T at time t. In section 6, we derived ~(t) = f(p~,t) -g(pb,t). (45) To obtain ~, we 
must doubly differentiate f and g with respect to time. Using the chain rule, ~tf(pa,t) = f'(pa,t)l~a 
+.f(pa,t) = V f(pa,t)rt~a +?(Pad). (46) Then d 2 ,, Vf(pa,t)] rpa + dt 2 f(pa't) = If (P~'t)pa + Vf(pa,t)rpa 
+ f (pa,t)l)a + f(pa,t) (47) T t~, =Pa f (pa,t)p. + 2Vf(pa,t)rba + Vf(pa,t)rpa + f(p.,t). From equation 
(36) and the fact that VF(pa,to) is colinear with the z axis, Vf(pa,to) r = (0, O) r. (48) This yields 
d 2 . r ,, . dt 2 f(pa,to) =Pa f (pa,to)Pa + 2Vf(p~,to)Tt~a + f(Pa,to) (49) A similar expression is 
obtained for g. Thus, neither Pa nor Ph is required for the sym.bolic computation .of ~(t0). Equation 
(49) is a linear function of F by its last term, f(pa,to) which is in turn a linear function of the contact 
forces. Thus, ~(t0) is itself a linear function of the contact forces. Appendix D: Parametrically Defined 
Surfaces Appendix C derived ~ by defining explicit surfaces fand g that modeled the implicit surfaces 
F and G near extremal points was then written in terms of the derivatives of the extremal points and 
the derivatives of f and g; in turn, the derivatives of f and g were expressed in terms of the implicit 
functions F and G. Given two parametric surfaces, S and T, the same thing can be done. We will first 
show how to express the derivatives of f and g in terms of the parametric functions S and T. We will 
then show how the extremal points and their derivatives are defined for parametric functions. This enables 
~ to be computed as shown in appendix C. Let a time-dependent parametric function S(u,v,t), S :R 2 ×R---~R 
3, define a surface. We will write S in terms of three component functions S~, Sy and S~ as S(u,v,t) 
: [Sx(u,v,,), Sy(u,v,t), S~(u,v,t)l r" (50) As in appendix A, S is assumed to be the rigid body motion 
of some time-invariant base shape S 0; S(u,v,t) = R(t)So(u,v) + c(t). (51) Differentiating with respect 
to t, OS . -~-(u,v,t) = co (t)R(t)So(u,v) + v (t) =co*(t)IR(t)So(u,v)+c(t)-c(t) 1 + v(t) (52) = cox IS 
(u,v,t) -c(t) 1 + v(t). Assume that at time to, the surface normal of S at the point S(uo,Vo,to) is colinear 
with the z axis. As in appendix C, we let f(x,y,t) explicitly describe S near S(uo,vo,to). The definition 
off is f(Sx(u,v,t),Sy(U,V,t),t) = Sz(u,v,t). (53) The existence of f follows from the implicit function 
theorem. Differentiating equation (53) with respect to u, v, and t, we obtain the system Of 3Sx by OSy 
OSz Ox Ou Oy Ou ~u Of ~Sx ~f aSy ~S z --+ = (54) Ox Ov ~y Ov Ov Of OSx Of ~S r ~f OSz --q --+ Ox Ot ~y 
Ot Ot 3t Thus, the first partials of f may be expressed in terms of partial derivatives of the parametric 
function S by solving a simple linear system. The second partials of f are obtained by differentiating 
the system of equations (54) and solving another linear system. A normal veetor Su(uo.vo,to) to S(uo.Vo,to) 
at time to is given by ~s ~s SN(Uo,Vo,to) = ~u (UO,Vo,to)×'~-(Uo,Vo,to). (55) Suppose that T(u,v,t) is 
the parametric function for a second sur- face, with T~ defined accordingly. Let the parametric coordinates 
of the extremal points p, and Pb (where Pa is on S and Pb is on T) be (u~,va) and (Ub,Vo). The analogue 
to equation (9) is then El: SN(Ua,v,,t) + ~.2TN(Ub,Vb,t) = 0 ~ E2: (T(Ub,Vb,t) -- S(ua,Va,t)) + ~qTN(Ub,Vb,t) 
= 0 ~, (56) AS in section 5, we may regard u~,v~,ub and vb as functions of time; derivatives are then 
given by O(E1,E2) ~(E1,E2) t~(t, Va,Ub,Vb) O(Ua,t, Ub,Vb) ha= , Va= (57) J J (and similarly for ub and/'b) 
where O(Ei,Ez) J -(58) ~(Ua,Va,Ub,Vb)" Given the derivatives of the parametric coordinates of the extremal 
points, we can calculate the needed derivatives of Pax, Pay, Pbx and Pby (for equation (49)) From equation 
(50) and since Pa = S(u~,va,t), bS~(u~,va,t) . OSx(uo,va,t) . bSx(ua,v.,t) l)a~ -Ou ua + Ov v~ + bt (59) 
and similarly for/~y ,/~b~ and/~by. For contact determination, equation (56) is solved (in place of equation 
(9)) to find (u~,va) and (Ub,Vb). The extremal points p~ and Po are then cached in terms of their parametric 
coordinates   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97882</article_id>
		<sort_key>29</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Dynamic simulation of autonomous legged locomotion]]></title>
		<page_from>29</page_from>
		<page_to>38</page_to>
		<doi_number>10.1145/97879.97882</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97882</url>
		<abstract>
			<par><![CDATA[Accurate simulation of Newtonian mechanics is essential for simulating realistic motion of joined figures. Dynamic simulation requires, however, a large amount of computation when compared to kinematic methods, and the control of dynamic figures can be quite complex. We have implemented an efficient forward dynamic simulation algorithm for articulated figures which has a computational complexity linear in the number of joints. In addition, we present a strategy for the coordination of the locomotion of a six-legged figure - a simulated insect - which has two main components: a gait controller which sequences stepping, and motor programs which control motions of the figure by the application of forces. The simulation is capable of generating gait patterns and walking phenomena observed in nature, and our simulated insect can negotiate planar and uneven terrain in a realistic manner. The motor program techniques should be generally applicable to other control problems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39080285</person_id>
				<author_profile_id><![CDATA[81100074245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McKenna]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics and Animation Group, The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032919</person_id>
				<author_profile_id><![CDATA[81100216523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeltzer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics and Animation Group, The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Kugler, P, N., J. A. S. Kelso and M. T. Turvey. On the Concept of Coordinative Structures as Dissipative Structures: I. Theoretical Line. Tutorials in Motor Behavior. Amsterdam, North-Holland (1980).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Featherstone, R. The Calculation of Robot Dynamics Using Articulated-Body Inertias. Robotics Research 2,1 (1983), 13-29.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>576516</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Featherstone, R. Robot Dynamics Algorithms. Kluwer Academic Publishers (1987).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sehrtder, P. The Virtual Erector Set, Master's Thesis, Massachusetts Institute of Teclmology (1990).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Barzel, R. and A. H. Barr. Controlling Rigid Bodies with Dynamic Constraints. ACM SIGGRAPH '88 Course Notes #27: Developments in Physically-Based Modeling, Section E (1988).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Isaacs, P. M. and M. F. Cohen. Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics. Computer Graphics 21,4 (July 1987), 215-224.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Barzel, R. and A. H. Bart. A Modeling System Based on Dynamic Constraints. Proceedings of SIGGRAPH '88 (Atlanta, Georgia, August 1988) In Computer Graphics 22,4 (August 1988), 179-188.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91403</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Sehrtder, P. and D. Zeltzer. The Virtual Erector Set: Dynamic Simulation with Linear Reeursive Constraint Propagation. Proceedings of the 1990 Symposium on Interactive 3D Graphics (Snowbird, Utah, March 1990). In Computer Graphics 24, 2 (1990), 23-31.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Witkin, A. and M. Kass. Spacetlme Constraints. Proceedings of SIGGRAPH '88 (Atlanta, Georgia, August 1988) In Computer Graphics 22,4 (August 1988), 159-168.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Walker, M. W. and D. E. Orin. Efficient dynamic computer simulation of robotic mechanisms. Proceedings of Joint Automatic Contr. Conf. (Charlottesville, VA, 1981).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J. Using Dynamic Analysis for Realistic Animation of Articulated Bodies. IEEE Computer Graphics and Applications 7,6 (June 1997), 12-27.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W. W. Reeursive solution to the equations of motion of an n-link manipulator. Proceedings of 5th World Congress Theory Mach. Mechanisms (Montreal, 1979) Volume 2, 1343-1346.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31466</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W. W., M, Green and R. Lake. Near-Real- Time Control of Human Figure Models. IEEE Computer Graphics and Applications 7,6 (June 1987), 52-61.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Lathrop, R. H. Constrained (Closed-Loop) Robot Simulation By Local Constraint Propagation. Proceedings of 1986 IEEE Int. Conf. on Robotics and Automation (San Francisco, 1986) Volume 2, 689-694.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Zeltzer, D., S. Pieper and D. Sturman. Art Integrated Graphical Simulation Platform. Proceedings of Graphics Interface 89 (London, Ontario, 1989), 266-274.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Zeltzer, D. Towards an Integrated View of 3-D Computer Animation. The Visual Computer 1,4 (December 1985), 249-259.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Muybridge, E. The Human Figure in Motion. New York, Dover (1955).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Muybridge, E. Animals in Motion. New York, Dover (1957).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Hildebrand, M. Analysis of Tetrapod Gaits: General Considerations and Symmetrical Gaits. Neural Control of Locomotion. New York, Plenum Press (1976).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Gallistel, C. R. The Organization of Action: A New Synthesis. Hillsdale, New Jersey, Lawrence Erlbaum Associates (1980).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Gelfand, I. M., V. S. Gurfinkel, M. L. Tsetlin and M. L. Shik. Models of the Structural-Functional Organization of Certain Biological Systems. Cambridge, M1T Press (1971).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[GriUner, S. Locomotion in Vertebrates: Central Mechanisms and Reflex Interaction. Physiological Reviews 55,2 (April 1975),]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Pearson, K. The Control of Walking. Scientific American 235,6 (December 1976), 72-86.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Bizzi, E. Central and peripheral mechanisms in motor control. Tutorials in Motor Behavior. North-Holland Publishing Co. (1980).]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Robertson, M. A, and L. E. Halverson. The Development of Locomotor Coordination: Longitudinal Change and Invariance. Journal of Motor Behavior 20,3 (1988), 197- 241.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Beer, R. D., L. S. Sterling and H. J. Chiel. Periplaneta Computatrix: The Artificial Insect Project. Case Western Reserve University. Technical Report, TR 89-102. (January 1989).]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Chiel, H. J. and R. D. Beer. A lesion study of a heterogeneous artificial neural network for hexapod locomotion. Case Western Reserve University. Technical Report TR-108. (February 1988).]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[McGhee, R. B. Robot Locomotion. Neural Control of Locomotion. New York, Plenum Press (1976).]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Raibert, M. H. and I. E. Sutherland. Machines That Walk. Scientific American 248,1 (january 1983), 44-53.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>911492</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Donner, M. D. Control of Walking: Local control and real time systen~. Phi) Thesis, Carnegie-Mellon University. (1984).]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6152</ref_obj_id>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Raibert, M. H. Legged Robots That Balance. Cambridge, MA, MIT Press (1986).]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>575977</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Song, S. and K. J. Waldron. Machines That Walk: The Adaptive Suspension Vehicle. Cambridge, MA, MIT Press (1989).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Zeltzer, D. Motor Control Techniques for Figure Animation. IEEE Computer Graphics and Applications 2,9 (November 1982), 53-59.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Girard, M. and A. A. Maciejewski. Computational Modeling for the Computer AnJmatiort of Legged Figures. Computer Graphics 19,3 (July 1985), 263-270.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Sims, K. Locomotion of Jointed Figures over Complex Terrain, M.S.V.S Thesis,Massachusetts Institute of Technology. (June 1987).]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74357</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Bruderlin, A. and T. W. Calvert. Goal-Directed, Dynamic Animation of Human Walking. Proceedings of SIGGRAPH '89 (Boston, Massachusetts, July 1989) In Computer Graphics 23,3 (July 1989), 233-242.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Ball, R. S. A treatise on the theory of screws. London, Cambridge Univ. Press (1900).]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[McKerma, M. A. A Dynamic Model of Locomotion for Computer Animation. Master's Thesis, Massachusetts Institute of Technology. (1990).]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578659</ref_obj_id>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Forsythe, G. E., M. A. Malcolm and C. B. Moler. Computer Methods for Mathematical Computations. New Jersey, Prentice-Hall, Inc. (1977).]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Moore, M. and J. Wilhelms. Collision Detection and Response for Computer Animation. Proceedings of SIGGRAPH '88 (Atlanta, Georgia, August 1988) in Computer Graphics 22,4 (August 1988), 289-288.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Wilson, D. M. Insect Walking. Annual Review of Entomology 11 (1966), 162-169.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Pearson, K. G. and R. Franklin. Characteristics of Leg Movements and Patterns of Coordination in Locusts Walking on Rough Terrain. The International Journal of Robotics Research 3,2 (1984), 101-112.]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[McMahon, T. A. Muscles, Reflexes, and Locomotion. Princeton University Press (1984).]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Bizzi, E., W. Chapple and N. Hogan. Mechanical Properties of Muscle: Implications for Motor Control. Trends in Neuroscience (November 1982).]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Hogan, N. The Mechanics of Multi-Joint Posture and Movement Control. Biological Cybernetics 52 (1985), 315-331.]]></ref_text>
				<ref_id>45</ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Wigglesworth, V. B. The Principles of Insect Physiology. London, Chapman and Hall.]]></ref_text>
				<ref_id>46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Hughes, G. M. and P. J. Mill. Locomotion: Terrestrial. The Physiology of lnsecta. New York and London, Academic Press (1974).]]></ref_text>
				<ref_id>47</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91441</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[McKenna, M., S. Pieper and D. Zeltzer. Control of Virtual Actor: The Roach. Proceedings of 1990 Symposium on Interactive 3D Graphics (Snowbird, Utah, 1990) In Computer Graphics 24,2 (1990), 165-174.]]></ref_text>
				<ref_id>48</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Dynamic Simulation of Autonomous Legged Locomotion Michael McKenna and David Zeltzer Computer Graphics 
and Animation Group The Media Laboratory Massachusetts Institute of Technology Cambridge, MA ABSTRACT 
Accurate simulation of Newtonian mechanics is essential for simulating realistic motion of jointed figures. 
Dynamic simulation requires, however, a large amount of computation when compared to kinematic methods, 
and the control of dynamic figures can be quite complex. We have implemented an efficient forward dynamic 
simulation algorithm for articulated figures which has a computational complexity linear in the number 
of joints. In addition, we present a strategy for the coordination of the locomotion of a six-legged 
figure - a simulated insect -which has two main components: a gait controller which sequences stepping, 
and motor programs which control motions of the figure by the application of forces. The simulation is 
capable of generating gait patterns and walking phenomena observed in nature, and our simulated insect 
can negotiate planar and uneven terrain in a realistic manner. The motor program techniques should be 
generally applicable to other control problems. 1. COORDINATING AND CONTROLLING JOINTED FIGURE MOTION 
 Realistic modeling and animation of human and animal figures has long been a goal of researchers in 
computer graphics. There are two aspects to the synthesis of motor behavior [1]: The Coordination problem. 
How do we organize the movements of a complicated figure into coherent, useful motions? In other words, 
given a jointed figure with many degrees of freedom (DOFs), how do we decide which DOFs are needed to 
perform a given motion, and how do these movements vary with respect to each other?  The Control problem. 
Given a set of DOFs, Emd appropriate time-varying parameters for each DOF necessary to effect a given 
motion.  In this paper we will describe approaches to both problems. We use physically-based methods 
with dynamic motor control This work was" supported in part by National Science Foundation Grant IRI-8712772, 
and equipment grants from Hewlettopackard Co., Gould Electronics, Inc., and Apple Computer, Inc. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. to generate 
realistic movements, and we use biologically-based mechanisms to coordinate complex patterns of movement. 
In particular, we have implemented a dynamics simulation algorithm based on the work of Featherstone 
[2; 3], which is more efficient than dynamic simulation algorithms previously reported in the computer 
graphics literature. We use this algorithm to compute the movements of a six-legged virtual insect. Based 
on results from ethology and physiology, we coordinate its adaptive gait over planar and uneven terrain 
using coupled-oscillators, reflexes and a set of motor programs which apply controlling forces. In the 
next section, we discuss related work. In Section 3 we describe the major components of our dynamic locomotion 
simulator. We conclude with a discussion of results we have obtained so far. 2. RELATED WORK 2.1. Dynamics, 
Forward and Key-Event Simulation Rigid-body simulators compute the motion of articulated figures comprised 
of rigid links connected by joints, which can move relative to each other with one or more DOFs. Constraint-based 
approaches define the relationships among the links, and then solve for the forces required to maintain 
the prescribed connections. These methods are typically computationally more expensive and numerically 
less stable than non-constraint-based techniques [4; 5]. Isaacs and Cohen describe a straightforward 
method of constraint simulation based on a matrix forrnulation[6]. Joints are configured as kinematic 
constraints, and either accelerations or forces cart be specified for the links. An equation is established 
for each DOF, yielding n simultaneous equations to solve, giving O(n J) complexity. Interdependencies 
among the constraints typically make the matrix non-sparse, so that sparse matrix solutions cannot be 
employed to reduce the complexity. Control is applied through the kinematic constraints and user-defined 
"behavior functions," which specify accelerations or forces over time. Arbitrary motions can be specified, 
however, which have no physical basis. Barzel and Barr describe constraint-based simulators which allow 
for the "self-assembly" of linkage structures by satisfying constraint equations using a critically damped 
function [71. Their mcthod is of order O(n -~) computational complexity, where n is the number of constraints. 
This can be reduced to approximately O(n 2) ushag a sparse matrix solution [s]. @1990 ACM-0.-89791 - 
344-2/90/008/0029 $00.75 29  O SIGGRAPH '90, Dallas, August 6-10, 1990 Witkin and Kass describe spacetime 
constraints in which the constraint equations are solved not ordy for the joint/link geometry, but also 
for the applied control forces [91. Since the copAtraint equations are solved simultaneously for the 
entire time span of the simulation, energy (or some other function) can be minimized over all of time, 
though at a large computational cost. Like other constraint methods, forces that are not physically realizable 
may be produced to satisfy the constraints. Optimization techniques, such as spacetime con- straints, 
con~ast sharply with forward dynamic simulators, which require active force control to produce motion, 
thus encouraging the development of coordination strategies. The non-constraint methods fall into two 
main categories: ones that form and solve a set of simultaneous equations for the ac~lerations, and ones 
that form a re.cursive relationship propagating force and movement information through the linkage, solving 
directly for accelerations. The first type of formulation typically yields O(n ~) complexity, because 
solving the n sirnukaneous equations requires a matrix inversion. The recursive formulations, however, 
can reach O(n) complexity, although they can be more difficult to develop, and the cost of the computations 
per link is higher than the simultaneous equation methods. Articulated figures with few joints are less 
expensive to compute using simultaneous equations; figures with many joints are more efficiently computed 
using the reeursive methods. The Walker-Orin method is the most efficient of the simultaneous methods 
[10], and Featherstone's Articulated Body Method (ABM) is the most efficient of the recursive methods 
[31. When n > = 9, Featherstone's method is more efficient than the Walker-Orin algorithm. Wilhelms describes 
a dynamics simulator based on the Gibbs- Appell formulation [11]. She and her co-workers note that while 
dynamic simulation can produce realistic motion, it does not simplify coordination and control since 
it requires the specification of joint torques, rather than joint angles, without providing a means for 
determining the proper torques to apply. Because of this, they have devdoped an interactive., graphical 
editor, Virya, to allow the user to iteratively develop functions for useful force control. Armstrong 
has developed a recursive dynamic formulation, which has approximately the same computational efficiency 
as the ABM [12]. Armstrong, et al, have experimented with this method to simulate a moving human figure 
in near-real time [13]. However, the Armstrong method is only capable of efficiently simulating spherical 
joints, unlike the ABM which allows fully general joint types. Another efficient recurslve method has 
been formulated by Lathrop [14]. The advantage of Lathrop's method over Featherstone's is that it allows 
for kinematic constraints at the end-effectors. Lathrop's method can also be extended to handle kinematic 
loops [s]. Here we would like to distinguish between two simulation paradigms. Optimization and constraint 
techniques can be termed key-event simulation, because specific events must be satisfied. This is in 
contrast to forward simulation in which a system is established, and then simulated forward in time [15]. 
Controlling techniques for key-event simulation require global knowledge about the system, sometimes 
over the entire time span of the simulation. Forward simulation controllers, however, need only partial 
knowledge of the world, perhaps derived from a simulated sensor. The more sophisticated the controller, 
the more knowledge of the world it will require. External influences, such as interactive input, can 
be easily incorporated into a forward simulation at any point in time, unlike methods such as spacetime 
constraints, which must be solved over the entire span of time. In general, when it has been addressed 
at all, the coordination problem has been approached in two ways. Either interactive means are provided 
for the user to iteratively devdop functions of time-varying forces, or mechanisms have been developed 
for defining and satisfying motion constraints. Interactive coordination methods are inadequate for all 
but the simplest motions, because complex, adaptive behavior is simply not amenable to "hands-on" control 
[16]. 2.2. Human and Animal Motor Behavior Natural gait has been the focus of much research for many 
years. Muybridge [17;15], Hildebrand [19], and others have cataloged and analyzed the stepping patterns 
of the legs during different mammalian gaits, such as galloping, cantering, trotting, etc. An analysis 
of insect and vertebrate locomotion indicates a hierarchical arrangement of simple control mechanisms 
which control stepping and stance [2o] 121] [22] [23]. Our computational model of gait is based on these 
hypothesized biological mechanisms. Bizzi, et al, analyze the mechanical properties of the musculo- skeletal 
system and argue that motion is controlled by tuning the spring-like properties of muscles during movement 
[24]. Theoretical and clinical studies by Kugler, et al, and by Robertson and Halverson, including studies 
of human locomotion, have examined the notion that coordinated motion arises more from the mechanical 
constraints on the physical system than from central motor programs [1; 25]. We use the notion of tuned 
springs as a mechanism for controlling joint motion, as we describe in Section 3.3. Beer, et al, employ 
a heterogeneous neural network to simulate the stepping patterns exhibited by the cockroach [26; 27]. 
Their work is intended primarily for the detailed study of the neural mechanisms of motor control, and 
provides ordy limited, 2D graphical output. 2.3. Walking Machines Robeties research has resulted in fundamental 
algorithms for dynamic simulation and ccontrol, though in general, simulated articulated models in computer 
graphics have more kinematic DOFs than robot devices. MeGhee developed an autonomous 6-legged robot vehicle 
which could employ a number of gaits to negotiate rough terrain with areas marked as forbidden [28]. 
Another hexapod vehicle was later developed by Sutherland; its gait control system is similar to the 
one presented here [29; 30]. Legged robots designed by Raibert employ dynamic balance -i.e., they can 
run and hop without enough legs always on the ground to statically support the body [31]. McGhee and 
his tee- workers have developed mathematical tools for analyzing multi-legged gait, and they use these 
tools for designing gait control algorithms for a very large six-legged vehicle [32]. 2.4. Graphical 
Simulation of Gait Computer animation and simulation of animal locomotion has involved primarily kinematic 
ceontrol. Zeltzer describes the use of finite state control to simulate adaptive human walking over planar 
and uneven terrain [331. Girard reports the use of inverse- kinematics to interactively define gaits 
for legged animals [34]. Girard's gait sequencer is based on McGhee's analytical gait descriptions, so 
that gait changes are induced by explicitly varying the gait parameters -unlike our model, as we will 
show, in which smooth gait changes result naturally from variations in the overall gait frequency. Girard's 
model also incorporates some dynamic elements for added realism. However, the overall motion does not 
have a dynamic basis. Sims also employs inverse kinematics and dynamic elements, to simulate various 
adaptive gaits over uneven terrain [35]. Sims' gait sequencer is also based on McGhec's analytical gait 
description. Recently, Bruderlin has implemented a hybrid system in which limited dynamics and specialized 
knowledge about the kinematics of biped gait are applied to simulate human walking [3~]. Our system, 
unlike any of these, makes use of a general-purpose rigid-body dynamics module, as well as a gait controller 
based on biological mechanisms. 3. A DYNAMIC LOCOMOTION SIMULATOR: CORPUS Corpus is a system for simulating 
the forward dynamics of articulated figures, with gait control mechanisms, force-producing motor programs 
and rendering support 1. Corpus is implemented in C, and uses several support libraries, also implemented 
in C. There are three main procedural components (see Figure 1): a dynamic simulator, a gait controller 
and motor programs. In addition, a structural description specifies the mechanical and geomelrical parameters 
of the hexapod. A scripting language is provided for defining jointed figures, and for controlling each 
of these components. Dynamic simulation using Featherstene's Articulated Body Method, forms the foundation 
of the system. The gait contrdler, based on the coupled oscillator model with reflexive feedback, coordinates 
the sequences of stepping and stance for the hexapod. The motor programs, based on exponential spring 
and damper combinations, generate the forces required for stepping and stance. The structural component 
contains descriptions of the kinematic structureof the links and joints, the mass and inertia of the 
links, the gait and motor program parameters, and finally, the graphic parameters necessary for rendering 
the component objects. The graphics system is not directly involved in the creation of locomotion, but 
is required for display and animation of the simulation. 3.1. The Dynamics Simulator Our implementation 
of the Featherstone ABM algorithm is generalized and can compute the dynamics of any articulated figure 
with rigid links arranged in a branching structure, without intemal closed loops (loops may be approximated 
using spring closure forces). Joints may be rotary, prismatic, or screw, and multiple-DOF joints, combining 
these types, may be represented. We chose the Featherstone algorithm because it is an accurate and efficient 
recursive formulation for forward simulation, and because it can accommodate a variety of joint types. 
The algorithm is formulated in spatial notation -developed by Featherstone and based on screw calculus 
[37] -which essentially unites the rotational and translational aspects of motion into a single vector 
quantity. A complete treatment of spatial notation and the ABM algorithm is beyond the scope of this 
paper. The interested reader is directed to the work of 1. A "corpus" is the body of a man or animal 
(Webster's 7th), and thus the articulated-figure simulator, corpus is so-named. ] High level control: 
setsl speed, gait parameters I Controller Programs Simulator ~ Roach Description: ? ~ "TffFositions~ 
/ gait parameters A JJ motor parameters' ~ / / Graphics : kinematic strue.~e~ llnk mass, inertia-~ ~ 
System graphical objects f I Figure 1: Block diagram showing the procedural and structural components 
of the corpus system. Featherstone, and for discussions of spatial algebra, the ABM algorithm, as well 
as a more detailed discussion of implementation and numerical issues, the reader is referred to McKenna 
[38]. The key feature of the Articulated Body Method is the concept of the articulated body inertia. 
Just as the inertia tensor of a rigid body determines its acceleration when the applied force is known, 
the articulated body inertia tensor of a rigid body, within an articulated figure, determines the acceleration 
when the applied force is known. Formally, the equation of motion for an unconstrained rigid body is: 
= p Eq.l  where f is the applied force, I is the inertia tensor, ~ is the acceleration and ~v is the 
bias force (centripetal and Coriolis) produced by the body's velocity. The "hat" (A) denotes quantities 
expressed in spatial notation. The equation of motion for a rigid body in an articulated figure reads: 
~= ~A ~+~ Eq. 2 where ~A is the articulated body inertia tensor, andp is the bias force which incorporates 
the ~v from above, as well as joint reaction forces. The articulated body inertia ~A gives directional 
properties to the apparent mass of a body. Briefly, the algorithm progresses as follows: first the algorithm 
passes from the leaf bodies of the figure tree inward to the root body, accumulating the articulated 
body inertias ~A and bias forces p. Then Eq. 2 is used to compute the acceleration of the root body as 
in: ~= (p)-l(~. ~) Eq. 3 Finally, the algorithm passes from the root out to the leaves computing the 
accelerations of the joints. External forces and joint forces are specified before the dynamics algorithm 
begins; force generators include gravity, collisions, motor program springs, joint dampers, and spring 
connections to other fixed and moving bodies. Once the accelerations have been computed by the dynamics 
algorithms, they must be numerically integrated to compute velocities and positions; corpus uses fifth 
order, adaptive Runge-Kutta [39]. Because zhe integrator must be able to back up in time in order to 
adapt to less stable conditions, the integrator structure was modified to support the storage of certain 
time-varying state information which must be passed to the dynamics algorithm. The dynamics code in corpus 
is a straightforward implementation of the ABM, computed in body-local rather than world coordinates. 
This allows for some optimizations, provides more intuitive values for certain spatial quantities, and 
improves the accuracy of the integration. Collision and contact in corpus is handled through spring forc- 
es. When a collision is detected between two bodies, forces are applied to each body as a function of 
penetration depth in the direction of the collision normal. Linear or exponential spring functions can 
be used to create the forces; exponential springs are typically employed because deep penetration is 
strongly re- sisted by the exponential rise in force. Damping, a force pro- portional to the penetration 
velocity in the direction to oppose that velocity, earl be specified to create energy loss during col- 
lisions. However, energy loss is more directly modeled in corpus using the coefficient of restitution, 
8, as in [40]. The co- efficient describes the.elastic properties of the collision and normally ranges 
from 0 (complete energy loss) to 1 (complete- ly elastic collision). The calculated collision force is 
sealed by the coefficient when the colliding bodies are moving away from each other, yet are still interpenetrating. 
Friction is modeled in corpus by applying a force equal to the collision normal force, scaled by the 
coefficient of friction, in the direction opposed to the tangential sliding motion. Collision detection 
is handled in several ways in corpus. The most basic method detects interpenetration of body bounding 
boxes. The simple geometry allows for rapid execution when only rectangular solids are employed (as with 
level terrain and the roach model). Another rapid method detects bounding box penetration against a height 
field, suitable for detection of colIisions of the roach model with uneven terrains. Finally, a generai 
algorithm is available for detection of interpenetration of arbitrarily shaped objects. 3.2. The Gait 
Controller In order to move from place to place, an animal must coordinate its limbs to bring about coherent 
motion. Legs are alternately controlled between step and stance. Stepping brings the leg up and forward, 
while stance supports the body and drives it forward. The overall sequence of the various legs stepping 
and standing is termed the gait. Wilson analyzed the stepping patterns cockroaches exhibited under a 
variety of conditions, and proposed five rules which describe the gait behavior of many insects [41l: 
1) A wave of steps runs from rear to head (and no leg steps until the one behind is placed in a supporting 
position). 2) Adjacent legs across the body alternate in phase. 3) Stepping time is constant. 4) The 
frequency with which each legs steps varies. 5) The interval between steps of adjacent legs on the same 
side of the body is constant, and the interval between the stepping of the foreleg and hindleg varies 
inversely with the stepping frequency. Wilson made hypotheses about the neurological mechanisms which 
could generate these rules, and his ideas were conflrrned by the experimental work of Pearson [23]. Each 
leg in the cockroach has a pacemaker or oscillator, which rhythmically triggers the leg to step. The 
oscillators are coupled together, and their interaction generates the various gaits. In addition to the 
coupled oscillators, reflexes also play an important role in gait generation. Reflexes can both trigger 
or retard the stepping of limbs. In nature, the cockroach step reflex causes a leg to step when hair 
receptors detect that the leg has nearly reached its maximum rearward extension. An- other cockroach 
reflex employs cuticle stress-receptors, which measure the load that a leg is bearing, and prevents a 
leg from stepping if it is supporting the insect. In general, reflexes reinforce the stepping pattern 
generated by the coupled oscillators, while increasing the adaptability of the creature under changing 
environmental conditions. Reflexes seem to play an even more important role during locomotion over uneven 
terrain. A study by Pearson of locusts walking over uneven terrain shows that a fixed stepping pattern 
is not employed over rough terrain [42]. To find suitable footholds, the legs employ searching tactics, 
and an elevator reflex causes the leg to lift higher if it encounters an obstacle during a stepping movement. 
In corpus, each leg is assigned an oscillator, which periodically triggers stepping activity (see Figure 
2a). The coupling between oscillators is modeled as phase and time rdationships which the oscillators 
maintain among each other. These relationships are mathematical translations of the stepping rules observed 
in/.he cockroach by Wilson [411. The oscillators are constrained to match a master frequency, such that 
the coupling rules generate differing gaits and walking speeds as the master oscillator frequency is 
varied. At slow oscillator frequencies, slow wave gaits are generated. As the oscillator frequencies 
increase, faster wave gaits result until finally the tripod gait is generated. As the oscillator frequencies 
smoothly change, a smooth gait change is effected. Reflexes are modeled as conditional units (see Figure 
2b). When a certain condition is met, the reflex can inhibit or trigger different actions. For example, 
the step reflex triggers stepping when a leg is extended beyond a specified angle, which prevents over-extension 
of the legs. A load bearing reflex inhibits stepping if a leg is currently bearing too much weight. This 
prevents the hexapod from lifting a leg while it is supporting the body. The oscillators and reflexes 
trigger the stepping motor programs for the legs. Once stepping is initiated, it continues to completion 
and stance begins again. The gait controller only generates the pattern of stepping, and is not directly 
responsible for the movements of the legs or body. However, the movements of the legs, due to the motor 
programs and dynamic simulation, provide feedback into the gait controller through the reflexes. 3.3. 
Motor Programs The dynamic motor programs are responsible for delivering forces, through the joints of 
the hexapod, to create the movements required for locomotion. There are two motor programs: step and 
stance. The stepping program must compute the forces necessary to lift the leg up and forward, and place 
it in a position to take up the load of the body when stance begins. The stance program supplies the 
forces needed oscillators master~ ~ _____~upling oseilla .... rules thorax abdomen Figure 2a: The coupled 
oscillator configuration to support the body via the legs, and propel it forward. Stepping programs 
are triggered by the gait controller, as described above. Stance programs automatically begin when stepping 
has completed. In biological systems, the basic producer of bio-mechanical forces is the muscle. McMahon 
[43] contains an excellent review of the force-producing properties of muscle, under varying types of 
stimulation and external influences. Starting with the assumption that muscles are tunable, spring-like 
force generators, motor control researchers have come up with an equilibrium-point hypothesis to explain 
how controlled movements are produced [24; ,14]. This model treats the muscle, along with its feedback 
system, as a single, tunable unit, with measurable, spring-like properties. Postures are controlled by 
establishing an equilibrium between agonist and antagonist muscle groups. This equilibrium configuration 
forms a point (in a controlling space) which can be specified by the neuromuscular system. The equilibrium-point 
hypothesis states that movements are produced by changing the equilibrium point from one posture to another. 
Hogan describes a virtual trajectory of equilibrium points which control movements [45l. The dynamic 
motor programs in corpus create forces by using exponential springs. As their name implies, these springs 
have an exponential relationship between the displacement, x, of the spring from its rest position (or 
angle) and the force generated, f, such that: f=(x(el3 IXl_l) where a controls linear strength, and fl 
controls exponential rise. The exponential response creates a steep potential well; with a large displacement, 
the force becomes extremely high. The fl parameter controls the width of the well, and the a pa-rameter 
controls how fast a well of a given width will linearly rise. When an exponential spring is used for 
position control, the DOF it controls will very likely stay within the lower parts of the well, since 
the forces grow so large outside of the lower region. A motor program controls the rest position (or 
angle) of an exponential spring over time, which causes the force potential- well to travel along the 
DOF, "dragging" the controlled limb along with it. The rest position is modified using a linear coupling 
to other oscillators  tep gger \ i i leg angle sensor, step reflex: activates step '\ I load bearing 
sensor ....ib.~teP "~trigger coupling to other oscillatory leg angle sensor ] load bearing sensor, I 
load reflex: i: inhibits stepping Figure 2b: reflex feedback to the oscillators interpolation from the 
current position to the target position. In more physical terms, the rest position travels with a constant 
velocity to the target. This is basically open-loop control, which is appropriate for so-called patterned 
gaits, but inappropriate for free gaits -in which safe footholds must be found - or other movements which 
require positional accuracy, such as reaching and grasping. The potential wells created by the springs 
lead to a compliant system, which allows the final motion to fall within a range of possible motions. 
For example, to negotiate uneven terrain, a kinematic system would need to compute the leg joint angles 
required to place the feet on the varying heights of the terrain surface. Using a dynamic, compliant 
system however, the legs of our simulated insect can automatically conform to the terrain (see Figures 
6 and 8). A disadvantage of using exponential springs is that they can create a stiff system. As the 
force response of the springs is pushed further and further up the steep walls of the potential well, 
the numerical sampling of the integrator must take smaller and smaller time steps to get an accurate 
result. Linear springs would not create such a stiff system for a given force output, but exponential 
springs have the advantage that at small displacements, they are less stiff than linear springs. In addition, 
linear springs need to be very strong to create similar forces to the exponential springs at large displacements. 
3.4. Structural Description The kinematic structure of the hexapod was derived from insect physiology 
references [46]. Diagrams of the insect Blatta were used to parametrize the sizes of the limb parts of 
the hexapod[47]. A reproduction of one of the diagrams, along with a view of the resulting articulated, 
solid model is shown in Figure 3. The lengths and widths of the limb parts were measured, and a rectangular 
solid was constructed to represent each part. No further refinement in the shape of the limb and body 
parts beyond the rectangular solid was attempted; our study focuses instead on the basic motions and 
physical parameters involved in locomotion. FL ML ~FL ~FR BL =FR MR ~omputer model stepping pattern 
aa BI.., MR BL SR cockroach stepping pattern time > Figure 4: The coupled oscillators produce a wave 
gait at low oscillator frequencies. The activity of the oscillator model is shown to the left. When an 
oscillator reaches its peak, its leg is triggered to step, indicated by a dotted box. The stepping pattern 
of both the computer model and the biological cock- roach are shown to the right. White indicates step, 
and black stance. The cockroach stepping pattern, adapted from Pearson [23], depicts a slightly faster 
walking speed than the computer model stepping pattern. The overall scaling of the roach gives it a 
total length of approximately 2.9 era. The density of the body and llmb parts was set to the density 
of water, 1 grn/cm 3, since animal tissues in general are composed mostly of water. The total mass of 
the hexapod is 2.1 gin. A set of control parameters determine the basic gait features and the motor program 
parameters. Constant gait features are the stepping speed, the time between stepping of adjacent legs 
on the same side of the body, the number of legs and default values for other parameters such as oscillator 
frequency. The motor programs for step and stance clef'me what joint angles are traversed by the exponential 
springs during those actions. These programs are tuned via a trial-and-error method to determine appropriate 
spring strengths and joint angle values. In general, this trial-and-error approach is not the appropriate 
method to determine the operating dynamic parameters, since it requires an "expert" tuner to make "educated" 
guesses as to the parameters, based on the experience gained from previous experiments. In some sense, 
the expert tuner acts as natural selection in an "evolutionary" process which increases the robustness 
of the locomotion. An alternative to the manual tuning process would be to employ automatic calibration. 
The operating parameters for the motor programs could be deter- mined by an inverse dynamics or constrained 
optimization technique in a calibration phase before the primary simulation. Alternately, an automatic 
evolutionary process could be em-ployed in which successive, random changes are made to the motor program 
parameters (as well as other structural descrip- lions). The resulting simulations would be evaluated 
using measurement criteria, such as waiking speed, distance covered, and energy expended. 4. RESULTS 
AND ANALYSIS 4.1. The Gait Controller The computational model of the coupled oscillators produce stepping 
patterns which appear very similar to the recorded patterns of insect stepping [41;23]. For slow oscillator 
frequencies, the wave gait results (see Figure 4). The fastest allowed oscillator frequency produces 
the tripod gait (see Figure 5). Smooth changes in oscillator frequency result in smooth changes in gait. 
ML FL FR BL .......... ~Px BR :................. : computer model stepping pattern BL MR BL BR cockroach 
stepping pattem .................. time > Figure $: The coupled oscillators produce the tripod gait 
at the maximum oscillator frequency. The cockroach and corn- putter model stepping patterns are essentially 
identical, except that the cockroach has a longer stance time than step time. In the computer model, 
the step and stance time were set to be identical during the tripod gait in order to drive a standing 
leg backwards at the highest velocity. However, stability might be increased by allowing the standing 
leg to take up more of the body weight before its neighbors step, which would result in a stepping pattern 
more like the biological cockroach's. (cockroach stepping pattern adapted from Pearson [23]0 The step 
reflex and load bearing reflexes function correctly, but require calibration. They should not function 
during undisturbed walking, but should instead reinforce stable stepping patterns under disturbances. 
The calibration procedure is to observe and analyze undisturbed walking, and then set reflex trigger 
values beyond the norm. Different leg pairs (front, middle, and back) wiR require different values, since 
their ranges of motion are different, and they support different loads. This calibration has not yet 
been performed for the hexapod model. However, these two reflexes have been studied for a simple kinematic 
hexapod [ng]. The step reflex increases the robustness of the gait, especiaRy during turning and speed 
changes. The load-bearing reflex (implemented in the kinematic model as a table lookup of stable stepping 
patterns) increases stability when limbs are missing, and prevents the step reflex from triggering a 
supporting leg to step. To date, we have studied adaptive locomotion not through active control, but 
rather through the mechanical compliance of the physical simulation. 4.2. Walking Experiments Using the 
initial joint and spring angles established from the Blatta diagrams, the hexapod was "dropped" onto 
level ground in several dynamic simulations. The first attempts employed linear springs at the joints, 
and on every attempt the hexapod would collapse, as the supporting forces generated at the joints were 
not strong enough. Increasing the spring constants only resulted in a very stiff system, without providing 
enough support for the figure to stand. When exponential springs were introduced at the joints in place 
of the linear springs, they created forces sufficient to support the hexapod as it was dropped on the 
ground. In addition, while the hexapod was failing through the air, the integrator only slightly subdivided 
the frame rate -far less than with the strong linear springs -since the exponential springs generate 
less force at low displacements. During the first walking experiment, the initial posture was found to 
be too low, and the hexapod dragged its abdomen along the ground behind it. Although in nature the cockroach 
frequently drags its abdomen along the ground I47], we desired a model of locomotion in which the body 
was fully supported as in many other insects. Therefore the posture was raised by using joint motor programs 
to move the exponential spring rest angles to values which further extended the limbs. These spring angles 
were used as the new initial configuration for further walking experiments. Dozens of walking simulations 
have been executed, often successively "tuning" the action of the motor programs or other parameters. 
For example, the step program originally did not lift the foot fast enough or high enough to avoid dragging 
it aiong the ground for much of the stepping time, so the motor program was modified to lift the leg 
up higher, and more rapidly at the beginning of the step. Typical motor program pa- rarneters for the 
hexapod are available in [38]. Figure 7 shows the hexapod employing the tripod gait over level terrain. 
The interval between steps of successive legs employed was 50 rnsec, compared to approximately 120 msec 
for the beetle Chrysomela which has a "relatively long" stepping interval [47]. The walking speed exhibited 
by the hexapod was approximately 5.5 era/see. Insects show a wide variety of walking speed, varying from 
2.0-9.8 crn/sec in the Earwig, 3.2-17.5 enffsec for Blatta, and 1.0-20.0 cm/sec for the cockroach, Periplaneta. 
The walking speed of our simulated roach falls well within these ranges, but is considerably slower than 
real insects walking at their top speeds. This experiment employed a sliding model of friction with a 
fairly low coefficient of friction (0.7). A different walking experiment, also employing the tripod gait, 
used a ground contact model in which the "feet" were modeled as having sticky pads, under active control 
of the hexapod, as in the honey-bee and many other insects[46]. During stance, the feet would stick to 
the ground using exponential springs. The springs were allowed to break, if the force rose above a specified 
limit, allowing the feet to slide slightly and stick again. The walking speed of the hexapod increased 
to approximately 8.0 era/see, using the sticky foot model. Constraint-based methods, especially Lathrop's, 
would be appropriate to simulate these constrained kinematic foot placements. An interesting observation 
is that our hexapod exhibits a side- to-side "wiggle" as it progresses forward, using the tripod gait. 
In fact, the same sort of zig-zag path is seen in real insects [46]. The phenomenon can be explained 
when the propulsive forces are analyzed. The front supporting leg acts as a tractor, pulling the center 
of mass forward, and towards the point of support. The rear supporting leg (on the same side of the body 
as the front support) pushes the body forward, and produces either clockwise or counterclockwise turning 
forces, depending on whether the line of force produced by the limb passes in front of or behind the 
body's center of mass. At the beginning of stance, the rear leg will tend to rotate the body in the same 
direction as the front leg. As stance continues and the rear foot moves back relative to the body, the 
line of force produced by the leg will shift further and further forward, and its turning forces will 
tend toward the opposite direction. The middle supporting leg, on the opposite side of the body, serves 
to support that side, propel the body forward, and to counteract part of the rotary forces produced by 
the other two supporting limbs. Locomotion over uneven terrain is shown in Figure 8. The "stlcky-foot" 
model of contact was used for this simulation, to prevent the hexapod from sliding down the hill. The 
hexapod adapts to the terrain purely by the mechanical compliance provided by the springs and dampers 
in the legs. The stepping and stance motor programs were not modified for the terrain; a more complete 
system should adapt its motor control for different environmental conditions. However, it is interesting 
to note how dynamic simulation and mechanical compliance can lead to adaptive behavior, without special 
planning. The computation time involved in simulating the walking motion of the hexapod is relatively 
high, especially compared to kinematic models. On a Hewlett-Packard Series 9000 Model 835 (a RISC based 
workstation, rated at 12 MIPS) one videofrarne at 1/40 real time (1/1200 see simulation time) takes approximately 
4 minutes of computation time. The dynamics algorithm is called approximately 600 times in that interval 
by the adaptive step-size integrator. A simple kinematic model of the hexapod operates in real time, 
but has fewer degrees of freedom (20 DOF vs. 38 DOF) and does not display complex, realistic motion. 
The dynamics code does not currently take advantage of several numerical optimizations, which could increase 
speed by an order of magnitude. In addition, a stiff- system integrator could increase speed greatly 
by saving many calls to the dynamics algorithm. 5. FUTURE WORK The number of legs can simply become a 
parameter to the gait controller. We have used the same coupled oscillator paradigm to generate realistic 
biped and quadruped gaits, though only in kinematic simulations. Insects can employ wave and tripod gaits 
which always provide at least three support points at all times during the gait cycle, i.e., they rely 
on static balance. Bi-peds and quadrupeds, however, use mostly dynamic balance, in which the figure is 
falling from support point to support point. We intend to study the interaction of the mechanics of the 
figure with the coordination strategy in order to develop a dynamic biped locomotion system. 6. SUMMARY 
The realistic simulation and animation of the motions of human and animal figures has long been a goal 
of researchers in computer graphics. We have presented a dynamic locomotion simulator in which the coordination 
of a kinematically complex visual insect is automatically generated by a gait controller, and realistic 
motions of the limbs are produced by stepping and stance motor programs which apply appropriate forces 
to the limbs. Motion is accurately and efficiently computed by our implementation of the Featherstone 
Articulated Body Method. The simulation agrees well with the observed behavior of insects. The coupled 
oscillator model of gait coordination is general, and can be used to control biped and quadruped gaits. 
ACKNOWLEDGEMENTS The corpus system makes use of several large support libraries coded in C at the Computer 
Graphics and Animation Group, including rendermatic, a rendering library with geometric collision detection, 
by Brian Croll and David Chen; retepmatic, a rendering package with additional functionality by Peter 
Sehr0der, and robotlib an inverse kinematics and matrix manipulation package, by David Chen. In addition, 
Bob Sabiston must be given ample credit for co-designing the stills from Grinning Evil Death. BIBLIOGRAPHY 
[1] Kugler, P, N., J. A. S. Kelso and M. T. Turvey. On the Concept of Coordinative Structures as Dissipative 
Structures: I. Theoretical Line. Tutorials in Motor Behavior. Amsterdam, North-Holland (1980). [2] Featherstone, 
R. The Calculation of Robot Dynamics Using Articulated-Body Inertias. Robotics Research 2,1 (1983), 13-29. 
[3] Featherstone, R. Robot Dynamics Algorithms. Kluwer Academic Publishers (1987). [4] Schr6der, P. The 
Virtual Erector Set, Master's Thesis, Massachusetts Institute of Technology (1990). [5] Barzel, R. and 
A. H. Barr. Controlling Rigid Bodies with Dynamic Constraints. ACM SIGGRAPH '88 Course Notes #27: Developments 
in Physically-Based Modeling, Section E (1988). [6] Isaacs, P. M. and M. F. Cohen. Controlling Dynamic 
Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics. Computer Graphics 21,4 
(July 1987), 215-224. [7] Barzel, R. and A. H. Bart. A Modeling System Based on Dynamic Constraints. 
Proceedings of SIGGRAPH '88 (Atlanta, Georgia, August 1988) In Computer Graphics 22,4 (August 1988), 
179-188. [8] Schr6der, P. and D. Zeltzer. The Virtual Erector Set: Dynamic Simulation with Linear Recursive 
Constraint Propagation. Proceedings of the 1990 Symposium on Interactive 3D Graphics (Snowbird, Utah, 
March 1990). In Computer Graphics 24, 2 (1990), 23-31. [9] Witkin, A. and M. Kass. Spacetlme Constraints. 
Proceedings of SIGGRAPH '88 (Atlanta, Georgia, August 1988) In Computer Graphics 22,4 (August 1988), 
159-168. [10] Walker, M. W. and D. E. Orin. Efficient dynamic computer simulation of robotic mechanisms. 
Proceedings of Joint Automatic Contr. Conf. (Charlottesville, VA, 1981). [11] Wilhelms, J. Using Dynamic 
Analysis for Realistic Animation of Articulated Bodies. IEEE Computer Graphics and Applications 7,6 (June 
1987), 12-27. [12] Arrnstrong, W. W. Reeursive solution to the equations of motion of an n-link manipulator. 
Proceedings of 5th World Congress Theory Maeh. Meehartissms (Montreal, 1979) Volume 2, 1343-1346. [13] 
A.rms~ong,W. W., M. Green and R. Lake. Near-Real- Time Control of Human Figure Models. IEEE Computer 
Graphics and Applications 7,6 (June 1987), 52-61. [14,] Lathrop, R. H. Constrained (Closed-Loop) Robot 
Simulation By Local Corts~aint Propagation. Proceedings of 1986 IEEE Int. Conf. on Robotics and Automation 
(San Francisco, 1986) Volume 2, 689-694. [151 Zeltzer, D., S. Pieper and D. Stunnan. An Integrated Graphical 
Simulation Platform. Proceedings of Graphics Interface 89 (London, Ontario, 1989), 266-274. [161 Zeltzer, 
D. Towards an Integrated View of 3-D Computer Animation. The Visual Computer 1,4 (December 1985), 249-259. 
[17] Muybridge, E. The Human Figure in Motion. New York, Dover (1955). [18] Muybridge, E. Animals in 
Motion. New York, Dover (1957). [19] Hildebrand, M. Analysis of Tetrapod Gaits: General Considerations 
and Symmetrical Gaits. Neural Control of Locomotion. New York, Plenum Press (1976). [20] Gallistel, C. 
R. The Organization of Action: A New Synthesis. Hillsdale, New Jersey, Lawrence Erlbaum Associates (1980). 
[21] Gelfand, I. M., V. S. Gurfinkel, M. L. Tseflin and M. L. Shlk. Models of the Structural-Functional 
Organization of Certain Biological Systems. Carrtbridge, M1T Press (1971). [22] Grillner, S. Locomotion 
in Vertebrates: Central Mechanisms and Reflex Interaction. Physiological Reviews 55,2 (April 1975), [23] 
Pearson, K. The Control of Walking. Scientific American 235,6 (December 1976), 72-86. [24] Bizzi, E. 
Central and peripheral mechanisms in motor control. Tutorials in Motor Behavior. North-Holland Publishing 
Co. (1980). [251 Robertson, M. A, and L. E. Halverson. The Development of Locomotor Coordination: Longitudinal 
Change and Invariance. Journal of Motor Behavior 20,3 (1988), 197- 241. [26] Beer, R. D., L. S. Sterling 
and H. J. Chiel. Periplaneta Computatrix: The Artificial Insect Project. Case Western Reserve University. 
Teetmieal Report, TR 89-102. (January 1989). [27] Chiel, H. J. and R. D. Beer. A lesion study of a heterogeneous 
artificial neural network for hexapod locomotion. Case Western Reserve University. Technical ReportTR-108. 
(February 1988). [281 McGhee, R. B. Robot LocemotiorL Neural Control of Locomotion. New York, Plenum 
Press (1976). [29] Raibert, M. H. and I. E. Sutherland. Machines That Walk. Scientific American 248,1 
(January 1983), 44-53. [30] Dormer, M. D. Control of Walking: Local control and real time systems. Phi) 
Thesis, Carnegie-Mellon University. (1984). [31] Raibert, M. H. Legged Robots That Balance. Cambridge, 
MA, M1T Press (1986). [32] Song, S. and K. J. Waldron. Machines That Walk: The Adaptive Suspension Vehicle. 
Cambridge, MA, MIT Press (1989). [33] Zeltzer, D. Motor Control Techniques for Figure Animation. IEEE 
Computer Graphics and Applications 2,9 (November 1982), 53-59. [34] Girard, M. and A. A. Maciejewski. 
Computational Modeling for the Computer Animation of Legged Figures. Computer Graphics 19,3 (July 1985), 
263-270. [35] Sims, K. Locomotion of Jointed Figures over Complex Terrain, M.S.V.S Thesis, Massachusetts 
Institute of Technology. (June 1987). [36] Bruderlin, A. and T. W. Calvert. Goal-Directed, Dynamic Animation 
of Human Walking. Proceedings of SIGGRAPH '89 (Boston, Massachusetts, July 1989) In Computer Graphics 
23,3 (July 1989), 233-242. [37] Ball, R. S. A treatise on the theory of screws. London, Cambridge Univ. 
Press (1900). [38] McKenna, M. A. A Dynamic Model of Locomotion for Computer Animation. Master's Thesis, 
Massachusetts Institute of Technology. (1990). [39] Forsythe, G. E., M. A. Malcolm and C. B. Moler. Computer 
Methods for Mathematical Computations. New Jersey, Prentice-Hall, Inc. (1977). [40] Moore, M. and J. 
Wilhelms. Collision Detection and Response for Computer Animation. Proceedings of SIGGRAPH '88 (Atlanta, 
Georgia, August 1988) In Computer Graphics 22,4 (August 1988), 289-288. [411 Wilson, D. M. Insect Walking. 
Annual Review of Entomology 11 (1966), 162-169. [42] Pearson, K. G. and R. Franklin. Characteristics 
of Leg Movements and Patterns of Coordination in Locusts Walking on Rough Terrain. The International 
Journal of Robotics Research 3,2 (1984), 101-112. [43] McMahort, T. A. Muscles, Reflexes, and Locomotion. 
Princeton University Press (1984). [44] Bizzi, E., W. Chapple and N. Hogan. Mechanical Properties of 
Muscle: Implications for Motor Control. Trends in Neuroscience (November 1982). [45] Hogan, N. The Mechanics 
of Multi-Joint Posture and Movement Control. Biological Cybernetics 52 (1985), 315-331. [46] Wigglesworth, 
V. B. The Principles of Insect Physiology. London, Chapman and Hall. [47] Hughes, G. M. and P. J. Mill. 
Locomotion: Terrestrial. The Physiology of lnsecta. New York and London, Academic Press (1974). [48] 
McKenna, M. , S. Pieper and D. Zeltzer. Control of Virtual Actor: The Roach. Proceedings of 1990 Symposium 
on Interactive 3D Graphics (Snowbird, Utah, 1990) In Computer Graphics 24,2 (1990), 165-174.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97883</article_id>
		<sort_key>39</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Geometric collisions for time-dependent parametric surfaces]]></title>
		<page_from>39</page_from>
		<page_to>48</page_to>
		<doi_number>10.1145/97879.97883</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97883</url>
		<abstract>
			<par><![CDATA[We develop an algorithm to detect geometric collisions between pairs of time-dependent parametric surfaces. The algorithm works on surfaces that are continuous and have bounded derivatives, and includes objects that move or deform as a function of time. The algorithm numerically solves for the parametric values corresponding to coincident points and near-misses between the surfaces of two parametric functions.Upper bounds on the parametric derivatives make it possible to guarantee the successful detection of collisions and near-misses; we describe a method to find the derivative bounds for many surface types. To compute collisions between new types of surfaces, the mathematical collision analysis is needed only once per surface type, rather than analyzing for each pair of surface types.The algorithm is hierarchical, first finding potential collisions over large volumes, and then refining the solution to smaller volumes. The user may specify the desired accuracy of the solution. A C-code implementation is described, with results for several non-bicubic and bicubic time-dependent parametric functions. An animation of the collision computation demonstrates collisions between complex parametric functions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.3.2</cat_node>
				<descriptor>C</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP42052893</person_id>
				<author_profile_id><![CDATA[81100594687]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Von Herzen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034821</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P107764</person_id>
				<author_profile_id><![CDATA[81100509533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Harold]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Zatz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[David Baraff, "Analytical Methods for Dynamic Simulation of Non-penetrating Rigid Bodies," Computer Graphics 23, 3, July 1989, 223-232.]]></ref_text>
				<ref_id>Baraff 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alan I4. Barr, Geometric Modeling and Fluid Dynamic Analysis o} Swimming Spermatozoa, Ph.D. Dissertation, Rensselaer Polytechnic Institute, 1983.]]></ref_text>
				<ref_id>Barr 83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Alan H. Barr, "Local and Global Deformations of Solid Primitives," Computer Graphics 18, 3, July 1984, 21-30.]]></ref_text>
				<ref_id>Barr 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Rouen Barzel and Alan H. Baxr, "A Modeling System Based oft Dyrtamic Constraints," Computer Graphics $2, 4, August 1988, 179-188.]]></ref_text>
				<ref_id>Barzel et al. 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356797</ref_obj_id>
				<ref_obj_pid>356789</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[don L. Bentley and Jerome H. Friedman, "Data Structures for Range Searching," A Cite Computing Surveys 11, 4, December 1979, 397-409.]]></ref_text>
				<ref_id>Bentley et al. 79</ref_id>
			</ref>
			<ref>
				<ref_obj_id>51484</ref_obj_id>
				<ref_obj_pid>51481</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Paul J. Besl and Ramesh C. Jain, "Segmentation through Variable-Order Surface Fitting," IEEE Transactions on Pattern Analysis and Machine Intelligence 1 O, 2, March 1988, 167-192.]]></ref_text>
				<ref_id>Besl et al. 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Pierre Bezier, "Mathematical and Practical Possibilities of UNISURF," in Computer-Aided Geometric Design, edited by Robert E. Bamhill and Richard F. Riesenfeld, Academic Press, New York, 1974, pp. 127-152.]]></ref_text>
				<ref_id>Bezier 74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>908845</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Jim Dlinn, Computer Display of Curved Surfaces, Ph.D. Dissertation, University of Utah, 1978.]]></ref_text>
				<ref_id>Blinn 78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S.A. Cameron and R. K. Culley, "Determining the Minimum Translational Distance Between Two Convex Polyhedra," IEEE International Con}erence oft Robotics and Automation, 1986.]]></ref_text>
				<ref_id>Cameron et al. 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889291</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[John Canny, "Collision Detection for Moving Polyhedra," MIT A r$ifieial Intelligence Lab Memo 806, October, 1984.]]></ref_text>
				<ref_id>Canny 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Catmull, Ed, "Computer Display of Curved Surfaces," IEEE Con}erence Proceedings on Computer Graphics, Pattern Recognition and Data Structures, May 1975, 11.]]></ref_text>
				<ref_id>Catmull 75</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74358</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[John E. Chadwick, David R. Haumaxm and Richaxd El. Parent, "Layered Construction for Deformable Animated Characters," Computer Graphics 23, 3, July 1989, 243-252.]]></ref_text>
				<ref_id>Chadwick et al. 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. K. Culley and K. G. Kempf, "A Collision Detection Algorithm Based on Velocity and Distance Bounds," Proceedings 1986 IEEE International Conference on Robotics and Automation, Volume 2, pp. 1064-1069.]]></ref_text>
				<ref_id>Culley et al. 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31524</ref_obj_id>
				<ref_obj_pid>31519</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Daniel Filip, Robert Magedsort and Robert Markot, "Surface Algorithms using Bounds on Derivatives," Computer Aided Geometric Design 8, 1986, 295-311.]]></ref_text>
				<ref_id>Filip et al. 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>540426</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. William Gear, Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1971, p. 55.]]></ref_text>
				<ref_id>Gear 71</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[John Snyder, Jed Lengyel, Devendra Kada'a, Ronen Baxzel, John C. Platt, Alan H. Barr and Brian Von Herzen, Going Bananas, 1988 Siggraph Film Show.]]></ref_text>
				<ref_id>Going Bananas 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J.E. Hopcroft, J. T. Schwartz and M. Sharir, "Efficient Detection of Intersections among Spheres," The Internatior~al Journal of Robotics Research 2, 4, Winter 1983, 77-80.]]></ref_text>
				<ref_id>Hopcroft et al. 83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74364</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Devendra Kalra and Alan H. Barr, "Guaranteed Ray Intersections with Implicit Surfaces," Computer Graphics 23, 3, July. 1989, 297-306.]]></ref_text>
				<ref_id>Kalra et al. 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37423</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ane Kaufmart, "Efficient Algorithms for 3D Scan- Conversion of Parametric Curves, Surfaces, and Volumes," Comp_uter Graphics $i, 4, July 1987, 171-180.]]></ref_text>
				<ref_id>Kaufman 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>260999</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Donald Knuth, The Art o} Computer Programming; Vol. i, Fundamental Algorithms, Addisort-Wesley, Menlo Park, CA~ 1969, Section 2.2.4.]]></ref_text>
				<ref_id>Knuth 69</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Jeff Lane and Loren Carpenter, "A Generalized Scan Line Algorithm for the Computer Display of Parametrically Defined Surfaces," Computer Graphics and Image Processin.q 11 1979. 290.]]></ref_text>
				<ref_id>Lane et al. 79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jeff Lane and Richard F. Riesenfeld, "A Theoretical Development for the Computer Generation and Display of Piecewise Polynomial Surfaces," IEEE Transactions on Pattern Analysis and Machine Intelligence 2, 1, January 1980.35-46.]]></ref_text>
				<ref_id>Lane et al. 80</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[D. 2". Lee and Franco P. Preparata, "Computational Geometrym A Survey," IEEE Transactions on Computers G_-33,12, December 1984, 1072.]]></ref_text>
				<ref_id>Lee et al. 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[C. C. Lin and L. A. Segel, Mathematics Applied to Deterministic Problems in the Natural Sciences, Macmillan Publishing Co., Inc., New York, 1974, pp. 57-58.]]></ref_text>
				<ref_id>Lin et al. 74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Matthew Moore and Jane Wilhelms, "Collision Detection and Response for Computer Animation," Gom-]]></ref_text>
				<ref_id>Moore et al. 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Graphics ~$, 4, August 1988, 289-298. NAG Fortran Library, Numerical Algorithms Group, 1400 Opus Place, Suite 200, Downers (}rove, IL 60515 (312) 971- 2337.]]></ref_text>
				<ref_id>NAG</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[John C. Platt and Alan H. Barr, "Constraint Methods for Flexible Models," Computer Graphics 22, 4, August 1988, 279-288.]]></ref_text>
				<ref_id>Platt et al. 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[John C. Platt, personal communication.]]></ref_text>
				<ref_id>Platt 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356930</ref_obj_id>
				<ref_obj_pid>356924</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Hartan Samet, "The Quadtree and Related Hierarchlcol Data Structures," Computing Surveys 16, 2, June 1984, 187-260.]]></ref_text>
				<ref_id>Samet 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>77589</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Hanan Samet, The Design and A~alysis o} Spatial Data Structures, Addison-Wesley, Menlo Park, CA, 1990, Section 2.4, pp. 66--80.]]></ref_text>
				<ref_id>Samet 90a</ref_id>
			</ref>
			<ref>
				<ref_obj_id>77587</ref_obj_id>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Hanan Samet, Applications of Spatial Data Structures, Addison-Wesley, Menlo Park, CA, 1990, Section 1.3, pp. 15-16.]]></ref_text>
				<ref_id>Samet 90b</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15906</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Francis Schmitt, Brian Barsky and Wen-Hurl Du. "An Adaptive Subdivision Method for Surface-Fittlng from Sampled Data," Computer Graphics ~0, 4, August 1986, 179-188.]]></ref_text>
				<ref_id>Schmitt et al. 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[J.T. Schwarz, "Finding the Minimum Distance Between Two Convex Polygons," lnforma~io~ Processing Lett ors 13, 4, 1981, 168-170.]]></ref_text>
				<ref_id>Schwarz 81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801289</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[D. Schweitzer and E. S. Cobb, "Scanline Rendering of Parametric Surfaces," Computer Graphics 16, 3, July 1982, 265.]]></ref_text>
				<ref_id>Schweitzer et al. 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Tom Sederberg and Scott Parry, "Free-Form Deformation of Solid Geometric Models~" Computer Graphics 20 4, August 1986, 151-160.]]></ref_text>
				<ref_id>Sederberg et al. 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[John-Snyder Generative Models, Ph.D. Dissertation, California Institute of Technology, in progress.]]></ref_text>
				<ref_id>Snyder 90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Demetri Terzopoulos and Kurt Fleischer, "Modeling Inelastic Deformation: Viscoelasticity, Plasticity, Fracture," Computer Graphics ~, 4, August 1988, 269-278.]]></ref_text>
				<ref_id>Terzopoulos et al. 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Tetsuya Uchiki, Toshiakl Ohashl and Mario Tokoro, "Collision Detection in Motion Simulation," Cornputers and Graphics 7, 3, 1983, 285-293.]]></ref_text>
				<ref_id>Uchiki et al. 83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37415</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Brian Von Herzen and Alan H. Barr, "Accurate Triangulations of Deformed, Intersecting Surfaces," Computer _Graphics ~1, 4~ July 1987, 103-110.]]></ref_text>
				<ref_id>Von Herzen et al. 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Brian Von Herzen, Sampling De}ormed, Intersecting Surfaces with Quadtrees, Masters Thesis, California Institute of Technology, Computer Science Dept., 5179:TR:85, 1985.]]></ref_text>
				<ref_id>Von Herzen 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>76222</ref_obj_id>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Brian Von Herzen, Applications o} Surface Networks to Sampling Problems it, Computer Graphics, PhD. Dissertation, California Institute of Technology, Computer Science Dept., Caltech-CS-TR-88-15, 1989.]]></ref_text>
				<ref_id>Von Herzen 89</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 llll|m Geometric Collisions for Time-Dependent 
Parametric Surfaces Brian Von Herzen, Alan H. Barr, and Harold R. Zatz California Institute of Technology 
Pasadena, CA 91125 Abstract We develop an algorithm to detect geometric collisions be- tween pairs of 
time-dependent parametric surfaces. The algorithm works on surfaces that are continuous and have bounded 
derivatives, and includes objects that move or de- form as a function of time. The algorithm numerically 
solves for the parametric values corresponding to coincident points and near-misses between the surfaces 
of two paramet- ric functions. Upper bounds on the parametric derivatives make it pos- sible to guarantee 
the successful detection of collisions and near-misses; we describe a method to find the derivative bounds 
for many surface types. To compute collisions be- tween new types of surfaces, the mathematical collision 
anal- ysis is needed only once per surface type, rather than ana-lyzing for each pair of surface types. 
The algorithm is hierarchical, first finding potential col- lisions over large volumes, and then refining 
the solution to smaller volumes. The user may specify the desired accuracy of the solution. A C-code 
implementation is described, with results for several non-bicubic and bicubic time-dependent parametric 
functions. An animation of the collision compu- tation demonstrates collisions between complex parametric 
functions. CIZ Categories: 1.3.5--Computational Geometry and Ob- ject Modeling; 1.3.7--Three-Dimensional 
Graphics and Re- alism Additional Keywords: Collision Detection, Parametric Surfaces, Adaptive Sampling, 
Simulation, Dynamics, Con- straints, Deformations, Computer Modeling.  Introduction In computer animation 
and physical simulation it is fre- quently important for objects to interact with one another. One form 
of interaction between objects is a collision, which is initiated by geometric contacts that arise between 
two or more bodies. We distinguish the geometric contact of the objects from the forces that influence 
the motion of the ob- jects after the collision; we call these contacts the geometric part of the collision. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. k......~ n 
V ~L > (b) Increasing time (t) > Increasing time (t) Figure 1: Geometric collision of time-dependent 
parametric sur- faces. (a) A tlme-dependent parametric surface ](u, v, t). (b) A pair of deforming surfaces 
](ug, vg, t) and ~(ug, vg, t) that collide at time tin_in. The algorithm returns the paraaneters u f, 
vll, ug, v 9 , and train corresponding to the collision point on the two surfaces. In the physical world, 
collisions occur when two objects move through space and hit one another. To simulate this behavior in 
a computer graphics environment, we need a mathematical description of the objects and a coxrespond- 
ing geometric collision procedure to determine that contact has occurred. Many computer graphics objects 
are com-posed of polygons; geometric collision algorithms have been developed for these (for example 
[Moore et al. 88].) Although it is possible to represent virtually any surface with sufficient numbers 
of polygons, it is sometimes more convenient to use higher-level surface representations. Some people 
prefer to use bicnbic patches for their applications because the patches can be a more compact representation 
than polygons, and can be easier to work with. Just as bicubic patches are sometimes more conve-nient 
than polygons, there exist higher-level representations of parametric surfaces that at times are more 
convenient than bicubic patches. Examples include some forms of lo- cal and global deformations [Burr 
84], [Sederberg et al. 86], [Snyder 90]. These surfaces are typically functions of two &#38;#169;1990 
ACM-O-89791-344-2/90/O08/O039 $00.75 39 surface parameters, u, and v, as in f(u,v); A few inter- section 
algorithms for these surfaces have been developed [Filip et al. 86]. However, no results have been reported 
for dynamic collisions of general time-dependent paramet- ric functions. 1.1 Overview In this paper 
we describe a collision algorithm for time-dependent parametric surfaces that are described by para- 
metric functions of three arguments, u, v, and t as in f(u, v, t) (see Figures 1 and 2). These types 
of functions arise frequently in the context of physically-based modeling and simulation, as a body translates, 
rotates and possibly deforms as a function of time. In this algorithm, we com- pute the u and v collision 
parameters at the earliest time of collision t~i,. Unfortunately, for arbitrary parametric functions 
it can be proven that no algorithm (based solely on function eval- uation) can be constructed that is 
guaranteed to find the earliest time of collision (See Section 1.3). A restriction on the functions is 
needed in order to construct a workable col- lision algorithm. In this paper, we require the functions 
to have computable bounds on their regional rates of change. These bounds on the rates of change are 
called "Lipschitz" values. Such surfaces and functions with computable Lip- schitz values will likely 
become increasingly important for computer graphics rendering, both in terms of software, but also in 
terms of future computer graphics hardware [Kalra et al. 89], [Kaufman 87], and [Von Herzen et al. 87]. 
The potential hardware applications arise from an inter- esting feature of the algorithm. The reader 
may be aware that many other algorithms for intersecting parametric sur- faces use special cases: a different 
procedure is needed for each pair of surface types. For instance, the reader can imagine an algorithm 
that computes interactions between spheres and cylinders but does not compute interactions be- tween 
other surface types (say, ellipsoids and cylinders). Unlike the case-by-case algorithms in which a different 
procedure is needed for each pair of surface types, our algo- rithm works uniformly for all of its available 
surfaces. Each surface is analyzed by itself, to compute bounds on its rates of change (see Appendix 
B). From these bounds on the sur- face's rates of change, we can find geometric collisions with other 
surface types. Thus, we do not need to perform O(N 2) analyses (for each possible pair of N surface types) 
but in- stead we can analyze each function once, in isolation. Then it automatically interacts with all 
of our previously imple- mented surface types with no extra work. 1.2 Problem Statement The parametric 
surfaces may be considered to be vector functions of three parametric variables: f(us,v/,t ) and ~(ug, 
va, t), where ui and vi are parametric variables that span each of the surfaces, and t is time. For suitable 
types of surfaces, we want to find the earliest time tmi,, within bounds, such that [(U s, VS, tmirt) 
= g(UO, V o, grain). (1) We also want to find ul,vl,ug , and vg at some point of first collision on 
each surface. We assume that the surfaces are continuous, and that they are embedded in three spatial 
dimensions and one temporal dimension. In practice, we determine when the distance between ob- jects 
becomes less than a tolerance r: vg, tmi=)ll < r. (2) This event is termed a 7.collision, and includes 
collisions and near-misses closer than "y. Most dynamic modeling systems [Baraff 89], [Barzel et al. 
88] can readily utilize the approximate colli- sion parameters available with large values of r. The 
user requests a value of r that is roughly the largest value satis- factory for the particular application 
(smaller values would cause the collision-detection algorithm to put in more work than necessary); this 
value of r is typically much larger than the machine precision, ¢. Thus we are able to avoid the prob- 
lem of finite machine precision by explicitly using a value of 7 much larger than e. Eqn. 2 represents 
a difficult, non-linear, 5-dimensional, root-finding problem. The algorithm based on ]3qn. 2 pre- sented 
in Section 4 can quickly produce results at a coarse tolerance r, and later produce results at finer 
tolerances. Sometimes the r-collision algorithm terminates after a single sample has been taken from 
each surface: it becomes computationally trivial to reject potential collisions between distant objects. 
For additional efficiency, we develop a new method to produce bounding boxes for parametric func- tions, 
using a "Jacobian'-style matrix of Lipschitz condi- tions on the parametric function. This method produces 
much tighter bounds on the surface than does the standard Lipschitz condition, and enhances the effectiveness 
of the algorithm for computing collisions between parametric sur- faces. The next subsection describes 
some of the difficulties in detecting collisions, and potential solution methods. Sec- tion 2 describes 
other work in collision detection. Section 3 and Appendix A develop a new method to form a hierar- chy 
of bounding volumes for parametric surfaces. Section 4 describes the algorithm and computational results, 
and Sec- tion 5 describes methods for computing Jacobian maxima for parametric surfaces, useful in bounding 
box formation.  1.3 Problems with Arbitrary Surfaces The collision problem for parametric surfaces can 
be made arbitrarily difficult for suitably extreme parametric surfaces, such as the spike function of 
Figure 2. For suitably sharp spikes, finite sets of samples will probably miss the spikes completely. 
Finding a narrow spike becomes arbitrarily dif- ficult as the parametric width of the spike approaches 
zero. The spike problem exists in time as well as space for geo- metric collisions. If the location 
of a surface is discontinuous in time then it becomes impossible to detect collisions, be- cause it becomes 
impossible to know the location of a surface over a time interval. There must be some additional con- 
straint on a parametric surface in order to guarantee that the first collision is detectable. 1.3.1 A 
Method that Doesn't Work A simplistic approach for collision detection would be to position two surfaces 
at time tl and see if they intersect, and then move the surfaces to final positions at time t2 and see 
if they intersect. We could then split the time difference and sample the two surfaces at time (tz + 
t2)/2, or some other time between tl and t2. Recursing in this manner, we would sample the paths of the 
two surfaces. The problem with this technique for any finite number of samples is that  ~ Computer 
Graphics, Volume 24, Number 4, August 1990 X Figure 2: Parametric spike functions can be made arbitrarily 
sharp, so that their detection is extremely difficult. A fourth spike in this figure is invisible, since 
it falls between the grid points. Collision detection becomes arbitrarily difficult for such parametric 
surfaces. We need some other information in addition to the function values at isolated points in order 
to guarantee the detection of the first intersection. we have no information about the positions of the 
surfaces between the sampling times. Without this information, we can never be sure that we have not 
missed an intersection. The problem is analogous to the spike problem of Figure 2. 1.3.2 A Method that 
Works To solve the collision-determination problem, we require a constraint on the maximum velocity 
of any point on the sur- face. Similarly, we require constraints on parametric deriva- tives other than 
time. If velocity is unconstrained, then the position of a surface may be discontinuous as a function 
of time, and the collision determination problem is insol- uble [Von Herzen 89, Appendix A.5]. With knowledge 
of the maximum velocity of two surfaces, we can find the first collision of the surfaces. 1.4 Solution 
using Lipschitz Conditions We can construct bounding volumes of parametric surfaces with Lipschitz conditions. 
Given a continuous parametric surface f(ffff), the Lipschitz condition states that -;( 1311 _< L 11 2 
-111, (3) for some finite number L in some region R of f. The Lips- chitz condition is implied if the 
function f(~7) has finite par- tial derivatives [Linet al. 74, p. 58]. The Lipschitz value L is a generalization 
of the derivative of ~(ff). We can also find Lipschitz values for some surfaces that are not differentiable 
 [Von Herzen 89, Appendix B.3]. The Lipschitz condition on a surface is sufficient to create sets of 
bounding volumes that are guaranteed to bound the parametric surface. It is possible to develop a similar 
constraint on the tem- poral aspects of the collision-determination problem. We can have a moving parametric 
surface f(gg), g = (u, v, $)T, that changes as a function of time. We can construct a set of bounding 
volumes for the changing surface, in a manner analogous to the method for stationary surfaces. In this 
case, L sets an upper bound for the velocity of the paramet- ric surface as well as for the other parametric 
derivatives. This inequality is depicted graphically in Figure 3. Given parametric functions f(g) and 
~(g), along with their Lipschitz values LI, and L~, we have proven in Parametric Space Modeling Space 
Figure 3: Graphical illustration of the Lipschitz inequality for parametric functions of three variables. 
If D is the d.istoame from f(~2) to f(~l), and ,t = ll~2 -~zll, we have D _< Ld, where L is a Lipschitz 
value for ~, as in Eqn. 3. [Von Herzen 89] a method to determine the earliest colli-sion between two 
surfaces. Alternatively, we can confirm that two objects do not collide. In addition, we will gener- 
alize the notion of a Lipschitz value so as to provide tighter bounding volumes for the computations. 
 2 Previous Work Previous techniques have used velocity and distance bounds for collision detection 
of rigid objects [Culley et al. 86]. Up- per bounds on velocity and lower bounds on distance can determine 
the minimum time until the next collision be- tween objects. Here we extend the work to functions that 
can deform over time. There has been some work on determining lower bounds on distance for convex polygons 
and polyhedra [Schwarz 81], [Cameron et al. 86]. A number of collision algorithms have been developed 
for polyhedra [Moore el al. 88], [Canny 84], [Hopcroft et al. 83], [Uchiki et al. 83], but collision 
algo-rithms have not been developed for more general time-dependent parametric surfaces. Other work has 
developed techniques to compute the intersections of parametric functions based on derivative bounds 
[Filip et al. 86]. Their work applies to static ob-jects that do not move as a function of time. In Section 
4, we describe a method that works for time-dependent sur-faces, including deformable surfaces. The Lipschitz 
condition has been applied to problems in scan-conversion [Kauf_man 87], ray-tracing [Kalra et al. 89], 
and adaptive sampling [Von Herzen et al. 87]. Recent developments in constraint methods for flexi- ble 
models [Platt et al. 88] stress the importance of ac- commodating elastic and moldable objects in a physical 
simulation. Examples of plastic and inelastic deforma- tions appear in recent work on modeling inelastic 
defor- mation [Terzopoulos et al. 88]. Collisions between flexible objects are also important for deformable 
animated char- acters [Chadwick et al. 89], [Going Bananas 88]. The algo- rithm presented in Section 
4 can form a basis for a uniform environment in which varied objects may interact. The en- vironment 
can accommodate rigid surfaces, bicubic patches, moving surfaces, and deforming surfaces, all within 
the same framework for collisions and near-misses. Efficient collision determination involves the adaptive 
sampling of time-dependent parametric functions. Previous work in adaptive sampling includes [Catmull 
75], [Bllnn 78], [Lane et aL 79], [Lane et aL 80], [Schweitzer et aL 82], [Schmitt et al. 86], [Besl 
et al. 88], and [Von Herzen 85]. It is important to mention that the preceding articles do not deal 
with time at all, and therefore are not adequate for collisions of deformable time-dependent surfaces. 
As stated previously, the collision determination problem is insoluble for arbitrary time-dependent surfaces 
(Section 1.3), but in Section 4 we provide a solution for all surfaces that satisfy the Lipschitz condition, 
including all differentiable paramet- ric surfaces. The notion of an upper bound on velocity is generalized 
to parametric dimensions other than time (see Appendix A). We can automatically find a lower bound on 
the sep- aration distance between objects, given upper bounds on the parametric derivatives of the functions. 
The deriva-tive constraints enable us to sparsely sample a paramet-ric function that deforms over time 
[Barr 83], [Barr 84], [Sederberg et al. 86], and determine -r-collisions with other objects. 3 Bounding 
Volumes for Time-Dependent Para-metric Surfaces We develop a set of bounding volumes for time-dependent 
parametric surfaces. The method presented here is general enough to determine collisions of flexible 
objects that change shape over time. We develop a subdivision method over parametric rectangular prisms, 
and traverse the parametric volumes of two surfaces to verify that they do not collide. 3.1 k-d Trees 
in Parametric Space A variety of subdivision mechanisms are possible, includ-ing quadtrees of squares 
or bintrees of triangles [Samet 84], [Von Herzen 89]. We need a method that extends eas-ily to k dimensions, 
and that controls the aspect ratio of the parametric subregions. We choose to use an al-ternative to 
the quadtree, which generalizes to k dimen- sions, called the k-d tree (for k-dimensional binary search 
tree, [Bentley et al. 79], [Samet 90a], [Samet 90b]). In the k-d tree method, k-dimensional space is 
divided into k-dimensional boxes, using planes perpendicular to each of the parametric axes. Each subdivision 
level splits the k-dimensional box along one of the dimensions to form two descendant boxes (Figure 4). 
 3.2 Lipschitz Bounding Spheres We can constrnct bounding spheres from the Lipschitz equa- tion. Figure 
5 shows the bounding sphere for a paramet-ric region R, and its corresponding projection in modeling 
space. The radius r of the bounding sphere in modeling space is given by r >_ L(Au + Lxv + At). A sufficient 
value for L is  L_>maxR 2' 2 2 (4)  (°'1 I 0' °'l) It is important to emphasize that a liierarchy 
of bounding spheres is generated from the k-d tree hierarchy. Each sub- region in the k-d tree has its 
own bounding sphere. As subdivision proceeds, the bounding spheres become smaller. 3.3 Jacoblan Bounding 
Boxes While the Lipschitz spheres will suffice as bounding volumes, we can reduce the size of the bounding 
volumes, and con-sequently the average number of interference computations, 42 t ~3  ,lkl u~----.~ 
Parametric Space Modeling Space Figure 4: Successive subdivision of a 2-dirnensional k-d tree in parametric 
and modeling space. The function fmaps parametric space onto modeling space. Each individual subrectangle 
is called a node of the k-d tree. The aspect ratio of the rectangles may be adjusted by factors of 2. 
using the Jacobian of a parametric function. See Appendix A for a derivation of the Jacobian bounding 
boxes. To create the Jacobian bounding boxes, we find the max- imum of each component of the Jacobian 
over the region to be bounded, as described in Appendix B. The resulting ma- trix is called the rate 
matrix M, and places bounds on each of the parametric derivatives over the region R. A sufficient value 
for the rate matrix M is a constant matrix with all entries set to the value for L in Eqn. 4. Better 
results are obtained by deriving each component of M separately. The next section uses the rate matrix 
M to create bound- ing boxes for each parametric surface. If the boxes do not overlap, then we confirm 
that no collision occurs. If they do overlap, then we adaptively subdivide the surfaces to de- termine 
if a 7-collision has occurred. As with the bounding spheres, an adaptive hierarchy of bounding boxes 
is formed based on the k-d tree of each surface. 4 Collision Algorithm We compute collisions using a 
bounding volume hierarchy for each parametric surface. The collision algorithm has an important property: 
parametric surfaces that are far apart will be shown not to collide, using a single sample from each 
surface. This computation is extremely short, making it trivial to reject collisions between distant 
objects. Para-metric surfaces that do collide will cause the algorithm to adaptively sample each surface 
near the collision point, us-ing the k-d trees to guide the sampling. In this way the collision is refined 
until the desired accuracy 7 is reached. To set up the collision algorithm, we are given the para- metric 
functions f(uf,vl,t) and ~(ug,vg,t). We are also given a function that returns the rate matrix M over 
a para- metric region R. The task is to compute whether two objects collide, as  ~ Computer Graphics, 
Volume 24, Number 4, August 1990 Lipschitz Parametric Node Figure 5: Constructing a bounding sphere about 
a parametric node. The center of the sphere ](gc) in modeling space comes from the center ~c in parametric 
space. The radius r is based on the size of the node in parametric space, and the Lipschitz value for 
the function. A sphere of radius r = L(Au + LXv + ~t) bounds the region in modeling space, where &#38;u, 
&#38;v, and At represent half-widths of the parametric rectangle. determined by the loss of separation 
of the two parametric surfaces. We assume initially that the two objects are dis- joint. We are given 
a threshold distance tolerance 7, below which we should report a collision, including the parameters 
uS, el, ug, %, and time t. 4.1 Collision Algorithm Approach Initially we use one node to represent each 
surface. We sub- divide as necessary to determine if a geometric collision oc- curs within any particular 
subregion. Parametric sampling is concentrated where it is needed the most, near potential intersections. 
The algorithm must find the earliest collision between two surfaces. This implies that we should traverse 
the nodes of the k-d trees in forward-time order. We can schedule pairs of nodes (one from each surface) 
to be compared ac-cording to the earliest possible collision time, determined from the minima of the 
time bounds of the parametric sub- regions. The two parametric regions cannot collide until they both 
have come into existence. So the maximum of the two starting times represents the earliest possible collision 
time. Given the time interval tA :h AtA of node A, and the time interval tB At9 of node B, we sort the 
node-pairs according to the earliest possible intersection time tmin: - tmi= = max(tA &#38;tA, tB -- 
&#38;ts). (5) We maintain a heap data structure [Knuth 69] of pairs of nodes to be compared, sorted in 
ascending order, using train as the sort-key. The distance between the centers of the nodes is used as 
a secondary sort-key to focus effort on the most probable collision candidates. We successively pop node-pairs 
off the heap for comparison, in ascending order, according to tml,. The node comparison generates new 
node-pairs whenever there is an overlap in the bound- ing volumes. The pairs are pushed onto the heap, 
and the process continues until all pairs are evaluated. This method guarantees that we will find the 
earliest collision between the surfaces.  4.2 C Implementation Figure 6 shows an algorithm written in 
C for computing the collision between two parametric surfaces. The node typedef double vector[3], matrlx[3] 
[3] ; A node is a piece of a parametric sur]ace. typedef struct node_struct { vector parameters; (u,v,t) 
coords in parametric apace. vector width; (u,v,t) width in parametric space. vector posltlon; (x,y,z) 
eoords in modeling space. vector radii; (x,y,z) width in modeling space. node childl ,child2; The two 
subreglons of this node. int split_direction; The splitting axis ]or the node. } *node ; vector surface_collision(]n1, 
fn2, Jmaxl, Jmax2, gzumaa) vector fnl(), fn20; The functions to be collided. matrix JmaxlO, Jmax20 ; 
The maximum of the Jaeo~ians. float gamma; Collision tolerance. { One node from each ]unction; used for 
comparison. node node1, node2; heap_flushO ; Empty the heap of nodes. Put the initial node pair on the 
heap ]or evaluation. schedule_node_pair(init ial_node (fnl, Jmaxl), initial.xtode(fn2, Jmax2)) ; As 
long as nodes are on the heap, compare them. while (heap_pop(knode/, knode2)) { if (nodes_collide_e 
ithin_t olerance (node 1 ,node2, ganmm) ) return (¢olllsion_info (node1, node2)) ; The nodes are too 
large, if (norm(nodel->radii) > norm(node2->radii)) { node_split(node1, fnl, Jmaxl) ; schedule_node_pair(nodel->childl, 
node2) ; schedule_node_palr (nodel->child2, node2) ; } else {node.split (node2, fn2, Jmax2) ; a~hedu_le_node_pair 
(node1, node2-> child/) ; schedule_node_pair(node/, node2->child2) ; } } returnCIULL) ; I/there are 
no nodes left to } compare, the surfaces don't collide. int schedule_node_pair (nodel,node2) node nodel,nods2 
; { if (!~ime_overlap(nodel, node2)) return; if (!~pace_overlap(nodel, node2)) return; heap_push(node1, 
node2) ; Heap is sorted by tmi n- } Figure 6: An algorithm and data structure to determine colli- sions 
for time-dependent parametric surfaces. data structure represents a region of a parametric surface. The 
surface_collision function computes a 7-sphere that contains points from both surfaces, or else confirms 
that the two surfaces do not collide. The surface_collision function calls several other func- tions. 
The function initial_node computes an initial node for the entire surface at location (u,v,t) = (0.5,0.5,0.5). 
The function schedule_node_pair takes a pair of nodes, sees if they overlap in time and in space, and 
pushes them onto the heap to be scheduled for evaluation according to tmi=. The function space_overlap 
returns false if the min- imum distance between two bounding boxes is greater than 7. The operation heap_pop 
pops a pair of nodes off the heap for evaluation. The function collisionAnfo returns the collision parameters 
and time if a 7-colhsion took place. Finally, the function node_split subdivides a node into two smaller 
nodes along the parametric dimension with the greatest contribution to the bounding-box size. Detailed 
proofs of the algorithms may be found in [Von Herzen 89, Appendix A]. The function nodes_collide_wlthin_tolerance 
determines whether a 7-sphere contains both surfaces. For termina- tion, we compute the smallest isothetic 
rectangle (a rectan- gle aligned with the coordinate axes) that contains the two bounding boxes. If the 
largest dimension of the isothetic rectangle is smaller than the separation tolerance, we report the 
loss of separation of the two surfaces, down to the tol- erance specified. Expressed mathematically, 
for bounding boxes (XA, yA, ZA) =~ (Z~XA, &#38;yA, ZXZA) and (~, y~, ,~) =~ (ZXxB,&#38;YB,&#38;zB), and 
tolerance 7, we require (JzA-zBI+LXXA+~=~, \ max lya -ysl + &#38;VA + ZXyB, ) _< 7. (6)  [za -zB[ + 
AzA + AzB 4.4 Complexity for Interacting Spheres We can test the colhsion algorithm using two parametric 
spheres. We would expect that as the separation distance decreases between the two spheres, the number 
of bound- ing box comparisons should increase. In particular, if the separation distance drops by a factor 
of two, we will have to create bounding boxes twice as small to confirm that the surfaces do not intersect. 
For the parametric k-d tree hi-erarchy, every halving of the separation distance requires a constant 
number of additional subdivision levels. Assum-ing that CPU time should be proportional to the number 
of subdivision levels, the CPU time t should scale as t ~ logs ((r + S)/S), (7) where r is the radius 
of each sphere, and S is the minimum separation between spheres. 4.5 Results for Interacting Spheres 
As an illustration of the relationship between computation time and separation distance S, we determine 
collisions for two spheres while varying S. The total computation time is a function of the minimum separation 
distance between the two objects. The graph in Figure 7 shows an example of the computation time as a 
function of S. For an object of radius r and minimum separation distance S = 2r, we require only a few 
samples to be taken from each surface. As the minimum separation distance decreases, we notice an increase 
in CPU time proportional to the negative logarithm of the separation distance In this computation we 
assume 7<S.  4.6 Results for Other Objects As a demonstration of results for surfaces more complicated 
than polynomials or quadrics, the collision method is demon- strated for two spiked objects illustrated 
in Figure 8. The parametric equation for the spike function is ~(u, v) = r(u, v) sin(2ru) sin(rv) , (8) 
 v) cos( ) where the radius is given by i<n = + ,1 (9) i=0 44 120 - 110 - 100 - 90-CPU 80-Time 70-t 
60- (sec.) 50- 40- 30- 20- 10-   02-s 2-:-7 2&#38;6 2&#38;s 2'-4 2'-3 2'-2 2'-1 2'0 2'1 2'2 Log Separation 
Distance S, in units of r. Figure 7: CPU time for two interacting spheres of radius r as a function 
of log S, where S is the minimum separation between two objects In this example, ~ < S. The value n is 
the number of spikes on the sphere, (ui, vi) is the parametric location of the {-th spike, and w0 determines 
the radius of the spikes Without knowing something about the parametric derivatives of the spike function, 
it would be very difficult to solve the collision problem for two moving spike functions. As it is, we 
are able to construct a set of bounding volumes as the computation requires, in order to verify the paths 
of the two objects. We illustrate the results of the collision computation. In Figure 8.a, we see two 
spherical spike functions approaching each other In Figure 8.b, the algorithm computes a colhsion between 
two of the spikes. A physical simulation program computes the recoil as shown in Figure 8.c (see Section 
6). This collision computation would have been very difficult to solve without knowing the rate matrix 
M for the spike function. With this information, we can solve difficult col- lision problems, using a 
straightforward application of the collision algorithm of Figure 6. The appendices discuss the creation 
of M. 5 Constraints on Jacoblans For the collision technique to be most useful, we need to de- termine 
constraints on the Jacobian of the parametric func- tions (See Appendix A). A variety of methods are 
possible. The simplest approach is to compute the maximum of any component of the Jacobian over the entire 
surface, and then to set each entry of the rate matrix M equal to the maximum value This does not provide 
particularly tight bounds on the parametric surface, but is sufficient to com- pute collisions Alternatively, 
we can compute a global maximum for each parametric variable (u, v, *). It is common for the time derivatives, 
such as ax]Ot, to have separate scaling from the spatial parametric derivatives, such as Ox/Ou and Ox/av. 
It is also common for the u and v derivatives to have separate scaaings. If we define w, =-- max , , 
, R and w~ and w, similarly, then the following matrix con-strains the Jacobian of the parametric surface: 
M(R)= w,, w~ w~ . (11) 'IVu 'Wu ~,//t  SIGGRAPH '90, Dallas, August 6-10, 1990  works with many types 
of surfaces, including patches  interfaces to physical modeling systems  needs analysis only once 
per surface type, vs. O(N 2) comparisons between all pMrs of surface types  7.2 Disadvantages Disadvantages 
of the algorithm include: * must anMyze derivatives for each surface type . can't guarantee collisions 
for surfaces with unbounded derivatives Acknowledgments We would like to thank Carolyn Collins and Pete 
Wenzel for their assistance. The work presented in this paper was sponsored in part by International 
Business Machines, Inc., Hewlett-Packard Co., Apple Computer, Inc., and the Fannie and John Hertz Foundation. 
References [Baraff 89] David Baraff, "Analytical Methods for Dynamic Sim- ulation of Non-penetrating 
Rigid Bodies," Computer Graph- ics 23, 3, July 1989, 223-232. [Barr 83] Alan H. Barr, Geometric Modeling 
and Fluid Dy-namic Analysis of Swimming Spermatozoa, Ph.D. Disserta- tion, Rensselaer Polytechnic Institute, 
1983. [Barr 84] Alan H. Barr, "Local and Global Deformations of Solid Primitives," Computer Graphics 
18, 3, July 1984, 21-30. [Barzel et al. 88] Rosen Barzel and Alan H. Barr, "A Modeling System Based on 
Dynamic Constraints," Computer Graphics $2, 4, August 1988, 179-188. [Bentley et al. 79] Jon L. Bentley 
and Jerome H. Fried_man, "Data Structures for Range Searching," ACJIf Computing Surveys 11, 4, December 
1979, 397-409. [Besl et al. 88] Paul J. Besl and Ramesh C. Join, "Segmentation through Variable-Order 
Surface Fitting," IEEE Transactions on Pattern Analysis and Machine Intelligence 1 O, 2, March 1988, 
167-192. [Bezier 74] Pierre Bezier, "Mathematical and Practical Possibil- ities of UNISURF," in Computer-Aided 
Geometric Design, edited by Robert E. Barnhill and Richard F. Riesenfeld, Aca- demic Press, New York, 
1974, pp. 127-152. [Blinn 78] Jim Blinn, Computer Display of Curved Surfaces, Ph.D. Dissertation, University 
of Utah, 1978. [Cameron et al. 86] S. A. Cameron and R. K. Culley, "Determin- ing the Minimum Translational 
Distance Between Two Con- vex Polyhedra," IEEE International Conference on Robotics and Automation, 1986. 
[Canny 84] John Canny, "Collision Detection for Moving Poly- hedra," MIT Artificial Intelligence Lab 
Memo 806, October, 1984. [Catmull 75] CatmuU, Ed, "Computer Display of Curved Sur- faces," IEEE Conference 
Proceedings on Computer Graph- ics, Pattern Recognition and Data Structures, May 1975, 11. [Chadwick 
et al. 89] John E. Chadwick, David R. Haumann and Richard E. Parent, "Layered Construction for Deformable 
Animated Characters," Computer Graphics 23, 3, July 1989, 243-252. [Cu]_ley et aL 86] R. K. Culley and 
K. G. Kempf, "A Colli-sion Detection Algorithm Based on Velocity and Distance Bounds," Proceedings 1986 
IEEE International Conference on Robotics and Automation, Volume 2, pp. 1064-1069. [Filip ctal. 86] Daniel 
Filip, Robert Magedson and Robert Markot, "Su_face Algorithms using Bounds on Derivatives," Computer 
Aided Geometric Design 3, 1986, 295-311. [Gear 71] C. William Gear, Numerical Initial Value Problems 
in Ordinary Differential Equations, Prentice-Hall, Inc., Engle- wood Cliffs, New Jersey, 1971, p. 55. 
[Going Bananas 88] John Snyder, fed Lengyel, Devendra Kah'a, Ronen Barzel, John C. Platt, Alan H. Barr 
and Brian Von Herzen, Going Bananas, 1988 Siggraph Film Show. 46 [Hopcroft et al. 83] J.E. Hopcroft, 
J. T. Schwartz and M. Sharir, "Efficient Detection of Intersections among Spheres," The International 
Journal of Robotics Research 2, 4, Winter 1983, 77-80. [Kalra ctal. 89] Devenclra KMra and Alan H. Barr, 
"Guaranteed Ray Intersections with Implicit Surfaces," Computer Graph- ics 23, 3, July 1989, 297-306. 
[Kaufman 87] Aria Kaufman, "Efficient Algorithms for 3D Scan- Conversion of Parametric Curves, Surfaces, 
and Volumes," Computer Graphics $i, 4, July 1987, 171-180. [Knuth 69] Donald Knuth, The Art of Computer 
Programming; Vol. 1, Fundamental Algorithms, Addison-Wesley, Menlo Park, CA, 1969, Section 2.2.4. [Lane 
et al. 79] Jeff Lane and Loren Carpenter, "A Generalized Scan Line Algorithm for the Computer Display 
of Parametri- cally Defined Surfaces," Computer Graphics and Image Pro- cessln.q 11, 1979. 290. [Lane 
et a[. 80] Jeff Lane and Richard F. Rieserffeld, "A Theo- retical Development for the Computer Generation 
and Dis- play of Piecewise Polynomial Surfaces," IEEE Transactions on Pattern Analysis and Machine Intelligence 
2, 1, January 1980.35-46. [Lee et a[. 84] D. T. Lee and FFranco P. Preparata, "Computa-tional Geometry-- 
A Survey," IEEE Transactions ou Com-puters C-33, 12, December 1984, 1072. [Linet aL 74] C. C. Lin and 
L. A. Segel, Mathematics Applied to Deterministic Problems in the Natural Sciences, Macmillan Publishing 
.C9. J Inc., New York, 1974, pp. 57-58. [Moore et aL gS] Matthew Moore and Jane Wilhelms, "Collision 
Detection and Response for Computer Animation," Com-puter Graphics 22, 4, August 1988, 289-298. [NAG] 
NAG Fortran Library, Numerical Algorithms Group, 1400 Opus Place, Suite 200, Downers Grove, IL 60515 
(312) 971- 2337. [Plattet aL 88] John C. Platt and Alan H. Barr, "Constraint Methods for Flexible Models," 
Computer Graphics 22, 4, August 1988, 279-288. [Platt 8~] John C. Platt, personal communication. [Samet 
84] Hanan Saxaet, "The Quadtree and Related Hierarchi- cal Data Structures," Computing Surveys 1 6, 2, 
June 1984, 187-260. [Samet 90a] Hanan Sonnet, The Design and Analysis of Spatial Data Structures, Addison-Wesley, 
Menlo Park, CA, 1990, Section 2.4, pp. 66.--80. ISomer 90b] Hanan Samet, Applications of Spatial Data 
Struc- tures, Addison-Wesley, Menlo Park, CA, 1990, Section 1.3, pp. 15-16. [Schnfitt et al. 86] Francis 
Schmitt, Brian Barsky and Wen-Hut Du. "An Adaptive Subdivision Method for Surface-Fitting from Seanpled 
Data," Computer Graphics 20, 4, August 1986, 179-188. [Schwarz 81] J. T. Schwarz, "Finding the Minimum 
Distance Be- tween Two Convex Polygons," Information Processing Let- ters 13, 4, 1981, 168-170. [Schweitzer 
et al. 82] D. Schweitzer and E. S. Cobb, "Scardine Rendering of Parametric Surfaces," Computer Graphics 
16, 3, July 1982, 265. [Sederberg et al. 86] Tom Sederberg and Scott Parry, "Free-Form Deformation of 
Solid Geometric Models," Computer Graph- ics 20 4, August 1986, 151-160. [Snyder 90] John Snyder Generative 
Models, Ph.D. Dissertation, California Institute of Technology, in progress. [Terzopoulos ct al. 88] 
Demetri Terzopoulos and Kurt Fleischer, "Modeling Inelastic Deformation: Viscoelasticity, Plasticity, 
Fracture," Computer Graphics 22, 4, August 1988, 269-278. [Uchlkl et al. 83] Tetsuya Uchlkl, Toshlakl 
Ohashl and Marlo Tokoro, "Collision Detection in Motion Simulation," Com-puters and Graphics 7, 3,1983, 
285-293. [Von Herzen et al. 87] Brian Von Herzen and Alan H. Barr, "Ac- curate Triangulations of Deformed, 
Intersecting Surfaces," Computer Graphics 21, 4, July 1987, 103-110. [Von Herzen 85] Brian Von Herzen, 
Sampling Deformed, In-tersecting Surfaces with Quadtrees, Masters Thesis, Cal-ifornia Institute of Technology, 
Computer Science Dept., 5179:TR:85, 1985. [Von IIerzen 89] Brian Von Herzen, Applications of Surface 
Networks to Sampling Problems in Computer Graphics, PhD. Dissertation, California Institute of TeclmoloKy 
, Com- puter Science Dept., Caltech-CS-TR-88-15, 1989. @ ~ A Appendix: Jacobian Bounding Boxes Here we 
derive a set of bounding boxes for parametric functions using the Jacobian of the function. These boxes 
frequently pro- duce tighter bounds on a parametric surface than the Lipschitz bounding spheres. We start 
with the original definition of the Lipsckitz condition for parametric functions ([Gear 71]): -DIl, -, 
cll. (,3) Assume that the condition holds over some parmnetrlc subregion R : ul ~ u _< u2, Vl < v < v2, 
and tl < t < t2. We define para- metric coordinates fie = (ue, vc, to) at the center of region R, and 
modeling space coordinates (~cc,yc, zc) = f(gc). We choose an L1 norm for the right side of Eqn. 13, 
and we apply the condition to each component of ~ separately: I ~-xd _< L~(lu-ud+l "-vcl+l t-teD, IV- 
V¢I _< L~ (l~ -~1 + I" - "d + It-t~[), (14) I~-~cl < L~ (lu -u~l + I" - ~d + It - td), for some suitable 
values of ILl. We distribute the values Li and rename them to arrive at a more general inequality: I:-~ol 
<_ M:,lu-u¢l+M:~lv-vcl+M~tlt-t¢l, iv-vd _< M~,.lu-=¢l+M~,,Iv-v.l+M~tlt-tcl,  Iz-z¢l _< M~lu-u,l+M~lv-v,l+M~tlt-t,l. 
(15) We can solve for each iij by choosing appropriate values of (u, v, t). We illustrate with Mxu: 
 I~(u,v,t)-z(uc, v,t)l_<M=~lu-~l, 06) or IZ(UlV't)-~(u*'v't)lUc U#UO (17) Assuming that x(u, v, t) is 
differentiable, a sufficient value of Mxu is Mzu ~m~xlOX(u'v't) " (18) Mxu iS an upper bound on the parametric 
derivative over the region R. In general, a sufficient value of the rate matrix M is: M=- Ir~x-~ max 
1 9 ) "R( lot"~1 / Just as the Lipschitz value L is a generalization of the derivative, so the rate matrix 
M is a generalization of the Jacobiart matrix for parametric vector functions of several variables [Line* 
aL 74, p. 355]. The matrix M consists of upper bounds on all the para- metric derivatives of all the 
components of vector ftmction J. We define Au _= I~t2 -Ucl, ~v .~ Iv2 - Vcl, and At =--It2 - %1. Since 
ul < u _< u2, we have lu - ucl _< &#38;u. Similarly, Iv - Vcl _< Av, and it - tel < At. Substituting 
into Eqn. 15, we have the rate condition: Ix-xel < M=uAu + MzvAv + Mxt&#38;t, lY - ycl < M~u&#38;u + 
MuoAv + MurAt , (20) Iz --zcl < Mzuhu + MzvAv + MztAt. We define the bounding box radii to be Ax _= 
Mxu&#38;U + MxvAv + ~¢xtAt, Ay _= MuuAu + MuoAv + MvtAt , (21) hz ~ MzuhU + Mzvhv + ~lrtht. Now we can 
construct a bounding volume in modeling space from the bounding box radii, based on Au, Av, At, and the 
rate matrix. We form a rectangular prism that is aligned with the x, Computer Graphics, Volume 24, Number 
4, August 1990 uuuumu ill y, and z axes, centered about modeling coordinates (aZc,yc,zc). Combining Eqn. 
21 with Eqn. 20, we get the bounding box inequality: I=- ~cl _< A~ Iv-u.I _< Av (22) Iz-z~l 5 zx~. Such 
a rectangular region is called an iso~hetic rectanfle, a rect- angle whose sides axe parallel to coordinate 
axes [Lee et al. 84]. The set of points satisfying Eqn. 22 form a bounding box contain- ing the parametric 
region. We now have art efficient hounding box useful for computing collisions between moving parametric 
sur-faces. We are free to compute the Jacobian maxima over the entire surface, thereby computing with 
a single-valued constant matrix across the surface. Alternatively, we may compute the Ja- cobians over 
subregions in order to tailor the bounding volumes more closely to particular variations in the surface. 
These boxes frequently produce tighter bounds on the parametric functions than does the Lipschitz condition 
of Eqn. 3. B Appendix: Bounds on Parametric Derivatives Here we describe how to compute the entries in 
the matrix M from Eqn. 19. In addition to the differentiable surfaces, some non-differentiable surfaces 
also have computable Lipsehitz values from which to derive rate matrices ([Von Herzen 89, Appendix B.3]). 
In this section we will focus our attention on differentiahle parametric surfaces. B.1 Maxima of scalars 
We frequently have a closed-form description of x(u,v,t) that permits us to compute the derivative ~:t(u, 
v, t) directly. Then we can use the following identities to compute the maxima of fuxtctions: Eqn. 23 
is known as the triangle inequality. It is equivalent to the law that the length of the longest side 
of a triangle must be less than the lengths of the two shorter sides added together: maxR 17(n) + i(R) 
l _< r~x If(R)l + r~ax I¢(n) l, (23) Similar laws hold for the operations of subtraction, multiplication, 
and division of functions. maxR If(R) -)1 _~ax I](n)l + ~ax I~(R)I, (24) g( < maxR If(R)C(R)I _< ~ax 
If(n)l ~x Iff(n)l, (25) max If(R) l maxlf(R)l~(R)l < n (26) n -minl~(R)l ' R for all. ](R) and if(n). 
 B.2 Maxima of polynomials Given h(t), a polynomial function of degree n = 2,3, or more, we want to 
maximize its value over a range ta < t < tb. The polynomial h(t) is assumed to be of the form h(t) = 
ao + nit + a2t 2 + a3t 3 + a4t 4 + .... The maximum in h(t) occurs either at 0, t0, or at the points 
of solution for h'(t) = O. We take the derivative analytically and then solve the result- ing polynomial 
equation using any one of a variety of numeri- cal analysis programs (see [NAG]) for t, to get a set 
of values t = tl,...,tN. Add 0 and t0 to the set to get 0, tl, ...,tN, tO. Then we substitute these values 
into tile definition for h(t). and pick the maximum value of h(0) or h(ti), for 0 < i < N. This is the 
maximum value for the whole interval, ta _< t _< tb. For any interval ta _< t < tb we only need to evaluate 
h(t) at the endpoints ta and tb and any values in the solution set between ta and tb. This recalculation 
will reduce the magnitude of the Lipschitz value as the interval decreases with further iterations. Similar 
solutions are possible for polynomial patches that use a rational cubic representation in one parametric 
direction ([Filip el al. 86, p. 307]). It is straightforward to extend these results to several dimensions. 
 Product surfaces include superquadrics, spheres, profile surfaces, translational sweeps, and spherical 
products [Barr 83]. These sur- faces take the mathematical form: =~(=,v) = ~(v)c~(=) + d~(v), (27) where 
i = 1,2,3, and subscripts 1,2 and 3 correspond to compo- nents x, y, and z. The partial derivative of 
this surface with respect to u is: 2/) = ,~(V) -~ "1- di (V). (28) 0u Suffident values of the entries 
of the rate matrix M are: = i = 1, 2, 3. The rate matrix entries with respect to parazneter v are given 
by: m.. = maxa ~ maxR Ic~(u)l + n~x . (30) Finally, all the time derivatives are zero: m. = O. Given 
dif-ferentiable scalar functions for }(v), c~(u), and d~(v), we can find the rate matrix for the product 
surface. B.4 Surfaces with Translational Motion Assuming that we can compute the rate matrix for a stationary 
surface f(u, v), how can we compute the rate matrix for the same surface that is translating as a function 
of time? ([Von Herzen 89, Appendix B.2]). We define the translation function to be s~t). The translating 
surface is given by function ff(u, v, t) = f(u, v) + g(t). If the value mij represents the rate matrix 
for f, then the new rate matrix Mg for the moving surface ~(u, v, t) is Mg= . (31) I  B.5 Surfaces with 
Rotational Motion We now examine rotational motion for rigid objects. Given a function f(u, v), and a 
rotation matrix R.(t) as a function of time, we have if(u, v, t) = R(t)f(u, v). The parametric derivatives 
of ff are given by Off(u, t) =R(t) 0%'" v)," (32) 0u Off(u, v, t) R(t) Of~ v), = (33)Ov o~(~, v, t) _ 
oR(0 ,~rr~, V). (34) Ot Ot  B.6 Example of a deformation As an example of computing the rate matrix 
for a deforming function, we illustrate how to compute the rate matrix for an object with a variable 
taper as given in [Barr 84], assuming we have the rate matrix for the undeformed object. Let f(u, v) 
be the tmdeformed object with components (x, y, z). The deformed coordinates are given by X = r(z,t)v 
for the av component, Y = r(z,t)y for the y component, and Z = z for the z component, where r(z, $) is 
the tapering function that varies over time. Then the derivatives for the deformed coordinates are: OX 
Or Oz Ox Ou Oz ~z + ~r(z,t), (35) OX Or Oz Ox .... =+ 7-(t), (36) Ov Oz Ov ov r'z' 0X Or 0x t). (37) 
0--7 = + r(z, The equations are analogous for the Y component. All of the derivatives for Z are equal 
to the derivatives for z. A typical taper function r(z, t) is a pieeewise linear function that tapers 
from rl to r 2 starting at zl and ending at z2. We can make the ending values of the taper vary as a 
function of time, rl(t) and r2(0- The function r(z, t) is given by Z<Zl, = z,)r + -z)r, 31 _< _< (36) 
r2 (t) z2 -31 z > 32. The derivatives of r(z, t) are given by 0 z<zl, Or r2 --rl --~ Z 1 < Z < Z2, (30) 
Oz 32 -- Zl ---- 0 z >z2. The temporal derivative is given by Or~(O ' Z<Zl, 8r , at ,Or2 0rl (40) 0r2(t) 
32 zl z>z2. Eqn. 40 is valid for dynamic tapers of static objects. The dif-ferentiation rule for products 
leads to the equation for tapers of distorting objects. These equations may be substituted directly into 
Eqn. 19 for the rate matrix to obtain derivative bounds on parametric surfaces tapering as a function 
of time.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97884</article_id>
		<sort_key>49</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Rapid, stable fluid dynamics for computer graphics]]></title>
		<page_from>49</page_from>
		<page_to>57</page_to>
		<doi_number>10.1145/97879.97884</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97884</url>
		<abstract>
			<par><![CDATA[We present a new method for animating water based on a simple, rapid and stable solution of a set of partial differential equations resulting from an approximation to the shallow water equations. The approximation gives rise to a version of the wave equation on a height-field where the wave velocity is proportional to the square root of the depth of the water. The resulting wave equation is then solved with an alternating-direction implicit method on a uniform finite-difference grid. The computational work required for an iteration consists mainly of solving a simple tridiagonal linear system for each row and column of the height field. A single iteration per frame suffices in most cases for convincing animation.Like previous computer-graphics models of wave motion, the new method can generate the effects of wave refraction with depth. Unlike previous models, it also handles wave reflections, net transport of water and boundary conditions with changing topology. As a consequence, the model is suitable for animating phenomena such as flowing rivers, raindrops hitting surfaces and waves in a fish tank as well as the classic phenomenon of waves lapping on a beach. The height-field representation prevents it from easily simulating phenomena such as breaking waves, except perhaps in combination with particle-based fluid models. The water is rendered using a form of caustic shading which simulates the refraction of illuminating rays at the water surface. A wetness map is also used to compute the wetting and drying of sand as the water passes over it.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computations on matrices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39032842</person_id>
				<author_profile_id><![CDATA[81100215003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kass]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer, Inc., 20705 Valley Green Drive, Cupertino, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39080505</person_id>
				<author_profile_id><![CDATA[81332515728]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gavin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer, Inc., 20705 Valley Green Drive, Cupertino, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>806820</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Max, N., "Vectorized proceedural models for natural terrain: Waves and islands in the sunset," Proceedings of SIGGRAPH 81, (August 1981 ) 317- 324.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15893</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Peachy, D., "Modeling Waves and Surf," Proceedings of SIGGRAPH 86, (August 1986), 65-74.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Foumier, A. and Reeves, W., "A Simple Model of Ocean Waves," Proceedings of SIGGRAPH 86, (August 1986), pp 75-84.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35070</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ts'o, P. and Barsky, B., "Modeling and Rendering Waves," ACM Transactions on Graphics, 6, 3 (July 1987), 191-214.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30658</ref_obj_id>
				<ref_obj_pid>30657</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Masten, G., Watterberg, P. and Mareda, I., "Fourier Synthesis of Ocean Scenes," IEEE Computer Graphics and Application, 7, 3 (March 1987) 16-23.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lewis, J., "Generalized Stochastic Subdivision," ACM Transactions on Graphics, 6, 3 (July 1987) 167-190.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., "An Image Synthesizer," Proceedings of SIGGRAPH 85, (July 1985) 287-296.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Schachter, B., "Long crested wave models," Computer Graphics and Image Processing 12 (Feb. 1980), 187-201.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Miller, G. and Pearce, A., "Globular Dynamics: A connected particle system for animating viscous fluids," Computer Graphics 13,3 (1989) 305-309.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sims, C., "Particle Dreams,"{Video} Siggraph Video Review 38/39, ACM SIGGRAPH, New York, segment 42 (1988).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Patel, B. and Dvinsky, A., "The solution of the reynolds averaged Navier-Stokes equations in general curvilinear coordinates and its application to vehicular aerodynamics," in Computers in Design, Manufacture and Operation of Automobiles, Murthy and Brebbia, Eds., Springer Verlag, Berlin (1987).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kallinderis, Y. and Baron, J., "Adaptation methods for a new Navier-Stokes algorithm," AIAA Journal, 27, 1 (January 1989)37-43.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Miyata, H. and Nishimura, S., "Finite difference simulation of nonlinear waves generated by ships of arbitrary three-dimensional configuration," Journal of Computational Physics 60 (1985) 391-436.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6771</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Press, W., Flannery, B, Teukolsky, S. and Vetterling, W., Numerical Recipes: The Art of Scientific Computing, Cambridge University Press, Cambridge (1986).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Le Mehaute, B., An Introduction to Hydrodynamics and Water Waves, Springer-Verlag, New York (1976).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Crapper, G., Introduction to Water Waves, John Wiley &amp; Sons, New York (1984).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Stoker, J., Water Waves, Interscience, New York, (1957).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Shinya, M., Saito, T. and Takahashi, T., "Rendering Techniques for Transparent Objects," Proceedings of Graphics Interface, London, Ontario (June 1989).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63450</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Hall, R., Illumination and Color in Computer Generated Imagery, Springer Verlag, Berlin (1988).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Rapid, Stable Fluid Dynamics for Computer Graphics 
Michael Kass and Gavin Miller Advanced Technology Group Apple Computer, Inc. 20705 Valley Green Drive 
 Cupertino, ABSTRACT We present a new method for animating water based on a simple, rapid and stable 
solution of a set of partial differential equations resulting from an approximation to the shallow water 
equations. The approximation gives rise to a version of the wave equation on a height-field where the 
wave velocity is proportional to the square root of the depth of the water. The resulting wave equation 
is then solved with an altemating-direction implicit method on a uniform finite-difference grid. The 
computational work required for an iteration consists mainly of solving a simple tridiagonal linear system 
for each row and column of the height field. A single iteration per frame suffices in most cases for 
convincing animation. Like previous computer-graphics models of wave motion, the new method can generate 
the effects of wave refraction with depth. Unlike previous models, it also handles wave reflections, 
net transport of water and boundary conditions with changing topology. As a consequence, the model is 
suitable for animating phenomena such as flowing rivers, raindrops hitting surfaces and waves in a fish 
tank as well as the classic phenomenon of waves lapping on a beach. The height-field representation prevents 
it from easily simulating phenomena such as breaking waves, except perhaps in combination with particle-based 
fluid models. The water is rendered using a form of caustic shading which simulates the refraction of 
illuminating rays at the water surface. A wemess map is also used to compute the wetting and drying of 
sand as the water passes over it. CR Categories and Subject Descriptors: 1.3.7: [Computer Graphics]: 
Graphics and Realism: Animation; G.1.8: [Mathematics of Computing]: Partial Differential Equations; 
1.6.3 [Simulation and Modeling]: Applications. Additional Keywords and Phrases: Wave equation, fluid 
dynamics, flow, finite-difference, height-field, caustic. Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. CA 95014 INTRODUCTION The problem of realistically 
modeling scenes containing water has captured the attention of a number of computer- graphics researchers 
in recent years[l; 2; 3; 4; 51, The omni- presence of water as well as the complexities and subtleties 
of its motion have made it an attractive subject of study. Yet existing computer-graphics models of water 
motion adequately cover only a very small range of interesting water phenomena. Among other effects, 
they fail to account for wave reflections, net transport of water and boundary conditions with changing 
topology. A computationally inexpensive method of simulating these phenomena will be presented here. 
Based on solving a partial-differential equation on the surface of a height-field, the method is easy 
to implement and very stable. The approximations involved may not be suitable for high-precision engineering 
applications, but they produce pleasing animation with little effort. Many popular methods for modeling 
water surfaces work well for producing still images, but are unsuitable for animation because they do 
not include realistic models for the evolution of the surface over time. Examples of these techniques 
include stochastic subdivision [6] and Fourier synthesis [5]. Other techniques work well only in large 
bodies of water away from boundaries [7; 1; 8]. Recently, the realism of water modeling in computer graphics 
was substantially improved by three papers [2; 3; 4-] that took into account refrac- tion due to changing 
wave velocity with depth. In each case, specialized methods based on tracking individual waves or wave-trains 
were used to avoid the need to directly solve a differential equation. These papers deal adequately with 
waves hitting a beach, but they leave a wide range of water phenomena unexplored. None of the papers 
includes simulations of reflected waves. In addition, the underlying model in each case is that particles 
of water move in circular or ellipsoidal orbits around their initial positions, so there can be no net 
transport or flow. Finally, none of the papers considers situations in which the boundary conditions 
change through time altering the topology of the water -- for example a wave pushing water up over an 
obstacle and down the other side to create a puddle. It appears to be very difficult to deal with these 
phenomena efficiently by tracing waves. Two alternatives to tracing the propagation of waves or wave-trains 
exist. One is to simulate the fluid by the interaction of a large number of particles [9; 101, and the 
other is to directly solve a partial differential equation describing the fluid dynamics [11; 12; 13]. 
Both have been used by hydro-dynamicists to create iterative simulations of fluid flow. The problem is 
that a truly accurate simulation of fluid mechanics usually requires computing the motion throughout 
a volume. This means that the amount of computation per iteration grows at least as the cube of the resolution. 
If there are linear &#38;#169;1990 ACM -0- 89791-34.4-2/90/008/0049 $00.75 49 SIGGRAPH '90, Dallas, 
August 6-10, 1990 h 0 h 1 h 2 h a ... hn. 3 ha. 2 hn.1 b 0 b I b 2 b 3 . . b~. 3 b._2 b~.l U 0 U 1 Un_ 
3 Un. 2 Fig. 1: Discrete two-dimensional height-field representation of the water surface h, the ground 
bottom b, and the horizontal water veloc- ity u. systems to be solved at every iteration, the computational 
cost can grow even faster. In addition, the number of iterations required may grow as the resolution 
is increased. As a consequence, accurate simulation of fluid mechanics is typically reserved for vectorized 
supercomputers or very highly parallel machines. For the purposes of animation, accuracy is much less 
im- portant than stability and speed. An animator using tech- niques of physical simulation will typically 
have to experiment with a number of different conditions of a simula- tion before achieving satisfying 
motion. If the experiments take too much time or if the numerical methods become unstable, the process 
can become excruciating. Here, we examine the differential equation approach with the goal of constructing 
the fastest stable simulation which yields a wide range of convincing motion. We begin by considering 
a very simplified subset of water flow where the water surface can be represented as a height field and 
the motion is uniform through a vertical column. This subset of water flow is representative of a variety 
of non-turbulent shallow-water phenomena. Under these conditions, we can approximate the equations of 
motion of the water in terms of a grid of points on a height-field. The amount of computation can then 
be proportional to the number of samples on the surface of the water which varies as the square of the 
resolution instead of the cube. Integration of the partial-differential equations is done with an alternating-direction 
implicit technique [14]. The result is a very stable integration scheme which is also very fast. Stability 
derives from the use of an implicit integration scheme; speed derives from the tridiagonal structure 
of the required linear systems which are solvable in linear time. Be-cause of the stability, the time-step 
of the solution can be made equal to the frame time of the animation in most cases. SHALLOW WATER EQUATIONS 
In lieu of simulating the full Navier-Stokes equations of fluid flow, we begin with a vastly simplified 
set of equations which has been widely used for shallow water [15; 16; 17]. The simplification arises 
from three approximations. The first ap- proximation is that the water surface is a height field. This, 
of course, has some obvious limitations. The water cannot splash and waves cannot break. However, so 
long as the forces on the water are sufficiently gentle, the height-field as- sumption will not introduce 
error. The second assumption is that the vertical component of the velocity of the water particles can 
be ignored. Once again, the limitations of this assumption are fairly clear. If a disturbance creates 
very steep waves on the water surface, the model will cease to be accu- rate. The third assumption is 
that the horizontal component of the velocity of the water in a vertical column is approximately constant. 
If there is turbulent flow or unusually high friction on the bottom, this assumption will break down. 
Nonetheless, the experience of hydrodYnamicists suggests that this is a very useful approximation to 
phenomena ranging from the effect of a single rain drop to the refraction of waves in a sea port. For 
simplicity, we begin with a height-field curve in two dimensions. Later, the same techniques will be 
extended to a height-field surface in three dimensions. Let z = h(x) be the height of the water surface 
and let z = b(x) be the height of the ground, tf d(x)=h(x)-b(x) is the water depth and u(x) is the horizontal 
velocity of a vertical column of water, the shallow water equations that follow from the above assumptions[ 
16; 17] can be written as follows: ON oN   --+uN+ag Oh =0 at (eq. 1) ,gd 0 -~-+ ~ (ud) = 0 (eq. 2) 
 where g is the gravitational acceleration. Eq. 1 expresses Newton's law F=ma while eq. 2 expresses the 
constraint of volume conservation. Note that even with the above three simplifying assumptions, the resulting 
differential equations are non-linear. A further simplification which is often used is to ignore the 
second term in eq. 1 and linearize around a con- stant value of h. This will be reasonable if the fluid 
velocity is small and the depth is slowly varying. The resulting equations are then: oh --+g~=0 at (eq. 
3) Oh ON -5-+d-g = 0 (eq. 4) If we differentiate eq. 3 with respect to x, then differentiate eq. 4 with 
respect to t and finally substitute for the cross-deriv- atives, we end up with d 2h d 2h gd at 2 -0x 
2 (eq. 5) which is the one-dimensional wave equation with wave velocity ~. While this degree of simplification 
is suspect for many engineering purposes, our experience suggests that the resulting equations are quite 
adequate for a wide range of animation applications. DISCRETIZATION In order to solve eq. 5, we need 
to construct a discrete rep- resentation of the continuous partial-differential equation. There are two 
established techniques for doing so. The first is the finite-difference technique where the continuous 
functions are represented by a collection of samples. The second is the finite-element technique where 
the continuous functions are represented as the sum of a collection of continuous basis functions. Here, 
the finite-difference technique works particu- larly well because of the simple height-field representation. 
The resulting algorithm is very easy to implement and the  ~ Computer Graphics, Volume 24, Number 4, 
August 1990 linear systems involved are tridiagonal. Figure 1 shows the discrete representation of the 
height- field in two dimensions. Note that the samples for u lie half- way in between the samples of 
h. After experimenting with a number of finite-difference approximations to equations 3 and 4, the most 
stable version we have found is Ohi ( di_l + d i ( di + di+ 1 ~tli -;: t. 3m<- J",, ~, 2-z~c J (eq. 6) 
t~U i -g(hi+l --hi) Ot Ax (eq. 7) where Ax is the separation of the samples along the x direc- tion. 
Putting the above two equations together, we get t9 2h i ( d~ , + di~, Ot 2 ( d i + di+ 1 h (eq. 8) which 
is a discrete approximation to eq. 5. INTEGRATION The finite differences convert the partial-differential 
equa- tion into an ordinary differential equation involving h and its time derivatives. The remaining 
problem is to solve the ordinary differential equation. While there are a number of possible choices 
of solution method, the wave equation is a notoriously bad example for explicit differential equation 
methods such as Euler's method or Runge-Kutta integration. As the wave velocity approaches one sample 
per iteration, explicit methods tend to diverge very rapidly. Since the wave speed is proportional to 
the square-root of the depth, an ordinary explicit method would have to use a time-step appro- priate 
for the deepest water in the model. Implicit methods, on the other hand, do not suffer from these difficulties. 
For simplicity, we use a first-order implicit method which appears to be perfectly adequate. Let h(n) 
to denote h at the nth iteration and let dots denote differentiation with time. Then the first-order 
implicit equations can be written h(n) -h(n = 1) = /~(n) At (eq. 9) /~(n) -/~(n -1) = fi(n) At (eq. 10) 
Note that the right-hand sides of these equations are evaluated at time n which corresponds to the end 
of the iteration rather than time n-1 which corresponds to the beginning of the iteration. This is what 
makes the iteration implicit and stable. Rearranging the above, we get h(n) = h(n-1)+ At/~(n-l) + (At)2fi(n) 
(eq. 11) h(n) = 2h(n -I) -h(n -2) + (At)2t~(n) (eq. 12) hi(n ) = 2hi(n -1) -hi(n -2) 2 { di-1 + di )" 
-g(A,t) ( ~-z~c~ fl (hi(n) -hi-l(n)) ( d~ + d~+~ ~. + g(At)2 ( ;&#38;-~ fl( hi÷'(n)- hi(n)) (eq. 13) 
We are still left with non-linear equations because d depends on h. In order to solve these equations 
rapidly, we need a final linearization. Once again there are several possible choices, but a particularly 
well-behaved linearization is to regard d as a constant during the iteration. This means that the wave 
veloc- ity is fixed as a function of x. It limits the non-linearities to changing the wave velocities 
in-between iterations and virtual- ly ensures that the iteration will not diverge With this linear- ization 
the next value of h can be calculated from previous values with the symmetric tridiagonal linear system 
Ahi(n) = 2hi(n -1) - hi(n -2) (eq. 14) where the matrix A is given by  "e0 f0 f0 el fl f, e2 " ° A= 
".. ".° ".° e,-3 flu-3 f n-3 en-2 ffn-~ fn-2 en-1 (eq. 15) and the elements of A are as follows: e 0= 
l+g(At) 2 do + dl ei=l+g(At)Z(di-1+2di2(~x)2+di÷I)   (O<i<n-l) e._, = I+ gfm)2t 2(~x)2 ) 2 ( di + 
di+l f,= -g(At) ~ -2-(~c'-~ ) (eq. 16) Note that right-hand side of eq. 14 can be regarded as an extrapolation 
of the previous motion of the fluid surface. Some interesting effects are possible by slightly changing 
the extrapolation. In particular, if the equation is changed to be Ah~(n) = h;(n -1) + (1 -"r)(hi(n -1) 
-hi(n -2)) (eq. 17) then , introduces some damping in the extrapolation. If SIGGRAPH '90, Dallas, August 
6-10, 1990 f _~_Light /T\ B Fig. 2: Illumination Refraction for Uneven Terrain x. = 0, then it reduces 
to eq. 14, but if r is between zero and one, it will make the waves damp out over time. The visual effect 
is that of a viscous fluid. There is one further subtlety of importance in the two-di- mensional case. 
Even though eq. 14 was derived from eq. 6 which specifies conservation of volume, there is no guarantee 
that the results of the iteration will precisely conserve volume. The primary cause of departures from 
volume-conserving be- havior is that the iteration may leave h i < b i for some index i. To compensate 
for this negative volume, the iteration will create excess positive volume elsewhere. While the effect 
is small, it can accumulate over time and create substantial drift. If the entire surface acquires a 
small net upwards velocity it will very quickly create noticeable amounts of water. To combat this effect, 
the following simple projection appears to be adequate. After each iteration, find the connected pieces 
of the fluid. This can be done by scanning the h and b vectors in order and testing whether h~ < b i. 
For each connected piece of the fluid, calculate the old volume and the new volume. If the new volume 
is different, distribute the difference uniform- ly over the samples in the connected region. We can 
now state the entire algorithm for the two-dimen- sional case in some detail: Begin by specifying h(0), 
h(1) and b. Loop for j starting at 2 incrementing by one. Ifthere are net sources or sinks of water, 
add or subtract the amounts from the current and last values of h. Calculate dfrom h(j-1) and b. If h 
i < b i then d i = 0. Calculate the new value of h from h([-1) and h(#-2) using eq. 14. Adjust the new 
value of h to conserve volume as above. If h i < b i 'TOIsome index/, set hi(j) andhi( j-1)tob i-e. The 
resulting value of h is h(j). While there are a number of possible refinements, this is the basic version 
of the two-dimensional case. It can be implemented in one to two pages of very efficient, straightforward 
C code. THREE DIMENSIONS Height fields in two dimensions are interesting, but moving to three dimensions 
opens up a much wider range of possibilities. Fortunately, the three-dimensional equations can be approximated 
by a series of two-dimensional equations, so the complexity does not increase radically. The basic wave 
equation for water in three dimensions is the same as the two- dimensional case except that the second 
derivative of h with respect to x is replaced with the Lap!acian.  a2h /a2h a2h) &#38;2 = gat'-~'T + 
3y2 ) = eq. 18 In order to solve the equations in three dimensions, we rely on the alternating-direction 
method[14]. The basic idea of the method is to take eq. 18 and split the right-hand side of it into the 
sum of two terms, one of which is independent of y and the other of which is independent of x. We then 
divide the iteration into two sub-iterations. In the first sub-iteration, we replace the right-hand side 
of eq. 18 with the first term, and in the second sub-iteration, we replace the right-hand side of eq. 
18 with the second term. More specifically, in the first sub-iteration, we solve the equation 32h O2h 
--=gd-- 0t 2 ogx 2 (eq. 19) and in the second sub-iteration, we solve the equation 0~2h t~ 2h oat 2 
= gd Oy 2 " (eq. 20)  The advantage of this technique is that the required linear sys- tems remain tridiagonal 
so the computational cost per itera- tions is proportional to the number of samples on the surface. The 
resulting implementation remains very simple. For the first sub-iteration, we compute the update as before 
on each row of the height-field. For the second sub-iteration, we do the same for each column in the 
height-field. While artifacts can potentially arise from the favored directions, our experi- ence with 
the alternating-direction formulation of these equa- tions is very favorable. More so than in two-dimensions, 
it is important to be careful with the details of the volume conser- vation. Errors manifest themselves 
as line artifacts along the x or y axes. RENDERING WITH CAUSTIC SHADING Given a realistic way of simulating 
water motion, the next step is to render it convincingly. Several different effects must be taken into 
account. Firstly, rays of light which are incident on a water surface are refracted by that surface. 
This results in uneven illumination of the terrain undemeath the water. This effect is illustrated in 
Fig. 2 in which the ray from the light source is shown being deflected by the water surface. Instead 
of the incident light ray hitting the terrain at A, the ray ends up at B. The total illumination at B 
will depend on all the rays which are refracted in that direction for the entire water surface. To compute 
this exactly, it would be necessary to render a hemicube around B of all of the water. This is prohibitively 
expensive, especially since the shading of the water surface depends on the view point unlike the typical 
diffuse case in radiosity. An alternative approach[18l, feeds rays forwards from the light source and 
accumulates the results in an illumination texture for the surface to be shaded. Such an algorithm requires 
the intersection of a ray both with the water surface height field and the terrain height field for each 
illuminating ray. A very large number of rays is required for this technique, especially for grazing-incidence 
illumination. For samples evenly spaced around the light source, the average sample density on the terrain 
is inversely proportional to the cosine of the angle between the incoming ray and the surface normal. 
For grazing incidence illumination, very large numbers of illuminating rays are required. To avoid this 
expense, we use two approximations. The first is the flat bottom approximation which is illustrated 
in Fig. 3. If the terrain is locally flat, then the destination of the  '~' Computer Graphics, Volume 
24, Number 4, August 1990 ids," Computer Graphics 13,3 (1989) 305-309. [10] Sims, C., "Particle Dreams,"[Video] 
Siggraph Video Review 38/39, ACM SIGGRAPH, New York, seg- ment 42 (1988). [11] Patel, B. and Dvinsky, 
A., "The solution of the reynolds averaged Navier-Stokes equations in gen- eral curvilinear coordinates 
and its application to ve- hicular aerodynamics," in Computers in Design, Manufacture and Operation of 
Automobiles, Murthy and Brebbia, FEds., Springer Verlag, Berlin (1987). [12] Kallinderis, Y. and Baron, 
J., "Adaptation methods for a new Navier-Stokes algorithm," AIAA Journal, 27, 1 (January 1989) 37-43. 
[13] Miyata, H. and Nishimura, S., "Finite difference simulation of nonlinear waves generated by ships 
of arbitrary three-dimensional configuration," Journal of Computational Physics 60 (1985) 391-436. [14] 
Press, W., Flannery, B, Teukolsky, S. and Vetter- ling, W., Numerical Recipes: The Art of Scientific 
Computing, Cambridge University Press, Cam- bridge (1986). [151 Le Mehaute, B., An Introduction to Hydrodynamics 
and Water Waves, Springer-Verlag, New York (1976). [16] Crapper, G., Introduction to Water Waves, John 
Wiley &#38; Sons, New York (1984). [17] Stoker, J., Water Waves, Interscience, New York, (1957). [18] 
Shinya, M., Saito, T. and Takahashi, T., "Rendering Techniques for Transparent Objects," Proceedings 
of Graphics Interface, London, Ontario (June 1989). [19] Hall, R., Illumination and Color in Computer 
Gen- erated Imagery, Springer Verlag, Berlin (1988).    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97885</article_id>
		<sort_key>59</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Cone-spheres]]></title>
		<page_from>59</page_from>
		<page_to>62</page_to>
		<doi_number>10.1145/97879.97885</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97885</url>
		<abstract>
			<par><![CDATA[A cone-sphere consists of two spheres, together with the part of the cylinder or cone tangent to the two spheres and lying between them. Cone-spheres can be rapidly rendered with shading, highlights, texture, or bump maps, and composited to create twisted or branched tubular structures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39044822</person_id>
				<author_profile_id><![CDATA[81100480335]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nelson]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Max]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lawrence Livermore National Laboratory, P.O. Box 808, Livermore, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Kakimoto, M., Hayashi, N., Ohguchi, T., Santoh, S. and Max, N., "Methods for modeling and mapping branched surfaces using generalized cylinders," (in Japanese) Information Processing Society of Japan, Computer Graphics and CAD technical report 89-CG-39, Vol. 89, No. 64 (1989) pp 1-8.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617509</ref_obj_id>
				<ref_obj_pid>616007</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., "Optimal tubes," IEEE Computer Graphics and Applications Vol. 6 No. 5 (1989) pp 8-13.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Wijk, J. J. van, "Ray tracing objects defined by sweeping a sphere," Proceedings of the Eurographics '84 Conference, North Holland, Amsterdam (1984) pp 73-82. See also Van Wijk, "On new types of Solid Models and their Visualization with Ray tracing," Delft University Press (1986).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6118</ref_obj_id>
				<ref_obj_pid>6116</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bronsvoort, W., and Klok, F. "Ray tracing generalized cylinders," ACM Transactions on Graphics Vol. 4 No. 4 (1985) pp 291- 303 and Corrigendum Vol. 6 No. 3 (1987) pp 238-239.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R., "Paint" in "Tutorial: Computer Graphics" (Beatty, J., and Booth, K., editors) IEEE Computer Society catalog no. EH0194-1 (1982) pp 501-515.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801144</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Whitted, T., "Anti-aliased line drawing usirtg brush extrusions," Computer Graphics Vol. 17 No. 3 (1983) (Siggraph '83 proceedings) pp 151-156.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>988591</ref_obj_id>
				<ref_obj_pid>988584</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Max, N., "Siggraph '84 Call for Omnimax Films," Computer Graphics Vol. 17, No. 1 (1983) pp 73-76.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807439</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Max, N., "ATOMLLL: ATOMS with shading and highlights," Computer Graphics Vol. 13 No. 2 (1979) (Siggraph '79 Proceedings) pp 165-173.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Porter, T., and Duff, T., "Compositing digital images," Computer Graphics Vol. 14 No. 3 (1984) (Siggraph '84 Proceedings) pp 253- 259.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325188</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Max, N., and Lemer, D., "A two-and-a-half D motion blur algorithm," Computer Graphics Vol. 19 No. 3 (1985) (Siggraph '85 Proceedings) pp 85-93.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 O SIGGRAPH '90, Dallas, August 6-10, 1990 tolerates these straight segments much more readily than 
the scal- loped profile produced by the discrete spheres, many fewer spheres are required. A cone-sphere 
object thus consists of two spheres and the piece of the cone or cylinder joining them. The rest of this 
paper describes how to scan-convert, shade, and composite these objects efficiently. Since they are defined 
so simply, cone spheres are also a useful tool in modeling. Projection Let E and Fbe two spheres, neither 
entirely containing the other, and let C be the cone or cylinder tangent to E at the circle C E and to 
F at C F The cone-sphere defined by E and F is bounded by the curved surface of the truncated cone between 
C z and C F plus the parts of the surfaces spheres E and F outside this truncated cone. In perspective 
projection, the spheres project to ellipses and the cone's profile projects to these ellipses' common 
tangent lines. Our films used a fisheye lens in the projector, so we needed to account for the lens distortion, 
as described in Max [7]. Using a linear Taylor approximation to the lens distortion based at each sphere's 
center, we approximated the film plane projections of E and F by ellipses E' and F' in the fisheye case 
also, as in Max [8]. We then approximated the projection of the profile of the conical part of the surface 
by two lines tangent to the two ellipses, as in the perspective case. For the fisheye case, we found 
the common tangents to the two ellipses using iteration. However, for the perspective case, one could 
apply a technique similar to that in Blinn [2], based on a plane through the eye which slices the cone 
in a circular cross section. If the points of tangency are labeled as in Figure 3, the cone-sphere can 
be scan converted as the set of points inside the ellipses E' or F', or inside the quadrilateral ABCD. 
In the case that one ellipse is entirely contained inside the other, the projection is just the area 
inside the larger ellipse. Anti-aliasing Let the ellipse E' be defined by the equation e(x,y) = 0, where 
e(x,y) is a quadratic polynomial which takes the value 1 at the ellipse center. Then a(x,y) = min(1.,max(0.,.5+k2e(x,y))) 
gives a suitable anti-aliasing mask function for pixels to the left of line AB in Figure 3. The constant 
k is taken proportional to the linear B kl E' Figure 3. The projection ellipses E' and F' of two spheres 
E and F, and the profile lines L~ and L 2 of the cone between them. dimensions of the ellipse, and controls 
the spreading of the anti- aliasing filter. An analogous mask b(x,y) can be defined from the equation 
f(x,y) of the ellipse F', for pixels to the right of line CD. Similarly, the equations for the lines 
BC and AD can be used for anti- aliasing. Let Ni be a downward pointing unit normal to line L~ in figure 
3, and N 2 be an upward pointing unit normal to line L 2. Let c(x,y) = min (1., max (0., .5 + k (Nl 
((x,y) - B)))) and d(x,y) = min (1., max (0., .5 + k (N2 ((x,y) - A)))). Then the product c(x,y) d(x,y) 
gives an anti-aliasing function for the pixels between the lines AB and CD. For scan conversion, a bounding 
rectangle was found enclosing the two ellipses E' and F' and enlarged slightly to enclose all pixels 
whose anti-aliasing mask was non-zero. Lines parallel to L 1 and L 2 in Figure 3, but slightly displaced 
for anti-aliasing, were used to slice away pixels where the mask was sure to be zero. The mask was then 
evaluated on the remaining pixels, using vectorized compu- tations along horizontal scan lines. Compositing 
We sorted all the objects in a frame by distance from the camera, and then composited the objects in 
order from farthest to closest, using the formula Newlmage = (1 - Mask) * Currentlmage + NewObject As 
in Porter and Duff [9], the above formula assumes that the shading for NewObject has already been multiplied 
by Mask. When desired, the motion blur algorithm of Max and Lerner [ 10] is applied to the NewObject 
and Mask rasters before the compositing. This algorithm gains coherence efficiency by requiring a single 
velocity for each object. The velocity of a cone-sphere is thus taken as the average of the velocities 
of the projections of its two sphere centers. If the velocity difference between successive spheres is 
moderate, blending can cover up the velocity disparity between successive overlapping cone-spheres. 
 Blending In a curving tube approximated by a collection of cone- spheres, two consecutive cone-spheres 
join at a common sphere, forming an elbow. The outer surface of the elbow is formed by a piece of the 
sphere, to which the two successive cones are tangent, resulting in a smooth junction of surfaces. But 
at the inside of the elbow, the two cones intersect directly, which would give non-smooth shading. Therefore 
we decided to blend the conical shading together at the joints. Figure 4 shows three successive cone-spheres. 
The lines L 3 and L 4 join the intersections of successive pairs of profiles lines. Using the equations 
of these two lines, as in the section on anti- aliasing, one can define a non-negative blending function 
which takes the value 1 between the two lines, and decreases linearly to zero to the left of L 3 and 
to the right of L 4. This blending function is multiplied by the anti-aliasing mask of the cone-sphere 
to get the mask actually used in the compositing process described above. Thus, if the center cone sphere 
of figure 4 is composited last, the shading to the right of L 4 is a blend of the shading for the center 
and the right hand cone-spheres. Since this blend provides a smooth transition, it is not necessary to 
decide which pixels lie in the surface of the sphere $3.  ~ Computer Graphics, Volume 24, Number 4, 
August 1990 S3 C3 'C~ \ S2 L3 Sl Cl S4 C4 Figure 4. Three consecutive cones joining spheres 
S~, S 2, $3, and S 4. and shade them appropriately. Instead, the shading for an infinite cone is used 
within the outline mask of each cone sphere, and the blending smooths the shading across the spherical 
elbow. The width of the linear strip to the right of L 4 where the blending function decreases from 1 
to zero must be set at a compro- mise value, wide enough to give a reasonably smooth transition, but 
not so wide that the anti-aliasing mask along the profile of S 3 causes an abrupt jump to zero. One problem 
with the "2~ -D" compositing method is that the sorting order may change from frame to frame as the object 
and/ or camera motions change the distance relationships. For example, the center cone-sphere in Figure 
4 may be in front of the right-hand one in one frame, and behind it in the next, causing the region of 
blending between the two to "pop" from the right side of line L 4 to the left side. We tried to alleviate 
this problem by changing the shading computations linearly across each cone-sphere, so that successive 
ones matched more closely across their common sphere. We also found this popping less noticeable when 
texture and bump mapping were added. Shading We wanted to develop shading and texture mapping computations 
for the conical surfaces, which could be vectorized across horizontal scan lines so as to run efficiently 
on our vector supercomputer, the Fujitsu VP 200. Both shading and texture require the angular coordinate 
around the circular cross section of the cone. For simplicity, we computed the shading as if the projec- 
tion were orthogonal. Figure 5 shows the projection of a circular section E perpendicular to the axis 
CF of a cone, with P a point on E. Let BC and PD be lines in the plane of E, which are also parallel 
to the picture plane. Then BC is the radius of E, and PD is this radius times sin0, where 0 is an angular 
measure around E, starting from the point closest to the viewer. Therefore, 0 = arcsin(PD/BC). The length 
PD is a linear function of the projected (x,y) coordinates of P, as is the length QD. Therefore we approximated 
BC by QD, and took 0 = arcsin(t), where t = PD/QD, the quotient of two linear functions in x and y. The 
angle 0 is the first texture coordinate, and the distance v of the circular cross section along the axis 
is the second. This second coordinate can be computed as G + Hu, where G and H are also linear in x and 
y, and u = cos0 =~/1-t 2. The term Hu adds the appropriate curvature to the sections of constant v. To 
find the unit normal N to the cone at P, let N 1 be a unit vector along the axis, let N 2 be a unit vector 
perpendicular to N~ and parallel to the picture plane, and let N 3 be a unit vector perpendicular to 
both N~ and N 2, chosen to face towards the viewer. Then N = N~ sin[3 + N 2 cos~ sin0 + N 3 cos[~ cos0, 
where 13 is the angle of opening of the cone, positive if the cone is closing down in the direction N 
l, and negative if the cone is opening out. Q E F Figure 5. The orthogonal projection of a cross section 
circle E of radius CB of a cone with axis CF. In this figure, the same letters refer both to 3-D points 
and their projections, but since the projection is orthogonal and the lengths under discussion are along 
lines parallel to the picture plane, this makes no difference.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97886</article_id>
		<sort_key>63</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Particle transport and image synthesis]]></title>
		<page_from>63</page_from>
		<page_to>66</page_to>
		<doi_number>10.1145/97879.97886</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97886</url>
		<abstract>
			<par><![CDATA[The rendering equation is similar to the linear Boltzmann equation which has been widely studied in physics and nuclear engineering. Consequently, many of the powerful techniques which have been developed in these fields can be applied to problems in image synthesis. In this paper we adapt several statistical techniques commonly used in neutron transport to stochastic ray tracing and, more generally, to Monte Carlo solution of the rendering equation. First, we describe a technique known as <i>Russian roulette</i> which can be used to terminate the recursive tracing of rays without introducing statistical bias. We also examine the practice of creating ray trees in classical ray tracing in the light of a well-known technique in particle transport known as <i>splitting</i>. We show that neither ray trees nor paths as described in [10] constitute an optimal sampling plan in themselves and that a hybrid may be more efficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010346</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14183802</person_id>
				<author_profile_id><![CDATA[81100529394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arvo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Systems Division of Hewlett-Packard, 300 Apollo Drive, Chelmsford, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14068580</person_id>
				<author_profile_id><![CDATA[81100166914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kirk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Computer Science 256-80, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Albert, G. E., "A general theory of stochastic estimates of the Neumann series for solution of certain Fredholm integral equations and related series," in Symposium on Monte Carlo Methods, edited by M. A. Meyer, J. Wiley, New York 1956, pp. 37-46.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cercignani, Carlo, "The Boltzmann Equation and its Applications," Springer-Verlag, New York, 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Clark, Francis H., "Methods and data for reactor shield calculations," in Advances in Nuclear Science and Technology, No. 5, 1971, pp. 95-183.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter, and Loren Carpenter, "Distributed Ray Tracing," Computer Graphics, 18(3), July 1984, pp. 137-145.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Duderstadt, J. J., and W. R. Martin, "Transport Theory," J. Wiley, New York, 1979.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ferry, D. K., "Semi-Classical Boltzman Transport Theory in Semiconductors," in Physics of Nonlinear Transport in Semiconductors, New York, 1979.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile, "Modeling the interaction of light between diffuse surfaces," Computer Graphics, 18(3), July 1984, pp. 213-222.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hall, R. A., and D. P. Greenberg, "A testbed for realistic image synthesis," IEEE Computer Graphics and Applications, 3(10), November, 1983, pp. 10-20.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hammersley, J. M., and D. C. Handscomb, "Monte Carlo Methods," Chapman and Hall, 1964.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T., "The Rendering Equation," Computer Graphics, 20(4), August 1986, pp. 143-150.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>7050</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kalos, M. H., and Paula A. Whitlock, "Monte Carlo Methods, Volume I: Basics," J. Wiley, New York, 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lewis, E. E., and W. F. Miller, Jr., "Computational Methods of Neutron Transport," J. Wiley, New York, 1984.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert, and John R. Howell, "Thermal Radiation Heat Transfer," Hemisphere Publishing Corp., Washington DC, 1981.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37417</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Snyder, John M. and Alan H. Barr, "Ray Tracing Complex Models Containing Surface Tessellations," Computer Gaphics, Vol. 21, No. 4, July 1987, pp. 119-126.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Spanier, Jerome, and Ely M. Gelbard, "Monte Carlo Principles and Neutron Transport Problems," Addison- Wesley Publishing Company, 1969.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Michael F. Cohen, and Donald P. Greenberg, "A two-pass solution to the rendering equation: a synthesis of ray-tracing and radiosity methods," Computer Graphics, 21(4), July 1987, pp. 311-320.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Ward, Gregory J., Francis M. Rubinstein, and Robert D. Clear, "A Ray Tracing Solution for Diffuse Interreflection," Computer Graphics, 22(4), August 1988, pp. 85-92.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display," Communications of the ACM, 32(6), June 1980, pp. 343-349.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Williams, M. M. R., "Mathematical Methods in Particle Transport Theory," J. Wiley, New York, 1971.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Particle Transport and Image Synthesis James 
Arvo* David Kirk*~ *Apollo Systems Division of Hewlett-Packard 300 Apollo Drive Chelmsford, MA 01824 
 *t California Institute of Technology Computer Science 256-80 Pasadena, CA 91125 Abstract The rendering 
equation is similar to the linear Boltzmann equation which has been widely studied in physics and nu-clear 
engineering. Consequently, many of the powerful tech- niques which have been developed in these fields 
can be applied to problems in image synthesis. In this paper we adapt several statistical techniques 
commonly used in neu- tron transport to stochastic ray tracing and, more generally, to Monte Carlo solution 
of the rendering equation. First, we describe a technique known as Russian roulette which can be used 
to terminate the recursive tracing of rays without introducing statistical bias. We also examine the 
practice of creating ray trees in classical ray tracing in the light of a well-known technique in particle 
transport known as split-ting. We show that neither ray trees nor paths as described in [10] constitute 
an optimal sampling plan in themselves and that a hybrid may be more efficient. CR Categories and Subject 
Descriptors: 1.3.7-[Computer Graphics]: Three-Dimensional Graphics and Realism; 1.3.3--[Computer Graphics]: 
Picture/Image Generation; General Terms: Algorithms, Graphics Additional Key Words and Phrases~ BoItzmann 
equa- tion, Monte Carlo, particle transport, radiosity, ray tracing, rendering equation. Introduction 
The rendering equation [10] provides a framework in which aLl current image synthesis techniques can 
be be viewed as methods of approximation. Both radiosity [7] and ray trac- ing [18] are examples of approximation 
because they neglect various optical phenomena in order to yield a reasonable method of solution. An 
alternative, introduced by Kajiya, is to solve the rendering equation directly via Monte Carlo techniques 
similar to those developed for neutron transport problems. Such techniques have a long history and have 
 Pelmission to copy without fee all or part of this material is granted provided that the copies are 
not made or distributed for direct commercial advantage, the ACM cop)right notice and the title of the 
publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
been applied to integral equations of essentially the same form as the rendering equation since the 50's 
[1]. Kajiya demonstrated the feasibility of this approach in image synthesis by successfully solving 
the rendering equa- tion for scenes including both specular and diffuse reflectors. Though the level 
of realism attainable in this way is very high, the cost can be prohibitive due to slow convergence of 
the Monte Carlo method. Other more efficient approaches have been devised [16,17] but none have completely 
obvi- ated the need for stochastic approximation without sacrific- ing certain modes of light transport. 
 Related statistical approaches have been applied to ray tracing. Cook, et al. [4] described a stochastic 
sampling technique termed distributed ray tracing which provides a means of anti-aliasing as well as 
simulating effects such as motion blur, penumbrae, depth of field, and fuzzy reflec- tions. Its central 
idea is that features in the environment which vary in time and space can be sampled stochastically to 
estimate their contribution to the final image. Both of these paradigms have a great deal in common with 
Monte Carlo techniques applied to particle transport problems in other fields.  2 Particle Transport 
The class of particle transport problems consists of those problems which seek to characterize the distribution 
of ide- alized particles takiug account of their motion and inter-action with a medium [5,12,19]. Such 
problems appear in nuclear engineering as neutron transport [15], in heat trans- fer as photon transport 
[13], and in semiconductor device simulation as carrier transport [6]. Many of the equations governing 
these transport processes ultimately derive from the Boltzmann equation which arose from the kinetic 
theory of gases. In its simplest form the linear Boltzmann equation can be written as (P) = S(P) + f 
K(P' --~ P) q,(P')de' (I) Jfl where P represents particle position, direction, and energy, and ~(P) 
is the density of radiation at P due to emission from the source S as well as contributions scattered 
into P from all P' [11]. The function K is known as the scat- teeing kernel, and the domain of integration, 
~, consists of  &#38;#169;1990 ACM-0-89791-344-2/90/008/0063 $00.75 63 O SIGGRAPH '90, Dallas, August 
6-10, 1990 i all positions, directions~ and energies. This is a notoriously difficult equation to solve 
analytically in all but the most trivial problem instances [2,5]. This is true of the rendering equation 
as well which is essentially a variant of the linear Boltzmaun equation. The principal difference is 
that the scattering kernel is rephrased as a geometry term, g~ which accounts for occlusion and inverse 
square attenuation, and a trivariate scattering term, p, whose arguments are sur-face points (See [10]). 
The latter encodes the directions of incidence and reflection implicitly through the positions of the 
source and destination elements relative to the point of reflection. The similarity of the rendering 
equation to the linear Boltzmann equation suggests that many of the power- ful techniques which have 
been developed for other particle transport problems may be applied to problems in image synthesis. We 
note that there are several aspects in which the ren- dering equation is somewhat more tractable than 
the trans- port equations in fields such as nuclear engineering. 1) The particles (i.e. photons) do not 
influence one another, alter the environment, carry a charge, or replicate via fission. Thus scattering 
is independent of as well as external forces, making the equation linear. 2) In the absence of participating 
media, collisions occur only at surfaces. The particles therefore have a rela- tively large mean free 
path. 3) We seek only the steady state solution, not transient distributions on the way to equilibrium. 
These properties manifest themselves largely in the rela-tively simple form of the scattering kernel 
which is com-prised of the bidirectional reflectance functions associated with the surfaces. After probabilistically 
determining a new particle direction at each scattering event the next col].ision- site along the random 
walk is completely determined, elim- inating stochastic distance calculations. However, there are two 
respects in which this transport process is made more di~cult than typically encountered in other disciplines. 
First, the geometry of the simulated environments can be arbitrarily complex. While simulations of reactor 
cores and semiconductor devices benefit from fairly constrained geometries and exploit special properties 
of lattices, cylin- ders, slabs, etc. [12], the trend in computer graphics is to move toward greater 
and greater scene complexity. This is exemplified by recent work involving billions of geomet- rical 
primitives [14]. This can be further complicated by time-dependent scene geometry. Simulation of the 
resulting motion blur requires time averaging steady-state solutions at intermediate scene configurations. 
Secondly, the problem of interest in image synthesis is to compute the intensity of illumination impinging 
on a single point, the "eye", through small apertures which correspond to "pixels". Analogous situations 
occur in reactor shield-ing problems which simulate point radiation detectors [3]. These are inherently 
more diiBcnlt to solve than the typical problems which involve flux averages over volumes. Many important 
problems in particle transport do not admit analytic solutions and are also prohibitively expensive to 
solve via numerical integration due to the high dimension of the phase space in which they operate (e.g. 
three spa-tial dimensions, two directional dimensions, and an energy dimension). The only recourse for 
solving these types of problems appears to be Monte Carlo methods which track the behavior of large numbers 
of particles obeying the pre- scribed laws of motion expressed as scattering probabilities. Each particle 
undergoes a sequence of collisions or scatter-ing events which probabilistically alter its trajectory 
at each collision-site and contribute to the history of the particle. Each particle history, or random 
walk, is used as a statistical estimator of average case behavior. Ray tracing is a mecha- nism for computing 
points of collision, and a stochastic ray path [10] is the resulting random walk of a particle. The rendering 
equation provides a link which allows us to view image synthesis in terms of particle transport. Through 
this connection we can gain useful insight into the features and limitations of image synthesis techniques. 
For example, consider the use of decoupled passes of ray tracing and radiosity to model specular and 
diffuse modes of transport independently. It has been observed that sim-ply combining the results of 
these passes fails to account for some important phenomena of geometrical optics [16]. The most obvious 
example is a caustic formed by specularly transmitted or reflected light falling on a diffuse surface. 
Both classical ray tracing and radiosity totally neglect this mode o£ transport, therefore this deficiency 
cannot be reme- died by summing their contributions a posteriori. Wallace describes a solution for this 
particular case of specular-to- diffuse transport, but it is impossible to account for all such sequences 
of transport as special cases. This phenomenon has been observed in other linear transport problems and 
is attributed to the fact that equation 1, though linear in the source term, S, is nonlinear with respect 
to the scat-tering kernel, K. While the linearity in S allows us to sum the independent contributions 
made by different sources and wavelengths of light, the analogous decoupling fails when the kernel is 
partitioned into, for example, Kspec +Kdiff. A faith- fnl simulation of all modes of transport can only 
be achieved by coupling them in the solution process. 3 Russian Roulette The albedo of a surface is the 
probability that an incident particle will be re-radiated after collision [3]. In Monte Carlo simulations 
this probability is normally used to adjust a nu- merical weight associated with the particle rather 
than prob- abilistically terminating the history. This technique, termed implicit capture [12], has better 
statistical properties owing to longer particle histories. A property of implicit capture is that particle 
histories can only terminate at surfaces of zero albedo or by leakage, that is, by escaping the system. 
However, it is nearly always impractical to continue tracing a path until one of these conditions is 
met. Even if we could guarantee the eventual termination of every history, we would spend an inordinate 
amount of time computing collisions involving particles of negligible weight. One solution is to place 
a limit on the number of scattering events in a particle history and to ig- nore all contributions beyond 
this point. A better solution is to use weight cuto~ which truncates the particle's history only when 
its weight falls below some threshold [12]. The idea of using weight cutoff to terminate ray tracing 
recursion was introduced by Hall [8] and termed adaptive tree depth control. Both of these techniques 
are commonly employed in ray tracing implementations in order to avoid excessively deep ray trees and, 
in extreme cases, even unending recur-sion due to opposing mirrors or total internal reflection. The 
difficulty with this type of policy is that truncation intro- ~ if weight < Thresh then begin sample 
s uniformly from [0, 1] if s < .P then terminate path else weight e-weight~(1 -P) end Figure 1: The Russian 
Roulette algorithm which is used to ter- minate particles with insignificant weights without introducing 
bias. The value P can be any probability less than 1. duces a systematic bias to the estimator which 
may become significant if applied to a large number of paths. Fortunately, this bias can be eliminated 
by a simple tech- nique known as Russian roulette [3,12,15]. According to this technique, once the weight 
of a particle has fallen below a pre-defined threshold we terminate its history probabilisti- cally, 
with some given probability, P. If the particle "sur- vives," its weight is increased by a factor of 
1/(1 - P). Let w denote the weight of a particle before playing Russian roulette and let the random variable 
W denote its subse- quent weight. The expected value of W, denoted E(W), is then given by E(W) = Prob( 
termination ) 0 + 113 Prob( survival ) * 1--~- ff (2) But the probability of termination is P, and that 
of survival is 1 - P, so we have W P*0 + (l-P)* 1-P -w (3) which is the the original weight of the particle. 
On average, then, the particle will have the appropriate weight. We may therefore ignore the majority 
of the insignificant particles by artificially inflating the contributions of those which sur- vive. 
Although eliminating the bias in this way does in fact increase the variance slightly, if applied to 
particles of suf- ficiently low weight this can be more than compensated for by the additional samples 
we can collect for the same overall cost. Perhaps more importantly, eliminating the bias guar- antees 
that we will converge to the correct result in the limit if the sample mean converges at all. The Russian 
Roulette algorithm is outlined in figure 1.  4 Splitting: Paths vs. Trees Another technique which is 
commonly used to improve the efficiency of particle transport simulations is splitting.While Russian 
roulette reduces the number of scattering events at the expense of a slight increase in variance, the 
goal of splitting is to reduce variance by introducing more scatter- ing events. It works by partitioning 
a single particle into a multiplicity of particles, tracking their diverging histories independently, 
then down weighting their contributions ap- propriately. In reactor simulations splitting is used when 
a neutron encounters a region which is particularly important or of high sensitivity. Though tracking 
many light weight   Computer Graphics, Volume 24, Number 4, August 1990 particles is costly, it is 
justified if the variaucc is reduced sufficiently. Because it is used strictly as a variance reduc- tion 
technique and not as a means of simulating fission, it is applicable to photon transport as well. In 
the classical approach to ray tracing introduced by Whitted [18], a single ray can recuxsively spawn 
a multiplic- ity of rays at surfaces which both reflect and transmit light specnlarly. Cook, et al. [4] 
generalized this approach by replacing the deterministic branching steps by probabilis- tic ones distributed 
over spatial and temporal dimensions. Through the generality of Monte Carlo integration, this al- lowed 
a wider variety of optical effects to be simulated with the same number of samples. The resulting method 
of prob- abilistic branching is essentially an application of splitting. As Kajiya observed, however, 
this approach creates un- necessarily bushy ray trees and expends most of the effort at the leaves (higher 
generation rays) which make only a small contribution [10]. Though Russian roulette (Sec. 3) can help 
to limit the depth of these trees by terminating low-weight branches fairly, it does not in itself reduce 
the bushiness of the tree. Kajiya suggests that it is more ap- propriate to trace paths instead of trees. 
At each collision event, exactly one ray is followed by probabilistically choos- ing one scattering mode 
to sample from; for example, either the reflected or the transmitted light. We can compare the two approaches 
using the figure of merit [12] or efficiency[11] of the resulting estimators. This measure, which we 
shall denote by ~, is defined by 1 -(4) if2 T where 0.~ is the variance of the estimator and ~-is the 
cost associated with drawing a single sample. In this case a sam- ple consists of a complete particle 
history. At each collision event we wish to sample the incident illumination in such a way that the entire 
estimator is as efficient as possible. The idea behind path tracing is to use a single particle, thereby 
reducing v, which includes the cost of tracing each ray in the envkonment. This cost can be considerable 
for complex environments. On the other hand, averaging many particle histories leads to an estimator 
with a smaller variance, 0 "2. Are there any situations in which this reduction in variance outweighs 
the cost of tracking multiple particle histories? Though it is difficult in general to estimate both 
~-and 0.2 for any given strategy, we can nevertheless construct exam- ples in which splitting confers 
a clear advantage. Consider a particle which encounters N ideal mirror re- Rectors before reaching a 
diffuse reflector. If we estimate the incident illumination at the diffuse surface by tracing a single 
path, obtaining a variance of o-1 z at a cost v, then the efficiency of the entire estimator is 1 el 
-0.~(No~ + r) (5) where a is the average cost of tracing a single ray in the environment. On the other 
hand, if we achieve a slightly lower variance, 2 paths of the same a,~, by splitting into m cost after 
tracing a single path to the diffuse reflector then the efficiency of the entire estimator is 1  ~ 
= 0.~(Na + mr) (6) To see that splitting can be advantageous in some instances we need only observe that 
 O StGGRAPH '90, Dallas, August 6-10, 1990 ~rn __ Cr12 N~o¢ el o'~ > 1 (7) This shows that for any given 
a and v, after a sufficiently large number of mirror reflections splitting into multiple paths is a more 
efficient strategy than continuing a single path. Another instance in which splitting is advantageous 
is when multiple samples reduce the variance significantly. More precisely, if at any point along a path 
we can employ m samples of equal cost to estimate the incident illumination 2 such that and achieve 
a variance O'm ~m < -- (s) m where o-12 is the variance of a singe sample, then em > el and we have 
an increase in el~iciency. Under certain conditions, such a reduction in variance can be obtained through 
sample stratification, a common Monte Carlo technique in which the domain of integration is partitioned 
into disjoint regions which are sampled independently. If the incident illumination at a surface point 
can be separated into low-variance strata whose mean values differ greatly, then splitting into one path 
for each stratum will result in a more efficient estimator [9]. Two strata which will often meet these 
criteria are the intense direct illumination from light sources and the attenuated indirect illumination 
from the remainder of the environment [10]. While ray trees generally place too much of the compu- tational 
burden at the leaves, these examples indicate that there exist cases in which trees lead to greater efficiency 
than a strict application of path tracing. This suggests that a hybrid method can achieve higher efficiency 
than either strategy alone if inexpensive heuristics for strategy selection are employed. Conclusion 
 As the level of realism in computer generated images has grown, the underlying illmnination models have 
encountered many of the complications common to other particle trans- port problems. This is not surprising 
when one views the rendering equation as a form of the linear Boltzmann equa- tion, a transport equation 
which has application in many ar- eas of science and engineering. We can exploit this similarity by drawing 
upon techniques developed for other transport problems and applying them to image synthesis. Fields such 
as nuclear engineering are rich sources of statistical tech-niques which are applicable to stochastic 
ray tracing and to Monte Carlo solution of the rendering equation. As ex- amples, we have discussed the 
uses of Russian roulette and splitting in this context. Finally, because image synthesis presents additional 
challenges due to features such as com- plex scene geometry, techniques developed for image synthe- sis 
may also be useful in other domains. References [1] Albert, G. E., "A general theory of stochastic estimates 
of the Neumann series for solution of certain Fredholm integral equations and related series," in Symposium 
on Monte Carlo Methods, edited by M. A. Meyer, J. Wiley, New York 1956, pp. 37-46. [2] Cercignani, Carlo, 
"The Boltzmann Equation and its Applications," Springer-Verlag, New York, 1988. [3] Clark, Francis H., 
"Methods and data for reactor shield calculations," in Advances in Nuclear Science and Tech- nology, 
No. 5, 1971, pp. 95-183. [4] Cook, Robert L., Thomas Porter, and Loren Carpenter, "Distributed Ray Tracing," 
Computer Graphics, 18(3), July 1984, pp. 137-145. [5] Duderstadt, J. J., and W. R. Martin, "Transport 
The- ory," J. Wiley, New York, 1979. [6] Ferry, D. K., "Semi-Classical Boltzman Transport The- ory in 
Semiconductors," in Physics of Nonlinear Trans- port in Semiconductors, New York, 1979. [7] Coral, Cindy 
M., Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile, "Modeling the interac- tion of light 
between diffuse surfaces," Computer Graph- ics, 18(3), July 1984, pp. 213-222. [8] Hall, R. A., and D. 
P. Greenberg, "A testbed for realistic image synthesis," IEEE Computer Graphics and Applica- tions, 3(10), 
November, 1983, pp. 10-20. [9] Hammersley, J. M., and D. C. Handscomb, "Monte Carlo Methods," Chapman 
and Hall, 1964. [10] Kajiya, J. T., "The Rendering Equation," Computer Graphics, 20(4), August 1986, 
pp. 143-150. [11] Kalos, M. H., and Paula A. Whitlock, "Monte Carlo Methods, Volume I: Basics," J. Wiley, 
New York, 1986. [12] Lewis, E. E., and W. F. Miller, Jr., "Computational Methods of Neutron Transport," 
J. Wiley, New York, 1984. [13] Siegel, Robert, and John R. Howell, "Thermal Radia- tion Heat Transfer," 
Hemisphere Publishing Corp., Wash- ington DC, 1981. [14] Snyder, John M. and Alan H. Barr, "Ray Tracing 
Com- plex Models Containing Surface Tessellations," Computer Graphics, Vol. 21, No. 4, July 1987, pp. 
119-126. [15] Spanier, Jerome, and Ely M. Gelbavd, "Monte Carlo Principles and Neutron Transport Problems," 
Addison-Wesley Publishing Company, 1969. [16] Wallace, John R., Michael F. Cohen, and Donald P. Greenberg, 
"A two-pass solution to the rendering equa- tion: a synthesis of ray-tracing and radiosity methods," 
Computer Graphics, 21(4), July 1987, pp. 311-320. [17] Ward, Gregory J., Francis M. Rubinstein, and Robert 
D. Clear, "A Ray Tracing Solution for Diffuse Interreflec- tion," Computer Graphics, 22(4), August 1988, 
pp. 85-92. [18] Whitted, Turner, "An Improved Illumination Model for Shaded Display," Communications 
of the ACM, 32(6), June 1980, pp. 343-349. [19] Williams, M. M. R., "Mathematical Methods in Parti- cle 
Transport Theory," J. Wiley, New York, 1971.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97887</article_id>
		<sort_key>67</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Rendering CSG models with a ZZ-buffer]]></title>
		<page_from>67</page_from>
		<page_to>76</page_to>
		<doi_number>10.1145/97879.97887</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97887</url>
		<abstract>
			<par><![CDATA[The ZZ-buffer is a simple acceleration scheme for ray tracing that can be applied to a wide variety of scenes, including those with small features, textured and transparent surfaces, shadows and penumbrae, and depth-of-field effects. In this paper, we describe how the ZZ-buffer algorithm can be adapted to the rendering of scenes defined by constructive solid geometry operations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P63624</person_id>
				<author_profile_id><![CDATA[81100188207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salesin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, Stanford University, Stanford, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030834</person_id>
				<author_profile_id><![CDATA[81100171458]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jorge]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stolfi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DEC Systems Research Center, 130 Lytton Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amanatides, J., "Ray Tracing with Cones," Computer Graphics (SIGGRAPH "84) vol. 18 no. 3 (July 1984), 129-135.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37409</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arvo, J. and Kirk, D., "Fast Ray Tracing by Ray Classification," Computer Graphics (SIGGRAPH '87) vol. 21 no. 4 (July 1987), 55-64.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801135</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Atherton, P. R., "A Scanline Hidden Surface Removal Procedure for Constructive Solid Geometry," Computer Graphics (SIGGRAPH '83) vol. 17 no. 3 (July 1983), 73-82.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Barr, A, H., "Superquadrics and Angle Preserving Transformations," IEEE Computer Graphics and Applications, vol. 1 no. 1 (1981), 11-23.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. E, "A Generalization of Algebraic Surface Drawing," ACM Transactions on Graphics, vol. 1 no. 3 (July 1982), 236- 256.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Carpenter, L., "The A-buffer, an Antialiased Hidden Surface Method," Computer Graphics (SIGGRAPH '84) vol. 18, 3 (July 1984), 103-108.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Catmull, E., "A Subdivision Algorithm for Computer Display of Curved Surfaces," Ph.D. Thesis, University of Utah, Salt Lake City, December 1974.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Chazelle, B. and Guibas L. J., "Fractional Cascading," Algorithmica, vol. 1, no. 2 (1986), 133-191. Also DEC Systems Research Center report # 12 (June 1986).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics vol. 5, no. 1 (January 1986), 51-72.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Porter, T., and Carpenter, L., "Distributed Ray Tracing," Computer Graphics (SIGGRAPH '84) vol. 18 no. 3 (July 1984), 137-145.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Dipp6, M. A. Z., and Wold, E. H., "Antialiasing through Stochastic Sampling," Computer Graphics (SIGGRAPH '85) vol. 19 no. 3 (July 1985), 69-78.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Foley, J., van Dam, A., Feiner, S., and Hughes, J. Computer Graphics: Principles and Practice, 2nd Ed., Addison-Wesley, Reading, MA (1990).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42460</ref_obj_id>
				<ref_obj_pid>42458</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Fournier, A. and Fussell, D., "On the Power of the Frame Buffer," ACM Transactions on Graphics voI. 7 no. 2 (April 1988), 103-128.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Glassner, A. S., "Space Subdivision for Fast Ray Tracing," IEEE Computer Graphics and Applications, vol. 4 no. 10 (October 1984), 15-22.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15898</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Goldfeather, J., Huitquist, J. P. M., and Fuchs, H., "Fast Constructive Solid Geometry Display in the Pixel-Powers Graphics System," Computer Graphics (SIGGRAPH '86) vol. 20 no. 4 (August 1986), 107-116.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Guibas L. J. and Stolfi J., "Ruler, Compass, and Computer: The Design and Analysis of Geometric Algorithms," in Theoretical Foundations of Computer Graphics and CAD, R. A. Earnshaw, ed., NATO ASI Series F, vol. 40, Springer-Verlag (1988), 111-165. Also DEC Systems Research Center report # 37 (February 1989).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Haines, E. A. and Greenberg, D. P., "The Light Buffer: A Ray Tracer Shadow Testing Accelerator," IEEE Computer Graphics and Applications, vol. 6 no. 9 (September 1986), 6-15.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801136</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., "Ray Tracing Algebraic Surfaces," Computer Graphics (SIGGRAPH '83) vol. 17 no. 3 (July t983), 83-90.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Heckbert, P. S. and Hanrahan, P., "Beam Tracing Polygonal Objects," Computer Graphics (SIGGRAPH '84) vol. 18 no. 3 (July 1984), 119-127.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Kay, D. S., "A Transparency Refraction and Ray Tracing Model for Computer Synthesized Images," Master's thesis, Comell University, Ithaca, New York, 1979.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807438</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Kay, D. S., and Greenberg, D. P., "Transparency for Computer Synthesized Images," Computer Graphics (SIGGRAPH '79) vol. 13 no. 2 (August 1979), 158-164.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Kay, T. L. and Kajiya, J., "Ray Tracing Complex Scenes," Computer Graphics (SIGGRAPH '86) vol. 20 no. 4 (August 1986), 269-278.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Lee, M. E., Redner, R. A., and Uselton, S. P., "Statistically Optimized Sampting for Distributed Ray Tracing," Computer Graphics (SIGGRAPH '85) vol. 19 no. 3 (July 1985), 61-67.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D. P., "Generating Antialiased Images at Low Sampiing Densities," Computer Graphics (SIGGRAPH '87) vol. 21 no. 4 (July 1987), 65-72.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378514</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D. P., and Netravali, A. N., "Reconstruction Filters in Computer Graphics," Computer Graphics (SIGGRAPH '88) vol. 22 no. 4 (August 1988), 221-228.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Moore, R. E., Interval Analysis, Prentice-Hall, Englewood Cliffs, N. j. (1966).]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Porter, T. and Duff, T., "Compositing Digital Images," Computer Graphics (SIGGRAPH '84) vol. 18 no. 3 (July 1984), 253-259.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74362</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Painter, J. and Sloan, K., "Antialiased Ray Tracing by Adaptive Progressive Refinement," Computer Graphics (SIG- GRAPH '89) vol. 23, no. 3 (July 1989), 281-288.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>108781</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Pratt, W. K., Digital Image Processing, Wiley and Sons, New York (1978).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Okino, N., Kakazu, Y., and Morimoto, M., "Extended Depth- Buffer Algorithms for Hidden-Surface Visualization," IEEE Computer Graphics and Applications vol. 4, no. 5 (May 1984), 79-88.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37435</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., Salesin, D. H., and Cook, R. L., "Rendering Antialiased Shadows with Depth Maps," Computer Graphics (SIGGRAPH '87) vol. 21 no. 4 (July 1987), 283-291.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Rossignac, J. R. and Requicha, A. A. G., "Depth Buffering Display Techniques for Constructive Solid Geometry," IEEE Computer Graphics and Applications vol. 6, no. 9 (September 1986), 29-39.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>51123</ref_obj_id>
				<ref_obj_pid>49155</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Rossignac, J. R. and Voelcker, H. B., "Active Zones in CSG for Accelerating Boundary Evaluation, Redundancy Elimination, Interference Detection, and Shading Algorithms," ACM Transactions on Graphics vol. 8, no. 1 (January 1989), 51-87.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Roth, S. D., "Ray Casting for Modeling Solids," Computer Graphics and Image Processing vol. t8 (1982), 109-144.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Salesin, D., "The Fuzzy Buffer: A Stochastic Antialiased Hidden Surface Algorithm," Ph. D. Programming Project Report, Stanford University (1986).]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Salesin, D. and Stolfi, J., "The ZZ-Buffer: A Simple and Efficient Rendering Algorithm with Reliable Antialiasing," Proceedings of the PIXIM '89 Conference (Hermes Editions, Paris, September 1989), 451-466.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74365</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[S6quin, C. G., Smyrl, E. K., "Parameterized Ray Tracing," Computer Graphics (SIGGRAPH '89) vol. 23 no. 3 (July 1989), 307-314.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Thacker, C. P., Stewart, L. C., and Satterthwaite, E. H. Jr., "Firefly: A Multiprocessor Workstation," DEC Systems Research Center, Research Report 23 (December 1987).]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Wamock, J. E., "A Hidden-Surface Algorithm for Computer- Generated Halftone Pictures," Computer Science Department, University of Utah, TR 4-15 (June 1969).]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357335</ref_obj_id>
				<ref_obj_pid>357332</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Weghorst, H., Hooper, G., and Greenberg, D. E, "Improved Computational Methods for Ray Tracing," ACM Transactions on Graphics, vot. 3, no. 1 (January 1984), 52-69.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Williams, L., "Casting Curved Shadows on Curved Surfaces," Computer Graphics (SIGGRAPH '78) volt 12 no. 3 (August 1978), 270-274.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Rendering CSG Models with a ZZ-Buffer David Salesin* 
and Jorge Stolfit *Computer Science Department Stanford University Stanford, CA 94305  t DEC Systems 
Research Center 130 Lytton Avenue Palo Alto, CA 94301 ABSTRACT The ZZ-buffer is a simple acceleration 
scheme for ray tracing that can be applied to a wide variety of scenes, including those with small features, 
textured and transparent surfaces, shadows and penumbrae, and depth-of-field effects. In this paper, 
we describe how the ZZ-buffer algorithm can be adapted to the rendering of scenes defined by constructive 
solid geometry operations. CR Categories and Subject Descriptors: 1.3.3 [Computer Graph- ics]: Picture/Image 
Generation. 1.3.7 [Computer Graphics]: Three- dimensional graphics and realism. Additional keywords and 
phrases: ray tracing, antialiasing, constructive solid geometry, transparent surfaces, display buffers, 
visible-surface algorithms, rendering algorithms. INTRODUCTION The ZZ-buffer algorithm [35, 36] is a 
simple acceleration scheme for ray tracing that can be applied to a wide variety of scenes, in- cluding 
those with small features, textured and transparent surfaces, shadows and penumbrae, and depth-of-field 
effects. The ZZ-buffer improves on the performance of naive ray tracing by three major strategies. First, 
it uses an efficient indexing scheme, similar to the "item buffer" of Weghorst et al. [40], for locating 
the objects intersected by primary rays and by rays to the light sources. Second, it uses symbolic manipulation 
of the scene description to perform the visibility computations for many rays at once. Finally, it uses 
rough estimates of the depths of objects at each pixel in order to eliminate invisible objects, without 
ever computing their exact depths. Unlike most other optimization schemes for ray tracing, such as octrees 
[14], hierarchical subdivision [22], and ray classification [2], the ZZ-buffer algorithm puts all its 
effort into optimizing only the tracing of "initial" and "final" rays; that is, those rays traced from 
the camera to the visible objects, and from the visible objects to the light sources. For most scenes, 
including those with many inter-object reflections, such rays constitute the majority of all rays that 
are traced, since a new ray must be traced back to each light source at every ray-object intersection. 
By limiting its scope to Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. initial and final rays, the ZZ-buffer achieves substantial speed-ups in a very simple 
fashion. The ZZ-buffer algorithm superficially resembles the A-buffer [6] and Z-buffer [7, 13] algorithms, 
in that it uses an image-space buffer to aid in determining visibility. However, unlike the Z-buffer 
and A-buffer, the ZZ-buffer is used only as an acceleration scheme for stochastic ray tracing [9, 11, 
23, 24], and is therefore free of the aliasing artifacts that plague these other methods. In this paper 
we show how the ZZ-buffer algorithm can also be used to speed up the ray tracing of models built with 
constructive solid geometry (CSG) operations. Several schemes have been proposed for accelerating this 
computation, exploiting, for example, scan-line coherence [3] and the notion of "active zones" [33]. 
Our use of the ZZ-buffer for CSG models most closely approximates the depth buffer techniques of Rossignac 
and Requicha [32], Okino, Kakazu, and Morimoto [30], and Goldfeather, Hultquist, and Fuchs [15]. Compared 
to these methods, the ZZ-buffer algorithm has several advantages: it produces antialiased shadow edges, 
avoids the shading of invisible objects, and does not require computing exact z-coordinates for every 
object at every pixel. The major drawback of the ZZ-buffer algorithm is the large size of its data structures. 
For instance, our current (unoptimized) implementation typically uses from 10 to 20 megabytes of virtual 
memory to render simple scenes such as the ones shown in this paper. Fortunately, computers and workstations 
with address spaces of this size are becoming increasingly common. Furthermore, the ZZ-buffer algorithm 
can be easily tuned to use less memory, at the cost of increased rendering time. 2 CONSTRUCTIVE SOLID 
GEOMETRY The CSG solid modeling paradigm is very popular because of its power and its compatibility with 
the standard ray-tracing algo- rithms [34]. CSG models are built from a set of primitive objects (such 
as half-spaces and quadrics), combined with Boolean-like operations such as union, intersection, and 
set difference. While the meaning of these operations for point sets is well- established, their meaning 
for the kind of objects normally used in solid modeling is not entirely obvious. The difficulty lies 
in specifying the effect of those operations on the various geometric and optical properties normally 
attached to these objects, such as surface normals, textures, and shading attributes. Since the ZZ- buffer 
algorithm relies heavily on symbolic manipulation of CSG expressions, it is important that we define 
these operations with some care. &#38;#169;1990 ACM-0-89791-344-2/90/008/0067 $00.75 O SIGGRAPH '90, 
Dallas, August 6-10, 1990 2.1 Shapes In our model, the shape of an object A can be described by its characteristic 
function CA(p), which associates to each point of space p a class, either exterior (E), surface (S), 
or interior (I). We assume that characteristic functions are reasonably well-behaved. In particular, 
we require that any ray in general position contain only a finite number of surface points in any finite 
interval. Furthermore, we require that along each ray there exist at least one surface point between 
any interior point and any exterior point. The CSG operations defined below preserve these requirements. 
Note that a surface may have interior points on both sides, or exterior points on both sides. A CSG operation 
combines the characteristic functions of its operands in a point-wise fashion: the class of a point p 
in the resulting object depends only on the classes of p in each operand. In particular, for the union 
operation U, the class CAUB (p) is the stronger of the two classes CA(p) and C,(p), where interior is 
stronger than surface, and surface is stronger than exterior. For the unary complement operation -1, 
the class C,A(p) is interior if CA (p) is exterior, and vice versa, while surface points are left unchanged. 
The operations of intersection and difference are defined by the formulas A n B = -~((-~A) U (~B)) and 
A \ B = A n (~B). The CSG operations defined here enjoy many of the properties of their Boolean counterparts. 
In particular, for any objects A, B, andC, wehaveAUB= BOA, (AUB) UC= AU(BUC), A U A = A, and -~(-~A) 
= A. The CSG equivalent of the empty set is the vacuum object 0, which is everywhere exterior. Its complement 
is the plenum 1 : -0, an object that is everywhere interior. These objects satisfy the relations A U 
0 = A and A U I = 1, for any A. These properties also hold for intersection, except that 1 and 0 exchange 
roles. Moreover, intersection and union distribute over each other. As we shall see, the ZZ-buffer algorithm 
relies heavily on these properties when constructing and simplifying CSG expressions. Note that the CSG 
operations fail to satisfy some properties of the corresponding Boolean functions. For example, A n (~A) 
is not 0, since all the surface points of A survive in the result; dually, A U (-~A) is not 1. 2.2 Shading 
parameters For rendering purposes, we also associate with each object a shading function SA (p), which 
maps each point of space p to a collection of shading parameters, such as color, transparency, normal 
direction (for surface points), and so on. Note that the shading function is defined not only for interior 
and surface points of each object, but also for exterior points, which are typically (but not necessarily) 
invisible. A CSG operation must combine not only the characteristic functions of its operands, but their 
shading parameters as well. For the union operation, at every point p where CA(p) ~ CB(p), the shading 
parameters SAuB (p) of the result are copied from those of the object with the stronger class at p. At 
any point p where Ca(p) : CB(p), the shading parameters of A and B must be combined with an appropriate 
union-like operation O, that is, SAul(p) = SO(p) 0 S~(p). 68 Similarly, when taking the CSG complement 
of an object A, we need to transform its shading parameters by a suitable complement-like operation -:1, 
that is, S~A (p ) = -USA (p ). The operations 0 and -h can be chosen arbitrarily, provided that they 
satisfy the basic properties of union and complement listed in the previous section. In particular, we 
must arrange things so that the shading parameters of the vacuum S o and of the plenum `sl are respectively 
minimal and maximal, in the sense that `SA (P) U ,So (P) = `SA (P), and `SA (P) 0 S t (p) = S l (p). 
For example, we can define the complement of a color (r, g, b) to be the color (1 - r, 1 -g, 1 - b), 
and define the union of two colors to be their component-wise maximum. In this case, vacuum should be 
black, and plenum, white. Other shading parameters, such as transparency coefficients and highlight colors, 
can be handled in the same way. Note that these definitions provide a reasonable behavior in most typical 
situations. For example, intersecting an object with a clipping half-space--a fiat surface with vacuum 
on one side and plenum on the other--gives a cut-away view of the object, without affecting the colors 
of the surviving parts. 2.3 CSG expression trees For the purposes of this paper, we assume that the 
scene to be rendered is represented by a CSG tree, a data structure built from three kinds of nodes: 
Substance, PtTinitive, and Union. A Substance node describes a shading function divorced from any shape 
information. Its detailed representation does not concern us here. A Primitive node describes a basic 
CSG building block and contains two fields: a characteristic function shape, which describes a partition 
of space into exterior, surface, and interior points; and pointers to the three Substance nodes, subst 
[E], subst [s], subst [1], which specify the shading parameters to be used for each point class. Finally, 
a Union node represents the union of two CSG models, and contains pointers to the two corresponding subtrees. 
type PointClass = {E, S, I} type Substance : record ... end record type PnPnitive : record shape: Shape 
subst: array PointClass of Substance end record type Union : record a, b: CSGTree end record Instead 
of using explicit Complement nodes to denote complement operations, we always refer to a CSG tree or 
subtree by means of a "tagged pointer," a pair consisting of a pointer to the tree's root node and a 
one-bit negate flag. Besides saving some space, this encoding allows us to quickly complement any CSG 
expression, without incurring any allocation or garbage collection overhead: type CSGTree = record node: 
pointer to ( Union or Primitive or Substance ) negate: boolean end record  ~ Computer Graphics, Volume 
24, Number 4, August 1990 3 THE ZZ-BUFFER ALGORITHM The ZZ-buffer rendering algorithm consists of two 
phases: tiling and rendering. In the tiling phase, we pre-process the scene into a data structure called 
a ZZ-buffer. During this step we determine object visibility and perform the CSG computations down to 
a resolution of a few pixels. In the rendering phase, we use the ZZ-buffer to speed up stochastic ray 
tracing. During this step we refine the visibility and CSG computations performed during the tiling phase 
down to the level of a single ray, and we compute the shades of objects that are found to be visible. 
For clarity, we will give at first a very simplified description of the algorithm that, while correct, 
is extremely inefficient in terms of time and space. Later, in Section 8, we will discuss the optimizations 
necessary to make the algorithm efficient. We will use the following coordinate systems, or spaces, after 
Foley et al. [12, pages 279-281]. The scene is described in a coordinate system called worm space. We 
define also a screen space that is related to world space by a perspective transformation. In screen 
space, the camera is situated at the point (0, 0, -oo), and the image is obtained by projecting the points 
of the camera's screen space onto the plane z = 0 (the screen plane) with rays parallel to the z-axis. 
This perspective transformation also brings the plane at infinity to a background plane at a finite depth 
z = z .... After the transformation, the visible parts of the object have z-coordinates in the interval 
Z* = (-o¢,zm~). When computing shadows, we also define a separate screen space for each light source, 
with the source located at (0, 0, -cxD). 3.1 The ZZ-buffer The ZZ-buffer is a two-dimensional array ZZ[i, 
3], each of whose entries is associated with a rectangular cell in the screen plane. Each cell covers 
a fixed-sized rectangular block of pixels (or possibly a single pixel) of the final image. Each entry 
of the ZZ-buffer describes the portion of the scene that is visible within the corresponding cell. See 
Figure 1. ZZ-buffer tile lists ZZ-buffer entries image cells pizels_~ ~-- Figure 1 : The ZZ-buffer. 
 Each entry of the ZZ-buffer is a list of tile records. Each tile record describes a tile, which is a 
fragment of the scene, clipped to the ZZ-buffer cell and to a specified range of screen z-coordinates. 
 type Tile : record zz: Interval expr: CSGTree [lags: TileFlags end record type Interval = record 
1o, hi." real end record The zz field of each tile record (from which the ZZ-buffer derives its name) 
gives the range of screen z-coordinates spanned by the tile. The tiles in a tile list are pairwise disjoint, 
sorted by increasing z-coordinate, and cover the entire visible interval Z*. The expr field of a tile 
points to a CSG tree describing the part of the scene that may appear within the tile. The Hags field 
summarizes the characteristic and shading functions of the tile, and is discussed in the next section. 
Figure 2 shows the tile list for a particular ZZ-buffer cell in a scene described by the CSG expression 
A u (B n C), where A and B are solid spheres, and C is a half-space. to C¢lmC,'~f~  ( ~ screen i ; 
ZZ-buffer I ~ _1 ! i ~'-i.. I cell 2' > Figure 2: A tile list for A U (B n C). Observe that the expr 
field of each tile record points to a simplified version of the original CSG tree A u (B n C). In particular, 
in four of the tiles the tree has been reduced to just 0 or 1. (In this respect, the ZZ-buffer is reminiscent 
of the shading expression arrays produced by Sdquin and Smyrl's parameterized ray-tracing algorithm [37].) 
The number of elements in a tile list, as well as the tiles' z-ranges, can be chosen in many ways, as 
long as each expr field correctly describes the scene inside the corresponding tile. Thus, for example, 
the second, third, and fourth tiles in the list (counting from the left) could all be replaced by a single 
tile spanning their combined z-range, with expr = A U C. In the limit, the entire list could be reduced 
to a single tile with zz = Z* and expr = A U ( B n C). The ZZ-buffer structure helps optimize ray tracing 
in two ways. First, it provides a coarse sort of the objects in front-to-back order, so that, as we traverse 
each tile list in the ray-tracing phase, objects '~' Computer Graphics, Volume 24, Number 4, August 
1990 The refinement of a tile list has three positive effects. First, the z-ordering of the objects in 
the refined list is more accurate than in the original list, because the smaller cell size allows the 
objects' z-ranges to be estimated with greater precision. Second, the CSG expression trees appearing 
in the refined list will usually be simpler than those in the original list. Finally, some objects may 
be found to be invisible in the refined list, because they lie beyond other opaque objects that completely 
cover the smaller cell. 4.1 Refining a tile list The refinement of a tile list is carried out by the 
following procedure: procedure Retine TileList takes oldList: TileList newCell.'Rectangle returns TileList 
begin newList ~ NIL for each old771e in oldList do auxList ~-- ComputeTiles (oldTile.expr, newCell ) 
for each auxTile in auxListdo if auxTile.zz n oldTile.zz ~ q5then newTile ~-- ClipTile ( auxTile , oldTile.zz 
) newList ~ Append(newList , newTile ) end if end for end for return ncwList end procedure The Compute 
Tiles procedure will be described later on. The call ClipTile(t, zz) makes a copy of tile t with its 
z-range replaced by t.zz A zz, and with its dens flags modified accordingly. (Specifically, if the new 
z-interval is a proper subset of t.zz then any DENSE flags of t are downgraded to UNKNOWN.) The Append 
procedure adds a new tile to the end of the given list; it then checks whether the last two tiles have 
the same expr field and contiguous z-ranges, and, if so, replaces them by a single tile spanning their 
combined z-ranges. After we have computed the refined tile list for a new cell, and before we refine 
it further or store it in the ZZ-buffer, we remove any invisible tiles and truncate the list after the 
first opaque tile. We know that a tile is invisible if trans [e] = CLEAR and color[c] = BLACK for every 
nOn-EMPTY point class c. Similarly, we know that a tile is opaque if dens [c] = DENSE and trans [c] = 
OPAQUE for some class c, or if trans [c] : OPAQUE for every nOn-EMPTY class c. The core of the ZZ-buffer 
algorithm is the Compute Tiles proce-dure, which constructs a tile list for a given CSG expression or 
subexpression and a given ZZ-buffer cell. It does so by recursively traversing the CSG expression tree, 
computing a tile list for each of its proper sub-expressions, and combining these tile lists with the 
appropriate CSG operations. (Note that this recursion down the CSG tree is nested inside each step of 
the recursive subdivision of screen space.) The following sections describe the Compute Tiles algorithm 
in detail for each of the three node types: Substance, Primitive, and Union. 4.2 Tiling substance nodes 
For Substance nodes, ComputeTiles builds a trivial tile list with a single tile, spanning the entire 
visible z-range Z*. The tile's dens flags are set according to the substance's point class; for example, 
if the substance consists entirely of exterior points, the dens flags are set to (E: DENSE, S: EMPTY, 
I: EMPTY). The color and trans flags are determined from the substance's shading parameters. 4.3 Tiling 
primitive nodes Recall that the shape of a Primitive node p is defined by a characteristic function p.shape 
that assigns to each point of space one of the labels {E, S, 1}. For the purposes of the ZZ-buffer algorithm, 
this function is implemented as a procedure that, given a cell C of the ZZ-buffer, partitions the interval 
Z* into a set of disjoint intervals zz [i] and determines for each of these intervals an appropriate 
set of density flags dens [i]. The Compute Tiles procedure uses this information to construct a tile 
list for the primitive p. The expr field of each output tile may be p itself, or may reduce to one of 
the substances p.subst [E], p.subst [S], or p.subst [I], depending on the density flags returned by p.shape 
for that interval. For example, if the density flags are (E: DENSE, S: EMPTY, I: EMPTY), then p has only 
exterior points in the interval, so the CSG tree of the corresponding tile can be set to p.subst [E]. 
The same rule applies to intervals that are entirely surface or entirely interior. The shape functions 
can be implemented using techniques similar to those used in beam tracing [ 19] and cone tracing [ ! 
]. However, for the ZZ-buffer algorithm, the computations can often be considerably simplified, since 
only coarse estimates of the objects' z-coordinates are required. Planes As a more concrete example, 
we now describe our shape procedure for a plane P. First, we construct the long rectangular prism in 
screen space that extends over the entire interval Z*, and whose cross-section is the given ZZ-buffer 
cell. We test the twelve edges of this prism against the plane P, obtaining from zero to twelve intersection 
points. If we get no intersection points at all, then the plane is not visible inside the cell, and we 
output a single z-interval with den- sity flags (E: DENSE, S: EMPTY~ I: EMPTY). Otherwise, we split the 
interval Z* into three parts, with the middle part being the small- est interval that includes the z-coordinates 
of all the intersection points. The density flags for the two outer intervals are always (E: DENSE, S: 
EMPTY, I: EMPTY). For the middle interval, we have to distinguish two cases: if P intersects all four 
long edges of the prism, then any ray through the cell must also intersect the plane, so we set the density 
flags to (E: DENSE, S: DENSE, l: EMPTY); otherwise, we set them to (E: DENSE, S: UNKNOWN, 1: EMPTY). 
Quadric surfaces As another example, we sketch briefly our shape procedure for a quadric surface Q. In 
general, the z-coordinates of the intersections of an arbitrary ray with the surface Q can be found by 
solving a Q SIGGRAPH '90, Dallas, August 6-10, 1990 quadratic equation Az 2 + Bz + C = 0, where the coefficients 
A, B, and C depend on the ray and on Q. Using standard techniques of interval arithmetic [26], we can 
compute intervals A, B, C, which contain the values of A, B, and C for all camera rays that pass through 
the given ZZ-buffer cell. We can then solve the "fuzzy" quadratic equation Az 2 + Bz + C = 0 using interval 
arithmetic. The result is a pair of intervals 20 and 21 that are guaranteed to contain the intersections 
of any ray through the cell and the quadric surface. These two intervals decompose the interval Z* into 
at most five parts. If 20 and 21 do not overlap and lie entirely inside Z*, then we output them with 
density flags (E: DENSE, S: DENSE, l: EMPTY), since we know that any ray will intersect points of the 
quadrie's exterior and surface within those intervals. If either interval extends outside Z*, then parts 
of the quadric surface may be cut away by the camera's near and far clipping planes, so we set the corresponding 
density flags to (E: DENSE, S: UNKNOWN, I: EMPTY). Finally, if the intervals overlap, the cell may contain 
a silhouette edge of the quadric, and so we output the combined interval [Y.0.lo, .~l.hi] with density 
flags (E: DENSE, S: UNKNOWN, I: EMPTY). In any case, the complement of ~0 U ~1 relative to Z* contributes 
up to three additional intervals, which are completely exterior. Although we have only discussed the 
tiling of "hollow" objects with no interior points, the modifications needed to handle "filled" objects, 
such as half-spaces and quadric solids, are straightforward. 4.4 Tiling union nodes In the case of a 
Union node, the ComputeTiles procedure constructs (recursively) a tile list for each of the two operands 
A and B, and then merges the two lists to produce the final result. To merge the lists, the procedure 
breaks up their tiles into shorter tiles so that the two lists have the same length, and corresponding 
tiles have the same z-ranges. It then traverses the two lists simultaneously, combining each pair of 
corresponding tiles tA and tB into a single tile tR of the output list. (The procedure also merges consecutive 
output tiles that have the same expr field, as described for RefineTileList.) In general, the expr field 
of the output tile tR will point to a new Union node with operands tA.expr and tB.expr. The flags field 
of tR is derived from those of tA and tB. For instance, the density of exterior points tR.dens [El is 
determined as follows: if (tA.dens [E] = EMPTY) and (tB.dens [E] = EMPTY) then tR.dens [E] +-- EMPTY 
elseif ((tA.dens [E] ~- DENSE) and (tB.dens [t] = EMPTY)) or ((tB.dens [E] = DENSE) and (tA.dens [t] 
= EMPTY)) then tR.dens [E] ~--DENSE else tR.dens [E] ~-- UNKNOWN end if The dens flags for the surface 
and interior of tR, as well as the color and trans flags for all three point classes, are computed by 
similar formulas, which can be derived by a tedious but straightforward case analysis. The new tile's 
expression tR.expr does not always have to be a new Union node. Often, by examining the Bags bits of 
tA and tB, 72 we can decide that tA.expr U tB.expr reduces to either tA.expr or tB.expr alone. Specifically, 
the union reduces to tB.expr if the following procedure returns TRUE: procedure NotStronger takes a, 
b: TileFlags returns boolean begin for each c, c' in {E, S, I} do if c > c' and amens [c] ~ EMPTYand 
&#38;dens [e'] # EMPTYthen return FALSE end if end for for each c in {E, S, 1} do if amens [c] # EMPTYand 
&#38;dens [c] # EMPTYthen if (a.color [c] # aLACK and b.color [c] # WHITE) or (a.trans [c] ~ CLEARand 
b.trans [c] # OPAQUE) then return FALSE end if end if end for return TRUE end procedure Note that the 
union can always be simplified when tA.expr or tB.expr is either 0 or 1. Another case where the union 
can always be simplified (not included in the code above) is when tA.expr and tB.expr are the same expression--which 
happens, for example, when A and B are overlapping solid objects with the same interior substance. The 
simplification rules described above are very important, as they account for most of the CSG tree simplification 
in the final ZZ-buffer cells. 5 THE RENDERING PHASE In the rendering phase of the algorithm, we produce 
the final image by performing stochastic ray tracing on the objects stored in the ZZ-buffer. More precisely, 
we subdivide each image pixel into an array of S x S subpixels and shoot a sampling ray from the camera 
through a random point in each subpixel, as described by Cook [9]. For each ray, we locate the ZZ-buffer 
cell that contains the sampling point and examine the corresponding tile list from front to back. We 
check each tile for intersections against the ray by evaluating its CSG expression along the ray, clipped 
to the tile's zz range. Finally, we compute the color and transparency of those objects that are found 
to be visible, and accumulate these data according to the standard compositing formulas [27]. We stop 
examining the tile list when we find an opaque object, or when the combined transparency of the tiles 
traversed by the ray becomes sufficiently small. As we have already noted, the ZZ-buffer algorithm does 
not handle the secondary rays that arise from mirror-like or refracting surfaces. We should therefore 
treat any such surfaces as opaque, and handle the secondary rays separately with a general ray-tracing 
algorithm.  ~ Computer Graphics, Volume 24, Number 4, August 1990 5.1 Computing ray-tile intersections 
The intersections between a ray and the scene are represented as a list of hits. Each hit is a segment 
of the ray whose points all have the same class, and whose shading parameters all come from a single 
Substance node or from a CSG combination of Substance nodes: type Hit : record expr: CSGTree zz: Interval 
class: PointClass color: ColorFlag trans: TransFlag end record Note that a Hit record is essentially 
equivalent to a Tile record whose ZZ-buffer cell has been contracted to a single point, and whose z-range 
is small enough that every point in the hit belongs to a single point class. The computation of hit lists 
is entirely similar to that of tile lists, except that the ComputeHits routine always returns hits whose 
objects are Substance nodes or unions of Substance nodes. These computations are the same as those of 
ordinary ray tracing. 5.2 Shading and filtering Once we have determined the visible hits--i.e., the 
objects visible along a sample ray, and their z-coordinates--we compute the contribution of each hit 
to the image sample, based on the amount of light reaching the hit and the shading parameters of hit.expr. 
Note that we need not prefilter the textures to avoid aliasing artifacts, since (as observed by Cook, 
Porter, and Carpenter [10]) the stochastic sampling of the camera rays used to antialias object edges 
will antialias textures as well. The output of the rendering phase is an array of samples, with S × ,5' 
samples for each pixel of the final image We combine these samples using standard convolution filtering 
[25, 29]. Each sample contributes to a 3 x 3 square of pixels in the final image, with weights that depend 
on the distance between the unjittered sample position and the centers of those pixels. 6 SHADOWS The 
ZZ-buffer can also be used to compute shadows, in a manner similar to the "light buffer" of Haines and 
Greenberg [17]. To implement shadows, we modify the ZZ-buffer algorithm in two ways. In the tiling phase, 
we construct an additional ZZ-buffer from the point of view of each light source. In the rendering phase, 
when computing the illumination at each visible point of the scene, we use the ZZ-buffer of each light 
source to test whether the point is shadowed by other objects More precisely, to compute the light reaching 
a point p from a given source, we cast a ray from the source through p and locate the cell of the source's 
ZZ-buffer that is hit by this ray. We extract the list of tiles from that cell, and for each tile t we 
compute the intersections between the ray and the object t.expr, clipped to the tile's zz range. The 
intersections are computed by the same algorithm used for camera rays. If we find an opaque object that 
intersects the ray, we conclude that p is in shadow with respect to that light source. If we find any 
semitransparent objects, we filter the light by their transmission coefficients For computing shadows, 
the ZZ-buffer has many advantages over methods based on ordinary Z-buffers, such as William's algo- rithm 
[41 ] or "percentage-closer filtering" [31 ]. First, the ZZ-buffer allows us to correctly antialias sharp 
shadow boundaries and shad- ows cast by small objects and fine textures, independently of the size and 
resolution of the light's ZZ-buffer. Our algorithm also handles colored transparent surfaces that filter 
light, an effect that cannot be reproduced by Z-buffers, which can keep track of only one shadowing object 
at each point. 7 PENUMBRAE AND CAMERA BLUR The ZZ-buffer can also be used to compute the penumbrae (soft 
shadow edges) produced by extended light sources, as shown in Figure 6. To obtain this effect, we imagine 
that the light source is a disk of some fixed size, oriented parallel to the projection plane of its 
ZZ-buffer. When computing the illumination of some point p of the scene, we cast a ray from a random 
point on this disk towards the point p, as in distributed ray tracing [10]. tn the light source's screen 
space, each of these rays will consist of points of the form (xp +m~z, yp +m~z, z), where (xp, yp) is 
the point where the ray hits the screen plane, and m=, m u are numbers that measure how far the ray deviates 
from the z-axis direction. See Figure 5. screen plane .."" o$ light .~ perturbed ..""" ]\ 80tirce ,-" 
m .4  t,ght my "~i _..--"[~ I%, ,, 1, 0] -'"' ~'~. ............ i~, I [°'°'1'°1 "-.,. [%, yp, 0,1] 
point light source being at infinity shaded Figure 5: Ray tracing penumbrae In the light's screen space, 
the light source itself is a disk at infinity centered at the point (0, 0, -oo). If 0 is the angular 
radius of the light source, as seen from the light's screen plane, then V/~ + mZu is at most tan 0. Note 
that this bound on rn~ and mu is independent of the screen coordinates xp and yp. In order to quickly 
find the objects that could be intersected by the perturbed ray, we have to modify the computation of 
tiles somewhat. When computing the tile lists for a primitive object A in a given ZZ-buffer cell, we 
need to estimate the z-coordinates of the intersections between A and the rays from all points in the 
light source to all points in the given cell.  '~' O(n). (This optimization is an instance of the general 
technique of "fractional cascading" [8, 16]). Hit list optimizations. All of the optimizations described 
above, except for pruning, can also be applied to the computation of hit lists during the rendering phase. 
(Pruning cannot be applied since coalescing hits would violate the restriction that each hit have a single 
point class.) Other optimizations. There are many other simple optimizations worth considering. For example, 
we can save some space by omitting vacuous tiles and hits. In addition, for many primitives there are 
certain computations, such as the world-to-screen space transformation, that can be shared for all the 
cells of the same ZZ-buffer. Therefore, it is best to separate the ComputeTiles procedure into two parts: 
a Project routine that is called once for each primitive in each view, and a Compute Tiles proper, which 
uses the data produced by Project to compute the tile lists of each cell. 9 IMPLEMENTATIONS The first 
version of the ZZ-buffer algorithm, handling only poly- gons, was developed in 1986 by one of the authors 
as part of a com- mercial production system for Sogitec Audiovisuel in Paris [35]. The algorithm was 
reimplemented in Modula-2+ at the DEC Sys- tems Research Center in Palo Alto in 1988, and extended to 
handle quadrics, shadows, penumbrae, and depth of field effects [36]. (This version was later ported 
to Modula-3 and used for experiments in distributed rendering.) The version described in this paper, 
specialized for rendering CSG models, is implemented in Modula-2+ and runs on the Firefly, an experimental 
workstation developed at DEC SRC with four CVAX microprocessors and 64 megabytes of memory [38]. All 
figures in the paper were produced on this machine. 10 FURTHER WORK Lazy evaluation. The algorithm as 
described computes the entire tile list for every node, even when only a small portion of the list is 
actually needed for refining a parent's tile list, or for ray tracing. A more efficient scheme would 
be to use lazy evaluation: instead of actually computing a tile list, we merely build a record indicating 
the computation that needs to be done. The actual computation is performed later, if and when the tiles 
are actually required, and carried out only as far as necessary to produce the desired tiles. Adaptive 
supersampling. The rendering of scenes with penumbrae and camera blur effects requires a relatively large 
number of samples per pixel in order to keep the sampling noise down to an acceptable level. However, 
a large number of samples is only really necessary for pixels in which a discontinuous function is being 
sampled. Since such pixels are difficult to distinguish a priori, we would like to incorporate an adaptive 
method for choosing the number of samples per pixel, such as the ones proposed by Lee, Redner, and Usclton 
[23], or by Painter and Sloan [28]. Additional modeling primitives. In principle, the ZZ-buffer algo- 
rithm can easily be extended to handle additional modeling prim- itives such as polygonal meshes, fractal 
terrains, B6zier patches, and so on. In particular, the interval arithmetic computations used   Computer 
Graphics, Volume 24, Number 4, August 1990 for tiling quadrics in Section 4.3 should readily extend to 
algebraic surfaces [18], superquadrics [4], and other surfaces defined by implicit equations [5]. Pseudo-refraction. 
The same mechanism used for penumbrae and camera blur can also be used for a variety of other effects 
involving slightly non-axial rays or slightly blurred objects. For example, we could use the ZZ-buffer 
to speed up refracted rays, as long as the ray's direction does not deviate too much from the z-axis. 
Although it is not possible to render all refractions accurately in this way, previous work suggests 
that even a crude approximation may provide sufficient realism for many purposes [20, 21]. The same general 
techniques could also be used to compute a ZZ-buffer suitable for a scene with motion blur [ 10], or 
for several consecutive frames of an animated sequence. Acknowledgements We would like to thank all the 
people at DEC who helped us in our work and whose workstations we crashed while testing our program. 
We are particularly grateful to Stephen Harrison who ported the original ZZ-buffer algorithm to Modula-3 
and provided lots of valuable advice. We would also like to thank DEC Systems Research Center and the 
AT&#38;T Foundation for their financial support.  References [I] Amanatides, J., "Ray Tracing with Cones," 
Computer Graph- ics (SIGGRAPH "84) vol. 18 no. 3 (July 1984), 129-135. [2] Afro, J. and Kirk, D., "Fast 
Ray Tracing by Ray Classifi- cation," Computer Graphics (SIGGRAPH '87) vol. 21 no. 4 (July 1987), 55.-64. 
[3] Atherton, P. R., "A Scanline Hidden Surface Removal Proce- dure for Constructive Solid Geometry," 
Computer Graphics (SIGGRAPH '83) vol. 17 no. 3 (July 1983), 73-82. [4] Barr, A, H., "Superquadrics and 
Angle Preserving Transfor- mations," IEEE Computer Graphics and Applications, vol. 1 no. 1 (1981), 11-23. 
[5] Blinn, J. E, "A Generalization of Algebraic Surface Drawing," ACM Transactions on Graphics, vol. 
1 no. 3 (July 1982), 236- 256. [6] Carpenter, L., "The A-buffer, an Antialiased Hidden Surface Method," 
Computer Graphics (SIGGRAPH '84) vol. 18, 3 (July 1984), 103-108. [7] Catmull, E., "A Subdivision Algorithm 
for Computer Display of Curved Surfaces," Ph.D. Thesis, University of Utah, Salt Lake City, December 
1974. [8] Chazelle, B. and Guibas L. J., "Fractional Cascading," Algo- rithmica, vol. 1, no. 2 (1986), 
133-191. Also DEC Systems Research Center report #12 (June 1986). [9] Cook, R. L., "Stochastic Sampling 
in Computer Graphics," ACM Transactions on Graphics vol. 5, no. 1 (January 1986), 51-72. [10] Cook, R. 
L., Porter, T., and Carpenter, L., "Distributed Ray Tracing," Computer Graphics (SIGGRAPH '84) vol. 18 
no. 3 (July 1984), 137-145. @SIGGRAPH '90, Dallas, August 6-10, 1990 [11] Dipp6, M. A. Z., and Wold, 
E. H., "Antialiasing through Stochastic Sampling," Computer Graphics (SIGGRAPH '85) vol. 19 no. 3 (July 
1985), 69-78. [12] Foley, J., van Darn, A., Feiner, S., and Hughes, J. Computer Graphics: Principles 
and Practice, 2nd Ed., Addison-Wesley, Reading, MA (1990). [13] Fournier, A. and Fussell, D., "On the 
Power of the Frame Buffer," ACM Transactions on Graphics vol. 7 no. 2 (April 1988), 103-128. [14] Glassner, 
A. S., "Space Subdivision for Fast Ray Tracing," IEEE Computer Graphics and Applications, vol. 4 no. 
10 (October 1984), 15-22. [15] Goldfeather, J., Huttquist, J. P. M., and Fuchs, H., "Fast Constructive 
Solid Geometry Display in the Pixel-Powers Graphics System," Computer Graphics (SIGGRAPH '86) vol. 20 
no. 4 (August 1986), 107-116. [16] Guibas L. J. and Stolfi J., "Ruler, Compass, and Computer: The Design 
and Analysis of Geometric Algorithms," in The- oretical Foundations of Computer Graphics and CAD, R. 
A. Earnshaw, ed., NATO ASI Series F, vol. 40, Springer-Verlag (1988), 111-165. Also DEC Systems Research 
Center report #37 (February 1989). [17] Haines, E. A. and Greenberg, D. P., "The Light Buffer: A Ray 
Tracer Shadow Testing Accelerator," IEEE Computer Graphics and Applications, vol. 6 no. 9 (September 
1986), 6-15. [18] Hanrahan, E, "Ray Tracing Algebraic Surfaces," Computer Graphics (SIGGRAPH '83) vol. 
17 no. 3 (July 1983), 83-90. [19] Heckbert, E S. and Hanrahan, P., "Beam Tracing Polygonal Objects," 
Computer Graphics (SIGGRAPH '84) vol. 18 no. 3 (July 1984), 119-127. [20] Kay, D. S., "A Transparency 
Refraction and Ray Tracing Model for Computer Synthesized Images," Master's thesis, Comell University, 
Ithaca, New York, 1979. [21] Kay, D. S., and Greenberg, D. E, "Transparency for Computer Synthesized 
Images," Computer Graphics (SIGGRAPH '79) vol. 13 no. 2 (August 1979), 158-164. [22] Kay, T. L. and Kajiya, 
J., "Ray Tracing Complex Scenes," Computer Graphics (SIGGRAPH '86) vol. 20 no. 4 (August 1986), 269-278. 
[23] Lee, M. E., Redner, R. A., and Uselton, S. P., "Statistically Optimized Sampting for Distributed 
Ray Tracing," Computer Graphics (SIGGRAPH '85) vol. 19 no. 3 (July 1985), 61-67. [24] Mitchell, D. E, 
"Generating Antialiased Images at Low Sam- pling Densities," Computer Graphics (SIGGRAPH '87) vol. 21 
no. 4 (July 1987), 65-72. [25] Mitchell, D. E, and Netravali, A. N., "Reconstruction Filters in Computer 
Graphics," Computer Graphics (SIGGRAPH '88) vol. 22 no. 4 (August 1988), 221-228. [26] Moore, R. E., 
Interval Analysis, Prentice-Hall, Englewood Cliffs, N. J. (1966). [27] Porter, T. and Duff, T., "Compositing 
Digital Images," Com- puter Graphics (SIGGRAPH '84) vol. 18 no. 3 (July 1984), 253-259. [28] Painter, 
J. and Sloan, K., "Antialiased Ray Tracing by Adaptive Progressive Refinement," Computer Graphics (SIG- 
GRAPH '89) vol. 23, no. 3 (July 1989), 281-288. [29] Pratt, W. K., Digital Image Processing, Wiley and 
Sons, New York (1978). [30] Okino, N., Kakazu, Y., and Morimoto, M., "Extended Depth- Buffer Algorithms 
for Hidden-Surface Visualization," IEEE Computer Graphics and Applications vol. 4, no. 5 (May 1984), 
79-88. [31] Reeves, W. T., Salesin, D. H., and Cook, R. L., "Rendering Antialiased Shadows with Depth 
Maps," Computer Graphics (SIGGRAPH '87) vol. 21 no. 4 (July 1987), 283-291. [32] Rossignac, J. R. and 
Requicha, A. A. G., "Depth Buffering Display Techniques for Constructive Solid Geometry," IEEE Computer 
Graphics and Applications vol. 6, no. 9 (September 1986), 29-39. [33] Rossignac, J. R. and Voelcker, 
H. B., "Active Zones in CSG for Accelerating Boundary Evaluation, Redundancy Elimina- tion, Interference 
Detection, and Shading Algorithms," ACM Transactions on Graphics vol. 8, no. 1 (January 1989), 51-87. 
[34] Roth, S. D., "Ray Casting for Modeling Solids," Computer Graphics and Image Processing vol. t 8 
(1982), 109-144. [35] Salesin, D., "The Fuzzy Buffer: A Stochastic Antialiased Hidden Surface Algorithm," 
Ph.D. Programming Project Report, Stanford University (1986). [36] Salesin, D. and Stolfi, J., "The ZZ-Buffer: 
A Simple and Efficient Rendering Algorithm with Reliable Antialiasing," Proceedings of the PIX1M '89 
Conference (Hermes Editions, Paris, September 1989), 451-466. [37] S6quin, C. G., Smyrl, E. K., "Parameterized 
Ray Tracing," Computer Graphics (SIGGRAPH '89) vol. 23 no. 3 (July 1989), 307-314. [38] Thacker, C. P., 
Stewart, L. C., and Satterthwaite, E. H. Jr., "Firefly: A Multiprocessor Workstation," DEC Systems Research 
Center, Research Report 23 (December 1987). [39] Wamock, J. E., "A Hidden-Surface Algorithm for Computer- 
Generated Halftone Pictures," Computer Science Department, University of Utah, TR 4-15 (June 1969). [40] 
Weghorst, H., Hooper, G., and Greenberg, D. E, "Improved Computational Methods for Ray Tracing," ACM 
Transactions on Graphics, vot. 3, no. 1 (January 1984), 52-69. [41] Williams, L., "Casting Curved Shadows 
on Curved Surfaces," Computer Graphics (SIGGRAPH '78) vol. 12 no. 3 (August 1978), 270-274.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97888</article_id>
		<sort_key>77</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Antialiasing of interlaced video animation]]></title>
		<page_from>77</page_from>
		<page_to>85</page_to>
		<doi_number>10.1145/97879.97888</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97888</url>
		<abstract>
			<par><![CDATA[The production of computer-generated video presents a number of difficulties not encountered with motion pictures. Interlaced scanning and the color subcarrier of NTSC video are responsible for special problems such as interline flicker, and chroma aliasing. As in motion pictures, temporal aliasing is also an issue. A renderer can sample and filter a moving image in an arbitrary manner and is not constrained to simply imitate the behavior of a television camera. This paper explores several different spatiotemporal antialiasing filters and how they affect the quality of video animation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P142703</person_id>
				<author_profile_id><![CDATA[81100396467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Amanatides]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14128889</person_id>
				<author_profile_id><![CDATA[81100360165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Mitchell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA["Encoding Parameters Of Digital Television For Studios", CCIR Recommendation 601-1.]]></ref_text>
				<ref_id>CCIR601</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chuang, Richard, "Rendering for Television", SIGGRAPH Tutorial, 1985.]]></ref_text>
				<ref_id>Chuang85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter, and Loren Carpenter, "Distributed Ray Tracing", SIGGRAPH 84, July 1984, pp 137-145.]]></ref_text>
				<ref_id>Cook84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dubois, Eric, and William F. Schreiber, "Improvements to NTSC by Multidimensional Filtering", SMTPE Journal, June 1988, pp 446-463.]]></ref_text>
				<ref_id>Dubois88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hsu, Steve C., "Motion-Induced Degradations of Temporaliy Sampled Images", Master's thesis, MIT Department of Electrical Engineering, June 1985.]]></ref_text>
				<ref_id>Hsu85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Murata, Nobuo, et al., "Development of a 3-MOS Color Camera", SMPTE Journal, December 1983, pp 1270-1273.]]></ref_text>
				<ref_id>Murata83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mertz, Pierre, and Frank Gray, "A Theory of Scanning and Its Relation to the Characteristics of the Transmitted Signal in Telephotography and Television", Bell System Technical Journal, July 1934, pp 464-515.]]></ref_text>
				<ref_id>Mertz34</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378514</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mitchell, Don P., and Arun N. Netravali, "Reconstruction Filters in Computer Graphics", SIGGRAPH 88, August 1988, pp 221-228.]]></ref_text>
				<ref_id>Mitchell88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801169</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Potmesil, Michael, and Indranil Chakravarty, "Modeling Motion Blur in Computer-Generated Images," SIG- GRAPH 83, July 1983, pp 389-399.]]></ref_text>
				<ref_id>Potmesil83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74340</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Potmesil, Michael, Eric M. Hoffert, "The Pixel Machine: A Parallel Image Computer", SIGGRAPH 89, July 1989, pp 69-78.]]></ref_text>
				<ref_id>Potmesil89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Tonge, G. J., "The Television Scanning Process", SMPTE Journal, July 1984, pp 657-666.]]></ref_text>
				<ref_id>Tonge84</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August t 990 Antialiasing of Interlaced Video Animation John 
Amanatides and Don P. Mitchell AT&#38;T Bell Laboratories Murray Hill, NJ 07974 1. Abstract The production 
of computer-generated video presents a number of difficulties not encountered with motion pie- tures. 
Interlaced scanning and the color subcarrier of NTSC video are responsible for special problems such 
as interline flicker, and chroma aliasing. As in motion pictures, temporal aliasing is also an issue. 
A renderer can sample and filter a moving image in an arbitrary manner and is not constrained to simply 
imitate the behavior of a television camera. This paper explores several different spatiotemporal antialiasing 
filters and how they affect the quality of video animation. CR Categories and Subject Descriptions: 1.3.3 
[ Com- puter Graphics ]: Picture/Image Generation General Terms: Algorithms Additional Keywords and Phrases: 
Animation, Antialiasing, Interlacing, Video 2. Introduction Computer-generated images can be created 
for a number of different formats, such as still images, motion pictures, or video. It is known today 
that frames of a motion picture or a video should not neces- sarily be rendered in the same way as still 
images, with no consideration of time and motion. This paper focuses on the problem of rendering antialiased 
video, a problem which has not received much attention in the graphics literature. Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery, 
To copy otherwise, or to republish, requires a fee and/or specific permission. In many ways, a motion 
picture is a simpler representa- tion of moving images than video. A motion picture is made up of a sequence 
of essentially continuous two- dimensional images (ignoring the effects of film grain). In other words, 
a motion picture is continuous in the vertical and horizontal dimensions, but discrete in the time dimension. 
Most of the computer-graphics litera- ture on temporal antialiasing has been concerned with production 
of motion pictures [Cook84]. Unlike motion pictures, a video signal represents the scanning of a moving 
image. A video signal is essen- tially continuous in the horizontal dimension, but discrete in the vertical 
and time dimensions. In addi- tion, this scanning is interlaced, meaning that a video signal alternates 
between scanning the odd numbered lines and the even numbered lines [Tonge84]. In the video domain, both 
spatial and temporal aliasing can result, as well as other forms of aliasing caused by color encoding. 
Many of these unwanted aliasing artifacts occur at the source of the video signal, which in most cases 
is a television camera. Some problems are artifacts of the interlaced TV display. For computer-generated 
video, the source is a rendering program which converts a symbolic model of a scene into a digital image. 
A synthetic video signal could be produced by faithfully simulating a television camera, but rendering 
software is not constrained by the physi- cal realities that constrain the design of a camera. Given 
this freedom, it should be possible to synthesize video that is as good or better than the output of 
a camera. This work is motivated by our experimental ray tracing program, FX. FX is designed to render 
images in mul- tiple formats, including video. Moving scenes are represented by the constructive solid 
geometry (CSG) scheme, augmented with operators for translational and rotational velocity. Internally, 
samples of a moving image can be made at variable points in (x, y, t). This &#38;#169;1990 ACM4)-89791-344-2/90/008/0077 
$00.75 '77 @SIGGRAPH '90, Dallas, August 6-10, 1990 ray tracer was written to run on a parallel computer 
[Polrnesi189], and this has helped us to perform compu- tationally expensive experiments in a reasonable 
amount of time. 3. Theory A video signal represents the scanning of a moving 2D image at the rate of 
30 frames per second (25 in some countries). This scanning is interlaced, which means the odd-numbered 
lines are scanned in the first 1/60th second, and then the even lines are scanned. Figure 1 illustrates 
this scanning process in a slice perpendicular to the horizontal scan lines. This view in (t, y) coordi- 
nates illustrates the discrete sampling nature of the scanning process. Y 4 scanlines 2 1/30 2/30 3/30 
t seconds Figure 1. (t, y) Slice Through Interlaced Scans Even an analog video signal is discrete in 
the vertical and temporal dimensions, but digital video is also discrete in the horizontal dimension. 
A frame from a computer graphics video animation invariably starts out as a digital image in a frame 
buffer. It may continue to be digital throughout the recording and editing process, if the standard 4:2:2 
video format is used [CCIR601]. Sampling in the (x,y) dimensions is not interlaced like (t, y)---the 
sampling pattern is the usual rectangular arrangement of pixels. In our work, we have used the 4:2:2 
standard, in which the signal is represented by 720 samples (pixels) in the horizontal dimension, 486 
samples (scan lines) in the vertical dimension, and 30 samples (frames) per second in the time dimension. 
When a signal is sampled, the resulting interlaced video spectrum consists of replicas of the spectrum 
of the ori- ginal signal. Figure 2 shows the spectral consequences of interlaced sampling. fh 0.5 cycl.es 
_L J._l_~ f, Figure 2. (t, y) Spectrum of Interlaced Digital Video Figure 3 is another view of the sampled 
(i.e., digital) video spectrum on the (x,y) directions. Just the repli- cas centered on the ft = 0 plane 
are shown: 0.5 cycles per scardine- per scardine- r ~r iplxe I V -fx Figure 3 (x, y) Spectrum of Interlaced 
Digital Video When the bandwidth of the image spectrum is too wide (in any dimension), the replicas in 
the sampled spec- trum may overlap. This is the origin of aliasing, which can be prevented by prefiltering 
the signal to limit the bandwidth of the spectrum. Several distinct types of aliasing can occur in the 
generation of a video signal. Spatial Aliasing, all too familiar in computer graphics, will occur if 
the baseband spectrum shown in Figure 3 overlaps with the sideband above it or beside it. Little ~ Computer 
Graphics, Volume 24, Number 4, August 1990 will be said in this paper about spatial aliasing, since it 
is not such a novel problem. Temporal aliasing will occur if there is overlap (see: Figure 2) with the 
sideband to the right at (60 Hz, 0 cycles per scanline). This type of problem also appears in motion 
pictures. Spatiotemporal aliasing is what we will call the interlace-related problems that result from 
the sideband in Figure 2 which is to the upper right of the baseband at (30 Hz, 0.5 CPS). In particular, 
energy at vertical frequences in the baseband near 0.5 CPS will be repli- cated by the sideband at about 
30 Hz. For example, if a pattern is brighter at every other scan line, the display will flicker at 30 
Hz. Chroma aliasing is a problem that can occur in broad- cast video. Except in digital or component 
analog video (used mainly in the editing stage), low-bandwidth color information is encoded into a high-frequency 
por- tion of the spectrum. The circled "C" in Figures 2 and 3 show the location and approximate width 
of this color subcarrier. Energy in the baseband that overlaps this location can cause waves of false 
color to appear. 4. Temporal Antialiasing Both video and motion pictures represent movement by discrete 
samples in time. As with any sampling pro- cess, energy above the Nyquist frequency will lead to aliasing. 
Anyone who has played with a strobe light is familiar with the appearance of temporal aliasing, and the 
shutter of a movie camera can create similar effects. Moving objects seem jerky, or a spinning wheel 
may seem to turn backwards. These effects are called "motion judder" or "strobing". This aliasing can 
be removed by temporal prefiltering, which is often referred to as motion blur. But motion blur is not 
a panacea. Temporal filters may prevent motion judder, but a moving object may look unnatur- ally smeared 
along the direction of motion. This is a particular problem if viewers track a moving object with their 
eyes. Motion blur looks right when the viewer is not following the object with his or her gaze. But during 
visual pursuit, the image of the object is more or less fixed on the retina, and then motion blur looks 
quite unnatural. Unfortunately, the only way to eliminate these problems would be to greatly increase 
the frame rate of motion pictures and video (temporal-aliasing effects are visible even at 120 frames 
per second [Hsu85]). Given the current standardized frame rates, judgements about the degree of motion 
blur versus judder are generally made by the cinemato- grapher or videographer; they are not really engineering 
problems. A relationship exists between spatial and temporal filtering in the simple case of constant 
velocity motion (of the image on the viewplane, that is). In this ease, when a temporal filter is applied, 
the appearance of a frame is the same as if a one-dimensional spatial filter were applied to a stationary 
image along the direction of motion. This principle has been used to implement motion blur via spatial 
filtering [Potmesi183], but the algorithm is not completely general. The design of spatial filters involves 
image-quality trade-offs between aliasing, blurring, and ringing [Mitchell88]. The subjective effects 
of temporal filter- ing and sampling is also a complex subject for study [Hsu85]. Temporal aliasing could 
be removed by strong filtering, but such filters would have to span many frames and would lead to unacceptable 
blurring or ringing artifacts in moving objects. Figure 4 illustrates approximately how a CCD televi- 
sion camera filters an image by integrating over a rec- tangular region of space/time. The sensors in 
the CCD array integrate over regions one scanline high, and they are ganged together to average pairs 
of scanlines [Murata83]. This interlaced box filter averages over a rectangular region two scanlines 
high, one pixel wide, and one field-interval (l/60th second) in duration. Y ...... ~o I ...... : o 4 
: o l ...... , o , ...... scanlines I ...... I 1/30 sec 2/30 sec 3/30 sec Figure 4. Interlaced Spatiotemporal 
Box Filter In Figure 5, two images of the Fresnel zone plate are shown: on the left produced by an actual 
CCD camera, and on the right synthesized by FX using the interlaced box filter. Synthetic images were 
filtered by stochastic @SIGGRAPH '90, Dallas, August 6-10, 1990 sampling with 64 samples per pixeI. Figure 
6 shows a frame from a test animation, six humanoid figures revolving on a carousel. At 10 r.p.m., the 
figures move fairly rapidly in the foreground of the scene, but they can be tracked by the eye. It is 
interesting to consider other possible spatiotem- poral filters besides the interlaced box. Restricting 
our attention to volume-integration filters (unweighted aver- age over some volume of space/time), there 
are still a number of volume shapes that could be used. One alternative would be like Figure 4, but with 
the box filters rotated 90 degrees. This filter would aver- age over only one scanline of height and 
a full frame duration (l/30th second). Unfortunately, this filter yields far too much motion blur. Another 
interesting possibility is a spatiotemporal dia-mond shape, shown in Figure 7. Y ° o °° o ° - .  . 
 - , o°. l " oo . . . . . i .o "., o-°° - ° oo ,o "°  .o °. . °  scanlines ":.: o :.: :. . 
.°. .,. . o ," °°. oo" °Oo °. o ;; ;: ::° ..~ °°. °°° °.o . . o° ,.. .°°" °o°° o°0 %. . o . °. °. 
o ..° .° °° "°, .. "----.-" "-.-, = I 1/30 sec 2/30 see 3/30 sec Figure 7. Spatiotemporal Diamond Filter 
Altho this filter has a pleasing symmetry, the resulting video has serious problems. Again, there is 
too much motion blur, and too much vertical sharpness which causes interline flicker In fact, for the 
rotating-carousel animation, the best results were obtained by doing no motion blur at all. The filter 
used was like the interlaced box, but with no temporal width. At 10 r.p.m., motion judder was not apparent 
(even viewing digital video on studio moni- tors), and the image appeared noticeably sharper when no 
motion blur was used. Even without motion blur, it is still vitally important to generate samples that 
are interlaced in time. This is well known to animation experts [Chuang85]. The enlarged portion of Figure 
6 shows that a still frame from an interlaced animation has a serrated appearance. However, the moving 
image looks fine. If the anima- tion was generated without interlacing, the opposite effect is seen; 
still frames look fine, but the moving image has an unpleasant serrated appearance. Motion judder is 
not quite as serious a problem for video as it is in motion pictures, because the temporal sampling rate 
is higher. In an advanced renderer, an optional degree of temporal antialiasing would still be useful. 
Rapid period motion (e.g., a spinning wheel or a hummingbird's wings) demands temporal antialiasing. 
We believe the temporal width of the prefilter should be adjustable, like the shuttle angle in a motion 
picture camera. 5. Spatiotemporal Antlaliasing An annoying aliasing artifact of interlaced video is 
interline flicker. This is spatiotemporal aliasing caused by high spatial frequencies near 0.5 CPS (see: 
Figure 2) being replicated as a 30 Hz temporal frequency. Interline flicker can cause large areas of 
a display to flicker. However, a more typical manifestation of flicker is crawling jaggies or fluctuating 
Moire patterns. Unfortunately, there is a tradeoff between flicker and vertical sharpness. A filter like 
the spatiotemporal dia- mond is too sharp and causes a lot of flicker (as well as too much motion blur). 
To some extent, this is the fault of current display technology, as well as a prob- lem with interlacing 
itself. Better reconstruction of the video signal might remove flickering effects by postliltering to 
remove the offending sideband. But with current interlaced monitors, reduction of vertical sharpness 
is the only remedy. Moving jaggies seem to be most noticeable on near-horizontal edges moving vertically 
at a slow rate (around 30 scanlines per second). However, even when objects are stationary, flicker can 
be annoying. Figure 8 shows a side-by-side view of the even and odd scan lines of a frame of a stationary 
zone plate, prefiltered with a box filter only one scanline high. On an inter- laced display, these two 
complimentary Moire patterns alternate at 30 Hz. The image shimmers when viewed with a steady gaze, and 
blinking or head movement cause the Moire pattern to appear vividly. A more common (and less extreme) 
example of still images exhibiting interlace problems is line crawl. Moving jaggies can appear, even 
at the edges of a still image This is often seen in the output of poor-quality  @ ~ Computer Graphics, 
Volume 24, Number 4, August 1990 character generators. Some have suggested that strong vertical filtering 
be used when there is movement, and greater vertical sharpness allowed for still images [Chuang85]. We 
are not convinced that even this is safe, given that a still image with too much vertical sharpness can 
still exhibit line crawl and flicker as Figure 8 shows. Of the temporal filters described so far, the 
interlaced box (Figure 4) was the best. This filter is two scan-lines high, and its vertical frequency 
response (i.e., Fourier transform) is a sinc function with a zero at the offending frequency of 0.5 CPS. 
Smoother filters exist which have a notch in their spee- Irum at 0.5 CPS and attenuate other high frequencies 
better than a box filter. A family of smooth piecewise-cubic filters has been reported by Mitchell and 
Netravali [Mitchell88], and one member of that family has a notch at the desired frequency. In fact, 
this particular member of the family happens to be qua- dratic: -0.25 l Yl 2+0.5 if lYt <1 f(y) = .25 
lyl 2- ]yl +l.0 ifl_<]yl <2 otherwise The support of this filter is four units in width. One way of using 
it would be to sample a region of the image four scanlines high and weight the samples with this filter. 
A similar result is obtained by unweighted sampling within a shaped aperture with a width pro- portional 
to f (y) (as in Figure 9). This is reminiscent of the use of shaped apertures in early facsimile scanning 
machines [Mertz34]. As in those machines, the vertical frequency response of the aperture is designed 
to reduce aliasing. However, this aperture is not continuously moved across an image. Instead, each successive 
pixel value is derived by integrating within a corresponding fixed aperture, as shown in Figure 9. These 
apertures are two pixels wide (i.e., 4:2:2 standard pixels) at the center. This is done to ensure better 
horizontal filtering and to suppress chroma aliasing (discussed in the next seec-tion). In Figure 10, 
the even and odd scan lines of a zone plate are shown using this notch filter. The flickering Moir6 patterns 
are nearly absent. Y _ 3 ~ scanlines 2- _ X 1 2 3 4 pixels Figure 9. Notch-Filter Apertures 6. Chroma 
Aliasing No matter what type of video format a computer-generated animation is created on, it will almost 
cer-tainly be converted to composite video for broadcast or viewing on conventional home television sets. 
To maintain compatibility with older systems, composite video consists of a luminance (black-and-white) 
video signal with low-bandwidth chrominance (color) infor- mation encoded into a portion of the spectrum 
which usually contains little important information [Dubois88]. Figures 2 and 3 show the approximate 
location of the color subcarrier, which is modulated with the chromi- nance signal (consisting of two 
superimposed color sig- nals 90 degrees out of phase). From Figure 3, it is clear that if the luminance 
signal contains very high diagonal frequencies, it may overlap with the chromi- nance signal. The resulting 
chroma aliasing can be seen in Figure 11 as two colored bullseye patterns on the left and right sides 
(the aliasing at the top center is spatiotemporal). Chroma aliasing occurs at a later stage than spatial 
and temporal aliasing. It is created by the electronics that encode and'decode composite video signals. 
If the best encoding hardware is used, it is not generally a prob- lem (even in the test pattern shown 
in Figure 11), but such hardware'is expensive. The encoding that occurs in typical video recording equipment 
does not prefilter the video carefully enough before forming the compo- site signal. The notch aperture 
used to suppress interline flicker also does a fairly good job of reducing chroma aliasing. Because the 
filter is somewhat diamond shaped (see 81 SIGGRAPH '90, Dallas, August 6-10, 1990 Figure 9), it tends 
to attenuate diagonal frequencies. Chroma aliasing in the zone plate image was greatly reduced in comparison 
with the interlaced box filter. 7. Conclusions Generating synthetic interlaced video presents a number 
of problems not encountered when synthesizing a motion-picture animation. Interlaced scanning leads to 
the dilemma of having to choose between vertical sharpness or flicker. The color encoding of NTSC allows 
chroma aliasing if a scene contains high-frequency diagonal structure. In this paper, we describe some 
experiments with video synthesis and present an approach used in our multiformat rendering system. Interlace 
flicker is a problem in still images as well as scenes with motion. Better "de-interlacing" display systems 
could help someday, but all that can be done now is to deal with issues in the video source. This means 
reducing the vertical sharpness by suppressing frequencies around 0.5 cycles per scanline. Video syn- 
thesis software is not constrained to imitate television cameras, but our experiments with highly unconven-tional 
schemes, such as the spatiotemporal diamond filter, did not alleviate the flicker problem. Chroma aliasing 
and flicker are beth treated by area averaging of pixels over a shaped aperture. The shape of this aperture 
is selected so that its frequency response will have a notch at the vertical frequency of 0.5 CPS, and 
so that high diagonal frequencies will be suppressed. Temporal aliasing is a problem for both video and 
motion pictures. The tradeoff between motion blur and motion judder is complex and depends strongly on 
whether or not viewers track a moving object with their eyes. Temporal filtering should be an option 
which the artist can adjust. It is clear that aggressive low-pass filtering is not appropriate in the 
temporal domain, which is why sophisticated filter designs have not been considered. A possible future 
consideration is to allow the artist to apply different amounts of temporal filter- ing to different 
objects in the scene. 8. Acknowledgements We would like to thank Arun Netravali and Don Plan for many 
useful discussions about the theory of televi- sion. Many thanks to Gin Qua for his help in prepar- ing 
our video presentation. Thanks to Pat Hanrahan and the SIGGRAPH reviewers for their comments. 9. References 
[CCIR601] "Encoding Parameters Of Digital Televi- sion For Studios", CCIR Recommenda- tion 601-1. [Chuang85] 
Chuang, Richard, "Rendering for Televi- sion", SIGGRAPH Tutorial, 1985. [Cook84] Cook, Robert L., Thomas 
Porter, and Loren Carpenter, "Distributed Ray Trac- ing", SIGGRAPH 84, July 1984, pp 137-145. [Dubois88] 
Dubois, Eric, and William F. Schreiber, "Improvements to NTSC by Multidimen- sional Filtering", SMTPE 
Journal, June 1988, pp 446-463. [Hsu85] Hsu, Steve C., "Motion-Induced Degra- dations of Temporally Sampled 
Images", Master's thesis, MIT Department of Electrical Engineering, June 1985. [Murata83] Murata, Nobuo, 
et al., "Development of a 3-MOS Color Camera", SMPTE Jour- nal, December 1983, pp 1270-1273. [Mertz34] 
Mertz, Pierre, and Frank Gray, "A Theory of Scanning and Its Relation to the Characteristics of the Transmitted 
Signal in Telephotography and Televi- sion", Bell System Technical Journal, July 1934, pp 464-515. [Mitchell88] 
Mitchell, Don P., and Arun N. Netravali, "Reconstruction Filters in Computer Graphics", SIGGRAPH 88, 
August 1988, pp 221-228. [Potmesi183] Potmesil, Michael, and Indranil Chakra- varty, "Modeling Motion 
Blur in Computer-Generated Images," SIG-GRAPH 83, July 1983, pp 389-399. [Potmesi189] Potmesil, Michael, 
Eric M. Hoffert, "The Pixel Machine: A Parallel Image Com- puter", SIGGRAPH 89, July 1989, pp 69-78. 
[Tonge84] Tonge, G. J., "The Television Scanning Process", SMPTE Journal, July 1984, pp 657-666.   
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97889</article_id>
		<sort_key>87</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Parallel object-space hidden surface removal]]></title>
		<page_from>87</page_from>
		<page_to>94</page_to>
		<doi_number>10.1145/97879.97889</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97889</url>
		<abstract>
			<par><![CDATA[A parallel object-space hidden surface removal algorithm for polyhedral scenes is presented. The uniform grid technique is used to achieve parallelism for the hidden line removal. A conflict-detection and back-off strategy is then used to obtain parallelism for the visible region reconstruction from the visible segments. The algorithm has been implemented on a Sequent Balance 21000 shared-memory parallel computer. An average speedup of 10 has been obtained using 15 processors.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P300677</person_id>
				<author_profile_id><![CDATA[81100065460]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wm.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Randolph Franklin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electrical, Computer, and Systems Engineering Dept., Rensselaer Polytechnic Institute, Troy, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15036268</person_id>
				<author_profile_id><![CDATA[81100562305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohan]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Kankanhalli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electrical, Computer, and Systems Engineering Dept., Rensselaer Polytechnic Institute, Troy, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[1. Ajjanagadde V. G. and Patnaik L. M., "Design and Performance Evaluation of a Systolic Architecture for Hidden Surface Removal", <i>Computers & Graphics</i>, 12, 1 (1988), 71-74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[2. Akeley K. and Jermoluk T., "High-Performance Polygon Rendering", <i>Computer Graphics</i>, 22, 4 (August 1988), 239-246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>80672</ref_obj_id>
				<ref_obj_pid>80671</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[3. Akman V., Franklin W. R., Kankanhalli M. and Narayanaswami C., "Geometric Computing and Uniform Grid Technique", <i>Computer-Aided Design</i>, 21, 7 (September 1989), 410-420.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808586</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[4. Catmull E., "An Analytic Visible Surface Algorithm for Independent Pixel Processing", <i>Computer Graphics </i>, 18, 3 (July 1984), 109-115.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[5. Chandrasekhar N. and Franklin W. R., "An Efficient Parallel Algorithm for Determining Boolean Combinations of Complex Polyhedra" (in preparation).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808592</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[6. Dippe M. and Swensen J., "An Adaptive Subdivision Algorithm and Parallel Architecture for Realistic Image Synthesis", <i>Computer Graphics</i>, 18, 3 (July 1984), 149-158.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801143</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[7. Fiume E., Fournier A. and Rudolph L., "A Parallel Scan Conversion Algorithm with Anti-Aliasing for a General-Purpose Ultracomputer", <i>Computer Graphics </i>, 17, 3 (July 1983), 141-150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807480</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[8. Franklin W. R., "A Linear Time Exact Hidden Surface Algorithm", <i>Computer Graphics</i>, 14, 3 (1980), 117- 123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>7473</ref_obj_id>
				<ref_obj_pid>11840</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[9. Franklin W. R. and Akman V., "Reconstructing Visible Regions from Visible Segments", <i>BIT</i>, 26, 1986, 430- 441.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>810237</ref_obj_id>
				<ref_obj_pid>800179</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[10. Fuchs H., "Distributing a Visible Surface Algorithm over Multiple Processors", <i>Proceedings of the ACM Annual Conference</i> (1977), pp. 449-451.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74341</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[11. Fuchs H., Poulton J., Eyles J., Greer T., Goldfeather J., Ellsworth D., Molnar S., Turk G., Tebbs B. and Israel L., "Pixel-Planes 5: A Heterogeneous Multiprocessor Graphics System Using Processor-Enhanced Memories", <i>Computer Graphics</i>, 23, 3 (July 1989), 79- 88.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[12. Haines E., "A Proposal for Standard Graphics Environments", <i>IEEE Computer Graphics & Applications</i>, 7, 11 (November 1987), 3-5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[13. Hornung C., "A Method for Solving the Visibility Problem", <i>IEEE Computer Graphics & Applications</i>, 4, 7 (July 1984), 26-33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[14. Hu M. and Foley J. D., "Parallel Processing Approaches to Hidden Surface Removal in Image Space", <i>Computers & Graphics</i>, 9, 3 (1985), 303-317.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>95075</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[15. Joy K. I., Grant C. W., Max N. L. and Hatfield L., <i>Tutorial: Computer Graphics: Image Synthesis</i>, IEEE Computer Society Press, Washington D.C., 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807459</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[16. Kaplan M. and Greenberg D. P., "Parallel Processing Techniques for Hidden Surface Removal", <i>Computer Graphics</i>, 13, 1979, 300-309.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[17. Mulmuley K., "On Obstructions In Relation To A Fixed Viewpoint", <i>Proc. 30th Annual Symposium on Foundations of Computer Science</i> (Oct. 30 - Nov. 1, 1989), pp. 592-597.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[18. Overmars M. and Sharir M., "Output-Sensitive Hidden Surface Removal", <i>Proc. 30th Annual Symposium on Foundations of Computer Science</i> (Oct. 30 - Nov. 1, 1989), pp. 598-603.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807467</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[19. Parke F., "Simulation and Expected Performance Analysis of Multiple Processor Z-Buffer Systems", <i>Computer Graphics</i>, 14, 3 (July 1980), 48-56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74340</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[20. Potmesil M. and Hoffert E. M., "The Pixel Machine: A Parallel Image Computer", <i>Computer Graphics</i>, 23, 3 (July 1989), 69-78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[21. Rankin J. R., "A Geometric Hidden Line Processing Algorithm", <i>Computers & Graphics</i>, 11, 1 (1987), 11- 19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>73413</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[22. Reif J. H. and Sen S., "An Efficient Output-Sensitive Hidden Surface Removal Algorithm and its Parallelization", <i>Proc. fourth Annual Symposium on Computational Geometry</i> (June 1988), pp. 193-200.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[23. Sutherland I. E., Sproull R. F. and Schumacker R. A., "A Characterization of Ten Hidden Surface Algorithms", <i>ACM Computing Surveys</i>, 6, 1 (March 1974), 1- 55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>68349</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[24. Theoharis T., <i>Algorithms for Parallel Polygon Rendering </i>, Lecture Notes in Computer Science, Vol. 373, Springer-Verlag, Berlin, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>806789</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[25. Weinberg R., "Parallel Processing Image Synthesis and Anti-Aliasing", <i>Computer Graphics</i>, 15, 3 (Aug. 1981), 55-62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Parallel Object-Space Hidden Surface Removal Wm. Randolph Franklin* and Mohan S. Kankanhalli Electrical, 
Computer, and Systems Engineering Dept. Rensselaer Polytechnic Institute Troy, NY 12180 Abstract A parallel 
object-space hidden surface removal algorithm for polyhedral scenes is presented. The uniform grid technique 
is used to achieve parallelism for the hidden line removal. A conflict-detection and back-off strategy 
is then used to obtain parallelism for the visible region reconstruction from the visible segments. The 
algorithm has been implemented on a Sequent Balance 21000 shared-memory parallel com- puter. An average 
speedup of 10 has been obtained using 15 processors. CR categories: 1.3.3, 1.3.5, 1.3.7.  INTRODUCTION 
Hidden surface removal has been well-researched by the com- puter graphics and computational geometry 
communities. There is a wealth of literature on sequential hidden surface removal algorithms. The classic 
paper on hidden surface re- moval algorithms is by Sutherland, Sproull and Schumacker [23]. They introduced 
the taxonomy of hidden surface algo- rithms: image-spacealgorithms which iterate over the pixels of the 
display screen and determine the intensity of each of them, object-space algorithms which determine visibility 
of the objects of the scene such as a face and list-priority al-gorithms which work in object-space initially 
but the final output is in image-space. Joy at. al. present an up-to-date review of the field in their 
tutorial on image synthesis [15]. Some recent hidden surface removal algorithms are [17], [18]. There 
have been several studies on parallel image-space hidden surface removal [4], [7], [10], [14], [16], 
[19], [24]. Hardware implementations of image-space algorithms have been considered extensively [1], 
[2], [6], [11], [20], [25], but there has not been much work in the area of parallel object- space hidden 
surface removal. Hornung has developed an object-space algorithm which reduces the computation time for 
a network of polygons [13]. He then considers issues of extending this approach for a parallel machine. 
He gives general guidelines for parallelizing the algorithm but no spe- cific details are given. Rankin 
describes a hidden line re- moval algorithm which can be parallelized [21]. However, *Email: wrf@ecse.rpi.edu, 
Phone: (518) 276-6077 Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. it cannot be extended for the hidden surface problem. Reif and Sen have presented 
an object space parallel hidden sur- face algorithm which runs in time O(log4(n + k)) using n+k O -k~-~- 
 (log(~+k)) processors on a CREW PRAM model [22]. This method is valid only for surfaces of the form 
z = f(x,y). The algorithm is extremely complicated and the authors admit that their algorithm is not 
practical. Our aim has been to develop an efficient, parallel, ob- ject space hidden surface removal 
algorithm which is simple enough to be implemented on real parallel computers. This algorithm is based 
on the Franklin algorithm [8]. 2 PRELIMINARIES The key behind the parallelism achieved is the Uniform 
Grid technique. The uniform grid is a flat, non-hierarchical grid which is superimposed on the data. 
The grid adapts to the data since the number of grid cells, or resolution is a func- tion of some statistic 
of the input data, such as the average length of the edges. The grid is completely regular i.e. it is 
not finer in the denser regions of the data. The use of the uniform grid technique will become apparent 
from the algo- rithm presented in the next section. One objection against the uniform grid technique 
could be that it is not suitable for irregular scenes and that hierarchical methods such as quadtrees 
need to be used. But this has not been a prob- lem in practice [3]. From the parallel processing viewpoint, 
implementation becomes a lot easier with a flat data struc- ture since the overhead on scheduling can 
be reduced by using a static scheduling scheme. Readers are referred to [3] for fiarther details on the 
uniform grid technique and its applications to geometric computing. It is assumed that a perspective 
transformation has been applied on the scene so that the viewpoint is at infinity in the Z direction 
and the orthographic projection can be used. The scene consists of polyhedra with non-intersecting planar 
faces. The polyhedra are specified by their vertices, edges and faces. The vertices (edges) are ordered 
around the face. It is also assumed that the scene is scaled and projected to fit a 1 x 1 window. The 
output is a set of polygons where each polygon is an ordered list of vertices (edges). Definition: A 
blocking face of a grid cell is the front- most face, from the viewpoint, whose projection covers the 
cell completely (Figure 1). If it exists for a cell, then all faces of the cell behind the blocking face 
are invisible from the viewpoint. The blocking face helps eliminate a lot of unnecessary computation. 
The algorithm for hidden surface removal without the &#38;#169;1990 ACM-0-89791-344-2/90/008/0087 $00.75 
87 O SIGGRAPH '90, Dallas, August 6-10, 1990 1 :2 3 ............ i ..... i i .........i"; ....... 
.......... .......... J...9 ... Figure h Face "f" is the blocking face for cell 5 visible region reconstruction 
is now presented. The algo-rithm for visible region reconstruction in parallel, which uses a conflict-detection 
and back-off strategy, is presented sub- sequently. 3 THE ALGORITHM In this algorithm, the scene is 
organized into buckets (cells) using the uniform grid technique. The edges are then inter- sected to 
obtain the visible segments. The visible regions are obtained from the visible segments. Finally, a point 
in the visible region is used to find the shading value of that region. 1. Determine a grid size G using 
some statistic of the input scene, such as G = cmin(~, vfn) , where /is the average length of the edges, 
c is a constant and n is the number of edges. 2. Cast a G × Ggrid on the scene. For each of the pro- 
jected faces in parallel, determine which cells it covers -either fully or partially. Let f = current 
face being considered and fb be the current blocking face. If f covers the cell fully, compare it with 
the fb of that cell. If f is in front of fs, then f is the new blocking face, else it is to be discarded. 
If f does not cover the cell fully and it is in front of fb, then add it to the list of faces for that 
cell. This whole step can be done in parallel. 3. For each cell in parallel, compare the partially cover- 
ing faces with the cell's blocking face. If any face is behind the blocking face then discard it from 
the list of faces for that cell. This step is needed to remove some partially covering faces that were 
in front of a previous blocking face but are behind the final blocking face for that cell. 4. For each 
projected edge in parallel, determine the grid cells it belongs to. Check if the edge is behind the blocking 
face for each cell. If it is not, then add it to the list of edges for that cell. 5. For each cell in 
parallel, determine the intersection points of the projected edges in that cell. Consider the intersection 
only if it lies in that cell. Associate the intersection point with both the edges.  6. For each edge 
in parallel, sort the intersection points along it and partition the edge into segments. Each segment 
is either completely visible or completely hid- dell. 7. For each segment in parallel, check its visibility 
by comparing with the blocking face and the list of par- tially covering faces. If it is visible, add 
it to the list of visible segments. 8. In parallel, determine the regions formed by the visi- ble segments. 
This is the visible region reconstruction problem. The parallel algorithm for this problem is presented 
in section 4. 9. For each polygon of the visible regions in parallel, take a point inside that polygon. 
In the cell containing the point, find the closest face in which the point lies. Since that polygon is 
a part of that face, assign the shading value of the face to the polygon. If the point does not lie in 
any face, assign the background shading value to that polygon.  4 VISIBLE REGION RECONSTRUCTION IN 
PARALLEL Visible region reconstruction is a planar graph traversal pro- blein. More specifically, let 
E be a set of edges in the XY- plane such that the members of E constitute a legal planar subdivision. 
This means that every face (region) is bounded except for the outer ones which are infinite in size. 
The planar graph traversal finds the regions of the planar sub- division given in terms of its edges. 
The regions are to be specified by their vertices (or edges) in a positive order. For hidden surface 
removal, the edges are the visible segments and the regions found are the visible parts of the projected 
faces of the input scene. The algorithm we present for this problem is an extension of the Franklin-Akman 
algorithm [9]. A conflict-detection and back-off strategy is introduced to extend the algorithm for parallel 
processing. The input is assumed to be a set of visible edges which constitutes a legal connected planar 
graph. This condition can be relaxed to allow for discon- nected components which are not geometrically 
nested. If this is not satisfied, then the depth ordering of the nested components is not known. So a 
preprocessing stage of find- ing the connected components would be necessary. We as- sume, without loss 
of generality, that the input has no nested components. Figure 2 shows an example of a legal input graph 
and an illegal input gralJh. 4.1 PARALLELISM STRATEGY Intuitively, the algorithm proceeds in this manner. 
For every vertex, the edges incident to it are obtained. The edges are then sorted around each vertex 
in some order (clockwise). Two consecutive edges in this sorted list define a corner of a face. These 
corners could be merged in parallel to obtain the faces. Each corner is marked in order to be used only 
once. The merging can be started in parallel, but there is a problem. Ideally, each processor should 
work on a different face but there is no a priori way of ensuring this. Hence con- flicts may arise if 
two processors are determining the same face. This conflict is resolved using a conflict-detection and 
back-off strategy. Each processor is given a priority num- ber (which is based on the processor identification 
number).    / / / / / Figure 2: Illegal input on left &#38; legal input on right In this strategy, 
each of the corners are initially marked as 'unused'. As soon as a processor works on a corner, if it 
is marked as 'unused ~, it is marked with that processor's priority number. If it is not marked as unused, 
it means it has been processed by some other processor whose pri- ority is the value of the mark and 
there is a conflict. If that priority is higher than the processor's priority, then the processors backs 
off and starts working on a new corner. If the priority is lower, then it overwrites the mark with its 
priority and continues the work. The other processor will ultimately find that this face is being worked 
on by a higher priority processor, so it will eventually back off. So, in this strategy, the higher priority 
processor continues the merg- ing and obtains the face. Once a face is obtained, then its vertices are 
marked so that it is not found by some other processor again. If there are severa| processors working 
on the same face, then the processor with the highest prior-ity among them will ultimately traverse the 
face. This may mean some loss of work and lower efficiency but asymptot-ically, with a large number of 
corners, the penalty will not be too much. In practice, the speedup obtained was roughly half of that 
of the other parts of the hidden surface removal algorithm. 4.2 REGION RECONSTRUCTION ALGORITHM The input 
to the algorithm consists of a set of n edges in the XY-plane specified by the end-point coordinates: 
E = {((~,1, y,l), (x,2,y,2));i = 1,..., n} No order is assumed in E. Now we want to find for each vertex, 
the edges around it. Therefore, all edges have to be considered twice -once by the first vertex and once 
by the second vertex. So, we construct in parallel: E 1 = {((x~2, y,2), (~,,, u,,)); ((~, u~), (~i2, 
u,~)) ~ E} Then, hash each edge in E t2 E 1 using the X and Y coor- dinates of the first end-point as 
the key. This can be done for each edge in parallel. By this operation, we have all edges having the 
same first end-point in the same bucket. The elements which are in a bucket are the edges of the pla- 
nar graph which have an end-point(vertex) equal to their key. We call the other end-points (vertices) 
of these edges a row and the common key vertex a pivot. The pivot is not included in the row. Thus the 
input planar graph can be visualized as a table made of a family of rows, each having a different pivot. 
Now, for each row in parallel, we sort the elements of the row about the pivot in an angular order. If 
the vertices are sorted in a clockwise order, then the fi- nal faces (except the infinite face) output 
by the algorithm will be in a counter-clockwise order and vice-versa. We call -this final table of sorted 
elements the Navigation Table. The navigation is carried out on this table to obtain the regions (faces). 
The algorithm for navigating in parallel is presented in the next section. This procedure actually finds 
the faces. An example of an input graph, the navigation table and the faces is shown in figure 3. 4.3 
NAVIGATION PROCEDURE Assume that each processor has a unique id and all the ele- ments of the rows have 
been marked as unused (mark = -1). The processor priority number is its id and larger priority number 
implies higher priority. The navigation procedure is executed by each processor in parallel with each 
processor handling a different pivot (and its row). for each row of navigation table in parallel { current_pivot 
= first element of the row; for each element of the row { current_row = current_pivot; current_vertex 
= this element; face = {current_pivot}; /* Ist vertex of the face is the pivot */ do ~orever { lock( 
current_vertex mark); /* Lock mark to ensure it is updated by only one processor */ if my_id < mark(current_vertex) 
{ break; /* this face is being traversed by a higher id processor so back off. Move to next element 
of the row. */ } /* end if */ else mark current_vertex as used with my id; unlock( current_vertex mark); 
append current vertex to face;  O SIGGRAPH '90, Dallas, August 6-10, 1990 v4 v2 v3 v8 v6 v5 vl 1 Navigation 
Table: vl: v5, v2 v2: v3, vl v3: v7, v4, v2 v4: v8, v3 v5: vl, v6 v6: v8, v7, v5 v7: v3, v6 v8: v6, v4 
 2 The Faces Obtained: fl:(vl, v5, v6, v8, v4, v3, v2) f2:(v2, v3, v7, v6, v5, vl) fa:(v3, v4, v8, v6, 
v7) Figure 3: Example of a Navigation Table if current_vertex = current_pivot { output face and mark 
all vertices of the face with infinity; /* we have found the face */ goto next element of the row; } 
/* end if */ previous_row = current_row; current_row = current_vertex; current_vertex = the element 
of current_row following the previous_row with wrap around; } /* end do forever */ } /* end for each 
element */ } /* end for each row in parallel */   5 ANALYSIS OF THE ALGORITHM 5.1 CORRECTNESS Tile 
correctness of the algorithm given in section 3 is easy to see because it is a refinement of the following 
naive al- gorithm: Intersect all pairs of edges by pairwise comparison and divide the edges into segments. 
Each segment is fully visible or fully hidden. Compare each segment with all the faces to determine its 
visibility. Construct the visible regions from the visible segments and compare each region against all 
faces to see which face it corresponds to and shade it accordingly. The correctness of the region reconstruction 
algorithm is also easy to see. The navigation algorithm is correct because we cover all pivots and each 
element of a row is considered exactly once by only one of the processors. All elements of the rows are 
considered because the processor assigned to a pivot begins the navigation for each eleinent of the row. 
So all elements are traversed which gives all the faces. 5.2 COMPLEXITY For tile analysis, we assume 
a Concurrent-Read Exclusive-Write (CREW) PRAM model of computation. Let p be the number of processors. 
For the sake of the analysis, the input scene is assumed to consist of isothetic squares inde- pendently 
and identically distributed (i.i.d.) Each edge is of length l. For computing the grid size, we use: G 
= cmin(~-, x/7~) Assume that: C e=- 1 Since the cell size is a constant of the face size as n increases, 
the probability p that a given face completely covers a face is: c_l 2 v = (~-7~),c>l As the number 
of faces in the cell increases to infinity, the expected number of the first blocking face q is: co q 
= Eip( 1 _p)i-1 = _1 = (c+ 1) 2 p c-1 i=1 Therefore, the expected number of faces in a cell after the 
faces behind the blocking face is deleted (step 3 of the algorithm) is bounded by q. Let r be the expected 
number of ceils in which a face falls. We have: = (c + i) ~. 90, Let number of faces S= n So, the 
number of faces per cell before step 3 is ~ of which q faces per cell are not deleted. So the fraction 
of faces left after step 3 is: qC ~ (c_~)2 1 rsn --sg 2 n This is also the fraction of the edges that 
are in a cell af- ter the cell grid is cast because the edges are also similarly distributed. Let u be 
the average number cells in which an edge falls. We have: u=c+l. The average number of edges per cell 
is ~. So, the average number of edges per cell left after deletions is: qG 2 un qu c + 1 rsn " a 2 rs 
(c-1)2s which is a constant. Therefore, intersecting the edges in a cell takes a constant time. It also 
implies that an edge is partitioned into a bounded number of segments. Since the number of faces in a 
cell, the edges in a cell and the number of intersections in a cell are bounded by constants as shown 
above, we can deduce the following time complexities. Steps 1 and 2 of the algorithm take a time of O(~). 
Steps 2 and 3 take a time of O(-~) = O(~). Step 4 will again take a time of O(~). Steps 5, 6 and 7 will 
take a time of O(-~) = O(~). Therefore, the parallel hidden line removal algorithm takes a time of O(~) 
for n faces using p processors. For the visible region reconstruction, assume that we have k visible 
segments. Obtaining the navigation table with the elements of a row unsorted will take a time of 0(~) 
since hashing is used. Sorting the rows of the navigation table can at worst be O(k log k) since the 
maximum degree of the star vertex of a star graph (which is one of the worst-case in- puts to the algorithm) 
can be O(k). But, if such a case is detected and parallel sorting is used, this can be reduced to O(log 
k) using O(k) processors. But, we assume a worse complexity of O(klog k) for this step. For the navigation 
algorithm, consider the (hypothetical) worst-case in which the conflicts are not detected and all the 
processors find all the faces around its assigned vertices. The complexity of the navigation step for 
a row is then O(d~fav), where fay is the average size of a face. The worst-case for this step is a graph 
which is either a simple cycle or a star graph and for both cases the time complexity is O(k). But in 
actual practice, we will do better than that because conflicts are detected in the algorithm and the 
average input is not likely to be the worst-case input. Then, step 9 of the algorithm takes O(-~-) = 
O(~). So for the parallel hidden surface removal algorithm, the time complexity is of O"(7 + klog k) 
where n is the number of input edges, k is the number of visible segments and p is the number of processors 
assuming a CREW PRAM model of computation. Note that though the klogk term in the complexity suggests 
that the algorithm may not perform well, our implementation suggests otherwise. The reason for this is 
that the average data is not worst-case and secondly, the region reconstruction takes a small fraction 
(less than 10%) of the total time when p is equal to one. So, the algorithm is basically linear in the 
number of faces and the speedup is linear with the number of processors. The results are presented in 
the following section. 6 IMPLEMENTATION AND RESULTS Practical implementation of parallel algorithms 
is extremely important since the theoretical performance does not take into account the limitations of 
resource contention and com- munication costs of real parallel machines. These factors can severely limit 
the speedups obtained. So, we imple- mented the algorithm on a Sequent Balance 21000 computer, which 
contains 16 National Semiconductor 32000 processors and compared the elapsed time when up to 15 processors 
were used to the time for only one processor. Since the Se- quent Balance 21000 is a shared memory parallel 
computer, shared data structures are the communication mechanism for the processors. The synchronization 
of the processors is achieved by using atomic locks. The programming was done in C using the Sequent's 
parallel processing library routines for multitasking and synchronization. For testing the implementation, 
we used the tetrahedral pyramid (figure 4) and the meshed gears (figure 5) databases from the "Standard 
Procedural Database" proposed by Eric Haines [12]. The results from processing the tetrahedral pyramid 
having 4096 faces (each of which is a triangle) is shown in figure 6. It is seen that an almost linear 
speedup is obtained by adding more processors. For 15 processors (which is the maximum that can be used), 
a speedup of 11 is obtained. The results for the meshed gears database which had 16 faces with 144 vertices 
and 1152 faces with 4 vertices is shown in figure 7. Here also, an almost linear speedup has been obtained 
and a speedup of 10 has been obtained for 15 processors. Note that though the speedup is linear, it is 
not the ideal speedup because of the overhead for forking the processes and locking of the data structures. 
The speedup is linear for the hidden line removal part but for the visi- ble region reconstruction part, 
the speedup increases much slower. For 15 processors, the speedup obtained is about 6. But the time for 
region reconstruction is a small fraction, typically 3% to 10%, of the total time for the hidden surface 
removal. So, the overall speedup obtained is almost linear. This means that we should achieve an even 
bigger speedup on a machine with more processors. We are currently inves- tigating the viability of the 
techniques used in this algorithm on SIMD (Connection Machine) and message-passing (Hy- percube) architectures. 
 7 CONCLUSIONS We have presented a new parallel object-space hidden sur- face removal algorithm. This 
algorithm is practical and has been successfully implemented on a commercial parallel ma- chine. The 
uniform grid technique has been used to exploit parallelism in the geometric aspects of hidden surface 
re-moval. The uniform grid technique could be successfully used for parallelizing other geometric problems 
[3], [5]. A conflict-detection and back-off strategy has been introduced to achieve parallelism in the 
visible region reconstruction which is related to the topological aspects of the problem. This technique 
could be useful in parallelizing the topolog- ical aspects of other problems like polyhedron intersection 
and map overlay in cartography. These techniques lead to  O SIGGRAPH '90, Dallas, August 6-10, 1990 
 Figure 4: TetrahedrM Pyramid Figure 5: Meshed Gears practical parallel algorithms which has been 
demonstrated by the implementation of the object-space hidden surface removal algorithm. 8 ACKNOWLEDGEMENTS 
This work was supported by NSF Presidential Young Inves- tigator grant CCR-8351942. Partial support for 
this work was provided by the Directorate for Computer and Infor- mation Science and Engineering, NSF 
Grant No. CDA-8805910. We also used equipment at the Computer Sci-ence Department and Rensselaer Design 
Research Center at RPI. Part of this work was conducted using the computa- tional resources of the Northeast 
Parallel Architectures Cen- ter (NPAC) at Syracuse University, which is funded by and operates under 
contract to DARPA and the Air Force Sys- tems Command, Rome Air Development Center (RADC), Griffiss Air 
Force Base, NY, under contract No. F306002-88-C-0031. Part of the research reported here was made possible 
through the support of the New Jersey Commis- sion on Science and Technology and the Rutgers University 
CAIP Center's Industrial Members. 9 REFERENCES 1. Ajjanagadde V.G. and Patnaik L.M., "Design and Per- 
formance Evaluation of a Systolic Architecture for Hid- den Surface Removal", Computers ~ Graphics, 12, 
1 (1988), 71-74. 2. Akeley K. and Jermoluk T., "High-Performance Poly- gon Rendering", Computer Graphics, 
22, 4 (August 1988), 239-246. 3. Akman V., Franklin W.R., Kankanhalli M. and Nara- yanaswami C., "Geometric 
Computing and Uniform Grid Technique", Computer-Aided Design, 21, 7 (Sept- ember 1989), 410-420. 4. 
Catmull E., "An Analytic Visible Surface Algorithm for Independent Pixel Processing", Computer Graph- 
ics, 18, 3 (July 1984), 109-115. 5. Chandrasekhar N. and Franklin W.R., "An Efficient Parallel Algorithm 
for Determining Boolean Combi- nations of Complex Polyhedra" (in preparation). 6. Dippe M. and Swensen 
J., "An Adaptive Subdivision Algorithm and Parallel Architecture for Realistic Im- age Synthesis", Computer 
Graphics, 18, 3 (July 1984), 149-158. 7. Fiume E., Fournier A. and Rudolph L., "A Paral- lel Scan Conversion 
Algorithm with Anti-Aliasing for a General-Purpose Ultracomputer", Computer Graph- ics, 17, 3 (July 1983), 
141-150. 8. Franklin W.R., "A Linear Time Exact Hidden Surface Algorithm", Computer Graphics, 14, 3 
(1980), 117- 123. 9. Franklin W.R. and Akman V., "Reconstructing Visible Regions from Visible Segments", 
BIT, 26, 1986, 430- 441. 10. Fuchs H., "Distributing a Visible Surface Algorithm over Multiple Processors", 
Proceedings of the A CM Annual Conference (1977), pp. 449-451.  Computer Graphics, Volume 24, Number 
4, August 1990 11. Fuchs H., Poulton J., Eyles J., Greer T., Goldfeather J., Ellsworth D., Molnar S., 
Turk G., Tebbs B. and Israel L., " Pixel-Planes 5: A Heterogeneous Multi-processor Graphics System Using 
Processor-Enhanced Memories", Computer Graphics, 23, 3 (July 1989), 79- 88. 12. Haines E., "A Proposal 
for Standard Graphics Envi- ronments", IEEE Computer Graphics ~ Applications, 7, 11 (November 1987), 
3-5. 13. Hornung C., "A Method for Solving the Visibility Pro- blem", IEEE Computer Graphics ~ Applications, 
4, 7 (July 1984), 26-33. 14. Hu M. and Foley J.D., "Parallel Processing Approaches to Hidden Surface 
Removal in Image Space", Comput-ers ~ Graphics, 9, 3 (1985), 303-317. 15. Joy K.I., Grant C.W., Max 
N.L. and Hatfield L., Tu- torial: Computer Graphics: Image Synthesis, IEEE Computer Society Press, Washington 
D.C., 1988. 16. Kaplan M. and Greenberg D.P., "Parallel Processing Techniques for Hidden Surface Removal", 
Computer Graphics, 13, 1979, 300-309. 17. Mulmuley K., "On Obstructions In Relation To A Fix- ed Viewpoint", 
Proc. 30th Annual Symposium on Fo- undations of Computer Science (Oct. 30 -Nov. l, 1989), pp. 592-597. 
 18. Overmars M. and Sharir M., "Output-Sensitive Hid-den Surface Removal", Proc. 30th Annual Symposium 
on Foundations of Computer Science (Oct. 30 - Nov. 1, 1989), pp. 598-603. 19. Parke F., "Simulation 
and Expected Performance Ana- lysis of Multiple Processor Z-Buffer Systems", Com-puter Graphics, 14, 
3 (July 1980), 48-56. 20. Potmesil M. and Hoffert E.M., "The Pixel Machine: A Parallel Image Computer", 
Computer Graphics, 23, 3 (July 1989), 69-78. 21. Rankin J.R., "A Geometric Hidden Line Processing Algorithm", 
Computers fJ Graphics, 11, 1 (1987), 11- 19. 22. Reif J.H. and Sen S., "An Efficient Output-Sensitive 
Hidden Surface Removal Algorithm and its Paralleliza- tion", Proc. fourth Annual Symposium on Computa-tional 
Geometry (June 1988), pp. 193-200. 23. Sutherland I.E., Sproull R.F. and Schumacker R.A., "A Characterization 
of Ten Hidden Surface Algorith- ms", ACM Computing Surveys, 6, 1 (March 1974), 1- 55. 24. Theoharis 
T., Algorithms for Parallel Polygon Ren- dering, Lecture Notes in Computer Science, Vol. 373, Springer-Verlag, 
Berlin, 1989. 25. Weinberg R., "Parallel Processing Image Synthesis and Anti-Aliasing", Computer Graphics, 
15, 3 (Aug. 1981), 55-62.  SIGGRAPH '90, Dallas, August 6-10, 1990 500 15- 400 10 Total 300 Time Speed 
(secs.) 200 Up 100 I I I I I I I I I I 00 3 6 9 12 15 00 3 6 9 12 15 Number Of Processors (a) Number 
Of Processors (b) Figure 6: Timing for Tetrahedral Pyramid with grid size = 40. 700 15 600 500 10 
 Total 400 Time Speed (secs.) 300 Up 200 5 100 I I I I I  I I I I I 00 3 6 9 12 15 0 0 3 6 9 12 15 
Number Of Processors (a) Number Of Processors (b) Figure 7: Timing for Meshed Gears with grid size = 
32. 94   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97890</article_id>
		<sort_key>95</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Hidden curve removal for free form surfaces]]></title>
		<page_from>95</page_from>
		<page_to>104</page_to>
		<doi_number>10.1145/97879.97890</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97890</url>
		<abstract>
			<par><![CDATA[This paper describes a hidden curve algorithm specifically designed for sculptured surfaces. A technique is described to extract the visible curves for a given scene without the need to approximate the surface by polygons. This algorithm produces higher quality results than polygon based algorithms, as most of the output set has an exact representation. Surface coherence is used to speed up the process. Although designed for sculptured surfaces, this algorithm is also suitable for polygonal data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Verification</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39041104</person_id>
				<author_profile_id><![CDATA[81100400502]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gershon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14061451</person_id>
				<author_profile_id><![CDATA[81100146161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Elaine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, University of Utah]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>806007</ref_obj_id>
				<ref_obj_pid>800196</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Appel. The Notion of quantitative Invisibility and the Machine Rendering of Solids Proceedings A CM National Conference 1967.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807364</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Blirm. A scan line algorithm for displaying parametricaly defined surfaces. Computer Graphics 12.3. 1977.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Bruderlin, E. Cohen, and G. Elber. A Plane-Sweep Hidden-Surface Algorithm for Curved Surfaces. Technical report No. 90-006, Computer Science, University of Utah.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Sequin and P. Wensley. Visible Feature Return at Object Resolution. IEEE Computer Graphics and Application, May 1985, pp 27-50.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Cohen, T. Lyche, and R. Riesenfeld. Discrete B-splines and subdivision Techniques in Computer-Aided Geometric Design and Computer Graphics. Computer Graphics and Image Processing, 14, 87-111 (1980).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91422</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Griswold and M. Cohen. Automatic Illustration of 3D Geometric Models: Lines. Proceedings of the 1990 Symposium on Interactive 3D Graphics.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Fuson. Application of a Hidden Line Algorithm to Surface Visualization. MS thesis, Computer Science, University of Utah, 1984.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>362921</ref_obj_id>
				<ref_obj_pid>362912</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Galimberti and U. Montaaaari. An algoritlml for Hidden Line Elimination CACM 12, 4, 206, April 1969.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563895</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. Hamlin and C. W. Gear. Raster-scan hidden surface algorithm techniques Computer Graphics, Vol 11, pp 206- 213, 1977.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Hornung. An Approach to a Calculation-Minimized Hidden Line Algorithm. Computer &amp; Graphics, Vol 6, No 3, pp 121-126, 1982.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. Hornung. A Method for Solving the Visibility Problem IEEE CG&amp;A July 1984, pp. 26-33.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[(3. Hornung, W. Lellek, P. Pehwald, and W. Strasser. An Area-Oriented Analytical Visiblity Method for Displaying Parametrically Defined Tensor-Product Surfaces. Computer Aided Geometric Design, 2 (1985) 197-205.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Foley and A. VanDam. Fundamental of interactive Computer Graphics.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[G. Elber and E. Cohen. Hidden Curve Removal for Untrimmed and Trimmed NURB Surfaces. Technical report No. 89-019, Computer Science, University of Utah.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>40992</ref_obj_id>
				<ref_obj_pid>40988</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[R. Guting. New Algorithm for Special Cases of the Hidden Line Elimination Problem. Computer Vision, Graphics, and Image Processing 40, 188-204 (1987).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[I. Sutherland, R. Sproull, and R. Schumacker A Characterization of ten Hidden-Surface Algorithms. Computer Surveys, Vol. 6, No. 1, Max. 1974, pp. 1-55.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35042</ref_obj_id>
				<ref_obj_pid>35039</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Kamada and S. Kawai. An Enhanced Treatment of Hidden Lines. ACM Transaction on Graphics, Vol 6, No. 4, October 1987, Pages 308-323.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5155</ref_obj_id>
				<ref_obj_pid>5149</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Kripac. Classification of edges and its application in determining visibility. Computer Aided Design, Volume 17, Number 1, January/February 1985.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Lane and R. Riesenfeld. A Theoretical Development for the Computer Generation and Display of Piecewise Polynomial Surfaces. IEEE Transaction on pattern analysis and machine intelligence, vol. PAMI-2, No. 1, January 1980.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>55189</ref_obj_id>
				<ref_obj_pid>55185</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[L. Li. Hidden-line algorithm for curved surfaces. Computer Aided Design, Volume 20, No. 8, October 1988, Pages 466- 470.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[P. Loutrel. A Solution to the Hidden.line Problem for Computer Drawn Polyhedra IEEE Transactions on Computers, Vol. C-19, No. 3, 205-213, March 1970.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27627</ref_obj_id>
				<ref_obj_pid>27625</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Mckerma. Worst-Case Optimal Hidden-Surface Removal. ACM Transaction on Graphics, Vol 6, No. 1, 2anuary 1987, Pages 19-28.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[C. Montani and M. Re. Vector and Raster Hidden-Surface Removal Using Parallel Connected Stripes. IEEE Computer Graphics and Application, July 1987, pp 14-23.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4454</ref_obj_id>
				<ref_obj_pid>4450</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[O. Nurml. A Fast Line-Sweep Algorithm for Hidden Line Elimination. BIT 25 (1985}, pp 466-472.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[J. Peterson. PItT - A High Quality Image Systhesis System for B-spline Sm~taces. MS thesis, Computer Science Dept., University of Utah, Dec. 1987'.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[J. Ranldn. A Geometric Hidden-Line Processing Algorithm. Comput. &amp; Graphics Vol. 11, No. 1, pp. 11-19. 1987'.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>49188</ref_obj_id>
				<ref_obj_pid>49182</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[T. Sederberg and R. Meyers. Loop Detection in Surface P~tch Intersections. Computer Aided Geometric Design 5, pp 161-17'1, 1988.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>18559</ref_obj_id>
				<ref_obj_pid>18548</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[T. Sederberg and S. Parry. Comparison of Three Curve Intersection Algorithms. Computer Aided Design, Volume 18, Number 1, January/February 1986.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[M. Sweeney. Ray Tracing Free-Form B-Spline Surfaces. IEEE Computer Graphics and Application, Februaury 1986, pp 41-49.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Hidden Curve Removal for Free Form Surfaces* Gershon Elber and Elaine Cohen Computer Science Department 
University of Utah  Abstract This paper describes a hidden curve algorithm specifically designed for 
sculptured surfaces. A technique is described to extract the visible curves for a given scene without 
the need to approximate the surface by polygons. This algo- rithm produces higher quality results than 
polygon based algorithms, as most of the output set has an exact represen- tation. Surface coherence 
is used to speed up the process. Although designed for sculptured surfaces, this algorithm is also suitable 
for polygonal data. CR Categories and Subject Descriptors: 1.3.5 [Computer Graphics]: Computational Geometry 
and Object Modeling. 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. Additional 
Key Words and Phrases: hidden curve re- moval, curve-curve intersection, visibility propagation. Introduction 
 Hidden line removal is one of the earliest computer graphics problems; yet new algorithms appear every 
year [16,1,8,21,4,15,17,18,20,22,23,24,26]. Usually they are developed for polygonal data, so sculptured 
sur-faces must be preprocessed and approximated as large collections of polygons. The result displays 
the polygo- nized models accurately, but original model informa- tion is lost [4,18,20] (see figure 1). 
*This work was supported in part by DARPA (N00014-88-K-0689). All opinions, findings, conclusions or 
recommendations expressed in this document are those of the authors and do not necessarily reflect the 
views of the sponsoring agencies. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. In [16,1,8,21,26] the idea of quantitative invisibility and the use of critical 
points was developed. Crit-ical points are intersection points between projected polygon primitives. 
The technique was extended to bi-quadratic patches in [12]. The primitives are subdi- vided at each critical 
point which guarantees that the interior of each segment has homogeneous visibility. A segment's visibility 
is then tested by firing a ray from the eye to an interior point of the segment. While the same basic 
approach is used here, it is extended to apply to arbitrary nonuniform rational B-spline (NURBS) surfaces 
(the primitives). By not using polygonal approximations, the algorithm elimi- nates the vast amount of 
data resulting from the ap- proximation of surfaces by polygons. The algorithm presented here has several 
stages (including extracting curves of interest, splitting at critical points, and vis- ibility testing). 
Surface coherence is used extensively to reduce the number of ray tests one needs to perform to detect 
curve visibility, in a similar way to that for polygons[10,11]. The trade-off is a reduced number of 
primitives in exchange for a higher complexity of the operations be- tween them. Driving the output directly 
from the sur- face results in high quality images (Figure 1). Only silhouette curves need to be approximated, 
but they can be approximated at a much higher resolution than with pre-polygonized surfaces. Figure I 
compares the two, after adaptive subdivision has been used to obtain the polygonal approximations. Section 
2 defines the required elements for present- ing the algorithm and also introduces the basic hid- den 
curve algorithm. Section 3 briefly explains how the curves of interest are extracted from the surface. 
Usually four types of curves are useful: the surface boundary curves, curves along C 1 discontinuities 
in the surface (if any), iso-parametric curves, and silhou- ette curves. Section 4 addresses the 2D curve-curve 
&#38;#169;1990 ACM-0-89791-344-2/90/008/0095 $00.75 95 Figure 1: Left: 1930 polygons, middle: 4215 polygons, 
right: 2 NURBS surfaces (56 rational patches) intersection problems specific to this algorithm. Sec-tion 
5 presents issues in visibility testing arising from a surface-ray intersection algorithm. Computation 
of surface-ray intersections is relatively expensive, espe- cially when polygonal approximations to the 
surfaces have not been used, so methods to speed the compu- tation are described. Section 6 discusses 
extensions to this algorithm for trimmed surfaces. A more in depth treatment of the above issues can 
be found in [14]. All the images/comparison examples shown in this paper, were generated using nonuniform, 
rational B-spline (NURB) surfaces as implemented in the Alpha_l system. 2 The Basic Algorithm Let the 
view orientation be normalized so that the view point V is on the positive z-axis at ~ and the image 
is projected onto the plane z = 0, which will be referred to as the projection plane or the screen. All 
other views can easily be preprocessed into this view. Definition 2.1 1. A non-self-intersecting surface 
is called a simple surface. 2. A non-self-intersecting curve is called a simple curve. 3. Let P be the 
map to the projection plane, P(x,y, z) = (x,y,O). The subscript P will usually denote the mapped entity, 
 e.g., cp = P(C). We consider only simple surfaces whose projected curves are simple curves. Also, intersection 
between surfaces are restricted to lie along boundaries. If not, the surfaces should be intersected using 
the appropri- ate boolean operations, and trimmed surfaces should be created. Figure 9 has surfaces which 
interpenetrate, and so boundaries between them are unknown and vis- ibility cannot be always correctly 
determined. Suppose surface S = S(u, v) E C l, then N(u, v) =  ~Sxg'S 0"-~ ~ is normal to the surface 
S. Unless otherwise specified, all surfaces with which we deal are assumed to be C 1 continuous, and 
their parametrizations are assumed to be such that N(u, v) ~ O. If p is a point on the surface S, then 
it is the image of a point in parameter space, so we write p = S(u p, vP). Definition 2.2 1. A silhouette 
point of a surface is a point p on the surface whose normal has a zero z-component, i.e. Nz(u p, vP) 
_-- O. 2. A silhouette curve of surface S is an ordered set of silhouette points Q c S forming a continuous 
curve such that  V p E Q, andV e > O, 3 q E S such that Nz(u q, v') # O, and lip-qll < e. 3. If3 D 
C S that is the image of an open disk such that V d E D, Nz(u ~, v a) = O, we say that S has a silhouette 
surface and the above definition of the silhouette curve is simply its boundary. We will not consider 
surfaces with silhouette sub- surfaces in them. Surfaces that do contain silhouette surfaces may be preprocessed 
by trimming out the sil- houette sub-surfaces (see Section 6). Lemma 2.1 A surface S cart be decom-posed 
into silhouette curves and disjoint re-gions whose boundaries are surface bound-aries and/or silhouette 
curves. Proof: Consider a point p e S, Nz(uP, vP) ¢ O, and the set of points which can be reached from 
p by continuous paths in the surface that do not cross any silhouette curves. Let that set be Rp, and 
let Rq be a similar set for point q E S,q ~ R p, if such a point q exists. Clearly R v 1"7 R q = $, for 
if there exists point r E R p N R q, then there exists a continuous path from p to r and from r to q, 
and hence from p to q. But this contradicts the way we picked q. Call the collection of path connected 
regions T¢. For our proofs we require that the projection opera- tion be bijective between each R E 7~ 
and its projected image. Lemma2.2 Let R E 7~ and rl,r2 E R. Then, gz(url, vr,)Y,(ura, vr~) > O, i.e. 
they have the same sign at both rl and r~. Proofi Since there exists a continuous path from rl to r2 
totally in R, Nz along that path can have no zeros so Nz has the same sign at both rl and r2. We define 
invisibility as invisibility count of zero where: Definition 2.3 The invisibility count of a point p 
is the number of intersections of the half-open ray ~ from the view point V to the point p has with sculptured 
surfaces in the scene. We will concentrate our discussion on determining visibility only (i.e. where 
the count is zero), although one may use our algorithm to detect quantative invis- ibility [6]. Two types 
of curves are dealt with: Definition 2.4 1. Surface boundary curves and surface sil- houette curves are 
defined to be active curves. 2. The framework ~b s of a surface S is the set of all its active curves. 
Set ¢~ =  p(¢s). 3. Any curve which is not active is defined to be a passive curve. For example, an 
isoparametric curve is passive. Clearly active curves are those curves at which visi- bility of all 
curves can change when crossing them. Lemma 2.3 Let C be a curve in the scene. If Cp does not intersect 
UseS,, then all points p E C have the same invisibility count. Corollary 2.1 Given a curve C, let {C~} 
denote the collection of sub-curves of Cp re-sulting from subdividing Cp at each of its in- tersection 
points with UseSe, and let C ~ be each pre-image, i.e., C i C C. For each C i, all points p E C i have 
the same invisibility count, except possibly the two endpoints. The proof of lemma 2.3 can be found 
in [14]. Corol- lary 2.1 suggests an algorithmic way of testing visibility of curves in a scene. Obviously 
many projected curves will intersect with some projected frameworks, but the number of times they do 
is finite and usually small. For each of the subdivided curves, only one point in its open interval needs 
to be tested for its invisibility count. As noted in [2,11], silhouette curves can overlap; that is, 
a silhouette curve can be G 1 continuous and still have cusps in its projection (called a curtain fold 
[2]). Since the visibility of the silhouette curves may change at curtain folds, they must be split at 
these points. Using Corollary 2.1, we can define the basic algo- rithm: . Extract all curves of interest 
from the given sur- face(s) in the scene. This results in at least the framework of each surface, but 
can also include passive curves such as isoparametric curves. . Split each passive and active curve C 
at each point where its projection Cp intersects with any ¢~ and where cs is closer to the viewer. . 
For each curve that results from the previous stage, fire a ray in the view direction through an SIGGRAPH 
'90, Dallas, August 6-10, 1990 C 1 Discontinuity and Silhouette Bo~mdary Silhouette ~ G 1 Discontin~ty 
Figure 2: Four curve types in surface display. arbitrary interior point and find the invisibility count 
of that point. 4. If the invisibility count of the point is zero, then curve is shown, otherwise it 
is hidden. Based on Corollary 2.1, the evaluation of the invis- ibility count picks an arbitrary point 
p in the interior of curve C, and determines the visibility of all of C us- ing the invisibility count 
of p. Curves are always split at tangent intersections, since they could potentially change visibility 
at those points. A technique is used in [16,1,8,21,26] of splitting a line into segments anytime it intersects 
with any projected polygon boundary to make the segment visibility homogeneous. In the next sections, 
we will describe the different stages for ar-bitrary sculptured surfaces. This algorithm, although conceptually 
simple, does require accurate computa-tion in nonrobust numerical situations. We discuss our approaches 
to simplifying the operations and to reduc- ing the number of times these complex operations must be 
performed. Curve Extraction The four types of curves which we display are bound- ary curves, iso-parametric 
curves, curves along C 1 dis- continuities in the surface, and silhouette curves (see Figure 2). All 
but the last type are view independent. Extraction of the first three types of curves is usually extremely 
simple since these curves are isoparametric. For example, Figure 3 shows the same pawn as in Fig- ure 
1. We assumed the surfaces are C 1 continuous, but if some are not, they must be subdivided at the appropriate 
isoparametric values. This creates a new boundary and two new surfaces on which the algorithm is then 
correct. This splitting stage is only added when tangent plane discontinuities are present. lilli n 
n a o u I I -Iso-paramertic ...l|ii/|i   mmUmm niumimminn |-----Sill|Nil /mii/ml Figure 3: Pawn 
extracted curves, in u - v space. The silhouette curves are not isoparametric curves usually (Figure 
3), and in general, there is no compu- tationally feasible way to represent them exactly. An approximation 
technique must be used in this case, and a piecewise linear curve is the simplest choice. One method 
of extracting the silhouette curves of a surface is to subdivide the surface up to a given e toler- ance 
and fetch all the surface pieces with silhouettes on them. We seek methods using subdivision and spline 
properties to identify regions with silhouettes. To solve this problem we are interested only in the 
z component of g(u, v), N,(u,v) = 0=(u,v)00 (u,v)0 _ 0y( ,v)0u 0=(u,v)0 (1) Now if the first term on 
the right side of equation 1 is positive everywhere and the second negative every- where, Nn is positive 
everywhere. Lemma 3.1 Given a scalar B.spline surface n--I m--I a(u,v) = E E aijB',~.,~'.(u)BL'.,'.(v)' 
j=0 i=0 then oa(u,v) > 0 whenever ai+lj aij > 0 ou - Proof: Consider partial derivative of o" with respect 
Figure 4: Adaptive silhouette extraction, in R 3. Figure 5: Tangent CCI. to u. (90" n--1 m--2 0"-~ = 
E(k--1) E ai+l--"fi" "~ai"-"J Bi,k-l(U)Bj,t(v). j=O i:O Ti+k --Ti+l  Since the blending functions B 
are nonnegative, and the difference ri+k -ri+l > 0, if ai+l,j -ai,j > 0, for all i and j, ~ will be positive 
everywhere. Lemma 3.1, and an analogous version for aa can be ~, used on the x and y coordinate functions 
to provide a simple test for ruling out the existence of silhou- ette curves in a surface. Needing only 
O(mn) first or- der differences, it cart act as an additional termination condition for the subdivision. 
Figure 4 shows such an adaptive subdivision for a surface with three silhouette curves. One must trace 
the linear silhouette curve segments resulting from the subdivision process and connect them to form 
a piecewise linear approximations of the real continuous silhouettes. This solution frequently results 
in only poor approximations or else the pro- cess is time consuming. To improve the quality of each point 
obtained from the subdivision, a numerical technique is applied to make its approximation more accurate. 
The secant method is used with good con- vergence, because the subsurface pieces are relatively flat 
(from the flatness test during the subdivisions). Figure 6 shows the pawn object with the resulting po- 
tential silhouette sub-surfaces from another view (left), and improved (right). The result is a piecewise 
linear approximation of the real silhouette which is accurate on its vertices. One can adaptively improve 
the middle of each segment until the distance between the previ- ous and new are within tolerance. By 
including this improvement stage, we now have curve which has a high degree of accuracy, both in its 
resolution (num- ber of points) and accuracy of each point. 4 Curve-Curve Intersection Curve-curve intersection 
is not a problem specific to hidden curve removal algorithms. The solution to the curve-curve intersection 
problem is generally not available in analytic form, and some kind of subdivi- sion or iterative technique 
is used to determine those points [5,19,28]. We do not want to be restricted to a specific curve type 
or order, but would like as general a solution as possible. While the subdivision process guarantees 
convergence to all intersections, it is slow, and so effort is invested in finding methods to eliminate 
unnecessary subdivisions. The algorithm used here is based on combining as- pects of methods described 
in [5,19,28]. Strips (rotated bounding boxes) were used to bound the curves during the subdivision process. 
However, instead of carrying out all the subdivisions and then doing all the numer- ical improvement, 
the subdivision is alternated with a Newton's method at such point in the process that we can guarantee 
a unique intersection using cone tests (see [27]). It is required that we find the intersections between 
curves which are tangent to each other. Many inter- sections between iso-parametric curves and silhouettes 
are of this kind. For example, figure 5 is an enlarge-ment of one such problem region in figure 1. If 
two curves have the same tangent line at their intersec- tion point, the e selected as the error measure 
for the computation method affects the results. If it is too small, then the method may miss the intersection; 
if it is too big, several (approximated) intersection points may result close to each other, where only 
one actu- ally exists. When surfaces have been approximated by polygons exactly the same problem occurs. 
However, crossing of active curves in the projection plane must be detected since the visibility may 
change at such in- tersections (Lemma 2.3). In this specific case most of the tangential curve in- SIGGRAPH 
'90, Dallas, August 6-10, 1990 Figure 6: Sub-surfaces, potentially with silhouette, from different view 
(left), and improved (right). tersection can be considered in a simpler framework. Consider two parametric 
space curves that map onto curves in R 3 intersecting at simultaneous tangencies. In most cases (see 
Figure 5) one of the curves is a sil- houette curve and the other is isoparametric. Hence considering 
the intersection in parametric space re-duces it to the problem of intersecting a planar curve with a 
straight line. Another numerical instability may arise when deal- ing with curves whose projections are 
identical or have identical subcurves. If the curves are exactly the same, one can be eliminated. If 
two distinct curves project onto the same curve in the image space, but have different orders, knot vectors, 
or parametric continu-ity, there is currently no stable, computationally feasi- ble method for analytically 
determining that the two curves are identical. Instead a heuristic threshold on the maximum number of 
valid intersections is used. This solution causes some overhead which might be reduced by analytical 
detection of such cases. Given a curve-curve intersector, finding all the in-tersections among N curves 
the straightforward way of intersecting each curves against all the others is O(N2), which is the worst 
case possible. Usually one can do much better. Sweep algorithms to sort and improve Figure 7: Monotone 
curves have multiple intersection this order have been developed, mainly for straight line segments [15,9,22,24]. 
They improve the average case order to O(NlogN), but have the same worst case behavior of O(N2). Extending 
this notion for an arbi- trary curve type environment is complex since curves, unlike lines, may intersect 
more than once. In fact, two spline curves can be continuous and have no zeros in their first and second 
derivatives, but can intersect multiple times, as Figure 7 demonstrates. Although the current implementation 
of this algo- rithm uses a simplified bounding box sweep, research in this area is in progress. More 
on this can be found in [3]. Surface-ray intersection Finding intersections of rays with surfaces occur 
fre- quently in graphics and geometry problems, in particu- lax in the ray-tracing rendering technique[25,29]. 
Usu- ally freeform surfaces are first approximated into poly- gons or preprocessed into small simplified 
pieces. Both strategies require a relatively large amount of memory. Since only a partial invisibility 
count is needed, we need not solve for the exact intersection point. Lemma 5.1 Let S be a path connected 
con-tinuous surface with no silhouette curves, g p(¢S) is a simple curve, then S is visible rel- ative 
to itself, and therefore, all curves be-longing to S are totally visible relative to it. Proof: Since 
S has no silhouette curves, cs (defini-tion 2.4) consists only of S boundary curves, and ~ has exactly 
one element. Since p(¢S) is a simple curve, P is bijective on the interior of its whole domain. By making 
use of this lemma we can reduce signif- icantly the number of subdivisions required to solve the surface-ray 
intersection. When resolving the visi- bility of a given point p often one can use lemma 5.1, and decide 
on p-visibility much sooner than using only a subdivision technique. This decision can be made even if 
the exact intersection point of the ray from V to p with the surface S is unknown. Using curve visi- 
bility propagation and surface coherence, the number of rays that need to be fired can be reduced. Definition 
5.1 For a curve l?, Touching(l?) is the set @all curves, other than 13, that have one endpoint of their 
projections lying on ~p. If a curve o~ is split into oq and o~ at the parametric value where P(o 0 intersected 
with P(fl), such that cq has a lower parametric range than o~2, then: 1. as is the next curve oral, and 
will be denoted as c~2 = Next(a1). 2. oil is the previous curve of o~2, and will be denoted as gel = 
Prcv(c~2). 3. oq, o~2 E Touching(fl).  To use this coherence, the curve adjacencies of defini- tion 
5.1 must be determined and kept during the curve- curve intersection stage. Each time a curve is split, 
all the information on the splitting and split curves must be kept, in addition to the z level ordering 
relation be- tween them. Although, this might look time consum- ing, it is not. Each time a curve is 
split (a relatively complex operation), a constant number of adjacency pointers is updated. By doing 
so, one can derive a set of rules by which the visibility is propagated so fewer rays need be fired. 
The following corollary is only a subset of such rules and which will be sufficient to demonstrate its 
power: Corollary 5.1 If 0 is an active curve, ¢ E Touching(q), and 7 is split into 71 and 72 such that 
")'1,72 E Touching(rT), 71 = Prey(72) then (see Figure 8 for all refer-ence8) I. If ~7 is a silhouette 
curve of the surface a, and a has only one silhouette, then ~7 is visible relative ~o a. See h. 2. If 
17 is a visible silhouette curve, at least one of 71, 72 is visible. See a, b and c. If 7 is a passive 
curve or the scene has only closed models, then exactly one of 71, "Y2 is visible. See c. 3. If ~ is 
visible but not a silhouette curve, then exactly one of 71 , 72 is visible. See i. 4. Ire is passive 
curve and 77 is a boundary curve (but not a silhouette), and both have the same z at the touching point, 
then ¢ has the same visibility as 7. See f. 5. If rl E Touching(~b), both are boundary curves, and 
both ~ and ¢ have the same z at their touching point, then ~1 and ¢ have the same visibility. See g. 
 Proof.' All the above conclusions result directly from lemma 2.3. Each of these cases is simple by 
itself, but in combi- nation they form powerful visibility propagation tools. Corollary 5.1- 2 is unique, 
in that one needs more in- formation so the visibility of the adjacent curve can be resolved. A visible 
silhouette on closed objects must bound two regions, exactly one of which is visible, so only a single 
adjacent curve should be tested for visi- bility to classify the regions. For open objects, if a sil- 
houette curve splits a boundary curve, both subcurves may be visible (see a, Figure 8). I01 2.1 a 
b 2.2 4.2 C g i 3.1 3.2 Figure 8: The curves visibility is propagated - firing 2 rays is enough for 
all curves. Figure 9: A hidden curve view of the teapot. Propagation No propagation act. pas. tel. act. 
pas. rays rays time rays rays discont 9 14 5.5 19 96 saddle 2 2 8 8 54 wiggle 11 7 4.5 21 95 pawn 12 
68 i 1.9 17 ~ 152 Table 1: Visibility propagation comparison. We shall use Figure 8 to demonstrate the 
propaga- tion ability. Assume the framework curves are given in in the following order: the silhouette 
curve following by boundary curves 1, 4, 2, 3. The visibility of each curve in the framework is checked 
first. Using Corollary 5.1, since only one sil- houette curves exists, by result 1, it is visible. As 
this object is open, no propagation to the boundary curves is allowed. A ray is fired to test the visibility 
of boundary curve 1, and it is found to be visible. Using resutt 5.1-5, curves 2.1 (through i, Figure 
8) and 4.1 (through 2) are found to be visible. The next frame- work curve with unknown visibility is 
4 which has been split into two, 4.1 and 4.2. The first half (4.1) visibility is already known, so only 
one ray for the second half (4.2) is fired, and which find it to be visibile as well. Using result 5.1-5 
curve 4.2 (through 3) sets curve 3.2 to be visible, which in turn sets 3.1 (through 4), using result 
5.1-3, to be invisible. Since 3.1 touches curve 2.2 (at 5), at its end, 2.2 is also set, using result 
5.1-5, to be invisible. Instead of firing 8 rays, for the 8 active curves in the saddle surface (1, 2.1, 
2.2, 3.1, 3.2, 4.1, 4.2 boundary curves, and one silhouette), only 2 were fired. The question on the 
optimal way to order these curves is still open. But the improvement in this specific case in much greater. 
Using result 5.1-4, since all the iso-parametric curves touch boundary curves at the same z value, they 
inherit their visibility from that of the boundary. Using result 5.1-3, the visibility of the boundary 
curves is propagated to the interior iso- parametric pieces, so no ray need to be fired for any iso-parametric 
curve. In addition to all the above, if the number of surfaces is small, a cache of the subdivided surfaces 
can be han- dled. If a surface was subdivided once for given ray, all but the last few steps will be 
identical for nearby rays. The main problem with this approach is the amount of memory it may require, 
and so it may be useful only if the scene consists of a small number of surfaces. Table 1 compares this 
propagation in terms of num- ber of rays fired for active and passive curve and rel- Computer Graphics, 
Volume 24, Number 4, August 1990 II II II|| Figure 10: Support of trimmed surfaces. ative time to test 
the visibility of all the curves. Note the relation between the two is not linear mainly be- cause of 
the cache used.  6 Trimmed Surfaces An important issue to address is the support of trimmed surfaces. 
A careful look in the teapot (Fig- ure 9) uncovers a problem with the design near its handle/body joint. 
The model was originally done by juxtaposing the surface descriptions for the handle and body without 
trimming the surfaces, so the handle and the body surfaces interpenetrate. Curves which should be hidden 
at the joint are visible, since this algorithm cannot detect such cases. Using trimmed surfaces in the 
model and in the al- SIGGRAPH '90, Dallas, August 6-10, 1990 gorithm eliminates this difficulty. The 
modifications necessary in our algorithm to support trimmed surfaces were small and occurred in two stages 
of the algorithm. . The curve extraction stage needs to trim the ex- tracted curves against the trimming 
curves in the parametric space. . The surface-ray intersection stage should test if the point on surface 
S that hides the tested point is in a trimmed part of S. The trimming curves should be propagated through 
in the subdivision process, and a totally trimmed out surface can be another termination condition for 
the subdivision. Figure 10 shows the results of the modified algo- rithm. 7 Acknowledgements Particular 
thanks to the Alpha_l group for all their help and support in this research. References [1] A. Appel. 
The Notion of quantitative Invisibility and the Machine Rendering of Solids Proceedings ACM National 
Conference 1967. [2] J. Blinn. A scan line algorithm for displaying parametricaly defined surfaces. Computer 
Graplfics 12.3. 1977. [3] 13. Bruderlin, E. Cohen, and G. Elber. A Plane-Sweep Hidden-Surface Algorithm 
for Curved Surfaces. Technical report No. 90-006, Computer Science, University of Utah. [4] C. Sequin 
and P. Wensley. Visible Feature Return at Ob- ject Resolution. IEEE Computer Graphics and Applica- tion, 
May 1985, pp 27-50. [5] E. Cohen, T. Lyche, and R. Riesenfeld. Discrete B-splines and subdivision Techniques 
in Computer-Aided Geometric Design and Computer Graphics. Computer Graphics and Image Processing, 14, 
87-111 (1980). [6] D. Griswold and M. Cohen. Automatic Illustration of 3D Geometric Models: Lines. Proceedings 
of the 1990 Sympo- siurn on Interactive 3D Graphics. [7] V. Fuson. Application of a Hidden Line Algorithm 
to Sur- face Visualization. MS thesis, Computer Science, Univer- sity of Utah, 1984. [8] R. Galimberti 
and U. Monta~aari. An algorithm for Hidden Line Elimination CACM 12, 4, 206, April 1969. [9] G. Hamliu 
and C. W. Gear. Raster-scan hidden surface algorithm techniques Computer Graphics, Vol 11, pp 206- 213, 
1977. [10] C. Hormmg. An Approach to a Calculation-Minimized Hid- den Line Algorithm. Computer &#38; 
Graphics, Vol 6, No 3, pp 121-126, 1982. [11] C. Hornung. A Method for Solving the Visibility Problem 
IEEE CG&#38;A July 1984, pp. 26-33. 104 [12] C. Hornung, W. Lellek, P. Pehwald, and W. Strasser. An Area-Oriented 
Analytical Visiblity Method for Displaying Parametrically Defined Tensor-Product Surfaces. Com-puter 
Aided Geometric Design, 2 (1985) 197-205. [13] J. Foley and A. VanDam. Fundamental of Interactive Com- 
puter Graphics. [14] G. Elber and E. Cohen. Hidden Curve Removal for Untrimmed and Trimmed NURB Surfaces. 
Technical re- port No. 89-019, Computer Science, University of Utah. [15] R. Guting. New Algorithm for 
Special Cases of the Hid- den Line Elimination Problem. Computer Vision, Graph- ics, emd Image Processing 
40, 188-204 (1987). [16] I. Sutherland, R. Sproull, aaxd R. Schumacker A Char- acterization of ten Hidden-Surface 
Algorithms. Computer Surveys, Vol. 6, No. 1, Mar. 1974, pp. 1-55. [17] T. Kamada and S. Kawal. An Enhanced 
Treatment of Hid- den Lines. ACM Transaction on Graphics, Vol 6, No. 4, October 1987, Pages 308-323. 
[18] J. Kripac. Classification of edges and its application in determining visibility. Computer Aided 
Design, Volume 17, Number 1, January/February 1985. [19] J. Lane and R. Riesenfeld. A Theoretical Development 
for the Computer Generation and Display of Piecewise Polyno- mial Surfaces. IEEE Transaction on pattern 
analysis and machine intelligence, vol. PAMI-2, No. 1, January 1980. [20] L. Li. Hidden-line algorithm 
for curved surfaces. Computer Aided Design, Volume 20, No. 8, October 1988, Pages 466- 470. [21] P. 
Loutrel. A Solution to the Hidden.line Problem for Com- puter Drawn Polyhedra IEEE Transactions on Computers, 
Vol. C-19, No. 3, 205-213, March 1970. [22] M. Mckenna. Worst-Case Optimal Hidden-Surface Re- moval. 
ACM Transaction on Graphics, Vol 6, No. 1, Jan- uary 1987, Pages 19-28. [23] C. Montani and M. Re. Vector 
and Raster Hidden-Surface Removal Using Parallel Connected Stripes. It~EE Com- puter Graphics and Application, 
July 1987, pp 14-23. [24] O. Nltrrnl. A Fast Line-Sweep Algorithm for Hidden Line Elimination. BIT 25 
(1985), pp 466-472. [25] J. Peterson. PRT - A High Quality linage Systhesis System for B-spline Sin-faces. 
MS thesis, Computer Science Dept., University of Utah, Dec. 1987. [26] J. Rank_in. A Geometric Hidden-Line 
Processing Algo- rithm. Comput. &#38; Graphics Vol. 11, No. 1, pp. 11-19. 1987. [27] T. Sederberg and 
R. Meyers. Loop Detection in Surface Patch Intersections. Computer Aided Geometric Design 5, pp 161-171, 
1988. [28] T. Sederberg and S. PaJwy. Comparison of Three Curve Intersection Algorithms. Computer Aided 
Design, Volume 18, Number 1, January/February 1986. [29] M. Sweeney. Ray Tracing Free-Form B-Spline Surfaces. 
IEEE Computer Graphics and Application, Februaury 1986, pp 41-49.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97891</article_id>
		<sort_key>105</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Using tolerances to guarantee valid polyhedral modeling results]]></title>
		<page_from>105</page_from>
		<page_to>114</page_to>
		<doi_number>10.1145/97879.97891</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97891</url>
		<abstract>
			<par><![CDATA[A polyhedral solid modeler that operates on boundary representations of objects must infer topological information from numerical data. Unavoidable errors (due to limited precision) affect these calculations so that their use may produce ambiguous or contradictory results. These effects cause existing polyhedral modelers to fail when presented with objects that nearly align or barely intersect[10][7].An object description associating a tolerance with each of its topological features (vertices, edges, and faces) is introduced. The use of tolerances leads to a definition of topological consistency that is readily applied to boundary representations. The implications of using tolerances to aid in making consistent topological determinations from imprecise geometric data are explored and applied to the calculations of a polyhedral solid modeler. The resulting modeler produces a consistent polyhedral boundary when given consistent boundaries as input.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.4</cat_node>
				<descriptor>Reliability and robustness</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003705</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical software</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Reliability</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39083045</person_id>
				<author_profile_id><![CDATA[81100242032]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Segal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801152</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dennis S. Amon. Topologically reliable display of algebraic curves. Proceedings of SIGGRAPH'83 (Detroit, Michigan, July 25-29, 1983). In Computer Graphics 17,3 (July 1983), 219-227.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[John Francis Canny. The Complexity of Robot Motion Planning. PhD thesis, MIT, 1987.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73404</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[David Dobkin and Deborah Silver. Recipes for geometry &amp; numerical analysismpart I: An empirical study. In Proceedings of the Fourth ACM Symposium on Computational Geometry, pages 93-105, Urbana, Illinois, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Robin Forrest. Computational geometry and software engineering: Towards a geometric computing environment. in David E Rogers and Rae A. Earnshaw, editors, Techniques for Computer Graphics, pages 23-37. Springer-Verlag, New York, 1987.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13026</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. Randolph Franklin, Peter Y.E Wu, and Sumitro Samaddar. Prolog and geometry projects. IEEE CG &amp; A 6,11 (November 1986), 46-55.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73857</ref_obj_id>
				<ref_obj_pid>73833</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Leonidas Guibas, David Salesin, and Jorge Stolfi. Epsilon geometry: Building robust algorithms from imprecise computations. In Proceedings of the Fifth A CM Symposium on Computational Geometry, pages 208-217, 1989.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617524</ref_obj_id>
				<ref_obj_pid>616008</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cristoph M. Hoffmann, John E. Hopcroft, and Michael E. Karasick. Robust set operations on polyhedral solids. IEEE CG &amp; A 9,6 (November 1989), 50-59.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73405</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cristoph M. Hoffmann, John E. Hopcroft, and Michael S. Karasick. Towards implementing robust geometric computations. In Proceedings of the Fourth ACM Symposium on Computational Geometry, pages 106-117, Urbana, Illinois, 1988. "1"1,4]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>866412</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[John E. Hopcroft and Peter J. Kahn. A paradigm for robust geometric algorithms. Technical Report TR 89-1044, Department of Computer Science, Comell University, October 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15904</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[David H. Laidlaw, W. Benjamin Trumbore, and John E Hughes. Constructive solid geometry for polyhedral objects. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20,4 (August 1986), 161-170.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>7530</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Martti M~intyl~i. Boolean operations of 2-manifolds through vertex neighborhood classification. ACM Transactions on Graphics 5,1 (January 1986), 1-29.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63194</ref_obj_id>
				<ref_obj_pid>63180</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Victor Milenkovic. Verifiable implementations of geometric algorithms using finite precision arithmetic. Artificial Intelligence 37 (1988), 377--401.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73856</ref_obj_id>
				<ref_obj_pid>73833</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Victor Milenkovic. Calculating approximate curve arrangements using rounded arithmetic. In Proceedings of the Fifth ACM Symposium on Computational Geometry, pages 197- 207, ! 989.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S.P. Mudur and P.A. Koparkar. Interval methods for processing geometric objects. IEEE CG &amp; A 4,2 (February 1984), 7-17.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[I.E. Sutherland, R.F. Sproull, and R.A. Schumacker. A Characterization of Ten Hidden-Surface Removal Algorithms. Computing Surveys 6,1 (March 1974), 1-55.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>41970</ref_obj_id>
				<ref_obj_pid>41958</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Thomas Ottmann, Gerald Thiemt, and Christian Ullrich. Numerical stability of geometric algorithms. In Proceedings of the Third ACM Symposium on Computational Geometry, pages 119-125, Waterloo, Ontario, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Aristides A. G. Requicha. Toward a theory of geometric tolerancing. International Journal of Robotics Research 2,4 (Winter 1983), 45-60.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>323238</ref_obj_id>
				<ref_obj_pid>323233</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Mark Segal and Carlo H. Srquin. Consistent calculations for solid modeling. In Proceedings of the First ACM Symposium on Computational Geometry, pages 29-38, 1985.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44106</ref_obj_id>
				<ref_obj_pid>44102</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Mark Segal and Carlo H. Srquin. Partitioning polyhedral objects into non-intersecting parts. IEEE CG &amp; A 8,1 (January 1988), 53-67.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. Stoer and R. Bulirsch. Introduction to Numerical Analysis. Springer-Verlag, New York, 1980.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73407</ref_obj_id>
				<ref_obj_pid>73393</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Chee-Keng Yap. A geometric consistency theorem for a symbolic perturbation scheme. In Proceedings of the Fourth ACM Symposium on Computational Geometry, pages 134- 142, Urbana, Illinois, 1988.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Using Tolerances to Guarantee Valid Polyhedral 
Modeling Results Mark Segal Silicon Graphics Computer Systems* Abstract A polyhedral solid modeler 
that operates on boundary representa- tions of objects must infer topological information from numerical 
data. Unavoidable errors (due to limited precision) affect these calculations so that their use may produce 
ambiguous or contra- dictory results. These effects cause existing polyhedral modelers to fail when presented 
with objects that nearly align or barely intersect[ 101171. An object description associating a tolerance 
with each of its topological features (vertices, edges, and faces) is introduced. The use of tolerances 
leads to a definition of topological consistency that is readily applied to boundary representations. 
The implications of using tolerances to aid in making consistent topological determina- tions from imprecise 
geometric data are explored and applied to the calculations of a polyhedral solid modeler. The resulting 
modeler produces a consistent polyhedral boundary when given consistent boundaries as input. CR Categories 
and Subject Descriptors: 1.3.5 ]Computer Graphics]: Computational Geometry and Object Modeling - curve, 
sulface, solid and object representations; geometric al-gorithms, languages, and systems; G.4 [Mathematical 
Software]: Reliability and Robustness Additional Key Words and Phrases: solid modeling, boundary representation, 
numerical uncertainty  Introduction Constructive solid geometry (CSG) is a well-established technique 
for specifying solid objects. Finding an object's boundary given its CSG description entails computing 
the boundary of an intersection, union, or difference of solids given by their boundaries. Several methods 
have been used successfully to carry out these "boolean" operations on polyhedra[ l 0][ 1 1 ]119]. All 
these methods compute intersections between the input boundaries and use this information to produce 
a resulting boundary. "2011 N. Shoreline Blvd., Mountain View, CA 94043 Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permissionof the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. A Figure 1. An example in the 
plane that may lead to inconsistencies. A computed intersection may be inexact either because of the 
accumulated effects of round-off error in floating-point computa- tions or because of uncertainty in 
the coordinates on which the calculation is based. Because computed intersections must be used to derive 
topology in the result, such topology may be ambiguous or inconsistent. These effects sometimes cause 
previously published algorithms to fail. For instance, consider deciding whether a vertex of one polyhe- 
dral boundary lies in a face of the other[4]. If a vertex lies in a face, then the vertex's coordinates 
produce zero when substituted into the face's plane equation. However, if the face is not triangular, 
its plane equation may not be defined exactly, because the edges that define the face may not lie precisely 
in a single plane. The vertex's coordinates may similarly be uncertain. The test may be modified by deeming 
the vertex to lie in the face's plane if it lies within some small specified distance of an approximate 
plane, but this decision is still arbitrary (based on the small value chosen) and care must be taken 
that it is not contradicted by some later decision. The problem is exacerbated by making other related 
decisions based on numerical data, such as whether or not two faces are coplanar, and by deriving the 
locations of new vertices and edges from inexact, previously computed coordinates. Any inconsistency 
may lead to a result which does not represent the boundary of a solid; it may even cause the modeler 
to fail without producing any output. Figure 1 shows an example that may pose difficulties in two dimensions. 
An algorithm for finding polygon intersections might compute intersections among edges, break edges into 
segments at intersection points, and output those segments that lie inside of one polygon or the other 
(for two coincident segments, one of the two would be output). Suppose this algorithm were applied to 
the polygons in Figure 1, and suppose the intersection of an edge of the @1990 ACM-0-89791-344-2/90/008/0105 
$00.75 105 triangle and all edge of the trapezoid is found at X. Now suppose point Y is considered, and 
is found to lie close enough to A that it is deemed coincident with it (for clarity, the distance between 
A and Y is exagerated in the figure). But this is impossible since an intersection has already been found 
at X. Unless steps are taken to handle this situation, the algorithm's result may be missing an edge 
or contain an extra edge between X and A or X and Y. A more concrete example is given in [10] and later 
cited by other authors[7][ 19]. Two congruent cubes are placed with their centers coincident but with 
one rotated relative to the other about some axis by a small angle. A polyhedral modeler that accomodates 
coplanar faces can handle either an angle of zero degrees or large angles, but most modelers fail for 
a range of angles near zero. The size of this critical interval can be made very small by careful attention 
to numerical issues in the calculation of intersections, but there is still a range of angles, however 
tiny, for which a modeler may fail. Several methods have been proposed to address these issues. One method, 
exact rational arithmetic, attempts to represent all coordinates exactly as rational numbers[5], because 
intersections among features with rational coordinates have rational coordinates. More sophisticated 
techniques allow an arbitrary symbolic formula for each coordinate[2][ 1 ]. However, at some point the 
formula must be evaluated. If the coefficients and arguments (which are derived from the input objects' 
coordinates) are inexact, topological data derived from the formula may still be ambiguous. If the input 
coordinates are exact[ 16], then an arbitrary precision calculation can achieve any accuracy. Unfortunately, 
the output is still of limited accuracy, so the results from one calculation cannot be used as input 
to the next. A grid may be placed over the computed object and features snapped to it[18], but this process 
may incorporate large portions of the grid into the object, creating a myriad of tiny "staircase" features. 
Another method is to back up and increase the precision of an earlier calculation if it is later found 
that its accuracy is not great enough to resolve a topological determination[3]. Instead of recom- puting 
previous calculations, their results may instead be perturbed as necessary so that they do not introduce 
ambiguity[8][21]. Other methods that yield robust algorithms in limited domains include ones for computing 
intersections in the plane[12H13] and finding intersections between convex polyhedra[9]. We concede that 
input coordinates may be inexact and that numerical errors may accumulate during computation. We give 
methods that have their roots in interval arithmetic[20][6]114], to measure that accumulation. Each vertex, 
edge, and face is assigned its own tolerance. These tolerances are updated during algorithm operation, 
allowing a modeler to locate regions in which numerical uncertainty may lead to topological ambiguity. 
Using maintained tolerances instead of arbitrarily selected"epsilons" makes it possible to decide these 
cases consistently, guaranteeing that a solid modeling result is always the boundary of a solid. 2 Overview 
We begin by reviewing the essential means by which polyhedral boundaries in three dimensions are specified. 
Next we present a system of tolerances applied to these specifications and introduce a notion of consistency 
for inexact geometric objects. We describe modifications to the standard geometric notions of intersection, 
coincidence and containment that can be applied to objects incorpo- rating tolerances. These concepts 
provide the framework necessary to build a polyhedral modeler that accomodates numerical uncer- 106 tainty 
in its topological decisions. Then we describe the basic solid modeler and how it is modified to incorporate 
tolerance handling. We conclude with some examples and a discussion of the prospects of improving and 
extending the current implementation. 3 Geometry, Topology, and Consistency We distinguish three topological 
features in three dimensions: vertices, edges, and faces. A vertex is essentially a point. An edge is 
a connected subset of a line bounded by vertices. A face is a connected subset of a plane bounded by 
non-self-intersecting polygonal curves made up of edges lying in that plane. The affine subset of three-space 
corresponding to each feature (a point for a vertex, a line for an edge, and a plane for a face) is called 
aflat of dimension 0, 1 or 2. A particular fiat is specified by giving coordinates that specify its position 
with respect to a fixed origin and basis. A geometric object consists of an arbitrary set of particular 
topo- logical features described in two parts. The first part, called metric data, are the coordinates 
that locate each feature in space. The second part is a list ofconnectivities. Each connectivity comprises 
a set of geometric features that intersect (called the connectivity set), together with a distinguishing 
feature that represents the inter- section. For instance, several edges may meet at a vertex, or several 
faces may intersect in an edge. An object's representation is consistent if every intersection among 
an arbitrary set of features is represented explicitly in the connectivities, and conversely, every connectivity 
represents an intersection computable from the metric data. Consistency is desirable because connectivities 
encode most of an object's topology (a solid's genus, for example, can be found directly from its connectivities). 
Further, a solid modeler relies on connectivities to derive information about an object, such as determining 
which faces lie on either side of an edge or which edges emanate from a vertex. Inconsistency between 
connectivities and metric data may invalidate assumptions made in the modeler's algorithms, leading to 
the modeler's failure. 3.1 Numerical Uncertainty In practice consistency may be difficult to achieve 
because a polyhedron's metric data are represented with limited precision quantities. Computing an intersection 
from these inexact quantities (even if carried out to arbitrary precision) may lead to ambiguous results. 
To account for inaccuracy, and to quantify its effects during geometric computation, we introduce a tolerance[17] 
e for each topological feature f describing the positional uncertainty of its corresponding flat a. A 
tolerance specifies a tolerance region about a flat. To define this region, let q be any point and a 
be a flat, and let dist(q,a) = min{llq - q~ll l qa c a}. The region r = {qldist(q,a) < e} is the tolerance 
region about the flat a (Figure 2). A tolerance also specifies a tolerance region tot(f) about a feature 
f. Because a feature's boundary may not lie exactly in its corresponding flat, the definition of a feature's 
tolerance region requires some notation. Consider the projection operator .Pa(y) that computes the perpendicular 
projection of the point or points of y -_; .--'-. . ---.., ,.'"..... ., ', " i I ° ', I " i -*'" " A 
',," B ', ,' C ,i ...--- (a) (b) Figure 4. (a) non-symmetry of approximate alignment. B aligns with 
A, but not vice versa. (b) non-transitivity of approximate coincidence. A &#38; B coincide, as do B &#38; 
C, but A &#38; C do not. 1...................................................... ' I I r-......................... 
::= ...... -', I ', ..... :.: .................... I i ..................... - .................  
Figure 5. An illegal constellation of edges. Each pair of corre- sponding vertices approximately coincide, 
but it is unclear that the edges themselves do. more than one connected component. Figure 5 shows an 
example of the situation that this restriction is designed to exclude. Finally, if two distinct features 
are approximately aligned with and intersect some higher dimensional feature, and if their projections 
onto the higher dimensional feature's ideal fiat also approximately align and intersect (Figure 6), then 
we require the two features to be approximately aligned. 4 A Reliable Solid Modeler The techniques for 
achieving consistent object descriptions in the presence of numerical uncertainty form the basis for 
a reliable poly- hedral modeler. By reliable we mean that, given the descriptions of two consistent boundary 
representations, the modeler always runs to completion and that its result is always the consistent description 
of a boundary representation. In most cases, the connectivities of this result precisely correspond to 
the connectivities that would be obtained using exact inputs with infinite precision arithmetic. In some 
cases, when numerical uncertainties lead to arbitrary deci- sions, the exact result may have topologically 
complex regions of small size that are collapsed into simpler regions in the modeler's output. 4.1 Algorithm 
Overview The basic algorithmI 19] operates by detecting and removing inter- sections among pairs of candidate 
faces. It does this by tracing around the edges of one face and finding their intersections with the 
other face's plane; the procedure is repeated with the faces roles reversed. The intersection points 
are collected and sorted into order along the intersection line. Each face's contours are 108 ..--., 
.................................. ~" "~ ""7 ........... ,,..*" (a) (b)  Figure 6. (a) An illegal constellation 
of vertices about an edge. The ordering of the vertices along this edge is not well defined. (b) An illegal 
constellation of edges contained in a face. It is not clear whether or not the edges should intersect. 
 then sliced apart between these points to partition the faces into parts that intersect only along shared 
edges, if at all. Information gathered during cutting operations is used after all faces have been partitioned 
to select the contours appropriate to the desired CSG result. There is nothing that makes this algorithm 
especially amenable to using tolerances to assure reliable behavior in the presence of nu- merical uncertainty. 
Other algorithms could be similarly equipped, although the exact measures taken depend on the particular 
form of the algorithm and the stages that it goes through to achieve a modeling result. The essence of 
achieving reliability is to ensure that every stage of the algorithm leaves the geometric object on which 
it is working consistent and free from any violations of the restrictions presented in the last section. 
 4.2 Data Structures The algorithm encodes a geometric object in a data structure consisting of four 
items. These data structure items completely encode both the metric data and connectivities of a geometric 
object. The first three items correspond to features of dimension 0, 1, and 2, respectively. Vertices 
A vertex's position is described by three coordinates giving its location relative to a fixed origin 
and basis. In addition, each vertex has a list that indicates which edges emanate from it. Edges An edge's 
flat is described by a parametric line equation given by a point and a unit direction. Its boundary is 
described by pointers to its two bounding vertices. Each edge also has a list that describes which faces 
are incident on it (more precisely, each item in the list is a pointer to the use of the edge within 
a face's contour). Edges   ~ Computer Graphics, Volume 24, Number 4, August 1990 (a) (b) Figure 7. 
(a) Illegal spikes in contours. (b) Legal notches. are unique; there can be no more than one edge between 
any pair of vertices. Faces A face's flat is described by an implicit plane equation given by a point 
on and a unit normal to the plane. Its boundary is described by one or more pairwise disjoint contours, 
some of which may be holes. Each contour is a list of edges that form a non-self-intersecting loop. A 
contour must bound an open planar set so that the local orientation of the contour is defined at each 
vertex (Figure 7). This restriction ensures that a contour does not contain zero-width "spikes," although 
zero-width notches are allowed (the algorithm may insert such notches into faces as partitioning proceeds). 
 Solid Boundaries The boundary of a solid is simply a list of faces that make it up. Tolerances and 
Related Quantities Three quantities are kept with each feature f in addition to the coordinates that 
specify its fiat's position. The first of these is a tolerance describing the accuracy of these coordinates. 
The second, kept for edges and faces only, is an extent, denoted emt(f). This value gives the maximum 
deviation of the feature's tolerance region from its specified flat. The third quantity is called the 
near value, denoted near(f). This value is initialized to a large positive number when the modeler starts. 
Whenever the distance between a feature and some other feature is computed, and the pair of features 
are deemed not to intersect, the near value is updated so that it is the minimum distance to all features 
found to not intersect the feature so far. The use of the extent and near values will become apparent 
as the algorithm is described. If objects are presented to the algorithm without edge or plane equations 
or feature tolerances, the equations and tolerances are computed. Each vertex in the input is assigned 
an arbitrary small tolerance, typically 10-1° for an object centered about the origin whose longest edges 
have approximate length 1. This makes the ratio of the tolerance to the vertex coordinates a few times 
the machine precision when using IEEE double-precision floating- point, guaranteeing that round-off error 
will generally not affect tolerances. An edge's equation is found by finding the line that passes through 
its two endpoints. The tolerance assigned to such a computed edge equation is zero, because the line 
must intersect the vertices' tolerance regions. The extent for the edge is the larger of the two endpoints' 
tolerances. A face's equation is computed by applying Newell's algorithm[ 15] to each of the faces contours 
and averaging the results. The tolerance is found by substituting the coordinates of each vertex in the 
face's boundary into the computed equation and recording the maximum deviation from zero. The extent 
is this deviation added to the maximum of the vertices tolerances. 4.3 Topological Modifications As 
the algorithm proceeds, it modifies the topology of the input to incorporate computed intersections. 
These modifications are: 1. Breaking an edge into two edges at a new vertex where the edge crosses a 
face. 2. Inserting new edges into a face along an intersection line. 3. Merging coplanar faces, coincident 
edges, and coincident vertices.  Of these operations, (1) and (2) are purely topological in that they 
do not require alteration of metric data or tolerances. The operations in (3), however, require the selection 
of new coordinates and a new tolerance for the merged feature. Further, merging a pair of features may 
require topological changes beyond the merge itself. Vertex Merging If there is an edge between two 
merged vertices, it must be eliminated. This means excising the corresponding pointer from every contour 
that uses the edge. Further, there may be an edge from each of the merged vertices to a third vertex; 
such edges must be merged into a single edge.  Edge Merging and Edge Breaking If two distinct edges 
are bounded by the same two vertices (as may happen after a vertex merge), then the edges must be merged. 
Every reference to the either of the original edges must be replaced with a reference to a single new 
edge. If the two merged edges belong to a contour with three edges that is not a hole (Figure 8a), then 
merging the edges would create an illegal two-edged contour. In this case the vertices at the ends of 
this illegal contour are merged, eliminating the contour. Further, merging edges may create a spike in 
a contour that has more than three edges (Figure 8b). This possibility is detected by checking if the 
angle made by the unmerged edges in the contour is less than 180 ° . If so, the spike is removed from 
the contour. Two edges that have no boundary vertices in common overlap if one approximately aligns with 
the other and they approximately intersect. They also overlap if they violate the restrietion illustrated 
in Figure 6b. Two overlapping edges el and e2 must be broken into a series of two or three non-overlapping 
ones. This breaking creates two edges with identical bounding vertices that must be merged. Figure 8c 
shows how a merged edge resulting from an edge break can create a spike. This spike is eliminated when 
the edges are merged. (a) (b) (c) Figure 8. (a) A triangular non-hole must be merged when two of its 
vertices are. (b) A spike can be created when two vertices are merged. (c) Breaking an edge may create 
a spike. Coplanar Faces Two faces that approximately align and intersect must be merged into a set of 
non-overlapping contours just as edges are. In general, this would require using an algorithm to partition 
intersecting polygons in the plane, bat no such action is taken. Instead, we rely on there being two 
contours on either side of an edge. For an edge that lies in the plane of the coplanar faces, one of 
these contours belongs to one of the coplanar faces. The other contour belongs to a face that does not 
lie in the coplanar faces' plane. This third face will induce partitions in each of the coplanar faces. 
Eventaully (after all such edge-sharing faces have been considered), the coplanar contours will be partitioned 
into non-overlapping parts. Perturbation of Merged Features Merging two features f~ and f2 into a single 
new feature f requires finding coordinates and a tolerance for that feature. To maintain consistency, 
we must have tol(fl) U tot(f2) C_ tot(f). As much as possible, the coordinates of f's flat are selected 
so as to minimize f's tolerance subject to this inclusion condition, For a pair of vertices, this amounts 
to finding the sphere of minimum radius that encloses two intersecting spheres. For a pair of edges, 
an attempt is made to find the bounded cylinder that encloses two intersecting bounded cylinders. For 
a pair of faces, a less than optimal approach is taken for the sake of simplicity. Newell's algorithm 
is applied to each of the contours in the coplanar pair and the results are averaged to find a new plane 
equation. The coordinates of each of the vertices of the edges in .B(f) are substituted into the new 
plane equation and the maximum deviation recorded. Then for each e E B(f) with vertices vl and V2, the 
coordinates of P~(v]) and Pe(v2) are substituted into the plane equation and the maximum deviation found. 
The largest of these two maximum deviations becomes f's tolerance. The procedure ensures that f approximately 
contains its boundary. Both caNt(f) and near(f) must also be assigned a value, cult(f) must be recomputed 
from f's boundary features (this is done during the computation of its new coordinates and tolerance), 
while near(f) = min{near(fl),near(f2)}. If fl and f2 are vertices or edges, they may be contained in 
a feature of higher dimension. The extent of this feature may be affected when fl and f2 are merged, 
so every feature that includes fl or fz must be located and a test made to see if its extent needs updating. 
, - - ....-...-" ....... <.-._-... I ,' i a. '...-" ".. / ~ ", ................ ; \ l l ' :" ,: ~ B ",, 
'. ! '. J ",, ; '-,'. /."i Figure 9. Revision of a coincidence determination. Vertex C becomes coincident 
with vertices A and B only after A and B are found coincident.  Backtracking A merged feature f may 
be assigned a tolerance that is larger than either of the tolerances of the original features fl and 
f2. This may create an inconsistency, because a third feature f3 may have previously been determined 
not to intersect f] or f2 individually, but f, with its larger tolerance region, may now approximately 
intersect f3. Figure 9 shows the situation with vertices. If vertex C is considered against vertices 
A and B individually, vertex C will be found not coincident with either one. However, if vertex A is 
then considered against vertex B, these will be deemed coincident. A new tolerance region will be constructed 
that encloses those of A and B, contradicting the previous conclusion that C did not coincide with either 
A or B. This situation is accomodated by maintaining the near value for each feature. If a feature f's 
tolerance is increased (i.e. by merging two features) and the new tolerance exceeds near(f), an inconsistency 
may have been created. If this occurs, near(f) is reset to a large positive value, and the algorithm 
is rerun from the beginning. While this backtracking is certainly expensive, it is essential to ensure 
that no inconsistencies are introduced. The cost of backtracking could be reduced by employing a spatial 
subdivision to limit those features that are reconsidered, but this has not been implemented. Backtracking 
may lead to further backtracking, but any recursion must eventually terminate. The reason is that when 
backtracking occurs, all intersections between features considered so far will have been accounted for. 
Thus, any modifications made during a backtracking phase can only reduce the number of features (by merging 
them). At worst the process ends when all features that had been considered when backtracking started 
are merged into a single feature with a large tolerance. 4.4 Algorithm Operation The first step in partitioning 
a pair of faces fl and f2 is to compute the line of intersection between their planes a~ and az. The 
direction of this line is given by u = n~ × n2 where ni is the normal to ai. A third plane is introduced 
with normal u and passing through a point in one of the faces boundaries. The intersection point of the 
three planes gives a point v on the intersection line. The intersection line tolerance is made large 
enough so that the tolerance region about the intersection line encloses tol(az ) n tol(a2). If the face's 
  '~' Computer Graphics, Volume 24, Number 4, August 1990 tolerances are ¢1 and E2, respectively, the 
tolerance turns out to be (4 + 4 L7 ,2 cos e = sin 2 a ] where sins = [Inl × n2ll. 4.5 Coplanarity If 
max{t1 ,,2 } > n, where n is a user-specifiable coplanarity factor, the faces are tested for coplanarity, 
n is typically between 100 and 1000. Small values force the algorithm to deem pairs of faces that intersect 
in a relatively large dihedral angle to be coplanar. If the ratio exceeds n, the faces are deemed coplanar 
if two vertices in one face's boundary lie on opposite sides of the other's plane, or if any vertex 
of one face lies within a distance equal to the extent of the other. This second condition ensures that 
two faces whose tolerance regions intersect in more than one connected component are found to be coplanar 
(see Figure 5). 4.6 Finding Edge-Face Intersections If the ratio of the edge tolerance to the maximum 
of the two face tolerances is not too large, then the intersections of one of the face's edges with the 
other face's plane are found. For each edge, there are four possibilities: (1) the edge does not intersect 
the plane, (2) the edge intersects the plane in one boundary vertex, (3) the edge lies entirely in the 
plane, or (4) the edge crosses the plane. These possibilities are distinguished by computing the signed 
 distance of each of the edge's endpoints to the plane. The signed distance is deemed to be zero if the 
vertex lies within tolerance of the computed intersection line. If the lirte's equation is v + tu and 
the vertex's coordinates are p, then the vertex lies on the intersection line if lip -vii 2 -[u-(p -v)] 
2 _< (e + ep) 2 where e is the intersection line tolerance and ep is the vertex's tolerance. If the 
vertex v does not lie on the intersection line its signed distance d~ to the plane is obtained by substituting 
its coordinates into the plane equation d = n. (p -o) where n is the plane unit normal and o is the point 
in the plane. Id,~l is compared with both the vertex's and other face's near value; each value, if less 
than Id,, I, is replaced with [d, [. Even if the vertex does not lie on the intersection line, it may 
still intersect one of the other face f's boundary features. If Idol < eat(f), then each of the other 
face's boundary features is checked to see if it intersects the v. If so, the v's distance from the plane 
is zero. If sign(d,,, ) = sign(d,,~) for the edge e's vertices v~ and v2, then e does not cross the other 
face's plane. If one sign is positive and the other is negative, e crosses the plane and the intersection 
point x between e and the plane is computed. The tolerance for x is e. This guarantees that x approximately 
intersects both faces' planes as well as the computed intersection line. near(z) is min{near( e ), dist( 
x, vl ), dist( x, v2)}. The computed intersection point, along with auxilliary information indicating 
the edge and contour from which it came, are added to the list of intersection points. If one of an edges' 
vertices lies in the other face's plane, the vertex is entered into the list of intersection points. 
Information about edge adjacency and local orientation of the contour at the vertex is also recorded. 
Figure 10. One face completely contained in another's tolerance region. Some vertices must be merged 
and some edges broken because they violate the constraint illustrated in Figure 6. If it turns out that 
all the edges of one face lie in the other's plane, the faces are deemed coplanar. This may happen in 
spite of the intersection line having a relatively small tolerance if one face's edges are all about 
the same length as the other face's tolerance. Even if this is the case, the vertices are still recorded 
in the intersection point list. Some of the vertices may have to be merged (Figure 10); such merging 
is done after sorting the points. Finally, it may happen that one or both of an edges' endpoints lie 
off of the other face's plane, but the edge itself is approximately contained in the plane. This can 
occur if an edge e's tolerance is large compared to those of its endpoints. This situation is detected 
by determining if P,(Vl) and P,(v2) (vl and v2 are e's vertices) are both approximately contained in 
the other face's plane. If so, then the plane's tolerance is made large enough so that both of the original 
vertices approximately intersect the plane. If the new tolerance exceeds the face's near value, backtracking 
occurs. Otherwise, the current face pair is rerun with the increased face tolerance.  4.7 Feature Merging 
After finding the intersection points of each face's edges with the other's plane, the points are sorted 
into order along the intersection line. This is accomplished by computing the value t = (x -v) u for 
each intersection point x (this effectively projects the point onto the calculated intersection line), 
and sorting in order of increasing t. Points that appear more than once are sorted secondarily using 
orientation information. With the points ordered, a search is made for points that lie close enough 
together that they must be merged. Each point in the sorted list is checked against the next point. If 
they approximately intersect, the vertices defining the points are merged into a single vertex. This 
process may be repeated, eventually coalescing several vertices. In addition to vertex merging, edges 
that lie on the intersection line must be broken at intersection points that fall between their endpoints. 
Performing this operation ensures that pairs of edges that overlap are broken into a sequence of non-overlapping 
segments. Vertex and edge merging may invalidate some of the data about orientation and incident edges 
stored with the intersection points. Sometimes it is difficult to determine how to update these data. 
In these cases the current face pair is simply rerun. 4.8 Cutting The list of sorted and merged intersection 
points is used to determine where to slice contours to partition the pair of faces. Figure 11 shows some 
examples of cuts that are inserted into pairs of simple faces. O SIGGRAPH '90, Dallas, August 6-10, 1990 
Figure 11. Different ways in which a pair of faces may be cut. Either or both endpoints of a cut may 
correspond to newly calculated intersection points. Therefore an edge giving rise to such a point must 
be broken at that point before the cut is made. The edge is not broken when the intersection is computed 
because it is not known at that time whether or not the point lies in the interior of the face that the 
edge intersects. The point at which the edge is to be broken may approximately intersect one of the edges 
endpoints. If this is the case, the cut is made, after which the vertices are merged.  Results Figure 
12 shows the results of a union of two cubes centered at the origin where one cube is rotated through 
a small angle about a line through the origin with direction (1,2,3) T and the other is aligned with 
the coordinate axes. All computations were carried out in double-precision IEEE floating-point on a Silicon 
Graphics IRIS 4D/210VGX workstation. To make the results of this test easier to see, the face eoplanarity 
factor was set to the rather low value of 20. The figure on the left was obtained with an angle of 9.59863838340879299 
° while that on the right was produced with an angle of 9.59863838340879300 ° . The entries in the corresponding 
rotation matrices differed by no more than one significant bit in their mantissas. The algorithm was 
also tested for many values of the rotation angle slightly above and below these two values. For all 
higher values, the object produced was similar to the one at right; for all lower values, the object 
was similar to the one at left. Further transitions occur as the angle is decreased even more until the 
object finally becomes a cube (but with non-planar faces) at an angle of about 1.5 ° . Figure 13 shows 
the object in Figure 12 in terms of its feature's tolerance regions. If the coplanarity factor is increased 
to a more reasonable factor of 500, the angle at which the transition occurs is approximately 0.2 °. 
In this example, even high coplanarity factors (105) with tiny angles (about 0,001 o) produce a boundary 
of something other than a cube (but with some very short edges). This is because starting face and edge 
tolerances are zero, so computed vertex tolerances are set to the minimum value (10-10). If face tolerances 
are initialized to about 10 -6, however, such high coplanarity factors and small angles cause computed 
vertex tolerances to become so large as to engulf the original vertices, eventually collapsing the cubes 
into a single vertex. Higher coplanarity factors can be used to achieve reasonable results if the input 
tolerances are reduced, but a vertex's tolerance may not be reduced so far that its ratio to the coordinates 
whose inaccuracy it quantifies approaches the machine precision. Figure 14 shows the union of a pair 
of more complex objects, and Figure 15 shows the same union computed with a small coplanarity factor 
and with the final tolerances displayed. Figure 16 shows that the modeler can be used to generate complex 
objects without the tolerances causing any feature merging. This object was generated by starting with 
two congruent cubes in different orientations and computing their intersection. Then the resulting objects 
were rotated with respect to one another and the union taken and so on until, after eight iterations, 
the final result was obtained. In this object tolerances remain imperceptibly small because features 
are not merged (with the default tolerances and a coplanarity factor of 1000). If the process is carried 
out for another iteration, however, some features are near enough to one another that they are merged, 
and tolerances increase. Continued iteration causes tolerances to grow; features are rapidly collapsed 
so that after 11 iterations, the object is reduced to a single vertex. 6 Conclusions We have presented 
a tolerance scheme that accounts for the con- sistent definition of boundary representations whose specification 
may be numerically uncertain. This scheme has been applied to a polyhedral modeler computing CSG operations 
on boundary rep-resentations. The modeler always succeeds in producing a result that is a consistent 
polyhedral boundary. Doing so may entail the localized collapse of several features into a single feature 
with a large tolerance. Achieving this behavior has its costs; the algorithm runs 5-10 times slower, 
even when backtracking is not required, than an earlier version that performed only cursory tolerance 
checking. If n is the number of faces, the algorithm runs in time O(n 2) without backtracking, although 
the average time can be made O(n) by employing a spatial subdivision. Careful attention to making certain 
checks only when absolutely necessary, and replacing often called functions (such as the distance of 
a vertex to a plane) with in-line code would certainly reduce the required time. Even so, the resulting 
algorithm would likely be at least a factor of two slower than a similar algorithm that is not guaranteed 
to work in all cases. With backtracking, the worst case behavior is O(e I) where f is the number of features. 
In practice, it is difficult to construct a case that achieves this behavior, although if backtracking 
occurs once it typically occurs several times. For most object constellations no backtracking occurs; 
it is only necessary when features approxi- mately coincide and then only if there are other features 
near the coincident ones. If the input to the algorithm has numerical uncertainties, there may be no 
other solution than to occasionally collapse features. In normal situations, such as computing the union 
of two imperfectly abutting objects, this collapsing leads to modest tolerance increases that have only 
local effect. Only in unusual situations, such as those designed to stress the algorithm shown in Figures 
12-16, are the tolerance increases compounded enough to be objectionable. In any case, it makes sense 
to report large tolerances so that a user or higher-level program equipped with heuristics can be alerted 
to regions where unexpected behavior may occur. Perhaps tolerances can be decreased or features slightly 
perturbed to remove such behavior. In some cases the algorithm is too conservative in assigning tolerances 
to computed features because it has no access to global relationships among these features. It may be 
possible to design a post-processor that decreases tolerances while maintaining consistency. One possibility 
is to use a relaxation algorithm that perturbs feature coordinates in an attempt to reduce an objective 
function made up of a weighted sum of all the features' tolerances. The tolerance scheme can, in principle, 
be applied to other algorithms in geometric modeling. As already noted, polyhe- dral modelers other than 
the one described here can be modified to incorporate tolerances. Further, there is nothing inherently 
three-dimensional about a system of tolerances, so that the same techniques can be applied to geometric 
algorithms that operate in higher dimensions. Finally, it should be possible to extend the tolerance 
scheme to accomodate curved objects. The topological features of such objects are the same: vertices, 
edges, and faces. In this case the tolerances would not only reflect how accurately a feature is specified 
but also the accuracy of the computation used to evaluate points that lie on it. The challenge for this 
application is to extend the notions of approximate containment and coincidence to features that may 
intersect in several connected components or in isolated regions of tangency. Acknowledgements Many thanks 
to Carlo Srquin for his continued encouragement and support. Thanks also to Dan Baum, Derrick Burns, 
and Bob Drebin for helpful comments and criticisms. References [1] Dennis S. Arnon. Topologically reliable 
display of algebraic curves. Proceedings of SIGGRAPH'83 (Detroit, Michigan, July 25-29, 1983). In Computer 
Graphics 17,3 (July 1983), 219-227. [2] John Francis Canny. The Complexity of Robot Motion Plan- ning. 
PhD thesis, MIT, 1987. [3] David Dobkin and Deborah Silver. Recipes for geometry &#38; numerical analysis--part 
I: An empirical study. In Pro-ceedings of the Fourth ACM Symposium on Computational Geometry, pages 93-105, 
Urbana, Illinois, 1988. [4] A. Robin Forrest. Computational geometry and software engineering: Towards 
a geometric computing environment. In David E Rogers and Rae A. Earnshaw, editors, Techniques for Computer 
Graphics, pages 23-37. Springer-Verlag, New York, 1987. [5] W. Randolph Franklin, Peter Y.E Wu, and 
Sumitro Samaddar. Prolog and geometry projects. IEEE CG &#38; A 6,11 (November 1986), 46--55. [6] Leonidas 
Guibas, David Salesin, and Jorge Stolfi. Epsilon geometry: Building robust algorithms from imprecise 
com- putations. In Proceedings of the Fifth ACM Symposium on Computational Geometry, pages 208-217, 1989. 
[7] Cristoph M. Hoffmann, John E. Hopcroft, and Michael E. Karasick. Robust set operations on polyhedral 
solids. IEEE CG &#38; A 9,6 (November 1989), 50-.-59. [81 Cristoph M. Hoffmann, John E. Hopcrofl, and 
Michael S. Karasick. Towards implementing robust geometric compu- tations. In Proceedings of the Fourth 
ACM Symposium on Computational Geometry, pages 106---117, Urbana, Illinois, 1988. [91 John E. Hopcroft 
and Peter J. Kahn. A paradigm for robust geometric algorithms. Technical Report TR 89-1044, De-partment 
of Computer Science, Cornell University, October 1989. [10] David H. Laidlaw, W. Benjamin Trumbore, and 
John E Hughes. Constructive solid geometry for polyhedral objects. Proceedings of SIGGRAPH'86 (Dallas, 
Texas, August 18-22, 1986). In Computer Graphics 20,4 (August 1986), 161-170. [11] Martti M~intyl/i. 
Boolean operations of 2-manifolds through vertex neighborhood classification. ACM Transactions on Graphics5,1 
(January 1986), 1-29. [12] Victor Milenkovic. Verifiable implementations of geometric algorithms using 
finite precision arithmetic. Artificial Intelli- gence 37 (1988), 377-401. [131 Victor Milenkovic. Calculating 
approximate curve arrange- ments using rounded arithmetic. In Proceedings of the Fifth ACM Symposium 
on Computational Geometry, pages 197- 207, 1989. [14] S.P. Mudur and P.A. Koparkar. Interval methods 
for processing geometric objects. IEEE CG &#38; A 4,2 (February 1984), 7-17. [15] I.E. Sutherland, R.F. 
Sproull, and R.A. Schumacker. A Charac- terization of Ten Hidden-Surface Removal Algorithms. Com-puting 
Surveys 6,1 (March 1974), 1-55. [16] Thomas Ottmann, Gerald Thiemt, and Christian Ullrich. Nu- merical 
stability of geometric algorithms. In Proceedings of the Third ACM Symposium on Computational Geometry, 
pages 119-125, Waterloo, Ontario, 1987. [17] Aristides A. G. Requicha. Toward a theory of geometric tolerancing. 
International Journal of Robotics Research 2,4 (Winter 1983), 45-60. [18] Mark Segal and Carlo H. Srquin. 
Consistent calculations for solid modeling. In Proceedings of the First ACM Symposium on Computational 
Geometry, pages 29-38, 1985. [19] Mark Segal and Carlo H. SEquin. Partitioning polyhedral objects into 
non-intersecting parts. IEEE CG &#38; A 8,1 (January 1988), 53--67. [20] J. Stoer and R. Bulirsch. Introduction 
to Numerical Analysis. Springer-Verlag, New York, 1980. [21] Chee-Keng Yap. A geometric consistency theorem 
for a symbolic perturbation scheme. In Proceedings of the Fourth ACM Symposium on Computational Geometry, 
pages 134--- 142, Urbana, Illinois, 1988.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97892</article_id>
		<sort_key>115</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Merging BSP trees yields polyhedral set operations]]></title>
		<page_from>115</page_from>
		<page_to>124</page_to>
		<doi_number>10.1145/97879.97892</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97892</url>
		<abstract>
			<par><![CDATA[BSP trees have been shown to provide an effective representation of polyhedra through the use of spatial subdivision, and are an alternative to the topologically based b-reps. While bsp tree algorithms are known for a number of important operations, such as rendering, no previous work on bsp trees has provided the capability of performing boolean set operations between two objects represented by bsp trees, i.e. there has been no closed boolean algebra when using bsp trees. This paper presents the algorithms required to perform such operations. In doing so, a distinction is made between the semantics of polyhedra and the more fundamental mechanism of spatial partitioning. Given a partitioning of a space, a particular semantics is induced on the space by associating attributes required by the desired semantics with the cells of the partitioning. So, for example, polyhedra are obtained simply by associating a boolean attribute with each cell. Set operations on polyhedra are then constructed on top of the operation of merging spatial partitionings. We present then the algorithm for merging two bsp trees independent of any attributes/semantics, and then follow this by the additional algorithmic considerations needed to provide set operations on polyhedra. The result is a simple and numerically robust algorithm for set operations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39051340</person_id>
				<author_profile_id><![CDATA[81100625208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Naylor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT& T Bell Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P142703</person_id>
				<author_profile_id><![CDATA[81100396467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Amanatides]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P300128</person_id>
				<author_profile_id><![CDATA[81100074144]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thibault]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California State University at Hayward]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Sandra H. Bloomberg,"A Representation of Solid Objects for Performing Boolean Operations", U.N.C. Computer Science Technical Report 86-006 (1986).]]></ref_text>
				<ref_id>Bloomberg 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74343</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[N. Chin and S. Feiner,"Near Real-Time Shadow Generation Using BSP Trees", Computer Graphics Vol. 23(3), pp. 99-106, (Aug. 1989).]]></ref_text>
				<ref_id>Chin and Feiner 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs, Z. Kedem, and B. Naylor, "On Visible Surface Generation by a Priori Tree Structures," Computer Graphtcs Vol. 14(3), pp, 124-133, (June 1980).]]></ref_text>
				<ref_id>Fuchs, Kedem, and Naylor 80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97896</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Donald Fussell and A.T. Campbell, "Adaptive Mesh Generation for Global Diffuse Illumination," Computer Graphics Vol. 24(3), (Aug. 1990).]]></ref_text>
				<ref_id>Fussell and Campbell 90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74803</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Christoph M. Hoffmann, Geometric and Solid Modeling, Morgan Kaufmann, 1989.]]></ref_text>
				<ref_id>Hoffmann 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>75971</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Michael Karasick, "On the Representation and Manipulation of Rigid Solids," Ph.D. Thesis, ComeU University (March 1989).]]></ref_text>
				<ref_id>Karasick 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Martti Mantyla, Solid Modeling, Computer Science Press, 1988.]]></ref_text>
				<ref_id>Mantyla 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>909951</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bruce F. Naylor, "A Priori Based Techniques for Determining Visibility Priority for 3-D Scenes," Ph.D. Thesis, University of Texas at Dallas (May 1981),]]></ref_text>
				<ref_id>Naylor 81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>93302</ref_obj_id>
				<ref_obj_pid>93267</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bruce F. Naylor, "SCULPT : An Interactive Solid Modeling Tool", Proc. of Graphics Interface, (May 1990).]]></ref_text>
				<ref_id>Naylor 90a</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91787</ref_obj_id>
				<ref_obj_pid>91778</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bruce F. Naylor, "Binary Space Partitioning Trees as an Alternative Representation of Polytopes", Computer Aided Design, Vol 22(4), (May 1990).]]></ref_text>
				<ref_id>Naylor 90b</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bruce F. Naylor and William C. Thibauh, "Application of BSP Trees to Ray-Tracing and CSG Evaluation," Technical Report GIT-ICS 86/03, School of Information and Computer Science, Georgia Institute of Technology, Atlanta, Georgia 30332 (February 1986).]]></ref_text>
				<ref_id>Naylor and Thibault 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73836</ref_obj_id>
				<ref_obj_pid>73833</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M.S. Paterson and F.F. Yao, "Binary partitions with applications to hidden-surface removal and solid modeling", Proceedings of Fifth Syrup. on Computational Geometry, pp. 23-32, (1989).]]></ref_text>
				<ref_id>Paterson and Yao 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>320187</ref_obj_id>
				<ref_obj_pid>320176</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M.S. Paterson and F.F. Yao, "Optimal Binary Space Partitions for Orthogonal Objects", Proceedings of Ist Syrup. on Discrete Algorithms, pp. 100-106, (Jan. 1990).]]></ref_text>
				<ref_id>Paterson and Yao 90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. A. Schumacker, R. Brand, M. G illiland, and W. Sharp, "Study for Applying Computer-Generated Images to Visual Simulation," AFHRL-TR-69-14, U.S. Air Force Human Resources Laboratory (1969).]]></ref_text>
				<ref_id>Schumaker et al 69</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356626</ref_obj_id>
				<ref_obj_pid>356625</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[I.E. Sutherland, R.F. Sproull and R. A. Schumacker, "A Characterization of Ten hidden Surface Algorithms," ACM Computing Surveys Vol 6(1), (1974).]]></ref_text>
				<ref_id>Sutherland, Sproull and Schumaker 74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37421</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[W. Thibault and B. Naylor, "Set Operations On Polyhedra Using Binary Space Partitioning Trees," Computer Graphics Vol. 21(4), (July 1987).]]></ref_text>
				<ref_id>Thibault and Naylor 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>913766</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[William C. Thibault, "Application of Binary Space Partitioning Trees to Geometric Modeling and Ray- Tracing", Ph.D. Dissertation, Georgia Institute of Technology, Atlanta, Georgia, (1987).]]></ref_text>
				<ref_id>Thibault 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Enric Torres, "Optimization of the Binary Space Partition Algorithm (BSP) for the Visualization of Dynamic Scenes" Eurographics '90 (Sept. 1990).]]></ref_text>
				<ref_id>Torres 90</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Merging BSP Trees Yields Polyhedral Set Operations Bruce Naylor*, John Amanatidest and William Thibault 
$ *AT&#38; T Bell Laboratories tYork University ~:California State University at Hayward Abstract BSP 
trees have been shown to provide an effective repre- sentation of polyhedra through the use of spatial 
subdivision, and are an alternative to the topologically based b-reps. While bsp tree algorithms are 
known for a number of important opera- tions, such as rendering, no previous work on bsp trees has provided 
the capability of performing boolean set operations between two objects represented by bsp trees, i.e. 
there has been no closed boolean algebra when using bsp trees. This pa- per presents the algorithms required 
to perform such opera- tions. In doing so, a distinction is made between the semantics of polyhedra and 
the more fundamental mechanism of spatial partitioning. Given a partitioning of a space, a particular 
se-mantics is induced on the space by associating attributes re- quired by the desired semantics with 
the cells of the partition- ing. So, for example, polyhedra are obtained simply by associ- ating a boolean 
attribute with each cell. Set operations on polyhedra are then constructed on top of the operation of 
merg-ing spatial partitionings. We present then the algorithm for merging two bsp trees independent of 
any attributes/semantics, and then follow this by the additional algorithmic considera- tions needed 
to provide set operations on polyhedra. The result is a simple and numerically robust algorithm for set 
opera- tions. Introduction Methods for representing geometric objects is an issue of con- siderable 
importance to disciplines dealing with geometric computation. Several different representations, such 
as bound- ary-representations (b-reps), octrees, and esg trees, are cur-rently in use, and a number of 
new approaches are being ex-plored by various researchers. As in all computation, the data representation/structure 
determines the algorithms that are needed to provide the operations associated with any semantic domain. 
And it is the efficiency and simplicity of the algo- rithms operating on the data structures that determines 
the at- tractiveness of a particular representation. Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. Constructive solid geometry introduced the explicit use of 
the paradigm of constructing complex objects from combina- tions of other usually simpler objects, This 
methodology is built upon the mathematies of set theoretic expressions. These expressions are analogous 
to parenthesized boolean expres-sions, but the variables are instead subsets of a Euclidean D-di- mensional 
space and the operations include, in addition to the analogous regularized boolean set operations, affine 
transfor- mations. Instancing, i.e. the utilization of named sub-expres-sions, is also a part of this 
method. These expressions define a value and they can, at least in principal, be evaluated to produce 
this value. For example, ray- casting evaluates the expressions in a 1D sub-domain of the typically 3D 
domain, and so solves a simpler problem: classify a line with respect to the expression. When the operands 
are re- stricted to polyhedra and are represented by b-reps, then any number of algorithms are known 
for evaluating such an expres- sion (see for example [Mantyla 88] or [Hoffman 89]). The methodology underlying 
b-reps is that of the direct rep- resentation of the topology of a polyhedral surface/boundary. The topological 
approach requires the decomposition of a D- space polytope into connected components of all dimensions 
d, 0 _< d _< D, and explicitly encodes the cormeetivity/incidence among these components. Thus, the methodology 
distin-guishes for every d, 0 < d <_ D, affine subspaces containing sets of d-manifolds (shells), preferably 
with their relative con- tainment (which shells are inside which other shells), along with their connected 
set of d-1 dimensional boundary elements and the connectivity of these to other elements outside of their 
affine subspace, and so on recursively in dimension. B-reps, while widely used, possess a number of inherent 
dif- ficulties in terms of their representational power. The reliance on the concept of manifolds is 
at odds with the need for permit- ting non-manifold boundaries, i.e. the presence of regions on the boundary 
whose neighborhood is not homeomorphie to an g-ball of some affine subspace. (However, this problem is 
fix- able.) A second is the inability to represent sets whose bound- ary is unbounded, such as a linear 
halfspace. On the algorithmic side, performing set operations with b- reps requires explicit detection 
of the co-incidence of all C( D, 2 ) combinations of the variously dimensioned elements (e.g. face-face, 
face-edge, edge-vertex) along with some appropriate action for each. And the fundamental importance of 
incidence to the topological methodology exacerbates the already diffi- cult problem of numerical robustness. 
Additionally, efficiency considerations necessitate some kind of spatial search struc-ture, one that 
is extrinsic to the representation and is typically an axis-aligned spatial decomposition. Therefore, 
it does not transform with the representation and so must be reconstructed after each transformation. 
An alternative that has been evolving throughout the decade of the 80's is the binary space partitioning 
tree. The fundamen-tal methodology underlying bsp trees is spatial partitioning. Hyperplanes are used 
to recursively subdivide D-space to create a disjoint set of D-dimensional cells. Each cell is then desig- 
nated as either in the interior of the set or in the exterior. The boundary of the set need not be represented 
explicitly as it is derivable from the cells. The representational power of linear bsp trees is the class 
of linear sets 1, which includes linear polytopes. The methodology of spatial partitioning ignores all 
topological properties of the set, and so bsp tree algorithms treat all topologically distinct sets identically, 
nor is any dis- tinction made between convex and non-convex sets. Thus the entire representatibnal domain 
is treated uniformly, providing a considerable improvement in the simplicity of the algo-rithms. In addition, 
the spatial search structure is intrinsic to the representation and so transforms with it. I. BSP Trees 
The most intuitive way to understand bsp trees is through the process that constructs them, and so we 
begin our introduction to bsp trees with an example. Figure 1 illustrates the construc- tion of a bsp 
tree. One begins with a region of space r, chooses some hyperplane h that intersects r, and then uses 
h to induce a binary partitioning on r that yields two new regions: r.child" = r n h- and r.child + = 
r n h +, where h- and h + are the negative and positive open halfspaces of h respectively. Each of these 
unpartitioned children can in turn be partitioned, and so on, to produce a binary tree of regions. r 
O Initial tree Initial region First binary New tree partitioning s 3 D\ ,,C 3 --E 6 Spatial partitioning 
Binary tree Figure 1 Constructing a bsp tree A bsp tree is then a hierarchical set of regions of a D-dimen- 
sion Euclidean space with a relation of parent-child defined on 1 We have only studied bsp trees of finite 
size (as in number of nodes); but the concept can be extended to trees that are eountably infinite. the 
set corresponding to "child formed by a binary partitioning of parent". The graph of the relation on 
the set is a binary tree. The process that builds bsp trees uses a single local operator, viz. binary 
partitioning, which provides the construction: (region, hyperplane) -> (region-, region +, binary partitioner). 
A binary partitioner of a d-region R is any d-1 subset of R which partitions R into two disjoint subsets, 
R- and R +, such that any path between two points, p- ~ R- and p+ E R +, must intersect the binary partitioner. 
Recursively applying this op- erator produces a bsp tree. While the bsp tree is a geometric entity whereas 
its binary tree is combinatorial, the language of binary trees is often use- ful for describing certain 
aspects of the bsp tree. By definition, there is an isomorphism between bsp tree regions and binary tree 
nodes, and we denote the region of a node V as V.region and conversely the node of a region R as R.node. 
Each internal node V has an associated binary partitioner that partitions V.region, while each leaf node 
corresponds to unpartitioned re- gion. These unpartitioned regions are called cells. (In figure 1, the 
cells are labeled with numbers.) Each edge of the binary txee corresponds to a halfspace: a left edge 
to the negative halfspace of the parent node's hyperplane and a right edge to the positive halfspace. 
We can then define any region R as the intersection of open halfspaces corresponding to edges on the 
path from the root to R.node. (In figure 1, cell 3 = A" n B+.) Thus, if the ini- tial region, typically 
all of D-space, is a convex and open set, it follows that all of the regions of the tree are convex and 
open sets. The binary partitioner of a partitioned region R, denoted as R.bp, is comprised of a hyperplane, 
bp.hp, a sub-hyperplane (or sub-hp), bp.shp, which is the intersection of R.bp.hp with R, and its two 
halfspaces bp.hs- and bp.hs +. Every region R is the root region of some bsp tree T, denoted as R.tree, 
and the symmetrical relation is denoted as T.root_region (to unambiva- lently denote the set of points 
corresponding to T.root_region, as opposed to the data structure, we may also use T.root_region.domain). 
The two subtrees are denoted as T.neg_subtree and T.pos_subtree lying in T.root region.bp.hs-and T.root_region.bp.hs 
+ respectively. The set of cells corresponding to the leaves of T together with the sub-hyperplanes of 
its internal nodes forms a partitioning of T.root region, and is denoted as T.partitioning. Review of 
previous work The original context in which the bsp tree was developed is that of rendering. The linearity 
of both planes and viewing rays means that if a ray intersects a plane it does so at only one point. 
And so the plane divides the ray into near and far sec- tions. This permits inducing a visibility priority 
ordering on the three subspaces formed by the plane: near halfspace -> plane -> far halfspace. Given 
a bsp tree T, determining this ordering at every node of the tree in a reeursive manner pro- vides a 
total ordering of the elements of T.partitioning (see [Schumaker et al 69] or [Sutherland, Sproull, Schumaker 
74], and [Fuchs, Kedem, Naylor 80] or [Naylor 81]). These techniques were extended to ray-tracing polyhedra 
and non-linear csg-dags in [Naylor and Thibault 86]. This work led to the association of attributes 
at the cells and the overt idea of bsp trees as a representation of polytopes. In [Thibault and Naylor 
87] and [Thibault 87], several new algorithms were in- troduced. Conversation from a b-rep to a bsp tree 
and point classification algorithms were derived by extending earlier very similar algorithms. The work 
with csg-dags led to an algo- rithrn for evaluating a csg expression in which the primitive objects are 
polyhedra each represented by a b-rep, to yield a single bsp tree corresponding to the expression's value. 
An earlier idea of inserting moving objects into a bsp tree led to an algorithm for evaluating a polyhedral 
set operation between a bsp tree and a b-rep to yield a bsp tree, i.e. bspt <op> b-rep -> bspt. Finally, 
algorithms were given for generating the poly- hedral boundary as either a set of convex polygons represented 
by a list of vertices or as a set of edges. In [Bloomberg 86], very similar ideas are developed, and 
an algorithm for bspt <op> bspt -> brep is given which classifies faces of one tree with respect to the 
other; but no subtrees are classified atomically. Even more recent work on bsp trees has provided a means 
of generating shadows for polyhedral models [Chin and Feiner 89] , interactive object design and view 
vol- ume clipping [Naylor 90a], radiosity [Fussell and Campbell 90], as well as algorithms with asymptotically 
improved bounds for constructing bsp trees from a set of faces in 3D and edges in 2D (i.e. conversion 
from b-rep to bsp tree) [Paterson and Yao 89] and [Paterson and Yao 90]. In [Torres 90], a new treatment 
is given of the original problems addressed in [Schumaker et al 69] of constructing an inter-object bsp 
tree of moving objects, where the individual objects are represented as bsp trees. Geometric model as 
attributes on a space The motivation for inducing a partitioning on a space S is to provide a means of 
distinguishing points in S through the as- sociation of arbitrary attributes with any of its points; 
that is to provide the mapping Model( X 6 S ) -> Attributes. We use the bsp tree to implement this general 
function. We associate with each element of our partitionings (cells and sub-hps) a set of C O or higher 
continuous functions whose domain is consid- ered to be restricted to that element. This provides a quite 
gen- eral mechanism for constructing complex discontinuous func- tions on S that are piecewise C 0. However, 
we will restrict our attention in this paper to the problem of represent regular sets, which requires 
the simplest possible set of attributes, Membership : [ In, Out }. Nonetheless, the principal result 
of this paper is the merging of two independent bsp tree spatial partitionings both defined on S. This 
merging operation is completely independent of the semantics of any attribute space, and requires only 
the ability to determine whether the at- tribute space of two elements can be represented by a single 
at- tribute space. Set operations are then constructed on top of this merging operation.  II. Merging 
Trees The most primitive operation then is merging two spatial par- titionings : given partitionings 
of the same space, Pl and P2, form a new partitioning P3 = P1 + P2 from the pairwise inter- section of 
the ceils of P1 andP2, i.e. acell c3 e P3 ¢=~ ] c 1 ~ P1, c 2 ~ P2, s.t. c3 = el n c2, c3 ~ 0. Merging 
can be illustrated by simply overlaying the two parti- tionings on top of each other, as shown in figure 
2.1. We will then merge two trees T1 + T2 -> T3, s.t. T3.partitioning = Tl.partitioning + T2.partitioning. 
However, since bsp trees are a hierarchy of regions, we will need to do somewhat more than merely merge 
their partition- ings. Nonetheless, the algorithm to perform merging of bsp trees is fairly simple and 
recursive. T1 .partitioning T2.partitioning Tl.partitioning + T2.partitioning Figure 2.1 Merging partitionings 
As with most bsp tree algorithms, we can understanding lree merging in terms of the paradigm of inserting 
an object into a tree; in this case, the object is a tree as well. (Below, we will re- lax this asymmetrical 
view). As always, we need the two basic bsp tree operations: performing a binary partitioning of the 
object if at a partitioning node and executing a cell <op> object when at a leaf. Performing a binary 
partitioning of a bsp tree by the binary partitioner of a node provides ( Bspt, Bp ) -> ( in.NegHs, inPosHs 
: Bspt ); that is, a tree is split by a binary partitioner to yield two trees T- = T n bp.hs" and T + 
= T n bp.hs +. A Cell <op> Tree routine is imported by the tree merging routine, and it is this routine 
that embodies the semantics of the applica- tion. Its function is to merge the single set of attributes 
of a cell with the attributes of a tree. When the semantics is that of set operations on polyhedra, the 
spatial structure of the result will be either that of the cell or the tree (the specifics are dis- cussed 
below in section V). Given these two operations, the algorithm partitions one tree, say T2, by the binary 
partitioner at the root of the other, T1. The two resulting trees, T2" and T2 +, are defined on exactly 
the same region (domain) as Tl.neg_subtree and Tl.pos_subtree respectively. Thus, we have created two 
new sub-problems, each identical in form to the original problem: merge two trees each of which partition 
the same subspace. When a cell is reached, the semantics-dependent Cell <op> Tree routine is called. 
The basic algorithm is given in Figure 2.2. An illustration of tree merging appears in Figure 2.3. As 
one can see, each cell of T1 is replaced with that subset of T2 that lies in that cell. While figure 
2.2 provides the essentials of the merging al- gorithm, there remain a number of secondary issues. The 
first of these arises from the fact that the algorithm is completely symmetric with respect to its two 
operands, so one has the op- tion of choosing at each recursive invocation of Merge_Bspt0, whether to 
partition the first tree by the second or the second by the first. A method Choose_PartitionerO can be 
provided to Merge Bspt0 for this purpose, and may enforce whatever pol- icy is appropriate for the current 
usage. (Note that since the merge operations may be used to provide a non-commutative operator, the order 
of the operands must be preserved by having two distinct CASEs, one with T1 as the partitioner and one 
for T2.)   @SIGGRAPH '90, Dallas, August 6-10, 1990 Merge_Bspts : ( T1, T2 : Bspt ) -> Bspt tip Types 
 PartltlonedBspt : ( inNegHs, inPosHs : Bspt ) Imports Merge_TreeWlth_Cell : ( T1, T2 : Bspt ) -> Bspt 
User defined semantics. Partltion_Bspt : ( Bspt, Bp ) -> PartitionedBspt Definition IF TI.ls a cell OR 
T2.is a cell THEN VAL := Merge_Tree_With_Cell( TI, T2 ) ELSE Partltlon_Bspt( T2, Tl.root_region.bp ) 
-> T2_partitioned VAL.neg subtree .-'-  Merge_Bspts( Tl.neg_subtree, T2_partitioned.lnNegHs ) VAL.pos_subtree:= 
Merge_Bspts( Tl.pos_subtree, T2_partitioned.inPosHs ) VAL.root_region := Tl.root_region END If RETURN 
VAL END Merge_Bspts Figure 2.2 Merging BSP Trees Algorithm  D /A\ ~t_ Y X - /\ /N/\ T2"!"1 ~A~ t3 
 / ~,,,, ~X\ /X /Yx f T1 + T2 Figure 2,3 Merging two trees Secondly, it may be necessary to perform 
merging of at-binary partitioner are independent of those of the subtree, then tributes in the sub-hp 
of the bp that is used as the partitioner. this subspace must be taken into account as well when deter- 
This can be handled by a Merge_Bp_Attributes0 method. For mining homogeneity. Note that in the case of 
polyhedra, representing polyhedra, these attributes are the faces of the binary partitioner attributes, 
i.e. the faces of the polyhedra, are polyhedra and the requisite routines are discussed below in sec- 
not independent; they are a function of their neighborhood of tion VI. ceils. Finally, it is desirable 
to perform condensation. When the attributes defined on Tree.root_region.domain are homoge-neous, there 
is no reason to maintain a partitioning of the do- III. Binary Partitioning of a BSP Tree main, and so 
we will condense the tree into a single cell. Under the recursive assumption that the two subtrees are 
already con- We now address the problem of partitioning a bsp tree. Given a densed, determining homogeneity 
requires first that they both bsp tree T and a binary partitioner P defined on the same region be singular, 
i.e. comprised of a single node, and then that their of space, we want to form two trees, T- and T + 
such that T- = T attributes be identical. If attributes defined on the domain of the n P.hs" and T + 
= T ~ P.hs +, where Regions( T- ) =- { r- I r- = r n P.hs', r ~ Regions( T ), and r" ~ ~ } and similarly 
for Regions( T + ). To compute the two trees resulting from this operation, we will once again use the 
notion of inserting a geometric entity into the tree; in this ease, the entity is a binary partitioner. 
This insertion process will identify which regions of T lie en- tirely in P.hs', or entirely in P.hs 
+, or are intersected by P. (Note that insertion visits exactly those regions that are inter- sected 
by P). Accomplishing this requires determining the rela- tive spatial relationships of two bp's and, 
when they intersect, splitting each bp by the hyperplane of the other. This opera- tion as well as the 
representation and generation of sub-hp's is discussed below in section IV. We have the usual form of 
first distinguishing between cell and partitioning nodes (singular and non-singular trees), and in the 
case of a partitioning node, performing a binary partition- ing of the inserted entity, i.e. the partitioning 
bp. Partitioning a cell is trivial: one needs only to return two copies of that cell. For a partitioning 
node, however, the issue is more involved. The first step is to perform a hi-partitioning between Pand 
T's bp; that is, each bp is classified with respect to the other into the standard binary partitioning 
eases: Location : { InNegHs, InPosHs, InBoth, On }. Figure 3.1 shows the four possible geometric configurations. 
(Not shown are InNegHs/InPosHs, InPosHs/InPosHs, and On- parallel, since they have the same geometry 
but with one normal flipped.) The routine to perform this operation, Bi-Partition Bps0 is discussed in 
section IV. InPosHs/InNegHs InNegHs/InNegHs On one side InBoth Anti-parallel On Figure 3.1 Spatial binary 
relationships partitioners between two While each of the seven cases are treated separately, they all 
share the basic premise that any subtree containing the parti- tioner will need to be partitioned, and 
any that does not will need no modification. So, the case where P's location = InNegHs results in T.neg_subtree 
being partitioned but not T.pos_subtree, and InPosHs requires the opposite action, InBoth entails partitioning 
both, and On neither. The parts of subtrees resulting from this recursive partitioning are then pieced 
together to form the two trees which are the return values of this operation. To see this more clearly, 
figure 3.2 attempts to illustrate what is taking place for the InBoth case in which four subtrees are 
generated, two from each subtree of T. During the process of inserting the bp P into the tree, one views 
the activity primar- ily in terms of the two halfspaees of T.root region: we con- struct P- = P c~ T.hs- 
and P+ = P n T.hs +. In contrast, the re- suit, which is formed after any required subtree partitioning, 
is instead in terms of the halfspaces of P: T + = T n P.hs + and T- = T n P.hs-, which also entails computing 
T.bp- = T.bp n P.hs" and T.bp + = T.bp n P.hs +. So we have T- being formed out of pieces from both of 
T's two subtrees : T'.neg subtree := T's_neg_subtree.inNegHs T'.pos_suhtree := T's_pos_subtree.lnNegHs 
T'.root region.bp := T's_bp.inNegHs  and similarly for T +. 1oo~ PA~ btree+ po, u. T.bp ~ll~.~J. bp 
'~Jsu bt ree+  n e~.,u-b'l"~e n e g_s m.e.t"Fe e- Before Partitioning After Partitioning ~e~ ~tree 
pos_ ,~..~.,~.~ o o t. b p r o Ont;;_~ su btree VAL.inNegHs VAL.inPosHs Figure 3.2 Partitioning a tree 
for InBoth case The cases in which P is entirely to one side of T.bp is illus- trated in figure 3.3. 
There are four instances of this case ob- tained by flipping normals; only one is shown here. For this 
case T.bp and T.neg_subtree remain intact; only T.pos_subtree is partitioned. The return values are: 
T'.neg_subtree := T.neg_subtree T'.pos_suhtree := T's pos_subtree.inNegHs T'.root region.bp := T.bp 
and T + := T's_pos_suhtree,inPosHs. Analogous assignments yield the other three instances. And finally, 
the third case of On requires no further parti- tioning and is given simply by selecting the appropriate 
subtrees: IF normals are parallel THEN T" := T.neg_subtree T + := T.pos_subtree ELSE T + := T.neg_subtree 
T" := T.pos subtree END SIGGRAPH '90, Dallas, August 6-10, 1990 After Partitioning VAL.inNegHs VAL.inPosHs 
Figure 3.3 Partitioning a tree for InPosHs case It is important to note that any newly formed tree should 
have the condensation operation applied to it. While not needed for correctness, this can have a significant 
impact on performance. Consider figure 3.4 in which two complex objects are each contained inside their 
bounding simplex. If 1"2 is inserted into T1, then T2 will be partitioned by X then Y and then Z. At 
this point, the fragment of T2 inside Tl's bounding simplex will be condensed to a single out-cell, and 
so the merging operation will be complete. Neither of the subtrees inside the bounding simplices will 
be visited during this process. With the description of Partition_Bspt complete, we make the following 
observation : to merge T1 with T2, we can insert T2 into T1, which entails the apparent paradox of inserting 
T1 into T2 (actually, Tl's bp's), but one piece at a time. T1 T2 /x~ /A \ ll~tlCtl ~tO.t~ X After partitioning 
by X Figure 3.4 Effect of IV. Representation and partitioning of binary partitioners Partition Bspt 
relies upon Bi-Partition_Bps as the basic operation for determining the relative location of two Bps 
and for splitting them when the location is InBoth halfspaces. To provide this, we will need an explicit 
representation of the domain of a bp, i.e. of its sub-hp. This is unlike all previous operations on bsp 
trees, which require only hyperplane equa- tions and possibly a single "representative point" in the 
inte- rior of a sub-hp (as in the set operations in [Thibault and Naylor 87]). Determining the respective 
locations of two binary partitioners that partition the same region R can be based on computing their 
intersection : Pl.shp n P2.shp = (R c~ Pl.hp) ~ (R c~ P2.hp) = Pl.shp c~ P2.hp. Binary trees Y After 
partitioning by X, Y and Z condensing during partitioning As the value of R must appear in the expression, 
we "encode" it into a sub-hp. However, when there is no intersection, we need to know in which halfspace 
the sub-hp lies, and in this case the routine that computes Pl.shp n P2.hp can tell us only the location 
of P1 with respect to P2.hp. Therefore, we will need to either use the representative point method or 
perform the complementary operation P2.shp n Pl.hp. In the current implementation, a sub-hp is represented 
by a b-rep, and for the sake of simplicity we restrict the embedding space to be 3-dimensional so that 
the sub-hps are polygons. Since sub-hps are convex, we can represent them using the simplest representation: 
a list of vertices. Given explicit sub-hps, the hi-partitioning operation is comprised of two applications 
of the same operation: partition a polygon by a plane. First Pl.shp is partitioned by P2.hp. We then 
performing the same operation for P2.shp with respect to P1 .hp There is a one problem with using b-reps: 
sub-hps may be unbounded sets and b-reps can not represent unbounded sets (e.g. the sub-hp of T.root_region.bp 
when T.root region.domain = 3-space is a hyperplane). Our solution to this is to represent 3-space as 
a bounded set, in particular as a box centered at the origin whose size is sufficiently large to accommodate 
the geometric model. We call this the universe-box. Since geometric models typically require no more 
than 7 orders of magnitude (e.g. from 1 rnm. to 1 km ), constructing a sufficiently large box is easily 
done without compromising numerical robustness appreciably, especially when using double precision. To 
generate a representation of the sub-hp for the bp at some tree node v, we need to first construct a 
polygonal repre- sentation of the bp's hp [Thibault 87]. This is done by project- ing one of the sides 
of the universe-box onto the hyperplane. The side chosen is the one whose the ratio of its area to that 
of its projection is closest to unity. To achieve this, we choosing the side whose normal makes the smallest 
angle with that of the hyperplane. Given this "hyperplane as bounded polygon", we insert it into the 
txee, partitioning it at each node as usual, but follow- ing only the path that leads to the target node 
v. Thus, when our incipient sub-hp is InBoth, we retain only that half which is in the region of the 
next node on the path. When we reach v, we have the desired sub-hp. Given any bsp tree containing no 
explicit sub-hp's, we will perform this operation for every node in the tree. (Rather than following 
a path from the root to the "current" node, we actually follow the path in the opposite direction, from 
the node to the root via parent links. This of course is a unique path and avoids the issue in the root-to-node 
order of knowing whether to follow the left or right child.) Anytime an affine transformation is applied 
to a tree, those sub-hp's which are "unbounded" will need to be recomputed since they will no longer 
correspond to the intersection of their hyperplane with the universe-box. To facilitate this, each sub-hp 
is tagged to indicate whether it is unbounded, and if so, then regenerated when transformed. (If one 
uses the first D+I nodes to construct a bounding simplex, then only the first D sub-hps of this simplex 
are unbounded, i.e intersect the uni- verse box.) All other sub-hp's can be transformed normally (by 
their vertices), since they will remain bounded (under the assumption that the universe-box is sufficiently 
large). V. Set Operations on Polyhedra Once the mechanism for merging spatial partitionings is in place, 
performing set operations on polyhedra is a relatively simple matter. The merging process recurses until 
one of the two operands is homogeneous, i.e. is a cell, at which point we use a routine for merging cell 
attributes with those of some ar- bitrary tree (which may also be a cell). For set operations, this amounts 
to simply selecting either the cell or the tree, possi- bly complemented, as a function of the membership 
attribute (Figure 5.1). Complementation of a tree involves simply the boolean complementation of the 
membership attribute. Figure 5.2 illustrates the union of two bsp tree objects. In general, there is 
more to do than this. If there are other attributes, such as color, index of refraction, density, or 
what-ever, these will need to be merged in some appropriate way as well. And so the above routine will 
need to be augmented to handle these. (Exactly how a particular attribute, such as color or transparency, 
should be merged in a union for instance, is currently an unsettled issue ). Note that this additional 
merging of attributes may generate condensable subtrees. Cell_SetOp_Tree: ( T1, T2 : Bspt ) -> Bspt .om 
°°- VAL := IF Tl.ls an InCell THEN CASE operation Union -> T1 Intersection -> T2 Difference -> Complement_Bspt( 
T2 ) Symmetric_Difference -> Complement_Bspt( T2 ) END ELSEIF Tl.is an OutCeli THEN CASE operation Union 
-> T2 Intersection -> TI Difference -> T1 Symmetric_Difference -> T2 END ELSE Repeat the above with T1 
and T2 swapped. END Cell_SetOp_Tree Figure 5.1 Cell_SetOp Tree for Set Operations VI. Polyhedral Faces 
While the above routine covers "attribute maintenance" for D- dimensional ceils, there remains the same 
issue for the D-1 domains of the binary partitioners. For polyhedra, the entire boundary of the set lies 
in the sub-hps, and while the boundary is wholly derivable from the D-cells, one may wish to explic- 
itly represent the set of boundary faces. The primary motiva- tion for doing so is to provide the input 
required by rendering systems that are based on polygon drawing. Using the bsp la'ee, one can provide 
a visibility priority ordering of the faces to such a system. (Note that if instead one uses ray-tracing, 
the explicit representation of the boundary is unnecessary.) The boundary of a set is precisely those 
points whose t- neighborhood contains both interior and exterior points for all ~. Thus, any subset of 
a sub-hp which has an in-cell on one side and an out-cell on the other will be on the boundary of the 
polyhedra. In figure 6, we illustrate this idea by showing the boundary along with normals to the faces 
oriented to "point" to the exterior. Note that a sub-hp may contain more than one face and that the face 
orientations may be either parallel to the hyperplane orientation or anti-parallel. There are two possible 
approaches to face generation: either in every tree maintain faces as an intrinsic component of the representation, 
or delay creation of any faces until after an entire expression has been evaluated. Both approaches utilize 
a neighborhood operation that finds those cells in the neighbor- hood of a sub-hp, or equivalently, those 
cells whose boundary intersects a sub-hp. Consider any subtree T. If we insert the sub-hp at T.root_region 
into T.neg_subtree and then into T.pos subtree, the cells that are reached are precisely those in the 
sub-hp's neighborhood. These cells can be naturally grouped into those in the positive subtree and those 
in the negative subtree. In addition, the search of a subtree will parti- tion the sub-hp into subsets 
that bound a single cell, and so will classify the sub-hp into "in" and "out" subsets. ~ 1 0 1/ ~0 ~'X~A 
1/Z~0 % 1 I l/r\ Figure 5.2 Union of two objects /c\ o o 1 0 0 1 Figure 6 Faces of a polytope So 
with this, generation of faces from a sub-hp is straight- forward [Thibault 87]. First, classify the 
sub-hp with respect to one of T's subtrees, say the negative subtree, and then classify the resulting 
fragments with respect to the positive subtree. This yields fragments whose neighborhood is "homogeneous", 
i.e. is the same for all points in the fragment. With this infor- mation, we can generate the following 
classifications: neg_subtree pos_subtree classification in In in in out on (parallel) out 1 n on (anti-parallel) 
out out out Retaining the on fragments, separated into parallel and anti-parallel lists, as part of 
each binary partitioner provides the polyhedral faces. These faces, in fact, provide only a partial classification 
of the partitioner's domain. There are two kinds of on-regions, parallel and anti-parallel, but in-regions 
and out-regions are lumped together implicitly as not-on. Note that these face fragments are convex, 
since they are generated by the intersection of halfspaces with their supporting hyper-plane. To generate 
all of the faces of a tree that contains ex-plicit sub-hps but not explicit faces, one simply performs 
this neighborhood operation for every binary partitioner in the tree. The alternative is to maintain 
explicit faces at all times. So the result of a single set operation, T3 := T1 <op> T2, will entail generating 
all of the polyhedral faces of "I"3 before 1"3 is used in any subsequent set operations. The objective 
is the same as before, to know the classification of all sub-hps, but the approach is less direct. Instead 
of classifying sub-hps, we employ the fact that the faces of T3 are a subset of those of T1 and T2 combined, 
and in effect classify only the subsets of sub- hps "covered" by the faces. Note that the addition of 
faces to the representation will require extending both Complement_Bspt0 to swap parallel and anti-parallel 
face lists and Bi-Partition_Bp0 to partition any faces lying in a binary partitioner (this will be needed 
only if its sub-hp is InBoth, and thus the sub-hp provides a "convex hull" test for the faces). We will 
use a combination of two techniques already intro- duced: cell <op> tree and the neighborhood operation. 
The first is employed under two circumstances. When, during the recur- sire process of tree merging, 
one of the two arguments is a cell, the routine Cell_SetOp_Tree0 is called. This executes"the set operation 
by returning one of the two arguments (possibly complemented), and so implicitly classifies any faces 
in the process. The second circumstance occurs during Partition_Bspt0 whenever the partitioning bp reaches 
a ceil. Its face fragments can then have the same rules applied to them. The only remaining case is that 
of on-faces. Whenever the On case in Partition_Bspt0 occurs we will need to use the neigh- borhood operation 
in leu of direct classification by cells. On- faces from T1 (T2) will need to be classified with respect 
to the subtrees of T2 (T1) (see [Thibault and Naylor 87] and [Naylor 90a]). VII. Numerical Robustness 
The occurrence of numerical errors due to finite arithmetic has been a nemesis of geometric computing 
since its inception. Its negative impact is greatest when the result of a numerical com- putation is 
used to discriminate logical alternatives in an algo- rithm. This can lead to arbitrarily "discontinuous" 
behavior; that is, the output of the algorithm can be highly sensitive to small random perturbations 
of the discriminators (the program may fail as well). While a number of schemes have been devised to 
ameliorate the problem, the simplest and most common is the use of e-intervals. For example, a discrimination 
based on whether a real value X is less than, greater than, or equal to 0 can be replaced with one that 
determines whether a X < -e, X > +E, or in [-e +el respectively. More sophisticated methods enforce the 
intended semantics through a variety of schemes ( see e.g. [Karasiek 89]). The only numerical computation 
in this work is the parti- tioning of a polygon by a plane. Its primitive operation is the dot product 
of a point and a plane to determine the location of that point with respect to the plane. The specific 
algorithm we use assumes the semantics of planar, convex polygons, and we rely on the epsilon method 
just described to attain robustness (to dampen the noise). Thus, the hyperplanes are in effect slabs 
2E thick. Any failure of this technique is detected, but no correction strategy is evident other than 
using larger epsilons (this has been in use since [Naylor 81]). Unfortunately, this approach is insufficient 
to achieve a ro- bust bi-partitioning operation. In fact, larger epsilon exacer-bate the problem. Recall 
that there is a correlation between the location of the two bps: Pl's location = IrgBoth ¢=> P2's loca- 
tion = InBoth, and similarly On ¢=> On, and NotInBoth ¢0 NotInBoth . Numerically this does not always 
hold. Our ap-proach is to detect inconsistencies and induce a mapping to one of the consistent result. 
When one location is InBoth and the other is InNegHs or InPosHs, we can force the the former to be either 
InNegHs or InPosHs by selecting the "half" which contain vertices farthest from the partitioning plane, 
or we can force the second to the InBoth condition by extracting "on" vertices. If only one bp is On, 
we force it to a value consistent with the other bp. While we believe that forcing semantic con- sistency 
is essential, our current choices for enforcing this are at this point only tentative. Numerical problems 
also affect attaining the semantics of the neighborhood operation. The method used for constructing bsp 
trees, defined in the continuum, implies that any sets lying in T.root region.bp.shp will not be On any 
sub-hp in either of T's subtrees; however, numerically this does not always hold. We employ the following 
defense.When a face fragment from node V is classified as On during the neighborhood operation at a descendant 
node U, we essentially treat that node as if it were contained in the face's sub-hp, i.e. as if it did 
not exist. We then choose the subtree of U that is "not adjacent" to V, and continue the search. The 
combination of these techniques has led to a robust set operation algorithm is the sense that the program 
will not fail and its output is in the neighborhood of the ideal output over a large numerical range. 
For example, the standard test in which a set operation is performed between a cube and a second cube 
that has been rotated successively about each of its three prin- cipal axes by an angle 0t has been executed 
successfully with = 10 -9 with e < 10 -11, including e = 0, using 64-bit floating point numbers. For 
10 -9 > a > 10 -14, union continued to give the same results, while intersection and difference found 
some sides to be equivalent. As the value of e approaches ix, more equivalences are produced until the 
two objects are computationally considered identical. While using a small epsilon is interesting for 
testing the numerical limits, large epsilons are much more desirable (thicker hyperplanes) since they 
limit the size of the smallest fragments and so avoid representing features far below any Computer Graphics, 
Volume 24, Number 4, August 1990 viewing resolution. An upper bound to the thickness is the point at 
which the affect of treating faces as being co-planar, when in fact they are not, becomes visible to 
a viewer. VIII. Complexity A simple worst case lower bound of 12( n 2 ) is obtained by not- ing that 
a checker board can be constructed from the symmetric difference of two trees, the first composed of 
n horizontal strips with alternating boolean values and the second com-posed of n similiar vertical strips. 
As for an upper bound, the binary partitioner of each node of one tree is compared with the bp of each 
node of the second tree at most once, giving O(/T1/*/T2/) or more simply O(n2). This analysis would be 
sufficient if each comparison was guar- anteed to be 0(1). However, it is possible for a sub-hp to be 
of size O(n), e.g. the base of an n sided cone. If this were true for every sub-hp, Partition Bspt could 
take O( n 2 ) per call, giv- ing a total time of O( n 3 ). To show that this is not the case, we first 
observe that each sub-hp vertex is compared to a hyperplane of the other tree at most once per node. 
So if we can show that the total number of sub-hp vertices is O(n), we will have O( n 2 ) total work. 
To prove this we use arrangements of hyperplanes. An arrangement comprised of n d-cells can be represented 
by a bsp tree with an isomorphism from arrangement cells to bsp tree cells (leaf nodes) [Naylor 81]. 
Since it is known that the number of vertices of an arrangement is O(n) and the sub-hp vertices are a 
subset of these, it can be shown that despite the fact that there are multiple instances of some vertices, 
the number of sub-hp vertices of an arrangement is also O(n). Any bsp tree can be converted to its corresponding 
arrangement by replacing each cell/leaf with a tree representing the partitioning of that cell by all 
hyperplanes of the tree that intersect it. If we now remove any sub-hp separating two of the newly created 
cells, the new number of vertices will be: n * O(1)-fl(l) < (n-l) * O(1). If this is repeated, one node 
at a time, until the original tree is recreated, we will have O(/T/) vertices. We then have that merging 
bsp trees is worst case optimal t9( n 2 ). Of even greater interest is the expected case. This requires 
a definition of "good" trees, which we have developed but do not have space here to explore. If, for 
now, we simply take good to mean balanced, then merging two balanced trees of size n can produce, at 
worst, a tree with maximum depth of 2 log n. Or more generally speaking, merging two good trees should 
yield a reasonably good tree. Note that the use of a bounding simplex as in figure 3.4 can lead to O(d) 
time to merge two trees whose bounding simplices are disjoint and the interior of one simplex is not 
intersected by a sub-hp of the other. Concluding remarks It is worth comparing this algorithm to the 
method in [Thibault and Naylor 87]. One of the two methods in that work performs a set operation between 
a bsp tree represented polyhedron and a b-rep represented polyhedron. The inserted entity is the b-rep 
polyhedron, represented as a list of polygons. In this work, we have instead a bsp tree, clearly a more 
complex structure than a list, although not necessarily more complex than the more general b-rep structure 
as a hierarchy of lists (not used in [Thibault and Naylor 87]). However, there are at least two ways 
in which one gains from the using a bsp tree. The first advantage arises from the efficiency of a hierarchi- 
cal search structure: entire subtrees can be classified without examining their contents. In the average 
case, this can lead to O( log n ) behavior instead of O( n ). The second is algorithmic simplicity. Besides 
the obvious advantage of having only the bsp tree data type to deal with, it is difficult to determine 
with a b-rep the relative spatial classification of some other entity. The algorithms in [Thibault and 
Naylor 87] require, when the faees of the b-rep object are entirely to one side of a partition- ins hyperplane, 
the determination of whether the correspond- ing sub-hp is inside or outside of the polyhedron. While 
[Thibault and Naylor 87] gives the simplest solutions for this in 2D and 3D, the method is cumbersome 
and does not easily generalize to arbitrary dimensions (so much so that we have not seriously attempted 
to do so). In our new setting, while we still need this classification of the sub-hp with respect to 
the inserted object, its spatial structure being a bsp tree makes this straightforward, and in fact occurs 
as part of the partitioning operation itself, thereby necessitating no additional considera- tion and 
so solves the problem for arbitrary dimensions. This work remains a hybrid approach, since b-reps are 
used for polygons, both as sub-hps and faces. However, prior to im- plementing this scheme, we devised 
an "all bsp tree" represen- tation which dispenses with b-reps entirely (see [Naylor 90b] for a brief 
description). Thus, the sub-hps and the faces of a d- dimensional tree are represented by d-1 dimensional 
trees, and so on reeursing in dimension until d = 0. This representation has many advantages including 
dimension independence as well as obviating the problem encountered here with b-reps not being able to 
represent unbounded sets. We chose to imple- ment the hybrid approach described here to provide a more 
easily attainable intermediate step, since many techniques have been developed using polygons as b-reps 
that must be provided in the new scheme. Nonetheless, the routines Merge_Bspts and Partition Bspt are 
essentially the same in both schemes, the difference being limited primarily to Bi- Partition_Bps; and 
forming the boundary requires only the capabilities already provided by these routines. References [Bloomberg 
86] Sandra H. Bloomberg,"A Representation of Solid Objects for Performing Boolean Operations", U.N.C. 
Computer Science Technical Report 86-006 (1986). [Chin and Feiner 89] N. Chin and S. Feiner,"Near Real-Time 
Shadow Generation Using BSP Trees", Computer Graphics Vol. 23(3), pp. 99-106, (Aug. 1989). [Fuchs, Kedem, 
and Naylor 80] H. Fuchs, Z. Kedem, and B. Naylor, "On Visible Surface Generation by a Priori Tree Structures," 
Computer Graphics Vol. 14(3), pp, 124-133, (June 1980). [Fussell and Campbdl 90] Donald Fussell and 
A.T. Campbell, "Adaptive Mesh Generation for Global Diffuse Illumination," Computer Graphics Vol. 24(3), 
(Aug. 1990). [Hoffmann 89] Christoph M. Hoffmann, Geometric and Solid Modeling, Morgan Kaufmann, 1989. 
[Karasick 89] Michael Karasick, "On the Representation and Manipulation of Rigid Solids," Ph.D. Thesis, 
CorneU University (March 1989). [Mantyla 88] Martti Mantyla, Solid Modeling, Computer Science Press, 
1988. [Naylor 81] Bruce F. Naylor, "A Priori Based Techniques for Determining Visibility Priority for 
3-D Scenes," Ph.D. Thesis, University of Texas at Dallas (May 1981), [Naylor 9Oa] Bruce F. Naylor, "SCULPT 
: An Interactive Solid Modeling Tool", Proc. of Graphics Interface, (May 1990). [Naylor 90b] Bruce F. 
Naylor, "Binary Space Partitioning Trees as an Alternative Representation of Polytopes", Computer Aided 
Design, Vol 22(4), (May 1990). [Naylor and Thibault 86] Bruce F. Naylor and William C. Thibauh, "Application 
of BSP Trees to Ray-Tracing and CSG Evaluation," Technical Report GIT-ICS 86/03, School of Information 
and Computer Science, Georgia Institute of Technology, Atlanta, Georgia 30332 (February 1986). [Paterson 
and Yao 89] M.S. Paterson and F.F. Yao, "Binary partitions with applications to hidden-surface removal 
and solid modeling", Proceedings of Fifth Symp. on Computational Geometry, pp. 23-32, (1989). [Paterson 
and Yao 90] M.S. Paterson and F.F. Yam "Optimal Binary Space Partitions for Orthogonal Objects", Proceedings 
of Ist Symp. on Discrete Algorithms, pp. 100-106, (Jan. 1990). [Schumaker et al 69] R. A. Schumacker, 
R. Brand, M. Gilliland, and W. Sharp, "Study for Applying Computer-Generated Images to Visual Simulation," 
AFHRL-TR-69-14, U.S. Air Force Human Resources Laboratory (1969). [Sutherland, Sproull and Schumaker 
74] I.E. Sutherland, R.F. Sproull and R. A. Schumacker, "A Characterization of Ten hidden Surface Algorithms," 
ACM Computing Surveys Vol 6(1), (1974). [Thibault and Naylor 87] W. Thibauh and B. Naylor, "Set Operations 
On Polyhedra Using Binary Space Partitioning Trees," Computer Graphles Vol. 21(4), (July 1987). [Thibault 
87] William C. Thibault, "Application of Binary Space Partitioning Trees to Geometric Modeling and Ray-Tracing", 
Ph.D. Dissertation, Georgia Institute of Technology, Atlanta, Georgia, (1987). [Torres 90] Enric Torres, 
"Optimization of the Binary Space Partition Algorithm (BSP) for the Visualization of Dynamic Scenes" 
Eurographics '90 (Sept. 1990).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97893</article_id>
		<sort_key>125</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[An efficient radiosity solution for bump texture generation]]></title>
		<page_from>125</page_from>
		<page_to>134</page_to>
		<doi_number>10.1145/97879.97893</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97893</url>
		<abstract>
			<par><![CDATA[The development of global illumination and texture generation makes it possible to produce the most realistic images. However, it is still difficult or deficient so far to simulate bump texture effects while the interreflection of light being modeled by the present ray tracing or radiosity methods. A method of bump texture generation, being incorporated into the process of radiosity solution, is presented in the paper. The method is characterized by introduction of a <i>perturbed radiosity map</i>, established in the context of either progressive radiosity or standard radiosity solution. To calculate the perturbed radiosity, a concept of <i>perturbed form-factors</i> is proposed, and the algorithms for evaluating the perturbed form-factors are also given. As a result, a bilinear-interpolation shading scheme for perturbed surfaces is provided, and the texturing method is easily added to a newly improved solution of progressive refinement radiosity for non-diffuse environment.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14050396</person_id>
				<author_profile_id><![CDATA[81452604960]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Software, Academia Sinica, P. O. Box 8718, Beijing 100080, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P77547</person_id>
				<author_profile_id><![CDATA[81100657893]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[En-Hua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Software, Academia Sinica, P. O. Box 8718, Beijing 100080, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74367</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baum, D. R., Rushmeier, H. E. and Winget, J. M., Improving Radiosity Solutions through the Use of Analytically Determined Form-Factors, Computer Graphics, Vol 23(3), 1989, pp.325-334]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B linn, J. F. and Newell, M. E., Texture and Reflection in Computer Generated Images, Comm. ACM, Vol 19(10), 1976, pp.542-547]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B linn, J. F., Simulation of Wrinkled Surfaces, Computer Graphics, Vol 12(3), 1978, pp.286-292]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37434</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cabral, B., Max, N. and Springmeye R., Bidirectional Reflection Functions from Surface Bump Maps, Computer graphics, Vol 19(4), 1987, pp.273-281]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Carey, R. J. and Greenberg, D. P., Texture for Realistic Image Synthesis, Computer &amp; Graphics, vol 9(2), 1985, pp.125-138]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Catmull, E., A Subdivision Algorithm for Computer Display of Curved Surfaces, Ph.d Dissertation, Univ. of Uta, Salt Lake City, 1974]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>90996</ref_obj_id>
				<ref_obj_pid>90967</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Chert, H. and Wu, E. H., An Adapted Solution of Progressive Radiosity and Ray Tracing Methods for Nondiffuse Environment, Proceedings of CGI'90, June 26-30, 1990]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F. and Greenberg, D. P., The Hemi-cube: A Radiosity Solution for Complex Enviromnent, Computer Graphics, Vol 19(3), 1985, pp.31-40]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F., Greenberg, D. P., Immel, D. S. and Brack, P. J., An Ef~cient Radiosity Approach for Realistic Image Synthesis, IEEE CG&amp;A, Vol 6(2), 1986, pp.26-35]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F., Chen, S. E., Wallace, J. K. and Greenberg, D. P., A Progressive Refu~ment Approach to Fast Radiosity Image Generation, Computer Graphics, Vol 22(4), 1988, pp.75-84]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Shade Trees, Computer Graphics, Vol 18(3), 1984, pp.223-231]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Goral, C. M., Torrance, K. E. and Greertberg, D. P., Modelling the Interaction of Light between Diffuse Surfaces, Computer Graphics, Vol 18(3), 1984, pp.213-222]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Immel, D. S., Cohen, M. F. and Greertberg, D. P., A Radiosi~ Method for Non-diffuse Enviromnent, Computer Graphics, Vol 20(4), 1986, 133-142]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>23954</ref_obj_id>
				<ref_obj_pid>23944</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Max, N. L., Shadows for Bump-mapped Surfaces, Advanced Computer Graphics, Kunii T.L. Ed. Springer Verlag, Tokyo, 1986, pp.145-156]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., An linage Synthesizer, Computer Graphics, Vol 19(3), 1985, pp.287-296]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378492</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Shao, M. Z., Peng, Q. S. and Liang, Y. D., A New Radiosity Approach by Procedural Refinements for Realist&amp; Image Synthesis, Computer Graphics, Vol 22(4), 1988, pp.93-101]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Shao, P. P., Peng, Q. S. and Liang, Y. D., Formfactors for General Environments, Proc. Eurographits'88, Nice, 1988, pp.499-510]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sillion, F. and Puech, C., A General Two-pass Method Integrating Specular and Diffuse Reflection, Computer Graphics, Vol 23(3), 1989, pp.335-344]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sparrow, E. M. arid Cess, R. D., Radiation Heat Transfer, McGraw-Hill, New York, 1978]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wallace, J. R., Cohen, M. F. and Greenberg, D. P., A Two-pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radiosity Methods, Computer Graphics, Vol 21(4), 1987, pp.311-320]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Wallace, J. R., Elmquist, K. A. and Haines, E. A., A Ray Tracing Algorithm for Progressive Radiosity, Computer Graphics, Vol 23(3), 1989, pp.315-324]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Ward, G. J., Rubinstein, F. M. and Clear, R. D., A Ray Tracing Solution for Diffuse lnterreflection, Computer Graphics, Vol 22(4), 1988, pp.85-92]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Whitted, T., An Improved Illumination Model for Shaded Display, Comm. ACM, Vol 23(6), 1980, pp.343-349]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Efficient Radiosity Solution for Bump Texture Generation Hong Chen and En-Hua Wu Institute of Software, 
Academia Sinica P. O. Box 8718, Beijing 100080, China Abstract The development of global illumination 
and texture gen- eration makes it possible to produce the most realistic images. However, it is still 
difficult or deficient so far to simulate bump texture effects while the interreflectiort of light being 
modeled by the present ray tracing or radioslty methods. A method of bump texture generation, being incor- 
porated into the process of radiosity solution, is presented in the paper. The method is characterized 
by introduction of a perturbed radiosity map, established in the context of either progressive radiosity 
or standard radiosity solution. To calcu- late the perturbed radlosity, a concept of perturbed form- 
factors is proposed, and the algorithms for evaluating the perturbed form-factors are also given. As 
a result, a bilinear- interpolation shading scheme for perturbed surfaces is pro- vided~ and the texturing 
method is easily added to a newly improved solution of progressive refinement radiosity for non-diffuse 
environment. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation; 
Display Algorithm; 1.3.7 [Computer Graphics]: Three-Dimentional Graphics and Realism. General Terms: 
Algorithms. Additional Key Words and Phrases: perturbed radiosity map, perturbed form-factor, perturbed 
hemi-cube, bumpy tex- ture, radiosity, interreflection, progressive refinement. 1. Introduction The 
most realistic and attractive computer generated images are those that contain a large amount of visual 
com- plexity and detail. Ray tracing and radiosity methods are able to produce highly realistic images 
by faithful simulation of light energy exchange between surfaces. However, if an image is rendered only 
by taking illumination model into Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. account, it will look artificial due to the extreme smoothness of surfaces. To overcome 
this shortage, the surface complex- ity should be increased. Comparatively, texturing is an acceptable 
method that can increase the surface detail by a relatively low cost. Generally speaking, the surface 
texture mapping approaches come imo two main categories: color mapping and bump mapping. The conventional 
ray macing method simulates light reflection and refraction for specular and transparent surfaces, and 
produces direct illumination and shadow effects[23]. The diffuse interreflection in the ray tracing is 
simply treated as a constant "ambient" term, which makes images obviously computer-generated, as the 
interrefiection has significant effect on the lighting of a scene. There have been many approaches[2][3][4][5][6][ld] 
which incorporate the texture generation process directly into reflection calculation. These approaches 
are suitable for rendering pictures via standard ray tracing method. But within the standard ray tracing 
methodology, the texture solu- tion for diffuse interreflection is by no means viable due to the inherent 
nature of standard ray tracing. In 1988, Ward et al. introduced a new ray tracing method of modeling 
(diffuse) interreflection[22]. By their method, indirect illuminance is averaged over surfaces from a 
small set S of computed values to avoid calculation at each pixel. The members of the set S are determined 
by the split sphere model which estimates the illuminance gradient on each sur- face using the illuminance 
coherence. But such split sphere model only relates the illumninance gradient to the scene geometry without 
considering t_he lighting distribution. To maintain accuracy, when the orientation of a surface, such 
as a wrinkled surface, changes rapidly, the computation of indirect illuminance increases at a very high 
rate. Therefore, this method is not efficient for simulating textures, in particu- lar the bumpy texture[3], 
with diffuse interrflection effect. The radiosity method, based on the principle of heat transfer[ 19], 
is well suited to calculating diffuse interreflection[12]. In 1985 and 1986, Cohen, Greenberg et al. 
developed the standard radiosity method, in a diffuse envi.ron- ment[8][9]. Various radiosity methods 
were developed in the following years for rendering pictures in a non-diffuse &#38;#169;1990 ACM-0-89791-344-2/901008[0125 
$00.75 125 SIGGIqAPH '90, Dallas, August 6-10, 1990 environment[20][16][17][18]. The progressive refinement 
radiosity method proposed by Cohen et al. in 1988110] has made it possible for radiosity to be employed 
interactively for image synthesis in a complex environment. A diffuse interreflectional texture algorithm 
based on a reformed colour texture mapping technique was realized in Cohen's standard radiosity approach[9]. 
However, no efficient technique available so far for simulating the bump mapping texture[3] in an interrefleetional 
environment within the framework of radiosity or ray tracing methods. In the following part of the paper, 
we will present a radiosity solution for bump mapping texture rendering, based on illuminance coherence. 
The technique has been realized without significant degradation of the radiosity methods util- ized. 
Efficiency is obtained with an introduction of so called perturbed radiositv map and perturbed form-factor. 
Com-bined with an adapted progressive refinement radiosity method for non-diffuse environment[7], a general 
rendering method, which has a highly practical value, is established. 2. Bumpy Mapping Texture by Perturbed 
Radiosity Map The slight change of a surface normal direction will result in variation in the intensity 
distribution of the reflected light. Rased on this principle, Blinn first made a proposal for simu- lating 
wrinlded surfaces by perturbing surface normals. This is popularly known as "bumpy mapping"[3]. He developed 
a method for generating the direction and value of the normal perturbations from a bump function F(u,v) 
of the surface parameters. F(u,v) is stored as a two-directional lookup table indexed by u and v. By 
moving the parameterized surface t~(u,v) a small value F(u,v) in the direction of the surface normal 
A~, new normal AT" is calculated and the bumpy sur- face is produced in terms of/~'. t~y the shading 
scheme of radiosity method, the radiosity at a point within a patch is calculated by billnear interpola- 
tion from the radiosities at the patch vertices, and thus the true surface normal at the visible point 
has not been utilized directly during the rendering process. Therefore, the tradi- tional bump mapping 
technique is unable to be added into radiosity solution. We notice that within a relatively small range, 
the sur-faces which have the same normal will have their illuminance more or less the same. Based on 
this phenomenon of iUumi-nance coherence, we are able to design a shading scheme to calculate the perturbed 
radiosity on a perturbed patch. Briefly speaking, if the radiosity B (/~', P~) at a patch vertex P~ can 
be calculated and recorded in a perturbed radiosity map for different perturbed directions of ~', then 
The perturbed radiosity B(/~', P) at any point /~ on the patch can be derived from the traditional method 
of bilinear interpolation of the radiosities B (/~',/~) at vertices. If the patch is not perturbed, /~" 
is identicat to A~, B (~,/¢) can be determined just as in the standard radiosity method. Next, in Section 
2.1, before going through the detailed discussion of texture generation, we first review an imple-mentation 
of two-pass method for non-diffuse environments combining an adapted progressive radiosity and ray tracing 
methods. It was taken to be the bed for our texture genera- tion. A description is given in Section 2.2 
on how to evaluate the perturbed diffuse radiosity, which is followed in Section 2.3 by derivation of 
a method for the evaluation of perturbed form-factors. 2.1 Progressive Refinement Radiosity for Non-diffuse 
Environment Within a diffuse environment, the radiosity of a patch, say i, is given by: /¢ Bi = Ei+p¢ 
~BjFjiAi/Ai <1> j=l where Bi is radiosity of patch i (watts/m 2 )o Ei is emission of patch i (watts/m 
2 ), Pi is reflectance of patch i, Ai is area of patch i (rn 2 ), Fji is form-factor from patch j to 
patch i, N is number of discrete patches in the environ- ment. The equation <1> suggests that the energy 
on patch i is the result of gathering those from the environment. In this standard radiosity method, 
energy distribution irt the environ- ment may be simply obtained by solving the set of simultane- ous 
equations derived from equation <1>. However, estab-lishment of the coefficient matrix requires caleulating 
and saving form-factors between all patch pairs so that a compu- tation and storage expense of O (N z) 
is required. The method of progressive refinement radiosity has over-come the shortcoming above. The 
solution proceeds in a series of refinement steps by shooting radiosities from a shooting patch with 
greatest energy at each step. It is efficient since only one hemi-cube on the shooting patch need to 
be established at each iterative step, so that the time and space trade-off is only O (N). When the progressive 
refinement radiosity method[10] was proposed in 1988, it was constrained to diffuse environment. In 1989, 
an extended two-pass method for non-diffuse environment, capable of being adapted into a progressive 
pro- cess, was provided by Sillion and Puech[18]. In their method, the extended form-factors accounting 
for specular reflections are determined in terms of ray tracing. We have designed a different two-pass 
method[7] into which the texture generation is incorporated. The method and the related derivation are 
briefly introduced here to give a view of radiosity solution environment with which the texture generation 
is involved. Within a non-diffuse environment, surfaces are no longer perfectly diffuse reflectors and 
emitters, therefore, all interreflections of light between diffuse and non-diffuse sur-faces should be 
taken into consideration. For a non-diffuse surface, the bidirectional reflectance function is approximated 
as a sum of a diffuse portion Pa and a specular portion p, [17][20]: p"(0o~. 0i,) = k, p, (0o,~. Oi, 
) + ka Pa where k,, kd are specular and diffuse reflectance of the sur- face respectively, ks + ka -< 
1. In order to facilitate the incorporation of specular reflectance into the process of progressive refinement 
radios- ity in our method, the irradiation(H), a counterpart of radiation(B), is defined and utilized. 
For instance, the irradi- ation H.i i is defined as the irradiative amount ineideent on patch i due to 
the radiation from patch j. Thus, the radiosity equation in non-d use environments can be reformulated 
as N Bi = Ei + k,~.p~irc~Hji <2> j=l For a non-diffuse patch j, Hj~ consists of a diffuse term, H~, and 
a specular term, H]~., reflected onto patch i via patch j, or:  Hi, + H/, here H~ = AiBiF).IA i <3> 
N H~ = ]~AjH~jF, jik, ilA i <4> k=l where P, Q are the set of hemi-cube pixels covered by projection 
of patch k, i onto the hemi-cube, and AFp and AFq are delta form-factors related to pixel p and q respectively. 
Given k in <4>, H~ is increased by AjK#r~ ~AFq ~p,j(0q, 0v) HkJAFe Ai qe~2 pep FJ k Denote Hp = HkiAF~" 
, is the delta irradiation related to ej, pixel p. Since the non-diffuse patch j satisfies the "phong- 
like" bidirectional reflectance[13][17][20], the specular reflective energy leaving patch j through herni-cube 
pixel q is approximated by the weighted summation of energy which reaches the patch j through the area 
P (q) on the hemi-cube ( Fig. 1 ). Therefore, Aik, jn ZAFq Z p,(0q, 0p)Hp <6> H~ = Ai q~Q p~p(q) p,(0q, 
%) is employed as a weighted factor and is presented by an array of weights during implementation. Z 
q / I/ /. / / / ,I   (/ ,; i /, / \ _\ / / \. J / where Fkj i represents the fraction of energy shooting 
out from patch k to patch j and finally landing on patch i via specular reflection of patch j [17]: 1 
t t "O O "c°s0kc°s0~ eosOiceose~ F,:~ = --llP,J~ F~k &#38;a~ ~ o~. ,.) ~ r..Z~, dA~ dAk Using the hemi-cube 
over patch j, Fkji is evaluated by F,j, = --( Z p,J ) <5> F~ pep qe~ Fig. 1 Relationship between Outgoing 
and Incoming Energy Distribution  Based on the linear equations <2><3><6>, by also equally assigning 
non-diffuse patches the shooting candidacy, a two- pass progressive solution for non-diffuse environments 
is established, with a progressive preprocess iteratively refining the distribution of radiosities including 
specular reflections, followed by a postprocess of ray tracing for adding view-dependent effects such 
as highlight and mirrors. The solution of the first pass proceeds as follows: Do until convergence Select 
patch with greatest unshot energy as shooting patch; Compute form-factors from shooting patch to all 
other elements by hemi-eube algorithm; If shooting patch is non-diffuse, compute delta irradia- tions; 
Based on form-factors and delta irradiations, add con- tribution of the shooting patch to radiosity of 
all ele- ments and irradiation of none-diffuse elements. Instead of directly using the specular form-factors 
or extended form-factors like in methods in [16][17][18][21], in our method, when a selected shooting 
patch is non-diffuse, apart from calculating the standard form-factors by the newly constructed hemi-cube, 
delta irradiations are evaluated from the increment of irradiation which has been recorded in a queue 
from previous calculations. The delta irradiations are then utilized for calculating the specular portion 
of the shoot- ing to other patches. When the number of non-diffuse patches is relatively small compared 
to the number of diffuse patches, and the technique of subdivision[9][10] is employed, the storage cost 
of irradiation queues is low. The method above is based on hemi-cube algorithm, so it is readily implemented 
in terms of hardware Z-buffer. In con- trast, the method of ray tracing is now hardly implemented by 
hardware, particularly when a complex reflectance func- tion and an advanced ray tracing algorithm such 
as dislxi-buted ray tracing are utilized. Therefore, our method, with the hemi-cube algorithm assisted 
by hardware on the workstation such as SGI IRIS 4D/20, is more efficient than the methods like that described 
in [18]. 2.2 Perturbed Radloslty As shown in Fig. 2, the plane PL (i, ~') is through the center Oi of 
the patch i and its normal vector is the per- turbed normal ~'. Because the value of the perturbation 
function F(u,v) upon the patch i is small, we can assume that the solid angle dc0ii is not affected by 
the perturbation. The Radiant flux ~ji is shooting out from patch j to patch i within the solid angle 
df.oji. Tile area on the plane PL (i, ~') which is subtended by the solid angle dooji forms a new patch 
i', referred to as perturbed patch i', or P-patch i'. Note that P-patch i" and its area Ai' is affected 
by the per- turbed normal vector ~'. The form-factors between patch i and j have a reciprocity relationship[8]: 
AiFij = AjF]i <7> 128 where Ai is the area of patch i and Aj is the area of patch j; Fq is the form-factor 
from patch i to patch j; Fji is the form-factor from patch j to patch i. Fig. 2 Assumptive Perturbed 
Patch Define the form-factor from P-patch i" to patch j , Fij, a function of 2~', as perturbed form-factor. 
Since the solid angle d¢oji is constant, the form-factor from patch j to P-patch i" is equal to Fjl . 
So ai'Fij = A j F jl <8> From <7> <8>, we have A i' Fij Ai Fij The irradiance U)-(~') of P-patch i' 
from patch j is: Hi; = +~i +j, F,j = H...Fi;.. <9> A," -"~" ~q " Fii Similar to equation <2>, the diffuse 
radiosity Bi'(~') of P- patch i' is N Bi'= Ei + kipinZHjl j=l N F,j. =El + ki pix~Hji <10> j=l Fij It 
is clear from <10> that, to obtain the perturbed radiosity (B[) of patch i, we have to know, for each 
patch j, the irra- diation Hjl, and the form-factors Fii, Fq. In other words, the perturbed radiosity 
on one patch is gathered from all other patches in the environment. Therefore, the task of perturbed 
radiosity evaluation has to be taken by a pestprocess while the formula <10> is utilized. Latter on in 
the paper, we will derive another method to allow the evaluation of perturbed radiosity being performed 
at each iterative step in the process of progressive refinement solution with a shooting way. Evaluation 
of Hji has been described in Section 2.1. We now describe how to calculate t_he perturbed form-factors 
Fi)-. 2.3 Evaluation of Perturbed Form-Factor Because the perturbation is small in comparison with the 
size of perturbed patch, it is reasonable to suppose that the index of visible patch preserved in pixels 
on imaginary hemi-cube HM(~.) of patch i is not affected by perturbation. In another word, the hemi-cube 
of P-patch i' is the same as HM (I~i ). Note that the portion of HM(I~) behind the P-patch i" should 
be discarded when calculating perturbed diffuse form-factor. So the perturbed hemi-cube HM (l~i') is 
the fxac-tion of HM(I~i) excluding the shadowed part (Fig. 3). / // /% / / // / ~/ / A I /11 "\ / / I/ 
/I/ , A / ¥ /I/A t V / 1 J/ AI, Fig. 3 Perturbed Hemi-cube The form-factor between patches i and j is 
[8]: Fij = ~j. cos0i~r 2cOs0jHIDijdAjdA i <11> 3 By using the hemi-eube algorithm, Fq is evaluated from 
the sum of delta form-factors: FO = y. AF n pEM where AF n is the delta form-factor associated with pixel 
P on hemi-eube HM (1~); M is the set of hemi-cube pixels covered by projection of patch j on hemi-cube 
HM (h~.); cos0p den  AFn= /'C - de% / ~ <12> where On is the angle between the normal vector ~ and 
the direction vector ffp from the center of the patch i to the center of pixel P ; de% is the solid angle 
subtended by pixel p, and it is independent of normal vector/~. Similarly, the perturbed form-factor 
can be evaluated by perturbed hemi-cube HM (~.') : F,.) =-!-E ;''~ d°°n <13> where M' is the set of 
plxels covered by projection of patch j on perturbed hemi-cube HM (1~'). Delta perturbed form-factor 
is : ~''R=~ de% /~ <14> Given/~', to calculate Fp for every pixel p on perturbed henri-cube according 
to <14>, a dot product including three multiplications and two additions, plus another multiplication 
is required. The computation cost is therefore considerable. ff the property of scan line coherence is 
utilized, the dot pro- duct will be reduced to an addition calculation. It still requires an O(n) multiplication 
and art O(n+p) addition, where n is the number of pixels on the hemi-cube HM (h~.) and p, greater than 
0.5n, is the number of pixels on the per- turbed hemi-cube HM(I~.'). Because n is often very large, the 
latter method is still inefficient. In the following, we pro- pose an efficient method based on an idea 
similar to coordi- nate division, to decrease a large amount of computation. Note that I~' " R'p = ~_~ 
[(Rn'Ii)(Ik'?7")] <15> k=x,y ~ where /:=[100l, ~=[010l, /~=[0011. Denote wk = I~'1 ' k=x,y,z <16> 
and define the delta form-factors in three directions as: do, AF~ = ii~n I n / ~ , k=x ,y ,z <17> We 
obtain the delta perturbed form-factor AFp" = w~ AFn~ + w, AF~ + w~ AFpz <18> which shows that in each 
item only wk (k=x,y,z) but AFpk (k=x,y,z) depends on the normal vector N'. Thus, the per- turbed form-factor 
 F,/ = E AF." p~M' p~M" pcM' pEM' = wx &#38;/ + w, + w, P,#" <19> By traversing the HM(~i), we obtain 
Fq~, Fib and Fq:, the global summations of the delta form-factors in three directions respectively. Fq,. 
Fi~ and Fig, are calculated only once because they are equivalent for all the possible per- turbed normal 
vectors. For a given perturbed normal vector if', the corresponding wx, w~ and w: are calculated from 
the equation <16>. As shown in Fig. 3, the shadowed area is not bigger than the area of perturbed henri-cube 
HM (1~'), there-fore, to calculate Fi~, F~ and Fi~, we only need calculate the three abandoned summations 
of delta form-factors by traversing the shadowed area, and substract these abandoned summations from 
the corresponding global summations Fq~, Fie and Fij, respectively. Finally, the perturbed form-factor 
Fi) can be evaluated by <19>. For non-perturbed patch, ~" = ff = [0,0,1] and w~ = wy = O, wz = 1, Fij 
is only related to AFt=: Fig = ~,~'p,. pqM Hg. 4a to 4f show a test example, produced by progressive 
radiosity with 60 iterations. The resolution of henri-cube is 100 by 100. Fig. 4a took 92 seconds, without 
texture genera- tion, and Fig. 4b. took 27 seconds of extra time for texture generation (independent 
of iteration), with nine extra hemi- cubes built over the perturbed elements on the wrinkled sur-face 
of the green box on the table, and 16 directions (men-tioned latter) sampled for the evaluation of perturbed 
form- factors by means of perturbed hemi-cube algorithm. Obviously, the method above has been derived 
from the view point of radiosity gathering, and can be readily applied in the context of various radiosities 
such as standard radios- ity[9], two-pass radiosity[20] or Shao's method[16], where establishment of 
additional hemi-cube for perturbed patches is unnecessary, therefore, the cost of texturing operation 
is low. However, if the mentioned technique is to be applied to the progressive radiosity method, additional 
form-factors should be particularly calculated. Therefore, when the texture gen-eration is to be performed 
at each iterative step, the cost will become quite expensive unless the amount of perturbed patches is 
small. This fact prohibits the technique above from being effectively utilized in a complex environment 
with progressive radiosity approach. Of course, the technique could be used in a postprocess behind the 
termination of refinement process, but in which case the advantage of pro- gressive radiosity would have 
not been utilized for texturing purpose. In that follows, we suggest an approximate bumpy texture method 
based on the idea of radiosity shooting. doq O~- dj / X l~) di di " Fig. 5 Rotated Element As shown 
in Fig. 5, by rotating the differential element di onto the plane PL (di, ~'), a new differential element 
di" is obtained, with the area dA['=dAt. The form-factor from dAi to d&#38;" is F,~)~. = cosOaim "2c°s0'~i 
dAi So, Fd~'-ai = coseji cos0~ cos0~ dAi cosO~ ~r 2 Plj--cose -cose~ Therefore, 1 r r cos0al <20> 
 Similaxly, we can get 1 ~, coseC, AjFfi" = AiFij" According to the assumption of P-patch i" in previous 
section, because the distance between the two patches is usually large compared to their sizes, Fi~ ~ 
is a good approximation to Fi) (the form factor from P-patch i" to shooting patch j). So, equation <9> 
can be reformulated as -n ..Fi)'" = Hi, Fj; <21> HJ~-J'Fq F:i From <10><21>, we have Bi'= E~ + k~" Pl 
rc~H~i <22> This equation has the desirable characteristics for progres- sive radiosity design. At each 
refinement step, the shooting patch j selected may shoot its radiosity to other patches including perturbed 
patches, say i in <22>. F~" and F/i are evaluated at same time by the hemi-cube of shooting patch j. 
By our intention of making use of hardware-assisted hemi-cube technique for non-diffuse environment, 
F~" is evaluated nnmerieally as:   F~'= Xtw, a~(i) qaQ where Q is the set of hemi-cube pixels covered 
by the projection of patch i ; /~Fq is the standard form-factor related to pixel q. ¢Xq (i) is coseC(q) 
if coseC(q) > 0, or 0 otherwise; cosOl (q) here 0;(q), O~(q) are the angles between the normal /~', /~ 
respectively and the direction connecting the center of patch j with the center of pixel q. For the progressive 
radiosity method described in Section 2.1, we have implemented both <10> as a postprocess and <22> as 
refinement processing for bump texture generation. Fig. 4c shows the result of texture generation embodied 
in the progressive radiosity solution using the latter method, per- forming the texture operation at 
each iterative shooting step. The visual difference between Fig. 4b and Fig. 4c is hardly perceptible. 
It took 113 seconds with 60 iterative steps. Apparently, the latter method is particularly suitable for 
tex- ture generation in a radiosity refinement procedure. It allows users to have interactive control 
of texture generation in the go-between steps. However, when the interactive generation of texture is 
unnecessary, the former method by texture post- process is preferable to the latter one, because it takes 
a con- stant time to produce texture at the end. 2.4 Sampling the Perturbed Normal Vector Space and Rendering 
All possible perturbed normal vectors form a hemi-sphere space. In order to reduce the calculation and 
storage cost, we discretize the herni-sphere space of perturbed directions. In every sampled direction 
A~5', the perturbed radiosity B (AT,',/Yv) at a vertex/Y, can be determined by the algorithm previously 
mentioned, and stored in a perturbed radiosity map indexed by /~s'- It is often sufficient to sample 
/~ in 16 directions corresponding to E, NE, N, NW, W, SW, S and SE for sun angle 0 ° and 45 °. The more 
the sample directions, the more accurate the bumpy texture is. For all the colour figures shown in the 
paper, 16 directions were utilized. While rendering the image, if the perturbed normal ~' at a point 
is equal to an index/~,' of the perturbed radiosity map, its perturbed radiosity can be evaluated by 
a bilinear interpo- lation from the radiosities B(I~/, lay) at patch vertices. Oth- erwise, an interpolation 
of the perturbed radiosities B (if', Pv) from the adjacent sampled perturbed directions has to be per- 
formed at each vertex before the bilinear interpolation is car- fled out. Such shading scheme is view-independent 
for diffuse environment. Besides, the perturbed radiosity map is independent of perturbation functions. 
We may see in the test example a different texture was produced in Fig. 4e using the same perturbed radiosity 
map as the one in Fig. 4c. An interesting result is shown in Fig. 4f, where the /~' came from a cylinder 
fnnetion and a cylinder patch was generated by our method combined with displacement map tech-nique[l 
1]. This fact indicates a potential application of radiosity in the process of interactive control of 
curve simula- tion during art early stage of shape design. For a non-diffuse textured surface, the specular 
component of illumination is determined bu ray tracing postprocess. Recently, Wallace et al.[21] and 
Baurn et al.[1] provided two new methods for evaluating form-factors that eleminate the aliasing of hemi-cube 
algorithm. The true surface normal of receiving element is used in their form-factor algorithms for diffuse 
environment. Therefore, it is possible for the per-turbed radiosity map proposed in the paper to be established 
using their methods for calculating perturbed form-factors. For example, in Wallace's methodology, the 
perturbed form- factor from a source 2 to a perturbed differencial area dA 1 ( Fig. 6 ) is: dFA '~,"--~1 
cosOlicosO2z 2 -dA l = dA 1 5, ~ri2 + A 2In where n is thenumber of sample points on source 2 is 1 if 
sample point is visible to vertex 1, 0 if occluded The perturbed radiosity is obtained : 1 " cos0~icos0~- 
Bi = piB2A2--~Si n s=l ~rt z + A z/n Above equation can be evaluated by ray tracing algorithm, and then 
the perturbed radiosity map at vertex 1 is esta-blished. However, the method by hemi-cube is advantageous 
in two aspects. Firstly, as already shown in the paper, the method for texture is able to be naturally 
incorporated into our radiosity solution for non-diffuse environment while the problem for the other 
methods in non-diffuse environment is yet to be solved. In fact, introduction of specular irradiation(H~) 
derived from herni-cube has made it possible to produce the texture accounting for specular reflection. 
Secondly, the hemi-cube algorithm is suitable for hardware implementation, and has high efficiency comparatively. 
 /__._Z aA ,vSaA; "0; (a) (b) Fig. 6 Geometry for a) Form-factor, b) Perturbed Form-factor in Wallace's 
Methodology 3. Further Discussion For different perturbation functions, the distribution of radiant light 
energy from perturbed patches is different. For- tunately, the difference is usually very slight and 
can be neglected. Therefore, it is reasonable to take the distribution of non-perturbed radiant energy 
of patches in an environment as an approximation of that of perturbed patches when calcu- lating the 
contribution of radiosity from a perturbed patch to the radiosity of other patches in the environment. 
When considering so-called self-shadowing[14], the bump cast of a part of a surface on nearby parts of 
the same sur-face, the "horizon mapping" technique is able to be improved by the newly introduced perturbed 
herni-cube. Unfortunately, the processing of self-shadowing will lead the cost of textur- ing computation 
to be increased by ninety percent or more. We notice that the effect of self-shadowing in an interreflectlon 
environment is often very weak, especially in the case of surface light sources. In order to save computa-tion 
and storage expense, the present algorithm has not taken the self-shadowing into account like most of 
the other bump mapping approaches[3] [5] [ 15]. Bumps may be illuminated by nearby parts of the surface 
itself due to perturbation. This phenomenon is referred to as self-illumination, in which case, perturbed 
form-factor Fi~ is bigger than zero. If we build a global cube[13] perturbed around patch i, the index 
of visible patches reserved in the most of the pixels center-symrnetrized with the pixels in the shadowed 
area ( Fig. 3 ) is i, the index of the perturbed patch itself, as the bumpy height is very small. Therefore, 
we can denote a value to the self-illuminated form-factor F~ 132 according to the size of the shadowed 
area. We get N ~F~j _< 1. The summation of perturbed diffuse form-factors j=l is still not bigger than 
one. This technique has been used for bump texturing in Figure 4d. Because perturbation is very small, 
the self-illumination may be neglected. 4. Results In Fig. 7a and b, a room has been rendered to show 
the results in a non-diffuse environment. A very bright small source is close to the nearly perfect mirror( 
ka = 0.07, k, = 0.93). The model contains 578 patches and 3327 elements including 229 perturbed elements 
and 194 non-diffuse elements. The image on the mirror and the fuzzy image on the sphere(kd = 0.25, ks 
= 0.75) were produced in the second pass of ray tracing based on the radiosity result from the first 
pass. The resolution of hemi-cube is 150 by 150. The chessboard-like pattern on the floor and the painting 
on the wall were generated by color texture mapping tech- nique[9]. The image in Fig. 7a was generated 
by 30 iterative steps. The texture on the right wall, produced using a random perturbation function looks 
graceful and the texture on the box is also perceptible due to the specular reflection. Fig. 7b was rendered 
with 250 iterative steps in 14'31" and the effect of specular reflection is more significant. The bump 
texture on the box surface has been improved apparently due to more perfect intelrreflection produced 
in comparison with Fig. 7a. In Fig. 8, there are some thiner objects. The scene contains 832 patches 
and 5776 dements, with 122 perturbed elements for the texture of the light blue curtain sampled at 16 
direc- tions, and 64 specular elements for the mirror. A finer resolu- tion hemi-eube, 170 by 170, was 
utilized. The figure was displayed after 200 solution steps in 12'52". Because the ini- tial patch mesh 
on the mirror is less fine than in Fig. 7, there is slight hemi-cube aliasing within the region of specular 
reflection on the right-side wall. We have also tested that, when images in Fig.7b and Fig.8 are produced 
without texture generation under the same con- ditions, their running time is 12'20" (Fig.7b) and 11'23" 
(Fig.8) respectively. So the net time for texture generation is 2'11" and 1'29", or about 15% and 12% 
of the total time respectively. The perturbed radiosity maps in Fig.7 and Fig.8 are calculated at each 
iterative step in the progressive refinement radiosity method. All figures were measured on SGI Personal 
IRIS 4D/20 workstation, with hardware-assisted implementation of hemi- cube algorithm. 5. Conclusion 
I IIII I In sum, a bump mapping technique, by the perturbed radiosity map has been proposed in radiosity 
solution for tex- ture generation in non-diffuse environment. Separate algo- rithms have been provided 
for evaluation of the perturbed form-factors to fit different radiosity methods. Consequently, the texture 
processing is taken either as a postprocess or as a refinement step, incorporated into the procedure 
of progres- sive radiosity solution. The shading scheme based on the perturbed radiosity map is view-independent, 
and the perturbed radiosity map is also independent of the texturing perturbation function adopted. The 
bump mapping technique has improved the visual real- ism of radiosity image and promoted the practical 
value of radiosity solution. Acknowledgements Thanks are given to Yun-Mei Dong and Kei-De Li for pro- 
viding Apollo-DN580 on which the software was developed during the first stage, and for providing printing 
facilities. Acknowledgements are also due to Kong-Shi Xu, You-La Zhang and Yu-Guo Wang for their support 
and various help during the working period. We are grateful to You-Dong Liang and Qun-Sheng Peng of Zhejiang 
University for their generous help in providing related theses for references long before their papers 
appeared at conferences. Thanks are also given to SIGGRAPH reviewers for their helpful comments. The 
work has been supported by the National Natural Sci- ence Foundation. References . Baum, D. R., Rushmeier, 
H. E. and Winget, J. M., Improving Radiosity Solutions through the Use of Analytically Determined Form-Factors, 
Computer Graphics, Vol 23(3), 1989, pp.325-334 . Bllnn, J. F. and Newell, M. E., Texture and Reflection 
in Computer Generated Images, Comm. ACM, Vol 19(10), 1976, pp.542-547 , Blinn, J. F., Simulation of Wrinkled 
Surfaces, puter Graphics, Vol 12(3), 1978, pp.286-292 Com- 4. Cabral, B., Max, N. and Springmeye R., 
Bidirectional Reflection Functions from Surface Bump Maps, Com-puter graphics, Vol 19(4), 1987, pp.273-281 
. Carey, R. J. and Greenberg, D. P., Texture for Realis- tic Image Synthesis, Computer &#38; Graphics, 
vol 9(2), 1985, pp.125-138 . Catmull, E., A Subdivision Algorithm for Computer Display of Curved Surfaces, 
Ph.d Dissertation, Univ. of Uta, Salt Lake City, 1974 7. Chert, H. and Wu, E. H., An Adapted Solution 
of Pro- gressive Radiosity and Ray Tracing Methods for Non- diffuse Environment, Proceedings of CGI'90, 
June 26-30, 1990 8. Cohen, M. F. and Greenberg, D. P., The Hemi-cube: A Radiosity Solution for Complex 
Environment, Com-puter Graphics, Vol 19(3), 1985, pp.31-40 9. Cohen, M. F., Greenberg, D. P., lmmel, 
D. S. and Brack, P. J., An Efficient Radiosity Approach for Realistic Image Synthesis, IEEE CG&#38;A, 
Vol 6(2), 1986, pp.26-35 10. Cohen, M. F., Chen, S. E., Wallace, J. K. and Green- berg, D. P., A Progressive 
Refinement Approach to Fast Radiosity Image Generation, Computer Graph- ics, Vol 22(4), 1988, pp.75-84 
 11. Cook, R. L., Shade Trees, Computer Graphics, Vol 18(3), 1984, pp.223-231 12. Goral, C. M., Torrance, 
K. E. and Greenberg, D. P.,  Modelling the Interaction of Light between Diffuse Surfaces, Computer Graphics, 
Vol 18(3), 1984, pp.213-222 13. Immel, D. S., Cohen, M. F. and Greenberg, D. P., A Radiosity Method for 
Non-diffuse Environment, Com-puter Graphics, Vol 20(4), 1986, 133-142 14. Max, N. L., Shadows for Bump-mapped 
Surfaces, Advanced Computer Graphics, Kunli T.L. Ed. Springer Verlag, Tokyo, 1986, pp.145-156 15. Per[in, 
K., An linage Synthesizer, Computer Graph- ics, Vol 19(3), 1985, pp.287-296 16. Shao, M. Z., Peng, Q. 
S. and Liang, Y. D., A New  Radiosity Approach by Procedural Refinements for Realistic Image Synthesis, 
Computer Graphics, Vol 22(4), 1988, pp.93-101 17. Shao, P. P., Peng, Q. S. and Liang, Y. D., Form-factors 
for General Environments, Proc. Eurograph- its'88, Nice, 1988, pp.499-510 18. SiUion, F. and Puech, C., 
A General Two-pass Method Integrating Specular and Diffuse Reflection, Computer Graphics, Vol 23(3), 
1989, pp.335-344 19. Sparrow, E. M. and Cess, R. D., Radiation Heat Transfer, McGraw-Hill, New York, 
1978  20. Wallace, J. R., Cohen, M. F. and Greenberg, D. P., A  Two-pass Solution to the Rendering 
Equation: A Syn- thesis of Ray Tracing and Radiosity Methods, Com-puter Graphics, Vol 21(4), 1987, pp.311-320 
21. Wallace, J. R., Elmquist, K. A. and Haines, E. A., A Ray Tracing Algorithm for Progressive Radiosity, 
Computer Graphics, Vol 23(3), 1989, pp.315-324 22. Ward, G. J., Rubinstein, F. M. and Clear, R. D., A 
Ray Tracing Solution for Diffuse lnterreflection,   @ SIGGRAPH '90, Dallas, August 6-10, 1990 II II 
II I IIIIIII IIIII Computer Graphics, Vol 22(4), 1988, pp.85-92 23. Whitted, T., An Improved Illumination 
Model for Shaded Display, Comm. ACM, Vol 23(6), 1980, pp.343-349 (a) (b) (c) (d) (e) (0 Egure4 (a) 
Figure 8 (b) Figure 7  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97894</article_id>
		<sort_key>135</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Incremental radiosity: an extension of progressive radiosity to an interactive image synthesis system]]></title>
		<page_from>135</page_from>
		<page_to>144</page_to>
		<doi_number>10.1145/97879.97894</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97894</url>
		<abstract>
			<par><![CDATA[Traditional radiosity methods can compute the illumination for a scene independent of the view position. However, if any part of the scene geometry is changed, the radiosity process will need to be repeated from scratch. Since the radiosity methods are generally expensive computationally, the traditional methods do not lend themselves to interactive uses where the geometry is constantly changing. This paper presents a new radiosity algorithm to incrementally render scenes with changing geometry and surface attributes. In other words, the question to be asked is "<i>What is the minimum recomputation I need to do if I turn off a light source, change the color of a surface, add or move an object?</i>" Because a modeling change generally exhibits some coherence and affects only parts of an image, the proposed method may drastically reduce the rendering time and therefore allow interactive manipulation. In addition, since the method is conducted incrementally and view-independently, the rendering process can start before the modeling process is completed. The traditional paradigm of <i>modeling-then-rendering</i> is changed to <i>rendering-while-modeling</i>. This approach not only gives the user better visual feedback but also effectively utilizes CPU time otherwise wasted in the modeling process.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14048866</person_id>
				<author_profile_id><![CDATA[81451598765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shenchang]]></first_name>
				<middle_name><![CDATA[Eric]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Shenchang Eric Chen, John R. Wallace, Donald. P. Greenberg, "A Progressive Refinement Approach to Fast Radiosity Image Generation," Computer Graphics (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 1988, pp. 75-84.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth. E. Torrance, Donald. P. Greenberg, Bennett Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics (SIGGRAPH '84 Proceedings), Vol.18, No. 3, July 1984, pp.213-222.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald. P. Greenberg, "The Hemi- Cube: A Radiosity Solution for Complex Environment," Computer Graphics (SIGGRAPH '85 Proceedings), Vol.19, No.3, July 1985, pp.31-40.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald. P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE CG&amp;A, Vol. 6, No. 2, January 1986, pp.26-35.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gouraud, Henri, "Continuous Shading of Curved Surfaces," IEEE Transactions on Computers, Vol. 20, No. 6, June 1971, pp.623-628.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Phong, Bui-Tuong, "Illumination for Computer Generated Pictures," Communications of the ACM, Vol. 18, No. 6, June 1975, pp. 311-317.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Baum, Daniel R., John R. Wallace, Michael. F. Cohen, Donald. P. Greenberg, "The Back-Buffer: An Extension of the Radiosity Method to Dynamic Environments," The Visual Computer, Vol. 2, No. 5, 1986, pp, 298-306.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74342</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Buckalew C., Donald Fussell, "Illumination Networks: Fast Realistic Rendering with General Reflectance Functions," Computer Graphics (SIGGRAPH "89 Proceedings), Vol. 23, No. 3, July 1989, pp. 89-98.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert, John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp,. Washington DC., 1981.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91417</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Claude Puech, Sillion Franqois, Christophe Vedel, "Improving interaction with Radiosity-based Lighting Simulation Programs," Computer Graphics (Special Issue on 1990 Symposium on Interactive 3D Graphics), Vol.24, No. 2, March 1990, pp.51-57.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Kells A. Elmquist, Eric A. Haines, "A Ray Tracing Algorithm For Progressive Radiosity," Computer Graphics (SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp.315-324.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Michael F. Cohen and Donald P. Greenberg, "A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray-Tracing and Radiosity Methods," Computer Graphics (SIGGRAPH '87 Proceedings), Vol. 21, No. 4, July 1987, pp. 311-320.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Chen, Shenchang Eric, A Progressive Radiosity Method and its Implementation in a Distributed Processing Environment, Master's thesis, Program of Computer Graphics, Comell University, Ithaca, NY, January 1989.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91420</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Baum, Daniel R., James M. Winget, "Real Time Radiosity through Parallel Processing and Hardware Acceleration," Computer Graphics (Special Issue on 1990 Symposium on Interactive 3D Graphics), Vol.24, No. 2, March 1990, pp.67-75.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Rushmeier, Holly E., Extending the Radiosity Method to Transmitting and Specularly Reflecting Surfaces, Master's thesis, Cornell University, Ithaca, NY, 1986.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sillion, Francois, Claude Puech, "A General Two-Pass Method Integrating Specular and Diffuse Reflection, " Computer Graphics (SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp.335-344.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Incremental Radiosity: An Extension of Progressive 
Radiosity to an Interactive Image Synthesis System Shenchang Eric Chen Advanced Technology Group Apple 
Computer, Inc. ABSTRACT Traditional radiosity methods can compute the illumination for a scene independent 
of the view position. However, if any part of the scene geometry is changed, the radiosity process will 
need to be repeated from scratch. Since the radiosity methods are generally expensive computationally, 
the traditional methods do not lend themselves to interactive uses where the geometry is constantly changing. 
This paper presents a new radiosity algorithm to incrementally render scenes with changing geometry and 
surface attributes, In other words, the question to be asked is "What is the minimum recomputation I 
need to do if l turn off a light source, change the color of a su~ace, add or move an object?" Because 
a modeling change generally exhibits some coherence and affects only parts of an image, the proposed 
method may drastically reduce the rendering time and therefore allow interactive manipulation. In addition, 
since the method is conducted incrementally and view-independently, the render- ing process can start 
before the modeling process is complet- ed. The traditional paradigm of modeling-then-rendering is changed 
to rendering-while-modeling. This approach not only gives the user better visual feedback but also effectively 
utilizes CPU time otherwise wasted in the modeling process. CR Categories and Subject Descriptors: 1.3.3 
[Computer Graphics]: Picture/Image Generation - Display Algorithms. 1.3.7 [ Computer Graphics]: Three-Dimen-sional 
Graphics and Realism General Terms: Algorithms Additional Key Words and Phrases: Radiosity, Incre-mental 
Rendering, Incremental Radiosity, Global Illumination, Lighting Design, Progressive Radiosity. * Author's 
address: Apple Computer Inc., MS-60W, 20705 Val- ley Green Dr. Cupertino, CA 95014. E-mail: chense@apple.com 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.  INTRODUCTION 
Recent introduction of the progressive radiosity method has opened the door for using the technique in 
an interactive image synthesis system [ 1]. This new method applied the approach of rendering by progressive 
refinement to speed up the radiosity computation. In this approach, the image quality is continuously 
improved over time and intermediate results are displayed throughout the rendering process. However, 
as with the other radiosity methods, [ 2], [ 3], [ 4], this technique requires the rendered scene to 
be static. Whenever there is a change of the scene geometry, the entire radiosity process needs to be 
repeated from scratch. Although the progressive method has greatly reduced the rendering time, it is 
still too expensive to be used in an interactive environment where the scene descriptions are constantly 
changing. Our primary goal is to use the radiosity method in an environment where we can interactively 
modify the viewing positions, geometry and surface attributes. Because the radios- ity method is view-independent, 
it allows view positions to be changed freely once the radiosity computation is completed. In addition, 
the radiosity method can accurately simulate the diffuse interreflection between surfaces. In many applications 
such as lighting, or interior space design, this degree of realism is necessary and could not be obtained 
from other commonly used fast rendering techniques like Gouraud [ 5] or Phong shading [ 6]. The method 
introduced in this paper per- forms the radiosity computations incrementally based on the scene changes. 
This method is in the spirit of progressive refinement, i,e. image quality is constantly improved with 
time. When a scene change is made, the proposed method will attempt to update only the areas affected 
by the change directly. The change will later be propagated throughout the whole scene to account for 
diffuse interreflection. Since the change tends to be local and affects only a small portion of the image, 
the incremental method may drastically reduce the rendering time and therefore allow interactive manipulation. 
This approach also bridges the gap between modeling and rendering, which are traditionally regarded as 
two separate processes performed sequentially. Because of the view-inde- pendence and incremental nature 
of the proposed method, the rendering process can start before modeling is finished. This approach offers 
several advantages over the conventional modeling-then-rendering approach. It provides a great degree 
of realism during modeling and reduces the turnaround time. It also effectively utilizes the wasted CPU 
cycles in a modeling session. Early work in radiosity has shown that surface reflectance can be altered 
independently without affecting form-factors, which &#38;#169;!990 ACM-O-89791-344-2/90/008/0135 $00.75 
135 G SIGGRAPH '90, Dallas, August 6-10, 1990 are purely geometrical relationships between surface patches 
[ 3]. Once the form-factors are pre-computed and stored, radiosity images can be generated quickly with 
different color variations. However, the cost of storing the form-factors is O(n2), where n is the number 
of surface patches. Even though the form-factors are normally quite sparse, the overwhelming storage 
cost still makes it impractical for rendering complex scenes. This method also requires the geometry 
to be static and needs very long preprocessing time. A method presented by Baum et al. [ 7] attempts 
to lift the restriction of static geometry imposed on the radiosity methods. This method is primarily 
directed toward computing an animation sequence and requires the path of object movement to be known 
in advance. Therefore, it is not suitable for our purpose. A ray-tracing method presented in [ 8] shows 
the possibilities of updating the geometry and color changes incrementally if all the illumination links 
connecting the surfaces are pre-computed and stored. These approaches face the same storage and preprocessing 
problems as the previous one. Our algorithm is an extension of the progressive radiosity method. Therefore, 
it has the same advantages as the progressive method in that it only requires O(n) storage cost and does 
not need long preprocessing time. The new algorithm allows both the surface attributes and scene geometry 
to be changed during the rendering process. As with progressive radiosity, this method currently is limited 
to rendering diffuse surfaces only. The following section presents a brief review of progressive radiosity, 
since it is the basis of the proposed method. This is followed by the introduction of the incremental 
radiosity method and its implementation. Results are also shown to illustrate the usefulness of the new 
method. PROGRESSIVE RADIOSITY The progressive radiosity algorithm is a reformulation of the original 
radiosity method [ 3]. The original method proceeds by evaluating the following equation on some discrete 
surface areas or patches iteratively until the differences of radiosities between iterations are within 
some given tolerance. LP,F~.] (1) where Bi = the radiosity of patch i (energy/unit area/unit time), 
E i = the emission of patch i (energy/unit area/unit time), Pi = the reflectance of patch i, and /~j 
= the form-factor from patch i to patchj ( fraction of energy arrives at patch j from patch i). The above 
equation effectively computes the radiosity of a patch by gathering the energy from some other patches. 
The progressive method reverses the process by shooting the energy out from a patch. In each solution 
cycle, a patch that potentially contributes the most energy to the whole scene is chosen as the shooting 
patch and its unshot radiosity (the radiosity that has not been distributed previously) is distributed 
to every other patch. This process updates the radiosity of every patch in the scene instead of just 
one patch as in the gathering case. In each shooting, the radiosity of every patch is updated by:  B'l"° 
r ,l °" . . Lp.F.iJ (2) where B 7 is the unshot radiosity of patch i. The form-factors in Equation (2) 
are obtained from the reciprocity relationship [ 9]: = F,j A,/4 (3) where A i is the surface area of 
patch i. Since only the form-factors from the shooting patches are needed, the form-factors can be computed 
on-the-fly after each shooting patch is found. Fig. I shows one solution cycle of the progressive method. 
The cycle is iterated continuously until the solution converges to some threshold. Initialization Converged? 
 Fig. 1 One solution cycle of the progressive radiosity method. The view position can be changed freely 
during the solution. INCREMENTAL RADIOSITY The incremental radiosity method is an extension of the progressive 
radiosity algorithm. The proposed algorithm proceeds with the normal progressive solution. In the beginning 
of each solution cycle, though, the new method will monitor any requests from the user for scene changes. 
When a change is requested, the solution will be interrupted temporarily to process the request and resume 
when the processing is completed. The allowable changes currently include changing surface attributes, 
such as reflectance and emission, and scene geometry. Fig. 2 shows a solution c,,~Te of the incremental 
method. The proposed extensions to the progressive method include algorithms to incrementally adjust 
the radiosity values after an attribute or a geometry change. We also introduce a method to buffer the 
geometry changes in a queue so that multiple changes can be made in succession, without waiting for the 
in- cremental method to converge. Methods to provide fast feed- back during an interactive seession are 
also discussed.  ~ Computer Graphics, Volume 24, Number 4, August 1990 Initialization Converged? Scene 
c h a n g ~ Fig. 2 One solution cycle of the incremental radiosity method. In addition to changing view 
positions, the method allows scene descriptions to be modified during the solution. Changing Surface 
Attributes When the attributes of a patch are changed, the patch's incremental radiosity (the difference 
in radiosity as a result of the attribute change) is computed first. The incremental radiosity is then 
distributed in the same manner as distributing the unshot radiosity in the progressive refinement process. 
The changes will be propagated throughout the whole scene and will eventually result in a correct solution. 
For example, turning a light source off will result in shooting negative light from the light source. 
The negative light will eventually propagate to the whole scene to subtract all the radiosity emitted 
from the light source. This idea is similar to those mentioned by Buckalew et al. [ 8] and Puech et al. 
[ 10]. The incremental radiosity is computed by subtracting the old radiosity (before the attribute change) 
from the new radiosity (after the change). The old radiosity of a patch is given by: B n i = Ei +PiZBj~j 
i =~ (4) Let E[ and p~ be the new emission and reflectance of the patch i. The new radiosity of patch 
i is then: n B'= E; + pi'~ Bit~j i=~ (5) The incremental radiosity of patch i, AB i , is obtained from 
(5) - (4): ~B, = E;- E i + (p;- pi) Z n Bj Fi] j=l (6) From (4), this becomes (p~'-p~)(B~ -E) AB~ = 
E;- Ei + Pi (7) Note that the value of AB~ is undefined if Pi is zero. Therefore, the reflectance of 
a patch cannot be zero if it is to be changed to non-zero. However, this is not really a problem since 
real materials rarely have zero reflectance (i.e. most black surfaces still reflect a small amount of 
light). The above step can be easily added to the original progressive radiosity method. Once the changing 
patch's incremental radiosity is computed, it is added to the radiosity and unshot radiosity of the patch. 
The normal solution method can resume afterward. The only change that needs to be made to the original 
method is to perform the searching for the shooting patch based on the absolute value of the unshot radiosity 
in order to shoot out negative light.  Changing Scene Geometry Unlike attribute changes, geometry changes 
will modify some of the form-factors. Therefore, all the patches that have radiated energy to the scene 
need to reshoot their radiosities based on the form-factor changes. When a geometry change is made, every 
patch that has radiated energy is visited. For each of the patches, we need to first remove its radiosity 
contribu- tion to the scene based on the old geometry, and then reshoot its total radiosity based on 
the new geometry. After all of the patches are processed, the normal iterative solution cycle can resume 
to further propagate the radiosity and eventually yield a correct resultk Once the normal solution cycle 
is resumed, only the new geometry is needed since all of the patches that have radiated energy to the 
old geometry have redistributed their radiosities. The above process can be illustrated by a simple example 
as shown in Fig. 3. Initially, a plane is lit by a light source. When a sphere is added to the scene, 
the light is turned off first, the sphere is added, then the light is turned back on. The net effect 
is that the radiosities in the shadow area are subtracted from the plane and added to the sphere. As 
a result, energy is con- served. Because the plane's radiosity is modified, it needs to reshoot its radiosity 
too. The whole process iterates until con- vergence. 0   /:: !,ii: (a) initial (b) turn light off 
(c) add sphere (d) turn light on  Fig. 3 The process of adding a new object to a rendered scene. For 
every patch j, the first step is to remove the contribution from a patch i by : B; = Bj-pjB:F, (8) 1. 
In fact, the solution can resume immediately without finishing the processing first. This will be discussed 
in the "Geometry Queue" section.  ~ Computer Graphics, Volume 24, Number 4, August 1990 operations are 
capable of describing any geometry changes. For instance, moving a patch is described by deleting the 
patch from the old location and adding it to the new location. Whenever there is a request for a geometry 
change, the change is added to the queue and then the normal solution cycle may resume. Each patch has 
a queue counter which indicates the number of geometry changes in the queue that have been accounted 
for by the patch. For instance, a queue counter of m means the first m changes in the queue have been 
processed by its patch. The queue counters are initialized to zero and are incremented when changes in 
the queue are processed. When a patch is selected as the shooting patch, it can determine the patches 
that it has seen before (i.e., the old scene) from its queue counter and the queue. It also can determine 
the current scene from the entire content of the queue. A set of incremental form-factors from the patch 
to the other patches then can be computed from the two scenes as discussed before. Fig. 6 illustrates 
the above process. Note that when a patch is deleted, it still exists in the solution processing but 
is merely invisible. The patch can be removed from the solution only after it has been processed by all 
the patches. The queue also can be compressed at this moment to remove all the entries re- lated to the 
patch. L2% ~L1 % (a) initial (b) delete sphere (+L1, +L2, +P, +S) (+L1, +L2, +P, +S, -S) LI=4, L2=3, 
P=0, S=0 Ll=4, L2=3, P=0, S=0  % 6' % (9 / \ / \ (c) shoot from light 1 (d) shoot from light 2 (+L1, 
+L2, +P, +S, -S) (+L1, +L2, +P, +S, -S) Ll=5, L2=3, P=0, S=0 Ll=5, L2=5, P=0, S=0 Fig. 6 Initially, 
two lights (LI, L2), a plan (P) and a sphere (S) are added (+) to the scene. L1 has distributed its radi- 
osity to all of the objects and its queue counter is 4, which means all four changes in the queue have 
been accounted for. L2 has distributed its radiosity before S is added. Therefore, its queue counter 
is three. In (b), S is deleted (-) from the scene. In (c), L1 redistributes radiosity and its counter 
is set to 5. In (d), L2 is the shooting patch. Because the queue indicates S has been deleted, the process 
simply sets the counter to 5 and yields the correct results. Another advantage of buffering the geometry 
changes in the queue is that multiple changes in succession will not impose much extra computation since 
our algorithm only looks at the net change. In the above example, the sphere can be moved many times 
and only the first and the last locations matter in the computation. Searching for the Shooting Patch 
The main reason that the progressive radiosity algorithm converges quickly is that at every solution 
cycle, the shooting is always performed from a patch that potentially contributes the most energy to 
the scene. To perform the same task with the incremental method, we need an approximation to the contribution 
from each patch in order to identify the shooting patch. The total contribution to the scene in each 
shooting from patch i is given by: n Bi-t ...... = Z(B~pjFj; + B;pj~Ii) /=a (13) Following [ 1], we know 
that the form-factor from any patch j to patch i can be approximated as the fraction of the total area 
of the scene taken up by the area of patch i. Fj, = ACEj= , i (14) The incremental form-factor from any 
patchj to patch i, A/~i, is the difference between the new and the old form-factors. A quick estimate 
to the difference is given by the queue counter of patch i. If the counter equals the length of the queue 
(i.e., the new and old scenes are the same), there is no difference between the form-factors, and A/~i 
will be zero. Conversely, if the queue counter is zero, A/~i will equal Fj~. Therefore, A/~i can be approximated 
by: AFi,= (1 --~)Fj~ (15) where rr~ is the queue counter associated with patch i, cr is the length of 
the geometry queue, and 0 _< G i _< G. The queue counter does not necessarily provide a good approximation 
to the incremental form-factors because the changes might be invisible to the patch. It also does not 
take into account the sizes of the patches changed and their proximity to the shooting patch. Nevertheless, 
it provides a quick estimate without performing a visibility test. Note that the above estimate does 
not allow A/~i to become negative. This is desirable because we are only concerned with absolute values 
in the searching process. Substituting (14) and (15) into (13), we obtain: ,=lL Z~.,Ae G Zk=AkJ (16) 
This can be simplified to the following equation. Bit ..... ~[Bu-p(1--~)B~]Ai ET=IPj --E;=IA, (17) Since 
the summation term is constant and positive, it does not need to be evaluated in finding the shooting 
patch. The  O SIGGRAPH '90, Dallas, August 6-10, 1990 searching can be performed by evaluating Equation 
(18) below: (18) The patch that has the greatest fl~ is chosen as the shooting patch. The absolute signs 
in the equation are necessary to ensure finding the maximum difference. Note that when Gi equals G, which 
means A/~. i is zero, this equation yields the same result as the progressive method. Since the user 
may perceive greater difference from improvements made to areas that have just been modified than to 
the whole scene, the above equation can be revised to give more weight to the B~ term than the B~ term. 
In other words, the redistribution of radiosity to the changed areas may be more noticeable and should 
have higher priority than shooting the unshot radiosity to the whole scene. THE ALGORITHM The complete 
algorithm is summarized in the following pseudo-code description: /* initialization */ For every patch 
i { B i=E~; 13 7=E i; cri=O; } /* solution loop */ While (not converged or more changes requested) 
{ /* check user interaction */ if (change requested) { if (change patch i's attributes) { compute AB; 
from (7); B i = Bi + AB i; B;' = B7 + aBe; } else if (delete patch i) { append "delete i" to the geometry 
queue } else if (add patch i) { append "add i" to the geometry queue B~ = E~ ; B~ = E~ ; <r~ = 0 ; } 
} /* find the shooting patch*/ select the shooting patch i based on (18); /* find the old scene */ sl 
= a set of patches obtained from evaluating the first cr i operations in the geometry queue; /* find 
the new scene */ s2 = a set of patches obtained from evaluating all the operations in the geometry queue; 
s=sl us2; /* compute form-factors. In implementation,, the modeling coherence as discussed in the section 
"Incremental Form- factor" should be exploited to compute A/~i. */ For every patch j in s { if (j s2 
and i s2) compute Fj~ ; else F/~ = 0 ; if (j e sl and i sl) compute F/i; else F/i= 0; . /* distribute 
radiosities */ For every patch j in s { update Bj and B~ based on (11); } /* reset the shooting patch*/ 
  B~ =0; O" i =tY; display every patch in s2; INTERACTIVE MANIPULATION An important motivation of the 
incremental rendering approach is to provide the user real-time feedback (or close to real-time) so that 
interactive manipulation is possible. To give the user feedback interactively when changing the surface 
attributes without waiting until the normal solution resumes, the form-factors from the changing patch 
to the whole scene can be computed first. When the reflectance or emission is changed interactively, 
the patches illuminated directly by the changing patch are updated continuously. The update can be done 
very fast because the form-factors do not need to be recomputed. After the change is completed, the normal 
solution can resume to correctly model the secondary and further interreflection. Providing interactive 
control when moving an object and accounting for the shadowing effects at the same time is a more complicated 
issue. One solution is to find a shooting patch that potentially contributes the most illumination to 
the moving object. A hemi-cube is placed on the shooting patch and every patch except the moving ones 
is projected onto the hemi-cube. Then, only the moving object needs to be projected and composited to 
the pre-computed hemi-cube in interactive time. The result is that when moving an object, only the shadowing 
effects from the shooting patch are accounted for. The other patches will be accounted for when the normal 
solution process is resumed. This step also can be done in parallel to account for more than one shooting 
patch at a time. However, finding the shooting patches is not always a trivial task and may require some 
user intervention. RESULTS The current system that implements the incremental radiosity method includes 
a modeler and a renderer, which are executed concurrently. The modeler interacts with the user to obtain 
the scene changes and then sends the incremental changes to the renderer. The renderer continuously improves 
the image quality and is interrupted temporarily to process a change from the modeler. During the interrupt, 
the user will obtain almost real-time feedback showing the direct illumination change when changing the 
surface attributes interactively. When changing the geometry, the user will only see the geometry updated 
interactively in our current implementation; the radiosity changes will be updated when the solution 
resumes. Several tests were conducted to determine the effectiveness of   SIGGRAPH '90, Dallas, August 
6-t0, 1990 I1! extending the method to include the effects of adding a pre- rendered subscene to an existing 
scene. This approach not only can potentially speed up the rendering process but also allows a fully 
shaded scene to be saved and recalled later by the modeler as a primitive. Note that this is not the 
same as just replicating and merging the radiosity data of pre-rendered subscenes that demonstrated by 
Wallace et al. [ 11 ]. The latter method does not account for the interreflections between the subscenes. 
To obtain a high quality image, the meshing of the patches should be modified in response to a geometry 
change. This is not implemented currently and should be included in the future. Although the current 
implementation assumes a diffuse scene, the method itself does not impose such a restriction. The incremental 
form-factors can be computed from the extended form-factors which include specular reflection and transmis- 
sion [ 12], [ 15] and [ 16]. ACKNOWLEDGEMENTS The author is very grateful to Ken Turkowski and Greg Ward 
for their thoughtful comments on this paper. The algorithm was implemented on a rendering testbed developed 
by Ken Turkowski, Doug Turner and the author. The initial idea of this paper was developed when the author 
was a graduate student in Program of Computer Graphics at Cornell Universi- ty. Discussions with faculty 
members and students at Comell were valuable. Lance Williams and Paul Heckbert provided helpful reading 
of early drafts. Dan Baum's comments on the paper and Robin Myers's help in printing the color images 
are acknowledged. Thanks also go to Helen Tahn and Mark Cutter for moral support. REFERENCES [ 1] Cohen, 
Michael F., Shenchang Eric Chen, John R. Wallace, Donald. P. Greenberg, "A Progressive Refinement Approach 
to Fast Radiosity Image Generation," Computer Graphics (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 
1988, pp. 75-84. [ 2] Goral, Cindy M., Kenneth. E. Torrance, Donald. P. Greenberg, Bennett Battaile, 
"Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics (SIGGRAPH '84 Proceedings), 
Vol.18, No. 3, July 1984, pp.213-222. [ 3] Cohen, Michael F., Donald. P. Greenberg, "The Hemi- Cube: 
A Radiosity Solution for Complex Environment,"  Computer Graphics (SIGGRAPH '85 Proceedings), Vol.19, 
No.3, July 1985, pp.31-40. [ 4] Cohen, Michael F., Donald. P. Greenberg, David S. Immel, Philip J. Brock, 
"An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE CG&#38;A, Vol. 6, No. 2, January 
1986, pp.26-35. [5] Gouraud, Henri, "Continuous Shading of Curved Surfaces," IEEE Transactions on Computers, 
Vol. 20, No. 6, June 1971, pp.623-628. [ 6] Phong, Bui-Tuong, "Illumination for Computer Generated Pictures," 
Communications of the ACM, Vol. 18, No. 6, June 1975, pp. 311-317. [ 7] Baum, Daniel R., John R. Wallace, 
Michael. F. Cohen, Donald. P. Greenberg, "The Back-Buffer: An Extension of the Radiosity Method to Dynamic 
Environments," The Visual Computer, Vol. 2, No. 5, 1986, pp, 298-306. [ 8] Buckalew C., Donald Fussell, 
"Illumination Networks: Fast Realistic Rendering with General Reflectance Functions," Computer Graphics 
(SIGGRAPH "89 Proceedings), Vol. 23, No. 3, July 1989, pp. 89-98.  [ 9] Siegel, Robert, John R. Howell, 
Thermal Radiation Heat Transfer, Hemisphere Publishing Corp,. Washington DC., 1981. [10] Claude Puech, 
Sillion Franqois, Christophe Vedel, "Improving Interaction with Radiosity-based Lighting Simulation Programs," 
Computer Graphics (Special Issue on 1990 Symposium on Interactive 3D Graphics), Vol.24, No. 2, March 
1990, pp.51-57. [ 11] Wallace, John R., Kells A. Elmquist, Eric A. Haines, "A Ray Tracing Algorithm For 
Progressive Radiosity," Computer Graphics (SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp.315-324. 
 [ 12] Wallace, John R., Michael F. Cohen and Donald P. Greenberg, "A Two-Pass Solution to the Rendering 
Equation: A Synthesis of Ray-Tracing and Radiosity Methods," Computer Graphics (SIGGRAPH '87 Proceedings), 
Vol. 21, No. 4, July 1987, pp. 311-320. [ 13] Chen, Shenchang Eric, A Progressive Radiosity Method and 
its Implementation in a Distributed Processing Environment, Master's thesis, Program of Computer Graphics, 
Comell University, Ithaca, NY, January 1989. [ 14] Baum, Daniel R., James M. Winget, "Real Time Radios- 
ity through Parallel Processing and Hardware Acceleration," Computer Graphics (Special Issue on 1990 
Symposium on Interactive 3D Graphics), Vol.24, No. 2, March 1990, pp.67-75.  [ 15] Rushmeier, Holly 
E., Extending the Radiosity Method to Transmitting and Specularly Reflecting Surfaces, Master's thesis, 
Comell University, Ithaca, NY, 1986. [ 16] Sillion, Francois, Claude Puech, "A General Two-Pass Method 
Integrating Specular and Diffuse Reflection, " Computer Graphics (S1GGRAPH '89 Proceedings), Vol. 23, 
No. 3, July 1989, pp.335-344.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97895</article_id>
		<sort_key>145</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Adaptive radiosity textures for bidirectional ray tracing]]></title>
		<page_from>145</page_from>
		<page_to>154</page_to>
		<doi_number>10.1145/97879.97895</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97895</url>
		<abstract>
			<par><![CDATA[We present a rendering method designed to provide accurate, general simulation of global illumination for realistic image synthesis. Separating surface interaction into diffuse plus specular, we compute the specular component on the fly, as in ray tracing, and store the diffuse component (the radiosity) for later-reuse, similar to a radiosity algorithm. Radiosities are stored in <i>adaptive radiosity textures (rexes</i>)<sup>1</sup> that record the pattern of light and shadow on every diffuse surface in the scene. They adaptively subdivide themselves to the appropriate level of detail for the picture being made, resolving sharp shadow edges automatically.We use a three-pass, bidirectional ray tracing algorithm that traces rays from both the lights and the eye. The "size pass" records visibility information on diffuse surfaces; the "light pass" progressively traces rays from lights and bright surfaces to deposit photons on diffuse surfaces to construct the radiosity textures; and the "eye pass" traces rays from the eye, collecting light from diffuse surfaces to make a picture.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P221481</person_id>
				<author_profile_id><![CDATA[81100383628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Heckbert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dept. of Electrical Engineering and Computer Science, University of California, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arthur Appel, "Some Techniques for Shading Machine Renderings of Solids", AFIPS 1968 Spring Joint Computer Con}., vol. 32, 1968, pp. 37-45.]]></ref_text>
				<ref_id>Appel68</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[James Afro, "Backward Ray Tracing", SIGGRAPtt '86 Developments in Ray Tracing seminar notes, Aug. 1986.]]></ref_text>
				<ref_id>Arvo86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807403</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Peter R. Atherton, Kevin Weiler, Donald P. Greenberg, "Polygon Shadow Generation~, Computer Graphics (SIGGRAPH '78 Proceedings), vol. 12, no. 3, Aug. 1978, pp. 275-281.]]></ref_text>
				<ref_id>Atherton78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74367</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Daniel R. Baum, Holly E. Rushmeier, James M. Winger, "Improving l~diosity Solutions Through the Use of Analytically Determined Form Factors", Computer Graphics (SIGGRAPtt '89 Proceedings), vol. 23, no. 3, July 1989, pp. 325-334.]]></ref_text>
				<ref_id>Baum89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[James F. Blinn, Martin B. Newell, "Texture and Reflection in Computer Generated Images", CACM, vol. 19, no. 10, Oct. 1976, pp. 842-547.]]></ref_text>
				<ref_id>Blinn76</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74342</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chris Buck~lew, Donald FusseU, "Blumin~fion Networks. F~st Realistic Rendering with General Reflectance Functions", Computer Graphics (SIGGRAPH '89 Proceedings), vol. 23, no. 3, July 1989, pp. 89-98.]]></ref_text>
				<ref_id>Buckalew89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Michael F. Cohen, Donald P. Greenberg, "The I-feral-Cube: A Radiosity Solution for Complex Environments", Computer Graphics (SIGGRAPH '85 Proceedings), vol, 19, no. 3, July 1985, pp. 31-40.]]></ref_text>
				<ref_id>Cohen85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Michael F. Cohen, Donald P. Greenberg, David S. Immel, Philip ft. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis", {EEE Computer Graphics and Applications~ Mar. 1986, pp. 26-35.]]></ref_text>
				<ref_id>Cohen86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Michael F. Cohen, Shenchang Eric Chen, John R. Wallace, Donald P. Greenberg, "A Progressive Refinement Approach to F~st R~- diosity Image Generation", Computer Graphics (SIGGRAPH '88 Proceedings), vol. 22, no. 4, Aug. 1988, pp. 75-84.]]></ref_text>
				<ref_id>Cohen88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, Thomas Porter, Loren Carpenter, ~Distributed Ray Tracing", Computer Graphics (SIGGRAPH '84 Proceedings), vol. 18, no. 3, July 1984, pp. 137-145.]]></ref_text>
				<ref_id>Cook84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, "Stochastic Sampling in Computer Graphics", ACM Transactions on Graphics, vol. 5, no. 1, Jan. 1986, pp. 51-72.]]></ref_text>
				<ref_id>Cook86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mark A. Z. Dippe, Erling Henry Wold, "Antialiaslng Through Stochastic Sampling", Computer Graphics (SIGGRAPH '85 Proceedings), vol. 19, no. 3, July 1985, pp. 69-78.]]></ref_text>
				<ref_id>Dippe85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Cindy M. Goral, Kenneth E. Torrance, Donald P. Grcenberg, Bennett Battaile, ~Modeling the Interaction of Light Between Diffuse Surfaces", Computer Graphics (SIGGRAPH '84 Proceedings), vol. 18, no. 3, July 1984, pp. 213-222.]]></ref_text>
				<ref_id>Goral84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63450</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Roy Hall, Illumination and Color in Computer Generated lmajer~t, Springer Verhg, New York, 1989.]]></ref_text>
				<ref_id>Hall89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Paul S. Hcckbcrt, Pat HH~nrahan, "Beam Tracing Polygonal Objects", Computer Graphics (SIGGRAPH '84 Proceedings), vol. 18, no. 3, July 1984, pp. 119-127.]]></ref_text>
				<ref_id>Heckbert84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Paul S. Hcckbert, "Survey of Texture Mapping", IEEE Computer Graphics and Applications, vol. 6, no. 11, Nov. 1986, pp. 56-6"/.]]></ref_text>
				<ref_id>Heckbert86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[David S. Immel, Michael F. Cohen, Donald P. Greenberg, a3_ Radiosity Method for Non-Diffuse Environments", Computer Graphics (SIGGRAPH '86 Proceedings), vol. 20, no. 4, Aug. 1986, pp. 133- 142.]]></ref_text>
				<ref_id>Immel86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J~mes T. Kajiya, "The Rendering Equation", Computer Graphics (SIGGRAPH '8fi Proceedings), vol. 20, no. 4, Aug. 1986, pp. 143-150.]]></ref_text>
				<ref_id>Kajiya86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Mark E. Lee, }Lichard A. Redner, Samuel P. Uselton, "Statistically Optimized Sampling for Distributed Ray Tracing", Computer Graphics (SIGGRAPI-{ '85 Proceedings), vol. 19, no. 3, July 1085, pp. 61-67.]]></ref_text>
				<ref_id>Lee85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Don P. Mitchell, "Generating Antiali~sed Images at Low Sampling Densities~, Computer Graphics (SIGGRAPH '87 Proceedings), vol. 21, no. 4, July 1987, pp. 65-72.]]></ref_text>
				<ref_id>Mitchell87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Tomoyuki Nishita, Eihachiro Nak~mae, "Continuous Tone ReI>- resentation of 3-D Objects T~king Account of Shadows and Interreflection", Computer Graphics (SIGGRAPH '85 Proceedings), vol. 19, no. 3, July t985, pp. 23-30.]]></ref_text>
				<ref_id>Nishita85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74362</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[James Painter, Kenneth S}oan, "Antirdiased Ray Tr~cing by Ad~ptlve Progressive Refinement", Computer Graphics (SIGGRAPH '89 Proceedings), vol. 23, no. 3, July 1989, pp. 281-288.]]></ref_text>
				<ref_id>Painter89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37435</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[William T. Reeves, David }L Salesin, Robert L. Cook, ~Rendering Antiallased Shadows with Depth Maps", Computer Graphics (SIGGlZAPH '87 Proceedings), vol. 21, no. 4, 3uly 1087, pp. 283-291.]]></ref_text>
				<ref_id>Reeves87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>77589</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Hanan Samet, The Design and Analysis of Spatial Data Structures, Reading, MA, Addison-Wesley, 1990.]]></ref_text>
				<ref_id>Samet90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378492</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Mirt-ZhL Shao, Qun-Sheng Peng, You-Dong Liang, "A New Rs.- diosity Approach by Procedural Refinements for Realistic Image Synthesis", Computer Graphics (SIGGRAPH '88 Proceedings), vol. 22, no. 4, Aug. 1988, pp. 93-101.]]></ref_text>
				<ref_id>Shao88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Robert Siegel, John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington, DG, 1981.]]></ref_text>
				<ref_id>Siegel81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Francois Sillion, Claude Puech, ~A General Two-Pass Method Integrating Specular and Diffuse Reflection", Computer Graphics (SIC- GRAPH '89 Proceedings), vol. 23, no. 3, July 1989, pp. 335-344.]]></ref_text>
				<ref_id>Sillion89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[B.W. Silverman, Density Estimation for Statistics and Data Analysis, Chapman and Hall, London, 1986.]]></ref_text>
				<ref_id>Silverman86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>59709</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Paul S. Strauss, BAGS: The Brown Animation Generation Svstern, PhD thesis, Tech. Report CS-88-2, Dept. of CS, Brown U, May 1988.]]></ref_text>
				<ref_id>Strauss88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37415</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Brian Von Herzen, Alan H. Barr, "Accurate Tri~rtgultions of Deformed, Intersecting Surfaces", Computer Graphics (SIG- GRAPH '87 Proceedings), vol. 21, no. 4, July 1987, pp. 103-110.]]></ref_text>
				<ref_id>Von Herzen87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[John R. Wallace, Michael F. Cohen, Donald P. Greenberg, "A Two-Pass Solution to the Kendering Equation: A Synthesis of l~y Tracing and Radiosity Methods", Computer Graphics (SIGGRAPH '87 Proceedings), vol. 21, no. 4, July 1987, pp. 311-320.]]></ref_text>
				<ref_id>Wallace87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[John R. Wallace, Kells A. Elmquist, Eric A. Haines, "A Ray Tracing Algorithm for Progressive R~diosity", Computer Graphics (SIGGRAPI-I '89 Proceedings), vol. 23, no. 3, July 1989, pp. 315-324.]]></ref_text>
				<ref_id>Wallace89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Gregory J. Ward, Francis M. Rubinstein, Robert D. Cle~r, =A Ray Tracing Solution for Diffuse Interreflection", Computer Graphics (SIGGRAPI.I '88 Proceedings), vol. 22, no. 4, Aug. 1988, pp. 85-92.]]></ref_text>
				<ref_id>Ward88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[John E. Warnock, A Hidden Surface Algorithm for Computer Generated Halftone Pictures, TR 4-15, CS Dept, U. of Utah, June 1969.]]></ref_text>
				<ref_id>Warnock69</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97920</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[M~rk Watt, aLight-Water Interaction using Backwt~rd Beam Tr~c ing', Computer Graphics (SIGGRAPH '90 Proceedings), Aug. 1990.]]></ref_text>
				<ref_id>Watt90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Turner Whitted, "An Improved Illumination Model for Shaded Display", CACM, vol. 23, no. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id>Whitted80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Lance Williams, ~Casting Curved Shadows on Curved Surfaces", Computer Graphics (SIGGRAPH '78 Proceedings), vol. 12, no. 3, Aug. 1978, pp. 270-274.]]></ref_text>
				<ref_id>Williams78</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Adaptive Radiosity Textures for Bidirectional 
Ray Tracing Paul S. Heckbert Dept. of Electrical Engineering and Computer Science University of California, 
Berkeley, CA 94720 Abstract We present a rendering method designed to provide accurate, general simulation 
of global illumination for re- alistic image synthesis. Separating surface interaction into diffuse plus 
specular, we compute the specular component on the fly, as in ray tracing, and store the diffuse compo- 
nent (the radiosity) for later-reuse, similar to a radiosity algorithm. Radiosities are stored in adaptive 
radiosity tez- lures (fezes) that record the pattern of light and shadow on every diffuse surface in 
the scene. They adaptively sub- divide themselves to the appropriate level of detail for the picture 
being made, resolving sharp shadow edges auto- matically. We use a three-pass, bidirectional ray tracing 
algorithm that traces rays from both the lights and the eye. The "size pass" records visibility iufornmtion 
on diffuse surfaces; the "light pass" progressively traces rays from lights and bright surfaces to deposit 
photons on diffuse surfaces to construct the radiosity textures; and the "eye pass" traces rays from 
the eye, collecting light from diffuse surfaces to make a picture. CtL Categories: 1.3.3 [Computer Graphicsl: 
Picture/Image Generation-display algorithms; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and 
ReMism -visible line~surface algorithms. General Terms: algorithms. Additional Key Words and Phrases: 
global illumination, den- sity estimation, texture mapping, quadtree, adaptive subdivision, sampling. 
 Introduction The presentation is divided into four sections. We first discuss previous work on the 
global illumination problem. Then we out- line our bidirectional ray tracing approach in an intuitive 
way. Next we describe our implementation and some early results. We conclude with a summary of the method 
and of our experiences to date. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. 2 The Global Illumination Problem The primary goal of realistic image synthesis 
is the develop-ment of methods for modeling and realistically rendering three- dimensional scenes. One 
of the most chMlenging tasks of realistic image synthesis is the accurate and efficient simulation of 
global illumination effects: the illumination of surfaces in a scene by other surfaces. Early rendering 
programs treated the visibility (hidden surface) and shading tasks independently, employing a local illumination 
model which assumed that the shading of each surface is independent of the shading of every other surface. 
Lo- cal illumination typically assumes that light comes from a finite set of point light sources only. 
Global illumination models, on the other hand~ recognize that the visibility and shading are interre- 
lated: the shade of a sm'face point is determined by the shades of all of the surfaces visible fl'om 
that point. The intensity of light traveling in a given outgoing direction o~t from a surface point is 
the integral of the incident inten- sity times the bidirectional distribution function (BDF) over all 
possible incoming directions in: intensity(oWl) = fphere intensity(i~) BDF(in, o~t) d(in) The bidirectional 
distribution function is the fraction of energy reflected or transmitted from the incoming direction 
in = (¢i, Oi) to the outgoing direction out = (¢o, 0o); it is the sum of the bidirectional reflectance 
distribution function (BRDF) and the bidirectional transmittance distribution function (BTDF). See [Hall89] 
for a more detailed discussion of the physics of illumina- tion. We will characterize previous global 
illumination algorithms by the approximations they make to the above integral. Because of the superposition 
properties of electromagnetic ra- diatlon, we can segregate surface reflectance into two types: dif- 
fuse and specular. We define diffuse interaction (both reflection and transmission) to be the portion 
of interaction that scatters fight equally in all directions, and specular interaction to be the remaining 
portion. BDF = BDFdilf + BDF~pee. For many ma- terials, specular interaction scatters light in only a 
small cone of directions. When this cone includes just a finite number of direc- tions, each a cone with 
solid angle zero, we call the interaction ideal specular, otherwise, when the cone(s) have a positive 
finite angle, we call it rough specular. Two examples of ideal specular surfaces are: (1) a perfect mirror 
that reflects in one direction, and (2) a perfect transmitter that refracts in one direction and reflects 
in another. An ideal specular surface with micro-bumps behaves statistically like a rough specular surface. 
Oar three classes of interaction are diagrammed in figure 1.  O SIGGRAPH '90, Dallas, August 6-10, 1990 
diffuse rough specular ideal specular Figure 1: Three classes of reflectance: diffuse, rough specular, 
and ideal specular; showing a polar plot of the reflectance coeffi- cient for fixed incoming direction 
and varying outgoing direction. Transmittance is similar. A diffuse surface appears equally bright from 
all viewing di- rections, but a specular surface's brightness varies with viewing direction, so we say 
that diffuse interaction is view-independent while specular interaction is view-dependent. The simplest 
ma- terials have a position-invariant, isotropic BDF consisting of a linear combination of diffuse and 
ideal specular interaction, but a fully-general BDF can simulate textured, anisotropic, diffuse and rough 
specular surfaces. 2.1 Ray Tracing vs. l:tadiosity The two most popular algorithms for global illumination 
are ray tracing and radiosity. Ray tracing is both a visibility algorithm and a shading algorithm~ but 
radiosity is just a shading algo- rithm. 2.1.1 Ray Tracing Classic ray tracing generates a picture by 
tracing rays from the eye into the scene, reeursively exploring specularly reflected and transmitted 
directions, and tracing rays towaxd point light sources to simulate shadowing [Whitted80]. It assumes 
that the BDF contains no rough specular, and that the incident light relevant to the diffuse computation 
is a sum of delta functions in the di- rection of each light source. This latter assumption implies a 
local illumination model for diffuse. A more realistic illumination model includes rough specular BDF's 
and computes diffuse interaction globally. Exact simu- lation of these effects requires the integration 
of incident light over cones of finite solid angle. Ray tracing can be generalized to approximate such 
computations using distribution ray trac- ing [Cook84], ILee85], [Dippe85], [Cook86], [Kajiya86]. (We 
pro- pose the name "distribution ray tracing" as an alternative to the current name, "distributed ray 
tracing", which is confusing because of its parallel hardware connotations.) In distribution ray tracing, 
rays are distributed, either uniformly or stochasti- cally, throughout any distributions needing integration. 
Many rays must be traced to accurately integrate the broad reflectance distributions of rough specular 
and diffuse surfaces: often hun- dreds or thousands per surface intersection. 2.1.2 Radiosity The term 
radiosity is used in two senses. First, radiosity is a physical quantity equal to power per unit area, 
which determines the intensity of light diffusely reflected by a surface, and second, radiosity is a 
shading algorithm. The meaning of each use should be clear by context. 146 The Classic radiosity algorithm 
subdivides each surface into polygons and determines the fraction of energy diffusely radi- ated from 
each polygon to every other polygon: the pair's form ]actor. From the form factors, a large system of 
equations is constructed whose solution is the radiosities of each polygon [SiegelS1], [Gora184], [Nishita85]. 
This system can be solved ei- ther with Gauss-Seidel iteration or, most conveniently, with pro- gressive 
techniques that compute the matrix and solve the sys- tem a piece at a time [Cohen88]. Form factors can 
be determined analytically for simple geometries [Siege181], [Baum89], but for complex geometries a numerical 
approach employing a visibility algorithm is necessary. The most popular visibility method for this purpose 
is a hemicube computed using a z-buffer [Cohen85], but ray tracing has recently been promoted as an alternative 
[Wallace89], [Sillion89]. Classic radiosity assumes an entirely dif- fuse reflectance, so it does not 
simulate specular interaction at all. The output of the radiosity algorithm is one radiosity value per 
polygon. Since diffuse interaction is by definition view-inde- pendent, these radiosities are valid from 
any viewpoint. The radiosity computation must be followed by a visibility algorithm to generate a picture. 
The radiosity method can be generalized to simulate specu- lar interaction by storing not just a single 
radiosity value with each polygon, but a two-dimensional array [Imme186], [Shao88], [Buckalew89]. The 
resulting algorithm, which we call directional radiosity, simulates both diffuse and specular interaction 
globally, but the memory requirements are so excessive as to be impracti- cal. 2.1.3 Hybrid Methods 
Ray tracing is best at speculax and radiosity is best at diffuse, and the above attempts to generalize 
ray tracing to diffuse and to generalize radiosity to specular stretch the algorithms beyond the reflectance 
realms for which each is best suited, making them less accurate and less efficient. Another class of 
algorithms is formed by hybridizing the methods, using a two-pass algorithm that applies a radiosity 
pass followed by the ray tracing pass. This is the approach used by [Wallace87] and [Sillion89]. The 
first pass of Wallace's algorithm consists of classic radios- ity extended to include diffuse-to-diffuse 
interactions that bounce off planar mirrors. He follows this with a classic ray tracing pass (implemented 
using a z-buffer). Unfortunately, the method is limited to planar surfaces (because of the polygonization 
involved in the radiosity algorithm) and to perfect planar mirrors. Sillion's algorithm is llke Wallace's 
but it computes its form factors using ray tracing instead of hemicubes. This eliminates the restriction 
to planar mirrors. The method still suffers from the polygonization inherent in the radiosity step, however. 
 2.2 Sampling Radlositles Many of the sampling problems of ray tracing have been solved by recent adaptive 
algorithms [WhittedS0], [Cook86], [Lee85], [Dippe85], [Mitchel187], [Painter89], particularly for the 
simula- tion of specular interaction. The sampling problems of the radios- ity algorithm are less well 
studied, probably because its sampling process is less explicit than that of ray tracing. ~' Computer 
Graphics, Volume 24, Number 4, August 1990 We examine four data structures for storing radiosities: light 
images, polygons, samples in 3-D, and textures. Several different algorithms have been used to generate 
these data structures: ra-diosities have been generated analytically, with hemicubes at the receiver 
(gathering), with hemieubes at the sender (shooting), and by tracing rays from the eye or from the light. 
2.2.1 Light Images The simplest data structure, the light image, simulates only shad- ows, the first 
order effects of diffuse interreflection. Light images are pictures of the scene from the point of view 
of each light ~ource. They are most often generated using the z-buffer shadow algorithm, which saves 
the z-buffers of these light images and uses them while rendering from the point of view of the eye to 
test if visible points are in shadow [Wilhams78], [Reeves87]. This shadow algorithm is more flexible 
than most, since it is not lim- ited to polygons, but it is difficult to tune. Choosing the resolu- tion 
for the light images is critical, since aliasing of shadow edges results if the light images are too. 
coarse. 2.2.2 Polygonlzed l~adioslty The Atherton-Weiler algorithm is another method for comput- ing 
shadows that renders from the point of view of the lights [Atherton78]. It uses the images rendered from 
the lights to gen- erate "surface detail polygons", modifying the scene description by splitting all 
polygons into shadowed and unshadowed portions that are shaded appropriately in the final rendering from 
the eye. Surface detail polygons are an example of polygonized radiosity, the storage of radiosity as 
polygons. The shadows computed by the Atherton-Weiler algorithm are a first-approximation to the interrefiection 
simulated by radiosity algorithms. The most common method for computing polygonized radios- ity is, of 
course, the classic radiosity algorithm. A major prob- lem with this Mgorithm is that surfaces are polygonized 
before radiosities are computed. Difficulties result if this polygonization is either too coarse or too 
fine. Sharp shadow edges caused by small light sources can be un- dersampled if the polygonization is 
too coarse, resulting in blur- ring or abasing of the radiosities. Cohen developed the "sub-structuring" 
technique in response to this problem [Cohen86]. It makes an initial pass computing radiosities at low 
resolution, then splits polygons that appear to be in high-variance regions and recomputes radiosities. 
Substructuring helps, but it is not fully automatic, as the subdivision stopping criterion appears to 
be a polygon size selected in some ad hoc manner. The limi- tations of the method are further demonstrated 
by the absence to date of radiosity pictures in published work exhibiting sharp shadow edges. The other 
extreme of radiosity problems is oversampling of radiosities due to polygonization that is too fine for 
the hemicube. The resulting quantization can be cured by adaptive subdivision of the hemicube or of the 
light rays [Wallace89], [Baum89]. We conclude that polygonization criteria remain a difficult problem 
for the radiosity method. It is interesting to note the similaxities between radiosity al- gorithms and 
the Atherton-Weiler algorithm. Conceptually, the original radiosity method gathers light to each polygon 
by ren- dering the scene from the point of view of each receiver, but the progressive radiosity algorithm 
shoots light by rendering the scene from the point of view of each sender (a light source). A progressive 
radiosity algorithm using a hemicube is thus much like repeated application of the Atherton-Weiler shadow 
algo- rithm. 2.2.3 Samples in 3-D l~adiosities can be computed using brute force distribution ray tracing 
[Kajiya86], but the method is inefficient because it sam- ples the slowly-varying radiosity function 
densely. To exploit the coherence of radiosity values, Ward sampled the diffuse compo- nent sparsely, 
and saved this information in a world space octree [Ward88]. Because his algorithm shot rays from the 
eye toward the lights, and not vice-versa, it had difficulty detecting light sources reflected by specular 
surfaces. 2.2.4 Radiosity Texture The fourth data structure for radiosities is the radiosity texture. 
Instead of polygonizing each surface and storing one radiosity value per polygon, radiosity samples are 
stored in a texture on every diffuse surface in the scene [Arvo86]. Arvo called his tex- tures "illumination 
maps". He computed them by tracing rays from the light sources. 2.3 Light Ray Tracing Rays traced from 
the eye we call eye rays and rays traced from the lights we call light rays. We avoid the terms "forward 
ray tracing" and "backward ray tracing" because they are ambiguous: some people consider photon motion 
~'forward', while others consider Whitted's rays "forward". Light ray tracing was originally proposed 
by Appel [Appe168], who "stored" his radiosities on paper with a plotter. Light ray tracing was proposed 
for beams in previous work with Hanra- han [Heckbert84] where we stored radiosities as surface detail 
polygons like Atherton-Weiler. This approach was modified by Strauss, who deposited light directly in 
screen pixels when a dif- fuse surface was hit by a beam, rather than store the radiosities with the 
surface [Strauss88]. Watt has recently implemented light beam tracing to simulate refraction at water 
surfaces [Wattg0]. Arvo used light ray tracing to compute his radiosity textures [Arvo86]. Light ray 
tracing is often discussed but has been little used, to date. 3 Bidirectional Ray Tracing Using Adap- 
tive Radiosity Textures In quest of realistic image synthesis, we seek efficient algorithms for simulating 
global illumination that can accommodate curved surfaces, complex scenes, and arbitrary surface characteristics 
(BDF's), and generate pictures perceptually indistinguishable from reality. These goals are not realizable 
at present, but we can make progress if we relax our requirements. O SIGGRAPH '90, Dallas, August 6-10, 
1990 We make the following assumptions: (1) Only surfaces are relevant. The scattering or absorp- tion 
of volumes can be ignored. (2) Curved surfaces are important. The world is not polygonal. (3) Shadows, 
penumbras, texture, diffuse interreflection, specular reflection, and refraction are all important. 
(4) We can ignore the phenomena of fluorescence (light wavelength crosstalk), polarization, and diffraction. 
 (5) Surface properties can be expressed as a linear com- bination of diffuse and specular reflectance 
and trans- mission functions:  BDF =kd~BRDFdity + ksrB1~DF~pec+ kdtBTDFdi// + kstBTDFspec The coet-ficients 
klj are not assumed constant. (6) Specular surfaces are not rough; all specular interac- tion is ideal. 
3.1 Approach Our approach is a hybrid of radiosity and ray tracing ideas. Rather than patch together 
these two Mgorithms, however, we seek a simple, coherent, hybrid algorithm. To provide the great- est 
generality of shape primitives and optical effects, we choose ray tracing as the visibility algorithm. 
Because ray tracing is weak at simulating global diffuse interaction, the principal task before us is 
therefore to determine an etficient method for calcu- lating radiosities using ray tracing. To exploit 
the view-independence and coherence of radiosity, we store radioslty with each diffuse surface, using 
an adaptive radiosity texture, or rex. A rex records the pattern of light and shadow and color bleeding 
on a surface. We store radiosity as a texture, rather than as a polygonization, in order to decouple 
the data structures for geometry and shading, and to facilitate adaptive subdivision of radieslty information; 
and we store it with the surface, ratlier than in a global octree [Ward88], or in a light image, based 
on the intuition that radiosities are intrinsic properties of a surface. We expect that the memory required 
for rexes will not be excessive, since dense sampling of radiosity will be necessary only where it has 
a high gradient, such as at shadow edges. Next we need a general technique for computing the rexes. The 
paths by which photons travel through a scene can motivate our algorithm (figure 2). We can characterize 
each interaction along a photon's path from light (L) to eye (E) as either diffuse (D) or specular (S). 
Each path can therefore be labeled with some string in the set given by the regular expression L(D]S)*E. 
Classic ray tracing simulates only LDS*E [ LS*E paths, while classic radioslty simulates only LD*E. Eye 
ray tracing has dif- ficulty finding paths such as LS+DE because it doesn't know where to look for specularly 
reflected light when integrating the hemisphere. Such paths are easily simulated by light ray tracing, 
however. We digress for a moment to discuss units. Light rays carry power (energy/time) and eye rays 
carry intensity (energy / (time * projected area * solid angle)). Each light ray carries a fraction D 
° /  Figure 2: Selected photon paths from light (L) to eye (E) by way of diffuse (D ) and specular (S 
) surfaces. For simplicity, the surfaces shown are entirely diffuse or entirely specular; normally each 
surface would be a mixture. Figure 3: Left: first level light ray tracing propagates photons from the 
light to the first diffuse surface on a path (e.g. LD and LSD); higher levels of progressive light ray 
tracing simulate indirect diffuse interaction (e.g. LDD). Right: eye ray trac- ing shoots rays from the 
eye, extracting radiosities from diffuse surfaces (e.g. it traces DE and DSE in reverse). of the total 
power emitted by the light. We can simulate paths of the form LS*D by shooting light rays (photons) into 
the scene, depositing the photon's power into the rex of the first diffuse surface encountered (figure 
3, left). Such a light ray tracing pass will compute a first approximation to the radiosities. This can 
be followed by an eye ray tracing pass in which we trace DS*E paths in a backward direction, extract- 
ing intensity from the rex of the first diffuse surface encountered (figure 3, right). The net effect 
of these two passes will be the simulation of all LS*DS*E paths. The rays of the two passes "meet in 
the middle" to exchange information. To simulate dif- fuse interreflection, we shoot progressively from 
bright surfaces [Cohen88] during the light ray tracing pass, thereby accounting for all paths: L(S*D)*S*E 
= L(D[S)*E. We call these two passes the light pass and eye pass. Such bidirectional ray tracing using 
adaptive radiosity textures can thus simulate all photon paths, in principle. Our bidirectional ray tracing 
algorithm is thus a hybrid. From radiosity we borrowed the idea of saving and reusing the diffuse component, 
whicil is view-independent, and from ray tracing we borrowed the idea of discarding and recomputing the 
specular component, which is view-dependent. ~ Computer Graphics, Volume 24, Number 4, August 1990 3.2 
All Sampling is Adaptive There are three separate multidimensional sampling processes involved in this 
approach: sampling of directions from the light, sampling of directions from the eye (screen sampling), 
and sam- pling of radiosity on each diffuse surface. 3.3 Adaptive Radiosity Textures (Rexes) Rexes are 
textures indexed by surface parameters u and v, as in standard texture mapping [Blinn76], [Heckbert86]. 
We associate a rex with every diffuse or partially-diffuse surface. By using a texture and retaining 
the initial geometry, instead of polygo- nizing, we avoid the polygonized silhouettes of curved surfaces 
common in radiosity pictures. In the bidirectional ray tracing algorithm, the rexes collect power from 
incident photons during the light pass, and this in- formation is used to estimate the true radiosity 
function during the eye pass (figure 4). Our rexes thus serve much like den-sity estimators that estimate 
the probability density of a random variable from a set of samples of that random variable [Silver- man86]. 
Density can be estimated using either histogram meth- ods, which subdivide the domain into buckets; or 
kernel estima- tors, which store every sample and reconstrnct the density as a sum of weighted kernels 
(similar to a spline). The resolution of a rex should be related to its screen size. Ideally, we want 
to resolve shadow edges sharply in the final picture, which means that rexes should store details as 
fine as the preimage of a screen pixel. On the other hand, resolution of details smaller than this is 
unnecessary, since subpixel detail is beyond the Nyquist limit of screen sampling. Cohen's sub- structuring 
technique is adaptive, but its criteria appear to be independent of screen space, so it cannot adapt 
and optimize the radiosity samples for a particular view. To provide the light pass with information 
about rex resolu- tion we precede the light pass with a size pass in which we trace rays from the eye, 
labeling each diffuse surface with the minimum rex feature size. 3.8.1 Adaptive Light Sampling Adaptive 
sampling of light rays is desirable for seYeral reasons. Sharp resolution of shadow edges requires rays 
only where the light source sees a silhouette. Also, it is only necessary to trace light paths that hit 
surfaces visible (directly or indirectly) to the eye. Thirdly, omnidirectional lights disperse photons 
in a sphere of directions, but when such lights are far from the visible scene, as is the sun, the light 
ray directions that affect the final picture subtend a small solid angle. Finally, stratified sampling 
should be used for directional lights to effect their goniometric distribution. Thus, to avoid tracing 
irrelevant rays, we sample the sphere of directions adaptively [Sillion89], [Wallace89]. For area light 
sources, we use stratified sampling to distribute the ray origins across the surface with a density proportional 
to the local radiosity. Stratified sampling should also be used to shoot more light rays near the normal, 
since it is intensity that is constant with outgoing angle, while power is proportional to the cosine 
of the angle with the normal. If the surface has both a standard texture and a rex mapped onto it, then 
the rex should be modulated by this standard texture before shooting. With Figure 4: Photons incident 
on a rex (shown as spikes with height proportional to power) are samples from the true, piecewise-continuous 
radiosity function (the curve). We try to estimate the function from the samples. area light sources, 
the distribution to be integrated is thus four- dimensional: two dimensions for surface parameters u 
and v, and two dimensions for ray direction. For best results, a 4-D data structure such as a k-d tree 
should be used to record and adapt the set of light rays used. 3.3.2 Adaptive Eye Sampling Eye rays (screen 
pixels) are sampled adaptively as well. Tech-niques for adaptive screen sampling have been covered well 
by others [Warnock69], [Whitted80], [Mitchell87], [Painter89]. 3.4 Three Pass Algorithm Our bidirectional 
ray tracing algorithm thus has three passes. We discuss these passes here in a general way; the details 
of a particular implementation are discussed in §4. The passes are: size pass -record screen size information 
in each rex light pass -progressively trace rays from lights and bright surfaces, depositing photons 
on diffuse surfaces to construct radiosity textures eye pass -trace rays from eye, extracting light from 
dif- fuse surfaces to make a picture Specular reflection and transmission bounces are followed on all 
three passes. Distribution ray tracing can be used in all passes to simulate the broad distributions 
of rough specular reflections and other effects. 3.4.1 Size Pass As previously described, the size pass 
traces rays from the eye, recording information about the mapping between surface pa- rameter space and 
screen space. This information is used by each rex during the light pass to terminate its adaptive subdivision. 
3.4.2 Light Pass Indirect diffuse interaction is simulated during the llght pass by regarding bright 
diffuse surfaces as light sources, and shooting light rays from them~ as in progressive radiosity. The 
rex records the shot and unshot power.  ~ Computer Graphics, Volume 24, Number 4, August 1990 O0 i! 
0  0 o 1/16 1/16... Figure 6: Light quadtree shown schematically (left) and in light direction parameter 
space (right). When a light quadtree node is split, its power is redistributed to its four sub-nodes, 
which each send a ray in a direction (r,s) jittered ~oithin their parameter square. The fractional power 
of each light ray is shown next to the leaf node that sends it. The current implementation uses the following 
algorithm. 4.1 Light Pass First, rex quaxitrees are initialized to a chosen starting level (level 3, 
say, for 8x8 subdivision), and the counts and powers of all leaves are zeroed. For each light, light 
ray tracing proceeds in breadth first order within the light quadtree, at level 0 tracing a single ray 
carrying the total power of the light, at level 1 tracing up to 4 rays, at level 2 tracing up to 16 rays, 
etc (figure 6). At each level, we adaptively subdivide both the light quadtree and the rex quadtrees. 
Chang- ing the rex quadtrees in the midst of light ray shooting raises the histogram redistribution problem, 
however: if a histogram bucket is split during collection, it is necessary to redistribute the parent's 
mass among the children. There is no way to do this reliably without a priori knowledge, so we clear 
the rex at the beginning of each level and reshoot. Processing a given level k of light rays involves 
three steps: (1) rex subdivision to split rex buckets containing a high density of photons, (2) light 
marking to mark light quadtree nodes where more light rays should be sent, and (3) light subdivision 
to split marked light nodes. Rex subdivision consists of a sweep through every rex quadtree in the scene, 
splitting all rex buckets whose photon count exceeds a chosen limit. All counts and powers are zeroed 
at the end of this sweep. Light marking traverses the light quadtree, marking all level k nodes that 
meet the subdivision criteria listed below. (1) Always subdivide until a minimum level is reached. (2) 
Never subdivide beyond a maximum level (if a size pass were implemented, it would determine this max- 
imum level locally).  Otherwise, look at the light quadtree neighbors above, below, left, and right, 
and subdivide if the following is true: (3) The ray hit a diffuse surface, and one of the four neighbors 
of the rex node hit a different surface or was beyond a threshold distance in (u, v) parameter space 
from the center ray's. To help prevent small feature neglect, we also mark for subdi- vision all level 
k - 1 leaves that neighbor on level k leaves that are m~ked for subdivision. This last rule guarantees 
a restricted quadtree [Von Herzen87] where each leaf node's neighbors are at a level within plus or minus 
one of the center node's. Light subdivision traverses the light quadtree splitting the marked nodes. 
Subdividing a node splits a ray of power p into four rays of power p/4 (figure 6). When a light node 
is cre-ated (during initialization or subdivision) we select a point at random within its square (r, 
s) domain to achieve jittered sam- pling [Cook86] and trace a ray in that direction. Marked nodes thus 
shoot four new rays, while unmarked nodes re-shoot their rays. During light ray tracing we follow specular 
bounces, split- ting the ray tree and subdividing the power according to the re- flectance/transmittance 
coefficients kij, and deposit their power on any diffuse surface that are hit. When a diffuse surface 
is hit, we determine (u,v) of the intersection point, and descend the surface's rex quadtree to find 
the rex node containing that point. The power of that node is incremented by the power of the ray times 
the cosine of the incident angle. 4.2 Eye Pass The eye pass is a fairly standard adaptive supersampling 
ray tracing algorithm: nodes are split when the intensity difference between the four corners exceeds 
some threshold. To generate a picture, nodes larger than a pixel perform bilinear interpolation to fill 
in the pixels they cover, while nodes smaller than a pixel are averaged together to compute a pixel. 
The picture is stored in floating point format initially, then scaled and clamped to the range [0,255] 
in each channel. 4.3 Results Figures 7-12 were generated with this program. Figures 7, 8, and 9 show 
the importance of coordinating the light ray sampling pro- cess with the rex resolution. Sending too 
few light rays results in a noisy radiosity estimate from the rex, and too coarse a rex results in blocky 
appearance. When the rex buckets are approxi- mately screen pixel size and the light ray density deposits 
several photons per bucket (at least 10, s~y), the results are satisfac-tory. We estimate the radiosity 
using a function that is constant within each bucket; this simple estimator accounts for the blocki- 
ness of the images. If bilinear interpolation were used, as in most radiosity algorithms, we could trade 
off blockiness for blurriness. Figure 10 shows adaptive subdivision of a rex quadtree, split- ting more 
densely near shadow edges (the current splitting cri- teria cause unnecessary splitting near the border 
of the square). Its rex quadtree is shown in figure 11. Figure 12 shows off some of the effects that 
are simulated by this algorithm.  @SIGGRAPH '90, Dallas, August 6-10, 1990 [Buckalew89] Chris Buckalew, 
Donald FusseU, "Illumination Networks: Fast Realistic Rendering with General Reflectance Functions", 
Computer Graphics (SIGGRAPH '89 Proceedings), vol. 23, no. 3, July 1989, pp. 89-98. [Cohengg] Michael 
F. Cohen, Donald P. Greenberg, "The Hemi-Cube: A Radiosity Solution for Complex Environments", Computer 
Graphics (SIGGRAPH '85 Proceedings), vol. 19, no. 3, July 1985, pp. 31-40. [Cohen86] Michael F. Cohen, 
Donald P. Greenberg, David S. ]rnmel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic 
Image Syn- thesis", [EEE Computer Graphics and Applications, Mar. 1986, pp. 26-35. [CohenS8] Michael 
F. Cohen, Shenehang Eric Chen, John R. Wallace, Don- ald P. Greenberg, "A Progressive R.ellnement Approach 
to Fast R.~.- diosity Image Generation", Computer Graphics (SIGGRAPH '88 Pro- eeedings), vol. 22, no. 
4, Aug. 1988, pp. 75-84. [Cook84] Robert L. Cook, Thomas Porter, Loren Carpenter, "Distributed Ray Tracing", 
Computer Graphics (SIGGRAPH '84 Proceedings), vol. 18, no. 3, July 1984, pp. 137-145. [Cook86] P~obert 
L. Cook, "Stocha~stie Sampling in Computer Graphics", ACM Transactions on Graphics, vol. 5, no. 1, Jan. 
1986, pp. 51-72. [Dippe851 Mark A. Z. Dippe, Erling Henry Wold, "Antiallaslng Through Stochastic Sampling", 
Computer Graphics (SIGGRAPH '85 Proceed- ings), vol. 19, no. 3, July 1985, pp. 69-78. [Gora184] Cindy 
M. Goral, Kenneth E. Torrance, Donald P. Greenberg, Bennett Battaile, "Modeling the Interaction of Light 
Between Diffuse Surfaces", Computer Graphics (SIGGRAPH '84 Proceedings), vol. 18, no. 3, July 1984, pp. 
213-222. [Hallg9] Roy Hall, Rlumination and Color in Computer Generated lmagery, Springer Verlag, New 
York, 1989. [I-Iockbert84] Paul S. Heekbert, Pat Hanrahan, "Beam Tracing Polygonal Objects", Computer 
Graphics (SIGGRAPH '84 Proceedings), vol. 18, no. 3, July 1984, pp. 119-127. [Heckbert86] Paul S. Heckbezt, 
"Survey of Texture Mapping", 1EEE Com- puter Graphics and Applications, vol. 6, no. 11, Nov. 1986, pp. 
56-67. [ImmelS6~ David S. Immel, Michael F. Cohen, Donald P. Greenherg, "A Radiosity Method for Non-Diffuse 
Environments", Computer Graphics (SIGGRAPH '86 Proceedings), vol. 20, no. 4, Aug. 1986, pp. 133- 142. 
 [Kajiya88] James T. Kajiya, "The Rendering Equation", Computer Graph- ics (SIGGRAPH '86 Proceedings), 
vol. 20, no. 4, Aug. 1986, pp. 143-150. [Lee85] Mark E. Lee, 1Lichard A. Redner, Samuel P. Uselton, "Statistically 
Optimized Sampling for Distributed Ray Tracing", Computer Graph- ics (SIGGRAPH '85 Proceedings), vol. 
19, no. 3, July 1985, pp. 61-67. [Mitchell87] Don P. Mitchell, "Generating Antialiased Images at Low 
Sam- piing Densities", Computer Graphics(SIGGRAPH '87 Proceedings), vol. 21, us. 4, July 1987, pp. 65-72. 
 [INishita85] Tomoyukilqishita, EihachiroNakamae, "Continuous Tone Rep- resentation of 3-D Objects Taking 
Account of Shadows and lute,reflec- tion", Computer Graphics (SIGGRAPH '85 Proceedings), voh 19, no. 
3, July 1985, pp. 23-30. [Painter89] James Painter, Kenneth S]oan, "Antialiased Ray Tracing by Adaptive 
Progressive Refinement", Computer Graphics (SIGGRAPH '89 Pxoceedings), vol. 23, no. 3, July 1989, pp. 
281-288. [Keeves87] William T. Reeves, David H. Salesin, Robert L. Cook, "Ren- dering Antialiascd Shadows 
with Depth Maps", Computer Graphics (SIGGRAPH '87 Proceedings), vol. 21, no. 4, July 1987, pp. 283-291. 
[Samet90] Hanan Samet, The Design and Analysis of Spatial Data Struc- tures, Reading, MA, Addison-Wesley, 
1990. [Shaog8] Min-Zhi ShaD, Qun-Slieng Peng, You-Dong Liang, "A New Ra- diosity Approach by Procedural 
Refinements for Realistic Image Syn- thesis", Computer Graphics (SIGGRAPH '88 Proceedings), vol. 22, 
us. 4, Aug. 1988, pp. 93-101. [Siegel81] Robert Siegel, John R. Howell, Thermal Radiation Heat Trans- 
fer, Hemisphere Publishing Corp., Washington, DC, 1981. [SiUion89] Francois Sillion, Claude Puech, ~A 
General Two-Pass Method Integrating Specular and Diffuse ReflectionS, Computer Graphics(SIC- GRAPH '89 
Proceedings), vol. 23, no. 3~ July 1989~ pp. 335-344. [Silvermang6] B.W. Silverman, Density Estimation 
for Statistics and Data Analysis, Chapman and Hall, London, 1986. [Strnuasg8] Paul S. Strauss, BAGS: 
The Brotvn Animation GenerationSys- tern, PhD thesis, Tech. Report CS-88-2, Dept. of CS, Brown U, May 
1988. [Von Herren87] Brian Von Herren, Alan H. Burr, "Accurate Triangula- tions of Deformed, Intersecting 
Surfaces", Computer Graphics (SIC-GRAPH '87 Proceedings), vol. 21, no. 4, July 1987, pp. 103-110. [WallaceS7] 
John R. Wallace, Michael F. Cohen, Donald P. Greenber8~ "A Two-Pass Solution to the Rendering Equation: 
A Synthesis of Ray Tracing and Radiosity Methods", Computer Graphics (SIGGRAPH '87 Proceedings), vol. 
21, no. 4, July 1987, pp. 311-320. [Wallace89] John R. Wallace, Kells A. Elmquist, Eric A. Haines, "A 
Ray Tracing Algorithm for Progressive Radiosity", Computer Graphics (SIGGRAPH '89 Proceedings), vol. 
23, no. 3, July 1989, pp. 315-324. [Ward88] Gregory J. Ward, Francis M. Rubinstein, Robert D. Clear, 
"A Ray Tracing Solution for Diffuse Interrefleetion", Computer Graphics (SIGGRAPH '88 Proceedings), vol. 
22, no. 4, Aug. 1988, pp. 85-92. [Warnock69] John E. Warnoek, A Hidden Surface Algorithm for Computer 
Generated Halftone Pictures, TR 4-15, CS Dept, U. of Utah, June 1969. [Watt90] Mark Watt, "Light-Ware, 
interaction using Backward BeamTrae ing', Computer Graphics (SIGGRAPH '90 Proceedings), Aug. 1990. [Whlttedg0] 
Turner Whirred, "An Improved Illumination Model for Shaded Display"~ CACM, voh 23, no. 6, June 1980, 
pp. 343-349. [Wllllams78] Lance Williams, "Casting Curved Shadows on Curved Sur- faces", Computer Graphics 
(SIGGRAPH '78 ProeeedingS)r voL 12, no. 3, Aug. 1978, pp. 270-274.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97896</article_id>
		<sort_key>155</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Adaptive mesh generation for global diffuse illumination]]></title>
		<page_from>155</page_from>
		<page_to>164</page_to>
		<doi_number>10.1145/97879.97896</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97896</url>
		<abstract>
			<par><![CDATA[Rapid developments in the design of algorithms for rendering globally illuminated scenes have taken place in the past five years. Net energy methods such as the hemicube and other radiosity algorithms have become very effective at computing the energy balance for scenes containing diffusely reflecting objects. Such methods first break up a scene description into a relatively large number of elements, or possibly several levels of elements. Energy transfers among these elements are then determined using a variety of means. While much progress has been made in the design of energy transfer algorithms, little or no attention has been paid to the proper generation of the mesh of surface elements. This paper presents a technique for adaptively creating a mesh of surface elements as the energy transfers are computed. The method allows large numbers of small elements to be placed at parts of the scene where the most active energy transfers occur without requiring that other parts of the scene be needlessly subdivided to the same degree. As a result, the computational effort in the energy transfer computations can be concentrated where it has the most effect.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31071512</person_id>
				<author_profile_id><![CDATA[81100210909]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Campbell]]></last_name>
				<suffix><![CDATA[III]]></suffix>
				<affiliation><![CDATA[Department of Computer Sciences, The University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68424</person_id>
				<author_profile_id><![CDATA[81100584372]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Fussell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Sciences, The University of Texas at Austin, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74367</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baum, Daniel R., Holly E. Rushmeier and 3ames M. Winget, Improving R~diosity Solutions Through the Use of Analytically Determined Form-Factors, Computer Graphics (SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp. 325-334.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74343</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chin, Norman and Steven Feiner, Near Real-Time Shadow Generation Using BSP Trees, Computer Graphics (SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp. 99-106.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F. and Donald P. Greenberg, A R~- diosity Solution for Complex Environments, Computer Graphics (SIGGRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 31-40.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, David S. Immel and Philip J. Brock, A Radiosity Solution for Complex Environments, IEEE Computer Graphics and Applications Vol. 6, No. 3, March 1986, pp. 26-35.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Shenchang Chen, John. Wallace, Donald P. Greenberg, A Progressive Refinement Approach to Fast Radiosity Image Generation, Computer Graphics (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 1988, pp. 75-84.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter, Loren Carpenter, Distributed Ray Tracing, Computer Graphics (SIG- GRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. }11-120.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry, Zvi M. Kedem and Bruce Naylor, On Visible Surface Generation by A Priori Tree Structures, Computer Graphics (SIGGRAPH '80 Proceedings), Vol. 14, No. 3, July 1980, pp. 124-133.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile, Modeling the Interaction of Light between Diffuse Surfaces, Computer Graphics (SIGGRAPH '84 Proceedings), Vol. 18, No. 3, July 1984, pp. 213-222.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kajiya, Ja.mes T., The Rendering Equation, Computer Graphics (SIGGRAPtI '86 Proceedings), Vol. 20, No. 4, August 1986, pp. 143-150.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>909951</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Naylor, Bruce, A Priori Based Techniques for Determining Visibility Priority for 3-D Scenes, PhD Dissertation, University of Texas at Dallas, May, 1981.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki and Eihachiro Nakamae, Continuous Tone Representation of Three-Dimensiort~l Objects Taking Account of Shadows and Interreflection, Computer Graphics (SIGGRAPH 85 Proceedings), Vol. 19, No. 3, July 1985, pp. 22-30.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki, I. Ok~mura and Eihachiro Nakamae, Shading Models for Point and Linear Light Sources, ACM Transactions on Graphics, Vol. 4, No. 2, April 1985, pp. 124-146.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert and John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC, 198t.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37421</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Thibault, William and Bruce Naylor, Set Operations on Polyhedr~ Using Binary Sp~ce Partitioning Trees, Computer Graphics (SIGGRAPH 87 Proceedings), Vol. 21, No. 3, July 1987, pp. 153-162.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Kells A. Elmquist, El'ic A. Haines, A Ray Tracing Algorithm for Progressive Radiosity, Computer Graphics (SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp. 315-324.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Ward, Gregory J., Frances M. Rubinstein, Robert D. Clear, A Ray Tracing Solution for Ditfuse Interreflection, Computer Graphics (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 1988, pp. 85-92.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, An Improved Illumination Model for Shaded Display, Communications of the A CM, Vol. 23, No. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Adaptive Mesh Generation for Global Diffuse Illumination A. T. Campbell, III, and Donald S. Fussell 
 Department of Computer Sciences The University of Texas at Austin Austin, TX 78712 ABSTRACT Rapid developments 
in the design of algorithms for rendering globally illuminated scenes have taken place in the past five 
years. Net energy methods such as the hemicube and other radiosity algorithms have become very effective 
at comput- ing the energy balance for scenes containing diffusely reflect- ing objects. Such methods 
first break up a scene description into a relatively large number of elements, or possibly sev- eral 
levels of elements. Energy transfers among these ele- ments are then determined using a variety of means. 
While much progress has been made in the design of energy trans- fer algorithms, little or no attention 
has been paid to the proper generation of the mesh of surface elements. This pa- per presents a technique 
for adaptively creating a mesh of surface elements as the energy transfers are computed. The method allows 
large numbers of small elements to be placed at parts of the scene where the most active energy trans-fers 
occur without requiring that other parts of the scene be needlessly subdivided to the same degree. As 
a result, the computational effort in the energy transfer computations can be concentrated where it has 
the most effect. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation-Display 
algorithms. 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. General Terms: Algorithms 
Additional Key Words and Phrases: global illumination, radiosity, mesh-generation, diffuse, data structure, 
incre-mental. 1. INTRODUCTION Accurate modeling of illumination has long been a goal of computer graphics. 
Until ten years ago, local illumination Permission to copy without fee all or part of this material is 
granted provided that the copies are not made or distributed for direct commercial advantage, the ACM 
copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. was the only factor generally considered. The development of ray tracing 
for handling global specular reflection and re- fraction [17], and of net energy techniques for handling 
global diffuse illumination [8] [3] [11] [12] led researchers to realize that these effects could and 
should be modeled, although the computational burden of doing so can be great. While great strides have 
been made in improving the ef- ficiency of ray tracing for specular illumination, extensions of ray tracing 
to handle diffuse lighting effects remain quite expensive [6] [16]. Net energy methods such as hemicube 
and other types of radiosity algorithms are better suited to global diffuse illumination both because 
the energy distri- bution throughout the scene can be computed in a view-independent way and because 
such techniques as progres-sive refinement [5] can make the production of approximate solutions reasonably 
efficient. Methods for computing the energy balance in globally illu- minated scenes in which M1 surfaces 
are not perfect specular reflectors involve the numerical integration of a large system of highly interrelated 
equations [9]. Ray tracing techniques do this using Monte Carlo methods, while the most popular net energy 
methods based on hemicubes essentially use the rectangle rule for integration. The latter process consists 
of two steps. First, the surfaces in the scene are subdivided into a number of relatively small surface 
patches of equal size. Following this, a variety of algorithms have been used to distribute the energy 
initially available from light emit- ting surfaces throughout the scene. In some cases, energy distribution 
algorithms have incorporated techniques to re- fine the initial surface subdivision as needed in regions 
of significant intensity gradation. The major step in the development of adaptive refine-ment of surface 
meshes was taken with the development of patch-element radiosity computations in [4]. This technique 
subdivides energy receiving surfaces wherever an initial cM- culation indicates significant intensity 
gradations are occur- ring. The new subdivided surfaces, called elements, are used to refine form-factor 
calculations for larger patches, thereby allowing more accurate illumination computations to be per- 
formed at reasonable cost. While this method was a great step forward in enabling effective global illumination 
compu- &#38;#169; 1990 ACM-0- 89791-344- 2/90/008/0155 $00.75 155 SIGGRAPH '90, Dallas, August 6-10, 
1990 partition+ ~~f ~ SiUiCi l I < leak ~ / grid lines Figure 1: Light Leaking rations to be performed, 
it suffers several drawbacks. First, since shadow boundaries are never explicitly determined, the ability 
of the initial patch calculations to detect areas of in- tensity gradation where shadows occur is critical. 
SmM1 ob- jects casting shadows can easily be missed if the initial patch sizes are too large. Second, 
since emitting surfaces are not subdivided, accurate soft shadowing is not done. Finally, the subdivision 
of receiving polygons into a regular grid can lead to the phenomenon of "light leaks" where the grid 
par- titions along a surface do not coincide with light-occluding polygons abutting the surface and thus 
allow light to leak past the occluding polygons, as shown in Figure 1. Besides these mesh-related problems, 
the matrix/hemicube method used suffered from problems with time and memory requirements and aliasing 
of the results caused by the use of hemicubes. Recent developments have resulted in great improvements 
in these latter areas. Speed has been improved by replacing the original technique of si- multaneously 
solving all the integral equations in the system by a progressive refinement technique which quickly 
com- putes a good approximation and then gradually refines it to converge on the solution, as well as 
by exploiting the capa- bilitiesof many machines to perform hardware depth-buffer calculations [5]. This 
technique involves distributing energy from sources throughout the scene in decreasing order of source 
intensity. As a result, hemicube aliasing problems and errors caused by the violation of form-factor 
approximation assumptions are more severe than those of matrix-solution methods [1] [15]. Moreover, it 
is difficult to adaptively refine a surface mesh using this technique without sacrificing much of the 
performance advantage gained. In [15], a ray-tracing radiosity computation technique was introduced which 
alleviates hemicube aliasing and seems better suited to adaptive mesh refinement. This method gives improved 
results in the computation of penumbra ef- fects if the initial mesh is fine enough. However, the use 
of point sampling to determine visibility in form-factor calcula- tions still suffers from an inability 
to detect errors caused by missing shadows cast by objects small relative to the initial patch size. 
In this paper we present a new radiosity approach for global diffuse illumination which automatically 
generates an initial surface mesh by efficiently subdividing input surfaces along shadow boundaries. 
This initial mesh is then adap- tively refined using both further shadow boundary subdivi- sion and intensity-gradient 
refinement. Radiosity computa- tions are done using a ray-tracing approach like that of [15], although 
ray tracing is not required for visibility calculation due to the shadow boundary subdivision. In contrast 
with existing radiosity techniques, the surface elements created are rarely rectangular. This technique 
alleviates the prob- lems of potentially missed objects and light leaks. The following section reviews 
the essential theory and equations of illumination necessary for presentation of this work. Section 3 
presents the algorithm in full detail. Our implementation and results are detailed in Section 4, includ- 
ing test data, timing figures, and analysis. 2. SURFACE SUBDIVISION Radiosity approaches to global diffuse 
illumination compu- tation involve the solution of a large system of integral equa- tions which express 
the energy transfers among all the sur- face elements in an energetically closed environment. These equations 
take the form n B~A; = EiA~ + pl E BjAjFi5 (1) j=l where Bi is the radiosity (radiated energy per unit 
area) of surface i, Ai the area of the surface, .El the emitted energy per unit area, pi the reflectance 
of the surface, and Fij the form factor from surface j to surface i. The form factor Fij gives the fraction 
of energy leaving surface j that arrives at surface i, and is given by the equation cos os F,j = ~-i 
, rr~j V dA'dAj (2) where V is a boolean which is 1 when dAj is visible to dAi and 0 otherwise, and 
all other terms are as shown in Figure 2. The system of equations in 1 can be solved to an arbitrary 
desired accuracy for the radiosities of the surface elements if we know the form factors, reflectances, 
and areas accurately. This requires solving the integral equations in 2, or, when this is impossible, 
finding reasonable approximate solutions to them. Approximation can be done by assuming that the finite 
surface elements are very small relative to their dis- tances apart, and that the surfaces are either 
entirely visible or entirely invisible to each other. Under these conditions, V can be determined by 
a simple hidden surface computa- tion, and all other terms in the integrand become constants across the 
surfaces involved, so that 2 reduces to Nj ~dAj / Figure 2: Form Factor Geometry Fq = Ai cos ¢ cos 0 
(3) for visible surfaces and 0 otherwise. For any interesting scene, these assumptions do not hold for 
input polygons. Therefore, these surfaces are broken up into smaller patches for which the assumptions 
are reasonable for most pairs of patches. Even in this case, the assumptions are Unlikely to be reasonable 
unless the number of patches generated is unreasonably large, so a better approach is to numerically 
approximate the integrals. This can be done by breaking the source patch into n pieces of size ~SAj and 
the receiving patch into m pieces of size gA~, so that 2 may be approximated by 7rr~ l 8Ai~Aj (4) = /=1 
in the general case. If only the source patch needs to be subdivided to make the assumptions reasonable, 
then this simplifies to Fq = ~ k~l c°s eki COS Ùki Vki t~Aj (5) = ~rki and likewise to Fq= cos¢ cos 0#l 
V#z (8) when only the receiving patch needs subdivision. The patch-element adaptive mesh subdivision 
used with matrix and progressive refinement solution methods use pri- marily the receiver subdivision 
approach of 6, although in some difficult cases sources are subdivided also. The ray tracing method of 
[15] can replace subdivision with point sampling in the latter case. Indication that refinement of initial 
patches into elements is needed is obtained by mea- suring the intensity gradient between neighboring 
vertices in the mesh after initial radiosity computation, and then subdividing as necessary until a desired 
gradient threshold is reached. This works well as long as the initial mesh of patches is sufficiently 
dense, but if shadow boundaries are missed in the initial step, further subdivision will not take place. 
If in spite of subdivision individual elements extend to both sides of abutting polygons, light leaks 
are also possible. Our approach not only refines the mesh automatically, but generates the initial mesh 
automatically as well. We consider the input polygons to be the initial mesh and com- bine shadow boundary 
determination with intensity gradient criteria to steer further subdivision. As a result, no shadow boundaries 
are missed, light leaks are prevented, and the shape of the mesh elements more closely follows final 
isoin- tensity gradations. The method is based on Equation 4, where both source and receiving elements 
are subdivided. 3. ADAPTIVE MESH COMPUTATION As we have suggested, the initial mesh for the algorithm 
is a set of input polygons. Our strategy is to process these in de- creasing order of available energy, 
meaning that the most en- ergetic light source is the first polygon processed. The algo- rithm proceeds 
much like the ray-tracing progressive radios- ity technique of [15]. No hemicubes are used for form-factor 
computation. Rather, rays are cast between emitting and receiving elements to estimate form-factors between 
these elements. These rays are not, however, used for visibility computation. Once selected, a light 
source polygon is tested to ensure that it is small enough and far enough away from the rest of the scene 
that no penumbra calculations are necessary. If this is not the case, the light polygon must be subdivided 
into pieces which meet these criteria. Visibility is determined through the use of a BSP-tree based shadow 
algorithm similar to that of [2]. As a source element is being processed, each of the other polygons 
in the scene is considered in turn. These are sorted in order of increasing distance from the centroid 
of the source using the BSP tree. The first step in the processing of one of these polygons is to determine 
whether any of the polygons closer to the source casts a shadow on the polygon under consider- ation. 
If so, the polygon is split along the shadow boundary (note that sharp shadows generated using the source 
een-troid as a point light source are used). Once this splitting is complete for all potentially shadowing 
polygons, the original polygon has been subdivided into a set of receiving elements, each of which can 
be considered totally visible or totally hid- den from the source. SIGGRAPH '90, Dallas, August 6-10, 
1990 lira Viewer (* cast shadows and compute illumination *) a Procedure IllumWorld(NumPoly~, PolyList) 
Begin Tree := BspBuild(NumPolys, PolyList); While EnergyRemains(Tree) Do Begin Src := FindBrightest(Tree); 
 BspTraverse(Tree, Src, FRONTTOBACK, NumRcv, RcvPolys); DivSr¢(Src, RcvPolys[l], NumSrc, SrcPieces); 
 For i := 1 To NumSrc Do Begin Tree :ffi SbspShadow(SrcPieces[i], NumRcv, RcvPieces); IllumPieces(Tree); 
 End; Dissipate(Src)  End End; Figure 3: Overview of Algorithm Once the visibility determination 
is complete, form factors for each of the visible receiving elements are calculated. If these differ 
by more than a user-specified tolerance, the re-ceiving element is subdivided and form factors recalculated 
for each resulting element until the tolerance is met. These form factors are normalized to ensure energy 
balance and are then used to compute radiosities and sample the incoming energy at each receiving element 
vertex. This provides an intensity for each vertex, which can be used as a basis for Gouraud shading 
if it is desired that the image be rendered as the mesh is progressively determined. Further subdivision 
may be deemed necessary if the in- tensity variation across the element exceeds a user-supplied threshold. 
In such a case, the receiving element is subdivided along its largest dimension, and the energy estimation 
step is repeated until the variations for all the elements involved are below the threshold. Note that 
after each illumination step of our method, the variation limit is maintained. This is in contrast to 
the methods of [4], in which an entire coarse global solution is performed before any element subdivision 
is involved. After illumination, we add the current polygon to the list of potential shadowing polygons 
and move on to the next candidate for illumination. When one source element has fully scattered its light, 
we repeat the process for the remaining source elements on the current light source polygon. Once the 
polygon has dis-tributed all its available energy, we move to the next bright- est source polygon and 
repeat the process. This is continued until the total untransmitted energy has converged to zero within 
some tolerance. This tolerance is a user-supplied frac- tion of the input energy. These steps are summarized 
in Figure 3. / / /\ C e f / fgdeacb g (a) (b) (c) Figure 4: BSP Tree Example We will now discuss each 
of these steps in greater detail. 3.1. INITIALIZATION AND DATA STRUCTURES In order to facilitate the 
sorting of polygons and elements in- volved in shadow determination, as well as to perform visible surface 
determination when progressive rendering is done, the input polygons are used to generate a BSP tree 
repre- senting these elements as in [7]. The reader may recall that a BSP (Binary Space Parti- tioning) 
tree can be used to represent a collection of polygons in a volume of space by recursively subdividing 
the volume along planes determined by the orientations of the polygons within the volume. Polygons may 
be chosen in any order to determine these partitioning planes, with the most desirable order being one 
which results in the fewest polygons being split along plane boundaries as the process proceeds. (Note 
that determining such an optimal order is known to be NP- complete [10].) The resulting data structure 
is a binary tree, in which each interior node represents a partitioning plane and its defining polygon, 
along with any other coplanar poly- gons that may exist in the input database, and the leaf nodes represent 
convex volumes of space determined by the parti- tioning. Henceforth we will ignore these leaf nodes 
and as-sume that all nodes represent partitioning planes/polygons. Figure 4(a) shows a two dimensional 
example, in which line segments represent polygons. Figure 4(b) shows the BSP tree for this scene. As 
described in [7], BSP trees can be used to determine the visibility priority of a collection of polygons 
from any view- ing position. This is achieved by using an inorder traversal of the tree. Each node is 
processed recursively by inserting the coordinates of the viewing position into the planar equation of 
the partitioning plane at that node. The sign of the result indicates whether the viewing position is 
in the "front" half- space determined by the plane, the "back" halfspace, or on the plane itself, where 
~qront" and '~back" are relative to the plane normal. If the viewing position is in one of the half- 
spaces, the subtree representing that halfspace is processed first. If the viewing position is on the 
plane, the subtrees can be processing in any order. Once the first subtree has been processed, the polygons 
within the current node can be output and the other subtree processed to terminate the /'T7 a a b/ \c 
b/\c Figure 5: Polygon Substructuring routine for that node. Thus the exact order of traversal is de- 
termined by the viewing position, and it is guaranteed that this order will output polygons in front 
to back order relative to the viewing position. Further details can be obtained in [7]. Figure 4(c) shows 
the output order using this algorithm on the viewing position and scene shown in Figure 4(a). The BSP 
tree calculated in the initialization step, which we call a polygon BSP tree (pBSP tree) is used to sort 
surface elements in front to back order from the point of view of the eentroid of each emitting element 
in turn. This ordering is used to speed up shadow calculations. Some other operations are also enhanced 
through the use of the pBSP tree. In the processing of a source polygon, before all the other polygons 
are sorted in front to back order, backfacing polygons are removed from consideration and polygons in 
the back halfspace of the emitting surface's plane are also removed. The pBSP tree can also be used for 
visible surface determination for progressive rendering when the energy transfer computations at each 
step are complete using the technique of [7]. In processing a source element, all polygons that are in 
the front halfspace of this element and are not backfacing are sorted in front to back order using a 
pBSP tree traversal from the point of view of the centroid of the emitter. We call a node of the pBSP 
tree a pnode. It contains the equation of the plane passing through a set of coplanar input mesh polygons, 
the boundary representations of those polygons, and a representation of the surface elements into which 
each of these polygons has been subdivided. The collection of elements for each polygon in the pnode 
forms a BSP tree in two rather than three dimensions, which we call an element BSP tree (eBSP tree). 
This eBSP tree initially consists of a single enode representing the input polygon for that element tree. 
Surfaces in an eBSP tree are always found at the leaves, with internal enodes representing splitting 
lines. When an element at one of these leaves is split, its enode is replaced by a tree whose root represents 
the splitting line, with left and right children being the new leaves representing the two new elements 
formed by the split. This process is illustrated in Figure 5. 3.2. LIGHT SOURCE SUBDIVISION For each 
iteration of the illumination process, we use the polygon with most untransmitted energy as the light 
source. After the source polygon, S, is chosen, we use the pBSP tree to determine R, the nearest frontfacing 
receiver poly- gon. Then we calculate A, the solid angle subtended by S in the viewing hemisphere centered 
at R's midpoint. If A is small enough, then S may be approximated as a point light source for shadowing 
computations. We have experi- mentally determined that .005 steradians is an effective size tolerance. 
The average color of the source polygon is used as the light color in illumination calculations. If the 
light source exceeds our size criterion, we first check if it has already been subdivided by previous 
calculations. If so, the the size check is recursively applied to elements suc- cessively deeper in the 
subdivision hierarchy until either we find small enough pieces or the substructure can be traversed no 
further. If bottom level snbpolygons are too large, they are subdivided across their long axes until 
the size criterion is met. 3.3. SHADOW BOUNDARY COMPUTATIONS The first step in processing a receiving 
polygon for any given emitting element is to determine whether any of the polygons closer to the emitter 
casts a shadow on the current receiv-ing polygon. This is done by testing the receiving polygon against 
the merged shadow volume generated by the emit- ter centroid and closer polygons. This volume consists 
of a collection of semi-infinite pyramids, one pyramid emanat- ing from each shadowing polygon. The merged 
structure is maintained as a second BSP tree, called a shadow volume BSP tree (sBSP tree), similar to 
the SVBSP trees of [2], whose nodes we refer to as snodes, The sBSP tree is made up of the shadow volume 
planes cast by each of the previously-processed polygons. Internal snodes represent clipping planes, 
and leaf snodes represent regions which are classified as either totally lit or totally in shadow with 
respect to the current light source. Elements are filtered down this tree to determine which of their 
regions are lit or in shadow. Our algorithm is similar to that of [2], but features im- portant improvements 
in the shadow testing algorithm. We use the pBSP tree to generate a front-to-back ordering from the light 
source position. Polygons are tested for shadows in this order, which guarantees that no polygon will 
be pro- cessed before any that can shadow it. After shadow testing, the processed polygons are added 
to the sBSP tree. For the illumination step, we start out with the light source position, the pBSP tree 
of input polygons, and an empty merged shadow volume. Each polygon is filtered down the sBSP tree. If 
the entire polygon is completely lit or shadowed, the polygon does not need to be subdi- vided. If, however, 
the polygon crosses a shadow boundary, the polygon is split across this edge. When a polygon is split, 
we must refine its eBSP. Each split adds a level to the sBSP tree. We maintain the elements SIGGRAPH 
'90, Dallas, August 6-10, 1990 in this structure for efficiency in future illumination passes. This 
differs from [2], who maintain a simple linked list of fragments. After the first illumination pass, 
many of the original poly- gons may have been split multiple times by previous shadow planes. As a polygon 
is tested for shadows, we first check if the original polygon boundary is totally lit or in shadow. If 
so, we are done with this polygon. If not, we recursively descend the eBSP tree, each time checking if 
the current element is totally lit or shadowed. In this way wc are poten- tially able to avoid testing 
all the leaf enodes individually. When we finally do have to process a leaf enode, we know that it definitely 
falls across a shadow edge and must be split. Pseudocode is provided in Figure 6. A straightforward 
implementation of the described algo- rithm produces a mesh which is indeed fine and coarse in all the 
right places. However, the continuous splitting of ele- ments across shadow boundaries throughout all 
illumination calculation leads to excessive mesh refinement at shadow boundaries. In addition to the 
general undesirability of too fine a mesh, the memory costs can soar dramatically. Since shadow boundaries 
become less important after the brighter light sources are processed, at some point we can terminate 
splitting across shadow boundaries to prevent large numbers of unnecessary small elements from being 
cre- ated. The polygon can still be split for form factor computa- tion as usual, but its pieces may 
be merged back after illumi- nation computations have been made. We have found that stopping the shadow 
clipping after half of the light has been dissipated is effective. Using this optimization, light leaks 
may occur, but if a proper clipping termination threshold is used, the energy levels of the light sources 
are low enough to make this effect negligible. 3.4. INTENSITY CALCULATIONS Once shadow calculations are 
done for a particular source-receiver pair, the next step tests the quality of the resulting receiving 
mesh against our criterion of balanced energy dis- tribution across mesh elements. This is of course 
done only for elements which have previously been determined to be completely visible to the light source. 
The form factor for the receiving element is first estimated. This is done by comput- ing the point to 
point form factors between the centroid of the emitter and each of the receiver's vertice:~. These vertex 
form factors are averaged and multiplied by the receiveFs area to provide a form factor approximation 
for the entire element. Note that in the event that the receiver has a large as-pect ratio, there can 
be significant differences in the form factors at its vertices. In such cases, the two longest edges 
of the receiver can be bisected to form a pair of elements of lower aspect ratio,-and the vertex form 
factors for each (* Use sBSP tree for shadowing $) Procedure SbspShadow(Src, NumRcv, Rcv) Begin ShadTree 
:= Sbsplnit(); For i := I To NumRcv Do Begin ShadowCalc(Src, ShadTree, Rcv[i]); ShadTree := SbspUpdate(Src, 
ShadTree, Rcv[i]) End; SbspDestroy(ShadTree)  End; (* Traverse nested polygons *) (* LeafShadovCalc() 
does single-level sBSP shadowing, as in [2]. *) Procedure ShadowCalc(Src, Tree, Rcv) Begin Div0nSrcPlane(Src, 
Rcv, Front, Back); If Front = NIL Then SetIllum(Rcv, NONE); Else If HasChildren(Rcv) Then Begin If 
(Back <> NIL) Then Begin ShadowCalc(Src, Tree, Rcv. Pos); ShadowCalc(Src, Tree, Rcv. Neg) End; Else 
Begin PolyCopy(Rcv, Rcvl); LeafShadowCalc(S, Tree, Rcvl); If (HasIllum(Rcvl, NONE)) Then SetIllum(Rcv, 
NONE) Else If (HasIiIum(RcvI,TOTAL)) SetIllum(Rcv, TOTAL) Else Begin SetIllum(Rcv, PARTIAL); LeafShadowCalc(S, 
Tree, Rcv.Pos); LeafShadowCalc(S, Tree, Rcv.Neg) End End End Else Begin If (Back <> NIL) Then Begin 
SetIllum(Rcv, PARTIAL); AddChildren(Rcv, Front, Back); ShadowCalc(Src, Tree, Front)  End Else LeafShadowCalc(Src, 
Tree, Rcv); End End; Figure 6: Shadow Testing  5. CONCLUSIONS AND FURTHER WORK REFERENCES We have 
described an algorithm for adaptive mesh gener- [1] ation for global diffuse illumination. It operates 
by subdi- viding input polygons at shadow umbra boundaries relative to emitting elements, and then further 
subdividing until ap- proximately constant intensity for each illuminated element is obtained. The net 
result is a mesh whose density is propor- tional to its illumination. Using such a mesh in subsequent 
[2] energy transfer calculations concentrates the work done in these calculations where it will distribute 
the most energy in a way that complements such techniques as progressive re- finement. The adaptive mesh 
is itself computed by progres- sive refinement. Costs of shadow calculations are controlled [3] through 
the use of a nested BSP tree data structure in which the nodes of the overall polygon BSP tree themselves 
con- tain 2-dimensional element BSP trees to sort polygons and order shadow computations. [4] The current 
technique is still rather crude. For instance, our algorithm divides each light source into a worst case 
collection of elements which will cast reasonably accurate penumbras on even the closest surfaces. Explicitly 
calculat- ing penumbra and umbra boundaries may provide a more [5] effective technique for handling these 
regions. Also, stop- ping criteria for shadow clipping are currently ad hoc and need to be subjected 
to a proper illumination error analysis. Ultimately our goal is to use adaptive mesh generation as a 
means of accurately controlling illumination errors with- [6] out unduly multiplying the number of elements 
required throughout the scene. Achieving this goal will require a great deal of further analysis and 
adaptation of the mesh subdivision criteria. Robust criteria for subdividing emit- ters remain to be 
determined. Illumination errors caused by [7] point-to-point radiosity computation must be more carefully 
analyzed. Nevertheless, we believe that our technique rep- resents a promising step towards an understanding 
of mesh # generation constraints comparable to the understanding of energy distribution algorithms obtained 
over the past several [8] years. 6. ACKNOWLEDGEMENTS [9] We would like to thank Chris Buckalew, Don Speray, 
K.R. Subramanian, and Kelvin Thompson for their helpful discus- sions and suggestions. Thanks are due 
also to MIPS Com- puter Corp., John Beck and Jeff Carruth for the loan of one [lO1 of their workstations 
, and to the Applied Research Labo- ratory and the Center for High Performance Computing at the University 
of Texas at Austin for the use of their com- [11] puting facilities. We would especially like to thank 
ALFA Engineering, Inc., particularly Walter S. Reed and Philip D. Heermann, for access to their graphics 
workstation and for rewarding discussions. Baum, Daniel R., Holly E. Rushmeier and James M. Winget, 
Improving Radiosity Solutions Through the Use of Analytically Determined Form-Factors, Com-puter Graphics 
(SIGGRAPH '89 Proceedings), Vol. 23, No. 3, July 1989, pp. 325-334. Chin, Norman and Steven Feiner, Near 
Real-Time Shadow Generation Using BSP Trees, Computer Graph- ics (SIGGRAPH '89 Proceedings), Vol. 23, 
No. 3, July 1989, pp. 99-106. Cohen, Michael F. and Donald P. Greenberg, A R~ diosity Solution for Complex 
Environments, Computer Graphics (SIGGRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 31-40. Cohen, 
Michael F., Donald P. Greenberg, David S. Im- mel and Philip J. Brock, A Radiosity Solution for Com- 
plex Environments, IEEE Computer Graphics and Ap- plications Vol. 6, No. 3, March 1986, pp. 26-35. Cohen, 
Michael F., Shenchang Chen, John Wallace, Donald P. Greenberg, A Progressive Refinement Ap-proach to 
Fast Radiosity Image Generation, Computer Graphics (SIGGRAPH '88 Proceedings), Vol. 22, No. 4, August 
1988, pp. 75-84. Cook, Robert L., Thomas Porter, Loren Carpenter, Distributed Ray Tracing, Computer Graphics 
(SIC-GRAPH '85 Proceedings), Vol. 19, No. 3, July 1985, pp. 111-120. Fuchs, Henry, Zvi M. Kedem and Bruce 
Naylor, On Visible Surface Generation by A Priori Tree Struc-tures, Computer Graphics (SIG,GRAPH '80 
Proceed- ings), Vol. 14, No. 3, July 1980, pp. 124-133. Goral, Cindy M., Kenneth E. Torrance, Donald 
P. Greenberg, and Bennett Battaile, Modeling the Inter- action of Light between Diffuse Surfaces, Computer 
Graphics (SIGGRAPH '84 Proceedings), Vol. 18, No. 3, July 1984, pp. 213-222. Kajiya, James T., The Rendering 
Equation, Computer Graphics (SIGGRAPH '86 Proceedings), Vol. 20, No. 4, August 1986, pp. 143-150. Naylor, 
Bruce, A Priori Based Techniques for Determin- ing Visibility Priority for 3-D Scenes, FhD Dissertation, 
University of Texas at Dallas, May, 1981. Nishita, Tomoyukl and Eihachiro Nakamae, Continu-ous Tone Representation 
of Three-Dimensional Objects Taking Account of Shadows and Interreflection, Com-puter Graphics (SIGGRAPH 
85 Proceedings), Vol. 19, No. 3, July 1985, pp. 22-30. Q SIGGRAPH '90, Dallas, August 6-10, 1990 [12] 
Nishita, Tomoyuki, I. Okamura and Eihachiro Naka- mae, Shading Models for Point and Linear Light Sources, 
ACM Transactions on Graphics, Vol. 4, No. 2, April 1985, pp. 124-146. [13] Siegel, Robert and John R. 
Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washing- ton DC, 1981. [14] Thibault, 
William and Bruce Naylor, Set Operations on Polyhedra Using Binary Space Partitioning Trees, Com-puter 
Graphics (SIGGRAPH 87 Proceedings), Vol. 21, No. 3, July 1987, pp. 153-162. [15] Wallace, John R., Kells 
A. Elmquist, Eric A. Haines, A Ray Tracing Algorithm for Progressive Radiosity, Com-puter Graphics (SIGGRAPH 
'89 Proceedings), Vol. 23, No. 3, July 1989, pp. 315-324. [16] Ward, Gregory J., Frances M. Rubinstein, 
Robert D. Clear, A Ray Tracing Solution for Diffuse Interreflec- tion, Computer Graphics (SIGGRAPH '88 
Proceed-ings), Vol. 22, No. 4, August 1988, pp. 85-92. [17] Whitted, Turner, An Improved Illumination 
Model for Shaded Display, Communications of the A CM, Vol. 23, No. 6, June 1980, pp. 343-349.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97897</article_id>
		<sort_key>165</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Artificial reality with force-feedback: development of desktop virtual space with compact master manipulator]]></title>
		<page_from>165</page_from>
		<page_to>170</page_to>
		<doi_number>10.1145/97879.97897</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97897</url>
		<abstract>
			<par><![CDATA[A new configuration of Human Interface for "artificial reality" is discussed. This paper describes a method of implementing force-feedback in a virtual space manipulation system. The system is composed of two subsystems, a real-time graphic display system and a tactile input device with reaction force generator. A specialized graphics computer (Stardent TITAN) provides a realtime image of the virtual space. A 9 degree-of-freedom manipulator has been developed as a tactile input device. The manipulator applies reaction forces to the fingers and palm of the operator. The generated forces are calculated from a solid model of the virtual space. The performance of the system is exemplified in manipulation of virtual solid objects such as a mockup for industrial design and a 3D animated character.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.1.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.4.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40026665</person_id>
				<author_profile_id><![CDATA[81100382304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hiroo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Iwata]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Engineering Mechanics, University of Tsukuba, Tsukuba, Ibaraki, 305 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>319127</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Fisher,S.S., McGreevy,M., Humphries,J. and l~binett,W., "Virtual Environment Display System," ACM 1986 Workshop on Interctive 3D Graphics (North Carolina, Oct. 23-24, 1986)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>275628</ref_obj_id>
				<ref_obj_pid>29933</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Zimrnerman,T.G. and Lanier,J., "A Hand Gesture Interface Device," CHI+GI Conf.Proc., pp.189-192, 1987.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hirose,H. Koga,M. and Ishii,T., "3-Diraensional Interface Using Artificial Reality Technology," Proceedings of the 4th Symposium on Human Interface. pp.201-206, Tokyo, Japan, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Batter,J.J. and Brooks,F.P.,Jr. GROPE.I:"A Computer Diplay to the Sense of Feel." Proc. IFIP 1972, 759- 763.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>57168</ref_obj_id>
				<ref_obj_pid>57167</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brooks,F.P.flr., "Grasping Reality Through Illusion: Interactive Graphics Serving Science," Invited keynote address at the Fifth Conf. on Computer and Human Interation, Washington,D.C., May 17, 1988. Published in CHI'88 Proceedings, May 1988, 1-11. Addison wesley, 1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Minsky,M., Ouh-young,M., Steele,O., Brooks,F.P.,Jr., and Behensky,M., "Feeling and Seeing: Issues in Force Display" Computer Graphics Vol.24, No.2, pp.235-243, 1990.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Atkinson,W.D., Bond,K.E., Tribble,G.L., and Wilson~K.R., "Computing with Feeling," Compute. and Graphics, Vol.2, pp.97-103, Pergamon Press, 1977.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Agronin,M.L. "The design of a Nine-string Sixdegree-of-freedom Force-feedback joystick for telemanipulation," Proceedings of the NASA Workshop on Space Telerobotics, pp.341-348, Pasadena, CA, 1987.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>112710</ref_obj_id>
				<ref_obj_pid>112687</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Yokokoji,Y and Yoshikawa,T. "Control of Master Slave Manipulators for Object Teleperception," Proceedings of the 5th international Symposium on the Robotics Research, Tokyo, Japan, 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dudragne,J. et al., "A Generalized Bilateral Control Applied to Master-slave Manipulators," Proceedings of the 20th International Symposium on Industrial Robots, pp.435-442, Tokyo, Japan, 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Tsusaka,Y. Fukuizumi,T. and Inoue,H., "Parallel Manipulator: Its Design and Mechanical Characteristics," Journal of the Robotics Society of Japan. vol.5, no.3, 1987.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Artificial Reality with Force-feedback: Development 
of Desktop Virtual Space with Compact Master Manipulator Hiroo Iwata Institute of Engineering Mechanics 
University of Tsukuba Tsukuba, Ibaraki, 305 Japan ABSTRACT  A new configuration of Human Interface 
for "artifi- cial reality" is discussed. This paper describes a method of implementing force-feedback 
in a virtual space manipu- lation system. The system is composed of two subsys-terns, a real-time graphic 
display system and a tactile input device with reaction force generator. A specialized graphics computer 
(Stardent TITAN) provides a real-time image of the virtual space. A 9 degree-of-freedom manipulator has 
been developed as a tactile input device. The manipulator applies reaction forces to the fingers and 
palm of the operator. The generated forces are calcu- lated from a solid model of the virtual space. 
The perfor- mance of the system is exemplified in manipulation of vir- tual solid objects such as a mockup 
for industrial design and a 3D animated character. CR Categories and Subject Descriptors: 1.3.6 [Computer 
Graphic@Methodology and Techniques -interaction techniques; B.4.2 [Input/Output devices]; H.1.2 [Models 
and Principle@User/Machine Systems; J.6 [Computer-Aided Engineering]:Computer-aided design; General Terms: 
Algorithms, Performance, Human Fac-tors Addltional Key Words and Phrases: Artificial reality, Virtual 
reality, Input device, Force sense, Master mani- pulator, Real-time graphics 1. INTRODUCTION The recent 
evolution of intelligent systems requires natural interaction between machines and human beings. A configuration 
of human interface called "artificial real- ity" is discussed in this paper. The research objective of 
artificial reality is to present a computer-generated vir- Permission to copy without fee all or part 
of this material is granted providedthat the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. tual space to human operator's sense organs: 
eyes, ears, skin, and so on. Since the major channel of human recog- nition of the outer environment 
is the visual sense, real- time computer graphics is essential to artificial reality. Development of 
computer graphics has been focused on the generation of photo-realistic images, which requires large 
computational times. Recently, there has been widespread interest in real-time images corresponding with 
human action. An early use of artificial reality for human interface was proposed at NASA Ames Research 
Center in 198611]. Fisher, McGreevy, Humphries, and Robinett developed head-mouted display (HMD) and 
used a glove-like tactile input device (DataGlove). The DataGlove has been util- ized in research on 
telerobotics and user interface design. For example, Zimmerman and Lanier proposed operation of graph 
language[2] and Hirose et al. proposed operation of a slave manipulator[3]. Through these experiments 
in manipulation of virtual objects, the need for force output is recognized. Some works for force display 
devices are found in [4],[5] and [6]. The primary object of our research is implementa- tion of force-feedback 
in a manipulation system for vir- tual objects. Compared to presentation of visual and auditory information, 
methods for presenting tactile information have not been sufficiently developed. Here are 3 classes of 
tactile input devices: (1) glove (2) 3 dimensional mouse (3) master manipulator There have been 3 dimensional 
mice with a force-feedback handle controlled by nine strings. An example device, called "JoyString", 
was developed by Agronin in 198717][8]. These devices generate 6 degree-of-freedom reaction force, but 
their working volume is limited and there are singularities in their working spaces.  In the field of 
robotics research, master manipula-tors are used in teleoperation. Some examples of master- slave manipulators 
enabling teleperception of remote objects are found in [9] and [10]. Most master manipula- tors, however, 
have large hardware with high cost, which restricts their application areas. In our research, a compact 
9 degree-of-freedom manipulator has been developed as a tactile input device on a desktop. The manipulator 
generates reaction force  &#38;#169;1990 ACM-0-89791-344-2/90/008/0165 $00.75 | 65   O SIGGRAPH '90, 
Dallas, August 6-10, 1990 ment, which enables the operator to move the hand and fingers independently. 
Three actuators are set coaxially with the first joint of the thumb, forefinger and middle finger of 
the operator (see Figure 8). The last 3 fingers work together. DC servo motors are employed for each 
actuator. The maximum torque at each actuator shaft is 3 KO crn. Working angle of the thumb is 120 degrees 
and that of the other fingers are 90 degrees. We generate force to apply to the hand from the following 
formulae: 2 L = ~ F, (1) 2 M= S [ (~T°-p) * Fi] (2) i=o Fi [ (bt-bj) * (hl-bj) ] = 0 (3) where P : center 
of the palm p : position vector of P L : force vector at P M : moment vector at P F i : force vector 
at H i hi : position vector at H i bi : position vector at B i  The formula (1) indicates the balance 
of force. The for-mula (2) indicates the balance of moment. The formula (3) indicates that F i is involved 
in the same plan as the pantograph link. The formulae (1),(2), and (3) lead to nine dimensional simultaneous 
equations. The F i are obtained by solving the equations by the Gaussian method. Generated motor torques 
are calculated from the F i in the I/O processor.  3. METHOD OF MANIPULATION OF VIRTUAL SOLID OBJECTS 
3-1 Software Coldlguration The core module of the software is a solid model handler implemented on the 
graphics computer. A diagram of the data flow is illustrated in Figure 9. The I/O processor acquires 
the joint angles of the manipulator through the A/D converter, and calculates the position and orientation 
of the hand. A homogeneous transforma-tion is used in the calculation. The position and orienta-tion 
of the hand coordinate are first described with refer-ence to the base platform. In the next step, the 
hand coordinates are described with respect to the virtual space. The data of the hand coordinates and 
bending angle of the fingers are transmitted to the graphics com-puter. A solid model of virtual space 
is updated in accord with the received data. If a finger or the palm touches a virtual object, reaction 
force is generated. The force and moment vectors for the fingers or the palm are transmit-ted to the 
I/O processor. After the transmission, the solid model of virtual space is updated. The torque required 
at each joint of the manipulator is calculated in the I/O ac tun to r \ Figure 8. Actuators for the fingers 
TITAN PC-9801 ,,,l [ Doreinit. ] [ A/Dconv. ] Corrdinate transformation I Datain [~ ] Data out ]  [ 
Solidn,odol ] I reaction force [ D/Aconv. ] Figure 9. Diagram of the data flow processor from the received 
force and moment data. The computational time for coordinate transforma-tion and actuator torque cMculation 
is 100 msec. The computational time for the solid model handling and graphics generation depends on the 
complexity of the vir-tual objects. If the virtual object is a simple sphere con-sisting of 50 Gouraud 
shaded polygons, these processes require approximately 0.5 seconds. This time currently includes the 
large overhead of updating X window software. Since the Dore library is designed to be used in X window 
environment, this overhead is unavoidable at present. The computational time in the graphics corn- ~(~ 
Computer Graphics, Volume 24, Number 4, August 1990 puter determines the performance of the force feedback 
device. In our current example, the sampling rate is 4 Hz and lag time is 0.25 seconds. We are planning 
to separate graphics and force update, which improves the sampling rate to 10 Hz. 3-2 Solid Model Interaction 
The contact of the virtual hand with virtual objects is detected ~.t the 16 control points shown in Figure 
10. The distance between these points and the surface of a virtual object is calculated. If the thumb 
and one of other fingers touches a virtual object, the object is regarded as captured. After the capture, 
virtual object coordinates are fixed to the hand coordinates so that the object moves with hand as though 
gripped. Reaction forces to the fingers are generated accord- ing to the solidity of the captured object. 
If the object is a rigid body, the maximum possible torque is transmitted to the fingers to present the 
hard surface of the object. The force and moment vector at the palm is determined with respect to the 
position of palm and the object, according to the mass distribution of the object. In the case of handling 
a camera, for example, these vectors are obtained as follows (see Figure 11): F = a (4) M= G, (c-p) (5) 
where P : center of the palm p : position vector of P F : force vector at P M : moment vector at P 
 C : Center of gravity of the camera c : position vector of C G : gravitational force vector at C 
 The formula (4) indicates the balance of force. The formula (5) indicates the balance of moment. 4. 
APPLICATION AREAS Artificial reality is expected to be applied to various categories of human interface. 
Our application of the vir- tual space manipulation system is focused on two major fields of application 
of computer graphics: computer-aided design and 3D animation. (1) Virtual handling of prototype products 
The tactile sense plays important roles in the per-ception of size or shape of an object. These attributes 
cannot be directly perceived through planar CRT screens and conventional pointing devices. Touch-based 
artificial reality applied to a CAD system enables a designer to virtually handle prototype products 
during the designing process. An example of handing a virtual camera is shown in Figure 12. The operator 
can feel the mass bal-ance of the product. The refresh speed of this application \ \ \ Figure 10. Control 
points on the virtual hand Figure 11. Force and moment vectors at palm is 3.8 frames per second. The 
virtual camera consists of 80 Gouraud shaded polygons, and the simulated mass is 0.5 Kg . (2) Choreography 
for 3D animated character Application of computer graphics to amusement is making progress. 3D animated 
characters are popular in TV programs. Choreography for these characters is not easily done with conventional 
pointing devices. An exam- ple of handling a 3D animated character with our virtual space manipulation 
system is shown in Figure 13. The refresh speed of this application is 3 frames per second. Artificial 
reality may enable a choreographer to join in the production of 3D animation.  5. CONCLUSIONS This paper 
has shown a method of implementation of force-feedback in a virtual space manipulation system. The design 
of a compact nine degree-of-freedom master manipulator and its interaction with solid models was dis- 
cussed. Future directions in this research: (1)Presentation of sense of touch   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97898</article_id>
		<sort_key>171</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Rapid controlled movement through a virtual 3D workspace]]></title>
		<page_from>171</page_from>
		<page_to>176</page_to>
		<doi_number>10.1145/97879.97898</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97898</url>
		<abstract>
			<par><![CDATA[Computer graphics hardware supporting real-time interactive 3D animation has the potential to support effective user interfaces by enabling virtual 3D workspaces. However, this potential requires development of viewpoint movement techniques that support rapid and controlled movement through workspaces. Rapid movement through large distances avoids wasted work time; controlled movement near target objects allows the user to examine and interact with objects in the workspace. Current techniques for viewpoint movement typically use high velocities to cover distances rapidly, but high velocities are hard to control near objects. This paper describes a new technique for targeted viewpoint movement that solves this problem. The key idea is to have the user indicate a point of interest (target) on a 3D object and use the distance to this target to move the viewpoint logarithmically, by moving the same relative percentage of distance to the target on every animation cycle. the result is rapid motion over distances that slows as the viewpoint approaches the target object. The technique can be used with 2D and multidimensional input devices. We also extend the technique to move objects in the workspace.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>User interfaces</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011069</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Integrated and visual development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P141917</person_id>
				<author_profile_id><![CDATA[81452617082]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jock]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Mackinlay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P270634</person_id>
				<author_profile_id><![CDATA[81406592524]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stuart]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Card]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P95917</person_id>
				<author_profile_id><![CDATA[81452612822]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Robertson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>319132</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Badler, Norman I., Kamran H. Manoochehri, and David Baraff. Multi-Dimensional input techniques and articulated figure positioning by multiple constraints. in Proceedings o/ the 1986 Workshop on Interactive 319 Graphics (Chapel Hill, NC, October 1986). ACM, New York~ 1987~ 151-169.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319135</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bier, Eric A. Skitters and jacks: interactive 3D positioning tools. In Proceedings of the 1986 Workshop on Interactive 3D Graphics (Chapel Hill, NC, October 1986). ACM, New York, 1987, 183-196.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91446</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bier, Eric A. Snap-dragging in three dimensions. Proceedings of the 1990 Symposium on Interactive 3D Graphics (Snowbird, Utah, March, 1990). In Computer Graphics 24, 2 (March 1990), 193-204.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319122</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brooks, Frederick P. Jr. A dynamic graphics system for simulating virtual buildings. In Proceedings of the 1986 Workshop on Interactive 31) Graphics (Chapel Hill, NC, October 1986). ACM, New York, 1987, 9-21.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378497</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chen, Michael, S. Joy Mountford, and Abigail Sellen. A study in interactive 3-D rotation using 2-D control devices. Proceedings of SIGGRAPH'88 (Atlanta, Georgla~ August 1988). In Computer Graphics 25, 4 (August 1988), 121-129.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806794</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Evans, Kenneth B., Peter P. Tanner, and Marceli Wein. Tablet-based valuators that provide one, two, or three degrees of freedom. Proceedings of SIGGRAPH'81 (Dallas, Texas, August 1981). In Computer Graphics 15, 3 (August 1981), 91-97.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fairchild, Kim M., Steven E. Poltrock, and George W. Furnas. Semnet: three-dimensional graphic representations of large knowledge bases. In Cognitive science and its applications for human-computer interaction, Guindon, R. (ed), Lawrence Erlbaum, 1988.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mackinlay, Jock D., Stuart K. Card, and George G. Robertson. A semantic analysis of the design space of input devices. Human-Computer Interaction, to appear in vol. 5, 1990.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319134</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Nielson, Gregory M., and Dan R. Olsen Jr. Direct manipulation techniques for 3D objects using 2D locator devices. In Proceedings of the 1986 Workshop on Interactive 3D Graphics, (Chapel Hill, NC, October 1986). ACM, New York, 175-182.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Pew, R. W. Human perceptual-motor performance. In Human Information Processing: Tutorials in Performance and Cognition, Kantowitz, B. H. (ed), Lawrence Erlbaum, 1974, 1-40.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>62436</ref_obj_id>
				<ref_obj_pid>62402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Phillips, Cary B., and Norman I. Badler. Jack: a toolkit for manipulating articulated figures. In Proceedings of the A CM SIGGRAPH Symposium on User Interface Software, (Banff, Canada, October 1988). ACM, New York, 221-229.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73662</ref_obj_id>
				<ref_obj_pid>73660</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Robertson, George G., Stuart K. Card, and Jock D. Mackinlay. The cognitive coprocessor architecture for interactive user interfaces. In Proceedings of the A CM SIGGRAPH Symposium on User Interface Software and Technology, (Williamsburg, Virginia, November 1989). ACM, New York, 10-18.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>73663</ref_obj_id>
				<ref_obj_pid>73660</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sturman, David 3., David Zeltzer, and Steve Pieper. Hands-on interaction with virtual enviornments. In Proceedings of the A CM SIGGRAPH Symposium on User Interface So~ware and Technology, (Williamsburg, Virginia, November 1989). ACM, New York, 19- 24.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91442</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ware, Colin and Steve Osborne. Exploration and virtual camera control in virtual three dimensional environments. Proceedings of the 1990 Symposium on Interactive 3D Graphics (Snowbird, Utah, March 1990). In Computer Graphics 24, 2 (March 1990), 175-183.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>67495</ref_obj_id>
				<ref_obj_pid>67449</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Weimer, David, and S. K. Ganapathy. A synthetic visual environment with hand gesturing and voice input. In Proceedings of CHI'89, (Austin, Texas, April 1989). ACM, New York, 235-240.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ ~ Computer Graphics, Volume 24, Number 4, August 1990 Rapid Controlled Movement Through a Virtual 
3D Workspace Jock D. Mackinlay, Stuart K. Card, and George G. Robertson Xerox Palo Alto Research Center* 
 Abstract Computer graphics hardware supporting real-time interac- tive 3D animation has the potential 
to support effective user interfaces by enabling virtual 3D workspaces. However, this potential requires 
development of viewpoint movement tech- niques that support rapid and controlled movement through workspaces. 
Rapid movement through large distances avoids wasted work time; controlled movement near target objects 
allows the user to examine and interact with objects in the workspace. Current techniques for viewpoint 
movement typ- icaUy use high velocities to cover distances rapidly, but high velocities are hard to control 
near objects. This paper de- scribes a new technique for targeted viewpoint movement that solves this 
problem. The key idea is to have the user indicate a point of interest (target) on a 3D object and use 
the distance to this target to move the viewpoint logarithlni- cally, by moving the same relative percentage 
of distance to the target on every animation cycle. The result is rapid mo- tion over distances that 
slows as the viewpoint approaches the target object. The technique can be used with 2D and multidimensional 
input devices. We also extend the tech- nique to move objects in the workspace. Cl:t Categories and Subject 
Descriptors: 1.3.6 [Com- puter Graphics]: Methodology and Techniques - Interaction techniques; D.2.2 
[Software Engineering]: Tools and Tech- niques -User interfaces Additional Key Words and Phrases: Viewpoint 
move- ment, object movement, virtual reality, interactive graphics, 3D graphics, logarithmic motion, 
3D workspaces  INTRODUCTION Advances in computer graphics hardware have enabled the practical realization 
of real-time interactive 3D animation systems. These systems have the potential to provide simu- lated 
3D workspaces for user interaction with CAD/CAM, medical information, scientific visualization, "artificial 
real- ity", and general information access. An important require- *3333 Coyote Hill Road, Palo Alto, 
CA 94304, 415-494-4335, Mackinlay@Xerox.com Permission to copy without fee all or part of this material 
is granted provided that the copies arc not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. merit for such systems is a technique that allows the user to move 
the viewpoint (1) rapidly through large distances, (2) with such control that the viewpoint can approach 
very close to a target without collision. We call this the problem of rapid and controlled, targeted 
3D viewpoint movement. This problem arises in large information spaces, such as for complex machine parts 
in a CAD system or in simulated landscapes. Large information spaces contain numerous ob-jects and/or 
highly detailed objects that require the user to move back and forth from global, orienting views to 
manip- ulate detailed information. Current techniques for moving the viewpoint are not very satisfactory 
for targeted viewpoint movement. Some tech- niques fail to support rapid movement because of inefficient 
interactions or movement trajectories. Techniques support- ing rapid movement either use coarse-grained 
scale factors for direct positioning of the viewpoint over large distances or use high velocities for 
flying the viewpoint rapidly through large distances. Coarse-grained scale factors do not allow fine-grained 
control and high velocity flight is difficult to control once a target object is reached. This paper 
describes a new, more effective technique for targeted 3D viewpoint movement. The key idea is to have 
the user select a 3D point of interest (the target) on the surface of an object. On each animation cycle, 
the user's viewpoint is moved the same relative percentage of the dis- tance to the target, resulting 
in an approach that is rapid for large distances, but logarithmically slower as the target becomes closer. 
Since the technique only requires the mouse or afaother 2D input device, it integrates with existing 
in- terfaces and work environments. It can also be used with multidimensional input devices. In the paper, 
we summarize current viewpoint movement techniques, describe the Point of Interest logarithmic movement 
technique, and show how the ideas can be extended to include general object move-ment. 2 3D VIEWPOINT 
MOVEMENT Developing an effective technique for 3D viewpoint move-ment is difficult for several reasons. 
One problem is the number of parameters to be controlled by the user. 3D viewpoint movement involves 
at least six degrees of free- dom: three dimensions for position and three dimensions for rotation. The 
actual number of parameters depends on the movement metaphor, which typically involves either the direct 
positioning of the viewpoint in the workspace or the flying of the viewpoint through the workspace. Direct 
posi- tioning metaphors typically involve a scale factor parameter for the input device and flying metaphors 
typically involve &#38;#169;1990 ACM-0-89791-344-2/90/008/0171 $00.75 171  SIGGRAPH '90, Dallas, August 
6-10, 1990 velocity or direction parameters. Specialized tasks can in-volve additional viewpoint parameters 
(typically associated with the viewing matrix). For example, a cinematographic application might have 
a parameter for controlling the zoom of the field of view. Another problem is the type of viewpoint movement 
re-quired by a given task. We can distinguish at least four types of viewpoint movement for interactive 
3D workspaces: General movement. Exploratory movement, such as walking through a simulation of an architec- 
tural design. Targeted movement. Movement with respect to a specific target, such as moving in to examine 
a detail of an engineering model. Specified coordinate movement. Movement to a precise position and orientation, 
such as to a spe- cific viewing position relative to a molecule or a CAD solid model. Specified trajectory 
movement. Movement along a position and orientation trajectory, such as a cinematographic camera movement. 
 A technique appropriate for targeted movement--the focus of this paper--may not be appropriate for another 
type of movement. For example, general exploratory movement may proceed at a relatively uniform speed, 
and it may not be necessary to approach very close to objects. In that case, a technique based on the 
metaphor of walking or driving a car may be satisfactory even though it is relatively slow and is hard 
to control near objects. In addition to the inherent difficulties of controlling the viewpoint parameters, 
we also desire a technique that satis- fies the following general interface requirements: (1) is easy 
to use, (2) prevents user disorientation, (3) integrates with other user interface and work environments, 
and (4) sup- ports the perception of the virtual workspace. 3 CURRENT VIEWPOINT MOVEMENT TECHNIQUES 3D 
viewpoint movement can be accomplished by either mov- ing the viewpoint through the workspace [1,4,7,8,11,14] 
or by using object movement techniques [1,2,3,5,6,9,11,13,14,15] to move the workspace around the viewpoint. 
This section focuses on current viewpoint movement techniques and dis- cusses difficulties they have 
supporting targeted viewpoint movement. Experimental evidence suggests that the object movement approach 
does not work very effectively in com- plex multi-object workspaces [14]. Furthermore, except for Bier's 
snap-dragging technique [3], object movement tech-niques also have the problems described in this section, 
and Bier's gravity function for rapid movement of objects to tar- gets does not support controlled movements 
near targets. Current viewpoint movement techniques exhibit one or more of three basic difficulties in 
carrying out targeted move- ment: (1) inefficient interactions and movement trajecto-ries, typically 
caused by 2D input devices; (2) limits on hu- man reach and precision when the technique is based on 
directly positioning the viewpoint; and (3) difficulties con- trolling high velocities when the technique 
is based on flying or steering the viewpoint through the workspace. Inel~cient interactions and movement 
trajectories. Many techniques (typically based on 2D devices) require the user to accomplish a movement 
by shifting back and forth among simple movement modes [7,8~11]. For example, the Jack sys- tem [11] 
for manipulating articulated figures uses a menu 172 Figure 1: To move the viewpoint (shown as pyramids 
in the diagram) toward an object in the Jack system [11], the user must (1) pan the line of sight to 
face the object, (2) zoom to the desired distance, and (3) sweep to the desired orientation. for assigning 
the mouse to "sweep", "pan", or "zoom" op-erations. The interaction is non-optimal because the menu must 
be used frequently to assign the mouse to different op- erations. Figure 1 also shows that the movement 
trajectories are inefficient because the user cannot move directly to the point of interest. Movement 
interfaces based on "dial boxes" also result in inefficient movement trajectories because users generally 
adjust only one dial at a time. Limits on human reach and precision. Instead of using a low-dimensional 
transducer, such as a mouse, and shifting it among the multiple parameters of control, a common alter-native 
tactic uses a six degree of freedom input device, such as the Polhemus cube, to position the viewpoint 
directly in the workspace [1,4~14]. Unfortunately, psychophysical constraints limit direct positioning 
techniques from simul- taneously supporting rapid and control.led movements. For example, when the input 
device is scaled so that rapid move- ments can be accomplished in the span of the human arm, hand tremors 
make fine-grained controlled movements dif-ficult. A more fine-grained scale factor requires racheting 
techniques [14] to provide a full range of motion, leading to inefficient interactions. Therefore, this 
alternative tactic does not handle the large distances and very close position- ing of targeted movement. 
Difficulties controlling high velocities. Some techniques address the problem of rapid movement over 
distances by providing users with velocity controls [7,8,14]. The diffi-culty is that a high velocity 
for covering distances rapidly is difficult to control near the target. For example, Figure 2 plots three 
typical user strategies for controlling the velocity while approaching an object over a distance. These 
plots are functions of the form f(t) : rut where the user controls the parameter v~ over time t. The 
strategies are: (1) slow,sure, (2) fast,overshoot, and (3) pulse. The slow&#38;sure strategy uses a low 
velocity that al-lows the user easy control near the object. However, it takes a long time. The fast&#38;overshoot 
strategy uses a high ve-locity that covers distance rapidly. However, the user will probably overshoot 
the point of interest because of delays due to human reaction time and the discrete timing of an- imation 
frames (shown as vertical lines). After pausing to react to the overshoot, the user moves in the opposite 
direc- tion and inefficiently oscillates the viewpoint into the desired  ~ Computer Graphics, Volume 
24, Number 4, August 1990 time Figure 2: Motion functions of the form f(t) --v,,t for three user strategies 
for controlling the velocity of movement to- ward a target. The horizontal line at distance d represents 
a point of interest, the gray band represents the desired viewpoint range near the point of interest, 
and the verti- cal lines represent animation frames. The slow&#38;sure strat- egy has a wide intersection 
with the desired viewing range (shown in white) making it easy for the user to stop. The fast&#38;overshoot 
strategy has a narrow intersection which re- quires several attempts to stop. The pulse strategy involves 
pauses while the user plans the magnitude of the next pulse. viewing region. The pulse strategy uses 
little spurts of ve- locity to step towards the object. However, the user must pause to assimilate the 
effect of each pulse and the resulting movement takes a long time. 4 POINT OF INTEREST MOVEMENT This 
section describes a new viewpoint movement interface, called Point of Interest movement, that was developed 
by also considering the object that is the target of the user's desire to move the viewpoint. A Point 
of Interest (POI) is a location on the surface of an object in the workspace. POI movement comes in two 
versions: basic POI movement, which moves the viewpoint toward (or away from) the POI, and orienting 
POI movement, which moves the viewpoint and also orients it to face the POI for improved viewing and 
interaction. 4.1 Moving the viewpoint toward a POI Basic POI movement requires the user first to indicate 
a POI on the surface of a target object and then to initiate motion toward (or away from) that POI. The 
user indicates a POI to the system by using the mouse cursor to select a target object in the 3D workspace. 
When the user pushes a mouse button, the viewing transformation is inverted and a ray is cast into the 
3D workspace. The closest object pierced by this ray determines the POI and a circle is drawn on the 
surface of the object as feedback to the user. Since the feed- back might indicate that the POI is not 
placed at the desired location, the user can interactively adjust the mouse cursor while the mouse button 
is pushed and adjust the POI along the surface of the object. The interaction is very natural. Just as 
the human eye rotates through a small visual angle to adjust to a point of interest, the mouse cursor 
can move through a small distance. While these small adjustments are being made, the POI changes position 
rapidly and auto- matically in the 3D workspace over distances and through multiple degrees of freedom. 
Furthermore, objects near the   time Figure 3: Motion function for logarithmic motion f(t) = d -de 
-kt. The time when the motion intersects the desired region indicates the movement is rapid, and the 
width of the intersection rectangle indicates that the movement can be controlled. viewpoint fill larger 
visual angles, which allows the user to make controlled adjustments as the viewpoint approaches an object. 
Since all motions are relative to the POI, the user need not look at menus, inset orthographic displays, 
or virtual sliders, which would lead to inefficient interface interactions. The distance to the POI is 
used to compute a logarith- mic motion function that approaches the POI asymptot-ically along the ray 
from the viewpoint to the POI. The function is f(t) = d -de TM (1) where d is the distance to the object 
and k a proportion- ality constant for the change. The plot of this logarithmic motion function in Figure 
3 demonstrates the desired prop- erties of rapid motion over large distances to the object and controlled 
motion near the object. An informal analysis of the user's control task suggests that logarithmic motion 
should be more effective than high velocity motion for targeted viewpoint movement. The prob- lem with 
high velocity motion to a target object is that the object stays relatively small for a while and suddenly 
grows to fill the visual angle. Pew has studied perceptual motor performance and gives evidence that 
signal predictability cart significantly enhance tracking performance [10]. Loga- rithmic motion has 
the property that the target object ap- pears to grow at a constant rate of proportionality (the con- 
stant k in the motion function) as the viewpoint approaches, which makes it very easy to predict when 
the viewpoint will reach the desired distance from the object. A simple and efficient implementation 
of logarithmic mo- tion results from using the constant of proportionality k in equation (1) to calculate 
the change in the distance from the viewpoint to the POI on each cycle of the animation: eye, ~ eye, 
-k(eye~ -poi,) eye~ ~ ~ye~ -~(eVe~ -poi~) (2) eyez ~ eyez -k(eyez -poiz) where eyes, eyeu, eyez, poi~, 
poiv, and poiz are the world coordinates of the viewpoint and the POI. This technique avoids using a 
square root on every animation cycle for cal- culating the distance from the viewpoint to the POI and 
integrates nicely with the interactive adjustment of the POI described above. The adjusted position of 
the POI can be used directly to calculate the new position of the viewpoint @SIGGRAPH '90, Dallas, August 
6-10, 1990 for the next animation frame. The calculation can also be used to move away from the object 
by making k negative. POI adjustment and logarithmic motion represent the functionality of basic FOI 
movement. We have implemented a viewpoint movement interface that includes this function- ality as part 
of an environment with multiple workspaces called 3D Rooms [8,12]. The movement interface uses the middle 
mouse button (on a 3-button mouse) to adjust the POI and two keys on the keyboard to indicate either 
forward or backward logarithmic motion. This design separates the functionality of basic POI movement 
to different hands, the mouse hand for adjusting the POI and the keyboard hand for initiating logarithmic 
motion. The current interface is easy to use and integrates with our general viewpoint movement interface 
that uses virtual joysticks to control the velocity of a virtual walk around a 3D room [8]. 4.2 Orienting 
the viewpoint to face a POI Orienting POI movement extends basic POI movement to include an adjustment 
of the viewpoint to face the POI for improved viewing and interaction. Orienting POI movement requires 
two additional operations: (1) lateral movement of the viewpoint toward the object's surface normal at 
the POI, and (2) a rotation to face the POI. Unlike basic POI movement, orienting POI motion has the 
property that it moves the screen position of the POI away from the mouse cursor, which is being used 
to adjust the POI's 3D position. Rather than adjusting the mouse cursor to track the POI screen location, 
we have found it better to turn the mouse cursor off during POI motion and let the user adjust the POI 
feedback circle directly as a 3D cursor. Note that the lateral operation should only be used in combination 
with the rotation operation to prevent movement of the POI out of the window. The entire algorithm for 
a single animation cycle of orienting POI movement is as follows: 1. Cast a ray from mouse cursor into 
workspace. 2. Draw PO[ circle on closest object surface. 3. If the forward (or backward) key is pushed, 
then use equation (2) to move logarithmically forward (or back- ward) along ray. 4. If either key is 
pushed, orient viewpoint:  (a) Calculate the POI normal vector. (b) Multiply normal vector by the current 
distance to the POI to find the lateral position point. (c) Move logarithmically toward the lateral 
position point using a lateral proportionality constant. (d) Rotate the viewpoint to Jace toward the 
POL  We have implemented an efficient version of orienting POI movement for 3D planar objects using 
planar equations and the Silicon Graphics graphics library. Our implementa- tion has the additional feature 
that the user can make the viewpoint hover in front of the POI by simultaneously push- ing the forward 
and backward keys for logarithmic motion. When this is done, the viewpoint will follow the POI as the 
user adjusts its position, allowing the user to "scroll" across the surface of an object. We have experimented 
with various constants for the mo- tion to the POI and the lateral motion to the surface normal. The 
proportionality constant k for the logarithmic motion to the POI is currently 0.15. A wide range around 
this value 174 Figure 4: Compared to Figure 1, orienting POI movement has an efficient trajectory towards 
a point of interest with automatic adjustments of multiple degrees of freedom. The pyramids in the diagram 
represent two positions of the view- point before and after a POI movement toward a rectangle. The position 
of the viewpoint after movement is determined by logarithmic motion toward the target and lateral motion 
to the target's surface normal. The orientation of the view- point is also rotated to face the POI. also 
works. The proportionality constant for motion to the surface normal should simply be larger than for 
the motion to the POI so that the viewpoint moves to the normal before the desired distance is reached. 
The current value is 0.25. POI movement is subject to two additional constraints in our implementation. 
First, as with our general viewpoint movement using the walking metaphor [8], POI movement is constrained 
to keep the viewpoint in the 3D room and the virtual body upright. A second constraint is placed on the 
POI itself. Since the user can move the POI while mov- ing the viewpoint, we constrain the POI to the 
object se-lected when POI movement was initiated. This prevents the user from accidentally changing his 
or her focus of attention from one object to another during viewpoint movement and rapidly moving away 
from the intended target. 4.3 Discussion of POI movement POI movement is an effective targeted movement 
technique. The movement is rapid and controlled, and the interface is simple. Since all movement is relative 
to the POI, users can place their hands on the mouse and keyboard keys for log- arithmic motion and focus 
their entire attention on the 3D workspace as they move the viewpoint. The interface does not require 
users to be aware of multiple movement param- eters, such as velocity parameters. As Figure 4 shows, 
the movement trajectories are efficient. Logarithmic motion to the POI can automatically adjust the three 
degrees of free- dom of viewpoint position, and the surface normal opera- tions can adjust the other 
degrees of freedom of viewpoint orientation. Since users can point at any object they see in the 3D workspace, 
they are not limited by artificial move- ment restrictions such as only being able to move along the 
line of sight. POI movement integrates with current mouse- based interfaces and work environments. Furthermore, 
log- arithmic motion can also be used with multidimensional de- vices. For example, the user could point 
at a target object with a VPL glove and use simple hand gestures [13] to fly rapidly toward the target 
with logarithmic motion. POI movement is very effective for targeted viewpoint movements, but is less 
effective for general viewpoint move-  ~ Computer Graphics, Volume 24, Number 4, August 1990 ment, 
particularly when there is not an appropriate object to anchor the movement. We still use our general 
viewpoint movement interface (i.e., a walking metaphor) in our 3D Rooms system to explore the workspace. 
POI OBJECT MOVEMENT Useful 3D workspaces require an efficient and easy to use movement interface that 
supports both viewpoint and ob- ject movement. We have developed a simple general object movement technique, 
based on a 2D mouse input device, that integrates well with POI viewpoint movement. Further- more, it 
can easily be integrated with Bier's snap-dragging techniques when rapid targeted object movements are 
re-qnired [3]. The POI object movement technique uses the mouse cur- sor to control a ray that determines 
the lateral position of the object (given the viewpoint coordinates) and uses the same keyboard keys 
as POI movement to control the posi- tion of the object on the ray. The lateral movement algorithm selects 
the object's new coordinates by intersecting the ray (projected from the view- point through the mouse/cursor 
position) with the plane perpendicular to the user's line of sight that passes through the center of 
the object. Objects moved in this way are constrained to remain in the 3D room by clipping the new coordinates 
to the room coordinates. A desirable side-effect of this clipping is that an object moved into a wall 
can be dragged along the wall. The movement of an object along the ray requires a more sophisticated 
motion function than the one used for POI viewpoint movement because in addition to requiring rapid and 
controlled movements of the object relative to the view- point, the interface must support fine-grained 
movements of the object relative to its own coordinate system. For exam- ple, it is impossible to move 
an object close to a wall with just logarithmic motion when the distance between the ob- ject and the 
viewpoint is large enough that calculations like those in (2) result in large differences. Our solution 
is to combine two motion functions: one to accelerate the object relative to its coordinate system and 
the other to clip this acceleration by a logarithmic motion function when the ob- ject accelerates towards 
the viewpoint. The combination of these two functions is shown in Figure 5. The acceleration function 
allows the user to make fine-grained object move- ment using a pulsing technique similar to the one plotted 
in Figure 2. The logarithmic motion function ensures that the user can still make controlled movements 
as the object moves towards the viewpoint. The integration of POI object movement with 3D snap- dragging 
[3] should be straightforward. They both use the mouse cursor to cast a ray into the workspace for finding 
points of interest. The snap-dragging skitter cart be used for POI feedback, with the added bonus that 
gravity can assist with the precise specification of the point o£ interest. Finally, the style of the 
two techniques is similar, for they both allow the user to focus on the 3D workspace during movements. 
The principal advantage of 3D snap-dragging is that pre- cise placement of objects is easy. However, 
precise place- ment, with its additional complexity of specifying alignment objects, is not always desirable 
or necessary. The advan- tage of POI object movement is that it provides an intu-itive and natural way 
of doing approximate placement of objects. The combination of POI object movement and 3D snap-d_ragging 
will allow both general movement and precise   iiiiiJiiiifJ  iiiiiii!iill time Figure 5: The motion 
functions for POI object movement are plotted as previous figures with the viewpoint at distance 0 and 
the object at distance d. The acceleration function is plotted as parabolic curves toward and away from 
the viewpoint. The logarithmic motion is plotted toward the viewpoint and clips off the velocity of the 
acceleration. movement when needed. The POI object movement technique has a number of advantages. It 
uses the same user interface conventions as POI viewpoint movement, hence is fully integrated with it. 
It only requires a 2D input device like a mouse, but can be used with a multidimensional device. It is 
very easy to learn and use. Finally, it can be used in combination with 3D snap-dragging when precision 
is required. 6 CONCLUSION We have described a new technique, point of interest log- arithmic motion, 
that offers an improvement in the tech-niques available for targeted 3D viewpoint movement, which occurs 
when users wish rapid access to many objects or ob- jects with great detail. In this technique, the user 
selects a point of interest. The technique uses this information to simplify the user's control task, 
resulting in movement that is both rapid and controlled. On each animation cy- cle, the viewpoint is 
moved the same relative percentage of the distance toward the point of interest target. Thus the movement 
is rapid when the user is distant, but slow and controlled when very near the target. Like the arrow 
of Zeno's Paradox, the user's viewpoint continues to fiy closer to the point of interest, but never actually 
reaches it. In-stead~ the user seems to see the target open at a uniform rate, revealing ever finer detail. 
In addition to satisfying the goals of rapid and controlled viewpoint movement, this technique also satisfies 
the more general interface requirements listed in Section 2: 1. The technique is easy to use. The user 
only has to point into the workspace and indicate forward or back- ward movement. The complex parameters 
of view- point movement, such as position, orientation, and their rates of change are determined by the 
point of interest and are adjusted automatically. 2. The technique can help avoid disorientation. Logarith- 
mic motion is predictable and easy to control. This technique also helps with orientation by making it 
fast for the user to zoom out to get orienting views and then to zoom back in.   O SIGGRAPH '90, Dallas, 
August 6-10, 1990 3. The technique can be integrated with other techniques. It can be used with 2D or 
multidimensional input de- vices. It is fully integrated with the POI object move- ment technique for 
general object positioning, and can be combined with 3D snap-dragging to get precise ob- ject positioning. 
 4. The technique enhances the perception of the virtual workspace. POI movement allows the user to easily 
move through the workspace without having to shift attention to menus or other user interface artifacts. 
  POI movement should enhance a person's ability to in- teract with information spaces containing many 
items. It is thus a potential component of future systems that will sup- port complex and interesting 
interactions between human and machine. Acknowledgments We would like to thank Polle Zell- weger and 
Eric Bier for their suggestions and comments on this paper. Lermart LSvstrand helped us implement an 
ear- lier version of this algorithm. References [1] Badler, Norman I., Kamran H. Manoochehri, and David 
Baraff. Multi-Dimensional input techniques and articulated figure positioning by multiple constraints. 
In Proceedings of the 1986 Workshop on Interactive 3D Graphics (Chapel Hill, NC, October 1986). ACM, 
New York~ 1987~ 151-169. [2} Bier, Eric A. Skitters and jacks: interactive 3D po- sitioning tools. In 
Proceedings of the 1986 Workshop on Interactive 3D Graphics (Chapel Hill, NC, October 1986). ACM, New 
York, 1987~ 183-196. [3] Bier, Eric A. Snap-dragging in three dimensions. Pro- ceedings of the 1990 Symposium 
on Interactive 3D Graphics (Snowbird, Utah, March, 1990). In Computer Graphics 24, 2 (March 1990), 193-204. 
[4] Brooks, Frederick P. Jr. A dynamic graphics system for simulating virtual buildings. In Proceedings 
of the 1986 Workshop on Interactive 3D Graphics (Chapel Hill, NC, October 1986). ACM, New York, 1987, 
9-21. [5] Chen, Michael, S. Joy Mountford, and Abigail Sellen. A study in interactive 3-D rotation using 
2-D control devices. Proceedings of SIGGRAPH'88 (Atlanta, Geor- gia~ August 1988). In Computer Graphics 
25, 4 (August 1988), 121-129. [6] Evans, Kenneth B.~ Peter P. Tanner, and Marceli Wein. Tablet-based 
valuators that provide one, two, or three degrees of freedom. Proceedings of SIGGRAPH~81 (Dallas, Texas, 
August 1981). In Computer Graphics 15, 3 (August 1981), 91-97. [7] Fairchild, Kim M., Steven E. Poltrock, 
and George W. Furnas. Seranet: three-dimensional graphic representa- tions of large knowledge bases. 
In Cognitive science and its applications for human-computer interaction, Guin-don, R. (ed), Lawrence 
Erlbaum, 1988. [8] Mackinlay, Jock D., Stuart K. Card, and George G. Robertson. A semantic analysis of 
the design space of input devices. Human-Computer Interaction~ to appear in vol. 5, 1990. [9] Nielson, 
Gregory M., and Dan R. Olsen Jr. Direct ma- nipulation techniques for 3D objects using 2D locator devices. 
In Proceedings of the 1986 Workshop on Inter- active 3D Graphics, (Chapel Hill, NC, October 1986). ACM, 
New York, 175-182. [10] Pew, R. W. Human perceptual-motor performance. In Human Information Processing: 
Tutorials in Perfor- mance and Cognition, Kantowitz, B. H. (ed), Lawrence Erlbaum, 1974, 1-40. [11] 
Phillips, Cary B., and Norman I. Badler. Jack: a toolkit for manipulating articulated figures. In Proceedings 
of the ACM SIGGRAPH Symposium on User Interface Software, (Banff, Canada, October 1988). ACM, New York, 
221-229. [12] Robertson, George G., Stuart K. Card, and Jock D. Mackinlay. The cognitive coprocessor 
architecture for interactive user interfaces. In Proceedings of the A CM SIGGRAPH Symposium on User Interface 
Software and Technology, (Williamsburg, Virginia, November 1989). ACM, New York, 10-18. [13] Starman~ 
David J., David Zeltzer, and Steve Pieper. Hands-on interaction with virtual enviornments. In Proceedings 
of the ACM SIGGRAPH Symposium on User Interface Software and Technology, (Williams-burg, Virginia~ November 
1989). ACM, New York, 19- 24. [14] Ware, Cohn and Steve Osborne. Exploration and vir- tual camera control 
in virtual three dimensional envi- ronments. Proceedings of the 1990 Symposium on In- teractive 3D Graphics 
(Snowbird, Utah, March 1990). In Computer Graphics P4, 2 (March 1990), 175-183. [15] Weimer, David, and 
S. K. Ganapathy. A synthetic vi- sual environment with hand gesturing and voice input. In Proceedings 
of CHI'89, (Austin, Texas, April 1989). ACM~ New York, 235-240.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97899</article_id>
		<sort_key>177</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Project GROPEHaptic displays for scientific visualization]]></title>
		<page_from>177</page_from>
		<page_to>185</page_to>
		<doi_number>10.1145/97879.97899</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97899</url>
		<abstract>
			<par><![CDATA[We began in 1967 a project to develop a haptic+display for 6-D force fields of interacting protein molecules. We approached it in four stages: a 2-D system, a 3-D system tested with a simple task, a 6-D system tested with a simple task, and a full 6-D molecular docking system, our initial goal. This paper summarizes the entire project---the four systems, the evaluation experiments, the results, and our observations. The molecular docking system results are new.Our principal conclusions are:&amp;bull; Haptic display as an augmentation to visual display can improve perception and understanding both of force fields and of world models populated with impenetrable objects.&amp;bull; Whereas man-machine systems can outperform computer-only systems by orders of magnitude on some problems, haptic-augmented interactive systems seem to give about a two-fold performance improvement over purely graphical interactive systems. Better technology may give somewhat more, but a ten-fold improvement does not seem to be in the cards.&amp;bull; Chemists using GROPE-III can readily reproduce the true docking positions for drugs whose docking is known (but not to them) and can find very good docks for drugs whose true docks are unknown. The present tool promises to yield new chemistry research results; it is being actively used by research chemists.&amp;bull; The most valuable result from using GROPE-III for drug docking is probably the radically improved situation awareness that serious users report. Chemists say they have a new understanding of the details of the receptor site and its force fields, and of why a particular drug docks well or poorly.&amp;bull; We see various scientific/education applications for haptic displays but believe entertainment, not scientific visualization, will drive and pace the technology.&amp;bull; The hardware-software system technology we have used is barely adequate, and our experience sets priorities for future development.&amp;bull; Some unexpected perceptual phenomena were observed. All of these worked for us, not against us.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Input devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010391</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14037393</person_id>
				<author_profile_id><![CDATA[81100077256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frederick]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Brooks]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39081535</person_id>
				<author_profile_id><![CDATA[81339520766]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ouh-Young]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Labs, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P131658</person_id>
				<author_profile_id><![CDATA[81100419617]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Batter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P215720</person_id>
				<author_profile_id><![CDATA[81100186078]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jerome Kilpatrick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Corporation, Austin, TX]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Batter, J.J. and Brooks, F.P., Jr. GROPE-I: A computer display to the sense of feel. Information Processing, Proc. 1FIP Congress 71,759-763.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bejczy, A.K. Sensors,controls, and man-machine interface for advanced teleoperation. Science 208 (1980), 1327-1335,.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brooks, F.P., Jr. The computer scientist as toolsmith: Studies in interactive computer graphics. In Information Processing 77, 625- 634. B. Gilchrist, ed. North-Holland: Amsterdam, 1977.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>57168</ref_obj_id>
				<ref_obj_pid>57167</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brooks, F.P., Jr. Grasping reality through illusion: Interactive graphics serving science. Invited keynote address. Published in CHI'68 Proceedings, May 1988. Addison-Wesley: Reading, MA. 1- 11.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>904098</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Capowski, J.J. Remote Manipulators as a Computer Input Device. M.S. Thesis, Computer Science Department, University of North Carolina, Chapel Hill, 1971.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Connolly, M.L. Solvent-accessible surfaces of proteins and nucleic acids. Science 221 (August 1983), 709-713.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Deyo, R., Briggs, J., and Doenges, P. Getting graphics in gear. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 22, 4 (August 1986), 317-326.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Goertz, R.C. et al. The ANL Model 3 master slave manipulators-Its design and use in a cave. Proc. of the Ninth Conference on Hot Laboratories and Equipment, Washington, D.C., United States Atomic Energy Commission, 1961.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gregory, R.L. Eye and Brain. 2nded. McGraw- Hill: New York, 1973.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hill, J.W. and Salisbury, J.K., Jr. Two measures of performance in a peg-in-hole manipulation task with force feedback. Paper presented at Thirteenth Annual Conference on Manual Control, MIT (June 15-17, 1977).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hill, J.W. and Salisbury, J.K., Jr. Study to design and develop remote manipulator system. Quarterly Reports 5, 6 (January 1978). Stanford Research Institute, Menlo Park, CA.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hogan, N. Stable execution of contact tasks using impedance control. Proceedings of lEEE Robotics and Automation Conference, Raleigh, NC (t 987), 1047-1054.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907929</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kilpatrick, P.J. The Use of Kinesthetic Supplement in an Interactive System. Ph.D dissertation, Computer Science Department, University of North Carolina at Chapel Hill, 1976.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kuyper, L. Receptor-based design of Dihydrofolate Reductase inhibitors: Comparison of crystallographically determined enzyme binding with enzyme affinity in a series of carboxy-substituted Trimethoprim analogues." J. Med. Chem. 1122, 25 (1982), 1120- 1124.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[McCormick, B.H., DeFanti, T.A., Brown, M.D., eds. Visualization in scientific computing. Computer Graphics 21, 6 (Nov. 1987), and SIGGRAPH Video Review, Issues 28-29 (Nov. 1987).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Minsky, M., Ouh-young, M., Steele, O., Brooks, F. P., Jr., Behensky, M. Feeling and seeing: Issues in force display. Proc. of 1990 Symposium on Interactive 3D Graphics, Snowbird, Utah, March 1990. Published in Computer Graphics 24, 2 (March 1990), 235-244.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mowbray, G. H. and Gebhard, J. W. Man's senses as information channels. In H.W. Sinaiko, ed. Selected Papers on Human Factors in the Design and Use of Control Systems. Dover: New York, 1961. p. 118.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ouh-Young, M., Pique, M., Hughes,L, Srinivasan, N., Brooks, F.P., Jr. Using a manipulator for force display in molecular docking. Proc. IEEE Robotics and Automation Conference 3 (Philadelphia, April 1988), 1824-1829.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ouh-Young, M., Beard, D.V., Brooks, F.P., Jr. Force display performs better than visual display in a simple 6-D docking task. Proc. IEEE International Conference on Robotics and Automation (Arizona, May 1989), 1462-1466.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>917155</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ouh-Young, M. Force Display in Molecular Docking. Ph.D. Dissertation, Computer Science Department, University of North Carolina, Chapel Hill, 1990.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pattabiraman, N. et al. Computer graphics and drug design: Real time docking, energy calculation and minimization. Journal of Computational Chemistry 6 (1985), 432-436.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Smith, M.J. Tactile Interface for Three-Dimensional Computer-Simulated Environments: Experimentation and the Design of a Brake-Motor Device. M.S. Thesis, Mechanical Engineering Department., Massachusetts Institute of Technology, 1988.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Stark, L.W., Kim, W.S., Tendick, F. Cooperative control in telerobotics. Proc. IEEE International Conference on Robotics and Automation (Philadelphia, April 1988), 593-595.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>904153</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Steelman, H.S. The GROPE-I System: An Analysis of Friction and Backlash Problems. M.S. Thesis, Computer Science Department, University of North Carolina, Chapel Hill, 1968.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I.E. The ultimate display. Information Processing 1965, Proc. IFIP Congress 65, 506-508.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Turk, G. Interactive Collision Detection for Molecular Graphics. M.S. thesis, Computer Science Department, University of North Carolina at Chapel Hill, 1989.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Weber, C.O. The properties of space and time in kinaesthetic fields of force. Am. J. of Psychology 38, 4 (1927), 597-606.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Weber, C.O. The properties of space and time in kinaesthetic fields offorce. Am.J. of Psychology 41, 1 (1929), 95-105.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Webster's New International Dictionary. 2nd ed. Merriam: Springfield, MA.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @SIGGRAPH '90, Dallas, August 6-10, 1990 tists can induce generalizations and deduce experimentally 
testable predictions only as they comprehend and internalize data and the results of model computations. 
First, manual drawing, then com- puter graphics, and now interactive computer graphics have been the 
main tools of scientific visualization. 1.2 Can Haptic Displays Help? We say that scientists grasp new 
understandings, that they acquire a feel for the behavior of computed models. These very metaphors attest 
to the power of our haptic senses for understanding the real world. One would expect displays to the 
haptic senses to enhance our perception of computed worlds. Such force displays have long been used in 
flight simulators and in teleoperators. Here we report on our testing of haptic displays for scientific 
visualization (Figure 1). We know of no other published research on the application of haptic displays 
to scientific visualization. Richard Feldman of NIH implemented a 6-D Joystring docking device designed 
by John Staudhammer of the University of Florida. Kent Wilson of UCSD also built a 3-D haptic docking 
device. Neither seems to have pub- iished evaluations or results. Margaret Minsky of the MIT Media Lab 
is developing and evaluating high-performance haptic displays for simulating textures, as her Ph.D. dissertation 
project [16]. This technology has not yet been applied to a scientific visualization task. 1.3 Project 
GROPE Sutherland's Vision. In 1965 Ivan Sutherland set forth a vision of "The Ultimate Display," a view 
of a display as a window into a virtual world [25]. This vision, which has provided a research program 
for interactive computer graphics ever since, included seeing, hearing, and feeling in the virtual world. 
UNC Program. Stimulated by this vision, we began a research program in interactive graphics, selected 
molecular graphics as our principal driving problem, and started in 1967 Project GROPE to develop a haptic 
display for molecular forces. Stages. Given the difficulty of this goal, we approached it in stages. 
For the initial exploration we determined to build a 2-D system for continuous force fields, both radical 
simplifications. This GROPE- I system was built and tested, and some results published [1]. We then undertook 
to build a full 6-D system (3 forces, 3 torques), using an existing electrically-coupled remote manipulator 
and substituting the computer and its world-model for the manipula- tor's slave unit. We providentially 
encountered Ray Goertz, manipu- lator designer at Argonne National Laboratories, who arranged for us 
to get a pair of orphaned 6-D-plus-grip master stations for Model E- 3 Argonne Remote Manipulators (ARM's). 
This ARM has been the transducer for the GROPE-II and GROPE-III systems [8, 5]. It now has its third 
generation of electronics. The GROPE-II system used this hardware and represented hard- surface forces 
but provided only 3 translation degrees of freedom. The computer available, an IBM System/360 Model 75, 
could produce forces in real time only for a very Simple world model--a table-top, seven child's blocks, 
and the manipulator tongs. We estimated that 100x more compute power would be necessary for real-time 
evaluation of molecular forces. Therefore, after building and testing the GROPE-I1 system [13, 3], we 
mothballed the ARM and waited. By 1986 our VAXes offered the necessary power, and we began building the 
GROPE-III system, a full 6-D system [18]. This was tested first in 1988 with a simple world model consisting 
of a rod hung in space by three springs on each end, a set of experiments we call GROPE-IlIA [19]. We 
then built a full molecular force-field evaluator and tested it in the GROPE-111B experiments [20]. 2. 
HAPTIC DISPLAYS~CHARACTERIZATION We lump together in the term haptic displays all displays to the haptic 
senses. Our displays particularly affect the propriopositionat senses (the muscle-mediated sense that 
tells one where one's limbs are in space) and the pressure sense. Neither we, nor most other haptics 
researchers, display to the sense of touch proper, so it is misleading to call these tactile displays. 
Our users explore in the virtual worlds holding a handgrip, an experience somewhat like exploring a dark 
engine compartment with a screwdriver. Remote manipulators and teleoperators display to the haptic senses 
a model of the (ideally) contemporaneous real world at some remote point. Their purpose is to allow the 
haptic feedback to guide manipulation. There is an extensive literature [2]. Vehicle simulators display 
models of real or imaginary worlds (as in DisneyWorld's StarTours), so that one may feel the body forces 
of accelerations and]or the hand-foot forces of vehicle steering (as in Atari's Hard Drivin' video arcade 
game). There has also been much published research on simulators [7]. Virtual world displays show models 
of worlds that may be real or not, may be contemporaneous or not, and may be true scale or not. We shall 
reserve this term, however, for displays in which visual, aural, and haptic displays each show world 
aspects that one can imagine seeing, hearing, and feeling, respectively, in scientific visualization, 
of course, one can cross-map these aspects, or can map abstract variables onto visible, aural, or haptic 
representors. We would not call such a virtual worm display. We know of no research to date that has 
used haptic representors for anything other than forces, including reactive forces when a moving user 
encounters modeled obstacles. 3. THE RESEARCH QUESTIONS AND WHAT WE KNOW NOW Q1. Is the root hypothesis 
true: Do haptic displays demonstrably aid perception ? A1. We have demonstrated haptic displays to aid 
perception in four sets of controlled experiments, each with a different world model. Q2. How big is 
the effect? How much can haptic displays help? That is, when one has as communicative a visual display 
as one can devise,for an application maximally susceptible to haptic display, how large a performance 
gain can the haptic augmentation ever get? A2. The most performance enhancement we have been able to 
measure is 2.2 times, in a simple manipulation task, and 1.7 times in a complex 6-D molecular docking 
task. This agrees with results reported in the teleoperation literature, where Hill and Salisbury found 
that force feedback enhanced performance up to two-fold in the docking part of a remote manipulator task 
(and had no effect on the pre-positioning part of the task) [10, 11]. Q3. For what kinds of models and 
data are haptic displays most powerful? A3. We believe the properties rendering applications most sus- 
ceptible to fruitful haptic display are at least: Importance of force fields to performance Complexity 
of force fields, as to both kinds and distribution of forces Difficulty of optical visualization  Education 
per se as a goal. One wants to get information and understanding into the head for future use, not just 
for the task at hand. Almost all scientific visualization has this property.  The molecular docking 
application is nearly ideal as a test case, both for satisfying these requirements and for potential 
payoff. Q4. How good do haptic display technologies have to be to yield    ~" Computer Graphics, Volume 
24, Number 4, August 1990 creases inter-subject variance. Nevertheless, the molecular docking results 
describe the real-world effect more realistically than do the bar-spring results. A performance experiment 
of this kind was the best we could devise to get a quantitative evaluation of the power of haptic visualization. 
The greatest promise of the technique, however, lies not in time saving but in improved situation awareness. 
Chemists report getting better comprehension of the force fields in the active site and of exactly why 
each particular candidate drug docks well or poorly. From this improved grasp of the problem, one hopes 
users would get whole new hypotheses and ideas for new candidate drugs. This we cannot measure, and we 
do not yet have any anecdotal evidence. Research chemists are now investing their professional time in 
using this system on their problems. 5. HARD-SURFACE FORCES, SYSTEM STABILITY, AND MECHANICAL IMPEDANCE 
STUDIES 5.1 Hard-Surface Forces Are HardmKilpatrick[13] No two atoms can occupy the same space at the 
same time--the repulsive force rises as r to the -13, where r is the inter-atomic distance! Modeling 
such hard-surface forces is difficult with most haptic displays. It is essentially the same as demanding 
a square- wave response from a second-order se~o system. Two problems arise. First, even in a linear 
analog system, there is no force applied until the probe has overshot, penetrated the virtual surface. 
The system has inertia and velocity. Unless it is critically damped, there will be an unstable chatter 
instead of a solid virtual barrier. Second, digital systems do quantized time-sampling. Quantization 
effects, sampling effects, and computational lags add new causes for insta- bility. One solution is to 
provide a brake--a variable damping system that radically increases friction when a virtual hard surface 
is encoun- tered [22]. This requires measuring the force the user is applying to the damped system, and 
removing braking when he attempts to move away from the surface. In the GROPE-I system we modeled only 
continuous forces (up to r to the -3 power), so did not encounter the problem. In GROPE- II, we adjusted 
system damping to keep stability, and approximated hard surfaces as Hooke's Law elastic surfaces with 
adjustable elas- ticity. Even though the virtual blocks, table, and tongs were in fact rather mushy, 
with millimeter-scale deformations, they did not feel that bad. Kilpatrick augmented the haptic display 
with clicks whenever virtual contacts were made. This helped the haptic illusion noticea- bly. 5.2 System 
Stability and Responsiveness--Ouh-Young [2O] Following Hogan [12], Ouh-Young has published a true discrete 
analysis of the system composed of the Argonne ARM and the human arm driving it. Parameters were measured 
by using a 2-D high-performance haptic display system built by Minsky and Steele [16]. This system is 
capable of very fast sampling and force response, up to 1000 ups. The analysis and measurement show that 
80 ups should give as good behavior to our ARM-arm system as the human can perceive. Lighter-scale, finger 
manipulation systems would require higher up- date rates. A puzzle arising in these measurements is that 
users can in some cases perceive incremental simulation quality when the joystick update rate is increased 
from 500 ups to 1000 ups, even though the muscle-nerve system is theoretically incapable of sensing such 
fre- quencies. Our explanation is that although the joystick is running at 500 Hz, it may be unstable 
at that frequency when it is stable at 1000 Hz. The vibrations caused by this instability can be sensed 
by the human hand. When the system is stable at both sampling rates (500 Hz and 1000 Hz), we observe 
that there are no gross differences in force perception in a few simulations in Minsky's Sandpaper envi- 
ronment.  6. OBSERVATIONS 6.1 Indirect Force Perception The molecular docking task not only requires 
the small drug mole- cule to be positioned in translation and rotation, but also requires the user to 
change the conformation of the drug molecule to get best fit into the active site. This is done by manipulating 
up to twelve twist- able bonds in the drug, each represented by a 1 -D dial mounted on the ARM shaft 
(Figure 1). Docking is thus seeking an energy minimum in an 18-D space. (In our controlled experiments, 
all bonds but six were preset to optimum values, and users had to seek optima for only six bond twists, 
or 12-D in all.) Typical user action is to do bond twists, one at a time, with the left hand, then adjust 
6-D position with the handgrip in the right hand. The ARM delivers forces only in the six positioning 
dimensions; we have not yet mounted force motors on the bond-twist dials. Nevertheless, we observe that 
one perceives force feedback as he twists a bond dial. The forces on the right hand change as the left 
hand manipulates a dial; the brain integrates the two into an action- reaction perception. 6.2 Display 
to Fingers-Hand versus Display to Hand-Arm The GROPE-I experiments used a finger-grip display. Most joint 
action was at the wrist and outward. The GROPE-II and GROPE-Ill experiments used a hand-grip display 
with joint action at the shoulder and outward. We used the Argonne ARM because it was built and available 
to us; a 6-D finger-movement force-torque display was and is not available, although several research 
groups are now engineer- ing such. Based on our experience we would prefer to do our future work on a 
finger-hand display because: It is less tiring to use, since the elbow can be separately supported. To 
our surprise, however, none of our users complained of fatigue in the GROPE-Ill experiments, in spite 
of sessions lasting 2.5 hours. Most chose to stand, rather than using a stool. The relative manipulation 
resolution of the finger-hand muscles is at least as good as that of the hand-arm system [17]. Absolute 
resolution does not matter.  The relative force-perception resolution of the finger-hand system seems 
at least as good as that of the hand-arm system.  It is simpler and more economical to have hand-scale 
working volumes reflected in similar-scale visual displays than arm-scale ones. For GROPE-IIIB exploratory 
experiments we used a rear- projection screen to give comparable visual and haptic working vol- umes. 
For GROPE-IIIB formal experiments we used a visual working volume much smaller than that of the manipulator. 
The scale discrepancy did not bother any of our users--people instinc- tively normalize it out.  Cost 
should be lower because everything is smaller, including motors and power requirements.  6.3 Better 
Visual Interactive Docking As a By-Product Pursuing effective interactive docking with the GROPE-Ill 
System led Ouh-Young to a new visual docking technique that can be implemented on any workstation, without 
a haptie display. Ouh-Young discovered that the force-torque display of Figure 6,  SIGGRAPH '90, Dallas, 
August 6-10, 1990 combined with a Pattabiraman force-torque evaluator, sufficed to help chemists find 
the convergence neighborhood of the global minimum. The chemist then switches to a while-you-watch algo- 
rithmic minimizer, which uses a Pattabiraman approximate energy evaluator until it is close to the minimum. 
This speeds the whole process up to interactive-session times, even if not so much as the haptic display 
does. 7. FUTURE PROSPECTS 7.1 Carriers of Technology All of scientific visualization has been technologically 
enabled by the interactive graphics commercial base supported by word process- ing, spreadsheets, desktop 
publishing, CAD-CAM, flight simula- tors, and entertainment. Indeed, almost all of computer graphics 
has been technologically enabled by the commercial base of television. We expect the same processes to 
pace the development and cost ofhaptic display hardware. The manufacturing robotics industry, the video 
game industry, and the vehicle simulator industry will develop the technologies, which will be adapted 
for teleoperation and for scientific visualization. 7.2 Applications for Haptic Displays Molecules. 
We believe the pharmaceutical industry has a substantial potential for using haptic displays, but that 
such applications will develop very slowly over the decade. Besides drug-enzyme docking, one can imagine 
applications in DNA intercalators, in protein design, and in studies of protein folding and packing. 
Feeling these subtle force fields could matter a lot to a researcher seeking insight and new hypotheses. 
Other Scientific Visualization. Static scalar and vector fields abound: in geology, in seismology, in 
structures engineering, in magnetics design, in electron device design, in materials design. Haptic display 
can aid in the comprehension and exploration of these fields and in non-linear optimizations within them. 
Haptics can perhaps aid perception most when large variations in magnitudes occur in the fields. The 
eye quickly recognizes bigger and smaller in visual representations, and it is superb at detecting dis- 
continuities. But one does not readily internalize that "This density is ten times that one." A haptic 
display makes magnitudes vivid. Our more distant dreams include the testing of a tensor-field haptic 
display, in which one haptic manipulator-display allows one to apply force, and a second one allows one 
to explore the resultant forces all over the field. This dream awaits a radical upgrade in com- puting 
power, just as our molecular work had to wait from 1976- 1986. Never mind; the compute power will come. 
Education. Systems for scientific visualization will be very useful for education, but educational applications 
will not by themselves pay for haptic displays. CAD, CAM, and CAE. As mechanisms get smaller and more 
complex, design for manufacturability becomes more important. We foresee haptic displays used to design 
as sembly sequences and to test ease-of-assembly of virtual models in early design development. Essentially 
the same problem arises in planning the installation, repair, and removal of heavy equipment in a building. 
Bechtel already offers a graphics package to help architects and engineers script and test equipment 
movement plans. Collision-detection is necessary. Packages with audible and later haptic warnings will 
surely appear. Why should one add haptic display to a system that already does bump detection and audible 
notification? Because the designer really wants to know not merely that his plan does not work, but what 
other motion-path might work. That is much easier to explore when one can feel the constraints [13]. 
Just impeding the collision-causing motion in a visual-only display does not help task performance, but 
indeed hinders it [26]. Entertainment. StarTours and Hard Drivin' are just the beginnings ofhaptic displays 
in entertainment. The fact that approximate forces suffice for strong illusions is important for cost/performance 
in en- tertainment. We believe entertainment will be the fastest-growing application of haptic displays 
in the 90's. Invitation. We will be glad to host and help researchers who want to build and test a scientific 
visualization application on the GROPE- III system. The support software is packaged and documented. 
Communicate with Dr. William V. Wright, wright@cs.unc.edu, 919/962-1838.  Acknowledgements. We keenly 
appreciate support for this research: In the 1960's and 1970's by the U.S. Atomic Energy Commis- sion, 
now part of the Department of Energy, and by the National Science Foundation. In the 1980' s by the National 
Center for Research Resources, Na- tional Institutes of Health. The Argonne Remote Manipulator was furnished 
by the Argonne National Laboratory. The GROPE-I device was lent to us by Prof. Thomas Sheridan of MIT. 
Dr. Lee Kuyper of Burroughs-Wellcome provided the molecular data. Margaret Minsky made her apparatus 
available for our imped- ance studies of the human arm. We are indebted to all of the team through the 
years: especially to the students whose work is explicitly cited; to our technical staff-- John Hughes, 
David Harrison, Phil Stancil, James Ross; to Michael Pique and James S. Lipscomb, who have shared the 
vision and encouraged the work at every turn; to our experimental participants; and to our chemist collaborators--lane 
and Dave Richardson of Duke, Michael Cory and Lee Kuyper of Burroughs-Wellcome. REFERENCES [1] Batter, 
J.J. and Brooks, F.P., Jr. GROPE-I: A computer display to the sense of feel. Information Processing, 
Proc. 1FIP Congress 71,759-763. [2] Bejczy, A.K. Sensors,controls, and man-machine interface for advanced 
teleoperation. Science 208 (1980), 1327-1335,. [3] Brooks, F.P., Jr. The computer scientist as toolsmith: 
Studies in interactive computer graphics. In Information Processing 77, 625- 634. B. Gilchrist, ed. North-Holland: 
Amsterdam, 1977. [4] Brooks, F.P., Jr. Grasping reality through illusion: Interactive graphics serving 
science. Invited keynote address. Published in CHI'68 Proceedings, May 1988. Addison-Wesley: Reading, 
MA. 1 - 11. [5] Capowski, J.J. Remote Manipulators as a Computer Input Device. M.S. Thesis, Computer 
Science Department, University of North Carolina, Chapel Hill, 1971. [6] Connolly, M.L. Solvent-accessible 
surfaces of proteins and nucleic acids. Science 221 (August 1983), 709-713. [7] Deyo, R., Briggs, J., 
and Doenges, P. Getting graphics in gear. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). 
In Computer Graphics 22, 4 (August 1986), 317-326. [8] Goertz, R.C. et al. The ANL Model 3 master slave 
manipula- tors-Its design and use in a cave. Proc. of the Ninth Conference on Hot Laboratories and Equipment, 
Washington, D.C., United States Atomic Energy Commission, 1961. [9] Gregory, R.L. Eye andBrain. 2nd ed. 
McGraw- Hill: New York, 1973. [10] Hill, J.W. and Salisbury, J.K., Jr. Two measures of performance '~ 
 in a peg-in-hole manipulation task with force feedback. Paper pre- sented at Thirteenth Annual Conference 
on Manual Control, MIT (June 15-17, 1977). [11] Hill, J.W. and Salisbury, J.K., Jr. Study to design and 
develop remote manipulator system. Quarterly Reports 5, 6 (January 1978). Stanford Research Institute, 
Menlo Park, CA. [12] Hogan, N. Stable execution of contact tasks using impedance control. Proceedings 
of lEEE Robotics and Automation Conference, Raleigh, NC (t987), 1047-1054. [13] Kilpatrick, P.J. The 
Use of Kinesthetic Supplement in an Inter- active System. Ph.D dissertation, Computer Science Department, 
University of North Carolina at Chapel Hill, 1976. [14] Kuyper, L. Receptor-based design of Dihydrofolate 
Reductase inhibitors: Comparison of crystallographically determined enzyme binding with enzyme affinity 
in a series of earboxy-substituted Trimethoprim analogues." J. Med. Chem.. 1122, 25 (1982), 1120- 1124. 
[15] McCormick, B.H., DeFanti, T.A., Brown, M.D., eds. Visuali- zation in scientific computing. Computer 
Graphics 21, 6 (Nov. 1987), and SIGGRAPH Video Review, Issues 28-29 (Nov. 1987). [16] Minsky, M., Ouh-young, 
M., Steele, O., Brooks, F. P., Jr., Behensky, M. Feeling and seeing: Issues in force display. Proc. of 
1990 Symposium on Interactive 3D Graphics, Snowbird, Utah, March 1990. Published in Computer Graphics 
24, 2 (March 1990), 235-244. [17] Mowbray, G. H. and Gebhard, J. W. Man's senses as informa- tion channels. 
In H.W. Sinaiko, ed. Selected Papers on Human Factors in the Design and Use of Control Systems. Dover: 
New York, 1961. p. 118. [18] Ouh-Young, M., Pique, M., Hughes, J., Srinivasan, N., Brooks, F.P., Jr. 
Using a manipulator for force display in molecular docking. Proc. IEEE Robotics and Automation Conference 
3 (Philadelphia, April 1988), 1824-1829.   Computer Graphics, Volume 24, Number 4, August 1990 [19] 
Ouh-Young, M., Beard, D.V., Brooks, F.P., Jr. Force display performs better than visual display in a 
simple 6-D docking task. Proc. IEEE International Conference on Robotics and Automation (Arizona, May 
1989), 1462-1466. [20] Ouh-Young, M. Force Display in Molecular Docking. Ph.D. Dissertation, Computer 
Science Department, University of North Carolina, Chapel Hill, 1990. [21] Pattabiraman, N. et al. Computer 
graphics and drug design: Real time docking, energy calculation and minimization. Journal of Computational 
Chemistry 6 (1985), 432-436. [22] Smith, M.J. Tactile Interface for Three-Dimensional Com-puter-Simulated 
Environments: Experimentation and the Design of a Brake-Motor Device. M.S. Thesis, Mechanical Engineering 
De- partment., Massachusetts Institute of Technology, 1988. [23] Stark, L.W., Kim, W.S., Tendick, F. 
Cooperative control in telerobotics. Proc. IEEE International Conference on Robotics and Automation (Philadelphia, 
April 1988), 593-595. [24] Steelman, H.S. The GROPE-I System: An Analysis of Friction and Backlash Problems. 
M.S. Thesis, Computer Science Depart- ment, University of North Carolina, Chapel Hill, 1968. [25] Sutherland, 
I.E. The ultimate display. Information Processing 1965, Proc. 1FIP Congress 65, 506-508. [26] Turk, G. 
Interactive Collision Detection for Molecular Graph- ics. M.S. thesis, Computer Science Department, University 
of North Carolina at Chapel Hill, 1989. [27] Weber, C.O. The properties of space and time in kinaesthetic 
fields of force. Am. J. of Psychology 38, 4 (1927), 597-606. [28] Weber, C.O. The properties of space 
and time in kinaesthetic fields of force. Am.J. of Psychology 41, 1 (1929), 95-105. [29] Webster's New 
International Dictionary. 2nd ed. Merriam: Springfield, MA. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97900</article_id>
		<sort_key>187</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Extended free-form deformation: a sculpturing tool for 3D geometric modeling]]></title>
		<page_from>187</page_from>
		<page_to>196</page_to>
		<doi_number>10.1145/97879.97900</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97900</url>
		<abstract>
			<par><![CDATA[Current research efforts focus on providing more efficient and effective design methods for 3D modeling systems. In this paper a new deformation technique is presented. Among other things, arbitrarily shaped bumps can be designed and surfaces can be bent along arbitrarily shaped curves.The purpose of this research is to define a highly interactive and intuitive modeling technique for designers and stylists. A natural way of thinking is to mimic traditional trades, such as sculpturing and moulding.Furthermore, with this deformation technique, the modeling tool paradigm is introduced. The object is deformed with a user-defined deformation tool.This method is an extension of the Free-Form Deformation (FFD) technique proposed by Sederberg and Parry [17].]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39042187</person_id>
				<author_profile_id><![CDATA[81100424950]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sabine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coquillart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA-Rocquencourt, Domaine de Voluceau, 78153 Le Chesnay, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. H. Burr. Global and Local Deformations of Solid Primitives. In SIGGRAPH'84, volume 18, pages 21- 30. ACM, July 1984.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>910661</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[W.E. Carlson. Techniques for the Generation of Three Dimensional Data for Use in Complex Image Synthesis. PhD thesis, Ohio State University, 1982.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74358</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J.E. Chadwick, D.R. Haumann, and R.E. Parent. Layered Construction for Deformable Animated Characters. In SIGGRAPH'89, volume 23, pages 243-252. ACM, 1989.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>892734</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J.H. Clark. Parametric curves, surfaces and volumes in computer graphics and computer-aided geometric design. Technical Report 221, Stanford University, 1981.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>911441</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B.S. Cobb. Design of Sculptured Surfaces Using the B-Spline Representation. PhD thesis, University of Utah, June 1984.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W.H. Du and F.J.M. Schmitt. Free-Form Surface Modelling using Tensor Product B~zier Patches: A Review with New Solutions. Technical Report T~I~- com Paris 89 D 014, Ecole Nationale Sup~rieure des T~l~communications, 1989.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J.P. Duncan and G.W. Vickers. Simplified Method for Interactive Adjustment of Surfaces. Computer Aided Design, 12(6):305-308, November 1980.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378512</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D.R. Forsey and R.H. Bartels. Hierarchical B-Spline Refinement. In SIGGRAPH'88, volume 22, pages 205-212. ACM, August 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M.P. Gascuel. Welding and Pinching Spline Surfaces: New Methods for Interactive Creation of Complex Objects and Automatic Fleshing of Skeletons. in Graphics Interface'89, pages 20-27, 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Griessmair and W. Purgathofer. Deformation of Solids with Trivariate B-Splines. In EUROGRAPH- 1CS'89, pages 137-148. North-Holland, 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94442</ref_obj_id>
				<ref_obj_pid>94424</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Luk~cs. The Generalized Inverse Matrix and the Surface-Surface Intersection Problem. In Theory and Practice of Geometric Modeling, pages 167-185. Springer-Verlag.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563884</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. E. Parent. A System for Sculpting 3-D Data. In SIGGRAPH'77, volume 11, pages 138-147. ACM, July 1977.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13942</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S.R. Parry. Free-Form Deformations in a Constructive Solid Geometry Modeling System. P hD thesis, Brigham Young University, 1986.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>70253</ref_obj_id>
				<ref_obj_pid>70248</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[L. Piegl. Modifying the Shape of Rational B-Splines. Part 1 : Curves. Computer Aided Design, 21(8):509- 518, October 1989.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>69178</ref_obj_id>
				<ref_obj_pid>69177</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[L. Piegl. Modifying the Shape of Rational B-Splines. Part 2 : Surfaces. Computer Aided Design, 21(9):538- 546, November 1989.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T.W. Sederberg and S.R. Parry. Free-Form Deformation of Polygonal Data. in Second Image Symposium, pages 633-639. CESTA, April 1986.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T.W. Sederberg and S.R. Parry. Free-Form Deformation of Solid Geometric Models. In SIGGRAPH'86, volume 20, pages 151-160. ACM, August 1986.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Fleischer. Modeling Inelastic Deformation: Viscoelasticity, Plasticity, Fracture. In SIGGRAPH'88, volume 22, pages 269-278. ACM, August 1988.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[G.W. Vickers, J.P. Duncan, and V. Lee. Interactive Surface Adjustment of Marine Propellers. Computer Aided Design, 10(6):375-379, November 1978.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. Weil. The Synthesis of Cloth Objects. In SIG- GRAPH'86, volume 20, pages 49-54. ACM~ August 1986.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Extended Free-Form Deformation: A Sculpturing Tool for 3D Geometric Modeling Sabine Coquillart INRIA-Rocquencourt 
Domaine de Voluceau 78153 Le Chesnay, France Abstract 1 Introduction Current research efforts focus 
on providing more efficient and effective design methods for 3D modeling systems. In this paper a new 
deformation technique is presented. Among other things, arbitrarily shaped bumps can be de- signed and 
surfaces can be bent along arbitrarily shaped Curves. The purpose of this research is to define a highly 
inter- active and intuitive modeling technique for designers and stylists. A natural way of thinking 
is to mimic traditional trades, such as sculpturing and moulding. Furthermore, with this deformation 
technique, the mod- eling tool paradigm is introduced. The object is deformed with a user-defined deformation 
tool. This method is an extension of the Free-Form Deforma- tion (FFD) technique proposed by Sederberg 
and Parry [17]. Ci~ Categories and Subject Descriptors: 1.3.5 [Computer Graphics]:Computational Geometry 
and Object Modeling - Curve, surface, solid, and object representation; Geometric algorithms, languages, 
and systems; Hierarchy and geometric transformations; 1.3.6 [Computer Graphics]: Methodology and Techniques 
-Interaction techniques. Additional Keywords and Phrases: Solid geometric modeling, deformations. Presently 
on sabbatical at Thomson Digital Images, Paris. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. Geometric modeling has always been a major research area in computer 
graphics. Geometric modeling includes both the definition of the geometric model and the development 
of design methods. Often, systems offer design methods im- posed by the underlying geometric model or 
use geometric models imposed by the design methods. This solution is ef- ficient for specific applications. 
However, general modeling systems require less specific geometric models and several design methods that 
are as easy as possible to use and that can be combined with each other to increase the power of the 
system. A growing trend is thus to dissociate the un- derlying geometric model and the design methods 
so that the geometric model becomes transparent to the user. This paper describes an interactive deformation 
tech- nique independent of the geometric model. As we wanted to define a highly interactive and intuitive 
modeling tech- nique usable by designers and stylists, it was natural to try to mimic traditional tools, 
such as sculpturing or moulding. The use of the sculpturing metaphor for geometric model- ing is not 
recent. Several authors have suggested tools that allow a designer to see the design operations as sculpturing 
tools [12, 19, 7, 2, 1, 5, 17, 8, 15]. Our goal is to change the shape of an existing surface ei- ther 
by adding arbitrarily shaped bumps to it or by bending it along an arbitrarily shaped curve. Four problems 
must be considered: The position of the deformed region on the surface.  The size of the deformed region. 
 The shape of the boundary of the deformed region.  The shape of the deformed region (inside the bound- 
ary).  A common practice consists of interactively moving the control points of a spline surface. This 
solution is not sat- isfactory for the following reasons: The number of control points the user will 
have to move depends on the size of the deformed region. For example, the design of a large bump may 
require moving many control points whereas designing small bumps may be impossible. SIGGRAPH '90, Daltas, 
August 6-10, 1990 H.i  The shape of the deformed region (both along its boundary and within its interior) 
is imposed by the shape of the surface isoparametric lines, that is, by the position of the neighbouring 
control points. De-signing a bump with a circular boundary is almost impossible.  The position of the 
deformed region on the surface is imposed by the position of the control points since only the control 
points are moved.  Some of these problems, namely small bumps, can be partially solved by using refinement 
techniques. Note, how- ever, that refinement has the unpleasant property of being non-local -- it causes 
regions far from the region of interest to be refined as well. In [14] and [15] Piegl proposes a combination 
of control point-based and weight-based modifications. The weight- based technique, valid for rational 
B-spline surfaces, is a nice solution for the size problem. The position problem is partially solved 
by an automatic refinement technique. In [8], Forsey and Bartels describe a new geometric model where 
a surface is represented as a hierarchy of refined sur- faces. This representation solves the size problem 
as the user can choose the resolution of each region of the surface. However, the shape problem is not 
considered since the shape of the deformation is still influenced by the position of the neighbouring 
control points. The position problem is not solved either because the control point positions are fixed. 
In [1], Barr suggests a set of powerful transformations for deforming a solid object. The transformations 
he presents include stretching, bending, twisting, and tapering opera- tots. In spite of the fact that 
arbitrarily shaped deforma- tions are not possible, it is a very efficient method. Cobb [5] presents 
the first modehng tool allowing the user to define bumps with different shapes. She extends the basic 
warp technique previously discussed in [12, 19, 7, 2] and introduces the region warp and the skeletal 
warp. With region warp, the user specifies a polygonal region that defines the shape of the warp boundary. 
Skeletal warp is a variation of the region warp where the region is defined by its skeleton. The size 
and the position of the deformed region, as well as the shape of its boundary, are user defined without 
any limitations but the shape of the interior is not free. Notice that Cobb solves most of the previously 
listed problems by the addition of a structure which consists of a region or of a skeleton. This structure 
is independent of the surface geometry. The user does not need to know the underlying geometric model 
to deform the surface. Sederberg and Parry [17] present a powerful deformation tool ill which the representation 
of the surface is also hidden by a FFD lattice embedding the object. The deformations of the FFD lattice 
are automatically passed to the object. FFD has proved to be a very intuitive and efficient model- ing 
technique highly appreciated by designers [3]. It solves the size and the position problems but not the 
shape one. The intrinsic parallelepipedical shape of the FFD lattice prohibits arbitrarily shaped deformations. 
This paper introduces an extension of the FFD technique called EFFD, for Extended Free-Form Deformation. 
The new method uses non-parallelep~pedical 3D lattices. The shape of the user defined lattice will induce 
the shape of the deformation. This paper mainly describes surface deforma- tion although the technique 
is suitable for object deforma- tion as well. Deformations produced by this technique are more general 
than Cobb's warps, they are not restricted to bumps, and all the advantages of FFD are not only re- tained 
but extended. In addition, both the boundary and the interior of the deformation are arbitrarily shaped. 
After a presentation of our implementation of Seder- berg and Parry's FFD technique, the EFFD method 
is described. The steps of the deformation process are de-tailed and different classes of EFFD lattices 
are presented. Finally, some examples illustrate our approach.  2 Free-Form Deformations Free-Form 
Deformation (FFD) [17, 16, 13] consists of em- bedding the geometric model or the region of the model 
that has to be deformed into a parallelepipedical 3D lattice regularly subdivided, as shown in Figure 
1. The deforma- tions of the FFD lattice are then automatically passed to the model. Let l, m and n be 
the number of subdivisions along each of the three directions, U, V and W. These numbers can be chosen 
by the user depending on the de- formation he wants to produce (in Figure 1, I = 2, m = 1 and n = 2). 
P636 Po36 ~ , Psoe P3o6 W Figure 1: A parallelepipedical lattice In our implementation the 3D lattice 
is represented by a tensor product piecewise tricubic B~zier volume. This volume is defined by an array 
of (31+1) x (3m+1) x (3n+1) control points Pijk. Each subdivision element, also named L88 "chunk" by 
Clark in [4], is thus defined by : 3 L(u,v,w)= E Bi(u)Bj(v)Bk(w)Pijk (1) i,j,k=O with 0 _~ u,v,w < 
1, where the Bi(t) are the degree 3 Berstein polynomials, the Pijk are the chunk control points. The 
Free-Form Deformation technique is decomposed into two steps : Before deforming the 3D lattice, the 
coordinates u~, vs and w~, in the lattice parameter space, of each ob- ject point are computed. With 
parallelepipedical lat- tices, this step requires only the solution of three lin- ear equations. For 
any point X interior to the lattice, 0<us<l, 0<v~ <mand0<w~ <n.  After deforming the 3D lattice, the 
deformed positions of the object points are computed. The deformed po- sition Xlfa of an arbitrarily 
point X with coordinates (us, v~, w~) in the lattice parameter space is computed in two steps. First, 
determine the chunk where the point lies by computing the floor values (u0, v0, w0) ofus,vs and w~. Let 
u = u~-u0,v = v~-v0 and w = w8 - w0 be the X coordinates in the chunk pa- rameter space. The second step 
consists of computing the Cartesian coordinates of Xfld from u, v, w and the matrix of the 4 × 4 × 4 
control points Pijk of the chunk, according to equation (1).  Tensor product B6zier volumes are used 
throughout the paper. Naturally, as claimed by Sederberg and Parry, other bases such as B-spUnes or volumes 
of higher degree could be considered as well. The piecewise structure of the vol- ume allows the user 
to design local deformations on the 3D lattice. This will be very important for the proposed extensions. 
In our implementation the deformation is specified by moving the (1 + 1) x (m + 1) × (n + 1) control 
points (the P3iaj3k) corresponding to the corner control points of the volume elements (or chunks). Only 
these points are rep-resented on Figures i and 2. The tangents at the corner control points can also 
be modified by the user. The other control points are automatically updated. Two modes ex- ist for the 
manipulation of corner control points. Constant tangent mode, where the tangents of the point remain 
con- stant when the point is moved, and non-constant tangent mode where the tangents of the point are 
updated accord- ing to the position of the neighbour points simulating a C-Spline interaction [4]. These 
two modes can be chosen independently for each of the three directions.  3 Extended Free-Form Defor-mations 
FFD is a very intuitive modeling technique but it is too restrictive to allow real sculpturing of surfaces. 
The re-striction is mainly due to the shape of the lattice. As seen previously, FFD solves only the size 
and the position prob- lems but not the shape one. For example, defining a circular bump on a surface 
is not possible with FFD (see Figure 5a). One would like to use a cylindrical lattice instead of the 
par- allelepipedical one (see Figure 5b). The EFFD technique presented in this paper allows arbitrarily 
shaped deforma- tions by using non-parallelepipedical lattices. EFFD lat-tices are equivalent to FFD 
lattices; only the initial lattice shape is different. The EFFD technique can be described in four steps: 
1. Editing an EFFD lattice. 2. Associating an EFFD lattice with the surface. 3. "Freezing" an EFFD 
lattice. 4. Deforming the surface.  Notice that the EFFD lattice is defined independently of the surface 
to which it will be applied. The EFFD lattice is a deformation tool that is designed by the user and 
stored into a toolbox or a library until it is used. The modeling tool paradigm faithfully reproduces 
traditional tools and greatly increases the power of the modeling system. The user can adapt the modeling 
system to his needs by defining his own tools. Each of the four steps of EFFD will now be explained in 
detail. 3.1 EFFD lattices 3.1.1 Prismatic lattices The prismatic lattice is a very significant special 
case. Pris-matic lattices are especially useful for applying a deforma- tion to a surface. We have seen 
previously that the de- formation technique consisting of moving interactively the control points of 
a spline is not satisfactory because the shape, the size, and the position of the deformation are constrained 
by the geometry of the surface. The purpose of prismatic lattices is to redefine the geometry of the 
sur- face. From a user point of view, the geometry as well as the type (polygonal, B-spline, B~zier...) 
of the surface are hidden by a new user defined structure, the EFFD lattice. The prismatic lattice is 
positioned on the surface such that the surface passes through the lattice (see Figures 6a to lla). Only 
the corner control points, the P3i3j3k are shown on the shaded pictures presented in this paper. Then, 
the user works directly on the EFFD lattice by moving some of its points and the deformations are automatically 
passed to the surface. All the surface points inside the EFFD will be deformed. The EFFD can be applied 
to non-planar sur- faces or, for example, to surfaces that have already been deformed with another EFFD 
lattice. The height of the prismatic lattice must thus be adjusted such that the de- sired region of 
the surface fits into it. The shape of the pris- matic lattice is of paramount importance. Control points 
and consequently isoparametric lines must be carefully po- sitioned in order to allow the desired deformation. 
Two classes of prismatic lattices are defined, the elemen- tary prismatic lattices and the composite 
prismatic lattices. There is no restriction on the shape of elementary prismatic O SIGGRAPH '90, Dallas, 
August 6-10, 1990 lattices. All prismatic lattices obtained by moving or merg- ing any points of a parallelepipedical 
lattice are valid. It is therefore advised not to define lattices that intersect them- selves. The cylindrical 
lattice (see Figure 2) is a useful lattice obtained by welding two opposite faces of a para2- lelepipedical 
lattice and by merging all the points of the cylinder axis. Control points along one of the directions 
(V on Figure 2) are defined in order to approximate cir- cles. An exact representation of a cylindrical 
lattice is only possible with rational splines. Other elementary prismatic lattices can be designed by 
moving and merging some of the points of a parMlelepipedical lattice. P3o6 __,__-"j r33¢ Psss ]rage P333 
~ P3s3 P393 P330 * p.. ^ Pug0 Figure 2: A cylindrical lattice  3.1.2 Composite prismatic lattices Elementary 
prismatic lattices are not general enough. Composite lattices must be introduced in order to allow the 
design of some unconnected shapes (see the "8" exam- ple in Figure 9). Composite prismatic lattices are 
defined as several elementary lattices welded together; see 3.1.4 bee- low. 3.1.3 Non-prismatic lattices 
Non-prismatic lattices can also be used to create deforma- tions of objects and some non-prismatic lattices 
such as sphericM lattices can be very attractive. Composite non- prismatic lattices are also valid. However, 
the use of lattices which are too complex can lead to unpredictable results. 3.1.4 EFFD lattice design 
process From a user point of view, an EFFD lattice is defined either from a predefined three-dimensionnal 
lattice or from two- dimensionual lattices. Predefined EFFD lattices include parallelepipedical and cylindrical 
lattices. The number of subdivisions (or chunks) along each axis is user definable. In Figure 6a, a predefined 
cylindrical lattice with respectively 2, 12 and 1 subdivisions along each of the three U, V and W axis 
has been selected. This lattice has then been transformed by selecting one plane of points out of two 
and by moving them toward the axis. Valid edit- ing methods include moving (both points and tangents 
can be moved either alone or as a group), merging, inserting (by subdividing the lattice) and removing 
points. EFFD lattices can also be created from two-dimensional lattices in the same way as surfaces are 
defined from curves (loft, sweep, extrusion,...). 2D lattices are similar to surfaces. Traditional surface 
modeling methods are employed to define them. Valid editing methods for non-predefined 3D lattices are 
the same as for predefined 3D lattices. In the "S" exam-ple (see Figure 8a), the 3D EFFD lattice is defined 
from a two-dimensional lattice. The 2D lattice is a loft on three curves, two of them being an offset 
from the middle one. Two elementary two-dimensional lattices can be welded together in order to form 
a composite two-dimensional lat- tice and further a composite three-dimensional lattice. The welding 
operation is realised by merging the points of each lattice. Two or more points of the same lattice can 
also be merged. When merging two points (P0 and P1), two of their tangents (tO with tl and t'0 with t'l) 
are merged either automatically or on user request such that merged points are equivalent to other points 
(see Figure 3). In order to be able to assure tangent continuity at a merged point, the two tangents 
t"0 and t"l must be marked as aligned, which is also done either automatically or by user request.  
toe "PO -t'O Figure 3: Merging two points Some tricky cases cannot be solved automatically, such as 
the one representing the center point of the "8" lattice, in Figure 4. In this cas% the four points, 
P0, P1, P2 and lllllmHI I P3 are merged together, as well as ~0, tl, t2, t'2 and t'0, trl, t3, t'3. Figure 
4: Merging four points When several points are merged together, such as the center of a disc, some continuity 
problems may occur. These problems are discussed in paragraph 3.1.5. While the implemented welding method 
is very simple, some more sophisticated ones such as the one presented in [9], could be implemented as 
well. In the "8" example (see Fig- ure 9a), the 3D EFFD lattice is defined from a compos-ite two-dimensionM 
lattice made from 3 elementary two-dimensional lattices, two discs and an exterior lattice. In the future, 
more specific two-dimensional lattice de- sign methods will be developed. An example of these meth- ods 
is to automatically compute the 2D lattice from either the skeleton of the shape or from its boundaries. 
3.1.5 Continuity versus complexity Continuity is one of the most important problems to con- sider when 
working with piecewise surfaces or volumes. Be- fore examining continuity constraints for volumes, let 
us recall some results on piecewise surfaces continuity; see [6] for a complete survey. Assuming non-degenerate 
4-sided cubic patches, known results are as follows: C 1 and G 1 smooth connection between patches de-fined 
over a topologically rectangular network can be guaranteed.  C 1 continuity cannot be guaranteed if 
more than 4 patches meet at a point.  For G 1 continuity around an n-patch corner (n>4), constraints 
intertwining often requires either to sub-divide patches or to increase their degree (cf. [6]).  With 
degenerate patches constraints propagation is even more important. With volumes the problem is more tricky. 
Surface continuity property can easily be extended to pris- matic volumes but general non-prismatic volumes 
can lead to unsolved continuity problems. Even when a solution to the continuity problem exists, maintaining 
this continuity may be penalizing for the EFFD technique. For example, as continuity constraints require 
the increase of the degree or of the subdivision level of chunks, editing points have to be added automatically. 
This is not convenient for the user and allowing only lattices for which continuity prob- lems are easily 
solved (without adding points) is too restric- tive. Our choice is thus not to restrain volume complexity 
but rather to insure lattice continuity only for the simplest cases. What is important for the user is 
the surface con-tinuity but not the lattice continuity. Depending on the surface type, it is often possible 
to guarantee the surface continuity even if la.ttice continuity is not assured (for ex- ample with spline 
surfaces). Thus, ~rom our point of view, lattice continuity is not a primary concern. 3.2 Associating 
a lattice with the sur-face The next step consists in taking an EFFD lattice out of the library and associating 
it with the desired surface. A list of EFFD lattices may be associated with the surface. As-sociating 
an EFFD lattice with a surface consists of adding the lattice to the list. While an EFFD lattice is associated 
with a surface, one can still edit it without deforming the surface. At this time, an attractive capability 
is the posi- tioning command which allows moving the EFFD lattice to a user specified point on the surface. 
 3.3 Freezing a lattice Everything is now ready to deform the surface. Assuming that severallattices 
are associated with the surface, the user must first select one of the EFFD lattices and "freeze" it. 
Freezing a lattice consists in computing the u,, v, and w, coordinates of each point of the surface in 
the EFFD lattice parameter space. For each surface only one EFFD lattice can be frozen at a time. With 
arbitrarily shaped lattices, finding the (u,, vs, ws) coordinates of the surface points is decomposed 
into two steps. First, the chunk where the point is supposed to lie is determined by using the convex 
hull property of B6zier volumes. The (u, v, w) coordinates inside the chunk are then computed using Newton 
approx- imation. Two problems have to be considered: the tech- nique convergence and the degenerated 
chunks treatment. The convergence and consequently the determination of the starting point of Newton 
iteration is usually considered as a delicate problem. However, for our problem, experience has proved 
that choosing u = 0.5, v = 0.5 and w = 0.5 as a starting point leads to very good convergence. No divergent 
cases have been so far noted. A simple solution has thus been chosen. It consists of subdividing the 
chunk in order to get a better starting point when no convergence is detected.  SIGGRAPH '90, Dallas, 
August 6-10, 1990 With degenerated chunks, matrix inversion required by the Newton technique may not 
be possible because of differential vanishing. In this case, as proposed by Luk£cs in [11], the pseudo-inverse 
matrix method is used. 3.4 Deforming the surface When an EFFD lattice is frozen, all the transformations 
applied by the user to the lattice are passed to the surface when the user selects the update command. 
Only moving transformations are valid for frozen lattices. The C 1 conti- nuity along the intersection 
of an exterior face of the lattice with the object can be assured either by keeping the two planes of 
control points adjacent to the lattice border fixed or by guaranteeing the surface continuity as suggested 
in 3.1.5. The computation of the X1.ra coordinate points of the deformed surface is equivalent to the 
FFD one. The presented method has been implemented with polyg- onal surfaces but, as FFD, it also works 
with other surfaces, such as spline surfaces, and it should work with hierarchical surfaces [8] as well. 
Whatever surface is used, a subdivision technique such as that of Griessmair et al. [10] is recom- mended 
in order to maintain an acceptable resolution of the surface. The technique of Griessmair et al. is valid 
for polygonal surfaces. Each polygon is subdivided into triangles that are again subdivided according 
to a given accuracy threshold. Considering a surface with several lattices positioned on it, the deformation 
process can be described as follows: Loop 1: Deform the unfrozen lattices (move, insert, re-move and 
merge control points) Freeze one of the surface EFFD lattices Loop 2: Deform the frozen EFFD lattice 
(move points) Update the surface End loop 2 Unfreeze the EFFD lattice End loop 1 The ability to work 
with several EFFD lattices associated with the same surface is very important; it allows the user to 
apply successively different shaped deformations. In order to allow for an exact repetition of the same 
de- formation on several surfaces, a recording operator has to be implemented. 4 Examples and concluding 
re-marks Some simple examples of surfaces deformed using the EFFD technique are illustrated in Figures 
6 to 11. Figures 6a to lla present the initial surfaces with the EFFD lat-tices positioned on them. In 
Figures 6b to llb, the EFFD lattices have been frozen, some of their points have been moved, and the 
surfaces updated. Both the deformed lat- tices and the deformed surfaces are shown. In Figures 6c to 
llc, shaded pictures of the resulting surfaces or objects are shown. In Figures 6 and 7, the same EFFD 
lattice (see Figure 7a) is used to define two different deformations. In Figure 6, the axis and the intermediate 
cylinders of points are trans- lated whereas in Figure 7, the axis and every second col- umn of points 
of the intermediate cylinder have been moved back. As shown in Figures 6c and 7c, sandpies are easily 
modeled with EFFD. In Figures 8 and 9 two characters are impressed onto a surface. The "8" is sculptured 
into a piece of marble by "pulling" some of the lattice points whereas the granite "S" is sculptured 
by "pushing" the points. Sculpturing and moulding are accurately simulated by EFFD. Other types of deformations 
can also be repro-duced with this technique. The shape of cloth-like surfaces can also be simulated. 
Figures 10 and 11 are two exam-ples where folds are modeled with EFFD. In Figure 10c, a leather-like 
cushion is shown. Starting with a surface of revolution embedded into a cylindrical EFFD lattice, the 
points of the lattice axis are first moved in order to create a hull at the center of the cushion, then 
the folds are designed by moving some of the intermediate points of the lattice (see Figure 10b). In 
Figure 11, an oilcloth on a round table has been modeled. Starting with a planar surface embed- ded into 
a cylindrical lattice, the outermost points of the EFFD lattice are moved as shown in Figure llb to create 
the folding effect. The resulting textured picture is shown in Figure llc. EFFD is an easy to use and 
efficient method for modeling cloth-like surfaces. Shapes cannot, of course, be as natural as with physical 
methods [20] [18] but it can be an inter-esting alternative when other methods are computationally prohibitive 
or when naturalness is not the main objective. Deforming a surface with EFFD technique is very effi- 
cient. Only a few minutes were needed to design most of the previous examples. It is very easy to implement 
EFFD on a system including the FFD capability. This deforma- tion technique is part of ACTION3D, a general 
interactive modeling system developed jointly by SOGITEC and IN- RIA. 5 Acknowledgements I would like 
to thank Laurent Alt, Wen-Hui Du, Michel Gangnet, Tony Kasvand, and Marie-Luce Viaud for help- ful discussions 
and for reviewing early drafts of this paper. I am grateful to INRIA's audiovisual department for their 
assistance with color images and video demonstrations. would also like to thank the reviewers for their 
helpful com- ments. References [1] A. H. Barr. Global and Local Deformations of Solid Primitives. In 
SIGGRAPH'8$, volume 18, pages 21- 30. ACM, July 1984. [2] W.E. Carlson. Techniques for the Generation 
of Three Dimensional Data for Use in Complex Image Synthe- sis. PhD thesis, Ohio State University, 1982. 
[3] J.E. Chadwick, D.R. Haumann, and R.E. Parent. Lay-ered Construction for Deformable Animated Charac- 
ters. In SIGGRAPH'89, volume 23, pages 243-252. ACM, 1989. [4] J.H. Clark. Parametric curves, surfaces 
and volumes in computer graphics and computer-aided geometric design. Technical Report 221, Stanford 
University, 1981. [5] B.S. Cobb. Design of Sculptured Surfaces Using the B-Spline Representation. PhD 
thesis, University of Utah, June 1984. [6] W.H. Du and F.J.M. Sehmitt. Free-Form Surface Modelling using 
Tensor Product Bgzier Patches: A Review with New Solutions. Technical Report T616- com Paris 89 D 014, 
Ecole Nationale Sup6rieure des T61gcommunications, 1989. [7] J.P. Duncan and G.W. Vickers. Simplified 
Method for Interactive Adjustment of Surfaces. Computer Aided Design, 12(6):305-308, November 1980. [8] 
D.R. Forsey and R.H. Barrels. Hierarchical B-Spline Refinement. In SIGGRAPH'88, volume 22, pages 205-212. 
ACM, August 1988. [9] M.P. Gascuel. Welding and Pinching Spline Surfaces: New Methods for Interactive 
Creation of Complex Ob- jects and Automatic Fleshing of Skeletons. In Graph-ics Interface'89, pages 20-27, 
1989. [10] J. Griessmair and W. Purgathofer. Deformation of Solids with Trivariate B-Splines. In EUROGRAPH-ICS'89, 
pages 137-148. North-Holland, 1989. [11] G. Luk£cs. The Generalized Inverse Matrix and the Surface-Surface 
Intersection Problem. In Theory and Practice of Geometric Modeling, pages 167-185. Springer-Verlag. [12] 
R. E. Parent. A System for Sculpting 3-D Data. In SIGGRAPH'77, volume 11, pages 138-147. ACM, July 1977. 
[13] S.R. Parry. Free-Form Deformations in a Construc-tive Solid Geometry Modeling System. PhD thesis, 
Brigham Young "University, 1986. [14] L. Piegl. Modifying the Shape of Rational B-Splines. Part 1 : Curves. 
Computer Aided Design, 21(8):509-518, October 1989. [15] L. Piegl. Modifying the Shape of Rational B-Splines. 
Part 2 : Surfaces. Computer Aided Design, 21(9):538-546, November 1989. [16] T.W. Sederberg and S.R. 
Parry. Free-Form Deforma- tion of Polygonal Data. In Second linage Symposium, pages 633-639. CESTA, April 
1986. [17] T.W. Sederberg and S.R. Parry. Free-Form Deforma- tion of Solid Geometric Models. In SIGGRAPH'86, 
volume 20, pages 151-160. ACM, August 1986. [18] D. Terzopoulos and K. Fleischer. Modeling Inelastic 
Deformation: Viscoelasticity, Plasticity, Fracture. In SIGGRAPH'88, volume 22, pages 269-278. ACM, Au- 
gust 1988. [19] G.W. Vickers, J.P. Duncan, and V. Lee. Interactive Surface Adjustment of Marine Propellers. 
Computer Aided Design, 10(6):375-379, November 1978. [20] J. Weil. The Synthesis of Cloth Objects. In 
SIG-GRAPH'86, volume 20, pages 49-54. ACM, August 1986.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97901</article_id>
		<sort_key>197</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Comprehensible rendering of 3-D shapes]]></title>
		<page_from>197</page_from>
		<page_to>206</page_to>
		<doi_number>10.1145/97879.97901</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97901</url>
		<abstract>
			<par><![CDATA[We propose a new rendering technique that produces 3-D images with enhanced visual comprehensibility. Shape features can be readily understood if certain geometric properties are enhanced. To achieve this, we develop drawing algorithms for discontinuities, edges, contour lines, and curved hatching. All of them are realized with 2-D image processing operations instead of line tracking processes, so that they can be efficiently combined with conventional surface rendering algorithms.Data about the geometric properties of the surfaces are preserved as Geometric Buffers (G-buffers). Each G-buffer contains one geometric property such as the depth or the normal vector of each pixel. By using G-buffers as intermediate results, artificial enhancement processes are separated from geometric processes (projection and hidden surface removal) and physical processes (shading and texture mapping), and performed as postprocesses. This permits a user to rapidly examine various combinations of enhancement techniques without excessive recomputation, and easily obtain the most comprehensible image.Our method can be widely applied for various purposes. Several of these, edge enhancement, line drawing illustrations, topographical maps, medical imaging, and surface analysis, are presented in this paper.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31092723</person_id>
				<author_profile_id><![CDATA[81100652669]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Takafumi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saito]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Human Interface Laboratories, 1-2356, Take, Yokosuka-shi, Kanagawa 238-03, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31098782</person_id>
				<author_profile_id><![CDATA[81100491040]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tokiichiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takahashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Human Interface Laboratories, 1-2356, Take, Yokosuka-shi, Kanagawa 238-03, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Beck, J. M., Farouki, R. T., and Hinds, J. K. Surface Analysis Methods. IEEE Computer Graphics and Applications 6, 12 (1986), 18-36.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Carpenter, L. The A-buffer, an Antialiased Hidden Surface Method. Computer Graphics 18, 3 (Proc. SIG- GRAPH 'S4) (1984), 103-108.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L. Shade Trees. Computer Graphics 18, 3 (Proc. SIGGRAPH '8~) (1984), 223-231.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801253</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Crow, F. C. A More Flexible Image Generation Environment. Computer Graphics 16, 3 (Proc. SIG- GRAPH 'S$) (1982), 9-18.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617486</ref_obj_id>
				<ref_obj_pid>616005</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dickinson, R. R., Bartels, R. II., and Vermeulen, A. H. The Interactive Editing and Contouring of Empirical Fields. IEEE Computer Graphics and Applications 9, 3 (1989), 34-43.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Drebin, R. A., Carpenter, L., and Hanrahan, P. Volume Rendering. Computer Graphics 22, 4 (Proc. SIG- GRAPH 'as) (1988), 55-74.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325174</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Duff, T. Compositing 3-D Rendering Images. Computer Graphics 19, 3 (Proc. SIGGRAPH '85) (1985), 41-44.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ghazanfarpour, D., and Peroche, B. A Fast Antialiasing Method with A-Buffer. in Proc. Eurographics '87 (1987), 503-512.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Higashi, M., Kohzen, I. and Nagasaka, J. An Interactive CAD System for Construction of Shapes with High-quality Surface. Ia Computer Applications in Production and Engineering (Proc. CAPE '83) (1983), 371-390.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Higashi, M., Kushimoto, T. and Hosaka, M. On Formulation and Display for Visualizing Features and Evaluating Quality of Free-form Surfaces. In Proc. Eurographics '90 (to appear).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kondo, K., Kimura, F., and Tajima, T. An Interactive Rendering System with Shading. In Japan Annual Reviews in Electronics, Computers ~ Telecommunications 18, Computer Science and Technologies, Kitagawa, T. (Ed.), Ohmsha and North-Holland, Tokyo, 1988, pp. 255-271.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W. E., and Cline, H. E. Marching Cubes: A High Resolution 3D Surface Construction Algorithms. Computer Graphics 21, 4 (Proc. SIGGRAPH '87) (1987), 163-169.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617499</ref_obj_id>
				<ref_obj_pid>616006</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mammem, A. Transparency and Antialiasing Algorithms Implemented with the Virtual Pixel Maps Techniques. IEEE Computer Graphics and Applications 9, 4 (19s9), 43-55.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37412</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Nadas, T. and Fournier, A. GRAPE: An Environment to Build Display Processes. Computer Graphics 21, 4 (Proc. SIGGRAPH '87) (1987), 75-83.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617471</ref_obj_id>
				<ref_obj_pid>616004</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nakamae, E., Ishizaki, T., Nishita, T., and Takita, S. Compositing 3D Images with Antialiasing and Various Shading Effects. IEEE Computer Graphics and Applications 9, 2 (1989), 21-29.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F. Principles of Interactive Computer Graphics, 2nd Ed., McGraw-Hill, 1979.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. An Image Synthesizer. Computer Graphics 19, 3 (Proc. SIGGRAPH '85) (1985), 287-296.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Porter, T. and Duff, T. Compositing Digital Images. Computer Graphics 18, 3 (Proc. SIGGRAPH '8~) (19s4), 2zz-259.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578095</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Rosenfeld, A. and Kak, A. C. Digital Picture Processing, 2nd Ed., Academic Press, 1982.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Salto, T., Shinya, M., and Takahashi, T. Highlighting Rounded Edges. In New Advances in Computer Graphics (Proc. CG International '89) (1989), 613-629.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Udupa, J. K. Display of Medical Objects and their Interactive Manipulation. In Proc. Graphics Interface 'S9, (1989), 40-46.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357295</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. and Weimer, D, M. A Software Testbed for the Development of 3D Raster Graphics Systems. A CM Trans. Graphics 1, 1 (1982), 43-58.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~' Computer Graphics, Volume 24, Number 4, August 1990 Comprehensible Rendering of 3-D Shapes Takafumi 
Saito and Tokiichiro Takahashi N'V[ Human Interface Laboratories 1-2356, Take, Yokosuka-shi Kanagawa 
238-03, Japan Abstract We propose a new rendering technique that produces 3-D images with enhanced 
visual comprehensibility. Shape fea- tures can be readily understood if certain geometric proper- ties 
are enhanced. To achieve this, we develop drawing algo- rithms for discontinuities, edges, contour lines, 
and curved hatching. All of them are realized with 2-D image process- ing operations instead of line 
tracking processes, so that they can be efficiently combined with conventional surface rendering algorithms. 
Data about the geometric properties of the surfaces are preserved as Geometric Buffers (G-buffers). Each 
G-buffer contains one geometric property such as the depth or the normal vector of each pixel. By using 
G-buffers as interme- diate results, artificial enhancement processes are separated from geometric processes 
(projection and hidden surface re- moval) and physical processes (shading and texture map-ping), and 
performed as postprocesses. This permits a user to rapidly examine various combinations of enhancement 
techniques without excessive recompntation, and easily ob- tain the most comprehensible image. Our method 
can be widely applied for various purposes. Several of these, edge enhancement, line drawing illustra- 
tions, topographical maps, medical imaging, and surface analysis, are presented in this paper. CtL Categories 
and Subject Descriptors: 1.3.3 [Com- puter Graphics]: Picture/Image Generation; 1.3.7 [Com-puter Graphics]: 
Three-Dimensional Graphics and Realism; 1.4.3 [Image Processing]: Enhancement. Additional Key Words 
and Phrases: comprehensible rendering, visualization, geometric property, contour lines, edge enhancement, 
line drawing illustrations, topographical maps, medical imaging, surface analysis. Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. 1 Introduction Techniques 
for the comprehensible drawing of 3-dimensional shapes are indispensable for various applications such 
as in- dustrial design or medical imaging. Their importance in computer graphics is not at all inferior 
to that of photo- realistic rendering techniques. Comprehensibility is mainly created through suitable 
enhancement rather than by accu- rately simulating optical phenomena. For shape comprehen- sion, line 
drawings are effectively used as an addition to or substitute for surface coloring and shading [11]. 
For exam- ple, profiles and edges can be enhanced with black or white border lines. Curved surfaces can 
be made more comprehen- sible by hatching with curved lines. These techniques are commonly used in hand 
drawn illustrations. However, they have not been adequately developed for computer graphics compared 
to photoreahstic rendering techniques. The major problem for synthesizing a comprehensible image is determining 
the most suitable combination of en- hancement techniques. The reason is that comprehensibility depends 
on the object, purpose, and sometimes the view- ers' preferences, and cannot be expressed with theoretical 
definitions. Therefore, we must find the best combination by trim and error for each object or application. 
In order to maintain high productivity, graphics systems must be flexi- ble and interactive to match 
the users' experimentation. For photorealistic rendering, there is a lot of excellent research that aims 
to reduce image recomputation cost by preserving intermediate information [7,13,15,17,18], and/or to 
build a rendering system flexibly by separating it into small pro- cedures which can be combined freely 
[3,4,14,22]. These techniques might appear to be effective for comprehensible rendering. However, enhancement 
using line drawings and conventional surface rendering are so different that it is dif- ficult to combine 
them efficiently. This difficulty arises, for example, when eliminating hidden lines and surfaces for 
the same image [20]. We propose a new enhancement technique for 3-D shapes that conceptualizes geometric 
properties. We have developed drawing algorithms for the basic enhancement operations, the drawing of 
discontinuity lines, contour lines, and curved hatching. All operations are realized with £-D image processin 
9 operations, not with line tracking pro- cesses, so that they are suitable for interactive surface ten- 
 &#38;#169;1990 ACM-0- g9791-344-2/90/008/0197 $00.75 197 @SIGGRAPH '90, Dallas, August 6-10, 1990 dering 
environments. The geometric properties are preserved as a set of Ge- ometric buffers (G-buffers1). A 
G-buffer set is obtained by forming projection views and removing hidden surfaces. Each buffer contains 
one geometric property, such as the depth or the normal vector, of the visible object in each pixel. 
The basic enhancement operations can be performed using G-buffer contents during postprocessing. If geomet- 
ric factors (i.e. shapes and camera parameters) are fixed, any combination of enhancement can be examined 
without changing the contents of the G-buffers. The proposed method is also useful for photorealistic 
rendering. It can be considered an extension of Perlin's Pixcl Stream Editor [17]; it means that Perlin's 
mapping techniques can be easily performed on a G-buffer set. Since the G-buffer set contains no physical 
(or optical) proper- ties such as reflectance or colors, photoreahstic techniques can be used in postprocessing 
and performed independently from enhancement operations. Therefore, the proposed method can be considered 
a very powerful and flexible ren- dering concept for various purposes. Geometric Buffers In this section, 
Geometric buffer set contents are intro-duced. A G-buffer set is the intermediate rendering result, and 
used as the input data for enhancement operations. Each buffer contains a geometric property of the visible 
ob- ject in each pixel. The following properties are the typical contents of a G-buffer set. , id: object/patch 
identifier ou: patch coordinate u , or: patch coordinate v sz: screen coordinate z A B C (perspective 
depth) D X E i i wx: world coordinate x F G i H  wy: world coordinate y  wz: world coordinate z 
 Fig.l  nx: normal vector z Neighboring pixels.  ny: normal vector y  , nz: normal vector z Note that 
this list is not exclusive nor a requirement; the required G-buffer set depends on the required enhancement 
techniques. One of the significant advantages of preserving only ge- ometric information in a G-buffer 
set is that the rendering processes can be separated into the following three groups.  ty'- 1The pronunciation 
of ~G' is [be:] as in the German alphabet. We decided it for the following reasons :-) "~7.~ "5"~ L~ 
Many Japanese people pronounce both ~z' and 'g' like [~i:], which makes terrible confusion between z-baKer 
and G-buffer. * Our first choise was g.buffer, but we found that the name had been already used by Ghazanfarpour 
[8]. We tried to find another suitable name but we could not. Therefore, we changed 'g' to upper case 
'G' with German pronunciation. geometric processes: processes based on geometric factors such as object 
shapes and camera parameters; (ex. perspective projection, hidden surface removal)  physical processes: 
processes based on physical (optical) factors such as reflectance, colors, textures; (ex. shading, texture 
mapping)  artificial processes: processes based on psychological or artistic factors; (ex. enhancement) 
  G-buffers are formed during the geometric processes, and are used by the physical and artificial processes. 
When physical and/or artificial factors are changed, the new image can be recalculated without modifying 
existing G-buffers if the geometric factors are fixed. Since physical and artifi-cial processes can be 
applied independently, we can rapidly examine various combinations. Postprocessing is performed as a 
combination of image processing operations. Since they are uniform operations for 2-D arrays, special 
hardware or vector processors can effectively accelerate the calculations. In this paper, intermediate 
data which contains the scalar value of each pixel is called an 'image'. A G-buffer is also called an 
image; one example is the 'sz image'. 3 Basic Enhancement Operations In this section, basic enhancement 
operations --disconti-nuities, edges, contour lines, and curved hatching --are described. Though all 
of them are line drawings, they are realized with 2-D image processing operations instead of line tracking. 
3.1 Drawing Discontinuities Discontinuities of an image can be extracted with a first order differential 
operator. Various operators developed in the image processing field [19] are available, however, we recommend 
Sobel's: g= (IAT2B+C-F-2G-HI + It+ 2E+H-A-2D-F]) / 8, (t) where A-H and X are values of the neighboring 
pixels in Fig.1. In Eq.(1), g is normalized so that it corresponds to the gradient per pixel. Discontinuities 
of the first order differentials of an image can be extracted with a second order differential operator. 
For this calculation, we recommend the following operator:  I=(8X-A-B-C-D-E-F-G-H)/3. (2) Discontinuities 
can be extracted as sequences of peak levels by a differential operator, however, they are not suit- 
able for comprehensible rendering. Using a differential oper- ator only, it is impossible to draw discontinuities 
as uniform lines because of the following artifacts: 1) it is hard to distinguish discontinuities from 
large con- tinuous changes;  ~ 3.4 Curved Hatching In this subsection, we propose a method to express 
hatch- ing with curved lines that indicate some type of structure lines. Such lines include the latitudes 
and longitudes of a sphere or a rotated object, intersections by a set of paral- lel planes, and u-v 
mesh of a parametric surface. For the above examples, a set of structure fines can be defined as contour 
lines of a scalar field, so that they can be drawn with the method given in Subsection 3.3. However, 
contour lines drawn at regular intervals become too dense or sparse depending on the gradient, and are 
not suitable for hatch- ing. To uniformly hatch a surface, contour lines must be drawn at regular pixel 
intervals. Contour lines with uniform density can be drawn by using the binary thinning out technique. 
When the gradient is large and the contour lines become dense, alternate con-tours are thinned out. If 
the contour lines become sparse, new contours are added between existing fines. One exam- ple of the 
binary thinning out algorithm is as follows: (co -cb), (17) fa(t)----fl(t,-I-(PdT~-l).f, (P~g -[t,) , 
(18) where Pn = 2npd, (19) n= loge +1 , (20) and pa is the standard interval in the scalar field. The 
function fd has two terms; the first term corresponds to the density of normal contour fine, and the 
second term corresponds to thinned or added contour fine between nor-mal lines. With these functions, 
contour lines are approxi- mately spaced at intervals of di on the screen. An example of Eq.(16) is shown 
in Fig.6. Fig.6 An example of curved hatching. 4 Examples and Applications 4.1 Edge Enhancement A shaded 
image of 3-D shapes can be more comprehensi-ble by enhancing edges (profiles and internal edges) with 
black or white lines. This technique is commonly used in   Computer Graphics, Volume 24, Number 4, 
August 1990 II II I hand drawn illustrations in the field of industrial design [11]. When the shaded 
image is generated with conventional computer graphics techniques, the edge drawing method in Subsection 
3.1 and 3.2 is easily applied. This is because the depth image (the sz image) can be obtained as a by-product 
of hidden surface elimination. An enhanced image is gen- erated by combining the edge image with the 
conventional shaded image. This technique is not the original usage of G-buffers; the shaded image and 
depth image are preserved as intermediate results, and both have geometric and phys- ical factors. However, 
existing rendering software can be used with little modification, and the enhancement can be rapidly 
examined. Two examples are shown in Fig.7. The original shaded image is (a), and the depth image is (b). 
Applying the dif- ferential operations on (b) (this process is shown in Fig.3), an edge image (c) was 
obtained. An final enhanced image (d) was generated by composing (b) and (c). In images (c) and (d), 
convex edges are drawn with white lines, which present the edge highlight effect [11,20]. Another example 
of enhancement is shown in images (c') and (d'); all profiles and edges are enhanced with black lines. 
It was generated by taking absolute values of the internal edge image. Edges in reflected or refracted 
objects can be also en- hanced with the proposed method. For this purpose, a ray length image is used 
instead of a depth image. The ray length image contains the ray length form the eye to the last reflected 
(or refracted) object in each pixel, which can be obtained by ray-tracing. An example is shown in Fig.8. 
Note that this method is simple but not complete; a com- plete method is discussed in Subsection 5.1. 
 4.2 Line Drawing Illustration A lot of hand drawn illustrations are produced with just line drawings. 
Such illustrations consist of profiles, internal edges, and surface structure lines. Hatching techniques 
are effectively used instead of shading. With our method, these basic techniques can be ex-amined quickly 
through the use of G-buffers in computer graphics. An example is shown in Fig.9. Six images (nx~ ny, 
nz, sz, ou, ov) were preserved as G-buffers. The shaded image (sh) was calculated from the nx, ny and 
nz images. The profile image (pr) was obtained from the sz image. The curved hatching (cu, ev) was from 
(ou) and (or). By enhancing the hatching images with the sh im- age and composing with the pr image, 
the final illustrations (shu, shy, shuv) were obtained. Line drawing illustrations are easy to print 
or copy. No special treatment for gray scale is required, and even an in- expensive copy machine maintains 
the image quality. Fig-ure 10 is an example of the effect; shaded (sh) and line drawing (cv) images were 
copied five times. The quality of the copied sh image is completely poor, however, the copied cv image 
still has almost the same quality as the original.   ~ deformed by the disease or injury, or what 
is the exact place of the diseased part. For this requirement, we can make the image more comprehensible 
with G-buffers and 2-D image processing techniques. It is easy to draw profiles and con-tour lines that 
show us some useful geometric information of the 3-D shapes. These line drawings can be combined interactively 
with a conventional shaded or colored image. Example images are shown in Fig.14. The original voxel data 
had 50 slices of CT data. After separating the bone part [6], seven G-buffers (wx, wy, wz, sz, nx, ny, 
nz) were generated by ray-tracing the voxel data. The enhanced im- age (b) is the combination of four 
techniques: the profiles, shading, the contour lines of (wz), and the color bands for (wy). The conventional 
shaded image (a) is more realis-tic, however, the enhanced image (b) gives us much more information about 
the bone shapes. 4.5 Surface Analysis Free form surfaces such as Bezier or spline surfaces are widely 
used in geometric modeling. A shape with these pa.rametrie surfaces can be controlled flexibly, and their 
con- tinuity is mathematically well known. However, it is diffi- cult to evaluate the quality of surfaces; 
because the quality depends on a lot of geometric properties, and photorealistic rendering is insufficient. 
For this purpose, it is important to visualize and analyze the geometric properties. For exam- ple, contour 
lines, pseudo-highlight patterns, and curvature maps are effective to describe the features of a curved 
sur- face [1,5,9,10]. In conventional methods, line drawings are calculated by tracking, which requires 
a lot of consideration about numerical analysis. Some of the surface analysis techniques are easily re-alized 
with our method. For example, a pseudo-highlight pattern can be obtained as follows. A pseudo-highlight 
pat- tern is the reflected image on a curved surface of parallel lines that are assumed to lie at an 
infinite distance [10]. Assume the cylindrical coordinate whose z-axis is parallel to the parallel lines. 
Then, each line has a constant 0 value. For each pixel, the 8 value in the reflected image on the visible 
surface is easily calculated from the normal vector and the position of the surface, and the eye position. 
By drawing contour lines or curved hatching for the image of 8 value, the pseudo-highlight pattern is 
generated. In Fig.15, contour lines (a), and a pseudo-highlight pat- tern (b) of a curved surface are 
presented. The curved sur- face consists of two bicubic patches that connect with C 1 (not C 2) continuity. 
The overview of the shape is compre- hensibly presented with the contour lines. The discontinuity is 
clearly shown in the pseudo-highllght pattern. 5 Discussions 5.1 Antialiasing and Reflective/Transparent 
Objects A G-buffer contains the property of only one surface per pixel. This restriction leads the following 
problems: aliasing artifacts occur on surface borders;  reflected or transparent images cannot be enhanced. 
   Computer Graphics, Volume 24, Number 4, August 1990 Some simple solutions are possible. For example, 
edges can be anti-aliased by calculating the sz image as the average depth value in each pixel. Edges 
in reflected images can be drawn with the method in Subsection 4.1. However, these are not fundamental 
solutions. These problems can be solved by preserving the prop- erties of all surfaces visible in each 
pixel. This can be real- ized with Extended G-Buffers. In Extended G-buffers, each G-buffer has an extra 
memory area; the main area has the property of the primary visible surface at each pixel, and the extended 
area has the property of the other visible surfaces. A couple of additional G-buffers are preserved to 
retain pixel coverage information and the pointer to the next area for each pixel. This method can be 
considered as an extension of the A-buffer method [2], and reflection/refraction and an- tialiasing can 
be achieved with duplicated operations on the appropriate Extended G-buffers. Extended G-buffers have 
not been implemented yet; it requires more investigation. 5.2 Local Enhancement To draw a picture more 
comprehensibly, local enhancement is often required for some specific regions. This can be pro- vided 
with conventional 2-D paint systems. Various inter- active paint systems have been developed and effectively 
used. A system with useful enhancement tools for techni- cal illustration has also been developed [11]. 
Using such a paint system to enhance computer generated images, a designer can draw an image with any 
enhancement as he likes. However, it requires a great deal of effort to apply the same enhancement technique 
globally, i.e. apply it to a whole image, or a set of similar images such as an ani-mation sequence. 
Furthermore, it is difficult to apply the enhancement uniformly. Our method is mainly for global enhancement. 
How-ever, it is also possible to realize local enhancement by ap- plying operations only where some condition 
is satisfied. The object/patch identifier (the id image) can be effectively used for this condition. 
 5.3 Errors and Artifacts To implement G-buffers, the data type for each property should be carefully 
considered. In our experimentations shown in Section 4, all images including G-buffers are pre- served 
as floating point data in order to avoid digitization errors. However, it is rather inefficient in both 
execution time and memory space. Though it is difficult to gener-ally discuss the required precision 
of images, the following expectation is usually true. The required precision of an image depends on the 
subsequent operations. If the image is just used for linear operations, 1 byte integers are usually sufficient. 
Normal vectors (the nx, ny, nz images) are an example if they are used for the calculation of diffuse 
re- flection only. On the other hand, if the image is used for a differential operation, 2 or 4 byte 
integers or floating point numbers are needed. Since the process of drawing edges has differential operations, 
the sz image must have higher precision. It is also necessary to maintain the precision in the ge- ometric 
processes. If a G-buffer is generated with an ap- O SIGGRAPH '90, Dallas, August 6-10, 1990 proximation 
and is used for a differential operation, unde- sirable artifacts sometimes occur. Such artifacts are 
shown in Fig.3; thin lines shown on smooth curved surfaces are the border of tessellated polygon patches. 
Linear interpolation of normal vectors can make the shaded image smooth, how- ever, the interpolation 
of depth values leads artifacts in the internal edge image. 6 Conclusion We have proposed a new technique 
for rendering 3-D shapes comprehensibly. Enhancement techniques --drawing dis- continuities, contour 
lines, and curved hatching --are de- veloped with 2-D image processing operations, so that these line 
drawing algorithms can be easily combined with con-ventional surface rendering algorithms. By preserving 
ge- ometric properties in G-buffers and visualizing the prop- erties in postprocesses, various combinations 
of enhance- ment techniques can be rapidly examined and a user can efficiently select the best enhancement 
technique. Further- more, G-buffers are also useful for photorealistic rendering. Example images of edge 
enhancement, line drawing illus- trations, topographical maps, medical imaging, and surface analysis 
confirm that our method can be flexibIy and effi- ciently applied in various fields. Acknowledgements 
We would like to thank Dr. Hiroshi Yasuda, Kei Takikawa, Dr. Rikuo Takano, and Dr. Masashi OkudaSra for 
their con- tinuous support. We also wish to thank Prof. Tomoyuki Nishita of Fukuyama University, Mikio 
Shinya, Toshimitsu Tanaka, and other colleagues .in our section for helpful dis- cussions. We are very 
grateful to Dr. Jin Tamai of Nippon Medical School for providing us the original CT image data of Fig.14, 
and Atsushi Kajiyama for his assistance to gen- erate the G-buffers of Fig.14. Special thanks to Michael 
Blackburn for his useful comments. References [1] Beck, J. M., Farouki, R. T., and Hinds, J. K. Surface 
Analysis Methods. IEEE Computer Graphics and Ap- plications 6, 12 (1986), 18-36. [2] Carpenter, L. The 
A-buffer, an Antialiased Hidden Surface Method. Computer Graphics 18, 3 ( Proc. SIG- GRAPH '84) (1984), 
103-108. [3] Cook, R. L. Shade Trees. Computer Graphics 18, 3 ( Proc. SIGGRAPH '84) (1984), 223-231. 
[4] Crow, F. C. A More Flexible Image Generation En- vironment. Computer Graphics 16, 3 (Proc. SIG-GRAPH 
'8~) (1982), 9-18. [5] Dickinson, R. R., Barrels, R. H., and Vermeulen, A. H. The Interactive Editing 
and Contouring of Empirical Fields. IEEE Computer Graphics and Applications 9, 3 (1989), 34-43. [6] Drebin, 
R. A., Carpenter, L., and Hanrahan, P. Vol- ume Rendering. Computer Graphics ~2, 4 (Proc. SIG- GRAPH 
'88) (1988), 55-74. 206 [7] Duff, T. Compositing 3-D Rendering Images. Com-puter Graphics 19, 3 (Proc. 
SIGGRAPH '85) (1985), 41-44. [8] Ghazanfarpour, D., and Peroche, B. A Fast Antialias- ing Method with 
A-Buffer. In Proc. Eurographlcs '87 (1987), 503-512. [9] Higashi, M., Kohzen, I. and Nagasaka, J. An 
Inter- active CAD System for Construction of Shapes with High-quality Surface. In Computer Applications 
in Production and Engineering ( Proc. CAPE '83) (1983), 371-390. [10] Higashi, M., Kushimoto, T. and 
Hosaka, M. On Formu- lation and Display for Visualizing Features and Eval- uating Quality of Free-form 
Surfaces. In Proc. Euro- graphics '90 (to appear). [11] Kondo, K., Kimura, F., and Tajima, T. An Interac- 
tive Rendering System with Shading. In Japan Annual Reviews in Electronics, Computers £4 Telecommunica- 
tions 18, Computer Science and Technologies, Kita-gawa, T. (Ed.), Ohmsha and North-Holland, Tokyo, 1988, 
pp. 255-271. [12] Lorensen, W. E., and Cline, H. E. Marching Cubes: A High Resolution 3D Surface Construction 
Algorithms. Computer Graphics 21, 4 (Proc. SIGGRAPH '87) (1987), 163-169. [13] Mammem, A. Transparency 
and Antia~iasing Algo- rithms Implemented with the Virtual Pixel Maps Tech- niques. IEEE Computer Graphics 
and Applications 9, 4 (1989), 43-55. [14] Nadas, T. and Fournier, A. GRAPE: An Environment to Build Display 
Processes. Computer Graphics 21, 4 (Proc. SIGGRAPH '87) (1987), 75-83. [15] Nakamae, E., Ishizaki, T., 
Nishita, T., and Takita, S. Compositing 3D Images with Antialiasing and Various Shading Effects. IEEE 
Computer Graphics and Appli- cations 9, 2 (1989), 21-29. [16] Newman, W. M. and Sproull, R. F. Principles 
of In- teractive Computer Graphics, 2nd Ed., McGraw-Hill, 1979. [17] Perlin, K. An Image Synthesizer. 
Computer Graphics 19, 3 (Proc. SIGGRAPH '85) (1985), 287-296. [18] Porter, T. and Duff, T. Compositing 
Digital Images. Computer Graphics 18, 3 (Proc. SIGGRAPH '84) (1984), 253-259. [19] Rosenfeld, A. and 
Kak, A. C. Digital Picture Process- ing, 2nd Ed., Academic Press, 1982. [20] Salto, T., Shinya, M., and 
Takahashi, T. Highlighting Rounded Edges. In New Advances in Computer Graph- ics (Proc. CG International 
'89) (1989), 613-629. [21] Udupa, J. K. Display of Medical Objects and their Interactive Manipulation. 
In Proc. Graphics Interface '89, (1989), 40-46. [22] Whitted, T. and Weimer, D, M. A Software Testbed 
for the Development of 3D Raster Graphics Systems. ACM Trans. Graphics 1, 1 (1982), 43-58.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97902</article_id>
		<sort_key>207</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Paint by numbers: abstract image representations]]></title>
		<page_from>207</page_from>
		<page_to>214</page_to>
		<doi_number>10.1145/97879.97902</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97902</url>
		<abstract>
			<par><![CDATA[Computer graphics research has concentrated on creating photo-realistic images of synthetic objects. These images communicate surface shading and curvature, as well as the depth relationships of objects in a scene. These renderings are traditionally represented by a rectangular array of pixels that tile the image plane.As an alternative to photo-realism, it is possible to create abstract images using an ordered collection of brush strokes. These abstract images filter and refine visual information before it is presented to the viewer. By controlling the color, shape, size, and orientation of individual brush strokes, impressionistic paintings of computer generated or photographic images can easily be created.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor>Stand-alone systems**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P221441</person_id>
				<author_profile_id><![CDATA[81100466522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haeberli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anthea Callen, "Techniques of the Impressionists", 1982.]]></ref_text>
				<ref_id>Callen 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37411</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Paul S. Heckbert, "Ray Tracing Brand Gelatin", Computer Graphics, 1987.]]></ref_text>
				<ref_id>Heckbert 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27996</ref_obj_id>
				<ref_obj_pid>27993</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Michael Kass and Andrew Witkin, "Analyzing Oriented Patterns", Computer Vision, Graphics, and Image Processing, 37, 1987.]]></ref_text>
				<ref_id>Kass 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808605</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[John-Peter Lewis, "Texture Synthesis for Digital Painting", Computer Graphics, 1984.]]></ref_text>
				<ref_id>Lewis 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dick Phillips, "Siggraph '88 Panels Proceedings", 1988.]]></ref_text>
				<ref_id>Phillips 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Tom Porter and Sue Goodman, "Designer Primer", Charlse Scribner's Sons, 1988.]]></ref_text>
				<ref_id>Porter 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Franco P. Preparata and Michael Ian Shamos, "Computational Geometry", Springer-Verlag, 1985.]]></ref_text>
				<ref_id>Preparata 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[William T. Reeves and Ricki Blau, "Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems", Computer Graphics, 1985.]]></ref_text>
				<ref_id>Reeves 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Alvy Ray Smith, "Table Paint", SIGGRAPH tutorial notes for "Two Dimensional Computer Animation, 1981.]]></ref_text>
				<ref_id>Smith 79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ray Smith, "The Artists Handbook", Alfred A. Knopf, 1987.]]></ref_text>
				<ref_id>Smith 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15911</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Steve Strassman, "Hairy Brushes", Computer Graphics, 1986.]]></ref_text>
				<ref_id>Strassman 86</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Paint By Numbers: Abstract Image Representations 
Paul Haeberli Silicon Graphics Computer Systems ABSTRACT Computer graphics research has concentrated 
on creating photo-realistic images of synthetic objects. These images communicate surface shading and 
curvature, as well as the depth relationships of objects in a scene. These renderings are traditionally 
represented by a rectangular array of pixels that tile the image plane. As an alternative to photo-realism, 
it is possible to create abstract images using an ordered collection of brush strokes. These abstract 
images filter and refine visual information before it is presented to the viewer. By con- trolling the 
color, shape, size, and orientation of individual brush strokes, impressionistic paintings of computer 
gen- erated or photographic images can easily be created. CR Categories and Subject Descriptors: 1.3.2 
[Com-puter Graphics]: Picture/Image Generation -Display algorithms; 1.3.6 [Computer Graphics]: Methodology 
and Techniques - Interaction techniques; Additional Key Words and Phrases: Painting, image processing, 
abstract images. Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. Introduction This paper is not about radiosity, anti-aliasing, or motion blur. Its not about 
making pictures more realistic. It is about creating interesting abstract representations of natural 
and synthetic scenes. Graphic designers are experts at visual communica- tion. In their work, graphic 
designers use photographic images when they are appropriate, but often chose to use more abstract images 
such as drawings or paintings. In many cases the designer must balance realism and effec- tiveness. Sometimes 
a realistic photographic image may be less effective than a stylized image. In a panel discussion at 
Siggraph 1988 [Phillips 88] on the design of effective images Margret Hagen described the goal of the 
visual artist: "The goal of effective representational image making, whether you paint in oil or in numbers, 
is to select and manipulate visual information in order to direct the viewer's attention and determine 
the viewer's perception." Impressionist painters use brush strokes to control light to simulate objects 
without modelling object detail explicitly. Only a few brush strokes are needed to represent a standing 
figure, a person's face at a distance, or a tree. By carefully selecting tile location, color, size and 
direction of brush strokes, they control visual information to com-municate abstract images to the viewer. 
 A Simple Painting Technique Our goal is to take a synthetic or natural scene, and convert it into abstract 
impressionistic image. We want to make it easy for a user to interactively select and manipu- late visual 
information to explore many different represen- tations of a single source image. To do this we will 
point sample the source image at some set of brush stroke loca- tions, and draw a synthetic brush stroke 
with the appropri- ate color. A simple interactive program allows the user to operate on a source image. 
The basic interactive technique &#38;#169;1990 ACM-0-89791-344-2/90/008/0207 $00.75 207   O SIGGRAPH 
'90, Dallas, August 6-10, 1990 nique "pushing" an edge. This technique can be used to make depth relationships 
between objects in the scene more explicit where they overlap [Porter 88]. To simulate "pushing edges" 
we can high pass filter the original image. High frequencies are enhanced by using unsharp masking. This 
is done as a two step process. First the original image is blurred by convolution. Next we create an 
enhanced image by extrapolating from the blurry image out beyond the original image. To do this we define 
a linear interpolation operation on these two images such that a parameter of 1.0 gives us the blurred 
image and 0.0 gives the original image. To create an image with pushed edges, we make the parameter negative. 
As a result of this fiat fields in the original image will remain unchanged, but edges are accentuated. 
This process has two important variables; how blurry the image is made in the first step, and how much 
we extra- polate in the second step. Convolving with a 3 by 3 kernel, and making the parameter -0.5 will 
accentuate very high frequency detail and change the shading only very near edges. To make the shading 
change within 10 pixels of edges, a kernel with a width of more than 20 should be used. Some interesting 
effects can be created when the kernel is made very large -approaching 20% of the image diameter. An 
artist may chose to enhance the richness of some colors in a scene. Sometimes the color is uniformly 
saturated throughout the scene, or only particular parts of the image are enhanced in this way. If we 
want to increase the saturation of the image first we create a luminance image using a formula like this: 
lum = 0.3*r + 0.59"g + O.ll*b. Next, we extrapolate from the luminance image out beyond the original 
image. Achromatic parts of the image will remain unchanged, but all the colored parts of the image will 
be even more colorful, while preserving the same luminance. It is important that the original image be 
prop- erly color balanced before this is done, otherwise improper colors for skin tones will become obvious. 
When painting solid colored areas, artists may use a wide range of colors to communicate the color of 
a surface. This helps the viewer see a range of component colors in a surface that may be a single, fiat 
color. To add detail to regions of flat color, noise may be added to the image. When this is done, the 
final painting will have brush stokes with an interesting distribution of colors. This can make the final 
painting much more lively and interesting. Most books on painting recommend sticking to a fairly limited 
palette of colors so as to achieve an overall harmony of color across the painting. The palettes used 
by the impressionists usually contained fewer than 12 colors [Callen 82]. These raw colors were mixed 
to create addi- tional intermediate colors. Many beautiful paintings use remarkably few colors. With 
a restricted set of colors some brush strokes in the sky will closely match the color of brush strokes 
used to represent water. Restricting the number of different colors in a painting has the effect of unifying 
the painted image as a whole. By quantifying colors in the source image, we can reduce the number of 
different colors in a scene without restricting the color gamut. If a sufficient amount of noise was 
added as discussed above, then no contouring will be visible. Artists often cover the entire canvas with 
a wash of color before painting the image. The color of this back- ground image can affect how the colors 
are perceived by the viewer if it is left exposed in some areas of the final painting. It has been noted 
by Michel-Eugene Chevreul [Smith 87] that having some proximity to gray makes all primary colors gain 
in brilliance and purity. Allowing the background wash color to be exposed throughout an image gives 
it a kind of unity and integrity. Colors are sometimes used to provide depth cues. Colors in the range 
green (grass), cyan, and blue (sky) recede, while yellow, orange, red and magenta move to the foreground. 
We can use many of the techniques above to enhance digital images before painting begins. Sampling Geometry 
using Ray-Painting These painting techniques can be used to create painted representations of synthetic 
3D scenes as well. When sampling geometry, we have direct access to the color of each surface, its normal, 
and its depth. We can use the surface normal to control the direction of the brush strokes. This provides 
the viewer with valuable informa- tion about the orientation of surfaces. Figure 9. shows a raytraced 
scene, and a painting that uses surface normals to control the direction of brush strokes. To make these 
illus- trations, the user interface of the paint program was attached to a raytracer, letting the user 
reveal the geometry by sampling it in real-time. Notice how the brush strokes appear to wrap around the 
sphere, the cone and the cylinder. Approximating Images by Relaxation An iterative relaxation technique 
may be used to create interesting paintings with remarkably brush strokes. The left side of Figure 10 
shows a painting of 100 rec-tangular brush strokes that approximates an image of a seated man. The right 
side of Figure 10 shows a painting SIGGRAPH '90, Dallas, August 6-10, 1990 of 100 Dirichlet domains. 
These two paintings were created by stochastically perturbing the attributes of the brush strokes, while 
minimizing the root mean squared difference between the original image and the painted representation. 
This process ran for several hours before these images were saved. Conclusions We present several techniques 
for creating static and animated abstract images of photographed and synthetic scenes. In this work, 
the goal is not to make photo-realistic images, but rather effective, interesting images that com- municate. 
By interactively processing an image we can select and manipulate visual information to eliminate dis- 
tracting detail, provide cues about surface orientation, and influence the viewer's perception of the 
subject. It is natural that we want to continue to explore new painting techniques. A logical extension 
of this work would incorporate the texture synthesis work of [Lewis 84] and the brush modelling work 
of [Strassman 86]. Acknowledgements I would like to thank Seth Teller for creating software to support 
rendering Dirichlet domains. I also appreciate the many helpful comments provided by the reviewers. Some 
aspects of this work are patent pending. References [Callen 82] Anthea Callen, "Techniques of the [mpression- 
 ists", 1982. [Heckbert 87] Paul S. Heckbert, "Ray Tracing Brand Gela- tin", Computer Graphics, 1987. 
 [Kass 87] Michael Kass and Andrew Witkin, "Analyzing Oriented Patterns", Computer Vision, Graphics, 
and Image Processing, 37, 1987. [Lewis 84] John-Peter Lewis, "Texture Synthesis for Digi- tal Painting", 
Computer Graphics, 1984. [Phillips 88] Dick Phillips, "Siggraph '88 Panels Proceed- ings", 1988. [Porter 
88] Tom Porter and Sue Goodman, "Designer Pri- mer", Charlse Scribner's Sons, 1988. [Preparata 85] Franco 
P. Preparata and Michael Inn Shamos, "Computational Geometry", Springer-Verlag, 1985. [Reeves 85] William 
T. Reeves and Ricki Blau, "Approxi- mate and Probabilistic Algorithms for Shading and Render- ing Structured 
Particle Systems", Computer Graphics, 1985. [Smith 79] Alvy Ray Smith, "Table Paint", SIGGRAPH tutorial 
notes for "Two Dimensional Computer Animation, 1981. [Smith 87] Ray Smith, "The Artists Handbook", Alfred 
A. Knopf, 1987. [Strassman 86] Steve Strassman, "Hairy Brushes", Com- puter Graphics, 1986.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97903</article_id>
		<sort_key>215</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Direct WYSIWYG painting and texturing on 3D shapes]]></title>
		<subtitle><![CDATA[<h3>An error occurred during the printing of this article that reversed the print order of pages 118 and 119. While we have corrected the sort order of the 2 pages in the DL, the PDF did not allow us to repaginate the 2 pages.</h3>]]></subtitle>
		<page_from>215</page_from>
		<page_to>223</page_to>
		<doi_number>10.1145/97879.97903</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97903</url>
		<abstract>
			<par><![CDATA[This paper describes a 3D object-space paint program. This program allows the user to directly manipulate the parameters used to shade the surface of the 3D shape by applying pigment to its surface. The pigment has all the properties normally associated with material shading models. This includes, but is not limited to, the diffuse color, the specular color, and the surface roughness. The pigment also can have thickness, which is modeled by simultaneously creating a bump map attached to the shape. The output of the paint program is a 3D model with associated texture maps. This information can be used with any rendering program with texture mapping capabilities. Almost all traditional techniques of 2D computer image painting have analogues in 3D object painting, but there are also many new techniques unique to 3D. One example is the use of solid textures to pattern the surface.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15033698</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P221441</person_id>
				<author_profile_id><![CDATA[81100466522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haeberli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>573097</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[APPLE,, Human Interface Guideline: The Apple Desktop Interface, Addison-Wesley, Menlo Park (1987).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BASS, DANIEL H., "Using the Video Lookup Table for Reflectivity Calculations: Specific Techniques and Graphics Results," Computer Graphics and Image Processing 17(3) pp. 249-261 (1981).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319135</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[BIER, ERIC A., "Skitters and Jacks: Interactive 3-D Positioning Tools," Proceedings 1986 Workshop on Interactive 3-D Graphics, pp. 183-196 (October 1986).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42230</ref_obj_id>
				<ref_obj_pid>42188</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BLESER, TERESA W., JOHN L. SIBERT, AND J. PATRICK MCOEE, "Charcoal Sketching: Returning Control to the Artist," ACM Transactions on Graphics 7(1)pp. 76-81 (January 1988).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>965141</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[BLtNN, JAMES F., "Models of Light Reflection for Computer Synthesized Pictures," Computer Graphics 11(2) pp. 192-198 (1977).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMES F., "Simulation of Wrinkled Surfaces," Computer Graphics 12(3) pp. 286-292 (August 1978).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[BL~N, JAMES F., "Raster Graphics," pp. 150-156 in Tutorial: Computer Graphics, ed. K. S. Booth, IEEE Press (1982).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[CATMULL, EDWIN, "A Subdivision Algorithm for Computer Display of Curved Surfaces," Phd dissertation, University of Utah, Salt Lake City (1974).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378497</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[CHEN, MICHAEL, S. JoY MUMFORD, AND ABIGAIL SELLEN, "A Study of Interactive 3-D Rotation Using 2-D Control Devices," Computer Graphics 22(4) pp. 121-129 (August 1988).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[CooK, ROBERT L., "Shade Trees," Computer Graphics 18(3) pp. 223-231 (July 1984).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[FISHKBq, KENNETH, "An Application of Color Science to Computer Graphics," Master's Thesis, University of California, Berkeley, CA (1985).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[FRANCIS, GEORGE K., A Topological Picturebook, Springer-Verlag, New York (1987).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[GARDNER, GEOFFREY Y., "Visual Simulation of Clouds," Computer Graphics 19(3) pp. 297-303 (July 1985).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97902</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[HAEBERLI, PAUL E., "Paint By Numbers: Abstract Image Representations," Computer Graphics, (24)(1990).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[HECKBERT, PAUL S., "Techniques for Real-time Frame Buffer Animation," in Computer FX '84, , London (October 1984).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[HECKBERT, PAUL S., "Survey of Texture Mapping," IEEE Computer Graphics and Applications 6(ll)pp. 56-67 (November 1986).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[KAJr'rA, JAMES T., "Anisotropic Reflection Models," Computer Graphics 19(3) pp. 15-22 (July 1985).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808605</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[LEwas, JOHN PETER, "Texture Synthesis for Digital Painting," Computer Graphics 18(3) pp. 245-252 (July 1984).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74360</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[LEwiS, JOHN P., "Algorithms for Solid Noise Synthesis," Computer Graphics 23(3) pp. 263-270 Ouly 1989).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102332</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[MILLER, GAVIN S. P., "From Wire-Frames to Furry Animals," Graphics Interface "88, pp. 138-145 (1988).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319134</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[NELSON, GREGORY M. AND DAN R. OLSEN, JR., "Direct Manipulation Techniques for 3-D Objects Using 2-D Locator Devices," Proceedings 1986 Workshop on Interactive 3-D Graphics, pp. 175-182 (October 1986).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[NORMAN, DONALD A., The Psychology of Everyday Things, Basic Books, New York (1988).]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[PEACHEY, DAR~, "Solid Texturing of Complex Surfaces," Computer Graphics 19(3) pp. 279-286 (1985).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[PERLIN, KEN, "An Image Synthesizer," Computer Graphics 19(3) pp. 287-296 (July 1985).]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[PORTER, THOMAS AND TOM DUFF, "Compositing Digital Images," Computer Graphics 18(3)pp. 253-260 (July 1984).]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6026</ref_obj_id>
				<ref_obj_pid>6020</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[SALEStN, DAVID AND RONEN BARZEL, "Two-Bit Graphics," IEEE Computer Graphics and Applications, pp. 36-42 (June 1986).]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[SCHNEIDERMAN, BEN, "Direct Manipulation: A Step Beyond Programming Languages," IEEE Computer 16(8) pp. 57-69 (1983).]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[SLOAN, KENNE'rr: R. AND CrmIs'ropHErt M. BROWN, "Color Map Techniques," Computer Graphics and Image Processing 13(4) pp. 297-317 (August 1979).]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[SMITH, ALVY RAY, "Table Paint," in Siggaph '81 Tutorial Notes: Two-Dimensional Computer Animation, (August 1981).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[SMITH, ALVY RAY, "Paint," pp. 501-512 in Tutorial: Computer Graphics, ed. K. S. Booth,IEEE Press (1982).]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801127</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[WARN, DAVID R., "Lighting Controls for Synthetic Images," Computer Graphics 17(3)pp. 13-21 (July 1983).]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801144</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[WH:TTED, TURNER, "Anti-aliased Line Drawing Using Brush Extrusion," Computer Graphics 17(3)pp. 151-156 (July t 983).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91450</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[WILLIAMS, LANCE, "3D Paint," Computer Graphics (Proceedings 1990 Symposium on Interactive 3D Techniques) 24(2) pp. 225-233 (March 1990).]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Direct WYSIWYG Painting and Texturing on 3D Shapes 
 Pat Hanrahan* and Paul Haeberlit *Princeton University tSilicon Graphics Computer Systems Abstract 
This paper describes a 3D object-space paint program. This pro- gram allows the user to directly manipulate 
the parameters used to shade the surface of the 3D shape by applying pigment to its sur- face. The pigment 
has all the properties normally associated with material shading models. This includes, but is not limited 
to, the diffuse color, the specular color, and the surface roughness. The pigment also can have thickness, 
which is modeled by simultane- ously ereating a bump map attached to the shape. The output of the paint 
program is a 3D model with associated texture maps. This information can be used with any rendering program 
with texture mapping capabilities. Almost all traditional techniques of 2D computer image painting have 
analogues in 3D object paint- ing, but there are also many new techniques unique to 3D. One example is 
the use of solid textures to pattern the surface. CR Categories: 1.3.5 [Computer Graphics] Three-Dimensional 
Graphics and Realism -Color, shading, shadowing and texture; Visible line/surface algorithms. 1.3.6 [Computer 
Graphics] Methodology - Interaction Techniques Additional Keywords and Phrases: Painting, direct manipula- 
tion, user-interface Permission to copy without fee all or part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. i. Introduction In recent years the technology of 3D computer graphics is finding 
application in a large number of different disciplines. In the near future, it is likely that the typical 
personal computer or workstation will be fast enough to produce 3D models, anima- tions, and high quality 
computer generated imagery just as easily as the typical personal computer of today produces 2D paintings, 
illustrations, and documents. The key to the widespread use of 3D computer graphics, however, is not 
just dependent on advances in hardware, but requires similar advances in interactive techniques that 
make 3D concepts easy to use and accessible to large numbers of people. There is no reason to think this 
is an impossible task. Almost all the design principles that have been successfully applied to designing 
current user interfaces are likely to apply to 3D applications as well. One such principle is to use 
common metaphors. Users can then rely on their everyday experience to infer how a program works by analogy 
with how everyday things work[I,22]. This principle is easy to apply in 3D computer graphics because 
the 3D world provides so many concrete meta- phors. Another general principle in designing user interfaces 
is direct manipulation[27]. A pointing device such as a mouse can be used to move, drag, or manipulate 
graphics representations on the screen. The act of moving the mouse is directly associated with some 
action to be performed, and feedback is given immedi- ately to reinforce the action. Ideally, the results 
of the interactive action should be a faithful reproduction of the final product, or WYSIWYG (What You 
See Is What You Get). Unfortunately, most applications involving 3D computer graphics are still indirect 
and not WYSIWYG. The most progress has been in positioning and creating geometric models[3,21]. One example 
is the virtual sphere where the user rotates an object by manipulating a hypothetical crystal ball containing 
the object[9]. Another example is to fix a 3D plane and use the same direct manipulation techniques used 
by 2D illustration programs to create and modify geometry on the plane. This 2D geometry can be converted 
to 3D models using sweep operations. More recently, Williams has described how a ordinary paint program 
can be used to sculpt height fields[33]. However, the models needed for computer generated imagery involve 
not only geometric attributes, but also optical attributes that define the pro- perties of materials 
and light sources. One technique for interac- tively modifying the optical properties of a single surface 
illuminated by distant lights is to display an image of quantized surface norrnals (sometimes referred 
to as an orientation coded image) using a colormap whose entries have been set to the &#38;#169; 1990 
ACM -0-89791-344-2/90/008/0215 $00.75 215  @SIGGRAPH '90, Dallas, August 6-10, 1990 the normal. This 
is a reasonable approximation to what might happen if a real 3D brush was being used to paint on a solid 
object, since the brush bends to conform to the sur- face. Since parameter space brushes can be implemented 
much like 2D brushes in a 2D paint program, that method is used at the lowest levels to implement the 
actual painting into texture maps. The other two methods could be implemented by first distorting the 
brush pattern to form a parameter space brush, and then using the distorted brush to perform the painting. 
In general, the distortion of the brush is a complicated non-linear mapping to parameter- space and cannot 
be easily approximated. Fortunately, the map- ping from screen-space to parameter-space is stored in 
the object id buffer. At each xy screen location is the uv parameter that is visible at that location 
and this information can be used to recon- struct the functions u(x,y) and v(x,y). This reconstruction 
of the distortion is valid as long as all mieropolygons contain at least one sample, or, are magnified 
and not minified. Unfortunately, this technique does not work for tangent-space brushes. Another approach 
to simulating screen-space brushes is to simulate spray painting by randomly picking points within the 
brush and apply- ing dabs of paint at these locations. This technique has the nice effect of varying 
the density of the applied paint with the cosine of the angle between the normal and the viewing direction. 
Inclined surfaces receive less paint per unit area than surfaces normal to the direction of view. Resampling 
brushes allows the paint program to undo any distortions due to the surface parameterization, and makes 
the sys- tem feel more natural. Unfortunately, resampling brushes is expensive and involves making simplifying 
assumptions; also, since these brush distortions are done in the innermost loops, they can slow the system 
down. Paint is usually applied to a surface using strokes. A stroke begins when the tablet stylus or 
mouse button is pressed and con- tinues until the pressure is released. Most paint programs allow different 
types of strokes. For example, a rubberstamp only sam- ples the initial position, a rubberband stroke 
allows for perfectly straight lines, and an inteipolated strokes fills in intermediate brush positions 
between sampled cursor positions. All these methods can be used with this paint program. However, there 
are some subtleties in 3D painting that don't come up in 2D painting. One issue is when to terminate 
a stroke. A stroke should always end when there is no object underneath the brush. A stroke should normally 
end whenever a silhouette is crossed, since that would cause the brush to leave the surface momentarily 
as it jumps to its new position. It is reasonable, however, to think that silhouettes should be handled 
differently for screen-space vs. object-space brushes, since a screen-space brush tends to behave like 
spray can. It is also unclear whether paint should be applied to portions of the surface which are back-facing 
even though the center of the brush is on a front-facing surface. Another issue unique to 3D is the fact 
that there may be multiple objects (this would be like having multiple canvases in 2D). A parameter- 
space brush naturally paints on only one object; a tangent-space or screen-space brush, however, might 
feel more natural if it were allowed to paint on multiple objects if positioned near a point of intersection 
or contact between objects. A similar issue comes up when surface patches are pieced together, or joined 
to themselves. Connectivity information is important, otherwise seams might be visible when painting 
across a boundary. Ideally these details about the structure of the model should not be known by the 
user. Surfaces also have two sides, so it is reasonable to require a com- plete set of materials properties 
for the inside and outside surface. 4. Paint Modes and the Paint Equation The mathematics of painting 
is controlled by the paint equation[26, 30]. surface = blend( paint op surface, surface, brush ) This 
equation governs how the brush controls the application of paint to the surface. The brush shape is represented 
by a matte image; the brush is present where the matte image is 1, and not present where the values are 
0. The matte is continuous so that it can represent the partial coverage of the brush over a matte sam- 
ple[32]. The function blend, also sometimes referred to as lerp, linearly interpolates the first two 
arguments under the control of the third argument. blend(cO,cl,a) = (l-a)*cO + a*cl = cO + a*(cl-cO) 
 This blend in the paint equation combines the original values on the surface with the new computed values 
resulting from the interaction of the paint with the surface. There are many different possible paint 
operators. Those based on compositing are described in Salesin and Barzel[26]. The most common of which 
are copy and over. Other possibilities include max to implement z-paint[30,32], filtering Or blurring 
under the brush to simulate smearing or mixing, and sliding the surface values in a certain direction 
to simulate another form of smearir~g. All these painting modes can, in principle, be used when painting 
in 3D. Normally the paint on the brush is a constant material, but it is possible to allow the paint 
to vary as a function of position so that the paint has texture or is patterned. We will refer to this 
as pattern paint. The value of the paint applied at a given position is a function of a constant pigment 
and the pattern. paint = pigment in pattern(P) Ordinary painting can be considered a special case of 
pattern paint, if we use a pattern that is constant. The pattern function can be generated procedurally 
(see, for example, Lewis)[18], or from stored 1D tables, 2D images, or 3D voxel arrays. The pattern is 
combined with the pigment using the in compositing opera- tor[25] which says the pigment is present only 
where the pattern matte alpha values are non-zero. Since patterns don't always con- tain a matte, we 
provide two built-in methods for automatically generating mattes. Self-matting sets the matte to the 
value of the pattern, and opaque-matting sets the matte to 1. In most 2D paint programs, patterns are 
indexed by the coordinates of the canvas. In our 3D paint program, there is a much richer set of pattern 
coordinate transformations. First, there is a question as to what set of variables to use to index the 
pattern. These can be either (i) the surface parameters or texture coordi- nates (u,v), (ii) the screen 
or raster coordinates (x,y), or (iii) the position of points on the surface P. The default method used 
is texture coordinates, since this seems to be most like ordinary pat- tern paint. Using raster coordinates 
is useful if the brush is in screen space and the pattern is designed to simulate a frisket. Finally, 
using the surface position allows solid textures[19, 23, 24] to be used as patterns and leads to many 
new painting styles. When using solid textures as patterns it is also useful to transform points before 
indexing the solid texture. The same solid texture can then be overlaid multiple times with different 
orientations and phases. This is done by positioning the object with respect to a reference cube defining 
the texture coordinate system (by default this cube is aligned with the viewing pyramid) and issuing 
a com- mand which sets transformation to texture coordinates. An operator exists to apply a wash to the 
geometric object. This is equivalent to painting everywhere on the object and is used to set the initial 
material properties and to apply patterns and   ~ Computer Graphics, Volume 24, Number 4, August 1990 
References 1. APPLE,,Human Interface Guideline: The Apple Oesktop Interface, Addison-Wesley, Menlo Park 
(1987). 2. BASS, DANIEL H., "Using the Video Lookup Table for Reflectivity Calculations: Specific Techniques 
and Graph- ics Results," Computer Graphics and Image Processing 17(3) pp. 249-261 (1981). 3. BmR, ERIC 
A., "Skitters and Jacks: Interactive 3-D Posi- tioning Tools," Proceedings 1986 Workshop on Interac- 
tive 3-D Graphics, pp. 183-196 (October 1986). 4. BLESER, TERESA W., JOHN L. SIBERT, AND J. PATRICK 
MCGEE, "Charcoal Sketching: Returning Control to the Artist," ACM Transactions on Graphics 7(1)pp. 76-81 
(January 1988). 5. BLn~N, JAMES F., "Models of Light Reflection for Com- puter Synthesized Pictures," 
Computer Graphics 11(2) pp. 192-198 (1977). 6. BLINN, JAMES F., "Simulation of Wrinkled Surfaces," Computer 
Graphics 12(3) pp. 286-292 (August 1978). 7. BL~N, JAMES F., "Raster Graphics," pp. 150-156 in Tutorial: 
Computer Graphics, ed. K. S. Booth, IEEE Press (1982). 8. CATMULL, EDWtN, "A Subdivision Algorithm for 
Com- puter Display of Curved Surfaces," Phd dissertation, University of Utah, Salt Lake City (1974). 
 9. CHEN, MICHAEL, S. JOY MUMFORD, AND ABIGAIL SELLEN, "A Study of Interactive 3-D Rotation Using 2-D 
Control Devices," Computer Graphics 22(4)pp. 121-129 (August 1988). 10. COOK, ROBERT L., "Shade Trees," 
Computer Graphics 18(3) pp. 223-231 (July 1984). 11. FISHKIN, KENNE'n-I, "An Application of Color Science 
to Computer Graphics," Master's Thesis, University of Cali- fornia, Berkeley, CA (1985). 12. FRANCIS, 
GEORGE K., A Topological Picturebook, Springer-Verlag, New York (1987). 13. GARDNER, GEOFFREY Y., "Visual 
Simulation of Clouds," Computer Graphics 19(3) pp. 297-303 (July 1985). 14. I-IAEBERLI, PAUL E., "Paint 
By Numbers: Abstract Image Representations," Computer Graphics, (24)(1990). 15. HECKBERT, PAUL S., "Techniques 
for Real-time Frame Buffer Animation," in Computer FX '84, , London (October 1984). 16. HECKBERT,PAUL 
S., "Survey of Texture Mapping," IEEE Computer Graphics and Applications 6(ll)pp. 56-67 (November 1986). 
 17. KAJIYA, JAMES T., "Anisotropic Reflection Models," Computer Graphics 19(3) pp. 15-22 (July 1985). 
 18. LEWlS, JOHN PETER, "Texture Synthesis for Digital Paint- ing," Computer Graphics 18(3) pp. 245-252 
(July 1984). 19. LEWIS, JOHN P., "Algorithms for Solid Noise Synthesis," Computer Graphics 23(3) pp. 
263-270 (July 1989). 20. MILLER, GAV~ S. P., "From Wire-Frames to Furry Animals," Graphics Interface 
"88, pp. 138-145 (1988). 21. NmLSON, GREGORY M. AND DAN R. OLSEN, JR., "Direct Manipulation Techniques 
for 3-D Objects Using 2-D Loca- tor Devices," Proceedings 1986 Workshop on Interactive  3-D Graphics, 
pp. 175-182 (October 1986). 22. NORMAN, DONALD A., The Psychology of Everyday Things, Basic Books, New 
York (1988). 23. PEACHEY, DARWYN, "Solid Texturing of Complex Sur- faces," Computer Graphics 19(3) pp. 
279-286 (1985). 24. PERLIN, KEN, "An Image Synthesizer," Computer Graph- ics 19(3) pp. 287-296 (July 
1985). 25. PORTER, THOMAS AND TOM DUFF, "Compositing Digital Images," Computer Graphics 18(3)pp. 253-260 
(July 1984). 26. SALESIN, DAVID AND RONEN BARZEL, "Two-Bit Graph- ics," IEEE Computer Graphics and Applications, 
pp. 36-42 (June 1986). 27. SCHNEIDERMAN, BEN, "Direct Manipulation: A Step Beyond Programming Languages," 
1EEL Computer 16(8) pp. 57-69 (1983). 28. SLOAN, KENNETH R. AND CHRISTOPHER M. BROWN, "Color Map Techniques," 
Computer Graphics and lmage Pro- cessing 13(4) pp. 297-317 (August 1979).  29. SM1TH, ALVY RAY, "Table 
Paint," in Siggaph '81 Tutorial Notes: Two-Dimensional Computer Animation, (August 1981). 30. SMITH, 
ALVY RAY, "Paint," pp. 501-512 in Tutorial: Computer Graphics, ed. K. S. Booth,IEEE Press (1982). 31. 
WARN, DAVID R., "Lighting Controls for Synthetic Images," Computer Graphics 17(3) pp. 13-21 (July 1983). 
 32. WHrFFED, TURNER, "Anti-aliased Line Drawing Using Brush Extrusion," Computer Graphics 17(3)pp. 151-156 
(July t983).  33. WILLIAMS, LANCE, "3D Paint," Computer Graphics (Proceedings 1990 Symposium on Interactive 
3D Tech- niques) 24(2) pp. 225-233 (March 1990).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97904</article_id>
		<sort_key>225</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Reusable motion synthesis using state-space controllers]]></title>
		<page_from>225</page_from>
		<page_to>234</page_to>
		<doi_number>10.1145/97879.97904</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97904</url>
		<abstract>
			<par><![CDATA[The use of physically-based techniques for computer animation can result in realistic object motion. The price paid for physically-based motion synthesis lies in increased computation and information requirements.<sub>1</sub> We introduce a new approach to realistic motion specification based on state-space controllers. A user specifies a motion by defining a goal in terms of a set of destination states. A state-space controller is then constructed, which provides an optimal-control solution that guides the object from an arbitrary starting configuration to a goal. Motions are optimized with respect to time and control energy. Becasue controllers are specified in terms of destination states only, it is easy to reuse the same controller to produce different motions (from different starting states), or to create a complex sequence of motions by concatenating several controllers. An implementation of state-space controllers is presented, in which realistic motions can be produced in real time. Several examples will be considered.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Constrained optimization</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40036809</person_id>
				<author_profile_id><![CDATA[81319502903]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michiel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van de Panne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Electrical Engineering, University of Toronto, Toronto, Canada M5S 1A4]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43117278</person_id>
				<author_profile_id><![CDATA[81100188679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eugene]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fiume]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of Toronto, Toronto, Canada M5S 1A4]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40022802</person_id>
				<author_profile_id><![CDATA[81100021234]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zvonko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vranesic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Electrical Engineering, University of Toronto, Toronto, Canada M5S 1A4]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Alexander. The gaits of bipedal and quadrupedal animals. Int. Journal of Robotics Research, Summer 1984.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[W.W. Armstrong. Recursive solution to the equations of motion of an n-link manipulator. Proc. 5th World Congress Theory Mach. Mechanisms, volume 2, 1343-1346, 1979.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31466</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W.W. Armstrong, M. Green, and R. Lake. Near-real-time control of human figure models. IEEE Computer Graphics and Applications, 7(6):52--61, June 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>573692</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Asada and J.-J.E. Slotine. Robot Analysis and Control. John Wiley and Sons, 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31464</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N.I. Badler, K.H. Manoocherhri, and G. Waiters. Articulated figure positioning by multiple constraints. IEEE Computer Graphics and Applications, 7(6):28-38, June 1987.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Barzel and A.H. Ban'. A modeling system based on dynamic constraints. Proc. of SIGGRAPH" 88 (Aug. 1988). ACM Computer Graphics 22,4, 179-188.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378531</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L.S. Brotman and A.N. Netravali. Motion interpolation by optimal control. Proc. of SIGGRAPH'88 (Aug. 1988). ACM Computer Graphics 22,4,309-315.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Bruderlin. Goal-directed, dynamic animation of bipedal locomotion. Technical report, Simon Fraser University, 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[N. Burtnyk and M. Wein. Computer generated keyframe animation. Journal of the Society of Motion Picture and Television Engineers, 80(3):149-53, March 1971.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Calvert, J. Chapman, and A. Patla. Aspects of the kinematic simulation of human movement. IEEE Computer Graphics and Applications, 41-50, Nov. 1982.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. Csuri. Real time film animation. 1EEE Convention Digest, 42-3, March ! 971.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Featherstone. The calculation of robot dynamics using articulated body inertias, Int. Journal of Robotics Research, 2(1):13-30, Spring 1983.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102315</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D.R. Forsey and J. Wilhelms. Techniques for interactive manipulation of articulated bodies using dynamic analysis. Proc. of Graphics Interface, 8-15, 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31465</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Girard. Interactive design of computer-animated legged animal motion. IEEE Computer Graphics and Applications, 7(6):39-5 l, June 1987.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S, Grillner. Locomotion in vertebrates: Central mechanisms and reflex interaction. Physiological Reviews, 55:247-304, 1975.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Paul M, tsaacs and Michael E Cohen. Controlling dynamic simulation with kinematic constraints, behaviour functions and inverse dynamics. Proc. of SIGGRAPH '87. ACM Computer Graphics 21,4, 215-224.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P.M. Isaacs and M.F. Cohen. Mixed methods for complex kinematic constraints in dynamic figure animation. The Visual Computer, 4:296-305, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D.H. Kochanek and R.H. Bartels. Interpolating splines for keyframe animation. Graphics interface, 41-42, 1984.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. U. Korein and N. I. Badler. Techniques for generating the goal-directed motion of articulated structures. IEEE Computer Graphics and Applications, 71-81, Nov. 1982.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27063</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[B.C. Kuo. Automatic Control Systems. Prentice-Hall, Inc., 1987.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37407</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Lasseter. Principles of traditional animation applied to 3- d computer animation. Proc. of SIGGRAPH'87 (July 1987). ACM Computer Graphics 21,4., 35--44.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. Lasseter and W. Reeves. Luxo jr. Pixar Video, 1986.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5446</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[N. Magnenat-Thalmann and D. Thalmann. Computer Animation: Theory and Practice. Springer-Verlag, 1985.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[R. B. McGhee and G. I. Iswandhi. Adaptive locomotion of a multilegged robot over rough terrain. IEEE Transactions on System, Man, and Cybernetics, 176-182, April 1979.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378508</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[G.S.P. Miller. The motion dynamics of snakes and worms. Proc. of SIGGRAPH'88 (Aug. 1988). ACM Computer Graphics 22,4, 169-178.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[H. Miura and I. Shimoyama. Dynamic walk of a biped. Int. Journal of Robotics Research, 60-74, Summer 1984.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[T. J. O'Donnel and Arthur J. Olsen. Gramps - a graphical interpreter for real-time interactive three-dimensional picture editing and animation. 1981.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[K. Ogo, A. Ganse, and I. Kato. Quasi dynamic walking of biped walking machine aiming at completion of steady walking. Third Symposium on Theory and Practice of Robots and Manipulators, 340-356, Sept. 1978.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[W.H. Press, B.P. Flannery, Saul A. Teukolsky, and William T. Vetterling. Numerical Recipes. Cambridge University Press, 1986.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6152</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[M.H. Raibert. Legged robots that balance. Artificial InteJligence series. MIT Press, Cambridge MA, 1985.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801293</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[C. Reynolds. Computer animation with scripts and actors. Proc. of SIGGRAPH' 81., 1981.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[M.L. Shik and G. N. Orlovskii. Neurophysiology of a locomotor automatism. PhysiologicaIReviews, 56:465-501, 1976.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325243</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[S. Steketee and N.I. Badter. Parametric keyframe interpolation incorporating kinetic adjustment and phrasing control. Proc. of SIGGRAPH" 85 (July 1985). ACM Computer Graphics 19,3.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[D. Sturman. interactive keyframe animation of 3-d articulated models. Graphics Interface, 35--40, 1984.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[M. Townsend and A. Seirig. Effect of model complexity and gait criteria on the synthesis of bipedal locomotion. IEEE Transactions on Biomedical Engineering, 433-444, November 1973.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[M. W. Walker and D. E. Orin. Efficient dynamic computer simulation of robotic mechanisms. Journal of Dynamic Systems, Measurement, and Control, 205-211, Sept. 1982.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16589</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms. Virya: A motion control editor for kinematic and dynamic animation. Proc. Graphics Interface 86, 141-146. Morgan Kaufman, May 1986.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms, M. Moore, and R. Skinner. Dynamic animation: interaction and control. The Visual Computer, 4(6):283-295, 1988.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms. Using dynamic analysis for realistic animation of articulated bodies. IEEE Computer Graphics and Applications, 7(6):12-27, June 1987.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[A. Witkin and M. Kass. Spacetime constraints. Proc. of SIG- GRAPH'88 (Aug. 1988). ACM Computer Graphics 22,4, 159- 168, 1988.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[D. Zeltzer. Motor control techniques for figure animation. IEEE Computer Graphics and Applications, 53-60, Nov. 1982.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Reusable Motion Synthesis Using State-Space Controllers Michiel van de Panne*, Eugene Fiume** and Zvonko 
Vranesic* Department of*Electrical Engineering/**Computer Science University of Toronto Toronto, Canada 
M5S 1A4 Abstract The use of physically-based techniques for computer animation can result in realistic 
object motion. The price paid for physically-based motion synthesis lies in increased computation and 
information re- quirements. We introduce a new approach to realistic motion spec- ification based on 
state-space controllers. A user specifies a motion by defining a goal in terms of a set of destination 
states. A state- space controller is then constructed, which provides an optimal- control solution that 
guides the object from an arbitrary starting con- figuration to a goal. Motions are optimized with respect 
to time and control energy. Because controllers are specified in terms of desti- nation states only, 
it is easy to reuse the same controller to produce different motions (from different starting states), 
or to create a com- plex sequence of motions by concatenating several controllers. An implementation 
of state-space controllers is presented, in which re- alistic motions can be produced in real time. Several 
examples will be considered. CR Categories: 1.3.7 [Computer Graphics]: Three Dimensional Graphics and 
Realism -animation; 1.6.3 [Simulation and Mod- elling]: Applications; G. 1.6 [Constrained Optimization]. 
 Introduction Computer-assisted animation embodies a wide variety of motion-synthesis techniques. Kinematic 
approaches still predominate and are likely to do so, but physically-based techniques are gaining in 
popularity, The cost of greater physical realism has been increased computational cost and information 
requirements. Moreover, it is not usually possi- ble to reuse a previously-computed motion in other contexts. 
The physical modelling of natural phenomena or motions re- quires physical simulation. In such cases, 
one typically de- fines some initial conditions and then invokes a physical sim- ulation of the model. 
In a general animation system, some notion of motion control is also required. In this case, a de- sired 
goal is specified, and the system attempts to generate °The financial assistance of the Natural Sciences 
and Engineering Re- search Council of Canada, and of the Information Technology Research Cen- tre of 
Ontario, is gratefully acknowledged. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. a suitable series of forces and torques on a moving object in order to reach the 
goal from some initial configuration. The control problem is difficult, and it is the focus of this paper. 
We propose the use of encapsulated optimal control laws in the form of state-space controllers. The same 
controller can be used in many different situations, and it can be concate- nated with other controllers 
to produce seamless composite motions. The next section gives an overview of motion spec- ification techniques. 
We then describe our approach, some examples of its use, and future work. 2 Previous Work 2.1 Kinematic 
Motion Synthesis Complex motion synthesis has traditionally been per-formed kinematically using interpolation 
mechanisms such as keyframing [9-11,18,21,23,27,33], Approaches to simpli- fying the specification of 
key positions include inverse kine- matic solutions [5,14,19], and procedural position specifica- tion 
] 10,14,31,41 ]. Keyframes can also be obtained from real moving objects with the use of rotoscoping. 
Techniques for the kinematic specification of cyclic motions such as walking or hopping have also been 
investigated [14,41]. 2.2 Physically-Based Motion Synthesis To satisfy the physical constraints of motion, 
animators have turned to physical simulation [3,7,16,38]. Simulation guarantees realistic, but not necessarily 
desirable, motion. Achieving the desired motion is a difficult control problem. Objects such as articulated 
figures (AFs) are controlled by internal torques applied at the joints. The control problem is to find 
the function of the torques over time that produces the desired motion. Several methods of generating 
the required torque functions have been suggested. One method requires the user to spec- ify torques 
directly [3,13,37,38]. It is in general difficult to come up with the necessary torques to perform desired 
mo- tions through a process of trial and error. One need only ob- serve a backhoe operator to see that 
this is true. An alterna- tive is to use inverse dynamics to solve for the torques re-quired to produce 
a known acceleration [6,8,16,17]. This ap- proach is useful when it is desired to have a portion of an 
ob- ject follow a particular path, or to have an initial guess of the torques needed to perform a motion. 
One can also obtain the &#38;#169;1990 ACM-0-89791-344-2/90/008/0225 $00.75 225 SIGGRAPH '90, Dallas, 
August 6-10, 1990 required torques by using the desired joint positions as set- points for closed-loop 
controllers [3,20]. This models robots controlled by position-servos, permitting kinematic control while 
still utilizing the equations of motion. A solution to a specific inverse-dynamics problem can be encapsulated 
in a dedicated controller or control procedure. This method cleanly partitions the control from the dynamics 
equations. Although the concept has often been suggested in the literature, the construction of the required 
controller or control procedure has always been left to the animator or is constructed using a priori 
information, such as clinical data [8,16,41 ]. Many controllers have been carefully hand- engineered 
to solve specific problems. These include me- chanical bipeds [26,28,35], human walking [8], six-legged 
robots [24], snakes [25], and one-legged hopping robots [30]. Existing controllers have thus far been 
carefully tuned to solve a specific problem. Consequently, they are not likely to be flexible, reusable, 
or optimal with respect to time and en- ergy constraints. The state-controllers proposed in this paper 
seek to overcome these shortcomings. 2.3 Optimal Control Methods Good solutions to the motion control 
problem have been achieved by viewing it as a problem in optimization. A mo- tion can be formulated as 
a two-point boundary problem with the start and end points of the motion sequence being con- straints 
in state space that must be met. An optimization func- tion reflecting the control energy expended and 
time taken for the motion [ 1,7,40] is then minimized to produce the optimal solution (see Figure 1). 
The method of space-time constraints by Witkin and Kass uses a variant of sequential quadratic programming 
to solve the optimization problem, and generates convincing motion [40]. The user provides expressions 
for the total kinetic en- ergy of the object and must express all other constraints in a mathematical 
form. This is something that animators are unlikely to be adept in doing. The solution is also costly 
to compute. Brotman and Natravali [7] present a similar ap- proach to solving the control problem, but 
make use of a dif- ferent mathematical formulation. The same problems exist as for the method of space-time 
constraints. Neither paper suggests the possibility of saving a motion for future reuse. A generalization 
of these approaches would be to define a large set of optimal-control solutions in the form of a general 
control law. /___~_i_~state solution ate-space raversal) state-space for object beginning state Figure 
1: Optimal-control motion synthesis.  3 State-Space Controllers 3.1 Overview We now introduce the main 
contribution of this paper. A state-space controller (SSC) defines a set of control torques that guides 
an object to a specified goal from a large do- main of initial configurations, in a fashion that optimizes 
time taken and energy expended. A goal is characterized by a set of destination states, and depending 
on the nature of this set, several classes of motion are possible. Simple motions include those with 
a stationary destination state. A non-stationary destination state will result in periodic mo- tions 
such as hopping or walking. One can also define mo- tions with goals consisting of many destination states. 
This captures motions in which the terminal velocities or positions of parts of the object are irrelevant. 
For example, in a race, it is irrelevant which part of the body crosses the finish line first. Lastly, 
"conditional" motion can be defined: given more than one destination state, perform the easiest motion. 
While individual SSCs may define interesting motions in themselves, the real power of the approach lies 
in the abil- ity to concatenate SSCs to create a composite motion. SSCs can also be concatenated with 
other motion-generation tech- niques such as motor programs and key-framing, as we shall see later. Consider 
the following example. Suppose Luxo (the jumping lamp, Figure 2) is to hop forward several times, take 
a long forward jump to miss a ditch, and then do a back- flip out of elation of surviving. Given an appropriate 
set of controllers, a user can build (and view) an animation se- quence by writing a script consisting 
of the desired sequence of controllers. Figure 3 depicts the interaction of controllers with an animation 
system. The concatenation of SSCs may be specified in two ways. One way is to run each SSC to its conclusion 
or for a specified duration. The terminal state of this SSC will then become the starting state of the 
next SSC, as in the Luxo example above. An alternative approach is to specify state-space breakpoints, 
in which an SSC is associated with particular regions of state space. An object may thus have a complex 
interleaving of SSCs attached to it. 3.2 Motion through State-Space The state of an object represents 
all the information required to specify the position and velocity of every point on the ob- ject. The 
state space of the object is the set of all possible states that the object can assume. The state of 
a moving ob- Figure 2: The jumping lamp. l double backflip I [ single backflip ] Luxo Controllers L 
short hop t  I l°ng h°p I ~/ control (forces, torques) ~ graphics controller t simulator I pipeline 
state Figure 3: Using state-space controllers ject changes with respect to time. Consider a swinging 
pen- dulum, a simple articulated object (Figure 4). The state of a freely-swinging pendulum continuously 
changes with time under the force of gravity Its angular velocity plotted with respect to time is a near-sinusoid, 
and likewise for the pen- dulum angle. When these two functions are combined to ob- tain the state, the 
resulting path through the state-space of the pendulum is the almost circular path shown in Figure 5. 
By exerting control torques, it is possible to influence the state- space trajectory taken by an articulated 
object. We can use this technique to guide an object toward a goal. This is the central principle underlying 
state-space controllers, g=l.0m /~ m : 1.0 kg / \ I=0333kgm 2 / \ / m,l fixed point ~g o o t,oo \ ....... 
 Figure 4: The pendulum has mass m, length l, moment of inertia I, angular velocity w; 0 is the CCW angle 
from the positive x-axis, and 9 is the force of gravity.  3.3 Specification and Concatenation The motion 
to be executed by a controller is expressed in terms of a set of destination states for the object. The 
state transitions from an arbitrary start state to a destination state are optimized with respect to 
the time and energy taken to perform the motion, and can only use the internal torques that fall within 
the range of torques capable of being ex-erted by the object. The controller thus functions as a con- 
trol law, which defines the optimal-control solutions to a one 400- 200- Angular velocity 0 - (deg/s) 
@ -200 - -400- -180 I -90 I 0 Angle (degrees) I 90 180 Figure 5: Pendulum swing as represented in 
state space. state 1 / state 2 Figure 6: A one boundary-point state-space controller. boundary-point 
problem (the destination state), as shown in Figure 6. In this case, point D represents a destination 
state in a two-dimensional state-space. The arrows show some pos- sible state-space paths that will be 
followed by the object for various initial states. A controller is defined over a user-specified, bounded 
region of state-space called its domain. Figure 7 shows the regions of state space over which controllers 
A, B, and C are defined, as well as three respective destination states, Da, D#, and De. Let So represent 
the initial state of the object. Suppose that while controller A guides the object toward Do, it is desired 
to invoke controller B. Similarly, assume that it is next de- sired to change to controller C. The solid 
line in Figure 7 in- dicates one such set of changes, where Si and $2 are the states at which the new 
controllers are invoked. The only con- straints on $1 and $2 are that Sl C Domain(A) M Domain(B) and 
$2 E Domain(B) fq Domain(C). Clearly, concatenation of controllers need not occur only at destination 
states. 3.4 Structure of Controllers A controller is defined in a local co-ordinate system, and de- 
fines relative motions. Formally, a controller denotes a vector function f : S ~ T, where ,S is a state 
space and 7- is a set of torque tuples. It is entirely possible to define procedural con- trollers based 
on motor programs or kinematic interpolation (see below). We shall focus our discussion on the automatic 
generation of controllers that solve one-point optimal-control problems In our current scheme, a continuous 
state-controller f is syn- thesized from a discrete table of torques in state space. An n- O SIGGRAPH 
'90, Dallas, August 6-10, 1990 o D t state space ~'IID,'- Figure 7: Valid domains for exchanging controllers. 
 dimensional volume forming the controller's domain is regu- larly subdivided into small n-dimensional 
cubes. Here n rep- resents the number of dimensions of the object's state space, or alternatively how 
many numbers are required to specify the object's state. Table elements correspond to the comers of the 
small hypercubes. The torques provided by the tables are made continuous through n-linear interpolation 
in all dimen- sions of the object's state space (e.g., bilinear interpolation in two dimensions). Hierarchical 
or non-uniform sampling is advisable, and is planned. We expect to use better-quality re- construction 
filters when we move to non-uniform sampling. 3.5 The Generation of Controllers It is infeasible (and 
inefficient) to solve a one-point optimiza- tion problem by solving many instances of two-point prob- 
lems. We instead employ a divide-and-conquer technique called dynamic programming. The principle of dynamic 
pro- gramming is illustrated in Figure 8. Suppose path AC is opti- mal. Then the optimal path from any 
state P on AC to state C is given by the subpath PC of AC. If a better alternative path had existed (as 
shown by the dashed line), the optimal path from A to C would contain this subpath. This property is 
true of any monotonically-increasing optimization function of object motion, such as time or expended 
energy. A Figure 8: The principle of dynamic programming. Figure 9 illustrates how dynamic programming 
can be ap- plied to the generation of state-space controllers. Suppose optimal solutions are known for 
states located in region 1, which contains destination state D. To calculate the optimal solutions for 
states located in region 2, we solve a local op- timization problem to get from the current state to 
the edge of region 1. This provides a composite optimal solution for both regions. Clearly, then, an 
appropriate strategy for con- troller generation is to work backward from D, radiating the solutions 
outward. 228 Figure 9: Dynamic programming applied to an SSC. A more detailed picture of the local optimization 
problem to be solved is shown in Figure 10. ON and w~ are the angular position and angular velocity of 
a link of an articulated fig- ure. The quantization intervals of the table entries are given by ql and 
q2. The figure shows the possible state-space tra- jectories as projected onto the g~w~ plane of state 
space. The trajectory taken from state S depends on the angular acceler- ation c~n, which in turn depends 
on the control value (torque vector) contained in the table element corresponding to point S. The local 
optimization problem is to find the control value at S that minimizes the optimization function. ql -I 
I ql > A B O~n >>0 q2 E J °tn = 0 NN~ k D* q2 O~n <<0   (0,0) C Figure 10: The effect of various 
torques applied at S. The optimization function we use is given by two terms: tPsD /op,(PsD) = tPSD + 
KT(t) at. (1) dO The first term represents the time taken to perform the mo- tion, while the second 
term measures the energy expended [1,40]. PSD represents a path through state space from an initial state 
S to a destination D, and tpsD represents the time taken to traverse this path. K is a user-defined vector 
of con- stants that specifies the time/energy tradeoff, and T(t) rep-resents the applied torques (control 
values). A small value of K will minimize the time taken to perform the motion. A large value minimizes 
the energy used to perform the motion. Typical values for K depend on the magnitude of the forces and 
torques capable of being exerted by the object. For our III pendulum example, a value of K = 1 implies 
we are willing to exchange one second of time taken in reaching the desti- nation state for the "energy" 
expended to exert a torque of 1 Newton-metre for one second. Our "energy" term is more properly a measure 
of the effort required to perform a motion. Other objective functions are possible. It is required to 
find the torque vector at S that produces a state-space path PSD such that fopt(PsD) is minimized. The 
solution we currently employ consists of calculating fo,t (PsD) from a set of samples of torque vectors 
and then choosing the vector that results in the minimal value of the optimization function. The samples 
are chosen by uniformly sampling the space of torque vectors (since this space is bounded). This is admittedly 
a slow, brute-force approach whose sole virtue is that it works. For each sample torque vector, the state-space 
trajectory is calculated by simulating the motion of the object. The trajectory is followed until the 
object enters a region of state space in which the value of the optimization function is already known. 
For the path PSD this is indicated as point E in Figure 10. Once the exit state is known, the value of 
the optimization function can be determined from the equation tPsE fopt(PSD) = tPs E --[- KT(t) dt + 
fopt(PED). (2) J0 For the local optimization problem, the values of the opti- mization function are assumed 
to be known at neighbouring points (points A, B, C, and F in Figure 10) and are linearly interpolated 
between the points. The first two terms in Eq. 2 are simply fopt(PsE) (Eq. 1), while the last term represents 
the value interpolated between the values of the optimization function at B and C. Several iterations 
of controller compu- tation are required, because the values of the optimization function at neighbouring 
points may be unknown for the first iteration. In Figure 10, this means that the computation of a control 
value for state S is only accurate if the values of the optimization function are accurately known at 
points A, B, C, and F. It is difficult to sequence local optimizations such that each local optimization 
always uses accurate informa- tion. It is simpler to approximate this order and repeat this for several 
iterations. For each iteration, the value of the op- timization function will decrease. When the maximum 
such change is less than a user-specified value, the solution is as- sumed to be complete. An upper limit 
can also be placed on the number of iterations to use. Technically, this approach only yields a local 
minimum, but the local minimum found has always been satisfactory. 3.6 The Size of State Space While 
generating controllers for objects with few degrees of freedom is feasible, in our current implementation 
the num- ber of state-space dimensions becomes a problem for more complex articulated figures. Both the 
time-complexity of the algorithm and the size of the state-space control table are ex- ponentially dependent 
on the number of state-space dimen- sions. The size of the table is given by n~a, , where ds is the number 
of state-space dimensions (typically twice the num- ber of degrees of freedom since each degree of freedom 
has a position and velocity), and ns is the number of samples per state-space dimension. The time-complexity 
of the al- gorithm is given by O(nsa~n t at), where dt is the number of torques or forces to be applied, 
and nt is the number of sam- ples per torque or force. The problem arises because state space is defined 
as a large bounding hypercube that is uni- formly sampled. There are two main aspects to the prob- lem. 
First, the bounding hypercube is almost always far too large. A user should be allowed to eliminate irrelevant 
ar- eas of state space. Second, uniform sampling is far from optimal. The sampling rate close to the 
destination should be high, but the rate should fall off dramatically with "dis- tance" from the destination. 
Sampling artifacts do not seem to affect the stability of the controller significantly. If the in- terpolation 
of control values between table entries causes the object to drift from the optimal path to the destination 
state, the controller corrects itself because the control values being applied are always computed based 
on the current state. This allows the controller to function properly, even if the object's state changes 
suddenly as a result of a collision involving the object. There is a considerable amount of interesting 
research to be performed in studying the placement and frequency of control-table values in state space. 
 4 Dynamics Formulation To embed state-space controllers effectively in our anima- tion system (see 
below) it is necessary to perform physical simulations quickly. To date, we have focused our formu- lation 
on the planar forward dynamics of articulated figures (AFs). The extension to fully three-dimensional 
articulation is straightforward. (It involves adding a Coriolis-force term and changing moments of inertia 
from scalars to tensors so that the moment of inertia for a link becomes dependent on the current axis 
of rotation.) We assume that AFs have joints and links that can be represented as a tree, with one link 
serv- ing as the root link. A link can have any number of child links, which are connected by a rotating 
joint. The recursive Newtonian dynamics formulation we use is well known [4], and is based on two fundamental 
equations that balance the forces and moments exerted on each link. Ultimately, we solve for the linear 
acceleration of the root link and the angular acceleration for all the links with respect to the root 
link. The accelerations are then numerically inte- grated with an adaptive time step to determine the 
new ve- locity and position of the links. What is important about our approach is that, unlike most previous 
implementations of dynamics formulations, the equations of motion are formed symbolically, directly from 
the basic masses, forces, and in- ertial properties of the object. This is very useful representa- tion. 
We have written a dynamics compiler which can com- pile a brief physical description of the AF into the 
desired equations of motion. The equations generated are of the form Ax = b where A and b are dependent 
on the physical proper- ties and configuration of the links, and x represents the vector of unknown accelerations. 
The output of the dynamics com- piler gives the symbolic value of each of the elements of the matrix 
A and the vector b. In the implementation the values of A and b are output as lines of 'C' code so that 
the equa- tions of motion can be compiled and placed in a library. This makes our system more portable, 
and it allows us to separate the equations of motion from the remainder of the system. SIGGRAPH '90, 
Dallas, August 6-10, ~1990 Special-purpose motions could also be compiled and placed into this library. 
A symbolic representation of the equations of motion also allows a programmer or a compiler to simplify 
the expressions to be computed. For objects containing about 12 joints or fewer [36], the equa- tions 
of motion are best solved using LU-decomposition with back-substitution [29] once the values of A and 
b are calcu- lated. This solution has a complexity of O(n 3) for an AF with n links. O(n) methods do 
exist, but in practice they are only useful for AFs with many degrees of freedom [2,12]. Almost all interesting 
animations of objects involve colli- sions with the environment and have other constraints on the motion 
of the object, such as joint limits and friction. We use springs and dampers to implement collisions 
and joint limits [13,16,39]. We have developed an animation system that incorporates the above dynamics 
formulation, and in which controllers can be generated offline and subsequently scripted for use in re- 
altime animation. Figure 11 depicts our animation system, called Mosys. files ~.~ I prOgrams ~/ ] eontroller 
~ ~d ~ state space ~ ~_~/ . f I I~IM: Iinterface and ~ simulat°r I I ANIst anima Ise~v ,v: I on r I ~ompiled 
in ~~_~ompiled in I ~?=~a~/~ k~ ......... ~f~ I DYNCOMP: [ dynamics [ i i i ! object ......................... 
 Figure 11: Mosys implementation. 5 Examples We now consider several examples of the generation of state- 
space controllers using Mosys. The generation of controllers is entirely separate from their use, and 
are usually computed offiine. Once computed, they allow realtime animation of the objects for which they 
were constructed. 5.1 Periodic Motions A periodic motion, such as a link swinging or Luxo-lamp hopping 
corresponds to a cycle in the object's state-space. A controller that produces a periodic motion is created 
by spec- ifying a destination state with non-zero velocities. As the controller guides the object along 
the state-space cycle, the object performs a periodic motion corresponding to the states 230 passed through 
along the way. One of the many possible pe- riodic, swinging motions of a frictionless, free-swinging 
pen- dulum is shown by the state-space cycle in Figure 5. Motions such as walking or repeated hopping 
can be pro- duced by making the object follow a cyclic path through state space. In this case the state 
representing the horizontal dis- tance denotes the distance to complete one cycle. The value of this 
state increases until the object lands, at which point the state wraps back to the starting position. 
This allows a repeated motion to be described in terms of a state-space cy- cle, which can be modelled 
by a state-space controller. This idea was motivated by the fact that the spinal cord of animals can 
produce a periodic sequence of control signals resulting in periodic walking motions [15,32]. 5.2 Pendulum 
The pendulum has only one degree of freedom and therefore has a two-dimensional state space consisting 
of the angle and the angular speed (see Figure 4). The link is free to rotate in both directions (without 
friction) and has the force of gravity acting on it. The pendulum also has a motor or muscle lo- cated 
at the point of rotation that can exert a control torque on the pendulum. It is easy to represent the 
state-space path of a pendulum using a plot, which helps to illustrate how gen- eral SSCs guide objects 
to a destination. SSCs with various destinations have been generated to con- trol the motion of a pendulum. 
Figure 12 describes an SSC with a destination state of 0 = 0 deg, ~ = 0 deg/s. Ap-plied torques are constrained 
to the range -10 to 10 Nm, and pendulums cannot rotate at absolute angular speeds of more than 500 degrees 
per second. The state-space dimensions of 0 and ~ are divided into 36 and 21 discrete intervals respec- 
tively, yielding SSCs with a total of 756 entries. Figure 13 summarizes the pendulum SSCs that were generated. 
# controller for a single link # controller description commands: # ssd <name> <min> <max> <steps> # 
torq <name> <tmin> <tmax> <tsteps> <Ktorq> # dest <state> dyn linkl # dynamics equations ssd omega 
-500.0 500.0 21 ssd angle -180 170 36 wrap angle torq torque -10.0 I0.0 ii 0.1 dest angle=O omega=O Figure 
12: Specification for pendulum SSCs name destination state generation 0 (deg) w (deg/s) time (s) A 0 
0 381 B 120 0 452 C -120 0 341 D 0 300 460 E -120 -300 459 F 160 250 454 Figure 13: Six pendulum controllers. 
Controllers were corn- puted on a Sun 3/60 workstation.  Figures 14 and 16 depict some state-space plots 
of pendulum motion under control of the SSCs. The scales used for the state-space plots in are as in 
Figure 5. The curve connect- ing each starting state and the destination state represents the state-space 
path'that the pendulum takes when guided by the SSC. The right and left boundaries of the state-space 
plots are connected, giving each plot a cylindrical topology. Controller A Controller B . --m Controller 
E Controller F Figure 14: State-space trajectories followed using various SSCs (C and D omitted). The 
destination state is given by an encircled X, while some sample start states are given by the small squares. 
Controllers D, E, and F define periodic motions because their destination states specify non-zero angular 
velocities (see above). As seen in Figure 14, these controllers eventually drive the pendulum toward 
their respective state-space cy- cles, from all initial states. The state-space cycles are indi- cated 
in the figure with a thick line. The six different SSCs form a library of motion commands for the pendulum. 
Figure 15 shows an animation script used to 'animate' the pendulum, assuming that one would want to endow 
a pendulum with a 'muscle' that can exert a torque at the joint. Figure 16 depicts the resulting motion. 
The animation begins with controller B being used to drive the pendulum to the destination state for 
controller B. The point 'sB' in Figure 16 shows the point at which controller B is invoked, and point 
'dB' denotes the destination state for controller B. After 0.4 seconds of proceeding toward dB, con- 
troller A is invoked for 0.7 seconds. Before it reaches dA (the destination state for controller A), 
controller D is invoked for 0.6 seconds. The remainder of the animation script consists of similar exchanges 
of controllers. While the state of the pendulum is continuous over time, torques (and hence accelerations) 
are discontinuous at the point of controller exchange. Such discontinuities might de- tract from the 
realism of the resulting motion because real actuators (muscles or motors) cannot instantaneously change 
their applied torque or force. A simple solution to this prob- lem is to apply a slew limitation to the 
control values. This would limit the absolute rate of change of the control value,  Computer Graphics, 
Volume 24, Number 4, August 1990 state link -135,350 # starting state swapcon link conB.ctab # invoke 
controller B slm 0.4 # simulate 0.4 seconds swapcon link conA.ctab # invoke controller A smm 0.7 # simulate 
0.7 seconds swapcon link conD.ctab # invoke controller D slm 0.6 # simulate 0.6 seconds swapcon link 
conE.ctab # invoke controller E sam 0.4 # simulate 0.4 seconds swapcon link conC.ctab # invoke controller 
C sam 0.4 # simulate 0.4 seconds swapcon link conF.ctab # invoke controller F sxm 0.7 # simulate 0.7 
seconds Figure 15: A pendulum animation script. D dA adB Figure 16: State-space trajectory of pendulum. 
 resulting in C (2) continuous motion. 6 The Self-Parking Car We now consider the design of an SSC that 
is to parallel-park a car on the street as shown in Figure 17. The car has five state-space dimensions 
shown in Figure 18. The destination state for the ear is given by the dotted line in Figure 17, with 
the car being at rest. The domain of the controller is marked with a dashed line. The reference point 
of the car, located be- tween the front wheels, must remain within this region. The animator can place 
the car anywhere within the domain of the SSC and have it park in a fashion similar to people(!). The 
walls in Figure 17 are additional obstacles to be avoided. The car has two control variables: ~vst, the 
rate at which the steering wheel turns, and ct~, the angular acceleration or de- celeration of the front 
wheels of the car. y (metres) I domain  i _ controller ..... i ] _t__ 5 '.~.~,'.."~~ walls ~ ~ iestination 
state >  curb//~ 1'0 x (metres) Figure 17: The street (non-contact parking only). 231 illlll \ Yworld 
\ \ ~i//~ \ carre~ereliiCe Ycar \ / point I \ / Yc I / j/ ~.If \ I /~f \ I ~eentre of / rotation Xcar 
Xworld Figure 18: State-space dimensions for a car. The final SSC for the car has 13250 states. All 
table en- tries that correspond to collision states are removed while the state-space is being generated; 
thus the SSC algorithm knows these states are out of the controller domain. Some results of the car SSC 
in operation are shown in a sequence of frames in Figure 19. The position of the car is shown every 0.3 
seconds. The parked cars on the right are used to provide a reference showing the destination state for 
the car. In all six cases shown, the car is placed in the initial state at rest, but the wheels are oriented 
differently. The car SSC is then in- voked to park the car. The bottom-left and top-right cars are especially 
interesting. In these cases the cars back up past the desired destination and then drive forward to straighten 
the wheels. 7 Luxo In our next example, Luxo will perform a sequence of in- teresting motions, such as 
jumps and flips. Because we use uniform sampling of the state space to generate a continuous controller, 
two practical problems arise in trying to create a jump or flip controller for Luxo. The first is the 
size of the state space. As illustrated in Figure 20, Luxo has 5 degrees of freedom when in the air, 
and thus has a 10-dimensional state space. The second is that many of the most important states during 
a jump occur during takeoff and landing, when only one edge of the lamp's base is in contact with the 
ground. Since the state space is sampled uniformly without paying special attention to interactions with 
the environment (like the floor), collisions may not be properly sampled. The prob- lem is illustrated 
in Figure 21, which shows the states of suc- cessive table entries. The second state has its base protruding 
through the floor, and would therefore be discarded from the SSC table (removing it from the controller's 
domain). The state that is really of interest is the third one, with the left side of the base touching 
the ground. Both of the above problems serve to show that our choice of uniform sampling is some- 232 
Figure 19: Animation usmg the car-parking SSC. what crude. Fortunately, the remedy for the case of Luxo 
is not difficult. 03 02 Y Figure 20: Degrees of freedom for a jumping lamp. 0=10 ° 0=20 o 0= 13.9 ° 
Figure 21: The collision sampling problem. The problem of state-space size can be solved by breaking 
up canonical Luxo motions into two pieces: airborne motion, and motion on the ground (i.e., takeoff/landing 
motion). It is easy to write motor programs (i.e., procedural functions of torques over time) to make 
Luxo perform a flip or jump. It is very much more difficult to do a correct landing. We thus use motor 
programs for the airborne motions, and a controller to guide Luxo to a safe landing and to prepare it 
for the next mo- tion. All airborne motions begin from a distinguished starting state, which coincides 
with the destination state of the "land- ing" controller. Thus motions based on motor programs can be 
easily concatenated with motions based on SSCs. The "landing" controller only has to deal with 2 degrees 
of free- dom, or a four-dimensional state space, which is quite feasi- ble. The dynamics compiler was 
used to generate the equations of motion for Luxo. Some code was added to the resulting dynamics procedure 
in order to model collisions with the en- vironment, consisting of the floor and a set of stairs. Four 
mo- tions were created for the Luxo animation: a forward jump, a single back flip, a double backflip, 
and a single backflip down a step. Once controllers and motor programs for the individ- ual motions have 
been generated, scripting various anima- tions is a simple exercise. Figure 22 is a sample back-flip 
from the animation. See also the photographs at the end of this paper. Figure 22: A Luxo back-flip A 
brief comparison with previous animations of Luxo is informative. The Luxo Jr. video [22] by Pixar was 
pro-duced entirely using keyframing. The motion was synthe-sized manually and succeeds in looking realistic 
because of the formidable artistic talent of the animators. The reper- toire of motions that Luxo performs 
in the video is not large or complex; most motions are performed with the base on the ground. Witkin 
and Kass obtain a jumping motion for Luxo by formulating it as a two-boundary-point optimization problem 
[40]. The results produced are impressive, but their formulation appears to have a problem with the takeoff 
and landing occurring with only one edge of the base in contact with the ground. Their Luxo jump sequence 
has a takeoff and landing with a flat base. From our experience with the torques necessary to make Luxo 
perform a jump, we are con- vinced that a jump with a flat base on takeoff and landing is very difficult 
to perform and would therefore not be a natural mode of locomotion for a lamp!  Conclusions We have 
introduced a new approach to reusable motion syn- thesis based on state-space controllers. The controllers 
pro- duced are unique in that they are used to control the simula- tion of the object with no a priori 
knowledge of the object or how it should move, apart from a destination goal. The forward dynamics of 
articulated figures is automatically gen- erated from a basic physical description of the object. While 
the use of controllers in physically-based motion syn- thesis is very encouraging, there are several 
aspects that re- quire more thought. First, we wish to carefully compare con- troller response to the 
actual optimal solution. This may al- low us to develop error-control mechanisms for controller generation. 
Second, we would like to create hierarchical or distributed controller structures, in which more "abstract" 
controllers actually manage lower-level controllers in re-sponse to events in the system. Third, a controller 
is cur- Computer Graphics, Volume 24, Number 4, August 1990 rently quite dependent on the specific physical 
parameters of an object. To what extent can controllers themselves be pa- rameterized by, for example, 
interpolating between similar controllers? Fourth, faster controller-generation techniques are required. 
Fifth, better controller sampling and reconstruc- tion techniques are needed. Sixth, we wish to develop 
a better user interface for scripting controllers into significant anima- tions.  References [1] R. 
Alexander. The gaits of bipedal and quadrupedal animals. Int. Journal of Robotics Research, Summer 1984. 
[2] W.W. Armstrong. Recursive solution to the equations of mo- tion of an n-link manipulator. Proc. 5th 
World Congress The- ory Mach. Mechanisms, volume 2, 1343-1346, 1979. [3] W.W. Armstrong, M. Green, and 
R. Lake. Near-real-time con- trol of human figure models. IEEE Computer Graphics and Applications, 7(6):52-61, 
June 1987. [4] H. Asada and J.-J.E. Slotine. Robot Analysis and Control. John Wiley and Sons, 1986. [5] 
N.I. Badler, K.H. Manoocherhri, and G. Waiters. Articulated figure positioning by multiple constraints. 
IEEE Computer Graphics and Applications, 7(6):28-38, June 1987. [6] R, Barzel and A.H. Barr. A modeling 
system based on dy- namic constraints. Proc. of S1GGRAPH" 88 (Aug. 1988). ACM Computer Graphics 22,4, 
179-188. [7] L.S. Brotman and A.N. Netravali. Motion interpolation by optimal control. Proc. of SIGGRAPH'88 
(Aug. 1988). ACM Computer Graphics 22,4,309-3 l 5. [8] A. Bruderlin. Goal-directed, dynamic animation 
of bipedal locomotion. Technical report, Simon Fraser University, 1988. [9] N. Burtnyk and M. Wein. Computer 
generated keyframe ani- mation. Journal of the Society of Motion Picture and Televi- sion Engineers, 
80(3):149-53, March 1971. [10] T. Calvert, J. Chapman, and A. Patla. Aspects of the kinematic simulation 
of human movement. IEEE Computer Graphics and Applications, 41-50, Nov. 1982. [11] C. Csuri. Real time 
film animation. IEEE Convention Digest, 42-3, March 1971. [12] R. Featherstone. The calculation of robot 
dynamics using ar- ticulated body inertias, Int. Journal of Robotics Research, 2(1): 13-30, Spring 1983. 
[13] D.R. Forsey and J. Wilhelms. Techniques for interactive ma- nipulation of articulated bodies using 
dynamic analysis. Proc. of Graphics Interface, 8-15, 1988. [14] M. Girard. Interactive design of computer-animated 
legged animal motion. IEEE Computer Graphics and Applications, 7(6):39-51, June 1987. [15] S. Grillner. 
Locomotion in vertebrates: Central mechanisms and reflex interaction. Physiological Reviews, 55:247-304, 
1975. [16] Paul M, lsaacs and Michael E Cohen. Controlling dynamic simulation with kinematic constraints, 
behaviour functions and inverse dynamics. Proc. of SIGGRAPH '87. ACM Com- puter Graphics 21,4,215-224. 
[17] P.M. Isaacs and M.F. Cohen. Mixed methods for complex kinematic constraints in dynamic figure animation. 
The Visual Computer, 4:296-305, 1988. [18] D.H. Kochanek and R.H. Barteis. Interpolating splines for 
keyframe animation. Graphics Interface, 41--42, 1984.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97906</article_id>
		<sort_key>235</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Performance-driven facial animation]]></title>
		<page_from>235</page_from>
		<page_to>242</page_to>
		<doi_number>10.1145/97879.97906</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97906</url>
		<abstract>
			<par><![CDATA[As computer graphics technique rises to the challenge of rendering lifelike performers, more lifelike performance is required. The techniques used to animate robots, arthropods, and suits of armor, have been extended to flexible surfaces of fur and flesh. Physical models of muscle and skin have been devised. But more complex databases and sophisticated physical modeling do not directly address the performance problem. The gestures and expressions of a human actor are not the solution to a dynamic system. This paper describes a means of acquiring the expressions of real faces, and applying them to computer-generated faces. Such an "electronic mask" offers a means for the traditional talents of actors to be flexibly incorporated in digital animations. Efforts in a similar spirit have resulted in servo-controlled "animatrons," high-technology puppets, and CG puppetry [1]. The manner in which the skills of actors and puppetteers as well as animators are accommodated in such systems may point the way for a more general incorporation of human nuance into our emerging computer media.The ensuing description is divided into two major subjects: the construction of a highly-resoved human head model with photographic texture mapping, and the concept demonstration of a system to animate this model by tracking and applying the expressions of a human performer.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31100534</person_id>
				<author_profile_id><![CDATA[81100005753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lance]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer, Inc., 20705 Valley Green Drive, Cupertino, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Waiters, Graham, The Story of Waldo C. Graphic. ACM SIGGRAPH '89 Course Notes, 3D Character Animation by Computer, August 1989.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907312</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Parke, Frederick I., A Parametric Model for Human Faces. Ph.D. dissertation, Department of Computer Science, University of Utah, 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806812</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Badler, Norman, and Platt, Stephen, Animating Facial Expressions. Proceedings of SIGGRAPH '81 (Dallas, Texas, August 3-7, 1981). In Computer Graphics 15, 3, (August 198t), 245-252.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>912420</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Platt, Stephen Michael, A Structural Model of the Human Face. Ph.D. Department of Computer and Information Science, School of Engineering and Applied Science, University of Pennsylvania, Philadelphia, PA., 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brennan, Susan Elise, Caricature Generator. M.S. Visual Studies, Dept. of Architecture, Massachusetts Institute of Technology, Cambridge, MA. Sept. 1982.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Burson, Nancy, and Schneider, Thomas, "Method and Apparatus for Producing an Image of a Person's Face at a Different Age," U.S. Patent #4276570, June 30, 1981.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37424</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Oka, Masaaki, Tsutsui, Kyoya, Ohba, Akio, Kurauchi, Yoshitaka, Tago, Takashi, Real-Time Manipulation of Texture-Mapped Surfaces. Proceedings of SIGGRAPH '87 (Anaheim, California, July 27-31, 1987). In Computer Graphics 21, 4, (July 1987), 181-188.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lachapelle, Pierre, Bergeron, Philippe, Robidoux, P., and Langlois, Daniel, Tony de Peltrie. {film} 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Waters, Keith, A Muscle Model for Animating Three-Dimensional Facial Expression. Proceedings of SIGGRAPH '87 (Anaheim, California; July 27- 31, 1987). In Computer Graphics 21, 4 (July 1987), 17-24.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lasseter, John, Ostby, Eben, Reeves, William, Good, Craig, Rydstrom, Gary. Tin Toy. {film} Pixar, 1988.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Cyberware Laboratory, Inc.: 4020/PS 3D Scanner, 4020/RGB 3D Scanner with color digitizer. 8 Harris Court 3D, Monterey, California 93940.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Butt, P.J., Ogden, J.M., Adelson, E.H., and Bergen, J.R., Pyramid-Based Computer Graphics. RCA Engineer, Vol. 30, 5, Sept.-Oct. 1985.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Performance-Driven Facial Animation Lance Williams 
Advanced Technology Group Apple Computer, Inc. 20705 Valley Green Drive Cupertino, CA 95014 ABSTRACT 
As computer graphics technique rises to the challenge of rendering lifelike performers, more lifelike 
performance is required. The techniques used to animate robots, arthropods, and suits of armor, have 
been extended to flexible surfaces of fur and flesh. Physical models of muscle and skin have been devised. 
But more complex databases and sophisticated physical modeling do not directly address the performance 
problem. The gestures and expressions of a human actor are not the solution to a dynamic system. This 
paper describes a means of acquiring the expressions of real faces, and applying them to computer-generated 
faces. Such an "electronic mask" offers a means for the traditional talents of actors to be flexibly 
incorporated in digital animations. Efforts in a similar spirit have resulted in servo-controlled "animatrons," 
high- technology puppets, and CG puppetry [1]. The manner in which the skills of actors and puppetteers 
as well as animators are accommodated in such systems may point the way for a more general incorporation 
of human nuance into our emerging computer media. The ensuing description is divided into two major subjects: 
the construction of a highly-resolved human head model with photographic texture mapping, and the concept 
demonstration of a system to animate this model by tracking and applying the expressions of a human performer. 
Cr Categories and Subject Descriptors: 1.3.7 [Computer Graphics]: Three Dimensional Graphics and Realism--Animation. 
1.3.5 [Computer Graphics]: Computational Ge- ometry and Object Modeling -- Curve, surface, solid, and 
ob- ject representations..1.5 [Computer Applications]: Arts and Humanities--Arts, fine and performing. 
General Terms: Algorithms, Design. Additional Keywords and Phrases: Animation, Facial Ex- pression, Texture 
Mapping, Motion Tracking, 3D Digitiza- tion. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. BACKGROUND The seminal work of Parke [2] involved the photogrammetric 
digitization of human faces and expressions, and the creation of a parametric model that used local interpolations, 
geometric transformations, and mapping techniques to drive the features of a computer-animated face. 
Demonstrations of the face in action included lip-synchronized speech. Platt and Badler [3],[4] applied 
physical modeling techniques to the parametric face problem. Once again, the goal was to drive the face 
at a higher level of control. Simulation of muscles in this paper established the use of deformation 
functions, rather than interpolation, to animate a face. Brennan [5], working with hand-digitized 2D 
vector faces, implemented a kind of automatic caricature by exaggerating the differences of individual 
subjects from a prestored "norm." Burson and Schneider [6] established a mapping correspondence between 
facial features in different photographs, a mapping defined by hand-digitizing key points of correspondence. 
Changes in shape and texture between one pair of photographs could then be used to map changes in shape 
and texture to a third. This process has been used to artificially "age" the photographs of missing children 
(that is, to estimate an image of the same child some years hence). Similar mappings have been used by 
Burson and Kramlich (Face Software, Inc., NY., NY.) to interpolate faces and create composites. Concurrently, 
experiments at New York Institute of Technology involved mapping 2D animated features onto 3D characters 
(James Blinn and the author, 1976), and mapping of live-action video faces onto 3D "masks" (3D face surface 
models in which the eye and mouth regions have been smoothed over, so as not to interfere with the moving 
lips and blinking eyes of the mapped video). Live-action mapping was first essayed by Duane Palyka and 
the author in 1977, and was applied by Paul Heckbert in the NYIT videos, "Adventures in Success," and 
"3DV" (1984). At the same time, NYIT researcher Tom Brigham was doing extensive work with screen-space 
(2D) interpolation of texture and form. Brigham's "shape interpolation" was applied to faces, among other 
subjects, and must be considered an influence on this work. One conclusion of these experiments was that 
much of the detail and realism of the faces depicted was simple surface texture. A face model like Parke's 
would be much more powerful and convincing with photographic mapping, and perhaps more individual and 
personable, as well. The photographic mapping of 17] illustrates the power of texture alone, without 
surface shading of any kind. &#38;#169;1990 ACM-0-89791-344-2/90/008f0235 $00.75 235      
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>565650</article_id>
		<sort_key>243</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Fast animation and control of nonrigid structures]]></title>
		<page_from>243</page_from>
		<page_to>252</page_to>
		<doi_number>10.1145/97879.565650</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=565650</url>
		<abstract>
			<par><![CDATA[We describe a fast method for creating physically based animationof non-rigid objects. Rapid simulation of non- rigid behavior isbased on global deformations. Con- straints are used to connectnon-rigid pieces to each other, forming complex models. Constraintsalso provide mo- tion control, allowing model points to be movedaccurately along specified trajectories. The use of deformationsthat are linear in the state of the system causes the constraintmatrices to be constant. Pre-inverting these matrices there- foreyields an enormous benefit in performance, allowing reasonablycomplex models to be manipulated at interac- tive speed.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[constraints]]></kw>
			<kw><![CDATA[simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P18516</person_id>
				<author_profile_id><![CDATA[81100295587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Witkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University, Pittsburgh, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31024562</person_id>
				<author_profile_id><![CDATA[81100043538]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Welch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University, Pittsburgh, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[[1] William W. Armstrong and Mark W. Green. The dynamics of articulated rigid bodies for purposes of animation. In <i>Visual Computer</i>, pages 231-240. Springer-Verlag, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[[2] Alan H. Barr. Global and local deformations of solid primitives. <i>Computer Graphics</i>, 18:21-29, 1984. Proc. SIGGRAPH 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[[3] Ronen Barzel and Alan H. Barr. <i>Topics in Physically Based Modeling, Course Notes</i>, volume 16, chapter Dynamic Constraints. SIGGRAPH, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[[4] Ronen Barzel and Alan H. Barr. A modeling system based on dynamic constaints. <i>Computer Graphics</i>, 22:179-188, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74358</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[[5] John E. Chadwick, David R. Haumann, and Richard E. Parent. Layered construction for deformable animated characters. <i>Computer Graphics</i>, 23(3):243-252, 1989. Proc. SIGGRAPH 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>102331</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[[6] Kurt Fleischer and Andrew Witkin. A modeling testbed. In <i>Proc. Graphics Interface</i>, pages 127-137, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[[7] Michael Girard and Anthony A. Maciejewski. Computational Modeling for the Computer Animation of Legged Figures. <i>Proc. SIGGRAPH</i>, pages 263-270, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[[8] Herbert Goldstein. <i>Classical Mechanics</i>. Addision Wesley, Reading, MA, 1950.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[[9] Paul Issacs and Michael Cohen. Controlling dynamic simulation with kinematic constraints, behavior functions and inverse dynamics. <i>Computer Graphics</i>, 21(4):215-224, July 1987. Proc. SIGGRAPH'87.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74355</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[[10] Alex Pentland and John Williams. Good vibrations: Modal dynamics for graphics and animation. <i>Computer Graphics</i>, 23(3):215-222, 1989. Proc. SIGGRAPH 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>76524</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[[11] John Platt. <i>Constraint Methods for Neural Networks and Computer Graphics</i>. PhD thesis, Caltech, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[[12] John Platt and Alan Barr. Constraint methods for flexible models. <i>Computer Graphics</i>, 22:279-288, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91403</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[[13] Peter Schroeder and David Zeltzer. Dynamic simulation with linear recurive constraint propogation. <i>Computer Graphics</i>, 24(2):23-32, March 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[[14] Thomas Sederberg and Scott Parry. Free-form deformation of solid geometric models. <i>Computer Graphics </i>, 20(4):151-160, 1986. Proc. SIGGRAPH 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[[15] Demetri Terzopoulos, John Platt, Alan Barr, and Kurt Fleischer. Elastically deformable models. <i>Computer Graphics</i>, 21(4), July 1987. Proc. SIGGRAPH '87.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>102333</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[[16] Demetri Terzopoulos and Andrew Witkin. Physically based models with rigid and deformable components. In <i>Proc. Graphics Interface</i>, pages 146-154, Edmonton, Alberta, Canada, June 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[[17] Jane Wilhelms and Brian Barsky. Using dynamic analysis to animate articulated bodies such as humans and robots. <i>Graphics Interface</i>, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[[18] Andrew Witkin, Kurt Fleischer, and Alan Barr. Energy constraints on parameterized models. <i>Computer Graphics</i>, 21(4):225-232, July 1987. Proc. SIGGRAPH' 87.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91400</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[[19] Andrew Witkin, Michael Gleicher, and William Welch. Interactive dynamics. <i>Computer Graphics</i>, 24(2):11-22, March 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[[20] Andrew Witkin and Michael Kass. Spacetime constraints. <i>Computer Graphics</i>, 22:159-168, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Fast Animation and Control of Nonrigid Structures Andrew Witkin and William Welch School of Computer 
Science Carnegie Mellon University Pittsburgh, PA 15213  Abstract We describe a fast method for creating 
physically based animation of non-rigid objects. Rapid simulation of non- rigid behavior is based on 
global deformations. Con-straints are used to connect non-rigid pieces to each other, forming complex 
models. Constraints also provide mo- tion control, allowing model points to be moved accurately along 
specified trajectories. The use of deformations that are linear in the state of the system causes the 
constraint matrices to be constant. Pre-inverting these matrices there- fore yields an enormous benefit 
in performance, allowing reasonably complex models to be manipulated at interac- tive speed. Keywords 
-- Constraints, Simulation, Animation  Introduction A good deal of work has been done toward the use 
of physical simulation as a means of producing animation. Despite the wealth of impressive results, physically 
based modeling is not in wide use, because of the unfamiliarity and complexity of the methods, because 
of the computa- tional expense of simulation, and because of the difficulty of controlling simulated 
objects. In this paper we present a fast and simple formulation for building and controlling models composed 
of non-rigid pieces. Our method has three major parts: Non-rigid objects. Our model for non-rigid dynamics 
is based on global deformations with relatively few degrees of freedom. This formulation provides objects 
that deform Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. in a geometrically simple but physically correct way. A further simplification is achieved 
by restricting attention to deformations that are linear in the system's state variables. This class 
includes both free-form deformations of the sort described in [14], and simpler affine deformations. 
One beneficial effect of this simplification is that the body's mass matrix is constant, allowing it 
to be pre-inverted. Attachment constraints. Point-to-point attachment constraints are used to build complex 
models from the simple non-rigid pieces. Attachment constraints are im- plemented using a method fully 
described in [19], and related to those in [4] and [11]. The idea is to calculate a constraint force 
that accurately counters applied forces that would otherwise pull the pieces apart. Ordinarily, obtaining 
the constraint force requires the solution of a linear system at least once per time step. The linear- 
ity restriction, however, causes the constraint matrix to be constant, except when constraints are added 
or deleted. By pre-inverting this matrix, we need only perform a matrix multiplcation instead of an inversion 
at each step. Motion control. The same machinery that supports attachments allows specified object points 
to be moved accurately on arbitrary trajectories. Controlling the motion of a point is not fundamentally 
different from nailing it in place, except that the "nail" is moving as a known function of time, giving 
rise to simple additive terms that take account of its motion. As with attachment constraints, the restriction 
to linear deformations ensures a constant constraint matrix. Together, these elements give us the capability 
to cre- ate non-rigid pieces, wire them together in arbitrary ways, then control the motion of arbitrary 
points on the objects. A reasonably accurate view of the resulting models is to regard them as articulated 
puppets, whose parts are made of rubber, jello, or other non-rigid materials, with spec- ified points 
under full control of the "puppeteer." Our The work reported in this paper was support in part by Apple 
Computer. &#38;#169;1990 ACM-0-89791-344-2/90/008/0243 $00.75 243 G SIGGRAPH '90, Dallas, August 6-10, 
1990 method is fast enough to be practical: using widely avail- able hardware, we can achieve interactive, 
even real-time performance with models that are complicated enough to be interesting subjects for animation. 
This basic capability is only a starting point. Given the ability to control the motion of arbitrary 
points, how shall we specify where they should go? Interesting approaches include direct manual control 
and interactive keyframing. Our recent emphasis, however, has been on the develop- ment of a vocabulary 
of goal-directed behaviors that are chained to create complex actions. An example of a sim- ple atomic 
behavior is one that smoothly moves a body point to a specified position and velocity over a specified 
time interval. A slightly more elaborate one makes a body point chase and capture a moving target point. 
Simple chaining permits the specification of compound actions such as "Make point a grab point b, move 
it to point c, then let go." 1.1 Background A number of authors have investigated the use of articulated-body 
dynamics for animation [ 1, 17, 7, 9, 13]. Several of these employ highly efficient recursive dynam- 
ics formulations, but they are specific to articulated models composed of rigid bodies. The use of non-rigid 
dynamics for animation has been described in [15, 12, 16, 5, 10] The use of large finite-difference meshes, 
(or of mass- spring lattices, which are essentially equivalent,) poses a performance problem for two 
reasons: first, such systems possess many degrees of freedom, and second, they tend to lead to stiff 
equations which are expensive to solve. In [ 10], Pent/and and Williams describe the use of modal analysis 
to create simplified dynamic models. By discard- ing high-frequency modes, the dimensionality and stiff- 
ness of the models are both drastically reduced. The mod- els we develop here yield similar advantages, 
though we arrive there by a very different route. The use of constraint methods for model creation and 
motion control has been extensively treated. [3, 18, 7, 9, 4, 12, 11, 20, 19, 13] A number of these entail 
the use of inverse dynamics to calculate constraint forces. The formulation employed here, which is based 
on the method of Lagrange multipliers, is described fully in [19t, and is also closely related to that 
presented in [ 11 ].  2 Linear Deformations 2.1 The mechanics of global deformations A global deformation 
[2, 14, 6] is a mathematical function that maps space to itself by assigning new, deformed co- ordinates 
to each point within some region of undeformed space. Applying a global deformation to an object entails 
244 deforming the space in which the object sits, allowing the points on the object's surface to be carried 
along. Any given deformation has associated with it some control pa- rameters, such as bend or twist 
angles, that govern its behavior. Global deformations were originally introduced as a purely geometric 
modeling tool, allowing primitive shapes to be modified in stylized but interesting ways by manually 
adjusting the parameters. Global deformations may also be made to serve as a substrate for simplified 
nonrigid dynamics by augment- ing them in two respects: we embed masses in the space on which the deformation 
acts, and we define an energy of deformation that induces the desired behavior, such as elasticity or 
volume preservation. As with the simplified modal models of [10] the use of simple global deforma- tions 
offers the twin advantages of reduced dimensionality and the elimination of the high-frequency components 
that lead to stiffness. In return for this large performance ad- vantage, we naturally give up the ability 
to deform our objects in ways that cannot be represented using the cho- sen global deformation. As an 
aid to understanding the derivation that follows, imagine a cloud of fixed point masses, all subjected 
to a global deformation. Although stationary in undeformed coordinates, the deformed points would be 
seen to move in response to a change of the deformation parameters. The addition of mass thus associates 
with any parame- ter displacement a mass displacement. This association allows us to express the body's 
inertial proprties, in par- ticular its kinetic energy, as a function of the deformation parameters and 
their time derivatives. Once we have ex- pressed the kinetic and potential energies as a function of 
the parameters, Lagrange's equations of motion(see [8] or any other classical mechanics text) provide 
a cookbook procedure for deriving the equations of motion, producing a generalization of the familiar 
f =nm. In the parlance of Lagrangian dynamics, the vector of parameters consti- tute the system's generalized 
coordinates, which we will denote by q. To derive Lagrange's equations one must first express the kinetic 
energy T as a function of q and q, and the potential energy V as a function of q. In terms of the Lagrangian, 
defined as L = T -V, Lagrange's equations are then _ OL) OL Q--o, (l) d (oq -0---7 - where Q is the 
force in q-space, known as generalized force. The kinetic energy of a particle at position ~' with mass 
m is just ½~n~ "2, and the kinetic energy of a deformable body is the sum of its mass points' kinetic 
energy. For an arbitrary deformation, the velocity of a particle is where the Jacobian matrix J is defined 
by Oxi Jij = Oqj" If the mass at x is m, then the kinetic energy due to the point mass is 1 r = mxixi 
= ~InJijJi#@Ok. (2) and the kinetic energy of the whole body is just the sum of this quantity over all 
the point masses. In the case of a continuous mass distribution, the sum becomes an integral and mass 
is replaced by mass density. The form of the potential energy V depends on the desired behavior. For 
example, in a global bend defor- mation with bend angle 0, an energy term of the form V = (0 -0r) 2 would 
attract 0 elastically to the rest value Or. The generalized force Q is typically due to point forces 
applied to the object. The generalized force due to a point force f applied at :r is Q = fiJij, with 
the Jacobian J evaluated at x.  2.2 Linear deformations The preceding discussion applies to any deformation 
func- tion. However, the Lagrangian equations of motion sim- plify greatly for deformations that are 
linear functions of the state. Such deformations may be expressed in the form xl = Rijpj, where 3" is 
a world-space point, the components of matrix R are the generalized coordinates, and p is a function 
of the undeformed point, but not of R or of time. While deformations of this form are linear in the state 
R, z may depend nonlinearly on the undeformed coordinates through the function p. For example, p might 
be defined by p(x, y, z) = [1, x, y, z, xy, xz, yz, x 2, y2, z2], which is 2nd order. In fact, any polynomial 
deformation may be cast in this form. Since p is not a function of time, we then have point velocity 
xi = t~ijpj and kinetic energy I In index notation, an unsubscripted quantity is a scalar, one subscript 
denoles a vector, and two denote a matrix. Under the summation con- vention,the appearance of any index 
twice in a term implies summation, so that Mij vj means Ej A4ij vj, which is matrix M times vector v. 
where M is a constant symmetric mass matrix defined by Mjk = E (mpjpk ) , with summation performed over 
all the mass points in the body. For the sake of readability, we will omit the potential en- ergy V, 
noting that the force due to V is - (OV/Oq), which may be subsumed in the generalized force Q. Therefore 
the Lagrangian is just L = T. To obtain Lagrange's equa- tions, we observe that OL 1 @i~j~]-li~,. + 6i~k,t~ij) 
Mj~, (3) O[L.~ -2 where the 6's are Kroeneker deltas, defined by ~ij = 1 if i = j, and zero otherwise; 
that is, the identity matrix. Using the identity ai~ij = aj, and also the symmetry of M, we obtain OL 
-R,.A~Mk~. OR~ It follows straightforwardly that dt and also that OL --0. OR,.~ Combining these pieces, 
Lagrange's equations are /~jM~.-Oil. = o, (4) and since M is constant, its inverse W may be pre-computed, 
giving h~j = @~,Wkj. (5) Finally, the generalized force Q due to a force f applied at world-space point 
:ci = Rijpj is Oxi _ fiSi,.£j~pj = f,.p~. O,'~ = LOR~, The inverse mass matrix W represents the linear 
func- tion that maps forces into accelerations. The fact that W is constant affords some gain in efficiency 
in solving equation 5 because the matrix need not be inverted anew at each step. This is not a large 
advantage because the matrix is relatively small. The major benefit of a con- stant 14 7 will emerge 
later in the discussion of constraints. Figure 1 illustrates a second-order deformable object, with p(x,y,z) 
= [l,x,y,z, xy, xz, yz, x2,y2,z 2] ,andwithR a 3 × 10 matrix. 245  2.3 Affine deformable bodies A particularly 
simple linear deformation has where r is a point in body coordinates, and 'H?,I 1 TD,21 'Ht31 /7/12 ~22 
/71/,32 Rij = /'/Zi3 T/~23 m33 tl t2 t3 which resembles a homogeneous transformation matrix with the 
rightmost column deleted. The 3 x 3 subma- trix m is an ordinary 3D transformation matrix, and t is a 
translation vector. A body defined by subjecting mass points to this deformation is permitted to undergo 
affine transformations--translation, rotation, stretch, and shear, with equations of motion as given 
in equation 5. Despite the limited range of deformations they afford, affine de- formable bodies offer 
two significant advantages: first, graphics workstations perform affine deformations very quickly; and 
second, the potential energy terms that yield elastic and volume preserving behavior become extremely 
simple. 2.4 Potential energy functions for affine bodies An affine deformable body is in its undeforrned 
state ex- actly when the submatrix m is an orthogonal matrix, de- fined by TI).ijlTLik = 6jk. To see 
why, note that the squared magnitude of a transformed vector xj is ?3Zijl)LikXjZ k. This is equal to 
the squared magnitude of :e for all x ex- actly when m is orthogonal. An energy function whose minimum 
lies at the undeformed state is Ve = k~ Imijmi~ -6jk[ 2 , where/% is a stiffness constant. This is a 
"rigidity" term, giving elastic behavior. The affine deformation is volume preserving exactly when det(m) 
= 1, so that an energy function that resists compression and dilation is Vc = kc [det(rn) -112, where 
kc is also a stiffness constant. The imposition of this term gives a body that, when stretched along 
one dimension, reacts by squashing along the others, and vice versa. The required gradients that give 
the forces due to both these energy terms are readily derived. Velocity depen- dent damping forces may 
be imposed on these and other potential functions using the form Qij ~--kdV OV ORij ' 246 where kd is 
a positive drag constant. Adjusting the stiff- ness and drag constants yields a wide range of physical 
behavior, from a bouncy jello-like response to near rigid- ity. 3 Constrained Dynamics In [19] we present 
a general formulation for constrained dynamics, similar to that of [11], and more loosely related to 
[4]. Here we briefly summarize the general solution, then develop the simplified form for deformable 
bodies defined by linear deformations. 3.1 The general form If vector q represents the state of a physical 
system, then a holonomic constraint may be defined implicitly by a func- tion c(q, t), where the states 
consistent with the constraint are those that satisfy c(q, t) = 0. For example, if a and b are points 
whose world-space coordinates depend on state, then a(q) -b(q) = 0 is a constraint that requires the 
points to coincide. If multiple constraints are to be met simulta- neously, then c is a vector all of 
whose components must vanish. If the system begins in a legal state, with c = 0 and d = 0, then requiring 
that ? = 0 thereafter suffices in principle to hold the constraints in force. 6 depends on the acceleration 
q, so requiring that ~ = 0 defines a sub- space of legal accelerations. Because ~/in turn depends on 
force, the problem of constrained dynamics is to calculate a constraint force that projects the acceleration 
into the legal subspace. Because it is expressed differentially, this turns out to be a linear problem 
even when the constraints depend nonlinearly on state. To obtain the constraint equations we first express 
~ as a function of/~. Applying the chain rule twice gives OCi OCi OZci ~i = --~ij + --qj . + --(6) Oqj 
Oqj Ot 2 ' noting that O~i 02ci Oqj = OqjOqk (]~'" The term 02Ci/O~ 2 reflects the direct dependence, 
if any, of c on time, in contrast to its indirect time dependence through q. The equations of motion 
in turn give ~/as a function of the known applied force Q and an as yet undetermined constraint force 
C, according to iij = W~(C~ + Oh), where W is an inverse mass matrix. Substituting into equation 6 and 
setting ~ to zero gives Odi . d2ci Oc~ wjk(c~. + qk) + + = 0, (7)    oqj 5-£qjq -d-it where only 
the constraint force C is unknown. Equation 7 gives a set of linear conditions that C must satisfy, but 
in general there are fewer equations than unknowns. This deficiency is rectified by requiring that the 
constraint force does not add or remove energy from the system, which leads to the requirement, known 
as the principle of virtual work, that the constraint force be a linear combination of the constraint 
gradients. This in turn means that C must satisfy OctCj = Ai Oqj' for some vector A. The 3,'s are known 
as Lagrange mul- tipliers. Substituting for C in equation 7, after some re- arrangement, gives r Oci 
oct] oci o~i o%i -.lN: j : =-Wj Q + --OOj + -- oqj Oqj Ot 2 ' (s) in which the matrix on the left hand 
side is square, with dimensions of the constraints, and only A is unknown. The constraints are enforced 
by solving equation 8 for A, using A to compute C, adding C to the applied force, and computing the constrained 
acceleration 0". In practice, an additional feedback term must be added to the force to inhibit drift, 
and also to bring the system to a legal state initially. Including the damped feedback term, the total 
force becomes Oci Qj + (Ai + aci + flci) Oqj where a and/3 are constants. Equation 8 refers to the entire 
constrained system. In a system comprising a number of distinct objects, the global state vector q is 
formed by concatenating those of the original objects, and the constraint vector e is formed by concatenating 
the constraints. The inverse mass matrix W is block diagonal, receiving a block from each object. The 
constraint Jacobian receives a non-zero block for each constraint/object pair for which the constraint 
depends on the object. Although we have written the constraints as direct func- tions of state, in practice 
there is usually an intermediate quantity to which constraints are applied. For example, a constraint 
that nails a pair of points together depends on the points, and the points' coordinates depend in turn 
on the respective objects' state. See [19] for a general parti- tioning scheme that exploits this kind 
of structure. In brief, if e is a constraint on one or more points, x is a point on which c depends, 
and q is the state of the object to which x is attached, then the chain rule gives Oci Oci Oxk Oqj OXk 
Oqj ' as the Jacobian block representing c's dependence on q through the point x. 3.2 Impulses When 
very large forces act for very short times, producing large transient accelerations, it is often useful 
to describe the behavior of the system in terms of the integral over the short time interval, neglecting 
the internal dynamics of the event, and to treat the duration of the event as zero. The force integral 
is known as an impulse. Instead of accelerations, impulses produce instantaneous changes in velocity. 
The calculation of an impulse response closely resembles that of an acceleration. The equation qi = wljQj 
becomes A0i = wij[j where I is the impulse, and A 0 is the change in velocity. In computing an impulse 
all non-impulsive forces, such as gravity, are neglected. Impulses are most frequently encountered in 
the anal- ysis of collisions. Here, we are interested in impulses in connection with motion control, 
where we may wish to allow the prescribed velocity of a controlled point to un- dergo a discontinuous 
change. The desired discontinuity appears in the direct derivative of the constraint with re- spect to 
time, leading to an equation similar to equation 8: r Oci OcT ] A Oci where the right hand side gives 
the constraint discontinu- ities. Once A is obtained, the constraint impulse is I = Ai Oci. Oqj  3.3 
Linearly deformable bodies Now we recast equation 8 for the special case of a sys- tem of linearly deformable 
bodies, subject to constraints each of which depends linearly on one or more points on the bodies. This 
restricted class of constraints includes point-to-point attachments, and constraints that nail points 
in place or require them to follow arbitrary known trajec- tories. This set is thus sufficient for building 
models by attaching deformable pieces together, and controlling the models by controlling the motions 
of specified points. The benefit of imposing this restriction is a large one: the con- straint matrix 
on the left hand side of equation 8 remains constant, except when constraints are added or deleted. The 
matrix is inverted whenever the constraint structure changes, after which evaluating the constraint force 
re-quires only a matrix multiply rather than the solution of a linear system. Figure 2 illustrates the 
behavior of linearly deformable bodies subjected to attachment constraints. If x is a point on a linearly 
deformable body then its derivative with respect to the body's state is Oxi _ 0 On,,~ OR,.~ (R~jpj) = 
,%p~, which is a constant. Because each constraint is a linear function of one or more points, the derivative 
of any con- straint c with respect to a point x is a constant as well. Hence the global constraint Jacobian 
is composed of con- stant blocks each having the form 61~p,, possibly times a constant. For example, 
a two-point attachment constraint of the form ai -bi = 0 yields two such blocks, one positive and the 
other negative. Because x is a vector and R is a matrix, the derivative has rank 3. In practice, though, 
the R's are flattened and concatenated to form the global state, so that in an expression like tSi,.ps, 
the r and s are combined to form a linearized state index, and the quantity may then be viewed as a block 
in the global matrix. The bookkeeping involved in performing these index calculations is greatly simplified 
by the use of a block-sparse matrix data structure, in which a matrix is composed of a collection of 
rectangular blocks. Operations such as matrix-times-vector and matrix-times- matrix are readily implemented 
in terms of this structure. Once the constant Jacobian matrix has been computed, the left-hand-side matrix 
of equation 8 can be calculated and inverted. Because ~ does not depend on q, one term of the equation 
vanishes, giving OCi 02 C i . (10) oqj where Y is the inverted constraint matrix. Motion Control The 
preceeding sections provide the machinery required to animate a collection of connected objects--a puppet, 
for example by moving control points on the puppet as arbitrary functions of time. As the control points 
follow their assigned paths, the rest of the puppet moves with correct passive dynamics. We begin this 
section by con- sidering the generic problem of constraining a point to follow a known trajectory. Given 
this capability, we pro- ceed to treat the issue of generating motion paths both by interactive keyframing 
and by the specification of motion goals. A constraint that nails a point p at a fixed location n may 
be written Rijpj -ni = 0. Such a nail constraint depends on time only indirectly, through R, so that 
the constraint's contribution to the direct time derivative term of equation 10 is zero. Suppose that 
the nail position n is not constant, but is instead a known, twice-differentiable function of time, u(t).2 
By saying that n(t) is known, we mean that we have a way to evaluate ~z, h, and fi at the current time. 
We need not know anything further about 2We may relax this requirement to piecewise differentiability 
by in- serting impulses at velocity discontinuities, the form of n or the manner in which it is computed. 
The control constraint then becomes Rijpj -hi(t) = O, with direct second time derivative 02C 02n Ot 
2 Ot 2 Inserting this term into equation 10 induces a constraint force that causes point p to move with 
the desired acceler- ation. The feedback term + fl4i) ~ff/i3 inhibits drift from the desired trajectory. 
Note that Ot ' so that the feedback term as well as the constraint force take account of the desired 
motion. Depending on the acceleration supplied at each instant in time, the control point can be made 
to accurately follow any piecewise twice-differentiable trajectory. This form of control is analogous 
to attaching a jet engine at the control point and continuously adjusting its thrust to drive the point 
along the desired path. Note that it is not necessary that the path be completely specified in advance---only 
values at the current time need be known. Having the general ability to control the motion of points 
on an object makes it possible to separate the problem of motion specification from that of enforcing 
the specified motion. We now consider two approaches to motion spec- ification: keyframing, and goal-directed 
motion. 4.1 Keyframed Motion Paths A direct extension of standard animation techniques is to specify 
control point trajectories by interpolating between keyframes. If a user is allowed to intcractively 
position control points on arbitrary frames, piecewise cubic splines passing through the keyframed points 
suffice to provide the required values for n, n, and fi at each instant in time. Provided that position 
and velocity are matched at the beginning of a keyframed motion, our models are able to track the keyframed 
paths accurately and stably at interactive speeds. Experiments quickly showed us that physical keyframe 
control differs fundamentally from standard direct control of object parameters. First, the quantities 
that we are able to control are more likely to be the ones that we want to control. Second, we are permitted 
to employ far fewer degrees of control than degrees of freedom, the rest of the motion being determined 
by physics. This is a property with no counterpart in conventional keyframing, where nothing moves unless 
we move it. To fully exploit the ability to refrain from controlling all aspects of the motion, control 
points ought not to be re- garded as persistent entities whose keyframed trajectories span an entire 
scene. The style of keyframe control that we believe will be most effective is based on the ability to 
freely turn control points on and off during an animation, establishing and relinquishing control as 
required. For ex- ample, in animating a walk it is necessary to control heel, toe, knees, hips, shoulders, 
etc., but not all at the same time. The heel position must be accurately controlled just before and during 
the support phase, but during the swing the heel can simply be allowed to follow the toe. It would be 
an unnecessary burden to specify the heel's position all the time. The ability to turn control points 
on and off raises tech- nical issues. Turning a path constraint off is simply a matter of letting the 
point "go ballistic," eliminating the relevant blocks from the constraint matrix, and turning off the 
restoring forces. Turning a path constraint on in the midst of an ongoing motion is more difficult: at 
the moment that control is initiated, the position and velocity of the point being controlled must match 
those specified by the splined trajectory. However, the point's state can- not generally be predicted 
in advance. We handle this problem using what we call constraint preroll, by analogy to the video term. 
A short time before the nominal on- set of control we dynamically compute a spline segment that smoothly 
joins the point's current position and veloc- ity to those at the start of the pre-specified path. During 
the preroll interval, this segment serves to bring the point smoothly from its uncontrolled state to 
the required initial state. Impulses provide additional keyframing possibilities by allowing control 
points to undergo arbitrary velocity dis- continuities. For example, at the end of a motion path, it 
is possible to insert an impulse that makes the control point stop dead or "bounce," simulating collisions. 
Although not generally physical, starting a motion impulsively may also produce interesting effects. 
We also use impulses as a graceful way to start and stop animation runs. Before starting the run, we 
use an impulse to install the initial control point velocities, and at the end, an impulse is used to 
bring them to an instant but well behaved halt.  4.2 Goal-Directed Motion Keyframing of point trajectories, 
though offering real ad- vantages over object-parameter keyframing, can still be a frustrating process, 
primarily because motion must be specified in such a literal way. For instance, the fact that a reaching 
motion is intended to bring the hand into contact with an object to be grasped is entirely lost in the 
transla- tion to spline curves. If the object's position is changed, the hand will happily grab the empty 
space where it used to be, unless the hand's motion is manually changed as well. An alternative to keyframing 
is to specify the goals of actions directly, dynamically calculating the motion re- quired to satisfy 
them. In contrast to the first-principles approach to motion synthesis described in [20], our ob- jective 
here is to develop a minimal vocabulary of simple behaviors that are chained to produce motion. With 
the ability to control the motions of individual object points already in hand, it is comparatively simple 
to develop a variety of useful atomic actions. To implement an action that governs the behavior of one 
or more points, we must provide a way to compute the desired positions, velocities, and accelerations, 
as a function of state and of time. An example will illustrate the approach. Suppose we want to make 
one point chase another, making contact at a specified time, and with specified final velocity. If the 
tar- get point is stationary, then a cubic spline segment can be constructed, taking the chaser's current 
position and veloc- ity as initial conditions, and the position and velocity of the target point as final 
conditions. As the motion progresses, the spline and its derivatives are evaluated to supply the desired 
position, velocity, and acceleration. This is equiv- alent to the "preroll" segment described earlier. 
To chase a moving target, we use its current position and velocity to make a linear prediction of its 
position at the desired time of contact, build a spline to that point, and continu- ously update the 
estimate as things change. The action is complete when the appointed contact time is reached. Figure 
3 shows some frames of a very simple anima- tion in which a sky hook swoops down, grabs a pyramid, flys 
off with it, then hangs itself up, leaving the pyramid dangling. It was created using two primitive behaviors, 
"Chase," as described above, and "Connect," which ap- plies a velocity-matching impulse, then creates 
an attach- ment constraint. For convenience, we define a behavior "Grab" which performs a Chase followed 
by a Connect. Having first created the geometry and defined some named control points at strategic locations, 
we used the following script to produce the motion: Grab(hook_tip,pyr_tip, dtl, vxl, vyl) Grab(hook_eye,sky_point, 
dt2, vx2, vy2) where the dt's and v's are durations and final velocities for the chase segments. Figure 
4 shows a more complex sequence in which a hinge-horned monster skewers and ingests a small hu- manoid. 
The fine grained action is as follows: the monster waits until a humanoid comes in range, skewers it, 
moves its "elbow" to a suitable spot, and accelerates the humanoid to a point just outside its mouth. 
At just that moment, the monster lets go, simultaneously stopping its claw, and the SIGGRAPH '90, Dallas, 
August 6-10, 1990 humanoid pops neatly into the gaping jaws. Here is the script, including interactively 
chosen values for timing and velocity: Wait_For_Humanoid() Grab(claw~ip,humanoid, 1.0) Grab(elbow, 
feeding_position, 1.0, 0, 0) Grab(claw_tip,mouth_point, 1.0, -].5, -1.5) Disconnect(claw_tip,humanoid) 
Grab{humanoid, gullett, .5, -.07, -.07)  When no final velocity is specified, "Grab" com-putes a default 
based on the current position and veloc- ity, duration and distance to the target. The predicate "Wait_For_Humanoid" 
serves to trigger the action when suitable prey comes within range. Unlike a conventional animation script, 
this sequence defines what amounts to a reflex. The monster responds to its environment, suc- cessfully 
capturing its prey over a wide range of initial conditions.  References [I] William W. Armstrong and 
Mark W. Green. The dynamics of articulated rigid bodies for purposes of animation. In Visual Computer, 
pages 231-240. Springer-Verlag, 1985. [2] Alan H. Barr. Global and local deformations of solid primitives. 
Computer Graphics, 18:21-29, 1984. Proc. SIGGRAPH 1984. [3] Ronen Barzel and Alan H. Barr. Topics in 
Physically Based Modeling, Course Notes, volume 16, chapter Dynamic Constraints. SIGGRAPH, 1987. [4] 
Ronen Barzel and Alan H. Barr. A modeling system based on dynamic constaints. Computer Graphics, 22:179-188, 
1988. [5] John E. Chadwick, David R. Haumann, and Richard E. Parent. Layered construction for de- formable 
animated characters. Computer Graphics, 23(3):243-252, 1989. Proc. SIGGRAPH 1989. [6] Kurt Fleischer 
and Andrew Witkin. A modeling testbed. In Proc .Graphics Inte~ace, pages 127-137, 1988. [7] Michael Girard 
and Anthony A. Maciejewski. Com- putational Modeling for the Computer Animation of Legged Figures. Proc. 
SIGGRAPH, pages 263-270, 1985. [8] Herbert Goldstein. Classical Mechanics. Addision Wesley, Reading, 
MA, 1950. [9] Paul Issacs and Michael Cohen. Controlling dy- namic simulation with kinematic constraints, 
be- havior functions and inverse dynamics. Computer Graphics, 21(4):215-224, July 1987. Proc. SIG- GRAPH 
'87. [10] Alex Pentland and John Williams. Good vibrations: Modal dynamics for graphics and animation. 
Com-puter Graphics, 23(3):215-222, 1989. Proc. SIG- GRAPH 1989. [11] John Platt. Constraint Methods for 
Neural Networks and Computer Graphics. PhD thesis, Caltech, 1989. [12] John Platt and Alan Barr. Constraint 
methods for flexible models. Computer Graphics, 22:279-288, 1988. [13] Peter Schroeder and David Zeltzer. 
Dynamic sim- ulation with linear recurive constraint propogation. Computer Graphics, 24(2):23-32, March 
1990. [14] Thomas Sederberg and Scott Parry. Free-form defor- mation of solid geometric models. Computer 
Graph- ics, 20(4):151-160, 1986. Proc. SIGGRAPH 1986. [15] Demetri Terzopoulos, John Platt, Alan Barr, 
and Kurt Fleischer. Elastically deformable models. Computer Graphics, 21(4), July 1987. Proc. SIGGRAPH 
'87. [161 Demetri Terzopoulos and Andrew Witkin. Physically based models with rigid and deformable components. 
In Proc. Graphics Interface, pages 146-154, Edmon- ton, Alberta, Canada, June 1988. [17] Jane Wilhelms 
and Brian Barsky. Using dynamic analysis to animate articulated bodies such as humans and robots. Graphics 
Interface, 1985. [18] Andrew Witkin, Kurt Fleischer, and Alan Barr. En- ergy constraints on parameterized 
models. Computer Graphics, 21(4):225-232, July 1987. Proc. SIG- GRAPH '87. [19] Andrew Witkin, Michael 
Gleicher, and William Welch. Interactive dynamics. Computer Graphics, 24(2): 11-22, March 1990. [20] 
Andrew Witkin and Michael Kass. Spacetime con- straints. Computer Graphics, 22:159-168, 1988.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97907</article_id>
		<sort_key>253</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Strength guided motion]]></title>
		<page_from>253</page_from>
		<page_to>262</page_to>
		<doi_number>10.1145/97879.97907</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97907</url>
		<abstract>
			<par><![CDATA[A methodology and algorithm are presented that generate motions imitating the way humans complete a lifting task under various loading conditions. The path taken depends on "natural" parameters: the figure geometry, the given load, the final destination, and, especially, the <i>strength model</i> of the agent. Additional user controllable parameters of the motion are the <i>comfort</i> of the action and the <i>perceived exertion</i> of the agent. The algorithm uses this information to incrementally compute a motion path of the end-effector moving the load. It is therefore instantaneously adaptable to changing force, loading, and strength conditions. Various strategies are used to model human behavior (such as reducing moment, pull back, add additional joints, and jerk) that compute the driving torques as the situation changes. The strength model dictates acceptable kinematic postures. The resulting algorithm offers torque control without the tedious user expression of driving forces under a dynamics model. The algorithm runs in near-realtime and offers an agent-dependent toolkit for fast path prediction. Examples are presented for various lifting tasks, including one-and two-handed lifts, and raising the body from a seated posture.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP33025731</person_id>
				<author_profile_id><![CDATA[81100384347]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer and Information Science, University of Pennsylvania, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272341</person_id>
				<author_profile_id><![CDATA[81100474340]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Susanna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer and Information Science, University of Pennsylvania, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39081848</person_id>
				<author_profile_id><![CDATA[81332538022]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jianmin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer and Information Science, University of Pennsylvania, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038212</person_id>
				<author_profile_id><![CDATA[81452608047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Norman]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Badler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer and Information Science, University of Pennsylvania, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>31466</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W. W. Armstrong, M. Green, and R. Lake. Near-reaL time control of human figure models. IEEE Computer Graphics and Applications, 7(6):52-61, 1987.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Asmussen and K. Heeboll-Nielsen. Isometric muscle strength in relation to age in men and women. Ergonomics, 5(1):167-169, 1962.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. M. Ayoub, C. F. Gidcumb, M. J. Reeder, M. Y. Beshir, H. A. Hafez, F. Aghazadeh, ~nd N. J. Bethel. Development of an Atlas of Strengths and Establishment of an Appropriate Model Structure. Technical Report, Institute for Ergonomics Research, Texas Tech Univ. (Lubbock, TX), 1981.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. I. Badler. Artificial intelligence, natural language, and simulation for human animation. In N. Magnenat- Thalmann and D. Thalmann, editors, State-of-the Art in Computer Animation, pages 19-31, Springer-Verlag (New York), 1989.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. i. Badler, P. Lee, C. Phillips, and E. Otani. The Jack interactive human model. In Proceedings o.f the First Annual Symposium on Mechnaical System Design in a Concurrent Engineering Environment, Univ. of iowa, 1989.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31464</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[N. I. Badler, K. Manoochehri, and G. Wallets. Articulated figure positioning by multiple constraints. IEEE Computer Graphics and Applications, 7(6):28- 38, 1987.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Baraff. Analytical methods for dynamic simulation of non-penetrating rigid bodies. Computer Graphics, 23(3):223-232, 1989.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Beckett and K. Chang. An evaluation of the kinematics of gait by minimum energy. Journal of Biomechanics, 1:147-159, 1968.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. E. Bobrow. Optimal robot path planning using the minimum-time criteria. IEEE Journal of Robotics and Automation, 4(4):443-450, August 1988.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. E Breen. Choreographing goal-oriented motion using cost functions, tn N. Magnenat-Thalmann and D. Thalmann, editors, State-ofithe Art in Computer Animation, pages 141-151, Springer-Verlag (New York), 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378531</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[L. S. Brotman and A. N. Netravali. Motion interpolation by optimal control. Computer Graphics, 22(4):309-315, 1988.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74357</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Bruderlin and T. W. Calvert. Goal-directed, dynamic animation of human walking. Computer Graphics, 23(3):233-242, 1989.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. B. Chaflin and G. B. J. Andersson. Occupational Biomechanics. John Wiley &amp; Sons (New York), 1984.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[E. Y. Chao and D. H. Jacobson. Studies of human locomotion via optimal programming. Mathematical Biosciences, 6:239-306, 1971.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Esakov, N. I. Badler, and M. Jung. An investigation of language input and performance timing for task animation. In Graphics Interface "89, pages 86- 93, Morgan-Kanfmann (Palo Alto, CA), Waterloo, Canada, June, 1989.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>111166</ref_obj_id>
				<ref_obj_pid>111154</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Girard. Constrained optimization of articulated animal movement in computer animation. In Mechanics, Control and Animation of Articulated Figures, Morgan-Kaufmann (Palo Alto, CA), 1990. To appear.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31465</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Girard. Interactive design of 3d computeranimated legged animal motion. IEEE Computer Graphics and Applications, 7(6):39-51, 1987.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Greenisen. NASA Johnson Space Center. personal communication, 1989. Data.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. R. Grosso, R. Quach, and N. I. Badler. Anthropometry for computer animated human figures. In N. Magnenat-Thalmann and D. Thalmann, editors, State.of-the Art in Computer Animation, pages 83-96, Springer-Verlag (New York), 1989.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378530</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. K. Hahn. Realistic animation of rigid bodies. Com. puter Graphics, 22(4):299-308, August 1988.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[V. H. Heyward, S. M. Johannes-Ellis, and J. F. Romer. Gender differences in strength. Research Quarterly .for Exercise and Sport, 57(2):154-159, 1986.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[C. Hoffmann and R. tIopcroft. Simulation of physical systems from geometric models. IEEE Journal ol Robotics and Automation, RA-3(3):194-206, 1987.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[J. M. Hollerbach and K. C. Suh. Redundancy resolution of manipulators through torque optimization. In IEEE Intern. Con}. on Robotic and Auto, pages 1016- 1021, St. Louis, MO, 1985.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. N. Imrhan. Modelling lsokinetic Strength o} the Upper Extremity. PhD thesis, Texas Tech Univ., 1983.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[P. M. Isaacs and M. Cohen. Controlling dynamic simulation with kinematic constraints, behavior functions and inverse dynamics. Computer Graphics, 21(4):215- 224, 1987.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[M. E. Kahn and B. Roth. The near-minimum time control of open loop articulated kinematic chains. Transactions o} the ASME: Journal of D~tnamic Sitsterns, Measurement, and Control, 93(3):164-172, 1979.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[K. Kazerouni~n and A. Nedungadi. An alternative method for minimization of driving forces in redundant manipulators. In IEEE International Conference on Robotics and Automation, pages 1701-1706, Raleigh, NC, 1987.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[O. Khatib. A unified approach for motion ~nd force control of robot manipulators: the operational space formulation. IEEE Journal of Robotics and Automation, RA-3(1):43-53, 1987.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[L. L. L~ubach. Comparative muscular strength of men and women: ~ review of the literature. Aviation, Space, and Environmental Medicine, 47(5):534- 542, 1976.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[P. Lee. An Archictecture for Modeling Human-like Motion with Constraints. PhD thesis, Dept. of Mechanical Engineering and Applied Mechanics, Univ. of Pennsylvania, Philadelphia, PA, 1990. To appear.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[A. A. Maciejewski and C. A. Klein. Obstacle avoidance for kinematically redundant manipulators in dynamically varying environments. The International Journal of Robotics Research, 4(3):109-117, 1985.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378508</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[G. S. P. Miller. The motion dynamics of snakes and worms. Computer Graphics, 22(4):169-178, 1988.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[NASA. The Anthropometry Source Book, Volumes 1 and 11. NASA Reference Publication 1024, Johnson Sp~ce Center, Houston, TX, 1978.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[E. Otani. Software Tools for Dynamic and Kinematic Modeling of Human Motion. Technical Report MS- CIS-89-43, Dept. of Computer and Information Science, Univ. of Pennsylwnia (Philadelphia, PAL), 1989. MSE Thesis, Dept. of Mechanical Engineering and Applied Mechanics, Univ. of Pennsylvania.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74355</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[A. Pentland and J. Williams. Good vibrations: modal dynamics for graphics and ~nimation. Computer Graphics, 23(3):215-222, 1989.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91452</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[C. Phillips, J. Zhao, and N. I. Badler. Interactive realtime articulated figure manipulation using multiple kinematic constraints. Computer Graphics, 24(2):245- 250, 1990.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_obj_id>9361</ref_obj_id>
				<ref_obj_pid>9356</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[G. Sahar and J. M. Hollerbach. Planning of minimumtime trajactories for robot arms. The International Journal of Robotics Research, 5(3):90-100, 1986.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[F. T. Schanne. Three Dimensional Hand Force Capability Model for a Seated Person. PhD thesis, Univ. of Michigan (Ann Arbor, MI), 1972.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[D. Schmitt, A. H. Soni, V. Srinivasan, and G. Naganthan. Optimal motion programming of robot manipulators. Transactions of the ASME: Journal of Mechanisms, Transmissions, and Automation in Design, 107:239-244, 1985.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[S. Singh and M.C. Leu. Optimal trajectory generation for robotic manipulators using dynamic programming. Transactions of the ASME: Journal of Dynamic Systems, Measurement, and Control, 109:88-96, 1987.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[D. Thalmann. Motion control: from keyframe to task level animation. In N. Magnenat-Thalmann and D. Thalmann, editors, State-of the Art in Computer Animation, pages 3-17, Springer-Verl~g(New York), 1989.]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378540</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[D. E. Thompson, W. L. Buford Jr., L. M. Myers, D.J. Giurlntano, and J. A. Brewer III. A hand biomechanits workstation. Computer Graphics, 22(4):335-343, 1988.]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms. Using dynamic analysis for realistic animation of articulated bodies. IEEE Computer Graphics and Applications, 7(6):12-27, 1987.]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms ~nd M. Moore. Collision detection and response for computer animation. Computer Graphics, 22(4):289-298, 1988.]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[A. Witkin and M. Kass. Sp~cetime constraints. Computer Graphics, 22(4):159-168, 1988.]]></ref_text>
				<ref_id>45</ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[V. Yen and M. L. N~gurk~. Suboptimal trajectory planning of a five-link human locomotion model. In Biomechanics Proceedings, 1987.]]></ref_text>
				<ref_id>46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[B.P. Yeo. Investigations concerning the principle of minimal total muscular force. Journal of Biomechan. ics, 9:413-416, 1976.]]></ref_text>
				<ref_id>47</ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[D. Zeltzer. Toward an integrated view of 3-d computer animation. The Visual Computer: The International Journal of Computer Graphics, 1(4):249-259, 1985.]]></ref_text>
				<ref_id>48</ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[J. Zhao and N.I. Badler. Real Time Inverse Kinematics with Joint Limits and Spatial Constraints. Technical Report MS-CIS-89-09, Dept. of Computer and Information Science, Univ. of Pennsylvania, Philadelphia, PA, 1989.]]></ref_text>
				<ref_id>49</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Strength Guided Motion Philip Lee, Susanna Wei, Jianmin Zhao, and Norman I. Badler Computer and Information 
Science University of Pennsylvania Philadelphia, PA 19104-6389 Abstract A methodology and algorithm 
are presented that generate motions imitating the way humans complete a lifting task under various loading 
conditions. The path taken depends on "natural" parameters: the figure geometry, the given load, the 
final destination, and, especially, the strength model of the agent. Additional user controllable parameters 
of the motion are the comfort of the action and the perceived exertion of the agent. The algorithm uses 
this information to incrementally compute a motion path of the end-effector moving the load. It is therefore 
instantaneously adaptable to changing force, loading, and strength conditions. Various strategies are 
used to model human behavior (such as re- ducing moment, pull back, add additional joints, and jerk) 
that compute the driving torques as the situation changes. The strength model dictates acceptable kinematic 
postures. The resulting algorithm offers torque control without the tedious user expression of driving 
forces under a dynam- ics model. The algorithm runs in near-realtime and offers an agent-dependent toolkit 
for fast path prediction. Exam-ples are presented for various lifting tasks, including one- and two-handed 
lifts, and raising the body from a seated posture. Introduction Realistic articulated figure animation 
is a long-sought goal of computer graphics researchers. While progress in mod- eling and image generation 
has been remarkable, many an- imation schemes still rely on human skill and creativity to effect natural-looking 
motion. As recent efforts have ex-amined physically-based models to achieve plausibility and accuracy 
of synthetic models, attempts at realistic human motion have just begun to trace their origins back to 
biome- chanical principles [42, 12, 30]. We believe that human mo- tion models are going to be hybrids 
of many motion and Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distribu~d for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. path generation techniques. The goal is to find effective combinations that provide realistic 
motion behaviors while simultaneously offering the animator]user reasonable and intuitive control mechanisms. 
Often described as "task level animation" [48, 41, 15, 4], the idea is to find parametric procedures 
that implement various basic human a~ctivities such as grasping, reaching, lifting, walking, and so on. 
Pre-sumably the list is finite: other behaviors are derived tom the sequential or parallel execution 
of such tasks, combined with appropriate transitions for smooth action. One of our research goals is 
to provide task-level control algorithms for human figures [6, 49, 36, 5]. Tasks we are primarily interested 
in include: multiple constrained reach, view, and object manipulation by an end-effector. The lat- ter 
is the one we will discuss here; in particulax, we ex- amine the problem of moving a load to a specified 
position in space. The resulting motion is dictated by the geome- try and is strongly influenced by the 
strength and comfort of the agent. Such problems have application in the ergonomic design and evaluation 
of workplaces for human operators, and maintenance facilities for service personnel.  2 Background 
Torques may be used to physically simulate motions of a figure. Typically the joint responses are conditioned 
by springs and dampers so that responses to external forces can be computed. Such dynamic animations 
have been studied by many researchers [17, 16, 1, 25, 43, 44, 20, 22, 34, 7]. Solving the dynamic equations, 
art initial value problem, is computationally expensive, especially if the joints are stiff [1]. Moreover, 
such motions are annoyingly difficult to control by art animator unless free-swinging motions are in 
fact desired. The resulting motions appear to drive a hapless mannequin or puppet by external forces 
such as gravity and collision reactions. When the torques are de- rived from a spring or vibration model, 
convincing motions of worms, snakes, and other flexible objects may be sim- ulated [32, 35], but this 
cannot be the same mechanism used for normal articulated figure motion. Kinematic and inverse kinematic 
approaches are easier to manipulate and may create the right "look," but suffer from potentially un- 
realistic motion (velocity, torque) in the body joints. These @1990 ACM-0-89791-344-2/90/008/0253 $00.75 
" 253 O SIGGRAPH '90, Dallas, August 6-10, 1990 problems have been addressed as boundary value problems 
with objective functions. The trajectories are then solved by global optimization approaches [45, 10] 
or control the- ory [11], but their methods presume complete knowledge of the driving conditions and 
overall constraints. Relatively successful animation of locomotion has been achieved by hydrid approaches 
combining kinematic and dynamic con- straints [17, 16, 12]. In robotics, the emphasis is to accomplish 
a motion within constraints and optimize with respect to some cri- teria, i.e. time, torque, energy, 
and obstacles [9, 23, 27, 28, 31, 40]. Bioengineers are curious to determine if human motion conforms 
to some optimality criterion, such as en- ergy [8, 14, 46, 47]. Human motion over its entire range of 
motion is not optimal with respect to a single criteria. Despite these diverse approaches to the human 
motion problem, none has been successful at specifying a task by describing a load and a placement goal, 
and then complet- ing the task in a realistic (though possibly suboptimal) manner. There has been work 
on generating a path be-tween two endpoints [37, 26, 39], but the usual solution in- corporates constraints 
and a single objective function that is optimized.  Our Approach We offer a solution which blends kinematic, 
dynamic and biomechanical information when planning and executing a path. The task is described by the 
starting position, the load (weight) that needs to be transported, and a goal po- sition for the load. 
Some simple additional parameters help select from the wide range of possible paths by invoking biomechanical 
and performance constraints in a natural fashion. Thus a path is determined from a general model rather 
than provided by the animator. In addition, the al- gorithm has the ability to adapt to changing forces 
that are required to complete a task. The basic premise of the method is that a person tends to operate 
within a comfort region which is defined by available strength. This is even more probable when the person 
has to move a heavy object. We support the general principle that constraints pre-dict motion. We considered 
applying the constraints which would be similar to those that a human encounters when moving. Human motion 
is known to be diverse, and there- fore, no single type of path or strategy is applicable for all cases. 
To address this, we developed a toolkit of mo- tion generators which produces characteristic motions 
and a corresponding toolkit of transition identifiers which point to the appropriate motion generator 
for any situation. The toolkits are the foundation of our human simulation sys- tem which is fast enough 
to allow interactive animation of tasks. The constraints for this system should be intuitive so that 
manipulation of constraint parameters generate the expected results. Finally, the constraint parameters 
should be easy to modify, allowing the animator some flexibility and creativity in producing a desired 
motion. We assume that a person tends to operate within a com- fort region dictated by muscular strength, 
especially when moving a heavy object. When a person has to accomplish a given task, say lifting a box 
or cup, he starts from some initial posture and then plans the direction for his hand to move. This planning 
is based on the person's perception of his strength, comfort range, and the importance of staying along 
a particular path. After a direction is determined, he tries to move in that direction for a short distance 
with joint rates that maintain the body's discomfort level be- low a particular threshold. Once the position 
is reached another direction is selected by balancing the need to fin- ish the task as directly as possible 
with restrictions derived from the body's limitations. Again, joint rates cart be de- termined once a 
new direction is established. 4 Problem Specification The objective is to find the trajectories, both 
joint and end- effector, that a human-like linkage would traverse to com- plete a task (Figure 1) . The 
task can be specified as a force that has to be overcome or imparted to reach a goal position over an 
entire path. The task specification can be generalized to describe a complicated task by letting the 
force be a function of body position, hand position, time, or other factors. In general, task specification 
can be rep- resented by a force trajectory. In addition to task speci- fication by a force trajectory, 
human motion is guided by many constraints that limit the joint and end-effector tra- jectories. Constraints 
that will guide this work are comfort level, perceived exertion, and strength. Comfort levelis defined 
in a mechanical sense. It is found by calculating, over the entire body, the maximum torque ratio: current 
torque divided by the maximum torque at each individual joint for the current joint position and ve- 
locity. In general when humans move they try to maintain their effort below a particular discomfort level. 
Therefore, it is desirable to dictate a motion that minimizes the maxi- mum torque ratio of a body in 
order to maximize the com- fort level. Perceived exertion is a variable used to indicate the ex- pected 
level of difficulty in completing a task. It depends on the perception of the amount of strength required 
(an implicit function of the force trajectory) and the amount of strength available. If perceived exertion 
is low then the comfort level is not expected to be exceeded for the paths "likely" to be taken to satisfy 
a task, especially for a path that travels a straight line between the initial body posi- tion and the 
goal. However, if the perceived exertion is high, then the end-effector path needs to deviate from a 
straight path in order to abide by the comfort constraint. Perceived exertion is represented by a cone 
which is defined by the maximum deviation angle of a path from its current position. The implementation 
of strength constraints is discussed in the next section. 5 Strength Model Ultimately, the shape of 
an end-effector's motion is derived from the body's resourcc strength: the maximum'achiev- able joint 
torque. Strength information (maximum torques) is defined as muscle group strengths and is stored on 
a joint degree of freedom (DOF) basis. Modeling strength in terms of muscle group strength allows different 
people to possess different strength capacities in different muscle O SIGGRAPH '90, Dallas, August 6-10, 
1990 External Interrupts: force trajectory, comfort, perceived exertion, etc. Figure 2: Overall system 
architecture. motion strategy, based on the constraints, concentrates on a separate fundamental aspect 
of motion. The strategies can be divided into those that represent indirect joint control and those that 
represent direct joint control. For indirect joint control strategies, the end-effector's need to reach 
a goal is more important than joint considerations; and for direct joint control, joint considerations 
are more important than reaching a goal. We can also interpret the strategies a~ particular optimization 
problems. The condition moni- tor is the highest level of the three procedures in predicting a path. 
6.2 Path Planning Scheme The path planning scheme, guided by the condition moni- tor, determines the 
direction to move. In general, the out- put of any system is bounded by its headroom 1. In the case when 
there is much strength in a system, a situation where indirect joint control applies, the headroom can 
be used to suggest incremental joint displacements, d0. A larger head- room allows a larger displacement. 
The mapping between the cartesian displacement and the joint displacement is dx = Jd0 (1) 1The aw.ilable 
raaxge of ~ wuriable within a con~tralnt. 256 where J is a 3 × n matrix and n is the number of joint 
displacements. If the headroom for each joint, which is represented by a weighting vector w, is proportional 
to d0, then d~ = Jw (2) where d~ is a normalized direction of reach, d~ is then compared to a cone, 
which represents a set of feasible di- rections to travel and is derived from perceived exertion. If 
d~ is within the cone then the direction of motion should be d~, otherwise the direction can be d~ projected 
onto the cone. When the system is relatively weak, the suggested direc- tion of motion must not violate 
the strength constraints. The decision process should shift importance from one strategy where the desirability 
to reach a goal is a ma-jor component of determining a suggested motion to an alternative strategy of 
avoiding positions where the joints are greatly strained. This leads to schemes where direct joint control 
is imperative to avoid positions where joints are strained. The methods for PPS are discussed in the 
Appendix. 6.3 Rate Control Process The rate control process, the most basic of the three pro- cedures, 
resolves the speed with which a body moves along a prescribed end-effector path. This requires the use 
of dy- namics, especially when the motion is fast. However, the incorporation of dynamics is difficult. 
When torques are specified to drive a motion (direct dynamics), control is a problem; when the driving 
forces are derived by kinematic specification (inverse dynamics), the forces are useful for only a short 
time interval and they may violate the body's torque capacity; and finally, when the forces optimize 
a par- ticular function between two sets of positional constraints (boundary value problem), the method 
presumes that the optimization criteria is valid for the body's entire range of motion. Dynamics equations 
can be interpreted as constraint equations solving for joint trajectories if they satisfy the conditions 
imposed by specific end-effector path and torque limits. The dynamics equations can be reformulated so 
that they provide a mapping between an end-effector path and a binding torque constraint. A binding torque 
constraint is the maximum torque allowed to drive a body with maxi- mum end-effector acceleration without 
the end-effector de- viating from the prescribed path. A greater torqu~e would cause excessive inertial 
force and therefore, undesirable path deviation. It is evident from the derivation of the re- formulated 
dynamics equations (see Appendix), which were originally derived to solve for path completion in minimum 
time [9], that joint trajectories can be found from the ac-celeration of an end~effector. In addition 
to finding the trajectories, the reformulated dynamic equations implicitly determine the force functions 
(joint torques) to guide an end-effector along a specified path. Torque limits are established by the 
current comfort con- stralnt. The comfort level variable, el, determines the torque limit at each joint 
by a simple relation: Tc.i ct= T(0) .... , (3) nllH i i i i Hi iHl|l i where rc,i is the torque limit 
for a particular joint, i. The value r(8) .... i, containing the maximum torque for the joint's current 
position, is obtained by examining the strength curves. When the value of cl becomes greater than one, 
there is no more strength to accomplish a task and therefore the attempt to complete a task should cease. 
Comfort level can be adjusted to achieve a desired motion. It influences both the rate of task completion 
and the di- rection of travel.   7 Motion Strategies This is a catalogue of human motion strategies 
that are eval- uated in the condition monitor and are executed in PPS. The strategies are given in the 
order of increasing discom- fort. The modeling of these strategies is discussed in the Appendix. 7.1 
Available Torque When a person moves, the tendency is to move the str6nger joint. This is much like the 
forces due to a spring or other types of potential forces. A stronger spring, based on the spring's stiffness 
coefficient, would yield a larger displace- ment per unit time than a weaker spring. Similarly, for a 
human, the amount of displacement for a joint depends not only on the strength that a joint is capable 
of, but mainly on the amount of strength that is currently available. The amount of strength available, 
which is based on the differ- ence between the current required torque to support a par- ticular position 
and the effective maximum strength, which is defined as the maximum strength factored by comfort, is 
called torque availability. If torque availability is low, mo- tion should not be encouraged. Conversely, 
if the torque availability is high, the joint should do more of the work. Torque availability is the 
driving factor for a joint to move and to redistribute the joint torques so that the comfort level is 
more uniform. 7.2 Reducing Moment As a joint approaches its effective maximum strength, the joint should 
move in a manner that avoids further stress on that joint while trying to reach a goal. A path towards 
the goal is still possible as long as the maximum strength is not surpassed for any of the joints. As 
the body gets more stressed it should attempt to reduce the moment caused by a force trajectory by reducing 
the distance normal to the force trajectory's point of application. In addition, a re-duction in moment 
increases the torque availability of (at least) the joint that is rapidly approaching its maximum strength. 
The reduction in the total moment involves ex- amining the moments on a joint by joint basis. At each 
joint a virtual displacement is given to determine if that displacement provides sufficient moment reduction 
to con- tinue moving in that direction. This strategy assumes that the body has enough effective strength 
to allow its joints to move to positions where the overall stress level of the body is smaller than if 
the joints were only guided by kinematic demands. 7.3 Pull Back The two previous strategies depend on 
the current torque to be less than the maximum strength. In these cases, ma- neuverability in torque 
space is high and therefore, an end- effector can still consider moving toward a goM without exceeding 
any joint's maximum strength. However, when a particular joint reaches its maximum strength, then that 
joint can no longer advance toward a goal from the current configuration. The Pull Back strat- egy proposes 
that the end-effector approach the goal from another configuration. In an effort to determine another 
approach to the goal, the constraint of moving toward a goal within a restricted path deviation can be 
relaxed. The emphasis of the strategy is one where the joints dictate an improved path in terms of torques. 
This can be accom-plished by increasing the ultimate auailable torque -the difference of maximum strength 
to current torque -for a set of weak joints -joints that are between the joint which has no ultimate 
available strength and an end-effector. In general, the joint with the least amount of ultimate available 
torque will reverse direction and cause the end- effector to pull back (move away from its goal). The 
idea is to increase the overall comfort level. When the joints form a configuration that has a greater 
level of comfort, there might be enough strength to complete the task. Then the governing strategy could 
return to Reducing Moment, which allows the end-effector to proceed toward the goal. The Pull Back strategy 
leads to a posture of stable con-figuration. A stable configuration is a posture that a set of joints 
should form so that it can withstand large forces, such as those caused when changing from a near-static 
situation to one that is dynamic.  7.4 Added Joint, Recoil, and Jerk When the three strategies, Available 
Torque, Reducing Mo- ment, and Pull Ba~:k have been exhausted and an agent still cannot complete a task, 
it is obvious that the active joints -the joints that were initially assigned to the task -can-not supply 
sufficient strength. When this occurs it should be determined if the task should be aborted or if there 
are other means of acquiring additional strength. One mode of acquiring more strength is to add a joint 
to the set of active joints. This assumes that the added joint is much stronger than any of the active 
joints. Another mode to consider is to use the added joint to jerk -apply with maximum force -the set 
of active joints. Jerk reduces the forces necessary to complete ~ task for the set of active joints. 
Before jerking is initiated, a stable configuration should be formed by the active joints. After a stable 
configuration has been formed and the added joint has jerked, the active joints can then proceed to reach 
their goal since the required torques have decreased. A third possibility is to recoil another set of 
joints and then jerk with the recoiled set of joints in order to reduce the forces needed by the set 
of active joints to complete a task. For example, a weight lifter sometimes recoils his legs and then 
pushs off to reduce the force required in his arms.   O S!GGRAPH, '90, Dallas, August 6-10, 1990,,,, 
where rain is a function which returns the minimum ele- ment of a column vector. This equation offers 
the advantange of resolving the joint trajectories by integrating a single constraint equation in- stead 
of a system of dynamic equations. Because the pa- rameterized path can be determined by an integration 
of a single equation and the joint trajectories can be deter- mined by multiplication, the required dynamic 
computa- tions should be relatively fast. Dynamics are important when a task involves a fast mo- tion 
such as moving a light object or jerking because the body's inertial forces have a major impact on the 
forces of the system. However, when the body's inertial forces are relatively small compared to a force 
trajectory and there is no jerk in the motion, the slow motion allows static ap- proximation to yield 
reasonable results. The speed of the motion is probably determined by other factors. Because of this 
slow speed, the resolution of the joints does not re- quire dynamics; instead, it can be approximated 
by inverse kinematics[36]. A.2 Indirect Joint Control for PPS These w vectors can be applied to the the 
equation d~ = Jw. A.2.1 W Based on Available Torque The elements of w, a n x 1 vector (n is the number 
of degrees-of-freedom) which is based on available torque, is created by using strength curves. The ith 
joint that has the larger amount of available torque, rmax.i- rcu,-,i, should move more. Tm~,i is found 
from the strength curves and rc,,r,i can be computed very quickly from inverse dynamics. Based on the 
need to weight the motion to favor the joint that has the potential to be more active, the value of each 
element of w can be r .... ~ - r~,,~ (16) tOi = max [7"max] where i is enumerated for each of the joints 
and max is a function that returns the value of the maximum torque of all the joints. This ratio follows 
the property that when a joint's torque value is near its maximum torque, move-ment is discouraged, and 
when it is far from the maximum, movement is encouraged towards the position where the maximum torque 
occurs. A.2.2 W Based on Reducing Moment When a joint's stress level is' in the neighborhood of its 
max- imum effective strength, the joint rates of most of the joints are close to zero so the joint torques 
can be appoximated with the static force equation +.°.o = J(O)TF (~7) where ¢,tati¢ is the static force 
vector and F is the force trajectory at the current position. The static force equa- tion can be used 
to determine which joints will benefit with respect to moment reduction, given a change in joint angle. 
26O The static torque vector computed for a small change in joint i's position is rdOi = J(O + ~oi)TF. 
(18) The ith component of faoi, rdOi,i, can be compared with the ith component of ~ot,,¢, statlc,i, 
to determine the effect on each joint torque of altering each joint angle. Let's define 1"dil,i to be 
equal to gotatic,i --TdOi,i. Then for the joints that are proximal to the joint that is most stressed, 
both a positive and a negative dO should be investigated. The one that yields the larger difference should 
be used to define w. Finally, wi = i rdi[.i (19) where the denominator is the maximum rdiff from all 
the joints, wi would be negative if the zd0 used was based on a negative dO. It can be shown that wi 
is similar to ~o0i [30].  A.3 Direct Joint Control for PPS A.3.1 Pull Back A set of weak joints participate 
in Pull Back. The objective is to acquire more strength. The ultimate available torque is evaluated beginning 
from the weakest joint to the joint nearest an end-effector. The equations for this are rt,(vtus),i = 
rs,i(Oi + ~Oi) -rdoi,i (20) ,-.(m,..o),, = T,,,(o, -60,) -,-~o,,, (21) where r,,~(Oi + ~Oi) and r~,i(Oi 
-gOi) are the strength values (from the appropriate strength curve) for small changes in joint i's position. 
Then the most stressed joint moves in the direction of improving ru,i. The next topologically closer 
joint to the end-effector performs the same calculation, in- corporating the displaced joint values. 
This process is re- peated until the joint nearest the end-effector is reached. The amount of joint displacement 
can be an arbitrary joint displacement weighted by its discomfort level which causes the most stressed 
joint to move the most. A.3.2 Singular Configuration and Recoil Pull Back brings the body to a stable 
configuration. To model the mechanical advantage obtained by a stable con- figuration completely, the 
structural capacity of a figure should also be assessed. The Pull Back strategy can also be used to find 
postures involving motions of high exer-tion (throwing a baseball, football, and shotputting). This involves 
using sensitivity analysis [30]. Recoil is similar to Pull Back -acquiring additional strength -except 
that it involves another set of joints. The amount of recoil must satisfy the static force condition 
~(O)recoi~ > JrF(O),,co, (22) where ~(O),-ecoli is the maximum strength of the other set of joints. 
Finally, F .... ,t = Ft + (Ft -(jT)t~s) (23) where Ft is a force trajectory and (JT)t~8 is the amount 
of force the active joints can supply. Since the joints are starting from rest, the static force condition 
is applicable.  B Acknowledgments This research is partially supported by Lockheed Engi- neering and 
Management Services (NASA Johnson Space Center), NASA Ames Grant NAG-2-426, FMC Corpora- tion, Martin-Marietta 
Denver Aerospace, NSF CISE Grant CDA88-22719, and ARO Grant DAAL03-89-C-0031 includ- ing participation 
by the U.S. Army Human Engineering Laboratory. The assistance of Dr. Mike Greenisen of NASA JSC in providing 
the strength curves is greatly appreciated. We would also like to thank members of the Computer Graphics 
Research Laboratory for their support. We especially would like to thank Cazy Phillips for his invaluable 
insights and for developing a graphical environment that has met not only our needs but also the future 
needs of the lab. Finally, we would like to thank Marc Grosso for his help in editing this paper.  References 
 [1] W. W. Armstrong, M. Green, and R. Lake. Near-real- time control of human figure models. IEEE Computer 
Graphics and Applications, 7(6):52-61, 1987. [2] E. Asmussen and K. Heeboll-Nielsen. Isometric mus- cle 
strength in relation to age in men and women. Er-gonomics, 5(1):167-169, 1962. [3] M. M. Ayoub, C. F. 
Gidcumb, M. J. Reeder, M. Y. Beshir, H. A. Hafez, F. Aghazadeh, and N. J. Bethea. Development of an Atlas 
of Strengths and Establish- ment of an Appropriate Model Structure. Technical Report, Institute for Ergonomics 
Research, Texas Tech Univ. (Lubbock, TX), 1981. [4] N. I. Badler. Artificial intelligence, natural language, 
and simulation for human animation. In N. Magnenat- Thalmann and D. Thalmann, editors, State-of-the Art 
in Computer Animation, pages 19-31, Springer-Verlag (New York), 1989. [5] N. I. Badler, P. Lee, C. Phillips, 
and E. Otani. The Jack interactive human model. In Proceedings of the First Annual Symposium on Mechnaicai 
System De- sign in a Concurrent Engineering Environment, Univ. of Iowa, 1989. [6] N. I. Badler, K. Manoochehri, 
and G. Waiters. Ar-ticulated figure positioning by multiple constraints. IEEE Computer Graphics and Applications, 
7(6):28-38, 1987. [7] D. Baraff. Analytical methods for dynamic simulation of non-penetrating rigid bodies. 
Computer Graphics, 23(3):223-232, 1989. [8] R. Beckett and K. Chang. An evaluation of the kine- matics 
of gait by minimum energy. Journal of Biome- chanics, 1:147-159, 1968. [9] J. E. Bobrow. Optimal robot 
path planning using the minimum-time criteria. IEEE Journal of Robotics and Automation, 4(4):443-450, 
August 1988. [10] D. E Breen. Choreographing goal-oriented motion us- ing cost functions. In N. Magnenat-Thalmann 
and D. Thalmann, editors, State-oflthe Art in Computer An- imation, pages 141-151, Springer-Verlag (New 
York), 1989. [11] L. S. Brotman and A. N. Netravali. Motion in-terpolation by optimal control. Computer 
Graphics, 22(4):309-315, 1988. [12] A. Bruderlin and T. W. Calvert. Goal-directed, dy- namic animation 
of human walking. Computer Graph- ics, 23(3):233-242, 1989. [13] D. B. Chaff:in and G. B. J. Andersson. 
Occupational Biomechanics. John Wiley &#38; Sons (New York), 1984. [14] E. Y. Chug and D. H. Jacobson. 
Studies of human locomotion via optimal programming. Mathematical Biosciences, 6:239-306, 1971. [15] 
J. Esakov, N. I. Badler, and M. Jung. An investi- gation of language input and performance timing for 
task animation. In Graphics Interface "89, pages 86- 93, Morgan-Kaufmann (Palo Alto, CA), Waterloo, Canada, 
June, 1989. [16] M. Girard. Constrained optimization of articulated animal movement in computer animation. 
In Me-chanics, Control and Animation of Articulated Fig- ures, Morgan-Kaufmann (Palo Alto, CA), 1990. 
To appear. [17] M. Girard. Interactive design of 3d computer-animated legged animal motion. [EEE Computer 
Graphics and Applications, 7(6):39-51, 1987. [18] M. Greenisen. NASA Johnson Space Center. personal communication, 
1989. Data. [19] M. R. Grosso, R. Quach, and N. I. Badler. Anthro-pometry for computer animated human 
figures. In N. Magnenat-ThMmann and D. Thalmann, editors, State.ofithe Art in Computer Animation, pages 
83-96, Springer-Verlag (New York), 1989. [20] J. K. Hahn. Realistic animation of rigid bodies. Com-puter 
Graphics, 22(4):299-308, August 1988. [21] V. H. Heyward, S. M. Johannes-Ellis, and J. F. Romer. Gender 
differences in strength. Research Quarterly ]or Exercise and Sport, 57(2):154-159, 1986. [22] C. Hoffmann 
and R. Hopcroft. Simulation of physi- cal systems from geometric models. IEEE Journal of Robotics and 
Automation, RA-3(3):194-206, 1987. [23] J. M. Hollerbach and K. C. Suh. Redundancy resolu- tion of manipulators 
through torque optimization. In 1EEE Intern. Con]. on Robotic and Auto, pages 1016- 1021, St. Louis, 
MO, 1985. [24] S. N. Imrhan. Modelling Isokinetic Strength of the Up- per Extremity. PhD thesis, Texas 
Tech Univ., 1983. [25] P. M. Isaacs and M. Cohen. Controlling dynamic sim- ulation with kilaematic constraints, 
behavior functions and inverse dynamics. Computer Graphics, 21(4):215-224, 1987. [26] M. E. Kahn and 
B. Roth. The near-mlnlmum time control of open loop articulated kinematic chains. Transactions of the 
ASME: Journal of Dynamic Sys- tems, Measurement, and Control, 93(3):164-172, 1979. @SIGGRAPH '90, Dallas, 
August 6-10, 1990 [27] K. Kazerounian and A. Nedungadi. An alternative method for minimization of driving 
forces in redundant manipulators. In 1EEE International Conference on Robotics and Automation, pages 
1701-1706, Raleigh, NO, 1987. [28] O. Khatib. A unified approach for motion and force control of robot 
manipulators: the operational space formulation. IEEE Journal of Robotics and Automa- tion, RA-3(1):43-53, 
1987. [29] L. L. Laubach. Comparative muscular strength of men and women: a review of the literature. 
Avia-tion, Space, and Environmental Medicine, 47(5):534-542, 1976. [30] P. Lee. An Arehicteeture for 
Modeling Human-like Mo- tion with Constraints. PhD thesis, Dept. of Mechanical Engineering and Applied 
Mechanics, Univ. of Pennsyl- vania, Philadelphia, PA, 1990. To appear. [31] A. A. Maciejewski and C. 
A. Klein. Obstacle avoidance for kinematically redundant manipulators in dynami- cally varying environments. 
The International Journal of Robotics Research, 4(3):109-117, 1985. [32] G. S. P. Miller. The motion 
dynamics of snakes and worms. Computer Graphics, 22(4):169-178, 1988. [33] NASA. The Anthropometry Source 
Book, Volumes 1 and 11. NASA Reference Publication 1024, Johnson Space Center, Houston, TX, 1978. [34] 
E. Otani. Software Tools for Dynamic and Kinematic Modeling of Human Motion. Technical Report MS-CIS-89-43, 
Dept. of Computer and Information Sci- ence, Univ. of Pennsylvania (Philadelphia, PA), 1989. MSE Thesis, 
Dept. of Mechanical Engineering and Ap- plied Mechanics, Univ. of Pennsylvania. [35] A. Pentland and 
I. Williams. Good vibrations: modal dynamics for graphics and animation. Computer Graphics, 23(3):215-222, 
1989. [36] C. Phillips, J. Zhao, and N. I. Badler. Interactive real- time articulated figure manipulation 
using multiple kinematic constraints. Computer Graphics, 24(2):245-250, 1990. [37] G. Sahar and J. M. 
Hollerbach. Planning of minimum- time trajactories for robot arms. The International Journal of Robotics 
Research, 5(3):90-100, 1986. [38] F. T. Schanne. Three Dimensional Hand Force Capa- bility Model for 
a Seated Person. PhD thesis, Univ. of Michigan (Ann Arbor, MI), 1972. [39] D. Schmitt, A. H. Soni, V. 
Srinivasan, and G. Na- ganthan. Optimal motion programming of robot ma- nipulators. Transactions of the 
ASME: Journal of Mechanisms, Transmissions, and Automation in De- sign, 107:239-244, 1985. [40] S. Singh 
and M.C. Leu. Optimal trajectory generation for robotic manipulators using dynamic programming. Transactions 
of the ASME: Journal of Dynamic Sys- tems, Measurement, and Control, 109:88-96, 1987. [41] D. Thalmann. 
Motion control: from keyframe to task level animation. In N. Magnenat-Thalmann and D. Thalmann, editors, 
State-of the Art in Computer Ani- mation, pages 3-17, Springer-Verlag(New York), 1989. [42] D. E. Thompson, 
W. L. Buford Jr., L. M. Myers, D.J. Giurintano, and J. A. Brewer III. A hand biomechan- ics workstation. 
Computer Graphics, 22(4):335-343, 1988. [43] J. Wilhelms. Using dynamic analysis for realistic ani- mation 
of articulated bodies. IEEE Computer Graph- ics and Applications, 7(6):12-27, 1987. [44] J. Wilhelms 
and M. Moore. Collision detection and response for computer animation. Computer Graphics, 22(4):289-298, 
1988. [45] A. Witldn and M. Kass. Spacetime constraints. Com-puter Graphics, 22(4):159-168, 1988. [46] 
V. Yen and M. L. Nagurka. Suboptimal trajectory planning of a five-link human locomotion model. In Biomechanics 
Proceedings, 1987. [47] B.P. Yeo. Investigations concerning the principle of minimal total muscular force. 
Journal of Biomechan. ics, 9:413-416, 1976. [48] D. Zeltzer. Toward an integrated view of 3-d computer 
animation. The Visual Computer: The International Journal of Computer Graphics, 1(4):249-259, 1985. [49] 
J. Zhao and N.I. Badler. Real Time Inverse Kinemat- ics with Joint Limits and Spatial Constraints. Tech-nical 
Report MS-CIS-89-09, Dept. of Computer and Information Science, Univ. of Pennsylvania, Philadel- phia, 
PA, 1989. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97908</article_id>
		<sort_key>263</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Accurate rendering technique based on colorimetric conception]]></title>
		<page_from>263</page_from>
		<page_to>272</page_to>
		<doi_number>10.1145/97879.97908</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97908</url>
		<abstract>
			<par><![CDATA[We have developed a rendering technique to generate realistic images meeting designers' requirements by strictly analyzing various physical phenomena relevant to the appearance of actual objects.We have numerically compared the results of the calculations using this technique with colorimetry values. As a result, both values were virtually equal, so we have been able to confirm the effectiveness of the established technique.Application of this technique to car design, which has not been realized to a large extent because of severe requests for realism, will make it possible to evaluate styles and colors on a graphics display before making a clay model.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Viewing algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P22892</person_id>
				<author_profile_id><![CDATA[81546773556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Atsushi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takagi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[System Engineering Dept. Design Div., Toyota Motor Corporation, 1, Toyota-cho, Toyota, 471 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P111333</person_id>
				<author_profile_id><![CDATA[81100356938]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hitoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takaoka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[System Engineering Dept. Design Div., Toyota Motor Corporation, 1, Toyota-cho, Toyota, 471 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31091479</person_id>
				<author_profile_id><![CDATA[81332519575]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tetsuya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Oshima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Development Dept. No. 1 Information Systems Div. No. 1, Toyota Motor Corporation, 1, Toyota-cho, Toyota, 471 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P306693</person_id>
				<author_profile_id><![CDATA[81100139831]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yoshinori]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ogata]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[System Engineering Dept. Design Div., Toyota Motor Corporation, 1, Toyota-cho, Toyota, 471 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Higashi,M., I.,Kohzen, J.,Nagasaka, "An Interactive CAD System for Construction of Shapes with High-Quality Surface', E.A.Warman(ed) Computer Applications in Production and Engineering, (North-Holland,1983), P.371 - 390]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Whitted,Tumer, "An Improved Illumination Model for Shaded Display", Communication of The ACM, VOL.23, No.6,June 1980, pp.343 - 349.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hall,Ray A., and Donald P. Greenberg, "A Testbed for Realistic Image Synthesis", IEEE CG&amp;A, Vol.3, No.8, November 1983, pp.10 - 20.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808589</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Amanatides,John, "Ray Tracing with Cones", Computer Graphics (Proceedings SIGGRAPH '84), Vol.18, No.3, July 1984, pp. 129 - 135.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, R.L., T.,Porter, and L.,Carpenter,'Distributed Ray Tracing", Computer Graphics (Proceedings SIGGRAPH '84), Vol.18, No.3, July 1984, pp.137 - 145.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajiya,James T.,"The Rendering Equation", Computer Graphics (Proceedings SIGGRAPH '86), Vol.20, No.4, August 1986, pp. 143 - 150]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ward,Gregory J.,Francis M. Rubinstein,Robert D. Clear,"A Ray Tracing Solution for Diffuse Interreflection", Computer Graphics (Proceedings SIGGRAPH '88), Vol.22, No.4, August 88 1988, pp.85 - 92]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cohen,Michel F.,Donald P. Greenberg, "THE HEMI-CUBE A Radiosity Solution for Complex Environments", Computer Graphics (Proceedings SIGGRAPH '85), Vol.19, No.3, July 1985, pp.31 - 40]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hall,Roy A.,'A Characterization of Illumination Models and Shading Techniques",The Visual Computer Vol.2, No.5,(September 1986), pp.268 - 277]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Immel,David S., Michel F. Cohen, Donald P. Greenberg,'A Radiosity Method for Non-Diffuse Environments", Computer Graphics (Proceedings SIGGRAPH '86), Vol.20, No.4, August 1986, pp. 133 - 142]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wallance,john R.,Michel F. Cohen, Donald P. Greenberg,"A Two -Pass Solution to The Rendering Equation: A Synthesis of Ray Tracing and Radiosity Methods", Computer Graphics (Proceedings SIGGRAPH '87), Vol.21, No.4, July 1987,pp.311 - 320]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Cohen,Michel F.,Shenchang Erie Chen,John R.Wallance, Donald P. Greenberg, "A Progressive Refinement Approach to Fast Radiosity Image Generation",Computer Graphics (Proceedings SIGGRAPH '89), Vol.22, No.4, August 88 1988, pp.75 - 84]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[For example, Hall,Roy A., "Illumination and Color in Computer Generated lmagery",Springer-Verlag, 1988]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Baba,Goroh, Hidejiroh,Mori, "The Measurements of Object Colors Which Give Metal-Like-Feeling", Proceedings of The 6th Joint Conference on Color Technology, 1989, November, pp. 131 - 134]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Habu,Mitsuhiro, Mamoru,Suzuki, Takehiko,Nagasaka, "Measurement of The Solar Spectral Irradiance at Tanashi, Tokyo(1)",Researches of The Electrotechnical Laboratory No.812 ,February, 1981]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Habu Mitsuhiro, Mamoru,Suzuki, "Measurement of The Solar Spectral Irradiance at Tanashi, Tokyo",J. Ilium. Engng. Inst. Jpn. Vol.68,No.2,1984 ,pp.83- 89]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[For example, R.M.L. Baker and M.W.Makemson,"An Introduction to Astrodynamics ",Academic Press,1960]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kasten,F.,"A rch. Meteor. Geophys. Bioklio, Ser. B.",VoI.14,p.14, 1966]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Shibata, kazuo, et. al.,"Spectral Distribution and measurement of Solar Energy",Gakkai Shuppan Center, JAPAN ,p.22,1987]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[WMO - No.590, "Commission for Instruments and Methods of Observation Abridged Final Report of The Eighth Session", October 1981, pp.8 - 11]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[FrShlich,C., G.E.Shaw, "New Determination of Rayleigh Scattering in The Terrestrial Atmosphere", Appl. Optics, Vol.19, 1980, pp.1773 - 1775]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Young, A.T.,"Revised Depolarization Corrections For Atmospheric Extinction ", Appl. Optics, Vol.19, 1980, pp.3427- 3428]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[For example, Iqbat,Muhammad, "An Introduction To Solar Radiation", The University of British Columbia, 1983, Academic Press, Chap.6.6]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Nakahara, Kanji, Naomasa, Yui, "Method for Outdoor Calibration of Reference Solar Cells", Researches of The Electrotechnical Laboratory No.842, May, 1984]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[E.C.Y.Inn, Y.,Tanaka,"Absorption Coefficient of Ozone in The Ultraviolet and Visible Regions", J. Opt. Soc. Am., Vol.43, No. 10, 1953, pp.870 - 873]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[T.G.ADIKS,YU.S. Georgiyevskiy ,M.S. Malkevich and N.S.Filippova, "Atmosphere Transmission in The 0.76 #m 02 Band ", Izv., Atmospheric and Oceanic Physics, Vol.8, No.4, 1972, pp.369 - 381]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[P.Koepke, H.Quenzel, "Water Vapor : Spectral Transmission at Wavelengths Between 0.7/zm and 1/.tm", Applied Optics, Vol.17, No.13, July 1978, pp.2114 - 2118]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Gates,David M,, "Near Infrared Atmospheric Transmission to Solar Radiation", J. Opt. Soc. Am. Vol.50, No.12, December 1960, pp. 1299 - 1304]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Gates,David M.,Walter J. Harrop, "Infrared Transmission of The Atmosphere to Solar Radiation", Applied Optics,Vol.2, No.9, September 1963, pp.887 - 898]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Division 3 , TC 3.09, Average Sky as A Standard CIE Technical Report, "Luminance Distributions of Various Reference Skies", Complete Draft, March 1988]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15900</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Nishita,Tomoyuki, Eihachiro,Nakamae, "Continuous Tone Representation of Three-Dimensional Objects Illuminated by Sky Light", Computer Graphics (Proceedings SIGGRAPH '86), Vol.20, No.4, August t986, pp.125 - 132]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35071</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Klassen, R. V., "Modeling The Effect of The Atmosphere on Light", ACM Transactions on Graphics, Vol.6, No.3, July 1987, pp.215 - 237]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sekine,Seishi, "Spectral Distributions of Clear Sky Light and Their Chromaticities", J. lllum. Engng. Inst. Jpn. Vol.73, No.2, 1989, pp.39 - 45]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Sekine,Seishi, "Optical Characteristics of The Turbid Atmosphere", J. lllum. Engng. Inst. Jpn. Vol.71, No.6, 1987, pp.333 - 338]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[CIE: Publication TC 4.2, No.22, "Standardization of Luminance Distribution on clear skies", 1973]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Kittler, Richard, "Luminance Models of Homogeneous Sky for Design and Energy Performance Predictions", Proc. 2. Int. Daylight Conf., Long Beach, Nov. 1986]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Natural Daylight. Official Recommendations, Compte Rendu CIE 13e Session 1955, (Paris: The Commision, Vol.2, 1955), Committee(E-3.2), P. II , 1955]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Judd, D. B., MacAdam, D. L., Wyszecki, G., .I. Opt. Soc. Am., Vol.54, 1964, p. 1031]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Phong,Bui Tuong, "Illumination for Computer Generated Pictures", Communications of The ACM, Vol.18, pp.311 - 317, 1975]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806819</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert,L, "A Reflectance Model for Computer Graphics", Computer Graphics (Proceedings SIGGRAPH '81), Vol.15, No.3, August 1981, pp.307 - 316]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Minato,Sachie, "Color and Gloss", J. of Color Science Association of japan, Vol.4, No.l, 1979, pp.29 - 30]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Hall,Roy A., "Hybrid Techniques for Rapid Image Synthesis", Image Rendering Trics, SIGGRAPH '86 Course Notes, Vol. 16, t 986]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
  '~' Computer Graphics, Volume 24, Number 4, August 1990 (1) Reflectance of diffusion area : High-precision 
measurement. (2) Reflectance of specular reflection area : Classify objects into those following the 
Fresnel formula and those not following the formula to measure reflectance. The latter needs to be measured. 
 (3) Transmlsslvlty: Consider it for transparent objects like glass. For colored glass, measure spectrum 
absorption. We examined the influence of sky light and ground light by changing the inclination of surface. 
 < Color > The light reflected on or transmitted through an object enters the human eye as spectrum 
distribution. The color human eyes "perceive" in this case is the sense caused by stimulated ocular cells. 
Physically, it can be said that ocular cells are receivers weighted by light wavelengths. Therefore, 
to accurately display the same colors as those that humans perceive on a CRT, it is necessary to reproduce 
colors by considering the characteristics of the human eye, Many studies on the above have already been 
reported "m. < Complexity > To correctly recognize an object a human sees, the object should be provided 
with some details. A human usually sees and touches various objects and memorizes the complexity of each 
object as knowledge. Visual meaning is determined by the association of empirical perception under various 
experiences. In the case of a car, for example, a human can imagine that it has tires with wheels, door 
handles, windows, and so on. To make the object appear more realistic on CG, the object should be provided 
with familiar details, such as side mirrors, license plate, etc. Complexity is needed not only for the 
object to be expressed but also for the peripheral background. This is also found in the display examples 
of the literature[5] which increases realism as a whole by providing the background reflected on an object 
with complexity. 3 RENDERING MODEL In this section, the reflection model expression, which is the fundamental 
model for rendering, is first established. Next, the light source and material which are important factors 
for realism are modeled, and then they are integrated into the reflection model. 3.1 Reflection model 
expression < other work > The conventional expression of object surface reflection is as follows tin.tin, 
 1(3.)=e(3.)+ fop(3.)u3.)cosoao 3.1 where, 3. : Wavelength 1 (3.) : Reflected light going in a certain 
direction e (a) : Light emitting from an object going toward the direction of the reflection /9 (a) : 
Reflectance of the objeet's surface L(3.) : Incident light 0 : Incident angle d ~ : Differential solid 
angle of incident light g2 : Solid angle of the entire incident light ( See Fig. 3.1 ) Though this is 
an excellent expression for a global illumination, it is not clear on the following points. (1) /9(3.) 
is not clearly defined. Because there are several different types of object surface reflectance, it is 
necessary to clarify which type to apply. (2) L(3.) is not minutely analyzed.  (3) Because the unit 
of each value is not clear, comparison with the actual value cannot be made. Therefore, it is difficult 
to verify the actual data.  < Our approach > We have solved the problems described in the above Items 
(l) through (3) and propose the following expression for practical use. It I(3.) =e(3.) + -~--IB( 3.)L( 
3.)cosOda~ Ed~ ( W" sr -~" nm -t" m -=) 3.2 Where, 3. is the wavelength having unit (nm). 1 ( 3. ), e( 
3. ), and L(a) have the same definition as that of expression (3.1). Each of them is the spectral radiance 
having each unit (W.sr -~.nm-Lm -=) . f2,O, and ~ have the same definition. /3 (3.) is the spectral radiance 
factor of object surface. Actually, however, the spectral reflectance factor R(3.) having unit (1) realizing 
colorimetry is used. Where, R(3.) : spectral reflectance factor(l) from L(3.) to I(3.) The coefficient 
1/n before the integral sign appears because of using the spectral radiance factor /5 (3.) as the reflectance. 
This expression includes the following to solve the problems (1) through (3). [I] All units are clarified 
and the measured value /3(3.) or R(3.) is used as/9(3.). [2] Especially the direct sunlight and sky light 
are precisely calculated for L(3.). I %1/ I L (3.) ~'9~'- 1(3.) ° Fig. 3.1 Incident light L (3.) and 
reflected light I(2) This paper advances by omitting e (3.) for convenience sake. That is, 1(3.)= a(3.)z(3.)cosoa 
, (W.sr-"nm-'.m-2). 3.3 To clarify the expression (3.3), separate the incident light L( 3. ) into specular 
reflected light, direct sunlight, and other light sources. g2 = g2R+Qs+g2o (sr) 3.4 Where, f2~ :Solid 
angle of the area in the direction of specular reflection Qs : Solid angle of the area in the direction 
of main light source f2o : Solid angle of the area other than the above The above expression is illustrated 
in Fig. 3.2. I ,~lj Fig. 3.2 Division of f~ Where each value is defined as follows: L,( 3. ) : Spectral 
radiance of the light from the direction of specular reflection Ls(3.) : Spectral radiance of main light 
source ( direct sunlight ) OR : Incident angle (rad) of LR(3.) Os : Incident angle of Ls(2) /3~( a): 
Spectral radiance factor (I) from L~( 3. ) to I( 3. ) B~( 3.): Spectral radiance factor (1) from Ls(3.) 
to I(3.) tier :Differential solid angle (sr) of LR(3.) SIGGRAPH '90, Dallas, August 6-10, 1990 Apes 
: Solid angle of Ls(3.) C~(2) : Absorption coefficient due to absorption of ozone tzsj Therefore, the 
reflected light I(3.) is obtained from the zo(3.) : Attenuation factor according to oxygen molecules 
in the expression atmospherC =~ (3.3) as follows: rw(3.):Attenuation factor according to water vapor 
in the atmosphere tzm=~ I(3.) = ~f,..o..oo /3(3.)L(3.)cosOdo Among the above values, zo(3.) and T~ 3. 
) are omitted because 1 they are very weak in visible wavelength, and their influence is = .f( 3.)L~(3.) 
+ ..E./3~ ( 3.)L~(3.) cosO~" Aog~ +G(3.). 3.5 small. /[ However, assume f(3.) and G ( 2 ) are as follows 
: 3.2.2. Sky light < Other work > Our purpose for sky light integration is to clarify spectral 1(3.) 
 f(3.) ~-= 3R( 3.) cosORd~R. 3.6 distribution and luminance at each point in the sky under any IR(3.) 
 weather condition. Many research studies have been made about luminance so fart~°L For spectral distribution, 
however, no decisive c( f J( 3.)L( 3.)cosOdw. 3.7 research has been made. This is because the logical 
analysis of spectral distribution is difficult since sky light is generated For normal paint surfaces, 
because f(3.) can be approximated through complex processes such as dissipation of direct sunlight by 
the Fresnel factor f which is independent of wavelength u4~, the due to air, aerosol, and clouds or repetitive 
reflection of it on the expression (3.5) can be rewritten as follows: ground. The following are examples 
of relevant research. Nakamae et a!.(1980) simulated object appearance with CG under 1(2 )= f .L,(3.) 
+-1--/3~(3.)L~(3.) cosOs.Ao), +G(3.). 3.8 clear sky and overcast sky using the CIE standard clear sky 
light 7[ luminance expression t~'. R.V. Klassen(1987) simulated refraction, diffusion, and absorption 
due to air molecules and aerosol to 3.2 Light source express the color of sky light through CG taM. 
Sekine(1989) analyticallyt~j calculated spectral distnbutmn" at each point of clear " 3.2.1 Direct sunlight 
sky . In these research studies, however, spectral distribution at Because direct sunlight has been ambiguously 
considered so far, each point in the sky under any weather condition was not it" has been used only,tlSj 
as a parallel light source with high obtained. luminance. Habu et m. insist that direct sunlight depends 
on the <Our approach > latitude, season, hour, air contamination, and amount of steam at We proposed 
a method to obtain spectral distribution at any the arrival point and has the characteristic in which 
the variation point in the sky under any weather condition using the empirical depends on the wavelength. 
Therefore, because it is assumed that formula obtained through measurement. direct sunlight influences 
the appearance of an object, we decided [1] Classification of sky light to rigorously consider direct 
sunlight. We clarified the sky that we handled. In general, the sky can be The spectral radiance Ls(3.) 
of sunlight on the ground surface is classified into the following three types t~j. expressed by the 
spectral irradiance E,( it ) (W.nm-"m -2) on <1> Clear sky : Sky free from clouds the ground surface 
and its solid angle AOgs (sr) as the following <2> Intermediate homogeneous sky : Sky in which weather 
expression. homogeneously changes between clear and overcast skies without clouds scattered in the L~( 
2 ) =E,( 3. ) /doo~ (W" sr -~" nm-'. m -z) 3.9 sky <3> Overcast sky : Sky covered with clouds so thick 
that the Moreover, E,(3.) is expressed according to the sun cannot be seen Beer-Bouguer-Lambert's law 
as followsUel: In the intermediate sky expressing the intermediate state between clear and overcast skies, 
clouds are actually scattered. In this section, however, we use the intermediate homogeneous sky E, ( 
3. ) = Eo( 3.)" e -'c"'~'.~"" - to( 3. )" z~( 3. ) in Item <2> for convenience sake. Also in this section, 
we deal (W.nm-~.m-ZL 3.10 with Items <1 > through <3> in order to meet (Requirement 3). Where, [2] Calculation 
of spectral distribution at any point of sky light. Ao)~ : Solid angle when viewing the sun from the 
ground surface The method proposed by us uses the fact that sky light luminance . HT1 has a certain correlation 
with color temperature(See Fig. 3.5). The m : Air mass tm spectral distribution at any point of sky light 
is obtained as shown Eo( 2 ) : Spectral irradiance out of atmosphere "°~. In this case, use in Fig. 3.3. 
The process to determine spectral distribution of sky CIMO- VII (1981) t~°j. light, turbidity factor 
T=, and atmospheric dirtiness are described CR(2) : Attenuation factor according to Rayleigh diffusion 
of air in Item 3.2.3. molecules tm.tza The calculation for processes <A>, <B>, and <C> in Fig. 3.3 is 
CR(3. )=0.008643. -' ~e*~,'~+ ~°:~' (2 :ttrn) 3.11 defined as follows: Process <A> (Calculation of sky 
light luminance distribution) Cm(3.) : Attenuation factor according to diffusion of aerosol t~j The luminance 
distribution at each point in the sky can be C.(3.) =Z3.-" (3. :ttm) 3.12 obtained by inputting the sun 
altitude 7s, turbidity factor T~, and atmospheric dirtiness. The following luminance expressions are 
The factors a and/3 are obtained through measurement tu~. proposed corresponding to the skies <1 >, <2>, 
and <3> classified Input < C > sky light I- /-,z L : Luminance at :1 solaraRitude L = AtemD~ature I-P"I 
Spectral P: Position at any j,-"'~'-.,.,,,,,. _ lCorrelatedcolorl ~1 2¢Jy_3 ,= .,,> .By, T.. ;. 0,st.bu.on 
I point in the sky ~" ~ R~ "v" any point in the   L~.~ sky i I Turbidity ]-~ Sky luminanceL factor 
T~ ,,, S: Position of the Lz: Zenith luminance sun ,'1 i<0,°,oo. 'ri0 too-I -o,, I I m Fig. 3.3 Process 
to determine spectral distribution of sky light Fig. 3.4 Symbols in the sky 266 ~ in Item [1]. <1> 
CIE standard clear sky light luminance function t~] . <2> Intermediate homogeneous sky light luminance 
function t~ . <3> CIE standard overcast sky light luminance function wn. The above expressions in Items 
<1> and <3> are specified as international standards, which express only clear sky and overcast sky respectively. 
The luminance at each point of the sky is expressed as the ratio to the zenith luminance Lz ( ccl/m~ 
).. Though the expression in Item <2> is not recognized as an international standard yet, it is shown 
in the 1988 CIE Technical Report in detail [~]. It is possible to continuously change the luminance at 
eaeh point of the sky between clear and overcast using the turbidity factor T~ as a parameter, Items 
<1> through <3> are expressed in the following form respectively. <1> L/Lz = f,(P,S)[~s, (1) 3.13 L~= 
o,(T., r.) ( cd/m ~ ) 3.14 <2> L = A(P, S,T.) ~l ( cd/m ~ ) 3,15 <3> L/L.= f3(P,S) '~ (1) 3.16 Lz = 02( 
r, ) ( cd/rn" ) 3.17 Process <B> (Conversion of luminance into correlated color temperature) When assuming 
the luminance at any point in the sky as L ( ccl/m ~ ) and the correlated color temperature corresponding 
to the above luminance asT~(K), the relationship between L and Tcp is shown by the expression below, 
 1.1985 ×10 ~ T~ = L~.2 + 6500 (K). 3.18 The above expression is based on our measurements. That is, 
we regressively obtained it from the results of examining the relationship between the luminance at any 
point in the sky and color temperature at any hour and spot in Japan. We found that there is a strong 
link between them(See Fig. 3.5.). Process <C> (Conversion of correlated color temperature into spectral 
distribution) A method is needed to convert correlated color temperature into spectral distribution using 
measured data. However, because the method is not determined at present, we used the CIE synthesized 
daylight expression proposed by Judd, MacAdam, Wyszecki t~]. 3.2.3 Weather simulation As stated in Requirement 
3, a car body's surface color is evaluated by assuming its appearance at various places and under various 
weather conditions, because the surface may not look good under a cloudy sky though it looks good under 
a clear sky. For the existing CG, most research is made for the rendering of appearance under a clear 
sky with direct sunlight, and does not include the idea of a rigorously rendered appearance depending 
on weather condition. We proposed a method to render the appearance of objects under any weather condition. 
For this, we first considered the spectral distribution and intensity of direct sunlight and skylight 
which are the main outdoor light sources by 30000 Tcp ! (K) : 1.1985x108 + 6500 ~ Z~== 20000 .,----i 
.............................................................. i ................................... 
~ ......................... i : measured d~lta 10000 ..........~ ~ ................... 1 ...............................................i 
 .................. .. ' "" " .L. ._ i  Computer Graphics, Volume 24, Number 4, August 1990 defining 
the factors which determine weather and using the factors as input data. [1] Factors to simulate weather 
It is considered that the following four factors change weather. (1) Position (Latitude and longitude 
on the earth). (2) Date and hour (Hour based on universal time). (3) Weather simulation factors. They 
are the values defined by meteorology.  <1> Atmospheric transmittance: P, Po. <2> Coefficient of turbidity 
a, B, water vapor content, oxygen content, and ozone content. <3> Turbidity factor: T, T,. (4) Atmospheric 
dirtiness.  This is the parameter to indicate how the atmosphere is contaminated due to artificial factors, 
though this is not minutely studied at present. For sky light, however, there is the method to indicate 
the condition of the sky on contaminated industrial areas by correcting the sky light luminance distributiont~( 
[2] Calculation for direct sunlight and sky light. (1) Direct sunlight. For direct sunlight, E,(~) in 
the expression (3.10) can be obtained using the factors described in Item[l[ to obtain the direct sunlight 
value Ls(2) as a light source using the expression (3.9). (2) Sky light. For sky light, it is first necessary 
to know the Luminance distribution of any weather condition. In this case, we use the intermediate homogeneous 
sky light Luminance function in the expression (3.15). This can also be obtained using the factors described 
in Item[l]. P, P, T, and T, can be obtained with E,(2) and air mass m 1301 3.3 Material To express realism, 
a rigorous definition of materials as well as light sources are needed. Because the modality of reflection 
or transmission when light hits an object depends on the object, it is very important for expressing 
appearance of various materials to accurately check these physical phenomena. Reflection or transmission 
produced when light hits an object isgenerally classified into the following four types from O through 
f.~. (~) Diffuse reflection Most existing research mathematically models the diffusion , reflection according 
to Lambert s law 130] [401 . However, it is difficult ' to use these model expressions because they include 
several parameters to delicately change the material, and the parameters must be adjusted through trial 
and error in order to express a proposed material. Therefore, the model expressions are rarely applied 
to the requirement to accurately render the materials of existing objects. Prof. Minute has established 
the method to specify the diffuse reflection of objects by measuring the spectral reflectance factor 
showing the diffuse reflectionf% By using the reflectance obtained through measurement as the reflectance 
/3(2) in the expression (3.3), the material of an actual object can accurately be rendered without setting 
parameters. The spectral reflectance factor R (2) is measured by changing the angle a(gonio-angle) on 
the basis of the specular reflection direction as shown in Fig.3.7. Figure 3.8 shows the equipment used 
to measure R ( a,2). The results of measuring R (a,3.) for paint are shown in Fig. 3.9. The material 
can be decided according to the shape of the 5000 10000 15000 20000 25000 @diffuse (~) specular ~ regular 
@diffuse  reflection reflection transmission transmission L (cd/m 2) Fig. 3.5 Measured data and approximate 
formula Fig. 3.6 Classification of reflection and transmission   SIGGRAPH '90, Dallas, August 6-10, 
1990 REFERENCE [ 1] Higashi,M., I.,Kohzen, J.,Nagasaka, "An Interactive CAD System for Construction 
of Shapes with High-Quali.W Surface", E.A.Warman(ed) Computer Applications in Production and Engineering, 
(North-Holland,1983), P.371 -390 [ 2] Whitted,Tumer, "An Improved Illumination Model for Shaded Display", 
Communication of The ACM, VOL.23, No.6,June 1980, pp.343 -349. [ 3] Hall,Ray A., and Donald P. Greenberg, 
"A Testbed for Realistic Image Synthesis", IEEE CG&#38;A, Vol.3, No.8, November 1983, pp.10 - 20. [ 
4] Amanatides,John, "Ray Tracing with Cones", Computer Graphics (Proceedings SIGGRAPH '84), Voi.18, No.3, 
July 1984, pp.129 -135.  [5] Cook,R.L., T.,Porter, and L.,Carpenter,'Distributed Ray Tracing", Computer 
Graphics (Proceedings SIGGRAPH '84), Vol.18, No.3, July 1984, pp.137 -145. [6] Kajiya,James T.,"The Rendering 
Equation", Computer Graphics (Proceedings SIGGRAPH '86), Vol.20, No.4, August 1986, pp.143 - 150 [ 7] 
Ward,Gregory J.,Francis M. Rubinstein,Robert D. Clear,"A Ray Tracing Solution for Diffuse Interreflection", 
Computer Graphics (Proceedings SIGGRAPH '88), Vol.22, No.4, August 88 1988, pp.85 -92 [ 8] Cohen,Michel 
F.,Donald P. Greenberg, "THE HEMI-CUBE : A Radiosity Solution for Complex Environments", Computer Graphics 
(Proceedings SIGGRAPH '85), Vol.19, No.3, July 1985, pp.31 -40 [ 9] Hall,Roy A.,'A Characterization 
of Illumination Models and Shading Techniques",The Visual Computer Vol.2, No.5,(September 1986), pp.268 
-277  [10] Immel,David S., Michel F. Cohen, Donald P. Greenberg,"A Radiosity Method for Non-Diffuse 
Environments", Computer Graphics (Proceedings SIGGRAPH '86), Vol.20, No.4, August 1986, pp. 133 - 142 
[11] Wallance,John R.,Michel F. Cohen, Donald P. Greenberg,"A Two -Pass Solution to The Rendering Equation: 
A Synthesis of Ray Tracing and Radiosity Methods", Computer Graphics (Proceedings SIGGRAPH '87), Vol.21, 
No.4, July 1987,pp.311 -320 [12] Cohen,Michel F.,Shenchang Erie Chen,John R.Wallance, Donald P. Greenberg, 
"A Progressive Refinement Approach to Fast Radiosity Image Generation",Computer Graphics (Proceedings 
SIGGRAPH '89), Vol.22, No.4, August 88 1988, pp.75 - 84 [13] For example, Hall,Roy A., "Illumination 
and Color in Computer Generated Imagery",Springer-Vedag, 1988 [14] Baba,Goroh, Hidejiroh,Mori, "The Measurements 
of Object Colors Which Give Metal-Like-Feeling", Proceedings of The 6th Joint Conference on Color Technology, 
1989, November, pp.131 -134 [15] Habu,Mitsuhiro, Mamoru,Suzuki, Takehiko,Nagasaka, "Measurement of The 
Solar Spectral Irradiance at Tanashi, Tokyo(1)",Researches of The Electrotechnical Laboratory No.812 
,February, 1981 [16] Habu Mitsuhiro, Mamoru,Suzuki, "Measurement of The Solar Spectral Irradlance at 
Tanashi, Tokyo",J. Ilium. Engng. Inst. Jpn. Vol.68,No.2,1984 ,pp.83 - 89 [17] For example, R.M.L. Baker 
and M.W.Makemson,"An Introduction to Astrodynamics ",Academic Press,1960 [18] Kasten,F.,"A rch. Meteor. 
Geophys. Bioklio, Ser. B.",VoI.14,p.14, 1966 [19] Shibata,kazuo, et. al.,"Spectral Distribution and measurement 
of Solar Energy",Gakkai Shuppan Center, JAPAN ,p.22,1987 [20] WMO -No.590 , "Commission for Instruments 
and Methods of Observation Abridged Final Report of The Eighth Session", October 1981, pp.8 - 11 [21] 
FrShlich,C., G.E.Shaw, "New Determination of Rayleigh Scattering in The Terrestrial Atmosphere", Appl. 
Optics, Vol.19, 1980, pp.1773 -1775 [22] Young,A.T.,"Revised Depolarization Corrections For Atmospheric 
Extinction ", Appi. Optics, Vol.19, 1980, pp.3427- 3428 [23] For example, Iqbat,Muhammad, "An Introduction 
To Solar Radiation", The University of British Columbia, 1983, Academic Press, Chap.6.6 [24] Nakahara, 
Kanji, Naomasa,Yui, "Method for Outdoor Calibration of Reference Solar Cells", Researches of The Electrotechnical 
Laboratory No.842, May, 1984 [25] E.C.Y.Inn, Y.,Tanaka,"Absorption Coefficient of Ozone in The Ultraviolet 
and Visible Regions", J. Opt. Soc. Am., Vol.43, No.10, 1953, pp.870 -873 [26] T.G.ADIKS,YU.S. Georgiyevskiy 
,M.S. Malkevich and N.S.Filippova, "Atmospheric Transmission in The 0.76 tzm 02 Band ", Izv., Atmospheric 
and Oceanic Physics, Vol.8, No.4, 1972, pp.369 -381 [27] P.Koepke, H.Quenzel, "Water Vapor : Spectral 
Transmission at Wavelengths Between 0.7/zm and lgm", Applied Optics, Vol.17, No.13, July 1978, pp.2114 
- 2118 [28] Gates,David M., "Near Infrared Atmospheric Transmission to Solar Radiation", J. Opt. Soc. 
Am. Vol.50, No.12, December 1960, pp.1299 -1304 [29] Gates,David M.,Walter J. Harrop, "Infrared Transmission 
of The Atmosphere to Solar Radiation", Applied Optics,Vol.2, No.9, September 1963, pp.887 -898 [30] Division 
3 , TC 3.09, Average Sky as A Standard CIE Technical Report, "Luminance Distributions of Various Reference 
Skies", Complete Draft, March 1988 [31] Nishita,Tomoyuki, Eihaehiro,Nakamae, "Continuous Tone Representation 
of Three-Dimensional Objects Illuminated by Sky Light", Computer Graphics (Proceedings SIGGRAPH '86), 
Vol.20, No.4, August 1986, pp.125 -132 [32] Klassen, R. V., "Modeling The Effect of The Atmosphere on 
Light", ACM Transactions on Graphics, Vol.6, No.3, July 1987, pp.215 -237 [33] Sekine,Seishi, "Spectral 
Distributions of Clear Sky Light and Their Chromaticities", J. lllum. Engng. Inst. Jpn. Vol.73, No.2, 
1989, pp.39 - 45 [34] Sekine,Seishi, "Optical Characteristics of The Turbid Atmosphere", J. lllum. Engng. 
Inst. Jpn. Vol.71, No.6, 1987, pp.333 -338 [35] CIE : Publication TC 4.2, No.22, "Standardization of 
Luminance Distribution on clear skies", 1973 [36] Kittler, Richard, "Luminance Models of Homogeneous 
Sky for Design and Energy Performance Predictions", Proc. 2. Int. Daylight Conf., Long Beach, Nov. 1986 
[37] Natural Daylight. Official Recommendations, Compte Rendu CIE 13e Session 1955, (Paris : The Commision, 
Vol.2, 1955), Committee(E-3.2), P. II , 1955 [38] Judd, D. B., MacAdam, D. L., Wyszeeki, G., J. Opt. 
Soc. Am., Vol.54, 1964, p.1031 [39] Phong,Bui Tuong, "Illumination for Computer Generated Pictures", 
Communications of The ACM, Vol.18, pp.311 -317, 1975 [40] Cook,Robert,L., "A Reflectance Model for Computer 
Graphics", Computer Graphics (Proceedings SiGGRAPH '81), Vol.15, No.3, August 1981, pp.307 -316 [41] 
Minato,Sachie, "Color and Gloss", J. of Color Science Association of Japan, Vol.4, No.l, 1979, pp.29 
-30 [42] Hall,Roy A., "Hybrid Techniques for Rapid Image Synthesis", Image Rendering Trics, SIGGRAPH 
'86 Course Notes, Vol.16, t986  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97909</article_id>
		<sort_key>273</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[A model for anisotropic reflection]]></title>
		<page_from>273</page_from>
		<page_to>282</page_to>
		<doi_number>10.1145/97879.97909</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97909</url>
		<abstract>
			<par><![CDATA[A reflection and refraction model for anisotropic surfaces is introduced. The anisotropy is simulated by small cylinders (added or subtracted) distributed on the anisotropic surface. Different levels of anisotropy are achieved by varying the distance between each cylinder and/or rising the cylinders more or less from the surface. Multidirectional anisotropy is modelled by orienting groups of cylinders in different direction. The intensity of the reflected light is computed by determining the visible and illuminated portion of the cylinders, taking self-blocking into account. We present two techniques to compute this in practice. In one the intensity is computed by sampling the surface of the cylinders. The other is an analytic solution. In the case of the diffuse component, the solution is exact. In the case of the specular component, an approximation is developed using a Chebyshev polynomial approximation of the specular term, and integrating the polynomial.This model can be implemented easily within most rendering system, given a suitable mechanism to define and alter surface tangents. The effectiveness of the model and the visual importance of anisotropy are illustrated with some pictures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computations on polynomials</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39077449</person_id>
				<author_profile_id><![CDATA[81100349049]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Poulin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of British Columbia, Vancouver, BC, Canada V6T 1W5]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051322</person_id>
				<author_profile_id><![CDATA[81100345881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alain]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fournier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of British Columbia, Vancouver, BC, Canada V6T 1W5]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bass, F. G. and Fuks, I. M., Wave Scattering from Statistically Rough Surfaces. Pergamon Press Ltd., 1979.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Beckm~nn, P., Spizzichino A., The scatterin9 of electromagnetic waves :from rough surfaces. Artech House, Inc., 2nd ed., 1987.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, J., Models of Light Reflection for Computer Synthesized Pictures. Proceedings of SIGGRAPH'77, In Computer Graphics 11, 2 (July 1977), 192-198.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blinn, J., Simulation of wrinkled surfaces. Proceedings of SIGGRAPH'78, In Computer Graphics 12, 3 (August 1978), 286-292.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Born, M. and Wolf, E., Principles o} Optics. Pergamon, Oxford, 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Brennan, B., Bandeen, W., Anisotropic Reflectance Characteristics of Natural Earth Surfaces. Applied Op. tic8 9, 2, (February 1970).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37434</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cabral, B., Max, N., Springmeyer, R., Bidirectional Reflection Functions from Surface Bump Maps. Proceedings of SIGGRAPH'87, In Computer Graphics 21, 4 (July 1987), 273-281.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806819</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, R., Torrance, K., A Reflectance Model for Computer Graphics. Proceedings of SIGGRAPH'81, In Computer Graphics 15, 3 (August 1981), 307-316.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Fiume, E., Ouellette, M. and Chee, C., FIAT: Light Driven Global Illumination. DGP Technical Memo DGP89-1, Dynamic Graphics Project, University of Toronto, 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H., Continuous Shading of Curved Surfaces. IEEE Transactions on Computers 20, 6 (June 1971), 623-628.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Heckbert, P., Survey of Texture Mapping. IEEE Computer Graphics and Applications, 6, 11 (November 1986), 56-67.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Immel, D., Cohen, M. and Greenberg, D., A Radiosity Method for Non-Diffuse Environments. Proceedings of SIGGRAPH'86, In Computer Graphics 20, 4 (August 1986), 143-150.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J., Anisotropic Reflection Models. Proceedings of SIGGRAPH'85, In Computer Graphics 19, 3 (July 1985), 15-21.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J., The Rendering Equation. Proceedings of SIGGRAPH'86, In Computer Graphics 20, 4 (August 1986), 143-150.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. and Kay, T., Rendering Fur with Three Dimensional Textures. Proceedings of SIGGRAPH'89, In Computer Graphics 23, 3 (July 1989), 271-280.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Max, N., Horizon mapping: shadows for bump-mapped surfaces. The Visual Computer, Vol. 4, 1988, 109-117.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102332</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Miller, G., From Wire-Frames to Furry Animals, Proceedings of Graphics Interface '88, 1988, 138-145.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Phong, B., Illumination for Computer Generated Pictures. Communications of the A GM 18, 6, (June 1975), 311-317.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Poulin, P. and Amanatides, J., Shading and Shadowing with Linear Light Sources. Proceedings of Eurographics 90, (September 1990).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ralston, A., A First Course in Numerical Analysis. McGraw-Hill, 1965.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Saito, T., Shinya, M., Takahashi, T., "Highlighting Rounded Edges", Proceedings of CG International 89. In New Advances in Computer Graphic~ 1989, 613-629.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sillion, F. and Puech, C., A General Two-Pass Method Integrating Specular and Diffuse Reflection. Proceedings of SIGGRAPH'89, In Computer Graphics 23, 3 (July 1989), 335-344.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Torrance, K., Sparrow, E., Polarization, Directional Distribution, and Off-Specular Peak Phenomena in Light Reflected from Roughened Surfaces. J.Opt.Soc.Am. 56, 7, 1966.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Torrance, K., Sparrow, E., Theory for Off-Specular Reflection from Roughened Surfaces. J.Opt.Soc.Am. 57, 9, 1967, 1105-1114.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Trowbridge, T., Reitz, K., Average Irregularity Representation of a Roughened Surfaces for Ray Reflection. J. Opt.Sac.Am. 65, 3, 1967.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Watanabe, Y., Suenaga, Y., Hair Animation in Backlight. Proceedings of CG International 89. in New Advances in Computer Graphics 1989, 691-700.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Whitted, T., An Improved Illumination Model for Shaded Display. Communications o/the A CM 23, 6, (June 1980), 343-349.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Williams, L., Pyramidal Parametrics. Proceedings of SIGGRAPtt'83, In Computer Graphics 17, 3 (July 1983), 1-11.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Yokoi, S., Toriwaki, J., Computer Science and Technologies, Ch. 3.7 Realistic Expression of Solids with Feeling of Materials, JARECT, Vol. 18, Ohmsha Ltd., 1988.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Model for Anisotropic Reflection Pierre Poulin and Alain Fournier Department of Computer Science 
University of Toronto Toronto, Ontario, Canada MSS 1A4  Currently: Department of Computer Science University 
of British Columbia Vancouver, BC, Canada V6T 1W5 {poulinlfournier}@cs.ubc.edu Abstract A reflection 
and refraction model for anisotropic surfaces is introduced. The anisotropy is simulated by small cylinders 
(added or subtracted) distributed on the anisotropic surface. Different levels of anisotropy are achieved 
by varying the distance between each cylinder and/or rising the cylinders more or less from the surface. 
Multidirectional anisotropy is modelled by orienting groups of cylinders in different di- rection. The 
intensity of the reflected light is computed by determining the visible and illuminated portion of the 
cylinders, taking self-blocking into account. We present two techniques to compute this in practice. 
In one the intensity is computed by sampling the surface of the cylinders. The other is an analytic solution. 
In the case of the diffuse com- ponent, the solution is exact. In the case of the specular component, 
an approximation is developed using a Cheby- shev polynomial approximation of the specular term, and 
integrating the polynomial. This model can be implemented easily within most ren- dering system, given 
a suitable mechanism to define and al- ter surface tangents. The effectiveness of the model and the visual 
importance of anisotropy are illustrated with some pictures. CI~ Categories and Subject Descriptors: 
1.3.7 [Com- puter Graphics]: Three-Dimensional Graphics and Realism. General Terms: Algorithms. Additional 
Key Words and Phrases: Shadowing, sur- face mapping, Chebyshev polynomials, hair rendering, sci- entific 
visualization.  Introduction Many objects in nature are visually very complex. Crow, as quoted in [13], 
suggested having different levels of geo- metric models to capture this complexity. However, as the representation 
of an object requires the addition of smaller Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. geometric models to define smaller details, the extra cost of modelling 
and rendering these details can become very high. Moreover such an object representation would be prone 
to aliasing problems. To overcome these problems, approximations to some ge- ometric models have been 
proposed. If we note Dg the level of the geometry at which objects are usually defined (i.e. polygons 
or parametric surfaces), then displacement and bump mappings [4] [16] approximate what the geometric 
model Da+l would define at a higher resolution or magnifi- cation. As the details become smaller, even 
surface mapping becomes highly subject to aliasing problems. At this geo- metric level, Da.t~, the details 
cannot be seen individually and appear only because of the way they modulate the light reflected off 
them. This is the reason why these details must be captured by local reflection models. Traditionally, 
reflection models have been divided into two components: diffuse and specular [24] [3] [8] [2]. The diffuse 
component takes into account the light that inter-reflects onto elements of a same surface and is reemitted 
equally in all directions. To model the specular reflec-tion, Torrance and Sparrow [24] assume that the 
surface is made of highly reflective microscopic facets distributed in v-grooves. If the facets are randomly 
distributed over the surface, shadowing and masking functions can be statisti- cally estimated, and, 
for a given distribution of slopes of the facets, the light reflected in a particular direction can be 
approximatedJ This type of surface is qualified as isotropic because the reflected light intensity at 
a given point is inde- pendent of the surface orientation along its normal at this point. Many surfaces, 
however, cannot be modelled by a ran-dom isotropic distribution of facets. If an element of such surfaces 
is rotated around its normal while the light and viewer directions remain unchanged, the light intensity 
re-flected to the viewer will vary. These surfaces are called anisotropic. Surfaces made of fur or burnished 
metal are examples where there is a strong correlation between the ori- entations of facets and the orientation 
of the surface. Bren-nan et al. [6] measured several natural surfaces and showed that surfaces like clouds, 
forests, oceans and even sand ex-hibit anisotropy. Anisotropy can be caused by a collection of strongly 
oriented elements, such as hair in fur or blades 1 All the reflection models discussed in this paper 
ignore the wave- length. In the facets model, this means that the size of the facets is assumed much 
greater than the wavelength of the light source. &#38;#169;1990 ACM-0-89791-344-2/90/008t0273 $00.75 
273 of grass in a meadow, or by the selected action of an exter- nal force. Many natural factors can 
contribute to preferred orientations of the facets like the wind, the sun's position for the orientation 
of leaves or the shape of the underwa- ter terrain for waves. Since anisotropy is so prevalent, and our 
visual system use it as a cue for orientation and depth, a wide range of anisotropic surfaces needs to 
be accurately rendered to obtain more realistic images. Moreover, the use of anisotropy is not restricted 
to the production of realistic images. With the recent emphasis on scientific visualization techniques, 
more and more informa- tion needs to be communicated to the viewers from a sin- gle image. The shape, 
colour, texture, opacity and surface roughness are some properties that can carry information. Anisotropy 
adds a new dimension to the information trans- mitted. For instance, a simple vector field over a surface 
can be associated to a given orientation of the facets on this surface, freeing colour or texture for 
other information. This paper first briefly surveys and discusses current anisotropic reflection models. 
The model based on cylinders is then presented in detail, with its parameters and solutions for the reflected 
light. Finally images illustrating applica- tions of anisotropy in computer graphics are.presented and 
commented. 2 Previous Work Kajiya [13] attempted to compute analytically the reflected intensity from 
a continuous surface. He bases his approach on the general Kirchhoff solution for scattering of electro- 
magnetic waves [1] [2]. For given incident and reflected di- rections, the intensity reflected by a surface 
is computed. However, the method has its restrictions. For instance, the Kirchhoff solution is valid 
only if self-shadowing and multi- ple scattering are negligible. Even if this limitation is not considered, 
the size of the surface required (Fresnel zones) by the Kirchhoff solution and the stationary phase method 
used to approximate the integral [5] introduce new problems that are dependent of each surface type. 
Cabral et al. [7] go down to the facet level. Facets are created from a height field and the reflection 
off each facet is studied, including the blocking factor for incident and reflected light. This method, 
which can be qualified as brute ]orce, is computationally expensive. The computation of the blocking 
factor is done via a modification of Max's method for the self-shadowing of bump maps [16]. This method 
can seriously alias the shadows for surfaces which exhibit high frequency behaviour. In these two approaches, 
the reflection intensities are computed once and kept in tables; interpolation is used for fast rendering. 
However, a new table needs to be com- puted each time another type of surface is being rendered, which 
involves a few hours of CPU time (~ 12 hours on an IBM4341 for Kajiya's and around the same time for 
Cabral's on a VAX 11/785). In Phong's reflection model, the distribution of the spec- ular intensity 
is symmetric around the reflection direction. Ohira [29] defines it as elliptic with the intention to 
sim- ulate the reflection from scratches-like surfaces. However, the definition of the ellipse has no 
physical motivation and can lead, according to Yokoi et al., to "unnatural images". Takagi et al. [29] 
extend this idea of an ellipsoid to the re-flection model of Torrance and Sparrow [24]. For a surface 
covered with scratches, the distribution of the normals of the facets can be approximated by an ellipsoid 
elongated in the preferred orientation of the scratches. For given light and viewer directions, the bisector 
between these two direc- tions is computed. Then the intensity reflected specularly 274 to the viewer 
is considered directly proportionM to the ratio of facets with their normal in this bisector direction. 
These last two models are only valid for "scratched" surfaces with negligible self-shadowing and multiple 
scattering. Miller [17] introduced the use of cylinders to simulate anisotropy. When projecting a cylinder 
onto the viewing screen, only half of it is visible. The intensities at equal intervals of this projected 
cylinder are computed and aver-aged. Later, at the rendering stage, if scratches are oriented in the 
direction of one cylinder, the computed intensity is used to simulate the effect of the anisotropy of 
the surface. Miller also adapts the reflectance sphere [28] for faster rendering. However, the technique 
inherits the limitations of the reflectance sphere. Thus, light sources are expected to be far from all 
the objects in a scene. The projection of the cylinder onto the viewing screen is also restricted to 
per- spective rendering of a scene and therefore, unsuitable for a rendering technique like ray tracing. 
Another disadvantage is that each cylinder is treated individually, which obliges Miller to neglect the 
self-shadowing and the inter-reflection of one cylinder onto its neighbours. Therefore in Miller's model, 
for a given orientation of a cylinder, the same in-tensity wifl be computed, whatever the orientation 
of the surface normal. 3 Cylindrical Scratches The model proposed here builds on the concept of Miller's 
cylinders. Scratches are represented by a large number of adjacent small cylinders. The intensity reflected 
by all the cylinders in one direction is approximated by the reflection off only a single cylinder. This 
approximation is accurate if many cylinders cover every sampled region of the sur-face. Moreover, since 
the cylinders have a very small radius in comparison to their length, the intensity reflected off a cylinder 
can be approximated by the reflection off only one cross section of this cylinder. Consider the hierarchy 
of geometric models discussed previously. At the geometric level Dg+2, the details can-not be seen individually 
and are captured by the reflection model. Including our anisotropic reflection model corre-sponds to 
inserting two new geometric levels between the mapping (displacement or bump) and the isotropic reflec- 
tion model, now identified as Dg+4. The isotropic reflection model Dg+4, like the facets model of Torrance 
and Sparrow, characterizes the surface nature of each cylinder. A group of adjacent cylinders oriented 
in one direction defines the D9+3 level while a set of groups of adjacent cylinders represents the Dg+2 
level. Figure 1 illustrates the interaction between these various levels. To orient the cylinders, surface 
frame bundles (to use the terminology of [13]) need to be established. One axis is the normal at the 
surface, N. Another axis is the tangent to the surface, T (thus perpendicular to the normal). This tangent 
allows the specification of the orientation of the cylinders on the surface. The last axis defined is 
the binormal, B, formed by the cross product T x N. The cross section of the cylinder of interest thus 
lies on the plane NB. Since the normals are already defined for most of the surfaces used in computer 
graphics, the extra information required for introducing anisotropy is simply a tangent at each point 
of the surface. Many techniques have been de- veloped to map textures [11] and perturbations of normals 
[4] onto objects; these techniques can easily be extended to map tangents onto objects. The cylinders 
are too small to be seen individually. For each cylinder, the viewer position is so far away relative 
to the cylinder's radius that its direction can be assumed to be . . . . . .. . , . ~ , G e o m e t r 
y .::iii'ii.i' , ........ Cylinders (unidirectionalanisotropy) (isotropic) Figure 1: Hierarchy of Geometric 
Models constant over the cylinder. By the same token, the light di- rection is also assumed constant 
over each cylinder. Groups of adjacent cylinders are also assumed to be small enough to not be seen individually. 
Moreover, the surface covered by parallel and adjacent cylinders (within one group) is as- sumed to be 
so large in comparison with the surface cov- ered by non-parallel and adjacent cylinders (cylinders on 
the edges of two groups with cylinders oriented differently) that the self-shadowing and the inter-reflection 
from one group on the other will be considered as negligible. We will now examine in details the fight 
reflected by in- dividual cylinders. The result is the heart of the anisotropic model introduced in this 
paper.  3.1 Controlling the Anisotropy The anisotropy in this model is created because the dis- tribution 
of the surface normals along the cross section of the cylinders is different from the distribution along 
their axis; this difference determines the level of anisotropy. Two parameters are used to control the 
anisotropy. One is the distance d between the centers of two adjacent cylinders. Without lost of generality, 
assume a unit radius for each cylinder. This means that an intersection point on a cylin- der defines 
directly the normal at this point. If the distance d E [0, oo) is 0, only the surface normal is taken 
(i.e. no variation of normals) and the resulting effect is given simply by the underlying reflection 
model (Torrance and Sparrow in this case). As d goes from 0 to 2, the anisotropy increases to its maximum 
(the variation of normals cannot be greater than ~-). If the distance is greater than 2, a floor between 
adjacent cylinders appears. The resulting anisotropy is then a combination of the varying normals ~cross 
the cylinders and the length of the floor where the surface normal does not vary. kc*'t d t<-~'t d Figure 
2: Controlling the Level of Anisotropy The anisotropy is also controlled by a second parameter, the height 
h E [0, 1] by which the floor is raised. A higher floor reduces the variation of the normals on the cylinders 
and increases the length of the floor. Figure 2 illustrates the control of the anisotropy by these two 
parameters, d and h. Defining an anisotropic surface relies on our intuitive knowledge of the surface. 
If the anisotropy is less pro- nounced (like in the scratched stainless steel surfaces shown in Image 
III and on the knobs of Image IV), a small d and no floor produce these characteristics. For surfaces 
like hair and textile (see the drapery of Image III), d is expected to be closer to 2. The roof of barns 
are often covered with cor- rugated iron that corresponds well to cylinders spaced by a large floor, 
d > 2. A complementary model using negative (transparent) cylinders has also been developed. This model 
allows for (a) large grooves with relatively sharp edges or (b) for sharp grooves spaced by a longer 
floor. Conceptually, this model is more suitable for (a) surfaces like water with waves form- ing crests 
or (b) records (see the record on the turntable in Image IV). The equations relative to the model are 
given in appendix A. Although the concepts for both models are quite similar, the rest of the paper will 
treat only positive cylinders in order to simplify explanations. 3.2 Shadowing and Hiding Consider one 
cylinder. Because of the parameters d and h, the normals on the cylinder can vary only within a certain 
angle 0M from the surface normal: 0M = rain(rid, dh) where ¢h = cos -1 (h) ~bd = I sin-1 (d/2) if d < 
2 otherwise. % Depending on the orientation of the fight vector L, some parts of the cylinder might 
not be fit. Let 0L be the an-gle between the light vector projected onto the NB plane and the surface 
normal. The self-shadowing angle 0o~ cor- responds to the angle from the surface normal at which the 
cylinder starts blocking light onto itself. The shadowing an- gle 0~ corresponds to the angle at which 
the neighbouring cylinder starts casting a shadow onto the cylinder. For a floor of length f, some length 
fi is lit and some length f~ is in the shadow of the cylinder. All of these values can be computed as 
follows:   O,,=~-OL f = max(d -2~/T:-~, 0) if (0~, > 0M) { Figure 3: Some Variables for the Positive 
Cylinders 0, = 0,~ = OM f~ = f;A =0 } else  { if (ooL < (d- 1)) 0s= else 0, = OL + sin-l(dcos OL --1) 
0o = min(0~, 0M) A = min(~o~ L - ~/1 - h z - c.~.~.~_~ colOL "f) f~ max(f,, 0) f, =f--f, ) The same 
logic is used to obtain the self-hiding angle O~u (the angle at which the cylinder starts hiding itself 
from the viewing position), the hiding aztgle 0h (the angle at which the neighbour cylinder starts hiding 
the cylinder from the viewing position), the length of the hidden floor fh and the length of the visible 
floor f~. It is only necessary to replace 0L by 0E, the angle between the viewing vector projected onto 
the NB plane and the surface normal. Figure 3 iden- tifies the various angles for given light and viewer 
positions. 3.3 Sampling as Seen by the Viewer At this point, all the information about the visible and 
illu- minated portions of the floor and the cylinder is known. It is now necessary to compute the light 
intensity reflected in the viewing direction. Since the floor has a constant normal and the viewer position 
is assumed at infinity, the intensity reflected by the floor is computed via any favorite reflection 
model. Computing the light reflected off the cylinder to the viewer is more involved. One solution consists 
of sampling the cylinder at regular intervMs as seen by the viewer. Fig- ure 4 illustrates this process 
and figure 5 shows how the sampled normals are computed. Thus, the visible and il- luminated arc is projected 
onto the surface plane and this projection is subdivided equally. For each subdivision, the 276 Figure 
4: Regular Sampling from the Viewer N E Op2 P2 pl Figure 5: Finding the Sampling Angles 0 v corresponding 
angle on the cylinder is 0 m = sin-l(plcosOg)+Og 0~2 = sin--I(p2COSOE)--OE depending on which side of 
N the projection of the sampling angle lies. The intensity reflected to the viewer is averaged from the 
intensities computed at all sampling normals. If the anisotropic surface is reflective, these normals 
axe used to determine the directions in which reflected rays are gener-ated. For transpaxent objects, 
the same normals are used. To reduce the strong aliaslng patterns susceptible to appear, the new rays 
are simply jittered. Finally, the new rays might intersect the neighbouring cylinders. In this case, 
only the colour of the surface is considered. The intensities computed so far are only for the visible 
and illuminated arc lo and floor If. However visible por- tions of the surface can be in shadow. For 
these portions, the diffuse and specular intensities axe zero. In order to be able to treat the floor 
and the cylinder in the same units, it is necessary to project the cylinder onto the surface plane. Then, 
the lengths of the visible part of the cylinder Iv and of the visible and illuminated part lvi are given 
by l~ = sin(0h -OE) + sin(0oh + 0Z) cos 0E ~i~r(Og--OE)+sin(Oe+OE) L,E same side of N cos @E lvi : "in( 
Oe--OE)faTn( Ol+O~ otherwise cos 01~ where 01 and 0¢ define the visible and illuminated arc, 0~ being 
the angle between the surface normM and the point where the visible and illuminated portion of the cylinder 
begins from the side of the light source, and Oe being defined like 0t but from the other side (see figure 
3). Now, the intensity I,. reflected to the viewer can be nor- realized by I, = (Iox t.) + (11x A,) 1~ 
+ f~ where ~ is the fraction of the incident light that is reflected to the viewer.  3.4 Analytic and 
Approximate Solutions Sampling the reflected intensity has some advantages, es-pecially in the context 
of a rendering method such as ray tracing. In this case, when the surface is reflective or refrac- tive, 
the same sampled normals can be used to compute the directions of the reflected or refracted rays. Sampling, 
how- ever, has many drawbacks. It is usually prone to aliasing. As the specular coefficient n of a reflection 
model like Phong's grows, the peak of the intensity reflected becomes thinner and could easily be missed 
when sampling the cylinder. As a result it is difficult to determine the correct number of sam- pies 
for a visually satisfactory result at a reasonable cost. In order to avoid sampling problems, an analytic 
solu- tion for the relevant integrals would be useful. An analytic solution for the diffuse term of the 
reflectance model is intro- duced in this section. The solution for the specular term is not as easy, 
but a solution is presented where the reflection function is approximated by Chebyshev polynomials and 
an analytic solution for the integral of this approximation is used. 3.4.1 Reflected Diffuse Intensity 
In many reflectance model, the term (N- L) determines the light reflected diffusely. If a coordinate 
system in two dimen- sions is established in the NB plane 2, summing the contri- butions as a function 
of (N. L) is expressed as: #'"(N. L) cos(qbE -- qb)d~ (1) i where the term cos(¢E -~b) is a correction 
factor due to the viewing position. In the NBT coordinate system, L is expressed as (L,,, Lb, Lt) and 
N as (sin ~,cos ~b, 0). The solution to equation 1 is sin qbE (q~, -- ~bi -sin ~b, cos ~b, + sin ~bi 
cos ~i) + sin ~E(sin ~ if, --sin2qbi)+ COS ~g (4, -- ~i + sin ¢, cos ~, + sin ~i cos ~i) Since it was 
necessary to include a correction factor due to the viewer's position, this solution must be normalized 
by dividing by ~" cos q~E(sin¢~,--sinffi)+ cos(~z -~)d~ = sin@E(cos~i -cos~,)  3.4.2 Reflected Specular 
Intensity If the term (N. It)n is used to determine the light reflected specularly z , an analytic solution 
similar to the one above 2¢ in this coordinate system is calculated from the positive axis of B. Then 
~bj~ in this coordinate system corresponds to ~ - 0E or "k 0E, depending on which side of the normal 
N the viewer is. ZH being the bisector vector between L and E and n Phong's specular coefficient. could 
be computed assuming n integer, but it degenerates into an impressive number of terms for each intersection 
point. If the curve of cos" ~ is plotted as a function of ~, one can observe that it is symmetric about 
the Y axis and relatively smooth. Thus, this curve can easily be approximated by one or more polynomials 
which are simple to integrate. It is important to mention that the approximating poly- nomials need only 
be computed once for a given n. The polynomials are thereafter only referred to at the rdndering stage. 
One approximation is based on Chebyshev polynomials. If regular samples are taken on the curve, Chebyshev 
ap- proximation is assured to return the best (rain-max) poly- nomial of a given degree. In order to 
reduce the degree of the polynomials for a given tolerance, some simplifications are necessary. First, 
since the curve is symmetric about the Y axis, the approximation can be limited to the positive side 
of the X axis. It is also known that the reflected in- tensity for an angle larger than ~ is zero. Moreover, 
since we deal with discrete intensities at a pixd level, we can use this fact to bound the error of the 
polynomial approxima- tion. If the intensity of an incident light ranges from 0 to 1, 4 the difference 
in intensity between the real value and the approximate one can be at most ~ if we want to be at . 56 
. :t:1 rgb value. Then the apprommate polynomial can cover the domain [0,¢] where ¢ = cos-l(~ 1/") without 
violat-ing the ~d accuracy. With this assumption, several curves with various n have been approximated 
and, by experience, a degree 6 polynomial has always been sufficient to respect this criterion. A short 
piece of code returning Chebyshev polynomials is given in appendix B. The advantage of this technique 
is that not only can the curve (N. H)" be approximated easily, but so can any smooth curve such as most 
of the curves given by other reflection models. The solution for (N H)" follows. To find the intensity 
reflected specularly to the viewer, an integral of the form ff " (Iv. //)" cos(¢ -0)d¢ (2) i has to 
be solved. Figure 6 illustrates the variables used to solve equation 2; N' is a sampling normal. Equation 
2 can be rewritten as f c~0--4~i (H cos ep)" cos" cos(¢ + - ./no -4~, for which the integral part is 
evaluated as   (cos fcosO+, + sin fco: sin sin ~g (cos a0 fcos" ctsin erda -sin o~0 fcos "+1 ads) In 
this solution, fcos "+z erda is approximated via Cheby- shev polynomials and _ cos n÷l cos not sin ctdo~ 
-- ot n+l There is another, simpler method to approximate the integral needed for the specular contribution. 
The first ob- servation is that the Phong model is itself only an approx- imation. A very similar distribution 
is obtained when, as 4This is an unrealistic limitation but many current rendering sys- tems use this 
range. T B ot Figure 6: Integrating (N H)" in the Torrance-Sparrow reflection model [24], one takes 
a Ganssian distribution around the highlight: e -(k¢)2 . As sug- gested by Blinn [3] the two distributions 
can be fitted to each other by specifying a common angle fl for which the inten- sity falls to one half 
of the peak value. In this case, the Phong exponent n is given by: log 2 n = --log(cos fl) and the coefficient 
k is given by: k = x/l~2fl We can therefore replace the Phong expression by the Oaus- sian distribution 
with the same characteristics using only one parameter. The result of the total integral is immediate 
from the knowledge of the integral of the Ganssian: ~° e_(k4,)2 dq b _ 2 jf 00 }x/~ In general what 
is needed is some definite integral. In this case one can replace the Ganssian by its dassic piece-wise 
approximation by a cubic spline, also known as the Parzen window (sealed to have a maximum of 1). The 
polynomials are: ~-(2 + u) 3 when -2 _< u < -1 ~(4-6u 2-3u 3) when -l<u<0 3(4-6u 2+3u 3) when 0<u<l 
~(2-u) 3 when 1 ~u<2 0 when [u[ > 2 The parameter u is scaled as a function of fl: u' --0.7223517uz 
2fl For the usual range of n, from 4 and up, the integral com- puted this way is never more than 1~ 
away from the corre- sponding Phong integral. If n is less, then the approximation of the Gaussian integral 
can deviate by up to 10% from the Phong integral. It must be remembered, however, than one has as much 
claim to the truth as the other. It is not critical for the present problem to have a fast method to 
replace the Phong expression by an integrable function, since it is done only once per distinct value 
of r~. Once the polynomials axe obtained, computing the inte- grals is quite close in cost for the two 
methods. The second method will be of interest in other applications (such as normalizing the energy 
redistributed by a specular reflec-tor) where it is important to have a fast approximation of the total 
integral. 4 Rendering Anisotropic Surfaces The model of cylindrical scratches presented in this paper 
can be used within several rendering techniques. The only requirements are to know the surface normals, 
tangents and the viewer and light positions. The images provided in this paper have been produced via 
ray tracing which is very at- tractive for this model because of its "ray" nature. Techniques relying 
only on scanline conversion are also suitable to render anisotropic surfaces through this model. However, 
the reflective and transparent anisotropic surfaces have to be treated differently. For instance, if 
some environ- ment is mapped onto the surface, the characteristics of the cylinders in the model can 
be used to determine the colour reflected/refracted to the viewer. This colonr will therefore be a weighted 
average of some portion of the environment map. Techniques intended to solve the global illumination 
of scenes can also include anisotropic surfaces. Path tracing [14], combinations of radiosity and ray 
tracing [12][22] and the fight driven approach of FIAT [9] are some examples of techniques where this 
model can be applied, demonstrating its flexibility. The equations used in this paper include many trigono- 
metric functions. The equations have been presented as such in order to simplify their understanding 
and make them as general as possible. However many times the angles them- selves do not have to be computed 
since only their sines and cosines appear in the actual code. In that case the cosines (and consequently 
sines) can be evaluated via dot products. Finally rules to decompose trigonometric functions can be used. 
Image Description Relative Time Image Ia and Ib arymg an 1.27 Image II Reflective surfaces isotropic 
1.00 bumps 1.09 longitudinal 14.55 latitudinal 14.75 Image III Kitchen utensils 1.06 Image IV Sound Design 
1.03 The table given above indicates the additional rendering cost for the images presented in this 
paper. The numbers given are times relative to rendering the same scene without anisotropy. Note that 
for the longitudinal and latitudinal anisotropy of Image II, no jittering was used and as much as 90 
reflected rays where shot in the environment. In the current implementation of Optik, our local ray tracer, 
the rendering of a scene with every surface anisotropic shows an increase on average of 25% over the 
same scene without anisotropy, assuming ray casting. As can be seen for Images III and IV, the ratio 
can be much lower for com- plex scenes. 5 Images On Image Ia and Ib, twelve spheres with different levels 
of anisotropy are rendered. A directional light source is used and all the spheres are projected orthogonally 
onto the screen in order to keep a constant viewing direction. The anisotropy over the spheres is defined 
by longitudinal scratches; on some spheres the position of one of the two poles is clearly visible as 
a black region. Image Ia shows spheres with the anisotropy simulated by positive cylinders. From left 
to right and top to bottom, the first sphere has a d = 0.0001 and h = 0. This is practically undistinguishable 
from an isotropic reflection model. On the next sphere, d is increased to 0.5; the highlight starts forming 
a ring. The highest anisotropy produced by the cylindrical model is shown on the next sphere where d 
= 2.0 while h is still 0. Note how the highlight ring is clearly defined and how dark regions appear, 
due to the shadow- ing between cylinders. On the next sphere (second row), d is raised to 5.0, leaving 
a floor of length 3.0 between the cylinders. Note how the isotropic highlight reappears due to this floor 
region while the highlight ring becomes dimmer because the cylinders occupy a smaller region (proportion- 
ally to the floor). The floor is raised to h = 0.86 on the next sphere, and most of the dark regions 
disappear. Fi-nally, the cylinders are spaced by only 2.0 with the same h = 0.86. The shadowing effect, 
while less pronounced on this last sphere, still makes the highlight ring dimmer. On Image Ib, negative 
cylinders are used, with the same values for d and h. Most of the spheres are quite similar to the ones 
with positive cylinders, but notice how the self- shadowing effect is more pronounced on the third sphere 
(with d = 2 and h = 0). The anisotropy on a surface also influences the way the environment is reflected 
onto it. Image II shows four views of the same highly reflective sphere above the unavoidable checkerboard. 
The surface is not specular so that highlights do not complicate the picture. A directional light source 
points down on the sphere. On the top left corner, we used a perfect mirror-like reflection. By adding 
high frequency bumps onto the surface, we get the image on the top right corner; it just adds some noise 
to the reflection. On the bot- tom left corner, the surface is given longitudinal anisotropy, and on 
the bottom right corner the surface exhibits latitudi- nal anisotropy. Note how the red squares are stretched 
hor- izontally on the left while on the right the reflected squares are stretched vertically. Images 
III and IV show some objects which we normally associate with anlsotropy. In Image III, the objects have 
been created by sweeping a spline curve, and the triangles produced have their tangents approximated 
via the same technique than used for the surface normals. In Image IV, the sound system has many anisotropic 
knobs abd other parts, The hanging cloth on the right is modelled as an isotropic surface. The motifs 
on the cube in the foreground were created using a 3D texture which provides the various orientations 
for the surface tangents. 6 Conclusion We presented an anisotropic reflection model based on covering 
the surface with groups of microscopic cylinders. Anisotropy is caused by the directional distribution 
of the normals along the cylinders. Multidirectional anisotropy can be achieved by defining groups of 
cylinders oriented in. specific directions and given specific weights. Two pa- rameters, the distance 
between cylinders and the height of the floor, provide qualitative and quantitative control over the 
anisotropy. These parameters can easily be tuned to simulate a specific surface or to produce the desired 
effect. Slightly different effects can also be produced by "negative" cylinders. The model takes into 
account hiding and shadowing be- tween cylinders. The reflected intensity can be determined from regular 
samples (as seen by the viewer) along the cylin- ders surface which are then averaged. The sampling angles 
can also be used to obtain the coloar reflected/refracted to the viewer via the anisotropic surface. 
An analytic solution to the diffuse intensity over the cylinders was developed, as well as an approximation 
to the specular intensity using Chebyshev polynomials. The Chebyshev approximation can also be used to 
solve similar problems encountered by Saito et al. [21] for the reflection off rounded edges and Kajiya 
and Kay [15] for the rendering of fur. It has also been used to solve the specular reflection off a surface 
lit by a linear light source [19]. There are several related problems yet to solve. One such problem 
concerns the trade-off between the accuracy of the Chebyshev approximation and the degree of the resulting 
polynomial. It might be possible to reduce the degree of the polynomial with a more careful study of 
the maximal difference between the curves such that, for a given display system, no observer could distinguish 
between the two re- salting intensities. The Chebyshev approximation can also be used to esti- mate the 
inter-reflection between cylinders. In the current model the inter-reflection is ignored, but it would 
be inter- esting to see if inter-reflection improves the realism of the model enough to justify the extra 
processing. The authors also believe this model can be used to pro- vide an additional tool for visualizing 
information on data like orientation of simple vector fields. However in order to obtain understandable 
results, some motion must be applied to the surface or to the light source. At the current stage of our 
implementation we are quite far from real-time motion. 7 Acknowledgement The authors would like to thank 
Avi Naiman, Andrew Woo, Mikio Shinya, Peter Cahoon and especially John Buchanan for their help. We also 
thank Frederic TaiUefer for the drap- ery model used in Image IV. The authors are grateful to NSERC, 
which provided an operating Grant and a Gradu- ate Scholarship, to Ontario ITRC for their financial support, 
and to the generous support of the University of British Columbia where the final phase of this work 
took place.   Appendix A Model of Negative Cylinders A negative cylinder is a cylinder subtracted 
from the surface. The mathematics involved with this type of cylinder are sim- pler because a negative 
cylinder cannot be hidden from the viewer by another negative cylinder. Thus, only the self- shadowing 
and self-hiding have to be considered. The same parameters d and h are used to control the anisotropy, 
how- ever the floor is pushed downwards by a distance h instead upwards from the surface in the case 
of positive cylinders. For negative cylinders, the angles are measured from the surface plane and they 
represent the opposite of what they did for the positive cylinders s (see figure 7, 8 and 9). The 5 The 
main reason of this redefinition is to generate simpler math- ematical expressions. N, E P2 Pl Figure 
7: Some Variables for the Negative Cylinders E~/e direction Figure 8: Regulax Sampling from the Viewer 
 variation of the normals is then within [OM, 7r --0M], where OM is given by OM = min(~bd, ~h) and 6t, 
= sin -1 (h) f cos -I(d/2) if d<2 ~bd [ 0 otherwise The angles at which the self-shadowing 0~, and the 
sdb hiding 0,h stop are then respectively 0,, = maX(20Z--0M,0M) Osn = max(2OE--OM,OM) Simplifications 
also occur because the floor is always completely visible and illuminated. The sampling angles are computed 
as Ov' = r_ 2 + 0g -sin-a (pa cos 0E) 0p2 = ~-OE-sin -I(pacos0E) 2 It is worthwhile to note that the 
analytic solution for the diffuse term as well as the Chebyshev approximation for the specular term axe 
the same as for positive cylinders.  B Chebyshev Approximation Pseudo-code is provided to compute the 
Chebyshev polyno- mials approximating the function cos n ~b, where ~b E [0, zM]. The array a[O..D(a)]will 
contain the coefficients of the poly- nomial approximating the curve. For more information on the properties 
of the Chebyshev polynomials for approxima- tion, consult [20]. ~ + OE -O~ N Figure 9: Finding the Sampling 
Angles tip D(a) is the degree of the polynomial approximation Approximate (n, D(a), aD) XM : COS -I 
0.0039~ for i = 0 to O(a) sum = O; for k = 0 to D(a) = cos(k /O(a)) x = XM × (XchebV+ 1)/2 if(k=0ork=D(a)) 
sum = sum + 0.5cos"(x)x Cheby(i, z~,~bu) else sum = sum + cos"(z)× Cheby(i, Z~,bu) endfor b[i] = 2/O(a) 
× sum endfor for i = 0 to D(a) if (i = 0 or i = D(a)) a[i]= 0.5b[i] × Cheby(i, x,n.bv) else a[i]= b[i] 
x Cheby(i, =chub,) endfor Cheby (degree, x) ff (degree=O) return (1) (degree= I) return (=) return 
(2x Cheby(degree-l,x) Cheby(degree-2, z)) References [1] Bass, F. G. and Fuks, I. M., Wave Scattering 
from Sta- tistically Rough SurJaces. Pergamon Press Ltd., 1979. I2] Beckmann, P., Spizzichino A., The 
scattering of elec- tromagnetic waves ]tom rough surfaces. Artech House, Inc., 2 "a ed., 1987. [3] Blinn, 
J., Models of Light Reflection for Computer Syn- thesized Pictures. Proceedings of SIGGRAPH'?7, In Computer 
Graphics 11, 2 (July 1977), 192-198. [4] Blinn, J., Simulation of wrinkled surfaces. Proceedings of SIGGRAPH'78, 
In Computer Graphics 12, 3 (August 1978), 286-292.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97910</article_id>
		<sort_key>283</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Building block shaders]]></title>
		<page_from>283</page_from>
		<page_to>288</page_to>
		<doi_number>10.1145/97879.97910</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97910</url>
		<abstract>
			<par><![CDATA[This paper describes an implementation of Cook's "shade trees" in which shaders are described as networks of modules, building blocks, whose connections can be defined interactively.The high level interface to the shaders is a graphical editor which permits users to construct complex shaders by connecting shading elements in a network, in effect a graphical shading language. A low level interface to the shaders is also provided. In the low level interface, shading elements are programmed in a standard programming language and compiled into modules which can linked either at run time or compile time.Each link in the shading network represents a subroutine call. In essence, execution of the network is analogous to the execution of an interpreted language.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P99648</person_id>
				<author_profile_id><![CDATA[81100592360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Abram]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Numerical Design Ltd., Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P285628</person_id>
				<author_profile_id><![CDATA[81100586999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Turner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitted]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Numerical Design Ltd., Chapel Hill, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abram, Gregory D., Lee Westover, and Turner WhJtted "Accelerated Rendering," Proceedings of AusGraph '88 (July 1988).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cool Robert L. "Shade Trees," Computer Graphics, Vol. 18, No. 3, (July 1984), pp. 223-231.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378494</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Haeberli, Paul, "ConMan: A Visual Programming Language for Interactive Graphics," Computer Graphics, Vol. 22, No. 4, (July 1988), pp. 103-111.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hamahan, Pat, and Jim Lawson, "A Language for Shading and Lighting Calculations," these proceedings.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37412</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Nadas, Tom, and Alain Foumier, "GRAPE: An Environmerit to Build Display Processes," Computer Graphics, Vol. 21, No. 4 (July 1987), pp. 75-84.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Peachey, Daxwyn R., "Solid Texturing of Complex Surfaces," Computer Graphics, Vol. 19, Ho. 3 (July 1985), pp. 279-286.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Perlirt, Ken, "An Image Synthesizer," Computer Graphics, Vol. 19, No. 3 (July 1985), pp. 287-296.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617498</ref_obj_id>
				<ref_obj_pid>616006</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Upson, Craig, Thomas Faulhaber, Jr., David Kamins, David Laidlaw, David Sehlegel, Jeffrey Vroom" Robert Gurwitz, and Andries van Dam, "Fhe Application Visualization System: A Computation Environment for Scientific Visualization," IEEE Computer Graphics and Applications, Vol. 9, No. 4 (July 1989), pp. 30-42.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Upstill, Steve, The RenderMan Companion Addison- Wesley, (Reading, Massachusetts), 1989.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Verbeck, Charming, James Miehener, Andries van Dam, and David Laidlaw, "Extending PHIGS for Lighting and Shading - PHIGS+," July 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97919</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Westover, Lee, "Footprint Evaluation for Volume Rendering," these proceedings.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357295</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Whirred, Turner and David Weimer, "A Software Test-bed for the Development of 3-D Raster Graphics Systems," ACM Transactions on Graphics, Vol. 1, No. 1 (January 1982), pp. 43-58.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Building Block Shaders Gregory D. Abram and Turner 
Whitted Numerical Design Ltd. Chapel Hill, NC Abstract This paper describes an implementation of Cook's 
"shade trees" in which shaders are described as networks of modules, building" blocks, whose connections 
can be defined interactively. The high level interface to the shaders is a graphical editor which permits 
users to construct complex shaders by connecting shading elements in a network, in effect a graphical 
shading language. A low level baerface to the shaders is also provided. In the low level interface, shading 
elements are programmed in a standard programming language and compiled into modules which can linked 
either at run time or compile time. Each link in the shading network represents a subroutine call. In 
essence, execution of the network is analogous to the execution of an interpreted language. CR Categories 
and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generations -Display Algorithms; 1.3.6 
[Computer Graphics] Methodology and Techniques -interactive techniques; 1.3.7 [Computer Graphics] Three-dimensional 
Graphics and Realism -Color, shading, shadowing, and texture. Additional Key Words and Phrases: shade 
trees, visual pro- gramming.  Access to Shaders The realism seen in synthetic images is largely due 
to the advanced techniques now available for simulating the effects of illumination and reflection, collectively 
called shading. How-ever, access to the best of these teclmiques has generally been limited to programmers. 
In this paper we describe a method that provides interactive access to shading techniques for non-programmers. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. Currently available 
commercial rendering systems provide a level of access that is too high to provide needed flexibility, 
i.e. monolithic shading procedures, or too low to be convenient, i.e. shading languages. Our approach 
is to provide an intermediate level of access which is flexible and yet interactive. In this inter- mediate 
level interface, shaders are assembled from building block modules by defining the connections between 
modules. This paper defines the building block elements, the range of effects that can be achieved with 
collections of building blocks, and the interface for editing shaders.  Evol~ion When shaded display 
was in its infancy, the simple Lambert law shader was the only function available. A typical rendering 
pro- gram operated on a single primitive surface type, used a single algorithm for determining visibility, 
and used a hard-wired shader. As better shading models were developed, a common strategy was to hard-wire 
the best available shader and obtain a wide range of appearances by varying the shading parameters. Shading 
parameters include coefficients to determine the amount of diffuse reflection, specular reflection, surface 
shininess, etc. The amount of control that a user can gain over a shader is extended tremendously through 
the addition of tables which modify the shading function. Texture maps which tabulate the color, ambient 
light (environment maps), displacement, or nor- real perturbation (bump maps) of a surface are the best 
known examples. In fact, anywhere that a coefficient is used in a shading calculation is a point at which 
a tabulated array of coefficients can add flexibility to the shader. Designers of most modern rendering 
packages recognize the need for more flexibility in the shader. One way to provide this is to make several 
built-in lighting models available to the user [10], [12]. This provides coarse control of appearance 
using shader selection and fine control with shader parameters. It also pro- vides efficiency since slower 
shaders are only used when the sur- face type calls for it. Cook's "shade trees" [2] are collections 
of shading components arranged as a tree. Intermediate shading results are propagated up the tree urttil 
the root returns a final shade value. Because of their flexibility shade trees are a wonderfully convenient 
concep- tual model for "do-it-yourself" shader construction. &#38;#169;1990 ACM-0-89791-344-2/90/008/0283 
$00.75 283 O SIGGRAPH '90, Dallas, August 6-10, 1990 The key to retaining flexibility in a shading network 
is the careful selection of bulk-in functions. Classes of shading functions are distinguished by the 
scope of their" operation. Global operators are those which are able to modify the global variables, 
generally as a side effect. Local operators produce a result which is assigned to a local variable of 
some other module. Pipe fitting modules are connection elements which glue other modules together. As 
an example of the use of the built-in functions, figure 2 shows a solid textured and bump mapped toms 
shaded with fog. The elements from which the shader is assembled are shown as a tree in figure 3. Note 
that marble and plastic are included as built-ins instead of describing them in terms of their components. 
(See [7] and [2] for a discussion of the components of each one.) The decision to include such moderately 
high level functions is based partly on efficiency considerations, partly on convenience in the user 
interface, but mostly on user expectations [5]. Obviously both the high level functions and their components 
can be included in the collection of available functions at the cost of some code replication.  Structural 
and Implementation Details Each building block component carries one or more "tabs" which define points 
of connection. Networks are constructed by linking tabs together. Tabs are typed STUFFBEFORE, STUFFDURING, 
or STUFFAFTER to identify when the child process attached to the tab is to be executed relative to the 
execution of the parent process. STUFFBEFORE and STUFFAFTER processes are exe- cuted automatically with 
no explicit intervention from the parent process; STUFFDURING processes are called explicitly by the 
parent. This implementation of shade trees differs from the traditional model by its explicit control 
over the order of execution of shad- ing modules, and by the inclusion of connection roanagers in each 
module. Associated with each tab may be the address of a parameter of the parent. If is exists, the the 
child will overwrite the default value of the corresponding parameter. For example, color is a parameter 
of the plastic process which carries an externally visi- ble tab of type STUFFBEFORE. If a texture map 
is attached to the color tab of plastic then the sampling process of the texture map automatically overwrites 
the color parameter of plastic. The tabs on shading elements indicate points of connection, but not necessarily 
data flow. A tab cormected to a child function causes the child function to be executed, but the result 
can be a side effect with no data actually passing from child to parent. Conceptually, constant parameter 
values are merely procedures which return constants. However our implementation distin-guishes constants 
from functions for efficiency's sake. The external representation of each module is an ASCII string containing/name 
value pairs in the format name=value for constant parameters and name@value in the case where value 
is the name of a function. We have discovered in the course of using these modules that the concatenation 
operation is extremely common, h is an implicit part of every built-in function through the addition 
of before and after tabs. In the actual implementation the concatenation ele-ment would be missing from 
figure 3 and bump map and fog would be attached to the before and after tabs of the plastic module. The 
ASCII string which represents the network in figure 3 is: refll: plastic before@txtr2 after@atmos color@txtrl 
\ dlffuse=CONSTl specular=CONST2 txtrl: marble freq=FREQUENCY ampi-AMPLITUDE txtr2: bump_map name=FILENAME 
atmos: fog At run time the ASCII string is decoded, procedures which are not in memory are loaded, and 
name/value pairs are converted to pointers.  Programmer/User Interface Most turnkey rendering applications 
contain a mechanism for interactively setting shading parameters and previewing the results. While not 
exactly providing WYSIWYG rendering, they provide a very effective editor for shading effects. There 
is a clear advantage to retaining this interactivity for more complex shading functions described above. 
For networks constructed from built in building block modules, the interface is simply a connection editor. 
While more elaborate systems such as ConMan [3] and AVS [8] incorporate both a con- nection editor and 
a connection manager, our shaders have their connection manager built in. Consequently the connection 
editor is a very simple piece of code which provides a point-and-click interface for constructing an 
ASCII description of networks. Figure 4 shows the connection editor and shading previewer. In the window 
labeled "Shade Tree Editor" a shading network is being constructed from built-in components. To test 
the effect of this network, a user hits the 'Try It" button. A pre-scan-converted sphere is shaded using 
the newly defined shader in the window labeled "Appearance View." The user selects a tab at which to 
extend the tree by clicking on the label for the tab. In the figure the "fileNarne" tab of the tex- ture 
sampler is highlighted by a thin box) indicating that it has been selected. The user then pops up a menu 
of modules, includ- ing file names and constants, which is attached to the selected tab. The layout of 
the schematic of the tree is handled automati- cally by the editor. Unlike all of the diagrams in this 
paper, the editor extends the tree from left to right. The important feature of this style of interaction 
is the quick feedback provided by the shading preview. This overcomes an argument that shading networks 
are too complicated for non-programmers to use. Our experience has been that users don't really have 
to understand the inner workings of the shader func- tions as long as they can tinker with various combinations 
and quickly see the effect of their tinkering. One problem with this graphical shading language is the 
poten- tial for type mis-matching. When an input tab of one module is   O SIGGRAPH '90, Dallas, August 
6-10, 1990 [5] Nadas, Torn, and Alain Fournier, "GRAPE: An Environ- merit to Build Display Processes," 
Computer Graphics, Vol. 21, No. 4 (July 1987), pp. 75-84. [6] Peachey, Darwyn R., "Solid Texturing of 
Complex Sur- faces," Computer Graphics, Vol. 19, No. 3 (July 1985), pp. 279-286. [7] Perlin, Ken "An 
Image Synthesizer," Computer Graphics, Vol. 19, No. 3 (July 1985), pp. 287-296. [8] Upson, Craig, Thomas 
Faulhaber, Jr., David Karnlns, David Laidlaw, David Schlegel, Jeffrey Vroom, Robert Gurwitz, and Andries 
vml Dam, "The Application Visuali- zation System: A Computation Environment for Scientific Visualization," 
IEEE Computer Graphics and Applica- tions, Vol. 9, No. 4 (July 1989), pp. 30-42. [9] Upstill, Steve, 
The RenderMan Companion Addison-Wesley, (Reading, Massachusetts), 1989. [I0] Verbeck, Charming, James 
Michener, Andries van Darn, and David Laidlaw, "Extending PHIGS for Lighting and Shading - PHIGS+," July 
1987. [11] Westover, Lee, "Footprint Evaluation for Volume Render- ing," these proceedings. [12] Whltted, 
Turner and David Wehner, "A Software Test-bed for the Development of 3-D Raster Graphics Systems," ACM 
Transactions on Graphics, Vol. 1, No. 1 (January 1982), pp. 43-58.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97911</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A language for shading and lighting calculations]]></title>
		<page_from>289</page_from>
		<page_to>298</page_to>
		<doi_number>10.1145/97879.97911</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97911</url>
		<abstract>
			<par><![CDATA[A shading language provides a means to extend the shading and lighting formulae used by a rendering system. This paper discusses the design of a new shading language based on previous work of Cook and Perlin. This language has various types of shaders for light sources and surface reflectances, point and color data types, control flow constructs that support the casting of outgoing and the integration of incident light, a clearly specified interface to the rendering system using global state variables, and a host of useful built-in functions. The design issues and their impact on the implementation are also discussed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15033698</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P140464</person_id>
				<author_profile_id><![CDATA[81547762256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lawson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[The RenderMan Interface, PIXAR (December 1989).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B ARR, ALAN H., "Decal Projections," A CM SIGGRAPH "84 Course Notes 15: Mathematics of Computer Graphics, (1984).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[BENTLEY, JON, "Little Languages," pp. 83-100 in More Programming Pearls, Addison-Wesley, Reading, Massachusetts (1988).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BIER, ERIC A. AND KENNETH R. SLOAN JR., "Two-Part Texture Mapping," 1EEL Computer Graphics and Applications 6(9) pp. 40-53 (September 1986).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMES F., "Simulation of Wrinkled Surfaces," Computer Graphics 12(3) pp. 286-292 (August 1978).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., "Shade Trees," Computer Graphics 18(3) pp. 223-231 (July 1984).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., "Stochastic Sampling in Computer Graphics," ACM Transactions on Graphics 5(1)pp. 51-72 (January 1986).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L., LOREN CARPENTER, AND EDWIN CAT- MULL, "The Reyes Image Rendering Architecture," Computer Graphics 21(4) pp. 95-102 (July 1987).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806801</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[DILL, JOHN C., "An Application of Color Graphics to the Display of Surface Curvature," Computer Graphics 15(3) pp. 153-161 (August 1981).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102331</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[FLEISCHER, KURT AND ANDREW WITKIN, "A Modeling Testbed," Graphics Interface "88, pp. 127-137 (June 1988).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13023</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[GREENE, NED, "Environment Mapping and Other Applications of World Projections," IEEE Computer Graphics and Applications 6(11) pp. 108-114 (November 1986).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[HALL, ROY A., "Color Reproduction and Illumination Models," pp. 194-238 in Techniques for Computer Graphics, ed. R. A. Earnshaw,Springer-Verlag (1987).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63450</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[HALL, RoY A., Illumination and Color in Computer Generated Imagery, Springer-Verlag, New York (1989).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, JAMES T., "Anisotropic Reflection Models," Computer Graphics 19(3) pp. 15-22 (July 1985).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, JAMES T., "The Rendering Equation," Computer Graphics 20(4) pp. 143-149 (August 1986).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, JAMES T. AND TIMOTHY L. KAY, "Rendering Fur with Three Dimensional Textures," Computer Graphics 23(3) pp. 271-280 (July 1989).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>7519</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[KERNIGHAN, BRIAN W. AND DENNIS M. RrrCHIE, The C Programming Language, Prentice-Hall (1978).]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74360</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[LEWIS, JOHN P., "Algorithms for Solid Noise Synthesis," Computer Graphics 23(3) pp. 263-270 (July 1989).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>36194</ref_obj_id>
				<ref_obj_pid>36206</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[MASSALIN, HENRY, "Superoptimizer: A Look at the Smallest Program," Proceedings of ASPLOS (Architectural Support for Programming Languages and Operating Systems), pp. 122-127 (October 1987).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[MILLER, (3ENE S. AND C. ROBERT HOFFMAN, "Illumination and Reflection Maps: Simulated Objects in Simulated and Real Environments," in Siggraph "84 Course Notes: Advanced Computer Graphics Animation, (July 1984).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102332</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[MILLER, GAVIN S. P., "From Wire-Frames to Furry Animals," Graphics Interface '88, pp. 138-145 (1988).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801252</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[NORTON, ALAN, ALYN P. ROCKWOOD, AND PHILIP T. SKOL- MOSKI, "Clamping: A Method of Antialiasing Textured Surfaces by Bandwidth Limiting in Object Space," Computer Graphics 16(3)pp. 1-8 (August 1982).]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[PEACHEY, DARWYN, "Texture On Demand," (submitted for publication), (1990).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[PERLIN, KEN, "An Image Synthesizer," Computer Graphics 19(3) pp. 287-296 (July 1985).]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74359</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[PERLIN, KEN AND ERIC M. HOFFERT, "Hypertexture," Computer Graphics 23(3) pp. 253-262 (July 1989).]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[PORTER, THOMAS AND TOM DUFF, "Compositing Digital Images," Computer Graphics 18(3)pp. 253-260 (July 1984).]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[STEELE, GUY L., Common Lisp, Digital Press, Burlington, MA (1984).]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[UPSTILL, STEVE, The RenderMan Companion, Addison- Wesley (1989).]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[VERBECK, CHANNING P. AND DONALD e. GREENBERG, "A Comprehensive Light-Source Description for Computer Graphics," IEEE Transactions on Computer Graphics and Applications 4(7) pp. 66-75 (July 1984).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[WHITYED, TURNER, "All Improved Illumination Model for Shaded Display," Communications of the ACM 23 pp. 343-349 (1980).]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357295</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[WHITIXD, ~R ArID DAVID M. WEIMER, "A Software Testbed for the Development of 3D Raster Graphics Systems," ACM Transactions on Graphics 1(1)pp. 44-58 (January 1982).]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 A Language for Shading and Lighting Calculations 
 Pat Hanrahan* and Jim Lawsont *Princeton University "tPixar Abstract A shading language provides a 
means to extend the shading and lighting formulae used by a rendering system. This paper discusses the 
design of a new shading language based on previous work of Cook and Perlin. This language has various 
types of shaders for light sources and surface reflectances, point and color data types, control flow 
constructs that support the casting of out- going and the integration of incident light, a clearly specified 
interface to the rendering system using global state variables, and a host of useful built-in functions. 
The design issues and their impact on the implementation are also discussed. CR Categories: 1.3.3 [Computer 
Graphics] Picture/Image Generation-Display algorithms; 1.3.5 [Computer Graphics] Three-Dimensional Graphics 
and Realism -Color, shading, sha- dowing and texture. Additional Keywords and Phrases: Shading language, 
little language, illumination, lighting, rendering 1. Introduction The appearance of objects in computer 
generated imagery, whether they be realistic or artistic looking, depends both on their shape and shading. 
The shape of an object arises from the geometry of its surfaces and their position with respect to the 
camera. The shade or color of an object depends on its illumina- tion environment and its optical properties. 
In this paper the term shading refers to the combination of light, shade (as in shadows), texture and 
color that determine the appearance of an object. Many remarkable pictures can be created with objects 
having a simple shape and complex shading. A well-designed, modular rendering program provides clean 
interfaces between the geometric processing, which involves transformation, hidden sur- face removal, 
etc., and the optical processing, which involves the propagating and filtering of light. This paper describes 
a language for programming shading computations, and hence, extending the types of materials and light 
sources available to a rendering sys- tem. In Bentley's terminology it would be called a "little" language[3], 
since, because it is based on a simple subset of C, it easy to parse and implement, but, because it has 
many high-level features that customize it for shading and lighting calculations, it is easy to use. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. Two major aspects 
of shading are the specification of sur- face reflectance and light source distribution functions. The 
earli- est surface reflectance models have terms for ambient, diffuse and specular reflection. More recent 
research has added anisotropic scattering terms[M, 16,21] and made explicit wavelength and polarization 
effects. Although not nearly as well publicized, many improvements have also been made in light source 
descrip- tion. The earliest light source models consisted of distant or point light sources, Verbeek 
and Greenberg[29] introduced a general framework for describing light sources which includes attaching 
them to geometric primitives and specifying their intensity distri- bution as a function of direction 
and wavelength. Light sources and surface reflectance functions are inherently local processes. However, 
many lighting effects arise because light rays traveling from light to surface are blocked by intervening 
surfaces or because light arriving at a surface comes indirectly via another surface. Turner Whitted 
termed these effects global illumination processes. Kajiya introduced the gen- eral light transport equation, 
which he aptly termed the rendering equation, and showed how all these techniques are tied together[15]. 
Most recent research in shading and lighting calcu- lations is now being focussed on making these global 
illumination algorithms efficient. Note that global and local illumination processes are independent 
aspects of the general illumination pro- cess. In parallel to the development of specific shading models 
is the development of shading systems. Most current systems imple- ment a single parameterized shading 
model. There are several problems with this approach. First, there is little agreement on what this shading 
model should be. Almost every rendering sys- tem written has used a slightly different shading model. 
Second, it seems unlikely that a single parametefized model could ever be sufficient. As mentioned earlier, 
the development of shading models is an active area of research and new material models are continually 
being developed. Shading also involves many tricks, one major example being texture mapping, and the 
use of render- ing tricks is completely open ended. Furthermore, the surface reflectance models of simple 
and composite materials are phenomenologically based and not derivable from first principles. Shading 
models that capture the effects of applying varnish or lac- quer to wood, or of adding an additional 
flap to a stage light, are much better expressed procedurally than as mathematical formu- lae. Another 
problem with this single parameterized model approach, is that simple shading formula carry the overhead 
of the most complicated ease. This overhead makes it more difficult for users to control, and more time 
consuming for the rendering &#38;#169;1990 ACM-0-89791-344-2/90/008/0289 $00.75 289 O SIGGRAPH '90, 
Dallas, August 6-10, 1990 system to compute. Because of these difficulties with the single shading model 
approach, several systems have been described that provide greater flexibility and extensibility. Whitted 
proposed that the rendering system have a collection of built-in shaders accessible via a shader dispatch 
table[31]. Presumably, the interface to these shaders was well-defined so that experienced hackers with 
access to the source code could extend the system. Cook developed a model which separated the conceptually 
independent tasks of light source specification, surface reflectance, and atmospheric effects[6]. The 
user could control each of these shading processes indepen.dently by giving a sequence of expressions 
which were read in, parsed, and executed at run-time by the rendering system. Perlin's image synthesizer 
carried this idea further by providing a full language including conditional and looping constructs, 
func- tion and procedure definitions, and a full set of arithmetic and log- ical operators[24]. But Perlin 
abandoned the distinction between the shading processes proposed by Cook, and instead introduced a "pixel 
stream" model. In the pixel stream model, shading is a postprocess which occurs after visible surface 
calculations. Unfortunately, this makes his language hard to use within the con- text of a radiosity 
or ray-tracing program, where much of the shading calculation is independent of surface visibility. In 
this paper, a new language is described which incor- porates features of both Cook's and Perlin's systems. 
The goals in the design of the new language were to: Develop an abstract shading model based on ray 
optics suitable for both global and local illumination models. It should also be abstract in the sense 
of being independent of a specific algorithm or implementation in either hardware or software.  Define 
the interface between the rendering program and the shading modules. All the information that might logically 
be available to a built-in shading module should be made available to the user of the shading language. 
 Provide a high-level language which is easy to use. It should have features -point and color types 
and operators, integration statements, built-in functions - that allow shad- ing calculations to be expressed 
naturally and succinctly.  A detailed description of the shading language grammar is avail- able in 
the RenderMan interface specification[l], and many examples of its use are contained in Upstill[28]. 
The intent of this paper is to point out the features of the new language beyond those described by Perlin 
and Cook. The design of the new language also raised many subtle design and implementation issues whose 
resolution required a combination of graphics and systems perspectives. The alternatives that were considered, 
and the factors that influenced the choices that were made are dis-cussed. Finally, we discuss some of 
the more interesting parts of the implementation, particularly those aspects where a combina- tion of 
techniques drawn from graphics, systems and compiler theory were used to improve performance. 2. Model 
of the Shading Process Kajiya has pointed out that the rendering process can be modeled as a integral 
equation representing the transport of light through the environment[ 15]. i (x, x')=v (x, x') [I (x, 
x') + S r (x, x', x") i (x" ,x") dr"] The solution, i (x, x'), is the intensity of light at x which 
comes from x'. The integral computes the amount of light reflected from a surface at * as a function 
of the surface bidirectional reflectance function r(x, x/, x'3 and the incoming light intensity distribution 
i (x', x"). The term l (x, x') gives the amount of light emitted by light sources at x' in the direction 
towards x. The sum of these two terms is the amount of light initially traveling from x' to x, but not 
all that light makes it to x: some of it may be scattered or blocked by an intervening material. The 
term v (x, x') gives the percentage of light that makes it from x' to x. The shading language allows 
procedures, called shaders, to be written that compute the various terms in the above equation. Shaders 
implement the local processes involved in shading; all the global processes used in solving the rendering 
equation are con- trolled by the renderer. The three major types of shaders are: Light Source Shaders. 
A light source shader calculates the term l (x, x'), the color and intensity of light emitted from a 
particular point on a light source in a particular direction.  Surface Reflectance Shaders. A surface 
reflectance shader calculates the integral of the bidirectional reflectance func- tion r(x, x', x') with 
the incoming light distribution i(x', x').  Volume or Atmosphere Shaders. Volume shaders compute the 
term v (x, x'). Only scattering effects need be com-puted; the effects of light rays intersecting other 
surfaces are handled by the renderer.  A surface shader shades an infinitesimal surface element given 
the incoming light distribution and all the local properties of the sur- face element. A surface shader 
assumes nothing about how this incoming light distribution was calculated, or whether the incom- ing 
light came directly from light sources or indirectly via other surfaces. A surface shader can be bound 
to any geometric primi- tive. The rendering program is responsible for evaluating the geometry, and provides 
enough information to characterize the infinitesimal surface element. Similarly, when a light source 
shader computes the emitted light, it makes no assumptions about what surfaces that light may fall on, 
or whether the light will be blocked before it reaches the surface. A light source shader also makes 
no assumptions about whether it is bound to a geometric primitive to form an area light. Kajiya has shown 
how standard rendering techniques can be viewed as approximate solutions of the rendering equation. The 
simplest approximation assumes that light is scattered only once. A ray is emitted from a light source, 
reflected by a surface, and modulated on its way towards the eye. This is often referred to as local 
shading, in contrast to global shading, because no information about other objects is used when shading 
an object. This shading model is what is used by most real-time graphics hardware and is easily accommodated 
by the shading language. Whitted's ray tracing algorithm[30] considers these direct tran- sport paths, 
plus light transported from surfaces intersected by reflected and refracted rays. This can also be accommodated 
by the shading language by recursively calling light source and sur- face shaders. To summarize, the 
abstraction used by the shading language provides a way of specifying all the local interactions of light, 
without assuming how the rendering program solves the light transport equation. Thus, shaders written 
in the shading language can be used by many different types of rendering algo- rithms. 3. Language Features 
The shading language is modeled after C[17], much like many other programming languages developed under 
UNIX. The specification of the syntax and grammar is available in the specification[l] and examples of 
its use are described in a recent book[28]. In the following sections the novel features of the shad- 
ing language are discussed. The emphasis is on the high-level design issues that influenced each feature, 
and the implementation problems that they posed. The features discussed include the semantics of the 
color and point data types, the meta types ~ Computer Graphics, Volume 24, Number 4, August 1990 uniform 
and varying, the classes and subclasses of shaders and how shaders are attached to geometry, the intrinsic 
state infor- mation which is provided by the rendering system, the special control constructs for integrating 
incoming light in surface shaders and for casting outgoing light in light source shaders, some of the 
more unusual built-in functions, and support for texture mapping. 3.1. Types The shading language supports 
a very small set of fixed data types: floats, strings, colors, and points. Since points and colors are 
the fundamental objects passed between shaders and the renderer, these are supported at a high level 
in the shading language. No facilities exists to define new types or data struc- tures. 3.1.1. Colors 
The physical basis of color is a spectrum of light. The spectrum describes the amount of light energy 
as a continuous function of wavelength. Since calculations involving continuous spectra are generally 
not feasible, spectra are represented with a fixed number of samples. Different methods for sampling 
spectra are described in Hall[12, 13]. In the shading language, color is an abstract data type which 
represents a sampled spectra. The number of color samples per color can be set before rendering to control 
the precision of the color computations. One sample implies a monochrome color space; three samples a 
triaxial color space; and more samples are available for more precise color computations. There is no 
support for sampling or resampling spectra; this is assumed to be done by the modeling program driv- 
ing the renderer or the output program generating the final display. Within the spectral color space 
model there are two impor- tant operations involved in shading calculations: additive light combination, 
where the result is the spectrum formed by combin- ing multiple sources of light, and~ltering, where 
the result is the spectrum produced after light interacts with some material. These operations are mapped 
into the language by overloading the stan- dard addition and multiplication operators ("+" and "*"), 
respectively. All color computations in the language are expressed with these operators, so that they 
are independent of the actual number of samples. A typical color computation might be expressed as CO 
* (La + Ld) + Cs * Ls + Ct * Lt where Cd and Cs are the diffuse and specular colors of a material, La, 
Ld, and Ls, are the amount of ambient, diffuse, and specular light reflected from the surface, and Ct 
and Lt are the transparency and amount of light transmitted through the material. Note that transparency 
is treated just like any other color, that is, it has the same number of color components. Many rendering 
systems make the mistake of modeling transparency with a single number. This is presumably motivated 
by the use of RGBA color models[26] where o~ which was originally developed to represent coverage is 
treated as an opacity (equal to one minus the transparency). We considered having two types of color, 
one for light spectra and another for material absorption spectra, and to restrict the values of light 
spectra samples to always be positive, since they represent energy which must be positive, and the values 
of mate~ai spectra to always be between 0 and 1, since they represent percent absorption. However, this 
was thought to be too restrictive -for example, negative light sources are sometimes used for faking 
shadows, and reflective colors greater than 1 are used for modeling stimulated emission. For similar 
reasons, we also allowed other arithmetic operators between colors, although they are very seldomly used. 
In our experience, it is very con- venient to think of color as light and hence, not to clamp it to some 
maximum value. Eventually, after all shading computations have been per- formed, the light "exposes" 
film using a non-linear remapping from light intensities to output pixel colors. After this process, 
a pixel color value of 1 is treated as the maximum display intensity. Since the addition and multiplication 
of colors is performed on a component by component basis, the shading language makes no assumptions about 
what. physical color each sample actually represents. Also, if only color operators are used to combine 
colors inside a shader, an arbitrary linear transformation can be applied to the input or output colors 
without affecting the results. This gives the modeling program driving the renderer complete control 
over what spectral color space the renderer is computing in. One advantage of this is that color computations 
can per-formed in absolute or calibrated color spaces, just by transforming the input or output color 
space. There are many other color spaces used in computer graph- ics for defining colors. We refer to 
these as modeling color spaces to distinguish them from spectral rendering color spaces. In general, 
adding and multiplying colors in these other color spaces has no physical basis, and hence executing 
shaders with colors in non-spectral color spaces can lead to unpredictable results. The language supports 
the use of modeling color spaces by providing built-in functions which immediately convert con- stant 
colors defined in these color spaces to the current rendering color space. 3.1.2. Points. The type point 
is used to represent a three component vec- tor. The arithmetic operators are overloaded so that when 
they involve points they are treated in the standard vector algebra sense. New operators were added to 
implement the operations of dot product C.") and cross product C^"). Using this syntax, a Lambertion 
shading formula can be expressed on one line. C * max( O, L.N ) where L and N are tile light and normal 
vectors, and C is a color. The main advantage of having built-in vector operations is that the standard 
shading formulae can be expressed in a succinct and natural way, often just by copying them right from 
the litera- ture. Another advantage of expressing shading calculations using vector arithmetic is that 
they are then expressed in a coordinate-free way, which means that the shader could be evaluated in different 
coordinate systems. Care must be taken in applying this idea since, in general, transformations between 
coor- dinate systems do not preserve metric properties such as angles and distances. Since the physics 
underlying shading calculations are based on these metric quantities, the results of shading calcu- lations 
will be different in coordinate systems which do not preserve them. For this reason shading calculations 
are defined "to appear" as if they took place in the world coordinate system, but it is permissible for 
the renderer to shade in other coordinate systems that are isometric to the world coordinate system. 
A common example of this is shading in "camera" or "eye" space instead of world space. In certain situations, 
it is necessary for a calculation involv- ing a point to be performed in a specific coordinate system. 
For example, all surface shaders accessing a solid texture need to access the texture in the solid texture's 
coordinate system. This is supported by providing a procedure which transforms points between named coordinate 
systems. The standard named coordi- nate systems are "raster", "screen", "camera", "world" and "object". 
In our system it is also possible to mark other coordi- nate systems, and then to refer to them within 
shaders. @SIGGRAPH '90, Dallas, August 6-10, 1990 3.2. Uniform and Varying Variables All variables in 
the shading language fall into one of two general classes: uniform and varying, uniform variables are 
those whose values are independent of position, and hence, constant once all the properties have been 
bound; varying variables are those whose values are allowed to change as a function of posi- tion. Varying 
variables come about in two ways. First, geometric properties of the surface usually change across the 
sur- face. Two examples are surface parameters and the position of a. point on a surface. The normal 
changes on a curved surface such as a bicubic patch, but remains constant if the surface is a planar 
polygon. Second, variables attached to polygon vertices or to comers of a parametric surface are automatically 
interpolated across the surface by the rendering program, and hence are vary- ing. The best examples 
of varying variables attached to polygons are vertex colors in Gouraud shading and vertex normals in 
Phong shading. The concept of interpolating arbitrary variables during scan conversion was first introduced 
by Whitted and Weimer[31]. The concept of uniform and varying variables allows the shading language compiler 
to make significant optimizations. If the shader contains an expression or subexpression involving only 
constants and uniform variables, then that expression need only be evaluated once, and not every time 
the shader is executed. This is similar to constant folding at compile time, but differs in that a different 
uniform subexpression may occur each time a new instance of a shader is created, or each time a shader 
is bound to a surface. Because shading calculations are so expensive, a folklore has developed over hand 
coding these types of optimizations. For example, if the viewing transformation is a parallel projection, 
meaning the eye is at infinity, and a planar polygon is being shaded, the incoming direction, the normal, 
and hence the direc- tion of the reflection vector are all constant and need only be com- puted once 
per polygon. A similar situation occurs with local and distant lights. The advantage of using uniform 
variables and hav- ing the compiler look for uniform expressions is that these optimi- zations are done 
automatically. 3.3. Shader Classes and instances It is often convenient to think of shaders in an object- 
oriented way. There are several major subclasses of shaders, corresponding to the set of methods required 
by the rendering sys- tem. The most general class of shading procedures is a shader, and there are subclasses 
for light sources, surface reflectance func- tions, and volume scattering. A shader for a specific subclass 
is created by prefixing its definition by a keyword: surface for a surface shader, light for a light 
shader, and volume for a volume shader'~. Surface shaders describe different types of material such as 
metal and plastic; and light source shaders dif- ferent classes of lights such as spotlights and bulbs. 
Shader definitions are similar to procedure definitions in that they contain a formal argument list. 
The arguments tO a shader, however, are very different than the arguments to a shad- ing language function. 
Calling a shader to perform its task is under the control of the rendering system, and all information 
from the renderer is passed to the shader through external vari- ables and not via its arguments (see 
Section 3.4). Shaders are never called from other shaders or from other functions in the shading language. 
"~ Actually the following types also exist: displacement, transformation, and imaqer. The shader arguments 
define the shader's instance vari-ables and are used to set the properties of a shader when the user 
adds the shader to the graphics state or attaches it to a geometric primitive. All instance variables 
have default values that must be specified as part of the definition of the shader. However, the defaults 
can easily be overridden when creating an instance. This is done by giving a list of name-value pairs; 
the name refers to which instance variable is being set, and the value to its new value. This method 
of defaulting makes it easy to use compli-cated shaders with many parameters. For example, the shader 
metal is declared in the shading language as surface metal( float Ka=l, Ks=l, roughness=.l )  and is 
attached to the surface with the following procedure call. RiSurface( "metal", "Ka", 0.5 );  This instance 
of "metal" has a different Ka than the default instance. The arguments, or instance variables, of a shader 
are typi- cally uniform variables because they describe overall properties of the surface or light source. 
User-defined interpolated variables are created in the shading language by declaring an argument to a 
shader to be a varying variable. The interpolated value is made available to the shader via that shading 
language variable. Finally, it is possible to pass point variables as instance variables to a shader. 
As a convenience, these points are interpreted to be in the current coordinate system, and transformed 
automatically to the coordinate system in which the shading calculation is being performed. For example, 
pointlight has as part of its declaration. light pointlight ( . . . ; point from = point "shader" (0,0,0); 
... )  The "shader" coordinate system is the one in effect when the shader was instanced. In the above 
example the light is placed at the origin of this coordinate system. Note how the transforma- tions apply 
to default points as well as points supplied when instancing. 3.4. Intrinsic State When a shader is bound 
to a geometric primitive, it inherits a set of varying variables that describe the geometry of the surface 
of the geometric primitive. All shaders also inherit the color and opacity of the primitive and the local 
illumination environment described as a set of light rays. This information is made avail- able to a 
shader as variables which are bound to the correct values by the rendering system before the shader is 
evaluated. A shader is very much like a function closure, which contains pointers to the appropriate 
variables based on the scoping rules for that func- tion[27]. The names and types of the major external 
variables are shown in Figures 1 and 2. These external variables, along with a few built-in func- tions, 
specify exactly what information is passed between the rendering system and the shading system, Because 
this is the only way these modules communicate, determining these variables was one of the most difficult 
aspects of the design of the shading language. Two general principles were followed: (i) the material 
information should be minimal, but extensible, and (ii) the geometric and optical information should 
be complete. A simpler interface between the shading and geometry is specified in Fleischer and Witkin[ 
10]. ¢ Computer Graphics, Volume 24, Number 4, August 1990 \ I L/ghtiSource ~ _ urface Element to Illuminate 
 Vantage Point .... . ........... ------" ......_.:.:i <i................ l z,~._ N ~: I[luminanceCone 
 """" '~~'~~~ !1 ///'llluminateCone x .. ";; "'" ," ,-% I dlPdv Primitive Surface Figure 2. Light source 
shader state. Figure 1. Surface shader state. Since one of the major goals of the shading language is 
to extend the types of materials used by the rendering system, it is important to be able to assign arbitrary 
properties to new materi- als. The only material properties assumed to always be present, and hence made 
available as global variables, are color and opa- city. All other material properties are explicitly 
declared as argu- ments to the shader. Since there is no resttriction, in principle, to the number or 
types of arguments to a shader, the properties of materials can involve any amount of information. The 
rendering system may perform shading calculations at many points on the surface of a geometric primitive, 
It provides enough geometric information to characterize The surface element in the neighborhood of the 
point being shaded. Most shading for- mulae involve only the position P and normal N of the surface. 
When doing texture mapping it is often necessary to provide the surface parameters. More advanced shading 
methods, such as bump mapping[5] or tangent bundle mapping[14] require the parametric derivatives of 
the position vector. From a mathemati- cal point of view, to completely characterize a surface at a point 
requires knowledge of all its parametric derivatives and cross derivatives at the point. Other intrinsic 
surface properties, such as Gaussian curvature, can be computed from this information. There are CAD 
and mathematical applications which require methods to visualize local properties of the surface geometry[9]. 
Providing all these derivatives of position through global variables would be unwieldy, so functions 
were provided to take derivatives of position with respect to the surface parameters. This derivative 
function is discussed in more detail below (see Section 3.7). It is expensive for the rendering system 
to compute all this information, and this is wasted computation if it is not being used by the shader. 
Unnecessary calculation can be prevented by hav- ing the shaders provide a bitmask indicating which external 
vari- ables are referenced within the shader before it is executed. Alter- natively, the runtime environment 
uses a lazy evaluation to com- pute the values of the variables on demand. It is also useful to provide 
a bitmask indicating which variables are changed by the shader, since in some cases the renderer may 
want to retain the original values. 3.5. Light Sources The most general light source description defines 
the inten- sity and color of the emitted light as a function of position and direction[29]. The shading 
language provides a method for describing an arbitrary light source distribution procedurally. It does 
this by providing two constructs, solar and illuminate, The illuminate statement is used to set the color 
of light coming from a finite point. Its arguments define a cone with its apex at the point from which 
the light emanates. Only points inside that cone receive light from that light source. The solar statement 
is used to set the color of light coming from dis- tant or infinite light sources. Its arguments define 
a cone, centered on the point being illuminated, to which distant light will be cast. Within the block 
of a illuminate or solar statement, the emitted light direction is available as an independent read-only 
variable L, and the color of the emitted light C1 is treated as a dependent variable which should be 
set to define the color and intensity of light emitted as a function of direction. During the design 
process the following canonical types of lights were considered, and they illustrate the types of light 
sources which can be modeled. Ambient light source. Ambient light is non-directional and ambient light 
shaders do not use either an illuminate or a solar statement. Note that ambient light can still vary 
as a function of position. Point light source. A point light source casts equal amounts of light in all 
directions from a given point. This is the simplest example of the use of an illuminate state- ment. 
Spot light source. This is point light source whose inten- sity is ma,~imum along the direction the light 
is pointed and fails off in other directions. A spotlight also has a circular flap which limits angle 
of the beam. This is art example of a procedurally defined point light source. Shadowed light source. 
This is a point light source whose intensity is modulated by a texture or shadow map. Distant light source. 
An infinite light casts light in only one direction. This is the simplest example of the use of a solar 
statement. Illumination or environment map. This is a omnidirec- tional distant light source whose intensity 
is given by a tex- ture map. 293 O SIGGRAPH '90, Dallas, August 6-10, 1990 ii Phong light source. 
This is a procedurally defined distant light source. Code for the light shaders for each of these types 
of sources is contained in the specification[1 ]. The light distribution from an area source is determined 
conceptually by evaluating a light shader at different points on the geometric primitive defining the 
shape of the source. The results are summed, in effect, convolving the light source distribution function 
with the shape of the source. Since all area light sources are finite, the light source shader attached 
to a primitive must con- tain an illuminate statement. Area light source shaders also have access to 
all the surface properties, just like surface shaders, so it is possible to define lights whose color, 
intensity and even direc- tional dependence varies across the surface. 3.6. Surface Reflectance A surface 
reflectance shader integrates all the incoming light with a procedurally defined bidirectional reflection 
function to compute the color and intensity of light reflected in a particular direction. This integration 
is controlled using an illuminance statment. The arguments to the iltuminance statement define a cone, 
usually the upper hemisphere centered on the surface ele- ment, over which the integration occurs. Inside 
of the block defined by an illuminance statement, two independent read-only variables are defined: the 
incoming color and intensity of light (C1) and the light ray direction (L). It is up to the programmer 
to accumulate the results of the reflectance computations. There is no restriction on the number of illuminance 
statements within a shader, although they cannot be nested. There are built-in func- tions that compute 
the ambient, diffuse, and specular reflection functions, because these are so commonly used. As an example 
of the use of the illuminance statement, the diffuse component of the anisotropic shading model for fur 
pro- posed by Kay and Kajiya[16] would be programmed as color C = 0; illuminance( P, N, Pi/2 ) { L 
= normalize (L) ; C += Kd * Cd * C1 * length(L " T); }  where T is the direction tangent to the fur. 
The length of the cross product of L and T is proportional to the sin of the angle between them, assuming 
they are unit vectors. The arguments to the illuminance statement define the upper hemisphere centered 
at the point being shaded; light coming from other directions is not considered when performing the integral. 
The variable C is used to accumulate the results of the integral. 3.7. Built-In Functions A lot of attention 
was paid to selecting the built-in func- tions in the language. Functions were added so that common shading 
operations were readily available and could be easily composed. Frequently used functions were also built-in, 
so that they could be implemented in the most efficient way possible. In a few cases, functions were 
built-in because their calculations could not be expressed within the shading language; however, this 
was always considered bad and whenever possible features were added to the language to make it more complete. 
Expressing all the functions using the language makes it possible for users to modify them to suit their 
needs. For maximum flexibility many of the built-in functions are polymorphic, that is, they can accept 
arguments with different types and perform the appropriate operations depending on the type of input. 
The most straightforward example is printf which can print any type in the language. More generally, 
polymotphic functions may return a type which also depends on the type of inputs or their values. Polymorphism 
significantly complicates the compiler and the run-time system, so to simplify, the return type of a 
polymorphic function can only be a function of the types of the inputs. These typing rules are built 
into the compiler, and so it is not possible for the user to write polymorphic functions. In some cases, 
the return type depends on the value of an argument and not its type (for example texture access, where 
the return type depends on the texture map being used which is identified by passing in a texture map 
name). This case is handled by requiring an explicit type cast before these types of functions. The remainder 
of this section will describe several of the more unusual functions and their impact on the implementation. 
Taking the derivative of position was discussed in Section 3.4. For generality, another function was 
added to take the deriva- tive of any varying variable with respect to any other varying vari- able. 
These functions turned out to be very useful, but much more difficult to implement than we expected. 
First, the derivative of a procedurally defined variable is not always continuous. For example, when 
a value is computed within a conditional state- ment, neighboring values computed in different branches 
of the if may be quite different. The logical expression controlling the if statement acts as a step 
function between the values computed in the branches of the if, so the derivative becomes infinite at 
the step. Fortunately, these situations tend to be avoided in practice because such shading formula are 
very prone to aliasing and cause artifacts. Second, to form derivatives of an arbitrary expression requires 
information about how it varies in a neighborhood of the point where the derivative is taken. This can 
be done reliably, if the variable is only a function of the properties of the surface, for example, rate 
of change of color as a function of texture coordi- nates. However, if the variable is a function of 
the illumination environment, then the values of its neighbors may be contingent on knowing the illumination 
environment of its neighbors, which may be difficult for certain types of renderers to provide. One difficulty 
with procedural shading models is that they are prone to aliasing. Shading functions will alias if they 
contain frequencies greater than the rate at which the surface is being shaded. Providing the sampling 
rate to the shader allows shading functions to clamp themselves so that no frequencies greater than the 
Nyquist frequency are present[22]. The best example of this is the use of band-limitied noise functions 
for solid texture syn-thesis[18, 25]. The sampling rate is provided by a function which returns the screen 
area covered by a single shading calculation, and also by two global variables, du and dr, which estimate 
the change in the surface parameters between adjacent samples. If the area is 1, the surface element 
being shaded occupies approxi- mately one pixel in the final image. A very interesting area for future 
work is to have the shading language compiler try to automatically band-limit the shading functions so 
that clamping need not be done explicitly. 3.8. Texture Mapping Functions The texture mapping functions 
retum filtered texture values based on user-supplied indices. There are four built-in texture functions: 
* texture returns floats or colors as a function of the surface's texture coordinates. , bump returns 
a point specifying the normal perturbation as a function of the surface's texture coordinates. environment 
returns floats or colors as a function of a direction in space passed as a point.  shadow retums a float 
specifying the percentage of the  surface element in shadow as a function of its position. There is 
no limit, in principle, to the number of texture maps allowed per shader or per scene. The texture indices 
may be the ~ Computer Graphics, Volume 24, Number 4, August 1990 surface parameters or texture coordinates, 
or they may be com- puted with the shading language. This flexibility in defining the mapping to texture 
space allows techniques such as decals[2], reflection maps[11, 20], and two-part texture mapping[4] to 
be programmed in the shading language. 4. Implementation A shader passes through various stages in its 
life cycle. We give an initial definition of the various stages in the shader life cycle, then examine 
each step in more detail. Compilation. Compilation occurs prior to rendering. Files containing shading 
language source statements are pro-cessed by a compiler which generates code for a particular run-time 
interpreter. The compiler is responsible for the inline expansion of user functions and performs several 
implementation-independent optimizations.  Loading. During the specification of the scene to the renderer, 
shaders are placed into the current graphics state or instanced. The first time a shader is instanced, 
the renderer must read in the code and symbol table.  Instancing. The shader's instance variables must 
be bound to the shader, replacing the default values. The "shader" coordinate system is also defined 
when the shader is instanced, and any point parameters passed to the shader must be transformed from 
this coordinate system to the coordinate system being used for calculation.  Binding to a Geometric 
Primitive. Next the shader is bound to a particular geometric primitive. This occurs whenever a geometric 
primitive is created, and since dif- ferent primitives may share a shader this occurs more fre- quently 
than instancing. At this point, the "object" coor-dinate system has been defined and can be bound. The 
sur- face color and opacity are inherited from the current graph- ics state or from the geometric primitive. 
Since these attri- butes can come from either source, the uniform or varying nature of late-binding variables 
is only now determined.  Elaboration. Surface parameters are bound to values in the graphics state, 
and data that may be located in various caches is organized for efficient execution.  Evaluation The 
shader is evaluated at different points on the surface.  Each subsequent stage in the life-cycle is 
usually per- formed many more times than the previous stages. This life cycle strains the implementation 
since it presents a general binding problem. For flexibility, it is desirable to bind as many values 
as late as possible, but for efficiency, it is desirable to optimize later stages in the life cycle. 
Since these optimization steps are them- selves time-consuming, it is desirable for them to occur as 
soon as possible in the life cycle so that they are not repeated. However, the optimizers do the best 
job once all the bindings have been established. Table 1 gives time and invocation counts for these various 
life cycle stages for a typical image (a single frame from the animated short "Luxo Jr."). Stage Invocations 
Time (seconds) Percentage Compile 1 5.6 1.33 Load 12 2.11 .50 Instance 45 3.61 .86 Bind 153 3.96 .94 
Elaborate 9004 0.78 .18 Evaluate 11255 403.08 96.16 Table 1: Shader Life Cycle We now consider these 
steps in more detail. 4.1. Compilation The compiler uses the shader class for determining allowed access 
to the intrinsic state. Only light shaders may set the light color and contain solar and illuminate statements. 
Only surface shaders may contain illuminance statements and only within these statements is access to 
the light color and direction allowed. These constraints are intended to limit the environment for each 
class of shader for performance reasons, and to detect user errors at compile time. Typically the time 
spent compiling a shader is many orders of magnitude less than the time spent actually executing a shader. 
This in turn implies that no compile-time optimizations are prohi- bitively expensive. Two of the more 
unusual optimizations per- formed by the compiler involve expression classification and com- piled function 
inlining. Shading language expressions can be categorized as falling into one of two classes: uniform 
or varying. In principle, uniform expressions need only be evaluated once. The compiler has facili- ties 
for rearranging uniform' expressions in order to execute them separately from the varying expressions 
in the shader body. There are implementation difficulties with this: the compiler has to be careful about 
code motion across loop and conditional boundaries, and the late binding of shader parameters restrict 
the type inferencing that can be done. In these cases, the compiler assumes the expression is varying 
but provides sufficient informa- tion for the run-time system to make the final decision (at a some- 
what reduced level of efficiency). It should be noted in passing that the uniform/varying distinction 
poses a classical time/space tradeoff. If the cost of saving the result of a computation is in some sense 
cheaper than the computation, it makes sense to save the result. There may be implementations where the 
storage requirements for these values are far more expensive (in terms of their size or management) than 
simply performing the computa- tion each time its result is required. The compiler is also responsible 
for the inline insertion of previously compiled shading language functions. The compiler reconstructs 
a parse tree from the compiled function and performs the normal optimizations after inserting the parse 
tree inline. If the function can be evaluated at compile time (that is, if its argu- ments are known 
constants), its result will be substituted for the function call. In general, we attempt to do as much 
optimization at compile-time as is possible, and for those cases where we must defer to the run-time 
system, we attempt to provide it with sufficient information for it to further optimize execution. To 
this end, the "object" file output by the compiler contains an exten- sive symbol table. In fact, there 
is sufficient information in the symbol table to reconstruct the original parse tree. For those shader 
parameters with default values, the symbol table contains a pointer to the block of code to compute this 
value. For each sym- bol referenced by the shader, the symbol contains pointers to the initial and final 
read and write references in the shader code. This is used to determine if a shader requires access to 
a external vari- able, or if the shader changes the variable, to ensure that a local copy is made or 
that related properties (position and normals for instance) are updated consistently. 4,2. Loading The 
run-time system loads shaders in response to shader directives which normally occur when a shader is 
made current. The shader name is mapped into an (operating system dependent) external file name for the 
initial request to read the file containing the shader. In order to minimize the amount of I/O traffic 
the sys- tem maintains a simple shader cache. The (system independent) O SIGGRAPH '90, Dallas, August 
6-10, 1990 shader name is used as the key for subsequent searches. The first time a shader is read, it 
is converted from an external to an inter- nal executable format. This converted shader object is subse- 
quently stored in the shader cache. Future references to this shader will fetch the copy from the cache 
thus avoiding the over- head of file I/O and the external to internal conversion process. 4.3. Instancing 
Associated with a shader directive is a parameter list. It is quite common for modeling systems to generate 
complex objects composed of alternating shaders containing the same parameters. If each shader directive 
results in the creation of a separate instance of the referenced shader, we would end up filling memory 
with many copies of identical shader instances. This problem is solved with the addition of a higher 
level shader instance cache. The shader's parameters are packaged up and inserted in the shader instance 
cache along with a reference to the basic entry in the lower level shader cache. The shader name and 
its parameters are used as a key to index the instance cache. Thus, shader directives that refer to the 
same shader with the same parameters will all share a common instance of that shader. These caches may 
be flushed at the discretion of the renderer, usually at end of frame. 4.4. Binding to a Geometric Primitive 
It is not until we actually bind the shader to a geometric primitive that we can finally determine the 
uniform/varying nature of its parameters. But the values of these variables are not yet available because 
they may be computed as part of the rendering process. Consequently, we package up the number and identity 
of varying parameters along with a reference to the shader instance, and insert this item into a bound 
instance cache. 4.5. Elaboration Eventually a geometric primitive has been reduced to an object for which 
the rendering system wishes to invoke a shader. Any varying parameters have been interpolated over the 
surface of the primitive. At this time, all parameters have been bound to the shader and we are in a 
position to determine their values. We allocate storage for the shader's local and temporary variables 
and finally evaluate its parameters. The parameters of the shader are assigned (in order of decreasing 
precedence) either: * the value associated with the geometric primitive, the value specified in a shader 
directive, or  the default value as specified in the shader. We refer to this as an elaborated shader 
instance and update the bound instance cache entry for the shader to indicate an elaborated  instance 
is available. Subsequent attempts to evaluate the shader will use this elaborated instance. Elabortt*d 
InstJnal Ir~tmnoo Lrmtnco Figure 3. Hierarchy of shader caches. Figure 3 illustrates the various internal 
caches and Table 2 demonstrates the effectiveness of the hierarchical cache scheme for the same Luxo 
Jr. frame described in Table 1. Cache Storage Probes Misses Hit Rate Shader 29.2K 14 12 14% Instance 
t.5K 45 14 68% Bound Instance na na na na Elaborated Instance 21.0K 9004 42 99% Table 2: Shader Cache 
Hit Rates The instance cache size is basically determined by the number of different types of surfaces 
and lights, the elaborated instance cache by the number of geometric primitives. The relatively low hit 
rates for the lower level caches are due to the effectiveness of the higher level caches. We have only 
counted actual probes of each cache. If one counts actual post-probe references (11255) to cached data, 
the importance of the lower level caches is more apparent. There are no vertex arguments in this example, 
so the bound instance cache is bypassed. 4.6. Evaluation The current run-time system implements a virtual 
SIMD array processing architecture. Geometric primitives are diced into surface elements or grids containing 
some number of surface points[8]. One geometric primitive may give rise to many grids. The shading interpreter 
executes shader operators once per grid, each operator performing its calculations over every point in 
the grid. This helps reduce the effect of interpreter overhead by amortizing it over the number of points 
in the grid. Earlier we mentioned that due to the late binding of shader parameters, certain optimizations 
must be left to the run-time sys- tem. Each operator is passed the address, type, and uniform/varying 
nature of its arguments. The individual operators may use this information to optimize their computations. 
For example, if an operator receives uniform arguments and is required to compute a varying result, it 
may perform its operation once, then replicate the result value. Thus, at the very worst, each uniform 
expression is computed at most once per grid. The SIMD nature of the run-time system does complicate 
the handling of loops and conditionals, especially if normal SISD semantics are to be preserved. Nevertheless, 
we felt it was impor- tant to hide the details of the implementation, and so resisted adding language 
constructs to deal with the lower level SIMD machine. 5. Discussion Overall the shading language has 
met most of the goals set out in the introduction. Figure 4 shows one example of the type of flexibility 
possible in the language. This surface shader dents the teapot using a fractal-like procedural displacement 
until the metal breaks. This breakage is modeled by making the surface transparent if the magnitude of 
the dent exceeds a certain value. Note that the shader shown in Figure 4 is quite short, which attests 
to the high-level nature of the language. Most shaders that have been written take much less than a screenful 
of text. The frame from the film knickknack shown in Figure 5 was created using procedural shading for 
everything except the texture mapped text on the pyramid and pool, and the drawing on the surfboard. 
The shading language encourages the development of compact.pro- cedural texture representations. In the 
future, we expect to see a great deal of research in procedural material representations of appearance. 
Catalogs of materials will be available much like catalogs of clip art are available today.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97912</article_id>
		<sort_key>299</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[The rendering architecture of the DN10000VS]]></title>
		<page_from>299</page_from>
		<page_to>307</page_to>
		<doi_number>10.1145/97879.97912</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97912</url>
		<abstract>
			<par><![CDATA[The Appollo DN10000VS treats graphics as an integral part of the system architecture. Graphics requirements influence the entire system design. All floating-point computations for graphics are performed by the CPU(s), while rasterizing is handled by simplified hardware having no microcode. We decided to support alpha buffering, quadratic interpolation, and texture mapping directly in hardware. This partitioning reduces the cost of a high-end workstation, without sacrificing high rendering quality and performance. This paper describes some of the design trade-offs which led to the final system design.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Parallel processors**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14068580</person_id>
				<author_profile_id><![CDATA[81100166914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kirk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Systems Division of Hewlett-Packard, 300 Apollo Drive, Chelmsford, MA and California Institute of Technology, Computer Science 256-80, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P70030</person_id>
				<author_profile_id><![CDATA[81100490984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Douglas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Voorhies]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Systems Division of Hewlett-Packard, 300 Apollo Drive, Chelmsford, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akeley, Kurt, T. Jermoluk, "High-Performance Polygon Rendering," Computer Graphics, Vol. 22, No. 4, August 1988, pp. 239-246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378518</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Apgar, Brian, B. Bersack, A. Mammen, '~ Display System for the Stellar Graphics Supercomputer Model GS1000," Computer Graph&amp;s, Vol. 22, No. 4, August 1988, pp. 255-262.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Apollo Computer, "Series 10000 Technical Reference Library:. Volume 1 - Processors and Instruction Set," Order No. 0011720-A00, Apollo Computer Inc. 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15897</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bishop, Gary, D. Weimer, "Fast Phong Shading," Computer Graphics, Vol. 20, No. 4, July 1986, pp. 103-106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bresenham, Jack, 'Algorithm for Computer Control of a Digital Plotter," IBM Systems Journal 4,1, 1965, pp. 25-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378468</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Deering, Michael, S. Winner, B. Schediwy, C. Duffy, N. Hunt, "The Triangle Processor and Normal Vector Shader. A VLSI System for High Performance Graphics," Computer Graphics, Vol. 22, No. 4, July 1988, pp. 21-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Floyd, R. W., L Steinberg, "An Adaptive Algorithm for Spatial Gray Scale," SID 75, International Symposium of Digital Technical Papers, 1975, 36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74341</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry, J. Poulton, J. Eyles, T. Greer, J. Goldfeather, D. Ellsworth, S. Molnar, G. Turk, B. Tebbs, L Israel, "PixeI-Planes 5: A Heterogeneous Multiprocessor Graphics System Using Processor-Enhanced Memories," Computer Graphics, Vol. 23, No. 3, July 1989, pp. 79-88.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378474</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gharaehorloo, Nader, S. Gupta, E. Hokenek, E Balasubramanian, B. Bogholtz, C. Mathieu, C. Zoulas, "Subnanosecond Pixel Rendering with Million Transistor Chips," Computer Graphics, Vol. 22, No. 4, July 1988, pp. 41-49.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Heekbert, Paul, "Survey of Texture Mapping," 1EEE Computer Graphics and Applications, Vol. 6, No. 11, November, 1986, pp. 56-67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kirk, David, O. Lathrop, D. Voorhies, U. S. Patent Application for, "Quadratic interpolation for Shaded Image Generation," U. S. Serial No. 077,202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617588</ref_obj_id>
				<ref_obj_pid>616013</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lathrop, Olin, '~ceurate Rendering by Subpixel Addressing," IEEE Computer Graphics and Applications, (to appear).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lindgren, Terence, "Principles Guiding Line Generation and their Application to Start and End Rule Selection for Vector Drawing", Private Communications, 1988]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mach, Ernst, "The Analysis of Sensations and the Relation of the Physical to the Psychical," Dover Publications, New York, 1959.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>363368</ref_obj_id>
				<ref_obj_pid>363347</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Myer, T., I. Sutherland, "On the Design of Display Processors," CACM, Vol. 11, No. 6, June 1968, pp. 410--414.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Porter, Thomas, T. Duff, "Compositing Digital Images," Computer Graphics, Vol. 18, No. 3, July, 1984, pp. 253-259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74340</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Potmesil, Michael, E. Hoffert, "The Pixel Machine: A Parallel Image Computer," Computer Graphics, Vol. 23, No. 3, July 1989, pp. 69-78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ratliff, Floyd, "Maeh Bands: Quantitative Studies on Neural Networks in the Retina," Holden-Day, Inc., San Francisco, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74339</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Rhoden, Desi, C. Wilcox, "Hardware Acceleration for Window Systems," Computer Graphics, Vol. 23, No. 3, July 1989, pp. 61--67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger, L Thayer, ''A Fast Shaded-Polygon Renderer," Computer Graphics, Vol. 20, No. 4, August, 1986, pp. 95-101.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37426</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Torborg, John, ''A Parallel Processor Architecture for Graphics Arithmetic Operations," Computer Graphics, Vol. 21, No. 4, July, 1987, pp. 197-204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance, "Pyramidal Parametrics," Computer Graphics, Vol. 17, No. 3, July, 1983, pp. 1-11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617501</ref_obj_id>
				<ref_obj_pid>616006</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Voorhies, Douglas, "Reduced-Complexity Graphics," IEEE Computer Graphics and .Applications, Vol. 9, No. 4, july, 1989, pp. 63-70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378517</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Voorhies, Douglas, D. Kirk, O. Lathrop, "Virtual Graphics," Computer Graphics, Vol. 22, No. 4, August, 1988, pp. 247-253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Rendering Architecture of the DNI0000VS David Kirk1* and Douglas Voorhies* *Apollo Systems Division 
of Hewlett-Packard 300 Apollo Drive Chelmsford, MA 01824 tCalifornia Institute of Technology Computer 
Science 256-80 Pasadena, CA 91125 ABSTRACT The Apollo DN10000VS treats graphics as an integral part 
of the system architecture. Graphics requirements influence the entire system design, All floating-point 
computations for graphics are performed by the CPU(s), while rasterizing is handled by simplified hardware 
having no microeode. We decided to support alpha buffering, quadratic interpolation, and texture mapping 
directly in hardware. This partitioning reduces the cost of a high-end workstation, without sacrificing 
high rendering quality and performance. This paper describes some of the design trade-offs which led 
to the final system design. CR Categories and Subject Descriptors: C.1.2 [Processor Architectures]: Multiprocessors 
- parallel processors; C.1.3 [Processor Architectures]: Other Architecture Styles; 1.3.1 [Computer Graphics]: 
Hardware Architecture - raster display devices; 1.3.2 [Computer Graphics]: Graphics Systems; 1.3.3 [Computer 
Graphics]: Picture/Image Generation; 1.3.7 [Com- puter Graphics]: Three-Dimensional Graphics and Realism 
General Terms: Architecture, Algorithms, Graphics, Interpo- lation, Systems Additional Key Words and 
Phrases: quadratic, shading, alpha buffering, texture mapping, Mach band INTRODUCTION High-performance 
graphics hardware for workstations has been evolving into massive, complex, autonomous, and highly-special- 
ized subsystems. While this focus improves cost/performance ratios, especially those measured by narrow 
rendering perform- ance metrics (e.g., vectors/see, and polygons/sec.), and leaves the CPU free for other 
tasks, the hardware is generally idle while the system executes the applications' non-graphics parts, 
such as modeling, simulation, and database manipulation. Permission to copy without fee all or part of 
this material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. An alternative approach is to invest in the CPU, memory, and 
bus structure, where performance improvements benefit all application activity. System balance, for example 
between modeling and rendering, is shifted from the presence of various hardware options to CPU process 
scheduling. Such a system can dynamically respond to the applications' changing demands from millisecond 
to millisecond. We will describe here a commerciai system architecture which offers high-performance 
graphics while having a minimum of specialized hardware. We will discuss our goals, its rendering features, 
and where we were successful and unsuccessful in minimizing the hardware.  PREVIOUS WORK Several commercial 
architectures, most notably Silicon Graphics [Akeley88] and Hewlett-Paekard [Rhoden89] [Swanson86], incorporated 
straightforward VLSI rendering pipelines. The process of polygon rendering is well understood; each step 
was cast in various mixes of hardware and microcode. Not unexpectedly, the targeted eases enjoy impressive 
ccost/perforrn- anee efficiencies. However, scalability and configurability, which allow a product to 
match and continue matching a user's evolving needs, were sacrificed. Moreover, the burden of microcode 
development and maintenance is significant, and often coding complexity is not faced until after the 
hardware is unalterable. The trend to add increasing amounts of hardware to improve polygon performance 
has continued [Deering88][Potmesi189]. Again, we see these systems excelling at the specialized rendering 
for which they were d~igned, and again they are difficult to modify for new rendering algorithms. Some 
advanced research implementations go even further [Gharachorloo88][Fuehs89], but currently these designs 
are too costly for a balanced workstation product. There has been work towards solving the scalability 
problem. A good example is Torborg's design, which configures 1 to 8 floating point processors to handle 
transformation, clipping, and lighting [Torborg87]. Unfortunately, the unit of work is coarse, so the 
system balance can be altered only by increasing the graphics power in large, fixed steps. While Torborg's 
dedicated graphics hardware potentially provides veryhigh graphics performance, it does so at a commensurately 
high cost. A step in the integration direction was taken in the Stellar GS1000, which leverages the CPU 
for part of the graphics setup [Apgar88]. However, there is still considerable graphics &#38;#169;1990 
ACM-0-89791-344-2/90/008/0299 $00.75 299  @ SIGGRAPH '90, Dallas, August 6-10, 1990 hardware, including 
a microeoded VLSI setup processor and a massive microcoded drawing engine. The Intel i860 also has an 
integrated architecture, since it appends some rasterizing instructions to a RISC instruction set. But 
graphics needs do not appear to have influenced the overall CPLI design. It provides only moderate graphics 
performance, while placing heavy demands on its memory subsystem. Brute force graphics hardware has been 
widely explored and commercially exploited, but little work has been focused on the gains possible through 
finesse and integration. Clearly, applying graphics techniques to solve real-world problems involves 
far more than just ultra-high polygon rendering rates. We wanted to explore the integration of a broad 
range of graphics functionality into the system as a whole. GOALS Our first goal was a balanced system, 
in which most of the hardware was usable most of the time. This is an elusive goal. The extreme variability 
in the system workload of a high-end interactive workstation led us away from devoting hardware to specialized 
tasks and toward techniques which improve system versatility and agility. Although our performance goals 
were aggressive and unyielding, we explicitly minimized the graphics hardware. We chose to try to modify 
the system as a whole to be more graphics-capable. Fortunately, the DN10000's PRISM'M instruction set 
was being designed simultaneously. We were able to influence its evolution, greatly improving the performance 
of our transform and lighting pipeline. Also, this software was reeoded to run on multiple CPUs in parallel. 
This work allowed us to replace the traditional micro-programmable graphics floating-point engine with 
powerful CPUs. Nonetheless, the unforgiving rasterizing performance require- ments demanded some dedicated 
hardware. This is a critical point. Myer and Sutherland [Myer68] forcefully argue against specialized 
hardware and for beefing up the main system to handle the job. We believe both extremes should be avoided. 
For example, device controllers, modems, and video back-ends all off-load the main CPU effectively and 
without loss of generality. But there is a risk in casting too much functionality in hardware. The fast-changing 
marketplace punishes the profligate imple- mentation of questionable features in hardware as newer techniques 
quickly supercede older ones. Moreover, as object procedures replace display lists, general-purpose CPUs 
will become more critical to rendering. Together these argue for a model where very fast general-purpose 
CPUs are central, and for reexamining the graphics pipeline's hardware/software bound- ary. We chose 
to push that boundary quite low to keep the graphics hardware as simple and inexpensive as possible. 
For example, we were able to eliminate the need for it to have microcode. This simplification mandated 
careful changes above the boundary to maintain performance.  CPU MODIFICATIONS We worked with the instruction 
set and CPU designers to bolster our performance. For better or worse, we targeted coordinate transformations 
as the "typical" application to be optimized to exhaustion. Most instruction set enhancements which improve 
the transformation loop positively affect matrix and vector operations as well. We completely examined 
the operations for the perspective transformation, dipping, and drawing of 3-D vectors. An in-depth attack 
on this one algorithm proved very effective in pushing our performance beyond our 1 million (connected, 
10-pixel, 3-D, transformed) vectors per second rendering target. The CPU cycle time was 55 ns. This translates 
to 19 or fewer CPU eydes available per vector. For each vector, we must read the next model space point, 
perform the 4x3 matrix multiplica- tion, cheek the clip limits, perform perspective divisions, and send 
the drawing command to the hardware. This results in the following 59 basic operations: Data fetch: 3 
loads 4x3 transform: 12 loads 9 multiplies 9 adds Perspective: 1 load I divide 2 multiplies Cli~check: 
6 loads 6 compares 6 branches Draw command: 2 fp-int converts 1 mask-merge 1 store To perform these 
59 operations in 19 cycles requires both innovative instructions and instruction-level parallelism. To 
meet these as well as other needs, the PRISM" CPU evolved into a super-scalar RISC architecture [Apollo88]. 
The instruc- tion set permits parallel dispatch of two instructions simultane- ously: one for the integer 
processor (IP) and one for the floating point processor (FP). Furthermore, the pipelined FP can initiate 
both an ALU and a multiplier operation in each cycle. The combination of parallel integer and floating 
point dispatch and 5-operand floating point opcodes allows the completion of 3 operations every cycle. 
One quickly notices that operating at these rates, the FP would be starved for data. For this reason, 
the IP was modified to directly access the floating point register file. By using a 7-port FP register 
file, the IP can decode and execute floating-point loads or stores (64-bits/cycle) while the FP is executing 
a 5-operand double operation. Although this does not provide fresh data at the maximum FP consumption 
rate, there is no starvation if more than one operation is performed on the data. Certainly this is the 
case in coordinate transforms and other matrix operations. Additional buffering between memory and FP 
operations is provided by increasing the number of FP single-precision registers to 64. Consequently 
the compilers can be far more effective at loop unrolling and software pipelining. Memory and bus bandwidth 
were further increased by using a larger 64-byte FP cache-fill line size. The clip check comparisons 
and associated branch conditions are operations that do not commonly occur in applications other than 
graphics. In a typical CPU with compare and test operations, 3-D vector clip checks require 12 comparisons 
in a hierarchy of test and jump operations. The PRISM" architecture includes a clip condition code register, 
holding the most recent 12 comparison results as two6-bit fields representing the 3-D clip volume comparisons 
for two endpoints. Branch predicates are provided for trivial accept and trivial reject. For iiiii ~ 
I connected vectors, these condition codes and branch predicates reduce the clip test to six FP compares 
and one branch for each polyline segment trivially accepted. Enlarging the FP register file to contain 
32 double precision values or 64 single precision values reduces the latency of the transform and dip 
loop and reduces the number of instructions per iteration. The need to reload the transform matrix, view 
distance for perspective, and clipping boundaries on subsequent loop traversals was eliminated. Taken 
together, these changes reduce the instruction count to 18 cycles as follows: TotalCycles IP FP-ALU FP-MPY 
Data fetch: 3 loads 3 4x3 transform: 9 multiplies, 9 adds 9 9 Perspective: 1 divide 7 2 multiplies 2 
Clip-check: 6 compares, I branch 1 6 Draw command: 2 ffp-int, I merge, i store 2 2 With these improvements, 
the multiplier is busy for 18 cycles, the ALU is busy for 17 cycles, and the IP is busy for 6 cycles, 
so the multiplier limits the transform rate. Unfortunately, although the cycle count is 18, the operations 
are sequential and the associated latencies (3 cycles for multiply/add, 7 cycles for divide) prevent 
processing of a single vertex in 18 cycles. After a single loop is unrolled to calculate 2 points at 
once and packed as tightly as possible, however, the resulting code does execute at 18 cycles per vertex. 
Transform and clip was an effective focus for influencing the architecture and implementation, because 
it is simple and readily analyzed. Nonetheless, it is a narrow goal, and not the only operation which 
must be optimized. Shaded polygon rendering is the obvious next graphics algorithm to examine, but its 
outer loop is over 30 times as large, making it more difficult to analyze. We surveyed it at a high level, 
to see if it contains operations that are missing from the transform loop. We found it to be a fairly 
typical floating point mix. Consequently, the main impact of examining polygon rendering was not specific 
floating point performance or instruction set modifications but the drive for multiprocessing. Main System 
Bus iJ~.,....L ._.1,_.. I I I I  Icpul lcpul IcPullcpull Main IIRa,terl,i.gl ' " " " 'lMemorHI Engine 
I 1700MBI I ...... IBM PC/AT'Bus apter , , VMEBus  I Adapter I Lp tp "'2 L_] --FDDI / / '~JISdStriped 
_ / / P-.I.IF..--.! Disks Apollo Token Ringl/ ~ ~ 6GB Ethernet~--.-I IBM Token RingJ Figure 1. Software 
Architecture for Multiprocessing In order to render shaded 3-D polygon images, the CPU must perform coordinate 
transformations, dipping, lighting calcula- tions, and differential setup for interpolation of color 
and depth information. One DN10000 CPU can do this at 32K triangles/ see. (for one light source, perspective, 
unconnected triangles), far short of the 108K 24-bit RGB Z-buffered 100.-pixel triangle/see. hardware 
rasterizing rate. To balance the hardware and software, and to make performance scalable, we need to 
exploit multiple CPUs, as shown in Figure 1. One might think that an effective way to harness multiple 
CPUs for a rendering pipeline is to emulate a hardware pipeline in software. While this is a direct approach, 
it has some straightforward drawbacks. In a software graphics pipeline, the data would flow from the 
display list through each of the processors in turn and then to the drawing engine hardware. This means 
that the data, in various forms, would cross the bus 8 times on a 4 processor system, passing in and 
out of the caches of each of the processors. This is a waste of bus resources, and would swamp the DN10000's 
150 Mbyte/sec bus. Finally, such a pipeline runs at the rate of its slowest stage, and rendering does 
not readily split into equal-load pipeline stages, especially if the number of stages may vary from one 
to four CPUs. We chose a different and more universal approach: each CPU does all the computing associated 
with a unit of work (e.g., a triangle). The CPUs stagger their activity so that access to each critical 
resource never overlaps. Simple round-robin spin locks enforce synchronization. Round-robin synchronization 
has very low overhead and works well when the tasks require equal time. The tasks naturally delay each 
other in a sequential rhythm; each lock is freed by the previous requestor just before being tested by 
the next. When the tasks are unequal, some spinning on locks occurs. Another important feature of the 
round-robin approach is that primitives are rendered in display list order, guaranteeing that a multi- 
processor-rendered image is identical to the single-processor image at object intersections. Two interlocks 
are used for graphics: one protecting the "next drawing primitive" fetch pointer and one protecting the 
drawing hardware itself. Since these resources are used at the beginning and the end of each processing 
loop respectively, they could apparently be merged into a single critical region. Separating them proves 
worthwhile, however, since they have different exception conditions. All four processes must have access 
rights to the graphics hardware in rapid sequence. Since access is controlled by virtual memory mapping 
of the drawing engine input FIFO [Voorhies88], we must bypass this normally exclusive mechanism and map 
access into the address space of all four processes concurrently. The multiprocessing is symmetrical 
for normal drawing. Non-drawing tasks, including attribute update and instancing, are handled by a single 
processor. This asymmetry arises from the need to broadcast the results of such tasks to the other processors. 
For this approach to multiprocessing to be successful, access to critical resources for N CPUs must be 
concentrated in 1/N th (chronological) of the code. For example, the basic fetch, transform, clip-test, 
light, and hardware setup loop takes about 600 CPU cycles. Updating the pointer to the next triangle 
only O SIGGRAPH '90, Dallas, August 6-10, 1990 takes about 40 cycles, and the 25 stores to the drawing 
hardware are scattered among 50 more cycles. But adding overhead from bus contention, interprocessor 
communication locks, and cache coherency makes for a very tight fit. Because of these effects, the multiproeessor 
speedup is slightly less than linear, especially with four processors. An image which averages 32K triangles/see, 
on one CPU averages 98K on four CPUs. Taken together, enhancing the floating point CPU performance and 
structuring the setup task to span multiple processors allow our general purpose CPUs to handle the rendering 
process up to pixel drawing. Since ourpcrformance goals required pixels tob¢ drawn faster than the CPU 
instruction rate, dedicated drawing hardware is necessary. Our success was mixed in keeping that hardware 
simple, due to our desire to add advanced rendering features. Rectangle, Vector, Window and Clip and 
Trapezoid Line Pattern traversal DIV 6 MOD 6; StaggerPROM Bank 0-5 Cycle Control GRAPHICS HARDWARE Address 
Synthesis We found it straightforward to keep the control logic and address synthesis logic simple, but 
our desire for high.quality rendering forced us to make the color synthesis data path highly parallel 
and complex. Scc Figure 2. We chose the simple control logic approach of generating one pixcl at a time 
[Voorhies89]. For address synthesis we chose scanline-aligned trapezoids as the fundamental hardware 
area primitive. The samc hardwarc easily handles rectangles and vectors. Trapezoids are an effective 
primitive for composing polygons, yet do not require much hardware to traverse. A screen-aligned trapezoid 
can b¢ traversed using only two vector generators, plus a horizontal traversal counter and a scanlinc 
counter, as in Figure 3. Main System Bus Window P_llrt (150 Mbytes/sec) Bus Interface I FIFO control 
Texture map address filter State Swap I 2Kx40 FIFO and State RAM Internal Data Bus Plane ConfigMux 
[ I Plane ConfigMux PraneConfigMux I Red Final ECL Mux, Video Timing Green Blue Figure 2. 0 0 0 O0 0 
0 O0 0 0 O0 Pixels are traversed clown the leading edge oo,~~o,,.and then horizontally to the trailing 
edge o , 0 0 0 O0 0 0 O0 Figure 3. Sub-pixel Vertex Positioning Faster CPUs allow delaying the conversion 
from floating point space to fixed point space, aiding precision. Bresenham vector and polygon edge-walking 
algorithms [Bresenham65] initialized using integer vertexes do not solve the crucially important consistency 
problem of double-hitting or missing pixels along the shared boundary of abutting triangles [Lathrop90], 
and cause visually distressing temporal aliasing in animated vectors. We chose to initialize these algorithms 
using floating-point arithme- tic, effectively positioning vertexes between pixels. For consistency between 
collinear vectors and edges, we derive the two Bresenham increments from the floating point slope alone, 
with final precision equivalent to the ratio of two 16-bit integers. We normalize all Bresenham constants 
values to preserve precision in the integer hardware. As all Bresenham vector generators are founded 
upon DIV and MOD arithmetic, setting the two hardware increment registers is a simple matter. However, 
setting the initial error term is not as straightforvrard, and choosing the correct starting pixel is 
problematic Three principles guided our thinking: Fidelity Rule: Collinear line segments which overlap 
.select the same pixels (within that overlap). Note that pixel selection being independent of traversal 
direction is an instance of the Fidelity Rule. Connected Rule: Start and end pixels of consecutive vectors, 
or shared polygon vertex pixels, are identical or adjaccent. So what is connected in floating point space 
remains visually connected in screen space. Extent Rule: When chosen pixels are projected onto either 
axis, all lie within the projection of the true line segment. Unfortunately, it is impossible to satisfy 
all three rules simultaneously, or even to choose the same rules for vectors and triangle edges. For 
polygons, we satisfy the Connected rule only in the Y dimension. For vectors, on the other hand, we were 
unwilling to sacrifice the Connected Rule, lest we have unsightly gaps. Instead, we give up the Extent 
Rule, as necessary, to connect polyline segments. Once we have identified the first pixel, we are free 
to calculate the initial data values for that pixel center, such as color/Z/alpha for triangles or the 
initial error term for vectors. We note in passing that our solution for vectors is appropriate for anti-aliased 
vectors. It largely solves the problems of abutting triangles and quivering or ratchety vector motion, 
producing more aesthetical- ly pleasing results. The complexity of this method lies in the floating point 
software initialization; the hardware is only a common 16-bit integer Bresenham vector and edge walker. 
COLOR/Z/ALPHA SYNTHESIS FEATURES We were less successful in minimizing the hardware to synthesize data 
values. The decision to synthesize one pixel at a time, coupled with our performance goals, forced a 
pixel drawing rate of 27.5 us. To complete pixels at this rate required parallelism. Computer Graphics, 
Volume 24, Number 4, August 1990 The difficulty was compounded by each rendering feature needing its 
own idiosyncratic hardware. Color Synthesis Most 3-D rendering employs linear interpolation of color 
and Z values across an area. Our linear interpolation uses a 28-bit data path. For colors and alpha values, 
the 2.8 bits are divided into 1 clamping hit, 8 color bits, and 19 color fraction bits. A full-screen 
trapezoid requires only 12 fraction bits to remain accurate (within .5) during linear interpolation. 
The 28-bit width was chosen to support 16-bit Z buffering and quadratic interpolation. Of course, this 
precision is only of value when the color and depth information are calculated accurately for the initial 
pixel center. A procedure for this is presented in [Lathrop9O]. Pixei addresses and data, although generated 
one-at-a-time, are pipelined. Trapezoid traversai requires three different color increments, one for 
horizontal and two for the Bresenham edge-walking. For linear interpolation, we keep only two color derivative 
registers, since the edge increments differ by exactly a horizontal increment. Since all derivative and 
initial value calculation is done in software, the hardware need handle only the interpolation itself. 
Z Synthesis For Z buffering, Z values of 16, 24, and 32 bits can be kept in the frame buffer. The 28-bit 
interpolator provides 16-bit Z values with 12 fraction bits. By duplicating the computation in two chips, 
one per Z byte, no carries need propagate between them. 24 and 32-bit Z-buffering use 44-bit arithmetic; 
propagating carries make them slightly slower. Ouadratio Interpolation Originally we implemented quadratic 
interpolation to reduce the perceived Maeh bands at polygon boundaries which are caused by discontinuous 
color derivatives [Math59]. For a more current and detailed discussion, as well as reprints of English 
transla- tions, see [Ratliff65]. We expected quadratic to come quite a bit closer than linear to preventing 
this problem. We saw it as between Gouraud and true Phong shading, equivalent in computational complexity 
to "Fast Phong" shading [Bishop86]. Indeed, by combining quadratic interpolation with an exponenti- ation 
table as a texture map, we can directly implement Bishop's "Fast Phong" algorithm. Quadratic hardware 
is also useful in accelerating the product of two linear polygon functions. Examples include depth-cued 
shading (as in the PHIGS model)where a linear shading intensity is multiplied by a linear depth function, 
or variable transparency, where the linear shading intensity is multiplied by a linear transparen~ function. 
This approach suoeeeds because the linear functions are combined as part of the setup done with high 
precision in the CPU. Additionally, initial experiments suggested second-order inter- polation would 
reduce highlight aliasing compared to linear interpolation. Figure 4 shows a curved surface rendered 
with no color interpolation, linear color interpolation, and quadratic interpolation. Note with quadratic 
interpolation the boundaries of the highlights are curved. Quadratic interpolation is set up by fitting 
a second-order surface to six points: a triangle's vertexes and side midpoints. Six lighting calculations 
are performed, and the simultaneous equations are solved to give the color derivatives. The hardware 
then   VLSI System for High Performance Graphics," Computer Graphics, Vol. 22, No. 4, July 1988, pp. 
21-30. Floyd, R. W., L Steinberg, '~n Adaptive Algorithm for Spatial Gray Scale," SID 75, International 
Symposium of Digital Technical Papers, 1975, 36. Fuehs, Henry, J. Poulton, J. Eyles, T. Greer, J. Goldfeather, 
D. Ellsworth, S. Molnar, G. Turk, B. Tebbs, L Israel, "PixeI-Planes 5: A Heterogeneous Multiproeessor 
Graph- ics System Using Processor-Enhanced Memories," Com-puter Graphics, Vol. 23, No. 3, July 1989, 
pp. 79-88. Gharaehorloo, Nader, S. Gupta, E. Hokenek, E Balasubramanian, B. Bogholtz, C. Mathieu, C. 
Zoulas, "Subnanosecond Pixei Rendering with Million Transistor Chips," Computer Graphics, Vol. 22, No. 
4, July 1988, pp. 41-49. Heekbert, Paul, "Survey of Texture Mapping," IEEE Computer Graphics and Applications, 
Vol. 6, No. 11, November, 1986, pp. 56-67. Kirk, David, O. Lathrop, D. Voorhies, U. S. Patent Application 
for, "Quadratic Interpolation for Shaded Image Genera- tion," U. S. Serial No. 077,202. Lathrop, Olin, 
'Accurate Rendering by Subpixel Addressing," IEEE Computer Graphics and Applications, (to appear). Lindgren, 
Terence, "Principles Guiding Line Generation and their Application to Start and End Rule Selection for 
Vector Drawing", Private Communications, 1988 Mach, Ernst, "The Analysis of Sensations and the Relation 
of the Physical to the Psychical," Dover Publications, New York, 1959. Computer Graphics, Volume 24, 
Number 4, August 1990 Myer, T., I. Sutherland, "On the Design of Display Processors," CACM, Vol. 11, 
No. 6, June 1968, pp. 410.-414. Porter, Thomas, T. Duff, "Compositing Digital Images," Com-puter Graphics, 
Vol. 18, No. 3, July, 1984, pp. 253-259. Potmesil, Michael, E. Hoffert, "The Pixel Machine: A Parallel 
Image Computer," Computer Graphics, Vol. 23, No. 3, July 1989, pp. 69-78. Ratliff, Floyd, "Maeh Bands: 
Quantitative Studies on Neural Networks in the Retina," Holden-Day, Inc., San Francisco, 1965. Rhoden, 
Desi, C. Wilcox, "Hardware Acceleration for Window Systems," Computer Graphics, Vol. 23, No. 3, July 
1989, pp. 61.-67. Swanson, Roger, L Thayer, '~A Fast Shaded-Polygon Renderer," Computer Graphics, Vol. 
20, No. 4, August, 1986, pp. 95-101. Torborg, John, '~A Parallel Processor Architecture for Graphics 
Arithmetic Operations," Computer Graphics, Vol. 21, No. 4, July, 1987, pp. 197-204. Williams, Lance, 
"Pyramidal Parametrics," Computer Graphics, Vol. 17, No. 3, July, 1983, pp. 1-11. Voorhies, Douglas, 
"Reduced-Complexity Graphics," IEEE Computer Graphics and Applications, Vol. 9, No. 4, July, 1989, pp. 
63-70. Voorhies, Douglas, D. Kirk, O. Lathrop, "Virtual Graphics," Computer Graphics, Vol. 22, No. 4, 
August, 1988, pp. 247-253.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97913</article_id>
		<sort_key>309</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[The accumulation buffer: hardware support for high-quality rendering]]></title>
		<page_from>309</page_from>
		<page_to>318</page_to>
		<doi_number>10.1145/97879.97913</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97913</url>
		<abstract>
			<par><![CDATA[This paper describes a system architecture that supports realtime generation of complex images, efficient generation of extremely high-quality images, and a smooth trade-off between the two.Based on the paradigm of integration, the architecture extends a state-of-the-art rendering system with an additional high-precision image buffer. This additional buffer, called the Accumulation Buffer, is used to integrate images that are rendered into the framebuffer. While originally conceived as a solution to the problem of aliasing, the Accumulation Buffer provides a general solution to the problems of motion blur and depth-of-field as well.Because the architecture is a direct extension of current workstation rendering technology, we begin by discussing the performance and quality characteristics of that technology. The problem of spatial aliasing is then discussed, and the Accumulation Buffer is shown to be a desirable solution. Finally the generality of the Accumulation Buffer is explored, concentrating on its application to the problems of motion blur, depth-of-field, and soft shadows.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P221441</person_id>
				<author_profile_id><![CDATA[81100466522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haeberli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39048699</person_id>
				<author_profile_id><![CDATA[81100563035]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akeley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{Akeley 88} Kurt Akeley, and Tom Jermoluk, "High- Performance Polygon Rendering", Computer Graphics, 1988.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378518</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{Apgar 88} Brian Apgar, et al., "A Display System for the Stellar Graphics Supercomputer Model GS 1000", Computer Graphics, 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Brotman 84} Lynne Shapiro Brotman and Norman I. Badler, "Generating Soft Shadows with a Depth Buffer Algorithm", IEEE CG+A October, 1984.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{Carpenter 84} Loren Carpenter, "The A-buffer, an Antialiased Hidden Surface Method" Computer Graphics, 1984.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{Cook 84} Robert L. Cook et al., "Distributed Ray Tracing", Computer Graphics, 1984.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{Cook 86} Robert L. Cook, "Stochastic Sampling in Computer Graphics", ACM Transactions on Graphics, January, 1986]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378468</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{Deering 88} Michael Deering, et al., "The Triangle Processor and Normal Vector Shader: A VLSI System for High Performance Graphics", Computer Graphics, 1988.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{Dippe 85} Mark A. Z. Dippe' and Erlin Henry World, "Antialiasing Through Stochastic Sampling", Computer Graphics, 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{E&amp;S 87} Evans and Sutherland, PS 390 Marke'~ing Brochure, 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{Fuchs 85} Henry Fuchs, et al., "Fast Spheres, Shadows, Texture, Transparencies, and Image Enhancements in Pixel-Planes", Computer Graphics, 1985.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15898</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Goldfeather 86} Jack Goldfeather, et al., "Fast Constructive-Solid Geometry Display in the Pixel-Powers Graphics System", Computer Graphics, 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15921</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{Heckbert 86} Paul S. Heckbert,'"Filtering by Repeated Integration", Computer Graphics, 1986.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Kajiya 85}, James T. Kajiya, "Anisotropic Reflection Models", Computer Graphics, 1985.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Kajiya 86} James T. Kajiya, "The Rendering Equation" Computer Graphics, 1986.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617499</ref_obj_id>
				<ref_obj_pid>616006</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{Mammen 89} Abraham Mammen, "Transparency and Antialiasing Algorithms Implemented with the Virtual Pixel Maps Technique", IEEE CG+A, July 1989.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325188</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{Max 85} Max, Nelson L., and Douglas M. Lerner, "A Two-and-a-Half-D Motion Blur Algorithm", Computer Graphics, 1985.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357300</ref_obj_id>
				<ref_obj_pid>357299</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{Potmesil 82} Potmesil, Michael, and Indranil Chakravarty, "Synthetic Image Generation with a Lens and Aperture Camera Model", ACM Transactions on Graphics, April 1982.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801169</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{Potmesil 83} Potmesil, Michael and lndranil Chakravarty, "Modeling Motion Blur in Computer Generated Images", Computer Graphics, 1983.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74340</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{Potmesil 89} Michael Potmesil, and Eric M. Hoffert, "The Pixel Machine: A Parallel Image Computer", Computer Graphics, 1989.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37435</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{Reeves 87} William T. Reeves, et al., "Rendering Anti- Aliased Shadows with Depth Maps", Computer Graphics, 1987.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[{SGI 85} Silicon Graphics, "Silicon Graphics 3000 Technical Report", 1985.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[{Star 89} Star Technologies, "Graphicon 2000 Technical Overview", 1989.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[{Swanson 86} Roger W. Swanson, and Larry J. Thayer, "A Fast Shaded-Polygon Renderer", Computer Graphics, 1986.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Accumulation Buffer: Hardware Support for High-Quality Rendering Paul Haeberli and Kurt Akeley 
Silicon Graphics Computer Systems ABSTRACT This paper describes a system architecture that supports 
realtime generation of complex images, efficient generation of extremely high-quality images, and a smooth 
trade-off between the two. Based on the paradigm of integration, the architecture extends a state-of-the-art 
rendering system with an additional high-precision image buffer. This additional buffer, called the Accumulation 
Buffer, is used to integrate images that are rendered into the framebuffer. While originally conceived 
as a solution to the problem of aliasing, the Accumulation Buffer provides a general solution to the 
problems of motion blur and depth-of-field as well. Because the architecture is a direct extension of 
current workstation rendering technology, we begin by discussing the performance and quality characteristics 
of that technology. The problem of spatial aliasing is then discussed, and the Accumulation Buffer is 
shown to be a desirable solution. Finally the generality of the Accumulation Buffer is explored, concentrating 
on its application to the problems of motion blur, depth-of-field, and soft shadows. CR Categories and 
Subject Descriptors: 1.3.1 [Computer Graphics]: Hardware Architecture - Raster display devices; 1.3.3 
[ComPuter Graphics]: Picture/Image Generation -display algorithms; 1.3.7 [Computer Graphics]: Three-Dimensional 
Graphics and Realism - Color, shading, shadowing and texture. Additional Key Words and Phrases: Accumulation 
buffer, antialiasing, motion blur, depth of field, soft shadows, stochastic sampling. Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. 1. Introduction Traditional 
3D graphics workstations include simplistic scan conversion hardware that samples points, lines, and 
polygons with a single infinitely small sample per pixel. As a result, the renderings of these primitives 
show aliasing artifacts. While increasing monitor pixel density has reduced the effects of aliasing, 
motion, the result of increased workstation performance, has increased them. The problem of aliasing 
remains significant in workstation rendering architectures. Contemporary workstations have attempted 
to solve the problem of aliasing using a variety of architectures. Several vendors offer machines that 
compute proper pixel coverage for points and lines. An early example is the raster-based Evans and Sutherland 
PS- 390 [E&#38;S 87], whose design goal was to duplicate the point and line quality of its calligraphic 
predecessors. A simpler and less effective line drawing algorithm is implemented by the Silicon Graphics 
GT system [Akeley 88]. This solution offers a great improvement over aliased lines, but still displays 
slope and endpoint related anomalies. Both these point and line solutions, and all others known to the 
authors, rely on the following two observations: 1. Pixel coverages are relatively easy to compute, because 
the screen geometry of the scan converted primitive is regular and predictable. 2. The quality of intersections 
is relatively less important than the quality of background-abutting edges, both because background-abutting 
edges predominate, and because intersections are typically between unrelated points or lines.  Neither 
of these assumptions is correct for polygons. Because vertexes and narrow areas are neither regular nor 
predictable, it is difficult to compute correct pixel coverage during polygon scan conversion. Further, 
polygons frequently share edges with related polygons, and intersect unrelated polygons. Still, there 
are some examples of workstation-class machines that attempt these calculations. The Pixel Machine [Potmesil 
89] takes the brute- force approach of oversampling and convolution with an arbitrary filter. While effective, 
this approach does not map nicely onto conventional scan-conversion hardware (the Pixel Machine scan 
conversion system is an array of general purpose processors). The Graphicon 2000 [Star 89] implements 
an approximation of an A- buffer [Carpenter 84], including hardware that computes a 4x4 coverage mask 
for each pixel. This implementation suffers from limited (fixed) resolution and errors at polygon vertexes 
and edges (when the polygon is very thin). @1990 ACM-0-89791-344-2/90/008/0309 $00.75 309 O SIGGRAPH 
'90, Dallas, August 6-10, 1990 We sought a polygon antialiasing solution with the following properties: 
 Compatibility. The solution should leverage the capabil!ties of a contemporary scan conversion system. 
It should be orthogonal to the features already present, including surface generation, blending, texture 
mapping, and interactive constructive solid geometry generation.  High Quality. There should be no limit 
to the quality of the result obtained. Thus, for example, fixed size masks, and algorithms that store 
finite amounts of depth or color data per pixel, could not be used.  Smooth performance~quality tradeoff 
Not only must the quality of the result be allowed to increase without bound, but it also must decrease 
smoothly toward an acceptable minimum. As quality is decreased, performance must increase toward a maximum 
that is competitive with other contemporary architectures.  First we describe the performance and quality 
characteristics of the current generation of workstation graphics systems. Then we describe an architecture 
that extends these characteristics to include polygon antialiasing. Finally we discuss the additional 
system features that result from the generality of our solution. 2. Current Architectures The problem 
of correctly sampling, and thus antialiasing polygons has been solved many times in many ways. Our concern 
here is to solve it in a manner that complements the operation of a contemporary high-performance scan 
conversion system. We must first be familiar with the properties of such a system. 2.1 Polygon Performance 
The most obvious trend in high-performance workstation graphics is toward the capability of rendering 
lots of small polygons per second. Numbers for previous generation machines reached the 100,000 to 150,000 
range [Akeley 88, Apgar 88]. The recently introduced Silicon Graphics 4D VGX raises this number to 750,000 
RGB lighted, Gouraud shaded, z-buffered, connected triangles per second, and to 1,000,000 per second 
when the triangles are fiat shaded. Substantial hardware resources are dedicated toward achieving these 
impressive polygon rates. We would like to leverage this investment when drawing antialiased polygons. 
 2.2 Sampling Quality A second trend is that toward improved sampling quality. Traditional workstation 
scan conversion systems have taken a less than rigorous attitude toward sampling. Shortcuts in arithmetic 
processing result in artifacts such as: 1. Non-subpixel positioning. After transformation, vertex coordinates 
are rounded to the nearest pixel location in an integer screen space. 2. Bresenham sampling. Pixels 
are included in the scan conversion of a polygon based on arithmetic appropriate for a line fill, rather 
than for an area sampling.  3. Sloppy iteration. Insufficient accuracy is maintained during edge iteration. 
Slopes and initial values of parameters are not corrected for the subpixel locations of vertexes, spans 
or scans. Early Silicon Graphics machines [SGI 85] and Hewlett Packard graphics systems [Swanson 86] 
were guilty of all thr~e errors. The Silicon Graphics GT graphics system, first shipped early in 1988, 
addressed issues 2 and 3, but still forced transformed coordinates to the nearest pixel center [Akeley 
88]. More recently shipped machines, including the Silicon Graphics Personal Iris and the Stellar GSI000 
[Apgar 88], correctly address all three concerns. The Pixel-Planes system [Fuchs 85] is an early example 
of an architecture that implements accurate polygon sampling. 2.3 Point Sampling We refer to a scan 
conversion algorithm that rigorously selects pixels for inclusion, and rigorously computes parameter 
values at each pixel, as a Point Sampling algorithm. Such rigor is most easily defined for triangles. 
The requirements are: 1. The projected vertexes of the triangle must not be perturbed during the scan 
conversion proc,Sss. 2. Pixels must be chosen for inclusion in the triangle scan conversion based on 
whether their infinitely small sample point is inside or outside the exact triangle boundary. A fair 
test must be established for pixets whose sample point is exactly on the triangle boundary. 3. Parameter 
values must be assigned to each pixel based on exact calculation at the infinitely small sample point. 
Such exact calculation is easily defined for triangles as the solution of the plane equation specified 
by the parameter values at the triangle's three vertexes.  While Point Sampling can require significantly 
more arithmetic than less rigorous sampling, it has numerous benefits. The Point Sampling pixel inclusion 
property insures that adjacent polygons neither share nor omit any pixels along their common border. 
Thus algorithms that count on the number of times a pixel is drawn, such as transparency and constructive 
solid geometry [Goldfeather 86], operate correctly. Redraws of single-buffered images also are much less 
"noisy", because pixels change color less often. The planar sampling inherent in Point Sampling allows 
polygon intersections to be Z-buffered accurately, resulting in smooth transitions from one polygon to 
the other. Likewise, smooth shaded polygons show no shear artifacts, such as those illustrated at the 
bottom of Figure 1. Finally, as we will see in the following section, the accuracy inherent in Point 
Sampling allows images to be integrated with predictable results. 3. Antialiasing When polygons are sampled 
with only one sample per pixel, aliased images, such as the one illustrated in Figure 2, are created. 
To obtain a properly sampled (antialiased) result, the rendering must take into account the areas of 
all the polygons that contribute to the shading of each pixel, rather than just a single sample point. 
This can be accomplished in one of two fundamentally different ways: 1. Area Sampling. The fraction of 
pixel coverage due to each polygon that intersects the pixel (perhaps multiplied by a filter function) 
is computed, and these fractions are blended to obtain the final pixel shading. 2. Multi-Point Sampling. 
Many point samples are taken in the region of each pixel, and these samples are integrated (again perhaps 
with a weighting function) to obtain the final  pixel shading. 3.1 Area Sampling While the area sampling 
solution has proved useful when antialiasing points and lines, its implementation for the antialiasing 
of polygons has several problems. These include: 1. Pixel coverage by a polygon is not easy to compute. 
Unlike points and lines, polygons can become arbitrarily thin, and have vertexes with arbitrary orientation 
relative to the pixel. Pixel coverage therefore cannot be computed with a simple function such as distance 
from the center of a point (or line).  2. The choice of parameter values to assign to each coverage 
fraction is arbitrary and inaccurate. Because parameters typically vary across the pixel, no single sample 
will yield a correct value. Worse yet, when the fraction-piece does not include the pixel center, a Point 
Sample algorithm has no parameter value to assign. (Any attempt to compute a parameter value outside 
a Point Sampled polygon risks substantial overflow or underflow.) 3. Correctly blending the pieces into 
a final pixel value is difficult as well. If the geometric relationship of the pieces is not known, blending 
will fail either for correlated edges  (adjacent polygons) or for uncorrelated edges (intersecting polygons), 
depending on the blending function chosen. Knowing the geometric relationship requires that some sort 
of multi-sample operation be done, which violates the spirit of this solution. While all of these problems 
can and have been managed well enough for useful area sampling systems to be built, we know of no solution 
that meets our requirements of compatibility, high quality, and smooth performance~quality tradeoffi 
Compatibility is compromised because hardware that is fundamentally designed to do Point Sampling is 
being used to do area sampling, and because the Z-buffer hardware is no longer useable (the pieces must 
be sorted, either prior to rendering or in the framebuffer itself). High quality is compromised for all 
the reasons listed above. Additionally, a smooth tradeoff between performance and quality is unlikely 
as there is no obvious parameter to vary. 3.2 The Accumulation Buffer Solution 2, the integration of 
multiple point samples taken in the region of each pixel, is typically thought to require scan conversion 
and storage of multiple samples per pixel in a single rendering pass. The availability of hardware that 
renders roughly 1,000,000 Point Sampled polygons per second, however, allows an alternative implementation 
to be considered. Specifically, the Point Sampling hardware is used to render multiple images, each with 
the sample point jittered by a specific amount. These images are then integrated to form the final, antialiased 
result. This basic technique for creating antialiased images has been described by others. [Fuchs 85] 
was the first to propose a successive refinement method that uses accumulation to create antialiased 
images by rendering the scene repeatedly with sub- pixel offsets. Also, [Deering 88] proposed that sub-pixet 
offsets could be jittered to further reduce aliasing, while [Mammen 89] described using alpha blending 
hardware to accumulate a series of images. The Accumulation Buffer provides 16 bits to store each red, 
green, blue, and alpha color component, for a total of 64 bits per pixel. The primary operations that 
may be applied to the Accumulation buffer are: 1. Cleat'. The 16-bit components for red, green, blue 
and alpha are set to 0 for each pixel. 2. Add with weight. Each pixel in the drawing buffer is added 
to the Accumulation Buffer after being multiplied by a floating-point weight that may be positive or 
negative. 3. Return with scale. The contents of the Accumulation Buffer are returned to the drawing 
buffer after being scaled by a positive, floating-point constant.  Figure 2. Point sampled polygons. 
 can be obtained. Geometry can be sampled using a Gaussian (or other sample function) in three distinct 
ways. 1. The first technique is to distribute samples with an even density around each pixel center, 
and weight each sample using a Gaussian. 2. Another technique is to distribute samples using a Gaussian 
distribution and weight each sample equally. This implements importance sampling. 3. As an alternative 
we can use convolution. After each image is drawn into the drawing buffer, a 3 by 3 filter kernel is 
calculated based on the subpixel offset used to create the image. The drawn image is convolved by the 
kernel to distribute samples to neighboring pixels. Then this convolved image is added to the Accumulation 
Buffer.  ~ Ib 4~ ~ o q~ e  Q 0 o o O Q ee # Figure 5. illustrates the difference between the box 
and the Gaussian filters. The left part of this figure shows the point samples that contribute to a pixel 
when simple super-sampling (box sampling) is used, while the right part of this figure shows the sample 
contributions if Gaussian sampling is used. To see the effectiveness of this antialiasing solutior/see 
Figure 6. This shows an infinite perspective checker-board sampled with 1, 4, 16, and 64 samples per 
pixel. The top row uses a box filter to sample the geometry, while in the bottom row a Gaussian filter 
is used. 4. Additional Applications The integration capabilities of the Accumulation Buffer allow us 
to handle problems of motion blur, depth of field, and soft shadows as well. Several general solutions 
to these problems have been discussed in the past [Cook 84, Cook 86, Dippe 85]. a °1 i ! ~ Q I I u 
I I Figure 5. Box and Gaussian sampling geometry. Figure 6. Antialiasing quality. The top row was created 
using a box filter while the bottom row shows the effect of using a Gaussian. The images were made with 
1, 4, 16 and 64 samples per pixel.  8. Appendix A The following function is used to specify a simple 
perspective projection in the SGI Graphics Library. window(left, right, bottom,top, nearJar) float left, 
right, bottom, top, near, far; I float Xdelta, Ydelta, Zdelta; float matrix[41141; Xdeita = right - 
left; Ydelta = top - bottom; Zdelta =far near; - matrix[O][O] = (2.0*near)/Xdelta; matrix[O][1] = 0.0; 
matrix[O][2] = 0.0; matrixlO][3] = 0.0; matrix[1][O] = 0.0; matrix[l][1] = ( 2.0*near)/Y delta; matrix[l][2] 
= 0.0; matrix[l][3] = 0.0; matrixl2][O] = (right+left)/Xdelta; matrix[2][1] = (top+bottom)/Ydelta; matrix[2][2] 
= -(far+near)/Zdelta; matrixl2][3] = -1.0; matrix[3][O] = 0.0; matrix[3H1] = 0.0; matrix[3]12] = -(2.0*far*near)/Zdelta; 
matrix13113] = 0.0; ioadmatrix( matrix); } The window command above creates a projection matrix that 
specifies the position and size of the rectangular viewing frustum in the near clipping plane, and the 
location of the far clipping plane. AII objects contained within this volume are projected in perspective 
onto the screen area of the current viewport. Subpixwindow, below, duplicates the functionality of window, 
and includes parameters that specify a subpixel offset in screen x and screen y. This function supports 
subpixel positioning for antialiasing. subpixwindow(left, right, bottom,top, nearJar, pixdx,pixdy) float 
left, right, bottom, top, near, far, pixdx, pixdy; I short vxl, vx2, vyl, vy2; float xwsize, ywsize, 
dx, dy; int xpixels, ypixels; getvie wport( &#38; vx l ,&#38; vx2 ,&#38; v y l ,&#38; vy2 ) ; xpixels 
= vx2.vxl+l; ypixels = vy2-vyl+l; xwsize = right-left; ywsize = top-bottom; dx = -pixdx*xwsize/xpixels; 
dy = -pixdy*ywsize/ypixels; window(Ieft+dx, right+dx, bottom+dy,top+dy, nearJar) ; ) First the pixel 
size of the viewport is determined. Then delta x and delta y values that incorporate the subpixel offset 
are calculated. Finally the projection matrix is set using the window function. 9. Appendix B The genwindow 
function below extends the functionality of subpixwindow to support depth of field. genwindow(left, right, 
bottom,top, nearJar, pixdx,pixdy, lensdx, lensdyJocalplane) float left, right, bottom, top, near, far, 
pixdx, pixdy; float lensdx, lens@, focalplane; I short vxl, vx2, vyl, vy2; float xwsize, ywsize, dx, 
dy; int xpixels, ypixeis; g etvie wport( &#38; v x l ,&#38; vx2 ,&#38; vy l ,&#38; vy2 ) ; xpixels = 
vx2-vxl +l; ypixels = vy2-vyl+l; xwsize = right-left; ywsize = top-bottom; dx = -(pixdx*xwsize/xpixels 
+ lensdx*near/foealplane); dy = -(pixdy*ywsize/ypixels + lensdy*near/focalplane); window(left+dx, right+dx, 
bottom+dy, top+dy, nearJar); translate(-lensdx,-lensdy, O.O); First the pixel size of the viewport is 
determined. Delta x and delta y values that incorporate the subpixel offset are calculated. The projection 
is then sheared to change the viewpoint position based on the lens x and y offsets, and set using the 
window function. Finally the projection is translated to insure that objects . in the focal plane remain 
stationary. O SIGGRAPH '90, Dallas, August 6-10, 1990 10. References 19. [Potmesil 891 Michael Potmesil, 
and Eric M. Hoffert, "The 1. [Akeley 88] Kurt Akeley, and Tom Jermoluk, "High-Performance Polygon Rendering", 
Computer Graphics, 1988. 2. [Apgar 88] Brian Apgar, et al., "A Display System for the Stellar Graphics 
Supercomputer Model GS 1000", Computer Graphics, 1988. 3. [Brotman 84] Lynne Shapiro Brotman and Norman 
I. Badler, "Generating Soft Shadows with a Depth Buffer Algorithm", IEEE CG+A October, 1984. 4. [Carpenter 
84] Loren Carpenter, "The A-buffer, an Antialiased Hidden Surface Method" Computer Graphics, 1984. 5. 
[Cook 84] Robert L. Cook et al,, "Distributed Ray Tracing", Computer Graphics, 1984. 6. [Cook 86] Robert 
L Cook, "Stochastic Sampling in Computer Graphics", ACM Transactions on Graphics, January, 1986 7. [Deering 
88] Michael Deering, et al., "The Triangle Processor and Normal Vector Shader: A VLSI System for High 
Performance Graphics", Computer Graphics, 1988. 8. [Dippe 85] Mark A. Z. Dippe' and Erlin Henry World, 
"Antialiasing Through Stochastic Sampling", Computer Graphics, 1985. 9. [E&#38;S 87] Evans and Sutherland, 
PS 390 Marketing Brochure, 1987. 10. [Fuchs 85] Henry Fuchs, et al., "Fast Spheres, Shadows, Texture, 
Transparencies, and Image Enhancements in Pixel-Planes", Computer Graphics, 1985. 11. [Goldfeather 86] 
Jack Goldfeather, et al., "Fast Constructive-Solid Geometry Display in the Pixel-Powers Graphics System", 
Computer Graphics, 1986. 12. [Heckbert 86] Paul S. Heckbert,'"Filtering by Repeated Integration", Computer 
Graphics, 1986. 13. [Kajiya 85], James T. Kajiya, "Anisotropic Reflection Models", Computer Graphics, 
1985. 14. [Kajiya 86] James T. Kajiya, "The Rendering Equation" Computer Graphics, 1986. 15. [Mammen 
89] Abraham Mammen, "Transparency and Antialiasing Algorithms Implemented with the Virtual Pixel Maps 
Technique", IEEE CG+A, July 1989. 16. [Max 85] Max, Nelson L., and Douglas M. Lerner, "A Two-and-a-Half-D 
Motion Blur Algorithm", Computer Graphics, 1985. 17. [Potmesil 82] Potmesil, Michael, and Indranil Chakravarty, 
"Synthetic Image Generation with a Lens and Aperture Camera Model", ACM Transactions on Graphics, April 
1982.  t8. [Potmesil 83] Potmesil, Michael and lndranil Chakravarty, "Modeling Motion Blur in Computer 
Generated Images", Computer Graphics, 1983. Pixel Machine: A Parallel Image Computer", Computer Graphics, 
1989. 20. [Reeves 87] William T. Reeves, et al., "Rendering Anti- Aliased Shadows with Depth Maps", 
Computer Graphics, 1987. 21. [SGI 85] Silicon Graphics, "Silicon Graphics 3000 Technical Report", 1985. 
 22. [Star 89] Star Technologies, "Graphicon 2000 Technical Overview", 1989. 23. [Swanson 86] Roger 
W. Swanson, and Larry J. Thayer, "A Fast Shaded-Polygon Renderer", Computer Graphics, 1986.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97914</article_id>
		<sort_key>319</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[High speed high quality antialiased vector generation]]></title>
		<page_from>319</page_from>
		<page_to>326</page_to>
		<doi_number>10.1145/97879.97914</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97914</url>
		<abstract>
			<par><![CDATA[A vector generation method is described in which a high quality image rendering scheme is coupled with a high speed scan-conversion algorithm.The rendering scheme consists of two parts. First a prefiltering method is used to antialias the vectors. Second a compositing technique is used to compose the vectors into the frame-buffer.The scan-conversion algorithm presented allows a single vector to be scan-converted by a either by a single processor or a set of processors running in parallel. When using parallel processors, antialiased vectors may be scan-converted and written to a frame store at the same high speed as aliased vectors. The VLSI technology used to implement this algorithm is capable of drawing over two million high quality antialiased vectors per second.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P20240</person_id>
				<author_profile_id><![CDATA[81100591791]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Barkans]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hewlett-Packard Company, Graphics Technology Division, Fort Collins, Colorado]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akeley, Kurt and Jermoluk, Tom. "High-Performance Polygon Rendering", Proceedings of SIGGRAPH '88 (Atlanta, Georgia August 1-5, 1988) In Computer Graphics, 22, 4, 1988,(August 1988)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>737458</ref_obj_id>
				<ref_obj_pid>647874</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barkans, Anthony. "A Virtual Memory System Organization: For Bit-Mapped Graphics Displays", Advances hz Graphics Hardware IV, Eurographics 1989, ed. W. Strasser, Springer-Verlag, Berlin, Heidelberg, New York, Tokyo, 1990]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617463</ref_obj_id>
				<ref_obj_pid>616003</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, Jim. "What We Need Around Here Is More Aliasing", 1EEE CG&amp;,4 9, 1 (Jan 1989)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13038</ref_obj_id>
				<ref_obj_pid>13036</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brady, James. "A Theory of Productivity in the Creative Process", IEEE CG&amp;A 6, 5 (May 1986)]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. "Algorithm For Computer Control Of A Digital Plotter", IBM Systems Journal 4(1) July 1965]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin. "The Aliasing Problem in Computer- Generated Shaded Images", Comm. ACM, 20, 11, November 1977]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378468</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Deering, Michael et al, 'The Triangle Processor and Normal Vector Shader: a VLSI System for High Performance Graphics", Proceedings of SIGGRAPH '88 (Atlanta, Georgia August 1-5, 1988) In Computer Graphics, 22, 4, 1988,(August 1988)]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Dull', Tom. "Compositing 3-D Rendered Images", Proceedings of SIGGRAPH '85 (San Francisco, California July 22-25, 1985) In Computer Graphics, 19, 3, 1985,(July 1985)]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Elmquist, Keils. "An Efficient Anti-Atiased Line Drawing Algorithm Suitable For Hardware Implementation", Unpublished Paper 1987]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Foley, James and Van Dam, Andries. "Fundamentals of Interactive Computer Graphics", Addison-Wesley, 1982]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, Akira and lwata, Kansei. "Jag-Free Images On Raster Displays", IEEE CG&amp;A 3, 9 (Dec 1983)]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30659</ref_obj_id>
				<ref_obj_pid>30657</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Goris, Andy et al, "A Configurable Pixet Cache for Fast Image Generation", IEEE CG&amp;,4 7, 3 (March 1987)]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806783</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gupta, Satlsh and Sprouil, Robert. "Filtering Edges For Gray Scale Displays", Proceedings of SIGGRAPH '81 In Computer Graphics, 15, 3, 1981,(August 1981)]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Newman, William and Sprouil, Robert. "Principles of bltemctive Computer Graphics", 2nd ed. McGraw-Hill, New York, 1979]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Oakley, David. "Dejagging Raster Graphics by Pixel Phasing", SID 86 Digest]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359027</ref_obj_id>
				<ref_obj_pid>359024</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Pitteway, M and Watkinson, D. "Bresenham's Algorithm with Grey Scale", Comm. ACM, 23, 11, November 1980]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>58990</ref_obj_id>
				<ref_obj_pid>58985</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Schneider, Bengt-Olaf. "A Processor for an Object- Oriented Rendering System", Computer Graphics Fol~tm 7 (1988) Nollh-Holland, Amsterdam, New York, Oxford, Tokyo]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger and Thayer, Larry. "A Fast Shaded- Polygon Renderer", Computer Graphics, 20, 4, 1986,(Proc SIGGRAPH)]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Terrell, T. "Introduction to Digital Filtet~'; 2nd ed. John Wiley &amp; Sons, New York, 1988]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Thayer, Larry. "Advanced Workstation Graphics Hardware Features", Proceedings of NCGA, March 1990]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 High Speed High Quality Antialiased Vector Generation 
Anthony C. Barkans Hewlett-Packard Company Graphics Technology Division Fort Collins, Colorado 80525 
 ABSTRACT A vector generation method is described in which a high quality image rendering scheme is 
coupled with a high speed scan-conversion algorithm. The rendering scheme consists of two parts. First 
a pre-filtering method is used to antialias the vectors. Second a compositing technique is used to compose 
the vectors into the frame-buffer. The scan-conversion algorithm presented allows a single vector to 
be scan-converted by a either a single processor or a set of processors running in parallel. When using 
parallel processors, antialiased .vectors may be scan-converted and written to a frame store at the same 
high speed as aliased vectors. The VLSI technology used to implement this algorithm is capable of drawing 
over two million high quality antialiased vectors per second. INTRODUCTION The procedural description 
for drawing a vector is quite simple. However, converting the procedural description into a bit-mapped 
raster image has three problems. The first problem is that scan-conversion processes typically used to 
digitize vectors into the frame store do not limit frequency components of the rendered line, resulting 
in visible aliasing artifacts. The second problem is that placing the rendered vector into an image may 
require blending with existing geometry and that the vectors be arbitraly colors to convey depth information. 
The third problem with scan-converting vectors is one of performance, measured in vectors per second. 
Each pixel in every vector must have its color and address presented to the the frame store. This is 
a time consuming process due to the large number of operations that must take place. In typical implementations, 
enabling antialiasing results in lower performance. All of these problems must be solved to provide maximum 
user productivity in applications with vectors. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. STATIC VECTOR IMAGES The most noticeable visual artifacts are due to 
incorrect filtering applied to the vectors. Shown in Figure 1 are two sets of vectors. The endpoint description 
of the set on the left is a simple horizontal translation of the endpoint set describing the vectors 
on the right. Note that the un-filtered vectors on the right appear jaggy, whereas the filtered set of 
vectors appear smooth along their length. FIGURE 1: Filtered and Un-filtered Vectors Applying filtering 
to vectors does not, by itself, remove all of the visual artifacts. For example, one of the issues in 
applying filtered vectors to real applications is determining if subpixel positioning of endpoints is 
required. The grids of both images in Figure 2 are made of chains of short vectors. While both grids 
use filtered vectors, the image on the left does not use subpixel positioning for the endpoints [1]. 
The image on the right makes use of subpixel addressing for vector endpoints. Notice that while the vectors 
on the left are smooth along their length, they appear crooked because the endpoints are moved from their 
true location. FIGURE 2: Chains of Vectors (With-out and With Subpixel Endpoint Locations) Another 
issue is that real applications require vectors with arbitrary color shading be blended into an image 
that may contain arbitrarily colored geometry. Arbitrarily colored vectors are commonly used to depth 
cue an image. Figure 3 shows an example of arbitrary color shading applied to vectors blended into a 
background. &#38;#169;1990 ACM-0-89791- 344-2/90/008/0319 $00.75 319  O SIGGRAPH '90, Dallas, August 
6-10, 1990 . induced motion artifacts. Therefore, users have begun to demand antialiasing. Unfortunately, 
there is typically a speed penalty for using the antialiasing feature in the systems that support it 
[1,11]. Slowing down the frame rate will reduce the aliasing-induced motion, but this is obviously not 
an optimal solution. Instead, users want the same high frame rate for antialiased images as they get 
for aliased images. Vector generation hardware based on Bresenham and digital differential analyzer (DDA) 
[14] algorithms has been extended to handle antialiased vector generation. One extension is to expand 
the inner loop to generate filtered pixel values for each major axis step [11,9]. Another approach is 
to repeatedly draw the line, offsetting the line by one pixei in the minor axis during each pass. The 
filtering of these vectors is built up during each pass of the line drawing [1]. These solutions result 
in a performance penalty when antialiasing is enabled. Another problem is if one pixel per clock cycle 
is produced, there is no guarantee that the frame buffer will be able to perform the random accesses 
at the required speed. Some frame buffers however, have been arehiteeted to eliminate the frame buffer 
bottleneck [2,12]. As the need for higher performance rendering became apparent, multiple rendering processor 
architectures were developed. However, the algorithms used to produce antialiased vectors have not taken 
full advantage of the multiple processors. In all these multiple rendering processor systems, enabling 
vector antialiasing results in some loss of performance. In one system with an image space subdivision 
[1] using 20 processors, enabling antialiasing for vector drawing results in a 50% degradation in the 
vector draw rate. A system using a pipeline of over 1000 primitive processors [7] has been designed. 
Antialiasing an image with this system requires rendering the frame several times into a 24-bit per color 
accumulator frame buffer [2,7]. Another system using a pipeline of primitive processors, with support 
for antialiasing in the individual processors, has been presented [17]. Each processor produces a list 
of objects that may contribute to the pixel and a filtering stage then produces subpixel coverage maps. 
In this last system the performance impact of antialiasing is proportional to the image complexity, t 
In order to fully utilize modern VLSI technology, a parallel algorithm for vector generation was developed. 
The basis of the algorithm is to efficiently match a hardware implementation to an image space sub-dMsion. 
In concept, the Bresenham type algorithms automatically step along the major axis and check whether the 
minor axis should be adjusted. However, the efficient use of multi-processing hardware requires that 
while each pixel is being processed, the position of the next pixel for each processor be determined. 
This decouples the processors so they can proceed independently. Since this is a more complex algorithm, 
it requires more logic than the Bresenham algorithm. The additional logic required is relatively easy 
and cost efficient to implement given modern VLSI technology. 1. It should be noted that the antialiasing 
techniques used in the two systems with pipelines of primitive processors can be applied to both vectors 
and polygons. DETAILS OF THE HIGH PERFORMANCE VECTOR STEPPING ALGORITHM Before presenting the details 
of the algorithm, the required state information will be described. The state information is received 
from the configuration pins of the processor and the data packets that are sent to describe each individual 
vector. -- This implementation supports one, two or four processors, with an image space sub-division 
along scan lines. The signals SO -$3 tell a processor which of the scan lines, 0 -3 (MOD 4), it owns. 
These signals are directly decoded from the configuration pins of the processor. -- In addition to the 
SO - $3 signals, the three configuration bits are used to produce a set of logical signals. These signals 
are called 4PP, 2_PP and STEP_CONTKOL. The 4PP signal is asserted if the current processor owns one of 
every four scan lines in a four processor configuration. The 2_PP signal is asserted if the processor 
is part of a two processor configuration. STEP_CONTROL is asserted if the current processor is part of 
a one or two processor configuration. -- The signal Y_MAJOR is asserted if the vector being rendered 
is Y-major, and not asserted if the vector is X- major. A Y-major vector is one that has a unique Y value 
for each major axis step of the vector. -- Serpentine mode is a way to specify the output order of the 
pixels. If the pixels along one scan line are output with incrementing x values, then the pixels for 
the adjunct scan line are output by decrementing the x values. This ordering is done to improve locality 
and thus increase throughput into the frame buffer [12]. The SERP signal is set to the value of the sign 
bit of the slope at the start of each vector. The SERP signal is toggled every time the major axis is 
stepped. -- The signal MAJ_DEC is asserted if the major axis should be decremented for each major axis 
step. -- The AA MODE signal is asserted if the vector is being rendered in antialiased mode. If the signal 
is not asserted then an aliased vector will be rendered. -- The MIN_I and MIN0 signals are the least 
significant bits of the minor axis position. These are used by the processor to determine the location 
of its pixels. -- Two signals; MAJ_I and MAJ_0 are the least significant bits of the major axis position. 
These are used by the processor to determine the location of its pixels. Figure 7 is used to show the 
positions where the pixels for a major axis step may be located. The grid is used to represent pixel 
locations on the CRT screen. Note that image space is sub-divided along scan lines, such that in a four 
processor system each processor would be responsible for every fourth scan line. The figure assumes that 
the current major and minor axis values point to the pixel location shown as 1. For an aliased vector 
only Pixel 1 would be rendered at the current major axis step. A Y-major antialiased vector would require 
that the processor responsible for scan line N render the pixels shown as 3, 1 and 5. An X-major antialiased 
vector would require the pfxels shown as 2, 1 and 4 be rendered. In a four processor configuration a 
different processor would render each of the three pixels required for the major axis step of the X-major 
antialiased vector. ~ (SCAN LINE) B N+2 m N+I N 3 2 1 u m N-1 4 N-2 m m FIGURE 7: Location of First 
Rendered Pixel The selection of which pixel to render first is based on the following criteria; -- The 
pixel at location 1 would be the first pixel rendered if; 1. The mode is aliased and the processor owns 
scan line N. 2. If the mode is antialiased and drawing an X-major vector in a two or four processor 
system, where the processor owns scan line N.  -- The pixel at location 2 would be the first pixel rendered 
if the mode is antialiased, the vector is X-major, and the processor owns scan line (N + 1). The serpentine 
bit must also be asserted unless the processor is part of a four processor system in which case the serpentine 
bit may be ignored. -- The pixel at location 4 is similar to the pixel at location 2 except that the 
serpentine bit is not asserted and the processor owns scan line (N -1). -- Pixels at location 3 or 5 
would be rendered first if the mode is antialiased, the vector is Y-major and the processor owns scan 
line N. The choice of drawing 3 or 5 first would depend on the state of the serpentine bit. -- The last 
possible case is that no pixel is rendered for the current major axis step. This would occur if; 1. A 
pixel, on scan line N, that is part of an aliased X-major vector is evaluated by a processor that does 
not own scan line N. 2. A Y-major vector is being rendered and the current major axis location is not 
on a scan line owned by the processor. 3. An antialiased X-major vector is being rendered by a system 
with four processors. The processor of interest owns scan line (N + 2). Note that in a four processor 
system the processor that owns scan line (N + 2) does not own another scan line until line (N-2) or(N 
+ 6).  On examination of the above cases it can be seen that at each major axis step, it must be determined 
if the minor axis value of the first pixel rendered be incremented, decremented, or held. Using the locations 
shown in Figure 7  Computer Graphics, Volume 24, Number 4, August 1990 it is obvious that positions 
2 and 5 are increments along the minor axis, and positions 3 and 4 are decrements along the minor axis. 
To stay at position 1 the minor axis is held. The last case is that there are no pixels for the processor 
to render at the current major axis location. Using the given state information, a set of Boolean expressions 
for increment, decrement and hold can be derived. As an example, the increment signal will be derived. 
From Figure 7 it may be seen that increment only occurs when the pixel to be rendered is either at position 
2 or 5. Earlier it was stated that the first pixel rendered is at position 2 if the mode is antialiased, 
the vector is X-major, the processor owns scan line (N + 1) and either the SERP signal or the 4_PP signal 
is asserted. Note that the logic required to find if the processor owns scan line (N + 1) implies that 
if an X major vector has MIN_i and MIN_0 both zero then scan line (N + 1) is S1. Likewise if MIN_I is 
a zero and MIN_0 is a 1 then the scan line (N + 1) is $2. The condition for going to position 5 in Figure 
7 requires that the mode is antialiased, the vector is Y-major, the serpentine mode signal is asserted 
and the processor owns scan line N. The Boolean expression may be written as follows; Increment = [[ 
[((MIN_I*MIN_0)*S 1) + ((MIN I*MIN_0)*S2) + ((MIN_I*MIN_0)*S3) + ((MIN_I*MIN_0)*S0)] * Y MAJOR*AA_MODE* 
[Serp + 4_PP] ] + [ [ ((MAJ_I*MAJ_0)*S0) + ((MAJ_I*MAJ_0)*SI) + ((MAJ_I* MAJ_0)*SZ) + ((MAJ_I*MAJ_0)*S3)] 
* Y MAJOR*AA_MODE*Serp ] ] The equations for Decrement and Hold can be derived in a similar fashion. 
After finding the first pixel to render, a decision is required to determine if there are other pixels 
to render along the minor axis. If the vector is Y-major and increment or decrement are true, then there 
are more pixels to render along the minor axis. Referring back to Figure 7 this condition implies that 
a pixel at position 3 or 5 was rendered first. In that case, the other two pixels must be rendered along 
the scan line. The other case where there are more pixels along the minor axis is when an X-major vector 
is rendered and the processor is part of a one or two processor system and the first pixel required an 
increment or decrement. A Boolean expression may be written for Minor_Step as follows; Minor Step = [(Increment+Decrement)*Y_MAJOR] 
+ [(Increment + Decrement)* STEP_CONT ROL*~r~_MAJ OR] A piece of pseudo code can now be written that 
describes the algorithm. 323 SIGGRAPH '90, Dallas, August 6-10, 1990 Vector(vector_modes,major_start,major_count,minor_start,minor_slope) 
/* vector_modes: includes bits for; AA_MODE, MAJ~DEC, YMAJOR major_start: a 16 bit integer, location 
of first major axis step major_count: a 16 bit integer, number of steps along major axis minor start: 
a 16.16 format number, location vector crosses first major axis position minor slope: a 2.16 format number, 
(1 sign bit, 1 bit for 45 degrees, and the fractional bits) */ begin Initialize_Register_Set;  While(major_count 
> = 0) { Move_Next_Major to_Current; [* move data from shadow registers to current registers */ If(Increment 
+ Decrement + Hold) { out_first_pixel; } adjust_major; /* adjust shadow registers to next major axis 
location */ major_count = major_count - 1; If(Minor_Step) { /* will only be true for some AA vectors 
*/ If(NOT['Y MAJOR*2 Processors]) { out_second_pixel; } If(Y_MAJOR*(4_PP+2_PP)) { ]* look ahead, for 
next major axis location, if possible *[ adjust_major; /* adjust shadow registers to next major axis 
location */ major_count = major_count- 1; } out_third_pixel; If(Y_MAJOR*4_PP) { /* look ahead, for next 
major axis location, if possible */ adjust_major; /* adjust shadow registers to next major axis location 
*[ major count = major_count - 1; } } } END There are several items to note about this algorithm; -- 
One of the main features of Bresenham's algorithm [5] is that the division operation required as part 
of the set up for the DDA algorithm is not needed. Since 1963 when Bresenham wrote his algorithm, the 
relative cost of doing division in hardware has dramatically decreased, such that the cost of the additional 
set up operations required for the DDA algorithm is relatively small. The advantage of using a DDA style 
algorithm is that the subpixel position of the true line can be calculated incrementally and then read 
directly from the fractional bits in the minor axis position register. The vector routine as written 
above takes the DDA style set-up as input. If the true endpoint of the line is not at an integer location 
on the major axis, then additional calculation will be required. The first minor axis intersection with 
an integer value of the major axis must be calculated. Note that the minor axis is specified with subpixel 
accuracy, but is sampled only at integer values of the major axis. The rational for requiring this subpixel 
adjustment of the minor axis position was shown in Figure 2. -- If aliased vectors are being rendered, 
then the signals Increment, Decrement and Minor_Step cannot be asserted. In the aliased ease the "while" 
loop becomes very much like the inner loop of a DDA algorithm, with one noticeable exception. That is 
in a multi-processor configuration the Hold signal will only be asserted when the processor owns the 
scan line. -- In a single processor configuration the algorithm will step to all rendered pixel locations. 
 -- In a four processor configuration with Y-major antialiased vectors, the major axis will be stepped 
ahead while rendering across the minor axis. The result is that in three clock cycles, the three minor 
axis pixels will be rendered and the major axis stepped ahead three scan lines. One extra clock is then 
needed to get to the scan line where the next pixels will be rendered. Thus using the four processor 
configuration, four major axis steps can be rendered in just four clock cycles. Note that aliased vectors 
also require four clock cycles to step four major axis steps. -- In a four processor configuration with 
X-major antialiased vectors, the Increment, Decrement and Hold signals will make the processor render 
the correct minor axis plxel on the first clock. The Minor Step signal will not be asserted. The combined 
processing of the four processors will be one major axis step rendered in every clock cycle. Note that 
aliased vectors also require one clock cycle to step a major axis step. PIXEL GENERATION PROCESS There 
are three subprocesses that need to be considered: color generation, accessing the filter table, and 
updating the frame store. In the CTI chip, prior to rendering, the red, green and blue color data for 
the endpoints of the vector are sent to the color interpolation hardware. Endpoint data include the major 
axis locations and colors for both endpoints. The color for the current major axis step is then found 
by a perspective interpolation [10,14] calculation invoh,,ing the endpoint data and the current position. 
'~' Alpha values are stored in a filter table with 12 bits of resolution. The table is accessed with 
a 10 bit address, where the upper two table address bits access one of four sub-tables. These sub-tables 
are called top, middle, bottom and aliased. While generating the filter table, the filter values for 
the three minor axis pixels for each vector position and slope position were stored in the top, middle 
and bottom array. The aliased table consists of only a single value that is used when rendering aliased 
vectors. There are four bits each of position and slope data used as the lower address bits. The four 
bits of position are taken directly from the minor axis position register. To generate the four slope 
bits, six bits of MINOR_SLOPE are used. The sign bit, the 45 DEGREE bit and the first four bits of fraction 
are sent through combinational logic to produce four bits corresponding to the absolute value of the 
slope within an octant. In generating the filter table address, the lower eight bits are generated from 
hardware registers in the datapath. These lower eight bits are comprised of the four bits of slope information 
and four bits of subpixel position. The upper two bits require additional logic. Decoding the case where 
the aliased table is selected is trivial since the ~_MODE bit is sent as part of the vector set-up. The 
middle table is relatively simple to decode. Referring back to Figure 7, it can be seen that if pixel 
1 is rendered as the first pixel in an antialiased vector, then the middle table should be used. It can 
also be seen that any time the second pixel is rendered the middle table should be used. The correct 
selection of the top and bottom table require a little more logic. Included in the decode logic for the 
top and bottom table selection is the sign bit from the minor_slope, the current state of the SERP signal 
and information indicating whether the current plxel is the first or third pixel along the minor axis. 
Updating the frame store is a complex operation. The 10 bits used for each interpolated color (30 bits 
of color total) and the 12 bit alpha values must be blended with the old 24 bits of gamma corrected data 
from the frame store. These operations must be done at the pixel generation speed in parallel for each 
of the image space sub-division regions. In the system implementation an extension to the pixel cache 
[12] is used. The pixel cache reads the old data from the frame store and performs an inverse gamma function 
correction, so that data will be blended in linear space. Then the pixel cache uses a set of blending 
rules [8] to combine the new color data into the pixel. The new pixel is then corrected with the gamma 
function and written to the frame store. One example blending rule allows any color vector to be blended 
with any color background on a pixel by pixel basis. The intensities of the red, green and blue channels 
are operated on separately as follows; NEW_FRAME_STORE_DATA = GAMMA [ALPHA* (NEW_COLOR) + ((I.ALPHA)*(GAMMA 
"t [OLD_DATA]))] HARDWARE IMPLEMENTATION The pre-computed filter table of alpha values and the color 
interpolation hardware were implemented as part of a single custom VLSI chip called the Color~Texture 
Interpolator (CTI), shown in Figures 8 and 9. Control of the CTI hardware during vector generation is 
done with the algorithm described. Some of the details of the chip are as follows: Computer Graphics, 
Volume 24, Number 4, August 1990 --The 252,000 FET chip is fabricated by the Colorado Integrated Circuit 
DMsion (CICD) of Hewlett-Packard. The internal circuitry of the CTI is clocked at 50 MHz while the chip 
I/O and frame buffer subsystem are clocked at 25 MHz. Running the internal circuitry at twice the system 
clock allowed simplification and size reduction of the CTI hardware. -- The datapath and control hardware 
support both vector and polygon operations. Polygons may be rendered at a peak rate of 4 pixels per frame 
buffer subsystem clock, in a four CTI chip system. -- The algorithm presented shows the conceptual flow 
of the vector generation process. However, the algorithm as presented does not reflect the pipelined 
nature of the hardware implementation. As an example, once the data for one vector is loaded into the 
register set, another data packet for the next vector may be loaded into a set of shadow registers. Once 
the hardware determines a given vector will finish in the next state, the next set of vector data may 
be moved into the active register set. In practice, once the major_count is known to be zero, the registers 
fill up with the next data set. The effect is that vectors (and polygons) may be rendered with as little 
as one dead clock between primitives. --Besides using pipelining, the hardware also supports parallel 
datapaths. For example, the pixel address, color and alpha values are all found in parallel. --The pixel 
cache may stop the CTI at any time. For example, this could occur when the RAM chips in the frame store 
are being refreshed. The stop logic is not shown in the conceptual algorithm presented; but in the implementation, 
each block of logic is gated by NOT_STOP. -- While stepping the major axis, a line-type register is also 
stepped. This allows patterned lines on both aliased and antialiased vectors. -- In the system implementation, 
a companion chip called the Z Interpolator (ZI) uses the same control algorithm to generate Z values 
for antialiased lines. --The CTI can generate over two million aliased or antialiased vectors per second, 
when in a four processor configuration. This is one major axis step per frame buffer subsystem clock. 
CONCLUSION A method to generate high-speed, high-quality vectors has been presented. The parallel algorithm 
allows vector generation to be split among several processors. In the implementation using four processors, 
an effective stepping rate of one major axis step per clock is achieved. The rate of one major axis step 
per clock is achieved for both aliased and antialiased lines. Many of the parallelizing concepts used 
in the vector generation may also be applied to polygon generation. The result is that the same datapaths 
and control hardware may be shared to render high speed polygons. The CTI chip implements the antialiasing 
method and stepping algorithm described in this paper. It provides high speed, high quality antialiased 
vectors in the Hewlett-Paekard Turbo-VRX graphics system.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97915</article_id>
		<sort_key>327</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Real-time robot motion planning using rasterizing computer graphics hardware]]></title>
		<page_from>327</page_from>
		<page_to>335</page_to>
		<doi_number>10.1145/97879.97915</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97915</url>
		<abstract>
			<par><![CDATA[We present a real-time robot motion planner that is fast and complete to a resolution. The technique is guaranteed to find a path if one exists at the resolution, and all paths returned are safe. The planner can handle <i>any</i> polyhedral geometry of robot and obstacles, including disjoint and highly concave unions of polyhedra.The planner uses standard graphics hardware to rasterize configuration space obstacles into a series of bitmap slices, and then uses dynamic programming to create a navigation function (a discrete vector-valued function) and to calculate paths in this rasterized space. The motion paths which the planner produces are minimal with respect to an <i>L</i><sub>1</sub> (Manhattan) distance metric that includes rotation as well as translation.Several examples are shown illustrating the competence of the planner at generating planar rotational and translational plans for complex two and three dimensional robots. Dynamic motion sequences, including complicated and non-obvious backtracking solutions, can be executed in real time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Computations on discrete structures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Routing and layout</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Path and circuit problems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010199.10010204</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Planning and scheduling->Robotic planning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636.10003811</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis->Routing and network design problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003640</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Paths and connectivity problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553.10010554</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems->Robotics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010213.10010204</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods->Robotic planning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P137139</person_id>
				<author_profile_id><![CDATA[81100361368]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lengyel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Graduate Student, Program of Computer Graphics, Cornell University, Ithaca, N.Y.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P190933</person_id>
				<author_profile_id><![CDATA[81332523089]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reichert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Graduate Student, Program of Computer Graphics, Cornell University, Ithaca, N.Y.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P33383</person_id>
				<author_profile_id><![CDATA[81100578171]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Donald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Assistant Professor and Director, Computer Science Robotics Laboratory, Department of Computer Science, 4130 Upson HalI, Cornell University, Ithaca, N.Y.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Director, Program of Computer Graphics, Jacob Gould Shurman Professor of Computer Graphics, Cornell University, Ithaca, N.Y.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barraquand, J. and J. Latombe. Robot Motion Planning: A Distributed Representation Approach, Report No. STAN-CS-89-1257, Stanford University, Department of Computer Science, May 1989.]]></ref_text>
				<ref_id>BL89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Canny, J., B. Donald, j. Reif, and P. Xavier. "On the Complexity of Kinodynamic Planning," in 29th Symposium on the Foundations of Computer Science, White Plains NY., 1988.]]></ref_text>
				<ref_id>CDRX88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889509</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Donald, B. R. Motion Planning with Six Degrees of Freedom, Report No. MIT AI-TR 791, MIT, Artificial Intelligence Laboratory, 1984.]]></ref_text>
				<ref_id>Don84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>25365</ref_obj_id>
				<ref_obj_pid>25363</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Donald, B. R. "A Search Algorithm for Motion Planning with Six Degrees of Freedom," Artificial Intelligence, 31, 1987, pages 295-353.]]></ref_text>
				<ref_id>Don87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dorst, L. and K. Trovato. "Optimal path planning by cost wave propagation in metric configuration space," Proceedings of SPIE-The International Society for Optical Engineering, 1007, November 1988, pages 186- 197.]]></ref_text>
				<ref_id>DT88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Donald, B. and P. Xavier. "A Provably Good Approximation Algorithm for Optimal-Time Trajectory Planning," in IEEE Int. Conf. On Robotics and Automation, Scottsdale, AZ, 1989.]]></ref_text>
				<ref_id>DX89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>98594</ref_obj_id>
				<ref_obj_pid>98524</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Donald, B. and P. Xavier. "Provably Good Approximation Algorithms for Optimal Kinodynamic Planning for Cartesian Robots and Open Chain Manipulators," in Proceedings of the ACM Symposium on Computational Geometry, Berkeley, CA, 1990.]]></ref_text>
				<ref_id>DX90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Khatib, O. and J. Le Maitre. "Dynamic Control of Manipulators Operating in a Complex Environment," Proceedings Third International CISM-IFToMM Symposium, September 1978, pages 267-282.]]></ref_text>
				<ref_id>KLM78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Koditschek, D. E. "Exact Robot Navigation by Means of Potential Functions: Some Topological Considerations," IEEE International Conference on Robotics and Automation, March 1987.]]></ref_text>
				<ref_id>Kod87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94670</ref_obj_id>
				<ref_obj_pid>102814</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Koditschek, D. E. "Planning and Control via Potential Functions," in Lozano-P6rez, T. and O. Khatib, editors, Robotics Review I, MIT Press, 1989, pages 349-367.]]></ref_text>
				<ref_id>Kod89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lozano-P6rez, T. Spatial Planning: A Configuration Space Approach, A.I. Memo No. 605, Massachusetts Institute of Technology, Artificial Intelligence Laboratory, December 1980.]]></ref_text>
				<ref_id>Loz80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1309766</ref_obj_id>
				<ref_obj_pid>1309288</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lozano-P6rez, T. "Spatial Planning: A Configuration Space Approach," IEEE Transactions on Computers, C-32, t983, pages 108-120.]]></ref_text>
				<ref_id>Loz83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lozano-Pgrez, T. "A Simple Motion Planning Algorithm for General Robot Manipulator," IEEE Journal of Robotics and Automation, RA-3(3), 1987, pages 224-- 238.]]></ref_text>
				<ref_id>Loz87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359164</ref_obj_id>
				<ref_obj_pid>359156</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Lozano-P6rez, T. and M. A. Wesley. "An Algorithm for Planning Collison-Free Paths Among Polyhedral Obstacles," Communications of the ACM, 22, 1979, pages 560-570.]]></ref_text>
				<ref_id>LPW79</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806786</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, T. "Contour Filling in Raster Graphics," Proceedings of SIGGRAPH'81 (Dallas, Texas, August 3-7, 1981), 1981, pages 29-36.]]></ref_text>
				<ref_id>Pav81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907618</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Udupa, S. Collision Detection and Avoidance in Computer Controlled Manipulators, PhD dissertation, Department of Electrical Engineering, California Institute of Technology, Pasadena, California, 1977.]]></ref_text>
				<ref_id>Udu77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Yap, C. K. "Algorithmic Motion Planning," in Schwartz, J. T. and C. K. Yap, editors, Advances in Robotics, Lawrence Erlbaum Associates, 1985.]]></ref_text>
				<ref_id>Yap85</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Real-Time Robot Motion Planning Using Rasterizing 
Computer Graphics Hardware .led Lengyel*, Mark Reichert*, Bruce R. Donaldl and Donald P. Greenberg ~ 
Abstract We present a real-time robot motion planner that is fast and complete to a resolution. The technique 
is guaranteed to find a path if one exists at the resolution, and all paths returned are safe. The planner 
can handle any polyhedral geometry of robot and obstacles, including disjoint and highly concave unions 
of polyhedra. The planner uses standard graphics hardware to rasterize config- uration space obstacles 
into a series of bitmap slices, and then uses dynamic programming to create a navigation function (a 
discrete vector-valued function) and to calculate paths in this rasterized space. The motion paths which 
the planner produces are minimal with respect to an L l (Manhattan) distance metric that includes rotation 
as well as translation. Several examples are shown illustrating the competence of the planner at generating 
planar rotational and translational plans for complex two and three dimensional robots. Dynamic motion 
sequences, including complicated and non-obvious backtracking solutions, can be executed in real time. 
 Introduction Motion planning has been regarded as a core algorithmic problem in computational robotics 
for many years, and many researchers have worked on finding better algorithmic solutions.[Yap85] However, 
despite the fact that all of the key elements in planning robot motion substantially overlap with computer 
graphics interests, the problem has not been presented as a computer graphics topic. The classical formulation 
of the Find-Path or Piano Mover's problem is stated as follows: given an arbitrary rigid polyhedral object, 
P, and polyhedral environment, find a continuous collision- free path taking P from some initial configuration 
to a desired goal configuration. *Graduate Student, Program of Computer Graphics, Cornell University, 
Ithaca, N.Y. 14853 t Assistant Professor and Director, Computer Science Robotics Labora- tory, Department 
of Computer Science,4130 Upson HalI,Cornell University, Ithaca, N.Y. 14853 ~Director, Program of Computer 
Graphics, Jacob Gould Shurman Pro- fessor of Computer Graphics, Comell University, Ithaca, N.Y. 14853 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. We view this 
motion planning process as an algorithmic en- deavor analogous to hidden surface removal in computer 
graphics. First, precise combinatorial solutions exist, but rasterized, approx- imating techniques (such 
as z-buffer algorithms) are faster and more effective. Second, such approximation algorithms can be provided 
with massively parallel, specialized hardware support. Instead of concentrating on more efficient, combinatorially 
exact algorithms, the end-user is more effectively served by (a) choosing good representations for the 
geometric constraints, (b) selecting local, isotropic geometric algorithms that are easily parallelizable, 
and (c) providing or using appropriate hardware support to make the algorithms run very fast. Our algorithm 
is based on the configuration space representations that are due to Lozano-Prrez [LPW79], and we use 
a local, isotropic search algorithm [Don87][Don84] to obtain a very fast motion planning algorithm that 
runs on standard graphics hardware. Two parts of the local algorithm we present here are very similar 
to the work of [DT88]. The paths produced have minimal length with respect to an L~ distance metric imposed 
on the rasterization which treats translational and rotational movements equally. In addition to being 
simple, the algorithm is complete to a resolution (of the rasterization), and while inherently "local", 
does not suffer from local minima. Many other fast motion planning algorithms, in particular, potential 
field methods, get "stuck" in local minima and therefore cannot be effectively used to plan paths for 
complex, concave, or disconnected robots. While these other algorithms run well when the robot is (a) 
small and convex relative to the environment, or (b) when the space of solutions is "very dense", our 
planner may be more effective in more complicated cases. For computer graphics applications, the visual 
impact of the robot motion is important. Since the motions are time-dependent and complex, real-time 
graphical playback is desirable to assess the motion sequence, including the complicated back-tracking 
paths which may be necessary to obtain a solution. In Section 2 a brief overview of the historical approaches 
used by the robotics community is presented. Section 3 describes our algorithm in detail. Section 4 presents 
the results of the implementation for several specific cases. Section 5 presents the conclusions and 
topics for future research. 2 Background The Piano Mover3" problem has been approached in many ways. 
We present below a brief overview of the two major approaches used by the robotics community, the configuration 
space and potential field methods, and discuss the advantages and limitations of each method.  O SIGGRAPH 
'90, Dallas, August 6-10, 1990 The first module allocates a voxel array representation of c-space and 
rapidly computes c-space obstacles in this array using standard graphics rasterization hardware. The 
second module calculates a c-space navigation function [Kod87] with a dynamic programming technique (expanding 
wavefront of solutions.) This navigation function is essentially a discrete vector-valued function which, 
when given the robot's current voxel location in c-space, returns the direction that the robot should 
move to decrease its distance to the goal. The third module determines the shortest path from any voxel 
start position to the goal if there is a viable solution. Since the navigation function gives the direction 
to move at every cell, this module can calculate the path quickly, and determine in constant time if 
a path exists. The fourth module produces a real-time kinematic simulation of the robot motion. Each 
of these modules is described in more detail below. 3.2 Definitions The following definitions due to 
[Loz80] are useful prior to the algorithmic explanations. A c-space obstacle, CO, is a forbidden region 
of c-space R 2 x S 1 . A slice, CO[Sl, 82], of CO is CO restricted to an angular interval [81, 82], i.e. 
CO N (R 2 × [81,82]). A slice projection is the projection of C0101,02] onto the "plane" R 2 x {80} for 
00 = (81 -q-82)/2. 3.3 Generation of Configuration Space Representation We calculate the configuration 
space obstacle polygons by taking the Minkowski sum of the obstacles and the rotated and negated robot 
as described by Lozano-Perez [LozS0] (Figure 3). We then use graphics polygon-fill hardware to fill the 
configuration space obstacle polygons (Figure 4). When the robot motion is restricted to two degrees 
of freedom (only translation in the plane) our discrete representation of c-space is a single bitmap 
with rasterized c-space obstacles. However, when rotation is allowed, the configuration space is represented 
by a set of bitmaps, where each bitmap is a slice projection representing the configuration space for 
the angular interval [01, 82]. While generating a representation of c-space at exactly one orientation 
is trivial, generation of a conservative, discrete, repre- sentation of c-space over some angular interval 
is more difficult. Our goal is to ensure that, in the bitmap slice representing c-space for the angular 
interval [8~, 02], no cell is labeled as free if it has a c-space obstacle penetrating it at any orientation 
in [81,82]. To produce a discrete representation of c-space for the angular inter- val [0~,Sz], we generate 
n discrete representations of c-space at equally spaced orientations within the interval [81, 82]. The 
angular increment 0 = (02 -01)/n. The bitmap slice representation for the angular interval [81,02] is 
the union of all of the sub-intervals. Figure 7 is a pseudo-code implementation of this method. Note 
that the bitmap slices are conservative. If any part of an obstacle penetrates a cell, then the whole 
cell is labeled with "obstacle." This discards some potential paths, but enforces the complete-to-a-resolution 
property of the planner. If two adjacent cells are labeled as being "free" of obstacles, then the path 
between them is free, since if there were any obstacle in the way, one or both of the cells would have 
been labeled with "obstacle," which would contradict the assumption of both cells being "free". Since 
330 movement is allowed only between "free" cells, every path returned is valid (collision-free.) GENERATE 
C-SPACE() For theta = 0 to 2= by 2~/]V (N~#of~em slices) Foreach robotPoly in robot polygon list For 
tl = theta -dtheta to theta + dtheta Rotate robotPoly by tl Foreach obstaclePoly in environment Generate 
the minkowski sum of rebotPoly and obstaclePoly Fill minkowski polygon with  obstacle color. Read filled 
polys from frame buffer Move bitmap into voxel array. Clear frame buffer. Return bitmap voxel array 
 Figure 7: Pseudo-code for Generation of Discretized C-Space 3.4 Calculation of Navigation Function 
A dynamic programming technique is used to expand a wavefront of solutions from the goal, with a queue 
to keep track of the current wavefront.[DT88] Each element in the queue holds a position in the rasterized 
environment and a current length of the path from the goal position. An element is dequeued, its location 
in the environment is filled with the current length, and then all of its free space neighbors that have 
not yet been filled are put on the end of the queue with an incremented distance. This algorithm is essentially 
isomorphic to the "Bumble Strategy" in Donald's 1984 algorithm [Don84] [Don87], which operated as follows: 
a search node N on a c-space grid is dequeued, and its c-space grid neighbors are generated, The reachable, 
unexplored, free-space neighbors are put on the end of the queue. Each new neighbor M contains a backpointer 
to N, and N's direction from M. This back pointer (and back-direction) corresponds precisely to our navigation 
function. Note the Bumble Strategy is simply a breadth-first-search (BFS) from the start (or goal.) We 
regard dynamic programming and BFS as "dual" algorithms in that BFS from the goal yields our dynamic 
programming algorithm. FILL NAVIGATION FUNCTION(goal location) Enqueue goal location with distance = 
0 While queue is not empty Dequeue element F Label F's location with F's distance Enqueue all neighbors 
of F that are not obstacles and that have not yet been filled with distance = distance + 1  Figure 
8: Pseudo-code for Navigation Function Fill The initial element placed in the queue is the goal node 
with a path length of zero. The algorithm takes that node out of the queue, fills its location in the 
rasterized environment with zero, then queues up all of the neighboring nodes with a path length of one. 
The wavefront continues out like a "brush fire", spreading around the C-space obstacles, in a way similar 
to flood-fill or seed-fill algorithms used in computer paint programs [Pav8 I]. Each cell that can be 
reached from the goal is set just once (Figures 9 and 8.)   ¢ Computer Graphics, Volume 24, Number 
4, August 1990 Start Position Goal Figure 9: Calculation of Navigation Function. Note that with the 
three-degree of freedom case (two translations plus rotation) that the fill expands upward and wraps-around 
in the theta direction as well as expanding in the x and y directions. The running time is proportional 
to the number of free cells in the environment. Complicated scenes which consist of many obstacles have 
fewer free cells. Thus, paradoxically, more complicated scenes are quicker to fill! 4 3.5 Path Generation 
Since the navigation function is generated by a breadth-first search through the rasterized configuration 
space, it yields the shortest path from the goal to any reachable position in the configuration space 
(where a "shortest path" is defined to be one passing through a minimal number of voxels.) [See [DT88] 
for other metrics.] To get closer to the goal from any start position, the robot moves to the lowest-numbered 
neighboring cell. This corresponds exactly to following the breadth-first search tree to the goal. (We 
call this process "surfing", since the robot is simply sliding down the "hills" of the potential function,) 
If there are multiple cells which have the lowest number, any one can be picked, since each would correspond 
to a path with the same number of moves needed to reach the goal. Given a choice between a rotation (a 
move in the theta direction) or a translation (a move in the x or y direction), our algorithm selects 
the translation option to minimize rotation(Figures 10 and I 1.) By construction, every cell that can 
be reached from the goal has a neighbor with a lower number than itself (the cell which was queued to 
label it.) Thus, there are no local minima in the navigation function. The robot can just follow the 
bread-first search tree to the goal and not worry about getting stuck. The following of the search tree 
is fast, running in linear time with respect to path length. This path generation technique corresponds 
precisely to gradient following[DT88][Kod87]. 3.6 Display Routines A program has been implemented which 
uses standard graphics hardware acceleration to generate dynamic real-time playback of the robot motion, 
allowing the viewer's position to be interactively modified. Two sequential pre-processing steps are 
required, the rasterization of c-space and the computation of the navigation function. This discretized 
configuration space must be recomputed 4Also observed by [DT88]. / Goal -~Path Figure 10: Path Generation. 
GENERATE PATH(start location) let C = cell corresponding to start location let P = NULL if C was not 
reached by fill (label is blank) return CANNOT REACH GOAL  else while C is not at goal add C to path 
P pick lowest numbered neighbor, L let C = L return P Figure 11: Pseudo-code for Path Generation 
(Surfing) for every change in the obstacle definitions or the robot geometry. The navigation function 
is recomputed only if there is a change in the goal position. Since the path generation is so fast, this 
can be computed on-the-fly, and the dynamic sequences of the robot motion can be displayed. 3.7 Use 
of Hardware While our algorithm is the slowest possible on serial machines, it is very fast using parallel 
or specialized hardware. Each of the above modules can benefit from use of specialized hardware. In our 
implementation only the first, the generation of the c-space obstacles, and the fourth, the kinematic 
simula- tion, use specialized graphics hardware. The second module, the flood-fill, uses a very local 
operation and is ideal for a distributed computation[BL89]. The third module, the gradient following 
or bread-first-search-tree following, is essentially a fast serial opera- tion. 4 Examples The algorithm 
was tested in several obstacle environments with robots and obstacles of varying shape and convexity. 
Experimen- tal timings for each of these examples are presented in Table 1. Note 'that once the preprocessing 
steps for the configuration space and navigation function are complete, the path-generation algo- rithm 
runs almost instantaneously, and real-time motion display is possible. @SIGGRAPH '90, Dallas, August 
6-10, 1990 Problem Figure She C-space Fill Surf Display Moving Planar Robot 13b 256x256x120 22.6 44.1 
0.11 35.8 Backtracking Planar Robot 13e 256x256x120 * * 0.11 50.3 Stuck Planar Robot 13f 256x256x120 
* * 0.01 0 Piano (Room 1) 14a 192x192x180 26.0 50.2 0.05 27.1 Piano (Room2) 15a 92x92x90 8.1 8.1 0.04 
7.2 Table 1 : Table of experimental timings. Times are given in seconds, Processing and display was performed 
on a Hewlett Packard 835 with a Turbo-SRX graphics display. The precalculations whose times marked as 
"*" for Figures 13e and 13f were already performed for Figure 13b and did not need to be repeated. 4.1 
Complex R 2 × S 1 This example illustrates the motion of a complex, concave planar robot, Note the triangular 
peg obstacles in the upper left-hand comer (Figure 13b.) Since the search algorithm does not rely on 
a heuristic distance to the goal, backtracking paths are easily found (Figure 13e.) In this example, 
the robot is not able to turn around until it backtracks all the way to the right side (where the region 
is devoid of the pegs preventing the turning on the left side). If the search backwards from the goal 
(the navigation function) reached the start point, then a path exists from the start to the goal, otherwise 
one does not exist at the given resolution. With one array reference, it is known whether or not a path 
can be found from the start configuration to the goal. In Figure 13f, the robot's "head" is stuck between 
the peg and the wall, and thus the algorithm returns with the result that no path exists. 4.2 R 2 x 
S 1 motion for 3D robots Many three-dimensional robots have pieces which are quite distinct vertically. 
A piano, for example, has small legs and a large main body. By creating two classes of environmental 
objects, one class of objects which obstruct the legs, and the other which obstruct the body, the algorithm 
for planar problems can be extended by object space partitioning (3~D1 representation.) Piano Body Piano 
Legs Figure 12: Piano Environment Partitioning. The rasterization is performed as before, with the exception 
that the body is now convolved only with the body obstacles, and the legs only with the leg obstacles. 
The union of the leg and body c-space obstacles is used to create one bitmap. Since the leg obstacle 
is not convolved with the body when generating the c-space obstacles, the piano body can move over it, 
while the legs maneuver around it (Figure 14a.) 332  5 Discussion &#38; Conclusion We have presented 
a robot motion planner that is fast and, unlike other fast motion planners, is based entirely on complete 
and provably-good approximation algorithms. The algorithm is based on part of Donald's original algorithm 
[Don87], which was initially considered to be slow and ineffective for real-time motion planning, but 
when modified to run on current graphics hardware is actually quite fast. The planner can handle any 
polyhedral geometry of robot and obstacles, including disjoint and highly concave unions of polyhe- dra. 
The planner is very general and is guaranteed to find a path if one exists at the resolution. In constant 
(O(1)) lime, it detects if a path exists from the start location to the goal, or between any two points 
through the goal (compare [DTS8].) The method is memory intensive, but for many problems the resolutions 
can be made much lower, especially in the rotational dimension. Storage can also be reduced by eliminating 
the navi- gation function value, and only storing a direction at each point, requiring as few as three 
bits per cell (for the 3DOF case.) The method is resolution dependent. The higher the resolution, the 
closer the robot can squeeze by the obstacles. The lower the resolution, the lower the memory requirements. 
We believe that we have demonstrated that provably good ap- proximation algorithms for kinematic motion 
planning can be made to run very fast, if the algorithms are local, isotropic, and can take advantage 
of special purpose computer graphics hardware for tasks such as rasterization (poly-fill), flood-fill, 
and gradient-following. We conjecture that the fastest solutions will involve algorithms similar to ours, 
that is, characterized by use of 1. Configuration space representations such as [LPW79]. 2. Local, geometric, 
isotropic, parallelizable search algorithms such as IDon87]. 3. Appropriate hardware support for geometric 
computation.  In robotics, and in animation, in addition to kinematic planning and simulation, one also 
desires to plan robot motions with full dy- namics. In recent work, [CDRX88][DX89][DX90] have developed 
provably good approximation algorithms that generate motions that (1) avoid obstacles, (2) obey dynamic 
bounds on generalized forces and velocities, (3) respect full Lagrangian rigid body dynamics equations 
of motion, and (4) are provably close to optimal-time. These algorithms are also grid-based, and currently 
run very slowly on traditional architectures. We hope that by using techniques similar to those we propose 
in this paper, that these algorithms can be made to run quickly when modified to exploit appropriate 
hardware support. We hope that this paper illustrates the substantial overlap in research areas between 
the graphics and robotics communities, and fosters collaborative efforts to create more innovative solutions. 
  ~' Computer Graphics, Volume 24, Number 4, August 1990 Figure 13a: Key to Robot Positions. Figure 
13b: Moving Planar Robot. B I ! Figure 13c: First Leg of Backtracking. Figure 13d: Last Leg of Backtracking. 
'1 | - . Figure 13e: Backtracking Planar Robot. Figure 13f: Trapped Planar Robot. 13a is a key to the 
start and goal locations of the subsequent figures. In 13b, the robot follows the gradient of the potential 
function to the goal (which is the same as following the breadth-first search tree.) In 13c, the robot 
first moves from the start to the right, since there is not enough room between the pegs on the left 
to reorient. The robot then has enough room to reorient (the right side is not blocked by the small pegs 
as on the left.) Finally, in 13d, the robot can squeeze by the small pegs, and obtain the goal position 
and orientation. 13e shows the entire motion of 13c and 13d. The algorithm is exactly the same as in 
13b, simply following the breadth-first search tree. In 13f, no solution exists. Our planner detects 
this in constant O(1) time.   ~ Computer Graphics, Volume 24, Number 4, August 1990 Acknowledgements 
The authors gratefully acknowledge the National Science Foun- dation whose two research grants entitled 
"Interactive Input and Display Techniques" (DCR8203929) and "Visualization for Sci- entific Computing" 
(ACS8715478) help support the Program of Computer Graphics. Support for Bruce Donald's robotics research 
is provided in part by the National Science Foundation under grant No. IRI-8802390 and by a Presidential 
Young Investigator award, and in part by the Mathematical Sciences Institute. Jed Lengyel is supported 
by a National Science Foundation Graduate Fellowship. Our interactive graphics computing environment 
has been substantially enhanced by generous equipment donations from Hewlett-Packard and Digital Equipment 
Corporation. Thanks to Robotics CS661, and Bruce's teaching assistants Pat Xavier and Russell Brown, 
for introducing us to the field of robotics (and for assigning Homework 1, which lead directly to this 
work.) Thanks to Len Wanger for the piano model, to Emil Ghinger for photographic work, to Tim O'Connor 
for keeping our computers alive and well, to Fran and Ellen for keeping everything else alive and well, 
to Jim Ferwerda for breathing life into the video system and to Dave Baraff for taking time to show us 
how to use it. Thanks to Roy Hall for proof-reading drafts of this paper. Special thanks to Wendy, Michele, 
Rachael, and Iris for their unending patience while this paper was being written. References [BL89] 
Barraquand, J. and J. Latombe. Robot Motion Plan- ning: A Distributed Representation Approach, Re-port 
No. STAN-CS-89-1257, Stanford University, De- partment of Computer Science, May 1989. [CDRX88] Canny, 
J., B. Donald, J. Reif, and P. Xavier. "On the Complexity of Kinodynamic Planning," in 29 th Symposium 
on the Foundations of Computer Science, White Plains NY., 1988. [Don84] Donald, B. R. Motion Planning 
with Six Degrees of Freedom, Report No. MIT AI-TR 791, M/T, Artificial Intelligence Laboratory, 1984. 
[Don87] Donald, B. R. "A Search Algorithm for Motion Plan- ning with Six Degrees of Freedom," Artificial 
Intelli- gence, 31, 1987, pages 295-353. [DTS8] Dorst, L. and K. Trovato. "Optimal path planning by cost 
wave propagation in metric configuration space," Proceedings of SPIE-The International Society for Op- 
tical Engineering, 1007, November 1988, pages 186- 197. [DX89] Donald, B. and P. Xavier. "A Provably 
Good Ap- proximation Algorithm for Optimal-Time Trajectory Planning," in 1EEE Int. Conf. On Robotics 
and Au- tomation, Scottsdale, AZ, 1989. [DX90] Donald, B. and P. Xavier. "Provably Good Approxi- mation 
Algorithms for Optimal Kinodynamic Planning for Cartesian Robots and Open Chain Manipulators," in Proceedings 
of the ACM Symposium on Computa- tional Geometry, Berkeley, CA, 1990. [KLM78] Khatib, O. and J. Le Maitre. 
"Dynamic Control of Manipulators Operating in a Complex Environment," Proceedings Third International 
CISM-1FToMM Sym- posium, September 1978, pages 267-282. [Kod87] [Kod89] [LozS0] [Loz83] [Loz87] [LPW79] 
[Pav81 ] [Udu77] [Yap85] Koditschek, D. E. "Exact Robot Navigation by Means of Potential Functions: Some 
Topological Consider- ations," IEEE International Conference on Robotics and Automation, March 1987. 
Koditschek, D. E. "Planning and Control via Potential Functions," in Lozano-Pgrez, T. and O. Khatib, 
editors, Robotics Review I, M1T Press, 1989, pages 349-367. Lozano-Prrez, T. Spatial Planning: A Configuration 
Space Approach, A.I. Memo No. 605, Massachusetts Institute of Technology, Artificial Intelligence Labora- 
tory, December 1980. Lozano-Prrez, T. "Spatial Planning: A Configuration Space Approach," IEEE Transactions 
on Computers, C-32, I983, pages 108-120. Lozano-Prrez, T. "A Simple Motion Planning Algo- rithm for General 
Robot Manipulator," IEEE Journal of Robotics and Automation, RA-3(3), 1987, pages 224-- 238, Lozano-Prrez, 
T. and M. A. Wesley. "An Algorithm for Planning Collison-Free Paths Among Polyhedral Obstacles," Communications 
of tile ACM, 22, 1979, pages 560-570. Pavlidis, T. "Contour Filling in Raster Graphics," Proceedings 
of SIGGRAPH'81 (Dallas, Texas, August 3-7, 1981), 1981, pages 29-36. Udupa, S. Collision Detection and 
Avoidance in Com- puter Controlled Manipulators, PhD dissertation, De- partment of Electrical Engineering, 
California Institute of Technology, Pasadena, California, 1977. Yap, C. K. "Algorithmic Motion Planning," 
in Schwartz, J. T. and C. K. Yap, editors, Advances in Robotics, Lawrence Erlbaum Associates, 1985. 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97916</article_id>
		<sort_key>337</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Ray tracing trimmed rational surface patches]]></title>
		<page_from>337</page_from>
		<page_to>345</page_to>
		<doi_number>10.1145/97879.97916</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97916</url>
		<abstract>
			<par><![CDATA[This paper presents a new algorithm for computing the points at which a ray intersects a rational B&amp;eacute;zier surface patch, and also an algorithm for determining if an intersection point lies within a region trimmed by piecewise B&amp;eacute;zier curves. Both algorithms are based on a recent innovation known as B&amp;eacute;zier clipping, described herein. The intersection algorithm is faster than previous methods for which published performance data allow reliable comparison. It robustly finds all intersections without requiring special preprocessing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36042611</person_id>
				<author_profile_id><![CDATA[81100539710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomoyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fukuyama University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P281616</person_id>
				<author_profile_id><![CDATA[81100400673]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Sederberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brigham Young University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP309709900</person_id>
				<author_profile_id><![CDATA[81546995456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Masanori]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kakimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fujitsu Laboratories LTD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>3651</ref_obj_id>
				<ref_obj_pid>3650</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Btihm, Wolfgang, Farin, Gerald and Kahmann, Jurgen. A survey of curve and surface methods in CAGD. Computer Aided Geometric Design, 1, 1 (1984), 1-60.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61954</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Farin, Gerald. Curves and Surfaces for Computer Aided Geometric Design, Academic Press, 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94788</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew ed., Introduction to Ray Tracing. Academic Press, 1989.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15917</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Joy, Keneth and Bhetanabhotla, Murthy. Ray Tracing Parametric Patches Using Numerical Techniques and Ray Coherence. Proceedings of SIGGRAPH '86 (Dallas, TX, August 18-22, 1986). In Computer Graphics, 20, 4 (August 1986), 279-285.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>95075</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Joy, Kenneth, Grant, Charles ,Max, Nelson and Hatfield, Lansing. Computer Graphics: Image Synthesis. Computer Society Press, 1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801287</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajiya, Jim. Ray tracing parametric patches. Proceedings of SIGGRAPH '82 (Boston, MA, July 26-30, 1982). In Computer Graphics,16,3 (July 1982), 245-254.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lane, Jeff and Riesenfeld, Rich. A Theoretical Development for the Computer Generation and Display of Piecewise Polynomial Surfaces. IEEE Trans. RAMI,2 (1980), 35-46.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Murakami, Koichi, Hirota, Katsuhiko and Ishii, Mitsuo. Fast ray tracing. Fujitsu Science and Technology Journal, 24, 2 (1988), 150-159.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74344</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Rockwood, Alyn, Heaton, Kurt and Davis, Tom. Real-Time Rendering of Trimmed Surfaces. Proceedings of SIGGRAPH '89 (Boston, MA, July 31 - August 4, 1989). In Computer Graphics, 23, 3 (July 1989), 107-117.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Rogers, Dave. Procedural Elements for Computer Graphics. McGraw-Hill, New York, 1985, 296-305.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Roth, Scott. Ray Casting for Modeling Solids. Computer Graphics and Image Processing, 18, 1982, 109-144.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>69179</ref_obj_id>
				<ref_obj_pid>69177</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Tom. An Algorithm for Algebraic Curve Intersection. Computer-Aided Design, 21, 9 (1989), 547-554.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>18559</ref_obj_id>
				<ref_obj_pid>18548</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Tom and Parry, Scott. A Comparison of Three Curve Intersection Algorithms. Computer-Aided Design, 18, 1 (1986), 58-63.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Tom and Parry, Scott. Free-Form Deformation of Solid Geometric Models. Proceedings of SIGGRAPH '86 (Dallas, TX, August 18-22, 1986). In Computer Graphics, 20, 4 (August 1986), 151-160.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>98661</ref_obj_id>
				<ref_obj_pid>98658</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Tom, White, Scott and Zundel, Alan. Fat Arcs: A Bounding Region with Cubic Convergence. Computer Aided Geometric Design, 6 (1989), 205-218.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378510</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Shantz, Mike and Chang, Sheue-Ling. Rendering Trimmed NURBS with adaptive Forward Differencing. Proceedings of SIGGRAPH '88 (Atlanta, GA, August 1-5, 1988). In Computer Graphics, 22, 4 (August 1988), 189-198.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sweeney, Michael and Bartels, Richard. Ray Tracing Free- Form B-Spline Surfaces. IEEE CG&amp;A, 6, 2, 1986, 41-49.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325233</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Toth, Dan. On Ray Tracing Parametric Surfaces. Proceedings of SIGGRAPH '85 (San Francisco, CA, July 22-26, 1985). In Computer Graphics 19, 3 (July 1985), 171-179.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner. An Improved illumination Model for Shaded Display. CACM, 23, 6, 1980, 96-102.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94452</ref_obj_id>
				<ref_obj_pid>94424</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Woodward, Charles. Ray Tracing Parametric Surfaces by Subdivision in Viewing Plane. in W. Strasser and H.-P. Seidel, editors, Theory and Practice of Geometric Modeling, Springer-Verlag, 1989, 273-290.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Ray Tracing Trimmed Rational Surface Patches 
Tomoyuki Nishita*, Thomas W. Sederberg t and Masanori Kakimoto :f *Fukuyama University tBrigham Young 
University :~ Fujitsu Laboratories LTD Abstract This paper presents a new algorithm for computing the 
points at which a ray intersects a rational B~zier surface patch, and also an algorithm for determining 
if an intersec- lion point lies within a region trimmed by piecewise B~zier curves. Both algorithms are 
based on a recent innovation known as Bfzier clipping, described herein. The in- tersection algorithm 
is faster than previous methods for which published performance data allow reliable comparison. It robustly 
finds all intersections without requiring spe- cial preprocessing. Categories and Subject Descriptors: 
1.3.3 [ Computer Graphics]: Picture/Image Generation; 1.3.5 [Computer Graphics]: Computa- tional Geometry 
and Object Modeling; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. General Terms: 
Algorithms Additional Key Words and Phrases: Computer graphics, ray trac- ing, visible surface algorithms, 
parametric surfaces. 1 INTRODUCTION The history, theory and capabilities of ray tracing are well docu- 
mented [3], [5]. This paper deals with the ray tracing of parametric surface patches. Specifically, we 
present an algorithm for comput- ing all points at which a ray intersects a rational Brzier surface patch 
of any degree. We also describe an algorithm for determining if a point lies within a trimmed region 
of the patch. We define a trimmed region to be an area bounded by piecewise (possibly rational) Brzier 
curves in the parameter plane of the patch. 1.1 Ray-Patch Algorithms Solutions to the ray/patch intersection 
problem can be categorized roughly as being based on subdivision, algebraic or numerical tech- niques. 
Subdivision approaches are described by Whitted [ 19], Rogers [10] and Woodward [20]. These algorithms 
harness the convex hull property of Brzier surfaces: if the ray does not intersect the convex hull of 
the control points, it does not intersect the patch. Through recursively subdividing the patch and checking 
convex hulls, the intersection points can be computed at a linear convergence rate, amounting to a binary 
search. Whitted's algorithm operates in three dimensions, whereas Rogers and Woodward map the problem 
to two dimensions. Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. Numerical solutions to the ray/patch intersection problem in- clude those developed by Toth 
[18], Sweeney and Barrels [17], and Joy and Bhetanabhotla [4]. Toth's algorithm is based on interval 
Newton iteration. It works robustly on any parametric surface for which bounds on the surface and its 
first derivatives can be obtained. Sweency and Bartels ray trace B-spline surfaces by refining the con- 
trol mesh using the Oslo algorithm until the mesh closely approxi- mates the surface, The ray intersection 
is then computed by inter- secting the control mesh with the ray, and using that intersection point as 
a starting point for Newton iteration. Joy and Bhetanab- hotla's algorithm uses quasi-Newton optimization 
to compute the point(s) on the patch nearest the ray, including intersection points. Kajiya[6] devised 
an intersection algorithm based on algebraic techniques (ie., resultants). Kajiya's algorithm reduces 
the problem of intersecting a bicubic patch with a ray into one of finding the real roots of a degree 
18 univariate polynomial. Our ray/patch intersection algorithm is based on the convex hull property of 
Brzier curves and surfaces using a technique we refer to as B~zier clipping. Traditionally, intersection 
algorithms (such as curve/curve [ 13], surface/surface [71, or ray/surface [ 19]) based on the convex 
hull property (that is, subdivision based algo- rithms) perform a linearly converging binary search. 
Brzier clip- ping uses the convex hull property in a more powerful manner, by determining parameter ranges 
which are guaranteed to not include points of intersection. Variations of this concept have proven prof- 
itable in algorithms for algebraic curve intersection[12] and planar parametric curve intersection[15]. 
Brzier clipping has the flavor of a geometrically based interval Newton method, and thus might be categorized 
as partly a subdivision based algorithm and partly a numerical method. 1.2 Trimmed Patch Algorithms 
Previous approaches to the rendering of trimmed patches include adaptive forward differencing [ 16] and 
polygonization [9]. Neither of these approaches adapts directly to ray tracing (unless one were to polygonize 
the patch[9] and then ray trace the polygons). If trim- ming is caused by a boolean operation involving 
solid geometric models, rendering can be performed using conventional construc- tive solid geometry methods[11]. 
Our algorithm renders trimmed patches defined in a boundary representation, by determining if a point 
on the patch lies inside or outside a trimmed region. One con- tribution of this paper is a fast, robust 
algorithm (based on Brzier clipping) for determining if a ray intersects a collection of trimming curves 
an even or odd number of times.  1.3 Paper Overview Section 2 introduces Brzier clipping and applies 
it to the problem of point classification for trimmed patches. Section 3 describes our O SIGGRAPH '90, 
Dallas, August 6-10, 1990 ray/patch intersection algorithm, and performance comparisons are presented 
in section 4. This paper assumes the reader is familiar with rational B6zier curves and surfaces[2]. 
The ray/patch intersection algorithm requires patches to be ex- pressed in B6zier form. The point classification 
algorithm requires trimming curves to be in Brzier form. Conversion from NURBS to B6zier representation 
is discussed in reference 9. 2 POINT CLASSIFICATION Figure 1 shows a trimmed Brzier surface patch. Its 
parameter do- main (see Figure 2) contains several trimming curves, expressed in Brzier (or rational 
Brzier) form. Regions enclosed by trimming curves are excluded from the patch. Point classification, 
in the context of trimmed patch ray tracing, is the problem of determining if a given point S in 8, t 
patch param- eter space lies IN the patch, OUT of the patch (in a region enclosed by trimming curves), 
or ON a trimming curve. If S is a point at which a ray intersects the patch, then S qualifies as a hit 
if it is IN, and as a miss if it is OUT. If S is ON a trimming curve, it is reported as a hit, but is 
flagged for possible anti-alias supersampling. Trimming curves completely enclose an OUT region. This 
may require linear Brzier curve segments along portions of the patch boundary (as in Figure 2). Recall 
a corollary of the Jordan curve theorem: If any ray R in s, t patch parameter space (not to be confused 
with a "tracing ray" in R 3) emanating from S intersects the collection of trimming curves an even (odd) 
number of times, then S is IN (OUT of) the patch. Our point classification algorithm amounts to an efficient 
method of determining that even/odd intersection parity. For this discussion, R points in the positive 
s direction. In practice, choose the ray in the :ks or ±t direction which exits the parameter square 
in the shortest distance, it might appear that ray/curve tangencies can cause a problem. As discussed 
in CASE/3 below, this is not a concern. The algorithm begins by splitting the patch parameter plane into 
quadrants which meet at S as shown in Figure 3. To determine if R intersects a given B6zier trimming 
curve an even or odd number of times, we categorize the curve based on which quadrants its control points 
occupy. For now, assume that no end control point lies on a quadrant boundary (a situation addressed 
in section 2.2.1). CASE A: All control points lie on the same side of the line containing R (in quadrants 
I, II, HI, IV, I&#38;II, or IH&#38;IV) or "behind" R ( in quadrants [I&#38;I1D. The convex hull property 
of Bdzier curves guarantees zero intersections with R. CASE/3: All control points lie in quadrants I&#38;IV, 
but not case A. Since the curve is continuous and obeys the convex hull property, if the curve endpoints 
lie in the same quadrant, the curve crosses R an even number of times. Otherwise, the curve intersects 
R an odd number of times. Note that tangencies be- tween the ray and trimming-curve tangencies, even 
those of high order, do not pose a problem. The only question is whether the curve endpoints strad- dle 
the ray. CASE C: All other curves. If a curve is case A or/3 no further processing is needed to de- 
termine its intersection parity with a ray. For a case C curve, we subdivide it using the de Casteljau 
algorithm[2] into three Brzier segments in such a way that the two end segments are guaranteed a priori 
to be case ,,4 or/3. The points at which to subdivide are determined using a technique we call Bdzier 
clipping, described 338 next. Discussion of the point classification algorithm resumes in Section 2.2. 
2.1 Brzier Clipping Figure 4 shows a Brzier curve C and the line L in s, t patch param- eter space C 
is defined by its parametric equation n C(u) = ~CiB~(u). (1) i=O C, = (si, t,) are the B6zier control 
points and B~(u) = (~)( 1 - u) ~-i u ~ denote the Bernstein basis functions. L is defined by its normalized 
implicit equation as + bt + c = 0, a 2 + b 2 = 1. (2) The intersection of L and C can be found by substituting 
equation 1 into equation 2: n d( u) = ~ d~B~( u) =0, di = asi + bt, + c. (3) i=O Note that d(u) = 0 
for all values of u at which C intersects L. Also, dl is the distance from Ci to L (as shown in Figure 
4). The function d(u) in equation 3 is a polynomial in Bemstein form, and can be represented as an "explicit" 
(or so-called "non- parametric") Brzier curve[l] as follows: n D(u) = (u,d(u)) = ~D~B~(u). (4) i=0 The 
Brzier control points D~ = (u~, d,) are evenly spaced in u (u, = ~). Since ~o ~B~(u) _--u[(1 u) + u] 
n z u, the horizontal coordinate of any point D(u) is in fact equal to the pa- rameter value u. Figure 
5 shows the curve D (u) which corresponds to the intersection in Figure 4. Since D (u) crosses the u-axis 
at the same u values at which C (u) intersects L, we can apply the convex hull property of Brzier curves 
to identify ranges of u for which C does not intersect L. Referring again to Figure 5, the convex hull 
of the Di intersects the u axis at points u = u~, = ~ and u = um~ = 3" Since D (u) lies inside the convex 
hull of its control points, we conclude that C does not intersect L in the parameter ranges 0 _< u < 
um~, or urea= < u < 1. Brzier clipping is completed by subdividing C into three segments using the de 
Casteljau algorithm[2]. Segment 1 is defined over 0 < u < u~i,, segment 2 over u~i~ < u < u .... and 
segment 3 over ureas < u < 1. 2.1.1 Rational Curves For rational Brzier trimming curves n C(~) = ~=o 
w~C~B?(u) (5) n with control point coordinates C~ = (s~, t~) and weights w,, the values of d~ must be 
modified as follows. Substituting equation 5 into equation 2 and clearing the denominator yields: n d(u) 
= ~ d,B~(u) = 0, d~ = w~(as~+ bt, + c). i=O  O SIGGRAPH '90, Dallas, August 6-10, 1990  2.2 Point Classification 
Algorithm Returning to the problem of point classification, our goal is to subdi- vide a case C curve 
into three segments, such that segments 1 and 3 are assured to be case A or/3. This can be accomplished 
by applying Brzier clipping against either the s quadrant axis (L = t -t~ = 0) or the t quadrant axis 
(L = 8 -s~ = 0) where the ray anchor S = ( s~, t~). If a case C curve is Brzier clipped against the 8 
quad- rant axis, the resulting curve segments 1 and 3 must be case A and segment 2 could be any case. 
If a case C curve is Brzier clipped against the t quadrant axis, the resulting curve segments 1 and 3 
must be case A or/3 and segment 2 could be any case. We should clip against the axis which will result 
in the smallest segment 2. A good heuristic for this is to measure the distance from the curve endpoints 
to each of the axes. Generally, the larger the distance from an axis, the larger the clip tends to be. 
Denote d~ = Idol + Idol for the case when L is the a quadrant axis, and dt = Idol + Idol when L is the 
t quadrant axis. Thus, ifd~ > dr, it is usually best to clip against s -s~ = 0. The complete point classification 
algorithm appears as follows. For clarity, we assume that the point is nearest the edge s = 1 in the 
parameter square, so we count intersections of the trimming curves with the ray in the positive s direction. 
If the distance from the point to one of the trimming curves is less than a tolerance value ON_TOL, the 
point is declared to be ON a trimming curve. ON_TOL= 10 -4 is conservative, and was used in producing 
Fig- ure 7. BEGIN CLASSIFY INPUT: Trimming curves, Point, ON_TOL OUTPUT: IN, OUT, or ON inter = 0 ; 
Push all trimming curves onto a stack; WHILE Stack not empty POP a curve; SIZE = largest dimension of 
the bounding box; Determine the case; CASE: A No action needed. /3 If the curve endpoints Co and Cn are 
in different quad- rants, increment inter. C If SIZE < ON_TOL, report ON and RETURN. Else if d~ _~ dr, 
perform Brzier clipping against L = a -a~ = 0. The resulting segments 1 and 3 are guar- anteed to be 
case ~A, so discard them. Push segment 2. Else, perform B~zier clipping against L = t -t~ = 0. Push all 
three segments. END CASE END WHILE If inter is odd, report OUT; else report IN END CLASSIFY. 2.2.1 Implementation 
A problem can arise when R happens to pass through an end control point shared by two trimming curves, 
because two intersections will be reported when one is often the correct answer. The solution we use 
is to perturb S away from R a sub-pixel distance <ON_TOE For the same reason, it is important that d(umi~) 
5 ~ 0 and d(u~) 5t 0 (in equation 4 and Figure 5) to within floating point precision. Therefore, make 
the adjustment u~, = 0.99 u~,~ and u~ = 0.99 Umaz + 0.01. Another reason for this adjustment is to 
avoid infinite loops. Brzier clipping a curve whose endpoint happens to lie on R (ie., do = 0 ) results 
in segments 1 and 2 having zero length, and segment 3 is simply the original curve. 340 2.3 Performance 
 ON is the classification which is most expensive to compute. Our algorithm can typically compute an 
ON classification to seven deci- mal digits accuracy in four Brzier clips. Figure 6 shows the trimmed 
patch in Figure 1, using color to indicate how many total Brzier clips were used in classifying each 
ray intersection. The average number of Brzier clips per point to be classified was 1.04 in this example 
involving ten trimming curves. Figure 7 shows a patch trimmed with precision by eight Brzier curves. 
3 RAY-PATCH INTERSECTION Our algorithm for computing the intersection of a patch with a ray uses the 
Brzier clipping concept to iteratively clip away regions of the patch which don't intersect the ray. 
The most costly single operation in a subdivision-based ray- patch intersection algorithm is de Casteljau 
subdivision. Typically, subdivision is performed in R 3 for non-rational patches, and in/~4 for rational 
patches. Woodward[20] (also alluded to by Rogers[ 10]) shows how the problem can be projected to R 2 
. This means that the number of arithmetic operations to subdivide a non-rational patch is reduced by 
33% (since subdivision is applied only to x, y com- ponents, rather than x, y, z) and for a rational 
patch is reduced by 25% (subdivision in x, y, w rather than in x, y, z, w). Section 3.1 re- views that 
projection, and further shows how the rational case can be handled by subdividing only two components. 
Section 3.2 then shows how to apply Bdzier clipping to itera- tively clip away regions of the projected 
patch which don't intersect the ray. 3.1 Projection to R 2 A rational Brzier surface patch in Cartesian 
three space ( ~, 9, 2) is defined parametrically by n m P(s,t) ~i=o ~]=o B~(s)B?(t)w,~Pij = (6) n rn 
~,=o ~j=o B?( a) B?( t)w,] where Pij = ( ~q, .yiy, ~ij) are the Bdzier control points with corre- sponding 
weights wq. (The symbols are hatted to later distinguish them from the projected (~, y) coordinate system). 
As does Kajiya[6], we define the ray to be the intersection of two planes given by implicit equations 
ak~+bk~+Ck~+ek=O, k= 1,2. (7) We assume that the plane equations are normalized: a~2 + ok-2 + ck2 = 
1 . In practice, it is best if the two planes are orthogonal. For primary rays, we use the scan plane 
and the plane containing the ray, parallel to the screen y axis. The intersection of plane k and the 
patch can be represented by substituting equation 6 into equation 7 and clearing the denomina- tor: d~( 
~, t) = B~( ~) B?( ~)d~ = 0 (8) i=0 j=0 where d~] = w~y( akz2ij + bk.~q + ck~,j + ek). (9) P(3,~) lies 
on plane k iffd~(3, ~) = 0. Note that dig is related to the distance from control point Pq to plane k: 
di~ = wq x DfSTANCE(Pq, Plane k) (10)   ~ Computer Graphics, Volume 24, Number 4, August 1990 We can 
now project the patch to a two dimensional ( x, y) coor- dinate system by taking the projected control 
point coordinates to be Pij = ( xq, Vii) = ( dilj, di3. ) (11) from equation 9. The projected patch is 
defined: n rn (12) i=O j=O In this projection, plane l becomes the y axis, plane 2 becomes the x axis, 
and the ray projects to the coordinate system origin, 0. Figure 8 shows a sample projected patch P ( 
s, t). i..t, .o'' I< I ~: ........ <."~:~.~, , X  Plane I Plane 1 I Figure 8: Projected patch P The 
ray-patch intersection problem now becomes one of finding ((s,t)lP(s,t)=O; O_~s,t_< 1}. (13) For a non-rational 
patch (that is, all w~] = 1), P is a simple or- thographic projection of P along the ray. P (8, t) is 
always non- rational (all its weights are equal), even if P (s, t) is rational. 3.2 BEZIER CLIPPING P 
This section applies B6zier clipping to the problem of finding all solutions to P(8,t) = 0. (14) Begin 
by defining a line L~ through 0 parallel to the vector Vo + Vt as shown in Figure 9. B6zier clipping 
will be used to identify ranges of the s parameter in which P (s, t) does not map to 0. If L~ is defined 
by its implicit equation ax+by+c=O, a2+b2 = 1 (15) then the distance Di] from each control point Pij 
= ( xi], yij) to L, is Dq = axl] + byq + c. (16) The Dq are shown in Figure 10. Likewise, the distance 
D(s, t) from L8 to any point P ( ~, t) on the projected patch is D( s, t) = B~( s) B~( t) Dij (17) i=O 
j=O The function d(s, t) can be represented, in an (s, t, d) coor-dinate system, as an explicit (or so-called 
non-parametric) surface o..t~"    <..<.Q~V1 ._° ..... , :~¢*"~ V0 s Figure 9: Line L, Ls Figure 10: 
Control point distances  SIGGRAPH '90, Dallas, August 6-10, 1990 patch[ 1 ] whose control points I)ij 
= ( ~ij, tij, Dij) are evenly spaced in 8 and t: s,j = ~, tiy= ~. A point on such a patch has coordinates 
D(~,t) = E B~(~)B~(t)i)q ; (.s,t,D(~,t)). (18) i=O j=0 The top view of this patch is shown in Figure 
I l, with control point D coordinates labeled. Compare those values with the distances in Figure 10. 
-2 -10~ _] ~ 7 ~' Figure 11: Top view of D ( s, t) patch. A side view of the D ( s, t) patch, looking 
down the t axis, is shown in Figure 12. The convex hull of the projected control points ~maz ! -8' 9' 
-10' Figure 12: Side view of D ( s, t) patch. bounds the projection of the D (s, t) patch. In this example, 
that convex hull intersects the s axis at points s,,~, = 2/5 and s .... = 2/3. We conclude that d(s, 
t) 5t 0, and therefore P (s, t) 51 0, for s < 2/5 and s > 2/3. The de Casteljau subdivision algorithm 
is applied to clip away those regions, leaving the two dimensional patch in Figure 13. This process of 
identifying values ~,~ and ~,,~ which bound the solution set, and then subdividing off the regions ~ 
< s,,,~ and > ~ will be referred to as B(zier clipping in ~. In an obviously similar manner, we define 
the process of B6zier clipping in t. Figure 13: First clip in s. Our ray-patch intersection algorithm 
consists of alternately per- forming B6zier clipping in s and t. Figure 14 shows the patch after B6zier 
clipping in s, then t, and again in s. The remaining sub- ~s°et ~ ~ ;; ~ rolen4e~U~ge~ott~enrsgntt~e~iiQ~rll;illla 
conditions. patch naC In practice, (In this c one should pick a tolerance value which assures sub-pixel 
accuracy. This is done by finding a bound on the largest first derivative of screen space z or y with 
respect to parameter space s or t.) How- ever, in computing t,,,~, t~ for the next t clip, it turns out 
that t~ -t,,.~ < 10 4. Without subdividing in t, we then compute ~m~.,s .... for an s clip, and discover 
that ~,~ -~ .... < l0 4 also. Thus, in the final step, we compute the intersection to within tolerance 
without actually subdividing to the clip values. The to- tal number of operations in this typical example 
is: s,,i,, s,,~ or t~i~, tm~ is computed five times, and three pairs of de Casteljau subdivisions are 
performed. 3.3 No intersection If a B6zier trim calculation determines 3.,,n > 1, S~a~ < 0, t.,,. > 1, 
or t.,~ < 0, the ray does not intersect the patch. It is possible to have t~a~ t.,~ < l0 4 and s ..... 
-~mi~ < 10 4, and yet the ray does not intersect the patch, However, this can only occur ifs,,,~ = 0,~ 
..... = 1, t,,,~ = 0, ort .... = 1. Whenever the subpatch lies on the boundary of the original patch. 
even if the tolerance criteria is satisfied, an additional B6zier clip ~ Computer Graphics, Volume 24, 
Number 4, August 1990 calculation should be performed to assure that the intersection does lie within 
the patch boundaries. 3.4 Multiple intersections If there are multiple intersections, Brzier clipping 
will not converge to a single value. Therefore, if a Brzier clip fails to reduce the pa- rameter interval 
width by at least, say, 20%, split the patch in half and resume Brzier clipping on each half. There is 
little theoreti- cal basis for this value of 20%. Empirically, 20% seems to provide nearly optimal performance 
in most cases. Execution speed is not highly sensitive to small changes in this 20% value, although for 
values less than 10%, excessive Brzier clipping can occur and for values greater than 40%, unnecessary 
binary subdivision can occur. The case of multiple intersections is illustrated in Figure 15. First, 
Brzier clipping in s discards regions labelled 1. In attempt- It 4 4 3 1 2 3 2 1 S Figure 15: Patch domain 
- two intersections ing to clip in t, it turns out that tm~ -t~n > 0.8. Therefore, the remaining domain 
is subdivided in half at t = 0.5. A stack data structure is used to store subpatches. We push one of 
the two sub- patches onto the stack, and proceed to process the other subpatch by Brzier clipping in 
s to eliminate regions 2 and clipping in t to remove regions 3. As in the example in Figure 14, without 
further subdivision we can compute the intersection which lies between re- gions 3 to within tolerance. 
There remains one subpatch on the stack, which we now pop and begin to process by clipping regions 4. 
The second intersection is refined in two more Brzier clips, as shown. 3.5 Primary Ray Preprocessing 
Brzier clipping can be used to advantage in a preprocessing step applied at the initialization of each 
scan line. By Brzier clipping P against the scan line in both s and t directions, regions of P can be 
discarded which do not intersect any primary ray along the scan line. Figure 16 shows the patch in Figure 
8 after Brzier clipping against the scan line (z axis). By performing this preprocess, a savings of up 
to two subdivisions per primary ray/surface intersection can be realized, and also non-intersecting rays 
can be detected more often. For example, in applying this preprocessing to rendering the teapot in Figure 
17, 86% of the calls to the intersection routine resulted in a hit. 3.6 Implementation To avoid potential 
infinite loops due to numerical roundoff, make the adjustment s~, = 0.99 Stain and sm~ = 0.99 s~ + 
0.0l Figure 16: Trimming to the Scan Line. and similarly for t in computing values at which to Brzier 
clip. Other than the ray/patch intersection algorithm, all of the other implementation details are standard. 
Antialiasing was performed using adaptive supersampling [5], and Murakami's voxel partition- ing [8] 
was implemented. Shadows, reflection and refraction are dealt with in the conventional manner, using 
our ray-patch inter- section algorithm. 4 DISCUSSION 4.1 Examples and Timings We tested the algorithm 
on an Iris-4D/70GT workstation and cre- ated Figures 17-20 at 500X500 resolution. Each figure caption 
lists the number of patches in the scene, total CPU time for rendering, (CPU time for rendering a similar 
scene, not antialiased, with pri- mary rays only), percentage of background pixels, and average num- 
ber of patch subdivisions per foreground pixel for primary rays. All patches are non-rational bicubics. 
The chains in Figure 19 were ori- ented using Free-Form Deformation[ 14]. 4.2 Performance Comparisons 
It is difficult to derive precise quantitative comparisons between various ray/patch intersection algorithms. 
The predominant single expense in most ray-patch intersection algorithms is de Casteljau subdivision. 
Our intersector spends 45% of its time computing sub- divisions. To split a projected two-dimensional 
bicubic patch in ei- ther parameter direction requires 144 floating point operations. All previous subdivision-based 
algorithms can take advantage of this projection to/~z (which, as mentioned, saves 33% of subdivision 
costs for non-rational and 50% for rational patches). We compared the number of subdivisions per non-background 
pixel required by our algorithm with the algorithms of Toth[ 18] and Woodward/20]. To attain three digits 
accuracy in s, t, Toth reported an average of 19.66 subdivisions for each non-background pixel in his 
Figure 6 (an example of a single patch in which roughly 30% of non-background pixels involve two ray-patch 
intersections). We duplicated the patch and viewing parameters for Toth's Figure 6 as nearly as possible, 
and tested our and Woodward's algorithms. The average number of subdivisions per non-background pixel 
is listed in Table 1. SUN SPARCstation I CPU times for 120X120 image are shown in parenthesis. It is 
difficult to make quantitative comparisons with the other published algorithms. Newton [17] and quasi-Newton 
[4] itera- ~ tion appear to converge quickly, but without actually implementing those algorithms, we 
cannot estimate the computational expense re- quired to assure robustness. 4.3 Higher Degree Patches 
This algorithm works on patches of arbitrary degree. However, since de Casteljau subdivision is an O( 
n 3) operation for surface patches, execution speed suffers as patch degree increases. A sam- ple bicubic 
patch containing a silhouette curve took 50 cpu seconds to render with 11.4 subdivisions per pixel. After 
elevating that same patch to degree four, the rendering took 94 cpu seconds with 11.2 subdivisions per 
pixel. The subdivisions per pixel tends to decrease with degree because the control polygon approximates 
the patch more closely as degree elevation is applied. Table 2 tallies the exe- cution speed for patches 
elevated up to degree eight. Degree 3 4 5 6 7 8 Seconds 50 94 130 186 243 322 suh/pixel 11.4 11.2 10.9 
10.9 10.7 10.7 Table 2: Higher Degree Patches Acknowledgements: The authors gratefully acknowledge the 
sup- port of Professor Nakamae of Hiroshima University in providing access to his computer graphics lab. 
The second author was sup- ported in part by the National Science Foundation under grant num- ber DMC-8657057. 
This work originated while the first author was visiting Brigham Young University, on leave from Fukuyama 
Uni- versity. REFERENCES 1. B0hm, Wolfgang, Farin, Gerald and Kahmann, Jurgen. A survey of curve and 
surface methods in CAGD. Computer Aided Geometric Design, 1, 1 (1984), 1-60. 2. Farin, Gerald. Curves 
and Surfaces for Computer Aided Geo- metric Design, Academic Press, 1988. 3. Glassner, Andrew ed., Introduction 
to Ray Tracing. Aca-demic Press, 1989. 4. Joy, Keneth and Bhetanabhotla, Murthy. Ray Tracing Para- metric 
Patches Using Numerical Techniques and Ray Coher- ence. Proceedings of SIGGRAPH '86 (Dallas, TX, August 
18-22, 1986). In Computer Graphics, 20, 4 (August 1986), 279-285. 5. Joy, Kenneth , Grant, Charles ,Max, 
Nelson and Hatfield, Lansing. Computer Graphics: Image Synthesis. Computer Society Press, 1988. 6. Kajiya, 
Jim. Ray tracing parametric patches. Proceedings of SIGGRAPH '82 (Boston, MA, July 26-30, 1982). In Com-puter 
Graphics, 16,3 (July 1982), 245-254. 7. Lane, Jeff and Riesenfeld, Rich. A Theoretical Development for 
the Computer Generation and Display of Piecewise Poly- nomial Surfaces. IEEE Trans. RAMI,2 (1980), 35-46. 
 8. Murakami, Koichi, Hirota, Katsuhiko and Ishii, Mitsuo. Fast ray tracing. Fujitsu Science and Technology 
Journal, 24, 2 (1988), 150-159.  Computer Graphics, Volume 24, Number 4, August 1990 9. Rockwood, Alyn, 
Heaton, Kurt and Davis, Tom. Real-Time Rendering of Trimmed Surfaces. Proceedings of SIGGRAPH '89 (Boston, 
MA, July 31 - August 4, 1989). In Computer Graphics, 23, 3 (July 1989), 107-117. 10. Rogers, Dave. Procedural 
Elements for Computer Graph- ics. McGraw-Hill, New York, 1985, 296-305. 11. Roth, Scott. Ray Casting 
for Modeling Solids. Computer Graphics and Image Processing, 18, 1982, 109-144. 12. Sederberg, Tom. 
An Algorithm for Algebraic Curve Inter- section. Computer-Aided Design, 21, 9 (1989), 547-554. 13. Sederberg, 
Tom and Parry, Scott. A Comparison of Three Curve Intersection Algorithms. Computer-AidedDesign, 18, 
1 (1986), 58-63. 14. Sederberg, Tom and Parry, Scott. Free-Form Deformation of Solid Geometric Models. 
Proceedings of SIGGRAPH '86 (Dallas, TX, August 18-22, 1986). In Computer Graphics, 20, 4 (August 1986), 
151-160. 15. Sederberg, Tom, White, Scott and Zundel, Alan. Fat Arcs: A Bounding Region with Cubic Convergence. 
Computer Aided Geometric Design, 6 (1989), 205-218. 16. Shantz, Mike and Chang, Sheue-Ling. Rendering 
Trimmed NURBS with adaptive Forward Differencing. Proceedings of SIGGRAPH '88 (Atlanta, GA, August 1-5, 
1988). In Com-puter Graphics, 22, 4 (August 1988), 189-198. 17. Sweeney, Michael and Bartels, Richard. 
Ray Tracing Free- Form B-Spline Surfaces. IEEE CG&#38;A, 6, 2, 1986, 41-49. 18. Toth, Dan. On Ray Tracing 
Parametric Surfaces. Proceed-ings of SIGGRAPH '85 (San Francisco, CA, July 22-26, 1985). In Computer 
Graphics 19, 3 (July 1985), 171-179. 19. Whitted, Turner. An Improved Illumination Model for Shaded 
Display. CACM, 23, 6, 1980, 96-102. 20. Woodward, Charles. Ray Tracing Parametric Surfaces by Subdivision 
in Viewing Plane. in W. Strasser and H.-P. Sei- del, editors, Theory and Practice of Geometric Modeling, 
Springer-Verlag, 1989, 273-290.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97917</article_id>
		<sort_key>347</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Generalized B-spline surfaces of arbitrary topology]]></title>
		<page_from>347</page_from>
		<page_to>356</page_to>
		<doi_number>10.1145/97879.97917</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97917</url>
		<abstract>
			<par><![CDATA[B-spline surfaces, although widely used, are incapable of describing surfaces of arbitrary topology. It is not possible to model a general closed surface or a surface with handles as a single non-degenerate B-spline. In practice such surfaces are often needed. In this paper, we present generalizations of biquadratic and bicubic B-spline surfaces that are capable of capturing surfaces of arbitrary topology (although restrictions are placed on the connectivity of the control mesh). These results are obtained by relaxing the sufficient but not necessary smoothness constraints imposed by B-splines and through the use of an n-sided generalization of B&amp;eacute;zier surfaces called S-patches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Spline and piecewise polynomial approximation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P43687</person_id>
				<author_profile_id><![CDATA[81100073180]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Loop]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39071131</person_id>
				<author_profile_id><![CDATA[81100493833]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[DeRose]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Boehm, Wolfgang. Cubic B-spline curves and surfaces in computer aided geometric design. Computing, 19:29-34, 1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Boehm, Wolfgang. Generating the B~zier points of B- splines. Computer Aided Design, 13(6):365-366, 1981.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>48484</ref_obj_id>
				<ref_obj_pid>48483</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Boehm, Wolfgang. Visual continuity. Computer Aided Design, 20(6):307-311, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[CatmulI, Edwin and James Clark. Recursively generated B-spline surfaces on arbitrary topological meshes. Computer Aided Design, 10(6):350-355, 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Charrot, Peter and John Gregory. A pentagonal surface patch for computer aided geometric design. Compnter Aided Geometric Design, 1(1):87-94, 1984.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801160</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chiyokura, Hiroaki and Fumihiko Kimura. Design of solids with free-form surfaces. Computer Graphics, 17(3):289-298, 1983.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[de Boor, Carl. B-form basics. In G. Farin, editor, Geometric Modeling: Algorithms and New 7kends, pages 131-148. SIAM, 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>912585</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[DeRose, Tony. Geometric Continuity: A Parametrization Independent Measure of Continuity for Computer Aided Geometric Design. PhD thesis, Berkeley, 1985. also available as Technical report UCB/CSD 86/255.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dog, Daniel and Malcolm Sabin. B~h~iou~ of r~~i~ division surfaces near extraordinary points. Computer Aided Design, 10(6):356-360, 1978.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>64563</ref_obj_id>
				<ref_obj_pid>64557</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gregory, John and JSrg Hahn. A C9 polygonal surface patch. Computer Aided Geometric Design, 6(1):69-75, 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gregory, John. N-sided surface patches. In J. Gregory, editor, The Mathematics of Surfaces, pages 217- 232. Clarendon Press, 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282923</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Guibas, Leo and Jorge Stolfi. Primitives for the manipulation of general subdivisions ~nd the computation of voronoi diagrams. A CM Transactions on Graphics, 4(2):74-123, 1985.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94435</ref_obj_id>
				<ref_obj_pid>94424</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hahn, JSrg Filiirtg polygonal holes with rectangular patches. In W. Strasser and H.P. Seidel, editors, Geometric Modeling: Algorithms and New Trends, pages 81-91. Spring-Verlag, 1989.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Herron, Gary. Triangular and Multisided Patck Schemes. PhD thesis, U. of Utah, 1979.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5100</ref_obj_id>
				<ref_obj_pid>5096</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Herron, Gary. Smooth closed surfaces with discrete triangular interpolants. Computer Aided Design, 2(4):297- 306, 1985.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Herron, Gary. Techniques for visual continuity. In G. Farin, editor, Geometric Modeling, pages 163-174. SIAM, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Hosaka, Mamoru and Fumihiko Kimura. Non-four-sided patch expressions with control points. Computer Aided Geometric Design, 1(1):75-86, 1984.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>77059</ref_obj_id>
				<ref_obj_pid>77055</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Loop, Charles and Tony DeRose. A multisided generalization of B~zier surfaces. A CM Transactions on Graphics, 8(3):204-234, 1989.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sabin, Malcolm. Non-rectangular surface patches suitable for inclusion in a B-spline surface. In P. ten Hagen, editor, Proceedings of Eurographics '83, pages 57-69. North- Holland, 1983.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Sablonniere, Paul. Sptine and B6zier polygons associated with a polynomial spline curve. Computer Aided Design, 10(4):257-261, 1978.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>19102</ref_obj_id>
				<ref_obj_pid>19101</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[van Wijk, Jarke. Bicubie patches for approximating nonrectangular control-point meshes. Computer Aided Geometric Design, 3(1):1-13, 1986.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>66820</ref_obj_id>
				<ref_obj_pid>62847</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Varady, Tamas. Survey and new results in n-sided patch generation. In R. Martin, editor, -The Mathematics of Surfaces II~ pages 203-236. Oxford University Press, 1987.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Generalized B-spline Surfaces of Arbitrary Topology 
Charles Loop and Tony DeRose University of Washington Abstract B-spline surfaces, although widely used, 
are incapable of de- scribing surfaces of arbitrary topology. It is not possible to model a general closed 
surface or a surface with handles as a single non-degenerate B-spline. In practice such surfaces are 
often needed. In this paper, we present generalizations of biquadratic and bicubic B-spline surfaces 
that are capable of capturing surfaces of arbitrary topology (although restrictions are placed on the 
connectivity of the control mesh). These re- sults are obtained by relaxing the sufficient but not necessary 
smoothness constraints imposed by B-splines and through the use of an n-sided generalization of B6zier 
surfaces called S- patches. CR Categories and Subject Descriptors: 1.3.5 [Com-puter Graphics]: Computational 
Geometry and Object Mod- eling-curve, surface, solid, and object representations; J.6 [Computer-Aided 
Engineering]: Computer-Aided Design (CAD); G.1.2 [Approximation]: Spline Approximation. Additional Key 
Words and Phrases: Computer-aided ge- ometric design, B-spline surfaces, n-sided patches, geometric continuity. 
Introduction Parametric surfaces have proven themselves an excellent tool for representing smoothly 
varying sculptured objects. B-splines have emerged as the polynomial basis of choice for working with 
parametric surfaces. However, the current the- ory of B-splines has serious shortcomings when modeling 
gen- eral closed surfaces or surfaces with handles. A B-spline surface is a deformation of a planar domain, 
tessellated into a regular grid of rectangles. It is quite natural for the surface to be treated as a 
collection of tensor product polynomial patches defined over these rectangles. This leads to notions 
of parametric continuity (denoted C k continuity), where smoothness is defined in terms of matching derivatives 
along patch boundaries. It is precisely this treatment that limits the possible topologies of a B-spline 
surface. This work was supported in part by the Xerox Corporation, IBM, Hewlett-Packard, the Digital 
Equipment Corporation, and the National Science Foundation under grants CCR-8957323 and DMC-8802949. 
Authors' address: Department of Computer Science and Engineering, FR-35,. University of Washington, Seattle, 
WA 98195. Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
A more general view considers the spline surface to be a collection of (possibly rational) polynomial 
maps from in- dependent n-sided polygonal domains, whose union possesses continuity of some number of 
geometric invariants, such as tangent planes. In this view, patches are required to meet with geometric 
continuity (denoted G k continuity), a measure of continuity that subsumes strict parametric continuity. 
This more general view allows patches to be sewn together to de- scribe free form surfaces in much richer 
and more complex ways. The n-sided element we use is the S-patch developed in [18]. Using the S-patch 
form, our surfaces possess many desir- able properties. One of the most important of these properties 
is that S-patches generalize both Bdzier tensor product and triangular patches, meaning that an S-patch 
based geomet- ric modeler is compatible with existing popular patch types. Since all S-patches are instances 
of a single general structure, algorithms may be derived that are independent of the number of sides 
n, leading to uniformity and simplicity. This dispels the notion that inclusion of n-sided patches into 
a geomet-ric modeler would increase complexity due to an increase in special cases. The S-patch form 
is more complicated than ten- sor product forms. However, it is also very structured, so we believe the 
increase in generality offsets the increase in com- plexity. By relaxing C 1 continuity to G 1 continuity, 
and by allow- ing n-sided S-patch elements, we obtain more general spline methods that contain B-spline 
surfaces as a proper subset. Just as for B-splines, our more general surfaces are created as smooth approximations 
to control meshes. By a control mesh we mean a collection of control points, or, synonymously, con-trol 
vertices, together with connectivity information used to define edges and faces. ? Here we offer two 
methods for trans- forming control meshes into G 1 spline surfaces. The methods differ in the connectivity 
restrictions placed on the control mesh. The first method is a generalization of biquadratic B- splines; 
it requires the control mesh to be constructed entirely from four sided faces, although any number of 
faces may meet at a vertex. The second method is a generalization of bicubic B-splines; it requires that 
exactly four faces meet at a vertex, although faces may contain any number of edges. There are two reasons 
for the choice of restrictions on the control meshes. First, the restrictions are sufficiently relaxed 
to describe surfaces of arbitrary topology. Second, the restric- tions are sufficiently strong to guarantee 
that all our surfaces have exactly four patches meeting at each interior corner. This specialization 
is exploited to yield a simple solution to the "twist compatibility" problem, a system of constraints 
that arises at interior corners. These schemes, therefore, retain the tA control mesh is more precisely 
defined as a subdivision of a topo- logical 2-manifold, possibly with boundary [12]. simple design features 
while overcoming the severe topologi-cal restrictions of traditional B-spline methods. It should be emphasized 
that these schemes are generalizations of nniform B-splines, although the extensions to the non-uniform 
and ra- tional cases (NURBs) pose no fundamental difficulties. 1.1 Overview After a review of previous 
work, given in Section 2, and a re- view of the basic properties of S-patches, given in Section 3, the 
principal results of this work are presented in a bottom up fashion. In Section 4, we solve the n-sided 
hole problem using S-patches. In this problem the existence of an n-sided hole surrounded by polynomial 
patches is assumed. The ob-jective is to find a single S-patch that meets the surrounding patches with 
G ~ continuity. In Section 5, we use the solution of the n-side hole problem to define a patch representation 
that mimics the relatively simple continuity requirements of B~zier tensor product patches. Hence these 
patches are easy to join together with G 1 continuity. In section 6 we presents the two generalized B-spline 
schemes for modeling surfaces with arbi- trary topology. Like B-splines, both of these schemes produce 
surfaces that are smoothed versions of control meshes. Unlike B-splines, however, our control meshes 
are capable of model- ing surfaces of arbitrary topology. Finally, in Section 7, we offer some concluding 
remarks and directions for future work. 2 Previous Work When modeling with B-spline surfaces, a common 
way to sub- vert the topological constraints is to introduce degeneracies into the control meshes. This 
amounts to collapsing one or more edges of the control mesh to a point, resulting in one or more 3-sided 
faces. This causes an irregularity in the param- eterization, meaning that partial derivatives are not 
linearly independent. Degeneracies of this sort introduce various prob- lems, such as calculating normal 
vectors. In an effort to find more robust solutions, a significant amount of recent work has been done 
in the areas of geometric continuity, non-tensor product patches, and generalizing B-splines. It has 
been shown (c.f. Herron [15]) that it is impossible to construct closed, non-degenerate C 1 surfaces 
of arbitrary topology. One solution to this is to replace parametric con-tinuity with geometric continuity, 
a topic that has received substantial study in recent years (cf. [3, 8, 16]). To address the problem 
of irregular patch networks, many non-tensor product patches have been developed. These in-clude the 
n-sided patches developed by Sabin [19], and ttosaka and Kimura [17], which are limited to at most 5 
and 6 sides re- spectively. The patch described by Gregory [11] is not limited in the number of sides, 
and is similar in spirit to the Coons patch. Other true n-sided patch representations have been proposed 
by Herron [14], and by Varady [22]. The Gregory Patches of Chiyokura and Kimura [6] are generalizations 
of B~zier tensor product patches that contain (removable) sin-gularities at patch corners. Several generalizations 
of B-splines have been proposed. The earliest of these are the recursive subdivision schemes of Doo and 
Sabin [9], and Catmull and Clark [4]. These methods allow arbitrary control meshes and generally produce 
pleasing surfaces; however, the surfaces are defined as the limit of a local averaging procedure and 
do not, in general, possess a closed form parameterization. A generalization of B-splines that makes 
use of parametric surfaces has been found by van Wijk [21]. This scheme uses tensor product patches exclu-sively 
and imposes relatively strict requirements on the form of the control mesh. 348 3 S-patches As mentioned 
in Section 1, the generalized B-spline schemes are based on S-patches. S-patches refer to a generalization 
of B6zier surfaces where any number n of boundary curves are permissible. The underlying theory has been 
established elsewhere [18]. In this section, we briefly summarize the results necessary to develop the 
generalized B-spline schemes. As is shown in [18], S-patches possess a rich structure, largely because 
they are defined in terms of multivariate Bern- stein polynomials and Bdzier simplexes. It is therefore 
conve- nient to begin with a discussion of B~zier simplexes. In what follows, multi-indices will be denoted 
by italic characters with a diacritical arrow, as in ~. Multi-indices are tuples of non-negative integers, 
the components of which are subscripted starting at one; for instance, ~= (il, ..., i~+l). The norm of 
a multi-index ~, denoted by [~[, is defined to be the sum of the components of ~. The symbol gj denotes 
a multi-index whose components are all zero except for the jth component which is one. Addition, subtraction 
and scalar multiplication of multi-indices are defined componentwise. By setting ~= (il,...,i~+1) and 
requiring [~1 = d, the k- variate Bernstein polynomials of degree d can be defined by BT(.,,...,.,+,) 
= tr) , ,= where (~) is the multinomial coefficient defined by = il! i2! ...ik+t!' and where ul, ..., 
uk+t are real numbers that sum to one. It is known [7] that for every polynomial Q : X1 ~ X2 of degree 
d, where XI is an affine space of dimension k and X2 is an affine space of arbitrary dimension, there 
exist unique points V r E X2, 13 = d, such that Q(u) =-E ViB](ul,..., uk+l), (1) where ul, ..., ut+l 
are the barycentric coordinates of u E X1 relative to a simplex A = {vl,...,vl+l}. (A k-simplex is a 
collection of k + 1 points such that none of the points can be written as an affine combination of the 
others. For example, the points of a 2-simplex form a triangle, and the points of a 3-sirnplex form a 
tetrahedron.) Summations such as the one in Equation 1 are intended to be taken over all multi-indices 
whose norm matches the degree of the Bernstein polynomial. Thus, in Equation 1, the multi-index Y is 
to take on all values such that [~'[= d. A polynomial Q, when expressed as in Equation 1, is called a 
B(zier simplex. The points V77 are called the control net, and ,~ is called the domain simpler. S-patches 
build on the theory of B6zier simplexes as fol- lows. An n-sided S-patch S is a mapping from a domain 
n- gon P and is conceptually constructed in two phases: first, P = {~,...,Pn} is embedded into an intermediate 
domain simplex A = {vl, ..., vn) contained in an affine space Y of di- mension n - 1; next a B6zier simplex 
is created using A as its domain; finally, S is defined as the composition of the embed- ding and the 
B6zier simplex.. That is, if L : P ~ zl represents the embedding, and if B : ~ --~ N 3 is the B6zier 
simplex, then S(p) = B o L(p), p E P, (2) as indicated in Figure 1.  @ ~ Computer Graphics, Volume 
24, Number 4, August 1990  Pn~v 2 V I S v0 /ullUvoii°ll°° Pl P: Figure 1: Schematic representation 
of S-patches. To describe the embedding L we use to map the domain polygon P into the intermediate simplex 
A, we first introduce several helpful definitions. Let cti(p) denote the signed area of the triangle 
PPiPi+i, where the sign is chosen to be positive if p is inside P. (Note: all indices are to be treated 
in cyclic fashion.) Let = l(p)  (v) .- for i = 1, ..., n, denote the product of all areas except 
for oq-1 and ai, and let e (p) = l(p) +... + ..(p)" With these definitions, every point p E P is mapped 
by L into the point L(p) = el (p)v'l + e2(p)v~ +... + g,(p)v,~, (3) in Y. This embedding has the important 
property that it is edge-preserving, meaning that if p lies on an edge of P, then L(p) lies on an edge 
of z~; additionally, the interior of P is mapped into the interior of ~ [18]. If V~ denotes the control 
net of a B6zier simplex B, then an S-patch S is defined as S(p) = B o L(p) = Z V~B~(gl (p), ..., gn(P)). 
(4) REMARK : The definition of S-patches given in Equation 4 is a slight specialization of the definition 
given in [18], since in that work B was allowed to be a rational B&#38;zier simplex. For brevity and 
simplicity, we have chosen not to introduce this additional complication here. The integer d in Equation 
4 is known as the depth of the S-patch, to avoid confusion with the polynomial degree of the patch, which 
is d(n -2). The control net V t is taken as the control net of S, an example of which are shown in Figure 
1. S-patch control nets consist of interconnected n-sided closed polygonal panels. For instance, in Figure 
1 the points V20000, Vll00O, Vim00, Vl0mo, Vlo0m form one such panel. The compositional structure of 
the S-patch S together with the edge-preserving character of the embedding L endows the S-patch representation 
with a number of useful properties, including (see [18] for proofs): Points on S can be computed using 
the multivariate ver- sion of deCasteljau's algorithm.  Boundary curves are in B~zier form, implying 
that boundary curves can be individually controlled. For in- stance, referring to Figure 1, the boundary 
curve cor- responding to the bottom boundary of the control net is a quadratic B~zier curve whose control 
points are V20o00, Vl10o0, Vo2o00. Control points such as these are called boundary points.  The panels 
of a control net that contain boundary points are termed boundary panels. The tangent plane varia- tion 
along a boundary curve is determined entirely by the corresponding boundary panels. Referring again to 
Figure 1 for example, the tangent plane along the bot- tom boundary of the control net is entirely determined 
by the two panels V2oooo, Vlxooo, Vloloo, Vloolo, Vloool and VlloOO, Vo2ooo, VOll0O, Vol01O, Polo01. 
  O SIGGRAPH '90, Dallas, August 6-10, 1990 \ / Pi t i Pi + 1 Figure 2: Patches Ft, ..., F, surrounding 
a n-sided hole. Given an S-patch control net of depth d describing a patch S = B o L, the S-patch control 
net of depth d + 1 for S can be constructed by executing the B ~zier simplex degree raising algorithm 
on the control net of B. Thus, S-patch control nets can be depth elevated.  If P is a regular n-gon, 
and if Q is a polynomial patch in triangular B4zier form defined over some domain triangle T, then there 
is a simple algorithm for representing Q in S-patch form over P, referred to as the polynomial representation 
algorithm.  When n = 3, the S-patch form reduces to the standard B6zier triangle, and when n = 4, S-patches 
coincide with B~zier tensor product patches.  4 The N-sided Hole Problem The n-sided hole problem arises 
in situations such as the one shown in Figure 2 where polynomial patches surround an n- sided hole. The 
objective is to construct a surface patch that fills the hole and meets the surrounding surfaces with 
at least G 1 continuity. Although this problem has been identified as an interesting problem in its own 
right [5, 10, 13], our reason for introducing and solving it here is two-fold: first, our so- lution 
fills the hole with a single S-patch; second, in Section 5 the solution is used to define a patch representation 
that is particularly convenient for developing the generalized B-spline schemes. Referring to Figure 
2, the hole to be filled is assumed to be surrounded by n patches Fi, ..., Fn, typically given in tensor 
product form; we wish to construct a single S-patch H that matches the surrounding patches with' positional 
and tangent plane continuity. We shall find it convenient to introduce the following notation: The boundaries 
of the hole are given by F~(ui, 1), i = 1,...,n, as indicated by Figure 2.  The domain polygon P of 
H is a regular n-ton with ver- tices P1,...,P,. (Let ~/ be the vector from p~ to P~+t, and let Ei denote 
the i *h edge of P, that is, Ei(ti) =   (1 -ti)p, + tip,+l, ti e [0, 1].) We assume that the patches 
surrounding the hole satisfy the following "twist compatibility" conditions: (A0) Fi_l(t, 1) = F~(0, 
t) (A1) OFi-lDui_l(1,1) = -~(0,1) (A2) aF,_lav,_ = 1 (1,1) ~:(0,1) (A3) ' We additionally assume that 
the patches are regular in the sense that partial derivatives are everywhere linearly indepen- dent. 
Positional continuity of H with the surrounding surfaces is simply achieved by requiring that H(Ei(ti)) 
= Fi(t~, 1), ti 6 [0, 1], for each i = 1, ..., n. Differentiating this with respect to ti implies that 
OFt. D~'~ H(Ei(t,)) = ~u (t~, i), ti 6 [0, i], (5) where D~ f(p) denotes the directional derivative 
of f in the direction g at the point p. We also require that H meets the surrounding surfaces with G 
1 continuity. Along the i ~h edge Ei this is equivalent to the existence of functions p,v : [0, 1] ~ 
~ such that . aFi D f~_, H(Ei(ti)) = #(ti)~ui(Q, 1) + y(ti) (ti, 1), (6) for all ti 6 [0, 1]. This equation 
states that at each point on El, a cross boundary derivative of H, in this case taken in the direction 
of-~/-1, should be in the tangent plane of Fi, and hence should be expressible as a linear combination 
of Fi's first order partial derivative vectors. Conditions 5 and 6 are therefore sufficient (and in fact 
necessary) to guarantee that H and Fi share a common tangent plane along their common boundary curve 
(cf. Herron [16]). The principal difficulty in constructing H is in determin- ing the functions/g and 
v. The general approach is to find a set of constraints on these functions that are sufficient to guar- 
antee that an S-patch form for H can be constructed subject to the V 1 continuity condition of Equation 
6. Once the con- straints have been determined, we construct # and v as the minimal degree polynomials 
that satisfy the constraints. It ~ Computer Graphics, Volume 24, Number 4, August 1990 Pi-1, Pi Pi+l 
 Figure 3: Boundary panels of the S-patch H. turns out that six constraints are sufficien L and that 
the con- straints are linear in the polynomial coefficients ofp and u. By choosing # and t, to be quadratic 
polynomials, six unknowns are introduced, and hence a unique solution to the system can be found. Our 
goal now is to determine these constraints. REMARK : Equation 6 implies that the same functions #, u 
are used for every edge since # and u do not appear in the equation with an i subscript. This appears 
to be an unnec-essary assumption. However, allowing p and u to differ from edge to edge introduces no 
new flexibility. Instead, what oc-curs is that a linear system of 6n equations in 6n unknowns is required, 
so again the solution is unique, and is such that the resulting functions are the same for each edge. 
The first two constraints on # and u are determined by setting ti = 0 in Equation 6, and using Equation 
5 together with (A1) to give OFi(o'l)ovi= p(O)~.~-(O, 1) + u(O).-~-(O, 1). It is therefore sufficient 
for ~(0) = 0 and u(0) = 1. These two constraints were found by restricting a condition imposed along 
Ei to the corner corresponding to Pl. The next two constraints follow by restricting to pi a condition 
imposed along the edge Ei-1. To do this, we require an expression for D~, H(Ei-a(ti-1)) in terms of Fi-1, 
Fi, # and u. The required expression can be found by noting that since P is a regular n-gon, -{'-1 = 
-2cos ~ + t~+l. Linearity of directional differentiation therefore implies that D_~i_ i H tl = -2cos 
~-r-D- H + . D~.~+iH. Substituting this expression into Equation 6, replacing i by i- 1, and solving 
for Dg~ H(Ei-1(ts-1))yields ~)OFi-1 (ti 1, I) Dr. H(Ei-l(ti-1)) = (U(ti-1) -1- 2cos OUi_ 1 - OFi-I. 
1). (7) The restriction of this equatiori to the point pi is achieved by setting ti-1 to one. Doing this, 
and using D~ H(pi) = 0F~_~ (0 1), allows us to deduce that it is sufficient for p(i) , =~':-~'- ~ -2cos-~ 
and u(1) = 1. The final two constraints on p and u follow from the fact that since H is sought in S-patch 
form, H must be twice dif- ferentiable everywhere on P. In particular, the order of differ- entiation 
should not matter, meaning that p and u must be constructed so that Dr,_, Dr, H(pl) = Dr, Dr,_, H(p,). 
(8) The left hand side of Equation 8 is expanded by differentiat- ing Equation 6 with respect to re-l, 
and the right hand side is expanded by differentiating Equation 7 with respect to ti. This process, together 
with (A3) is used to show that it is sufficient for t~'(O) = -u'(1) and g'(1) = u'(O), where prime denotes 
the first derivative. To summarize, # and r, must satisfy the following con- straints:  u(o)=o, ~(o)= 
1, W(o) = -~'(0, g'(1)=u'(0). This system is solved uniquely if p and u are assumed to be quadratic polynomials. 
In Bernstein form, the solution is ,(t) = -cos ~s~(t) -2cos ~-_~, ,, u(t) = Bo2(t) + (1-cos ~)B1(t ) 
+ B~(t), where B~(t) = (~)ti(1 -t) 2-i. Closer inspection of, shows that it is actually a linear polynomial. 
Additionally, notice that in the case n = 4, p reduces to the zero polynomial and u becomes identically 
one, indicating that H meets the surrounding four surfaces with strict C 1 continuity. ttaving determined 
~ and v as above~ the position and differential of H around the perimeter of P are completely determined 
by Equations 5 and 6. H then can be represented in S-patch form on P as follows: 1. The restriction of 
H and its differential to each edge Ei is found in triangular Bernstein form on the triangle pi-lPipi+l. 
This requires only straightforward manipula- tion of Bernstein polynomials since each of the functions 
appearing in Equations 5 and 6 is known in Bernsteiu form. The result of this step is a collection of 
triangular panels along each edge, as shown in Figure 3. Specific formulas relevant to our constructions 
are given in Sec- tion 5. SIGGRAPH '90, Dallas, August 6-10, 1990 2. For each triangular panel computed 
in step 1, and for each edge Ei, find the image of .P under the affine map that carries pl-tpipi+i to 
the vertices of the panel, as indicated in Figure 3. The polynomial representation algorithm for S-patches 
mentioned in Section 3 guarantees that the collection of interlocking n-gons thus formed represent H 
and its differential around the perimeter of P. 3. To complete the S-patch representation of H, the 
remain- der of the S-patch control net, consisting of all interior control poinls, i.e. those that do 
not contribute to posi- tion or differential around the perimeter of P, must be determined. These points 
can therefore be set arbitrarily without influencing the G i join between H and the sur- rounding surfaces. 
Of course, an intelligent choice for the interior points must be made to avoid unwanted ripples in H 
away from the boundaries. A method for setting the interior points that works well in practice is given 
in Section 5.  5 Sabin nets In preparation for the generalized B-spline schemes of Sec- tion 6, we recast 
the n-sided hole problem in terms of a self contained control point representation. We call this represen- 
-tation the Sabra net, due to its connection to the representa- tions proposed by Sabin [17, 19] *. Figures 
4 and 5 illustrate quadratic and cubic Sabin nets respectively. Intuitively, Sabin nets are used to construct 
the boundary data needed by our solution to the n-sided hole problem. An S-patch is then con- structed 
using the method of Section 4. The procedure to create an S-patch, given a Sabin net, is thus a three 
step pro- cess: i) Construct boundary data from the Sabin net. ii) Construct S-patch boundary panels 
as in Section 4. iii) Construct the interior S-patch control points. In Section 5.1, these steps are 
elaborated for the case of quadratic Sabin nets; Section 5.2 describes the case of cubic Sabin nets. 
5.1 Quadratic case qi+l Figure 4: A quadratic Sabin net. The first step is to convert the quadratic Sabin 
net into an instance of the n-sided hole problem. Assume the Sabin net The only difference is that we 
do not tim.lt the number of sides. labeling of Figure 4. The n boundary data functions are con- structed 
as follows: Fi(ui, 1) = qiBo2(ui) + piBt2(ui) + qi+lB~(ul), OFi. Ovi(Ui'l) = 2[(p,_l -ql)Bo2(Ul) + (v 
-pl)B~(ui) "4" (Pi+I -qi+l)B2~(ui)]. It is not difficult to show that these functions satisfy conditions 
(A0) through (A3). Next, triangular boundary panels of an S-patch H are computed by step 1 of Section 
4. From Equation 6 we see that o°~u~(ul,1), ~vF (ui, 1), p(tl), and u(ti) are at most quadratic functions; 
this implies that D~,_a H(E(ti)) is at most quar- tic, and therefore H(E(ti)) is at most quintic. This 
shows that the S-patch H must be at most depth 5. Let the h;, denote control points of H. Working through 
the details of step 1, the following formulas are found for the boundary panels of H up to symmetries: 
h5~i = qi h4~+ ~,+ 1 = 3 2 ~qi + ~Pi h3g,+2g,+l = ~0qi + i~Pi + l~q/+l 1-c 1-c h3~ +g,+~+g~_~, = "~' 
+ -~--Pi + -g'-Pi-i + ~_2.~,~.5 ~v h2~+:z,+~+~,_l = Lt_.~-L~.-. 1 30 qi+ is P= + ~Pi+i 1-4¢ _ ~...._...~. 
v 4+ --~--~i+l + ~P~-i +  where c = cos-~-, and i = 1...n. The remaining boundary panel points of H 
may be found using step 2 of Section 4. Constructing the boundary panels does not, in general, completely 
determine H. The remaining degrees of freedom are the positions of interior S-patch control points. The 
pro- cedure for finding positions for the interior points of H is as follows: 1. Define a depth 2 S-patch 
A whose boundary control points match those of the Sabin net. Let ar denote the control points of A. 
This step is algorithmically estab- lished by fori ~ lton a2e~ ~ qi a~,+g~+l ~ Pi end for 2. The remaining 
control points of A are found as convex combinations of the control points of the Sabin net so that A 
approximates the desired shape of H. The following algorithm is used for this purpose for i ~ 1 to n 
forj --2to [~-J if odd(j) then 7f" . ac,+r(,+j) ~--- (1 -- cos u )v + cos "~'P(i+l~J) else a~.+~o+j) 
~-- (1 -- cos ~-)v + cos "~'q(i+[}J) end if end for end for. 3. The S-patch A is then depth elevated 
from depth 2 to 5 to match the depth of H.   ¢ Computer Graphics, Volume 24, Number 4, August 1990 
4. The (unknown) interior control points of H are equated to the (known) interior control points of A. 
The justification for this procedure is that the lower depth S- patch A has fewer unknown control points 
than H; it should therefore, be easier to find geometric constructions for these points, and the resulting 
surface should have fewer undula- tions than a higher depth patch. It i.s not difficult to see that 
in the case n = 4, the Sabin net and the patch A are identical. The resulting surface is the usual tensor 
product biquadratic, although parameterized as a biquintic. 5.2 Cubic Boundary Case  Ci-I,I~ ci_  q,4y-q---- 
Ci,1 ci,2 Ci.+. 1 -~'---s Ci-Fl,1 Figure 5: A cubic Sabin net. Let the cubic Sabin net be labeled as 
in Figure 5. The n boundary functions of the n-sided hole problem are computed as follows: Fi(ui, 1) 
= c,,1B0a(u,) + c,,~B~(u,) + e,+x,,B?(u,) + OFi(u¢, 1) = 3[(e,,4-ci,~)Bo~(U,) Ovl + ¢,,=)B?(u,) + + 
Once again, it is not difficult to verify that these functions also satisfy conditions (A0) through (A3). 
 The boundary panels of H are again computed by step 1 of Section 4. A degree argument similar to the 
one used in Sec- tion 5.1 shows that H must be a depth 6 S-patch. Completing step 1 leads to the following 
formulas: 1 1 hst,+¢~+, = ~ci,1 --I- ~ci,2 h4g, +2g,+ * = 1 C 3 1 i,1 + ~ei,2 + ~ei+t,4 9 . 1 1--c 3~4c 
~ l--c h4g,+~+,+~._, : ~ci,3.4- ---U-ci,4 + 10 ~1,1 + -'6--ei,2 h3g~+2g',+z +g,- t = a-sc . -.~--ci,a 
-1- 2~ci,4.4- 3+4c 20 ul, 1 3 1--4e + -~ci,2 q" ~-6ci+La + "~'-~i+L¢ where c = cos ~ and i = 1...n. The 
remaining boundary panel points of H may be computed as in step 2 of Section 4. The unknown interior 
points of H are computed by a pro- cedure analogous to that of the quadratic case. Let A be a depth 3 
S-patch. Again, the boundary control points of A are equated to the boundary control points of the Sabin 
net. This is stated algorithmically as forl ~--- lton a2g.+~_, ~--Ci, 4 a3~ i +-- Ci, 1 a2~i+~i+, ~ Ci, 
2 end for Next, we compute the remaining control points of A. Let the Sabin net control points e1,3, 
e2.3,..., c~,3 be treated as the control points of a depth I S-patch .4. Let wr be defined by itpl + 
i2p2 + " + inpn n where 1~ = 3. The domain of A is taken to be the polygon w~,+e~+~,,wtt+~.2+es,...,wt~_,+¢~+~. 
The remaining con-trol points of A are found as follows for all wr ~ boundary(P)   ar (wr) end for 
The surface represented by A is now depth elevated from 3 to 6, and the (unknown) interior points of 
H are equated to the (known) interior points of A. In the case n = 4, A and the Sabin net are identical, 
im- plying that the resulting patch H is a tensor product bicubic, parameterized as a bisextic.  6 Generalized 
B-spline Schemes We now present two schemes for modeling surfaces with ar-bitrary topology: one is an 
generalization of biquadratic B-splines , the other a generalization of bicubic B-splines. Like traditional 
B-spline methods, these schemes take as input a control mesh that roughly approximate the desired shape, 
pro- ducing as output a smooth spline surfaces. These schemes are inspired by the close relationship 
be- tween the control points of B-spline and B6zier representa- tions. The essence of this relationship 
is that the B6zier con- trol points may be found by local averaging of the B-spline control points. Such 
a construction was first presented by Sablonni6re[20] for curves, and later by Boehm [1, 2] for B- spline 
surfaces. Here, we present analogous constructions for computing Sabin net control points by a local 
averaging of the input control mesh. Adjacent Sabin nets are constructed to share the same boundary position 
function, Fi(ui, 1), and cross boundary tan- gent vector function -~.-.Ei-tu. 1) (up to a constant scale 
fac- 0vi k s~ tot), corresponding to the common boundary. The resulting S-patches, constructed by the 
method of Section 5, are thus guaranteed to meet with G 1 continuity. The conditions that adjacent Sabin 
nets must satisfy in order to share the same boundary data functions are easily described. Equivalent 
boundary position for adjacent Sabin nets is achieved by sharing boundary points. To share equiva- lent 
cross boundary tangent vectors, the three rows of control points parallel to the boundary must be co-linear 
and form identical affine segments (see Figures 6 and 7). These con-ditions are equivalent to the usual 
C 1 conditions for B6zier tensor product patches.   G SIGGRAPH .'90, Dallas, August 6-10, 1990 6.1 
Generalized Biquadratic Scheme A control mesh for the generalized biquadratic scheme is re- stricted 
to 4-sided faces, but a vertex can be shared by any number of faces. There is a one to one correspondence 
be- tween vertices of the control mesh and individual patches of the spline surface. That is, for each 
vertex that is shared by n faces, an n-sided, quadratic Sabin net is constructed. The Sabin net corresponding 
to a vertex is found by con- structing the midpoints of all edges incident on the vertex, and the centroids 
of all incident faces. These poiuts, together with the vertex form the Sabin net (see Figure 6). It is 
easy to verify that neighboring Sabin nets satisfy the continuity con- straints. This construction is 
equivalent to that purposed by Sabin [19], but is not limited to patches with at most 5 sides. Figure 
6: 3-sided and 5-sided quadratic Sabin nets are con- structed to satisfy the continuity constraints. 
The Sabin nets are converted to S-patches by the method given in Section 5. Figures 8 and 9 show some 
examples of spline surfaces constructed using this scheme. 6.2 Generalized Bicublc Scheme A control mesh 
for the generalized bicubic scheme may have faces with any number of sides, but each (non-boundary) ver-tex 
must belong to exactly four faces. In this scheme, there is a one to one correspondence between faces 
of the control mesh and patches of the spline surface. That is, for each n- sided face of the control 
mesh, an n-sided cubic Sabin net is produced. Generating the Sabin net is slightly more complicated than 
for the generalized biquadratic scheme given in Sec- tion 6.1. In this case n key points are found for 
each n-sided face of the control mesh. The key points are connected across edges to form quadrilaterals 
corresponding to the vertices of the control mesh. The points of the Sabin net are taken to be edge midpoints 
and the centroids of the quadrilaterals as well as the key points (see Figure 7), The positioning of 
the key points can greatly affect the final shape of the surface. One , ossibility might be to leave 
them as user specified shape handles. Instead, we propose rea- sonable default placements for the key 
points. Let the vertices and centroid of a face be labeled as in Figure 7. The key point ki is computed 
by 1 k, = b,_l + + b,+l + where c is the centriod of the face bl,...,bn. This choice is justified empirically, 
and it generalizes the construction of 354 bicubic B-splines in the case n = 4. Other possibliries cer-tainly 
exist. O p Figure 7: 4-sided and 5-sided cubic Sabin nets are constructed subject to the continuity constrains. 
Filled dots represent key points. Once the Sabin nets have been constructed, they are con- verted to 
S-patches by the method given in Section 5. Figures 10 and 11 show some examples of spline surfaces constructed 
using this scheme. 7 Conclusions We have presented two methods for constructing surfaces from control 
meshes that provide sufficient generality for the mod- eling of arbitrary topological surfaces. One of 
the methods is a generalization of biquadratic B-splines, the other a generaliza- tion of bicubic B-splines. 
We have based these generalizations on S-patches, a class of n-sided parametric surface patches that 
contains B~zier triangular and tensor product patches as proper subsets. Our methods are also based on 
well known ge- ometric constructions for converting from a B-spline to B~zier representation: we convert 
a more general control mesh into a collection of S-patches that meet with tangent plane conti- nuity. 
The control meshes of this paper are not entirely general in that we require that exactly four surface 
patches meet at each interior vertex of the spline surface. This constraint was imposed for reasons of 
simplicity; the so c,alled "twist compat- ibility" problem has an easily described solution in this case. 
More general patch connections are certainly possible, and are currently being developed by the authors. 
Other topics of future research include: finding better ways of determining the interior control points 
of for the S- patch construction of Section 5, experimenting with alterna- tives to the key point placement 
algorithm of Section 6.2, and extending these results to produce curvature continuous (G 2) spline surfaces. 
We have not considered the case of Non-Uniform Rational B-splines or NURBs. The main reasons for this 
omission are the desire to avoid unnecessary complications, and because "knot lines" do not seem to have 
well defined counterparts when dealing with arbitrary topologies. However, our con-structions are easily 
extended to include non-uniformity by replacing the word "midpoint" with "knot vector ratio" in the constructions 
of Section 6. It is also quite straightfor- ward to incorporate rational polynomials through the use 
of homogeneous coordinates.  SIGGRAPH '90, Dallas, August 6-10, 1990 . References [19] [1] Boehm, Wolfgang. 
Cubic B-spline curves and surfaces in computer aided geometric design. Computing, 19:29-34, 1977.  [20] 
[2] Boehm, Wolfgang. Generating the Btzier points of B- splines. Computer Aided Design, 13(6):365-366, 
1981. [3] Boehm, Wolfgang. Visual continuity. Computer Aided [21]Design, 20(6):307-311, 1988. [41 CatmulI, 
Edwin and James Clark. Recursively generated B-spline surfaces on arbitrary topological meshes. Com- 
  [22] puter Aided Design, 10(6):350-355, 1978. [5] Charrot, Peter and John Gregory. A pentagonal surface 
patch for computer aided geometric design. Computer Aided Geometric Design, 1(1):87-94, 1984. [6] Chiyokura, 
Hiroaki and Fumihiko Kimura. Design of solids with free-form surfaces. Computer Graphics, 17(3):289-298, 
1983. [7] de Boor, Carl. B-form basics. In G. Farin, editor, Ge- ometric Modeling: Algorithms and New 
Trends, pages 131-148. SIAM, 1987. [8] DeRose, Tony. Geometric Continuity: A Parametrization Independent 
Measure of Continuity for Computer Aided Geometric Design. PhD thesis, Berkeley, 1985. also avail- able 
as Technical report UCB/CSD 86/255. [9] Dog, Daniel and Malcolm Sabin. Behaviour of recursive division 
surfaces near extraordinary points. Computer Aided Design, 10(6):356-360, 1978. [10] Gregory, John and 
JSrg Hahn. A C 2 polygonal surface patch. Computer Aided Geometric Design, 6(1):69-75, 1989. [11] Gregory, 
John. N-sided surface patches. In :I. Gre- gory, editor, The Mathematics of Surfaces, pages 217- 232. 
Clarendon Press, 1986. [12] Guibas, Leo and Jorge Stolfi. Primitives for the ma-nipulation of general 
subdivisions and the computation of voronoi diagrams. A CM Transactions on Graphics, 4(2):74-123, 1985. 
[13] Hahn, JSrg Filling polygonal holes with rectangular patches. In W. Strasser and H.P. Seidel, editors, 
Geomet-ric Modeling: Algorithms and New Trends, pages 81-91. Spring-Verlag, 1989. [14] Herron, Gary. 
Triangular and Multisided Patch Schemes. PhD thesis, U. of Utah, 1979. [15] Herron, Gary. Smooth closed 
surfaces with discrete tri- angular interpolants. Computer Aided Design, 2(4):297-306, 1985. [16] Herron, 
Gary. Techniques for visual continuity. In G. Farin, editor, Geometric Modeling, pages 163-174. SIAM, 
1987.  [17] Hosaka, Mamoru and Fumihiko Kimura. Non-four-sided patch expressions with control points. 
Computer Aided Geometric Design, 1(1):75-86, 1984. [18] Loop, Charles and Tony DeRose. A multisided generaliza- 
tion of Btzier surfaces. ACM Transactions on Graphics, 8(3):204-234, 1989. Sabin, Malcolm. Non-rectangular 
surface patches suitable for inclusion in a B-up/the surface. In P. ten Hagen, edi- tor, Proceedings 
of Eurographics '88, pages 57-69. North- Holland, 1983. Sablonniere, Paul. Spline and B6zier polygons 
associated with a polynomial spline curve. Computer Aided Design, 10(4):257-261, 1978. van Wijk, Jarke. 
Bicubic patches for approximating non- rectangular control-point meshes. Computer Aided Geo- metric Design, 
3(1):1-13, 1986. Varady, Tam_as. Survey and new results in n-sided patch generation. In R. Martin, editor, 
-The Mathematics of Surfaces H, pages 203-236. Oxford University Press, 1987.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97918</article_id>
		<sort_key>357</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Rendering and animation of gaseous phenomena by combining fast volume and scanline A-buffer techniques]]></title>
		<page_from>357</page_from>
		<page_to>366</page_to>
		<doi_number>10.1145/97879.97918</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97918</url>
		<abstract>
			<par><![CDATA[This paper describes a new technique that efficiently combines volume rendering and scanline a-buffer techniques. This technique is useful for combining all types of volume-rendered objects with scanline rendered objects and is especially useful for rendering scenes containing gaseous phenomena such as clouds, fog, and smoke. The rendering and animation of these phenomena has been a difficult problem in computer graphics.A new algorithm for realistically modeling and animating gaseous phenomena is presented, providing true three-dimensional volumes of gas. The gases are modeled using turbulent flow based solid texturing to define their geometry and are animated based on turbulent flow simulations. A low albedo illumination model is used that takes into consideration self-shadowing of the volumes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39075897</person_id>
				<author_profile_id><![CDATA[81100113675]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Ebert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer and Information Science, The Ohio State University, 2036 Neil Ave., Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P242699</person_id>
				<author_profile_id><![CDATA[81100414668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Parent]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer and Information Science, The Ohio State University, 2036 Neil Ave., Columbus, Ohio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMF~. Light Reflection Functions for Simulation of Clouds and Dusty Surfaces. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 26-30,1982 ). In Computer Graphics 16,3 (July 1982), 21-29.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[CARPENTER, LORt~. The A-buffer, an Antialiased Hidden Surface Method. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3 (July 1984), 103-108.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325174</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[DUFF, THOMAS. Compositing 3-D Rendered Images. Proeeedings of SIGGRAPH'85 (San Francisco, California, July 22-26,1985). In Computer Graphics 19, 3 (July 1985), 41- 44.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[EBERT, DAVID, BOYER, KEITH, AND ROBLE, DOUG. Once a Pawn a Foggy Knight .. {videotape}. In SIGGRAPH Video Review 54 (November 1989), ACM SIGGRAPH, New York. segment 3.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[EBERT, DAVID, EBERT, JULIA, AND BOYER, KErn/. Getting Into Art. {videotape}, Department of Computer and Informarion Science, The Ohio State University, May 1990.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[EBERT, DAVID, AND PARENT, POCHARD. Animation of gaseous phenomena using turbulent flow based solid texturing. Teeh. Rep. OSU-CISRC-7/89-TR36, Department of Computer and Information Science, The Ohio State University, 2036 Nell Ave, Columbus, Ohio 43210-1277, July 1989.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[GARDNER, GEOFFREY. Visual Simulation of Clouds. Proeeedings of SIGGRAPH'85 (San Francisco, California, July 22-26,1985). In Computer Graphics 19, 3 (July 1985), 297- 303.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, JAMES, AND KAY, TIMOTHY. Rendering Fur with Three Dimensional Textures. Proceedings of SIGGRAPH'89 (Boston, Massachusetts, July 31-Aug 4,1989 ). In Computer Graphics 23,3 (July 1989), 271-280.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, JAMES, AND VON HERZEN, BRIAN. Ray Tracing Volume Densities. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27,1984). In Computer Graphics 18,3 (July 1984), 165-174.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37423</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[KAtWMAN, ARm. Efficient Algorithms for 3D Scan- Conversion of Parametric Curves, Surfaces, and Volumes. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31,1987 ). In Computer Graphics 21,4 (July 1987), 171- 180.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35071</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[KLASSF.N, R. VtCTOR. Modeling the Effect of the Atmosphere on Light. ACM Transaction on Graphics 6, 3 (July 1987), 215-237.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[LEVOY, MARC. Private Communication, April 1990.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617545</ref_obj_id>
				<ref_obj_pid>616010</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[LEvoY, MARC. A Hybrid Ray Tracer for Rendering Polygon and Volume Data. IEEE Computer Graphics and Applications 10, 2 (March 1990), 33-40.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5515</ref_obj_id>
				<ref_obj_pid>5513</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[MAX, NELSON. Light Diffusion Through Clouds and Haze. Computer Vision, Graphics, and Image Processing 33 (1986), 280-292.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37437</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[NISHITA, TOMOYUKI, MrY^WAKI, Y^sumP, O, AND NAKA- MAE, EIHACHIP, O. A Shading Model for Atmospheric Seattering Considering Luminous Intensity Distribution of Light Sources. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31,1987). In Computer Graphics 21,4 (July 1987), 303-310.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[PERLIN, KEN. An Image Synthesizer. Proceedings of SIG- GRAPH'85 (San Francisco, California, July 22-26,1985). In Computer Graphics 19,3 (July 1985), 287-296.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74359</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[PERLIN, KEN, AND HOFFERT, ERIC. Hypertexture. Proceedhags of SIGGRAPH'89,(Boston, Massachusetts, July 31-Aug 4,1989 ). In Computer Graphics 20,3 0uly 1989), 253-262.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37436</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[RUSHy, HOLLY, AND TORRANCE, KEN. The Zonal Method for Calculating Light Intensifies in the Presence of a Participating Medium. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31,1987 ). In Computer Graphics 21,4 (July 1987), 293-302.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Voss, RICHARD. Fourier Synthesis of Gaussian Fractals: 1/f noises, landscapes, and flakes. In SIGGRAPH 83:Tutorial on State of the Art Image Synthesis (1983), vol. 10, ACM SIGGRAPH.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>26481</ref_obj_id>
				<ref_obj_pid>26477</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[WlLUS, PJ. Visual Simulation of Atmospheric Haze. Corn. puter Graphics Forum 6 (1987), 35-42.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Rendering and Animation of Gaseous Phenomena by Combining Fast Volume and Scanline A-buffer Techniques 
 David S. Ebert and Richard E. Parent Department of Computer and Information Science The Ohio State University 
2036 Neil Ave. Columbus, Ohio 43210-1277 Abstract This paper describes a new technique that efficiently 
combines volume rendering and scanline a-buffer tech- niques. This technique is useful for combining 
all types of volume-rendered objects with scanline ren- dered objects and is especially useful for rendering 
scenes containing gaseous phenomena such as clouds, fog, and smoke. The rendering and animation of these 
phenomena has been a difficult problem in computer graphics. A new algorithm for realistically modeling 
and an- imating gaseous phenomena is presented, providing true three-dimensional volumes of gas. The 
gases are modeled using turbulent flow based solid textur- ing to define their geometry and are animated 
based on turbulent flow simulations. A low albedo illu- mination model is used that takes into consideration 
self-shadowing of the volumes. CR Categories and Subject Description 1.3.3 [Computer Graphics]: Picture/Image 
Generation -Display Algorithms; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. Additional 
Keywords: volume rendering, a-buffer, gaseous phe- nomena, clouds, fog, solid texturing. INTRODUCTION 
The rendering of scenes containing clouds, fog, atmospheric dis- persion effects, and other gaseous phenomena 
has received much attention in the computer graphics literature. Several papers deal mainly with atmospheric 
dispersion effects [20, 15, 18], while many cover the illumination of these gaseous phenomena in de- 
tail [1, 9, 14, 11]. Most authors have used a low albedo reflection model, while a few, Blinn [1], Kajiya 
[9], and Rushmeier [18], discuss the implementation of a high albedo model. A major shortcoming of previous 
efforts in rendering scenes containing gaseous phenomena is that they have required that the same rendering 
techniques be used for all elements in the scene. This has made animations containing gaseous phenomena 
very computationally expensive and severely limited their usefulness. Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. Kajiya requires that everything 
be raytraced, which makes the ren- dering of other objects in the scene very slow [9]. The approach of 
Rushmeier requires a radiosity solution of the scene which yields a very accurate illumination model, 
but at a high computational cost [181. Most volume rendering systems also require that everything in 
the scene be volume rendered. Kaufman [10] allows the com- bination of surface geometry-defined objects 
with volume defined objects, but requires that the surface geometry-defined objects be converted to volumes 
before rendering, which is very inefficient. Levoy has used a similar approach to combine polygonal and 
volume data [12]. One volume rendering system that does not require that everything be volume rendered 
is described in [13]. This system uses raytracing for polygonal data. One solution to these problems 
is image compositing of scenes [3]. This solution would take volume-rendered objects and nor- mally-rendered 
objects and combine them in a post-process. How- ever, this is a limited solution, with only a few cases 
resulting in an accurate image. When compositing the sub-images, the volume- rendered image cannot cast 
shadows on the objects in the other scene. Also, compositing of an image containing semi-transparent 
volume-rendered objects with another image can only provide sat- isfactory results when the volume rendered 
object in the first image is totally in front of or behind the objects in the other image. For example, 
compositing of volume-rendered fog with a street scene is not possible. This suggests that to get accurate 
images of scenes containing gaseous phenomena, image composifing techniques are not a suitable solution. 
The technique described in this paper solves these problems by allowing a fast scanline a-buffer technique 
to be used to ren- der objects described by surface geometries, while volume mod- eled objects are volume 
rendered. This technique even allows the volume modeled objects to accurately cast shadows on the other 
objects in the scene. Another issue is modeling the geometry of these gases. Some authors use a constant 
density medium [11, 15], but do allow different layers of constant densities. To model the geometry of 
clouds, Kajiya uses a physically-based model [9], Gardner uses hollow ellipsoids [7], Voss uses fractals 
[19], and Max uses height fields [14]. This paper shows that realistic results can be obtained by using 
turbulent flow based functions to model the density of a variety of gases. These functions axe based 
on Perlin's visual simulation of turbulent flow [16] and axe similar to the idea of hypertextures [17]. 
The techniques described in this paper seem to provide more realistic results than most previous efforts 
by providing visually realistic renderings and animations of gaseous phenomena and the shadows they cast. 
These techniques are based on a visual simula- tion of turbulent flow, so it is a visual simulation of 
the turbulent @1990 ACM-0-89791-344-$00.75 2/90/008/0357 35'7 SIGGRAPH '90, Dallas, August 6-10, 1990 
 processes that determines the geometry of gaseous phenomena. These techniques can also be extended to 
use a physically-based turbulent flow model and can be very efficient when simplifying assumptions are 
made. In this paper, we discuss the efficient combination of volume rendering and a-buffer rendering 
techniques to provide realistic animations of gaseous phenomena. The algorithm which com-bines these 
techniques is discussed first. From a review of the literature, it appears that this is the first system 
that allows the combination of volume-rendered and scanline-rendered objects in the same scene. The following 
sections describe the volume ren- dering, illumination and modeling of the gases. Finally, a dis- cussion 
of the realistic results obtainable by these techniques is presented along with future extensions. Combining 
A-buffer and Volume Rendering Techniques The rendering system described in this paper effliciemly combines 
scanline a-buffer rendering with volume rendering without any restrictions on the geometric positioning 
or overlap of the vol- ume and non-volume elements. The algorithm first creates the a-buffer for a scanline 
containing a list for each pixel of all the fragments that partially or fully cover that pixel. At this 
point, the illumination calculations for the fragments have not been done. The fragment structure is 
similar to that used by Carpenter in his original paper on the a-buffer [2]. The structure used is as 
follows: Fra,~ment Structure -minimum and maximum z values -percent coverage -normal vector -pointer 
to parent object -bitmask for geometry of coverage -color -lisht attenuation values for each light The 
additional information added when combining volume rendering with the a-buffer technique is an attenuation 
amount for each light source, which is used for shadowing of the frag- ment by the volume elements. In 
the system described in this paper, the volumes are defined by procedural functions. The data structure 
used for visibility calculations of the volume modeled objects is the a-buffer fragment structure described 
above. The following section describes how the volume modeled objects are broken into sections to create 
a-buffer fragments and combined with the surface-defined a-buffer fragments. If a volume element is active 
for a pixel, the extent of volume tracing that is required is determined in the following manner. First, 
the ray from the eye through the pixel projected into world space is calculated. Then each of the scanline-rendered 
a-buffer fragments are mapped back to world space. From the geometry of the volume, the position of these 
a-buffer fragments in world space, and the hither and yon planes for the scene, the extent of the volume 
that must be traced ean be computed. The starting point for the volume tracing is the maximum of the 
hither plane and the closest point of intersection of the ray with the volume. The end point for the 
volume tracing is determined by the intersections of the ray with the volume, the yon plane, and the 
a-buffer fragments for this pixel. The a-buffer fragment list is traversed to determine the location 
in world space where full coverage of the pixel is obtained. Volume rendering will terminate at the minimum 
of this location, the yon plane, and the farthest intersection point of the ray and the volume. Each 
fragment in the fragment list also determines a starting or stopping point for separate volume elements 
to be added into the a-buffer fragment list. To get correct effects, the volume to be rendered must be 
broken into sections that lie between, in front of, and behind the a-buffer fragments (see Figure 1). 
For example, if there is a transparent object covering a pixel containing fog, a separate a-buffer fragment 
must be created for the fog in front of the transparent object, fog inside the transparent object (if 
desired), and the fog behind the transparent object. This is necessary since, if only one fragment was 
created, the fragment would be sorted in front of, in, or behind the transparent objeot's fragments based 
on the average z value of the fog, resulting in an incorrect pixel value. The volume rendering for this 
pixel then takes place, creating new fragments for the a-buffer fragment list that are sorted into place. 
For each of the fragments, computations to determine the shadowing by the volumes are performed. After 
the volume rendering is complete for each pixel, the geome~es of the bitmasks are used to determine 
the visible frag- ments for the pixel. This is done similar to [2] except that the illumination, texturing, 
etc., calculations are only performed for visible fragments. For volume fragments, the bitmask will contain 
all ls since only one ray is traced per pixel for volume elements. From the authors' experience, this 
resolution, although lower than that for surface-defined objects, provides quality images. The only additional 
computations performed for scanline-ren- dered fragments in combining these techniques is the inverse 
mapping of the fragment to world space and the shadow trac-ing through the volume. This inverse mapping 
needs to be done for most types of texturing, so this is not an additional expense ff the world space 
coordinates of the points are saved in the frag- ment structure. These shadow tracing calculations are 
needed for accurate shadowing. There is very little additional expense for scanline-rendered fragments 
when these techniques are combined in this way. Figure 3 shows an image of an art gallery, containing 
a volume modeled gaseous object as part of a modem sculpture. This scene was rendered with and without 
the volume modeled object. Calculation times are given in the results section. It will become clear from 
these timings that the overhead of combining the rendering techniques is negligible. The majority of 
rendering time is spent in the texturing of all the different objects. Volume rendering As mentioned 
above, only the visible portion of the volume is rendered. Volume tracing stops once full coverage of 
the pixel is reached. If the volume is completely covered by a wall in the scene, for example, no volume 
rendering takes place. Depending on scene composition, this can have significant time savings. The volume 
rendering technique used here is similar to the one dis- cussed in [17]. The ray from the eye through 
the pixel is traced through the defining geometry of the volume. As described above, volume tracing stops 
once full coverage of the pixel is obtained. If there is partial coverage of the pixel by some fragments, 
the volume is broken into sections in front of and behind the frag- ments until full coverage is reached. 
It is necessary to do this because each of the sections becomes a new element on the a- buffer fragment 
list. For each increment through the volume, the density function is evaluated. If the volume density 
function rep- resents a solid object, like the hypertexture functions described in [17], a slightly different 
algorithm is used than if the volume density functions represent a gas. The two algorithms differ in 
their illumination calculations and accumulation of densities. If normal illumination techniques are 
going to be used (for sold vol- umes), the normal to the surface is also calculated by the method described 
by Perlin [17]. If a gaseous illumination model is to be used these additional functional evaluations 
are not needed. The densities are also accumulated differently depending on whether the volume is a gas 
or a solid. The basic algorithm for rendering solid volumes is the follow- ing: determine 2 mutually 
orthogonal directions to the ray for each section of volume get the density value at the previous point 
for each increment along the ray get color, density, &#38; opacity of this element get density in 2 
mutually orthogonal directions determine the normal to the surface based on previous density, current 
density density in dirl,denslty in dir2 if self_shadowlng for each light source trace the ray to the 
light getting the light attenuation factor color = calculate the illumination of this volume using 
this normal and the color of the element tl = opacity* (1-sum_opaclty) ; final clr = final clr + tl*color; 
sum_opacity =sum ~paclty +tl; if sum_opacity =i stop tracing increment the sample_pt previous density 
- density create the a buffer fragment The opacity is determined from the density functions using the 
following formula from [17]: opacit71 = I --(1 --density1) T M where c is a normalizing constant used 
to make opacity a function of both density and step size. The algorithm for rendering gaseous volumes 
is the following: for each section of gas for each increment along the ray get color, density, &#38; 
opacity of this element if self_shadowlng for each light source trace the ray to light getting the light 
attenuation factor color =calculate the illumination of gas using opacity, density and the appropriate 
model final clr = final clr + color; sum density -sum denslty +density; if( transparency 0.01) stop 
tracing increment sample pt create the a_buffer fragment Here, the opacity is the value returned from 
evaluating the density function multiplied by the step-size. This is needed since in the gaseous model, 
we are approximating an integral to calcu- late the opacity along the ray. The integral from [9] is -~-xf 
'j'~ ~=<,) ~(,) Kt))a, opaeitt, = 1 -e ~' .... , where r is the optical depth of the material, P0 is 
the density of the material, t,,~ is the starting point for the volume tracing, and t y~ is the ending 
point. This is being approximated by -"×~i :'~ ~=('),~('),K'))~' opacitTI = 1 --e .... As Kajiya suggests 
[8], the final increment along the ray may not be the same size as the res4 so its opacity is scaled 
proportionally. The system currently implemented renders function-based vol- ume densities, but can easily 
be extended to handle voxel-based volume objects. In sampling along the ray, a Monte-Carlo method is 
used in choosing the point.  Illumination of gaseous Phenomena The illumination algorithm that is used 
is based on [9]. We have implemented the low-albedo iUumination model. The phase- functions that are 
used are sums of Henyey-Greenstein functions as described in [1]. The illumination model is the following: 
-~*S TM ~=(~),~(,,),,(~)) xzx~ B = e ~-" .... x I x tnear where I is x pha,,(a). i Phase(O) is the phase 
function, the function characterizing the total brightness of a particle as a function of the angle between 
the light and the eye [1]. Ii(z(t),lj(t),z(t)) is the amount of light from light source i reflected from 
this element. Self-shadowing of the gas is incorporated in this term by attenuating the brightness of 
the light. To approximate a high albedo model, an ambient term based on the albedo of the material can 
be added into I i. This ambient term accounts for the percentage of light reflected from the element 
due to second and higher order scattering effects. Shadowing of the gas The simplest way of shadowing 
the gas is to trace a ray from each of the volume elements to be rendered to the light, determining the 
opacity of the material along the way using the above equation for opacity. This method is similar to 
shadowing calculations performed in ray tracing and can be very slow. Depending on scene composition 
(amount of gas in the scene), our experiments have shown that self-shadowing in this manner can account 
for 75-95% of the total computation time. Kajiya talks of the importance of self-shadowing to correctly 
visualize data [8]. However, he shows that low-albedo models for gases with albedos over 30% produce 
too much self-shadowing [9]. If the gas to be rendered has a very high albedo, the effects of self-shadowing 
are negfigible compared to the secondary and higher order scattering of fight. Thus for gases with a 
high albedo, not performing self-shadowing can give realistic results at a much lower computational expense. 
For patchy fog or other gases with gaps of low density, shadowing earl be sped up by not calculating 
shadows for elements where the density is less than a threshold value. In order to speed up shadowing 
calculations a precalculated table can be used. Kajiya discusses this approach with the restric- tion 
that the light source be at infinity [9, 8]. This restriction was necessm3, for the method in which the 
table was produced, but is removed in the technique we propose in this paper. Using this technique, the 
light source may even be inside the volume. Use of a preealculated table is definitely faster for gases 
that do not move from one frame to the next. However, even if the gas does move from one frame to the 
next, it still provides faster rendering. The main reason that the shadow tracing calculations account 
for so much calculation time is that a large percentage of the calculations are repeated. In determining 
the shadowing for point p i, the ray from/~i to each light source is traced through the volume. While 
tracing this ray, the shadowing information for some points are also calculated, but not stored; therefore, 
shadowing calculations are repeated for these points. Shadowing calculations for points in the volume 
near the light source may be performed many times, depending on the order of processing. The amount of 
repeated calculations can be seen from a simple example. Assume a cu- bic volume of gas surrounding the 
entire scene, an image size of  Q SIGGRAPH '90, Dallas, August 6-10, 1990 500x500, a sample size of 
1/40th the volume size, the observer located along the positive Z axis, and the light source located 
directly above the volume. In determining the geometry of the gas, 500xS00x40 = 10,000,000 volume-density 
function calcu- lations will be performed. To calculate the shadow value for each of the elements, an 
average of 20 volume-density function cal- culations will need to be performed, for a total of 200,000,000 
volume-density function calculations for shadowing. The obvious way to eliminate these repeated calculations 
is to store all the shadow values that are calculated in a large three- dimensional table. Then, when 
a ray is traced towards the light, ff the shadow value has already been calculated for the point currently 
being sampled, the shadow tracing stops and this shadow value is added to the shadow values already accumulated. 
The main reason this approach is infeasible is the size of the table. If the image size is 640x480 and 
40 samples deep are being made, 12 Mb of memory would be required to store the table if only shadow values 
between 0 and 255 are being stored. However, this approach would become feasible if a reduced-resolution 
table were used, which is the approach the authors have chosen. Calculation of the shadow table To calculate 
the reduced-resolution shadow table values, a table of the same dimensions containing functional values 
is first com- puted. This is done to avoid repeated density functional evalu- ations. (If these functional 
evaluations are faster than a bilinear interpolation, this step would not save any time.) Next, the dis- 
tance squared from each point in the table to the light is calculated. These distances are then sorted, 
providing the order in which the shadow table values should be calculated. By calculating the shadow 
table values starting with the points closest to the light and proceeding to the points farthest from 
the light, only a bilinear interpolation is needed to determine each value. In determining the shadow 
value for a table entry, the ray to the light from this element is calculated (see figure 2). The ray 
from the point, Pi,j,k to the light will pass though one of the faces of a parallelepiped formed by table 
entries (i+l,j+l,k+l), (i+l,j-l,k+l), (i+l,j-l,k-1), (i-l,j+l,k+l),(i-l,j-l,k+l), (i-l,j-l,k-1). Now 
using the step sizes between table elements in world space and the normalized vector to the light, the 
face of the cube that surrounds this table element which will be pierced by the ray to the light can 
be determined. Once this is determined, the point of intersection of the ray and that plane can very 
quickly be determined since the table is aligned with the axes in world space. The restriction that the 
table aligns with the axes could easily be removed at the expense of some additional computations. This 
point of intersection now lies be- tween 4 table entries that already contain the shadow information 
for those points since the entries are calculated in sorted order. By adding the functional values of 
the entries times the step size to their shadow table values and bilinearly interpolating these sums, 
the shadow value for the current element can be found. To use the shadow table when volume tracing, the 
location of the sample point within the shadow table is determined. This point will lie within a parallelepiped 
formed by eight table entries. These 8 entries are tri-linearly interpolated to obtain the sum of the 
densities between this sample point and the light. To determine the amount to attenuate the light, the 
following formula is used. light_attert = 1 -e -r x sum_denslties X step-size This method is faster 
than tracing rays to each light if multiple volume density functional evaluations are slower than a tri-linear 
interpolation plus a fraction of the time needed to create the table. The average number of functional 
evaluations that are needed in determining the shadowing of an element by tracing the ray to the light 
will depend on the step size chosen for the volume tracing (normally tens of functional evaluations). 
The functions that the authors use are based on turbulent flow and are much slower than the above. These 
functions will be discussed in a later section. Time comparisons can be found in the results section. 
MODELING AND ANIMATING THE GASES Surface defined gases The authors originally used solid texturing of 
polygonal mesh objects for modeling gaseous phenomena [6], The solid texturing functions are based on 
the turbulence function from [16]. To simulate gaseous phenomena, solid texturing was used to control 
the transparency of objects that define the space that the gaseous substance occupies. In this way, solid 
textured transparency can be used to simulate fog, smoke, and clouds. For a cloud layer, one flat plane 
can be used. The transparency of this plane creates the clouds. The transparency is controlled by a turbulent 
flow based solid texturing function. A similar result could be obtained by having solid textured ellipsoids 
occupying the same solid texturing space. By using the ellipsoids, it is possible to get results similar 
to Gardner [7]. Gardner uses flat planes for creating cloud layers and ellipsoids for creating individual 
clouds positioned in space. A simple function to generate clouds is the following: clouds (pnt, pixel_size, 
frequency, power) xyz_td pnt; /* the location of the point in * the solid texture space */ float pixe 
l_si ze, frequency,power; { /* add some noise to the pnt */ pnt.x +-noise(pnt); pnt.y += nolse(pnt); 
 /* use a sine wave for the basis of the shape */ tmp=sin((turbulence(pnt, pixel_slze)*frequency)); 
 return(l.O -pow(tmp+l.O,power)*.5); }  By changing the parameters in this function, smile images of 
fog, mist, or smoke can be created. The frequency parame-ter controls the frequency of the sine wave 
through the turbulent space. The power parameter controls the distribution of the trans- parency values, 
basically determining whether linear interpolation, quadratic interpolation, or other types of interpolation 
are used to generate the transparency value. The other parameter that greatly affects the shape of the 
gaseous substance is the size of the solid texture space relative to the shape-defining object. Increasing 
this relative size creates the effect of zooming in on a portion of the gas. Volume-modeled gaseous 
phenomena The abeve technique has been extended to volume modeling of the gaseous phenomena. The turbulent 
flow based functions now control the density and geometry of the gases rather than the trans- parency 
of a polygonal object. In volume modeling these phenom- ena, a 3D solid defines the space that these 
gases occupy. Any ray-traceable solid can be used. One problem with this approach is that the solid's 
boundaries can be observed. However, by con- trolling the density functions, the defining shape of the 
solid can be made undetectable (if desired). This is easily accomplished by decreasing the density based 
on the location within the volume. Animating the gaseous phenomena There are two obvious ways that the 
above technique which sim- ulates gaseous phenomena can be animated. The first technique animates the 
turbulent space. The second technique moves the objects through the turbulent space. The first would 
be better for a true physically-based simulation of turbulent flow. However, since the method described 
here is not a physically-based simu- lation of turbulent flow, animating the turbulent space would be 
artificial and not worth the computational expense. The second, moving the objects through the turbulent 
space, is the approach described here since it is computationally more efficient and still gives effective 
results. A surface based version of animating solid textured gases was implemented to create the swirling 
fog in the animation "Once a Pawn A Foggy Knight..." [4]. A sample image from this film is in figure 
4. Three planes are positioned in the scene and are used to produce different movement patterns in the 
fog giving a more effective depth to the fog. Each plane has different parameters to the fog function 
to create varying amounts of transparency and motion. More planes would produce more complex motion but 
gready increase the computational expense. These planes all reside in a large solid texture space that 
surrounded the entire scene. The turbulence function is defined over this solid textured space. Each 
point on these planes that corresponds to a pixel location to be rendered is moved through this turbulent 
space based on the frame number and other parameters of the function for each plane. To animate the fog, 
each of these points is moved along a helical path through the solid texture space. Each point on the 
plane is then actually tracing out a different 3D path over time. Since the points on the plane are moving 
through the solid space, the fog appears to be 3D since you are seeing different points of the three 
dimensional volume of fog over time. A similar technique is used to animate full three dimensional volume 
modeled gaseous phenomena Instead of using multiple planes, as mentioned earlier, a solid object is used 
to define the space the gas occupies. In this case, each point in the volume is moved along a helical 
path to provide swirling gases. Figure 6 shows frames from a animation featuring volume-modeled steam 
rising from a glass. Notice the shadows east on the wall and on the inside of the glass by the steam. 
The steam itself has no self-shadowing. Many effects can easily be created from these simple func- tions. 
In the figure, the steam dissipates as it moves farther from the glass. This dissipating effect is created 
by decreasing the opac- ity as a function of the distance from the glass. The results section contains 
information about resolution and calculation times for the figures. Figure 7 shows frames from an animation 
featuring volume-modeled fog rolling in from the left of the screen. This also shows a chess piece moving 
through the fog. This attests to the true three dimensionality of the fog. To create the effect of fog 
moving in, each point in the volume was compared to a value, f, indicating the front of the fog. If the 
point's x value was greater than f, the density was set to 0. f changes based on the frame number, the 
turbulence value of the point, and the three dimensional location of the point in world space. This is 
done so that the front of the fog does not appear as a plane. It is actually a deformed plane where the 
deformation is controlled by turbulence and a table of random numbers. To create the fog thickening, 
the maximum density of the fog increases from zero at the front of the fog to one after a certain distance. 
The maximum density of the fog could also be increased based on the frame number so that the fog grows 
from thin wisps to dense patches. To create these effects, functions similar to the following are used. 
This function will create fog whose density increases over time and moves horizontally. chess_fog (pnt, 
density, plxel_size, parms, pnt_w, vol ) xyz td pnt, pnt_w; float *density, *parms, pixel_slze; vol 
td vol; { float trap, factor, front of fog, factor2; extern int frame num; extern float offSet[OFFSET_SIZE]; 
 xyz_td direction, cyl; int indx; /* apply some turbulence to the point * so that it appears more 
random */ tmp = turbulence(pnt, plxel_size); pnt.x += 2.0 + trap; pnt.y +-.5 +tmp; pnt.z += -2.0 -trap; 
 /* determine how to move the point through * the space (helical path) */ theta = (frame_num%SWIRL FRAMES) 
*SWIRL; (1) cyl.y = ELLIPSE1 * (float) cos(theta) ; cyl.z = ELLIPSE2 * (float) sin(theta) ; direction.x 
= pnt.x -(float) frame_num*DOWN; direction.y = pnt.x + cyl.y; direction.z = pnt.z + cyl.z; /* now determine 
the points transparency based * on its new location in the solid space */ tmp =turbulence (direction, 
pixel_size); /* have the fog grow more dense */ £actor = MIN ( (frame_num/FULL_FOG. 0), I. 0) ; *density 
= (tmp*opaque*factor) ; (2) *density = pow(*density, power) (3) ) The section of code (|) calculates 
how to move the point along the helical path based on the frame number, the number of frames to trace 
out an ellipse in the y-z plane (SW]RL_FRAMES and SWIRL), the amount to move horizontally per frame (DOWN), 
and the major and minor diameters of the ellipse (ELUPSEI, ELUPSE2). These parameters eon~ol the amount 
and direction of the overall fog movement. The intricacies in the fog movement are created by the turbulence 
function. The parameters, opaque and power, in transparency calculation (2) and (3) are used to control 
the opaqueness of the fog. Adjusting these values can change the density distribution of the fog since 
it shifts the opaqueness levels. Tbefactor causes the density to increase from a maximum value of 0 to 
a maximum value of opaque over FULL.FOG frames. Varying opaque can be used to to get patchy fog as opposed 
to wispy fog.  Use of turbulent flow for gases Using turbulent flow based functions for the simulation 
of fog makes sense since the varying densities of the fog are created by turbulent flow. Turbulence also 
creates the path over which the fog moves. Currently, a visual simulation of turbulent flow is used. 
This system can easily be extended to use a physical-based simulation of turbulent flow, since all that 
is needed is a different function to determine the density based on atmospheric turbulent flow. Developing 
the function to model atmospheric turbulent flow is a separate nontrivial problem. DISCUSSION OF RESULTS 
This paper has shown that volume rendering and scanline a-buffer rendering can be efficiently combined. 
This new technique is very useful when combined with turbulent flow based volume-modeled gases to produce 
realistic scenes with gaseous phenomena. All re- salts were calculated on a Hewlett-Packard 9000/370 
TSRX work- station with 16 Mb of memory. Table 1 shows rendering times for Figures 3 through 77. Table 
2 shows rendering times for each of the images in Figure 8. All rendering times arc approximate. Figure 
3 shows an art gallery scene containing a volume rendered gaseous sphere without volume shadowing. Table 
1 provides cal- culation times for the image in figure 3 and the same scene wRhout the volume. From these 
times, it is clear that the addition of a volume rendered object in the scene only slightly increases 
the computation time. Figure 4 shows a scene from "Once a Pawn a Foggy Knight..." showing surface based 
solid texturing to create the fog. Figure 5 SIGGRAPH '90, Dallas, August 6-10, 1990 shows the results 
obtainable by extending the turbulent flow based solid texturing to volume modeling. This scene is from 
"Getting Into Art" [5], and has table-based volume shadowing. Figure 6 shows 6 images of volume-modeled 
steam rising out of a glass casting shadow-traced shadows on the glass and the wall. The steam, however, 
does not shadow itself. These images represent every 30th frame of an animated sequence. Figure 7 shows 
9 frames of a chess scene similar to figure 4. In these images, the fog is volume rendered and is "rolling" 
in from the left of the image. Notice the shadows of the fog on the rook change as it moves forward. 
Also notice the shadows of the fog move across the curved base of the rook, the top of the pawn, and 
the ground plane in the last 3 images. R ~olutio n Rtnd~r/a 8 Tone Figure I (m/nines) 3 1024 x 682 71 
withvoltmae (actual picture) 1024 x 682 59 without volume 1024 x 768 105 1024 x 682 260 420 x 400 95 
each image 320 x 240 165 each image Table 1: Rendering Times for Figures 3 through 7 From this discussion 
of the results, it is clear that the com- putational time increases proportionally to the amount of gaseous 
volume in the image. Self-shadowing of the gases is also very expensive if shadow tracing is used. Figure 
8 shows 4 images of a glass with steam rising from it. The first image has no shadowing at all. The second 
image has shadowing of the volume onto the glass. The third and fourth images have self-shadowing of 
the vol- ume and shadowing of the volume on the glass. In the third image, the shadow-table technique 
was used with shadow table dimen- sions of 64x64x64. In the fourth image, shadow-tracing was used. The 
calculation times are given in Table 2. This further illustrates the improvement in computational time 
with table-based shadow- ing. In the times for images with shadow-table based shadowing, the times include 
the time to create the shadow table. Shadowin&#38; I Rendering Ti.rr~ I Figurc tara I (,ni=aez) none 
80 b shadow-traced, lot no self-shadowing shadow-traced, 1800 with self-shadowing table-based, 127 with 
self-shadowing Table 2: Rendering Times for Figure 8. Resolution is 360x250 The above calculation times 
are an upper limit on the com- putation time required to get the results seen in the figures. The same 
visual results might be achieved by using larger step sizes in volume tracing and shadow tracing and 
by using lower resolution shadow-tables, which would decrease the computation time. The combination of 
the volume rendering and scanline a-buffer rendering has wide ranging applications beyond the rendering 
of gaseous phenomena. This technique allows any volume data to be rendered in scenes with traditional 
surface based objects. The use of an a-buffer seanline renderer is not necessary if anti-aliasing is 
not desired. A normal scanline z-buffer could be used instead of the a-buffer; however, transparency 
will also not be handled easily, which is a normal problem with scanline z-buffer renderers. Many additional 
performance improvements are possible. The authors found that initially 65% of computation time was being 
spent in turbulence function evaluations. We have since achieved a 60% performance improvement in the 
turbulence function evalu- ation alone. There are certainly more performance improvements possible in 
the volume rendering section of this new system. An- other way to improve performance is to use a stored 
table of functional values with a lower resolution. This should provide improvements in computation time 
since volume density func- tional evaluations are the major computational expense. Animation using the 
above techniques is very suitable for dis- Iributed processing. The authors have used over 150 SUN and 
Hewlett-Packard workstations in computing the animation "Once a Pawn a Foggy Knight...." The same network 
distribution soft- ware used for this animation has been changed to handle the new techniques described 
above. Since the rendering time of a single frame is high, each workstation could also be given a range 
of seanlines to compute. The network distribution software took ap- proximately 20 minutes to distribute 
jobs to 150 machines. This time could easily be decreased if detailed information about the performance 
of machines was not kept. By using a large dis- tributed network like this, high resolution animations 
could easily be produced at the rate of more than 10 seconds per day. Future Extensions One extension 
to the above work is to extend the volume renderer to voxel-based volume rendering. This proposes no 
new problems in combining the volume rendering with the a-buffer. The authors are interested in extending 
the techniques for ren- dering and animating the gaseous phenomena to be physically- based. One idea 
is to control the overall fog movement based on a more global turbulent directional field. In this way, 
for exam- ple, the fog would move towards areas of low turbulence. A table containing barometric pressure 
readings could also be used to cre- am the dkectional movement of the gas by using the gradients of the 
values to control the speed and direction of the movement. In this way, you could begin to develop a 
physically-based model. The next step towards a physically-based model is to develop a physically-based 
turbulent flow model for various types of gases. This model seems to be eomputationally complex, but 
could easily be added into the current system since it is functionally based. As Perlin discusses, it 
is interesting how realistic the results obtained from a visual simulation of turbulent flow look [17]. 
The authors feel that developing a physically-based turbulent flow function, then simplifying the calculations 
to be tractable while maintain- ing the same visual quality is a good direction to take. Acknowledgments 
The authors wish to thank Keith Boyer, Jeff Ely, Bob Manson, and Rob Rosenblum for help in optimizing 
the turbulence functions. We also wish to thank Keith Boyer for writing the network dis- tribution software, 
Wayne Carlson and Julia Ebert for reviewing this paper, Ed Tripp for design help, Jim Kent for slab intersection 
software, and the computer staff of the Department of Computer and Information Science for providing 
a stable computer envi- ronment with high availability. The authors also wish to thank Hewlett-Packard 
for their donation of equipment to the graphics lab. References [1] BLINN, JAMES. Light Reflection Functions 
for Simulation of Clouds and Dusty Surfaces. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 
26-30,1982 ). In Computer Graphics 16,3 (July 1982), 21-29. [2] CARPENie~t, LOREN. The A-buffer, an Antialiased 
Hidden Surface Method. Proceedings of SIGGRAPH'84 (Minneapo- lis, Minnesota, July 23-27, 1984). In Computer 
Graphics 18, 30uly 1984), 103-108. [3] DUFF, THOMAS. Composiring 3-D Rendered Images. Pro- eeedings of 
SIGGRAPH'85 (San Francisco, California, July 22-26,1985). In Computer Graphics 19, 3 (July 1985), 41- 
44. [4] EBERT, DAVID, BOYER, KEITH, AND ROBLE, DOUG. Once a Pawn a Foggy Knight ... [videotape]. In SIGGRAPH 
Video Review 54 (November 1989), ACM SIGGRAPH, New York. segment 3. [5] EBERT, DAVID, EBERT, JULIA, AND 
BOYle, KEITH. Getting Into Art. [videotape], Department of Computer and Infor- marion Science, The Ohio 
State University, May 1990. [6] EBERT, DAVID, AND PARENT, RICHARD. Animation of gaseous phenomena using 
turbulent flow based solid tex- turing. Teeh. Rep. OSU-CISRC-7/89-TR36, Department of Computer and Information 
Science, The Ohio State Uni- versity, 2036 Nell Ave, Columbus, Ohio 43210-1277, July 1989. [7] GARDNER, 
GEOFFREY. Visual Simulation of Clouds. Pro- ceedings of SIGGRAPH'85 (San Francisco, California, July 
22-26,1985). In Computer Graphics 19, 3 (July 1985), 297- 303. [g] KAnYA, JAMES, AND KAY, TIMOTHY. Rendering 
Fur with Three Dimensional Textures. Proceedings of SIGGRAPH'89 (Boston, Massachusetts, July 31-Aug 4,1989 
). In Computer Graphics 23,3 (July 1989), 271-280. [9] KAJIYA, JAMES, AND VON HERZEN, BRIAN. Ray Tracing 
Vol- ume Densities. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27,1984). In Computer 
Graphics ]8,3 (July 1984), 165-174. [10] KAUFMAN, ARm. Efficient Algorithms for 3D Scan-Conversion of 
Parametric Curves, Surfaces, and Volumes. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31,1987 
). In Computer Graphics 21,4 (July 1987), 171- 180. [11] KLASSEN, R. VtCTOR. Modeling the Effect of the 
Atmo- sphere on Light. ACM Transaction on Graphics 6, 3 (July 1987), 215-237. [12] LEVOY, MARC. Private 
Communication, April 1990. [13] LEVOY, MARC. A Hybrid Ray Tracer for Rendering Polygon and Volume Data. 
IEEE Computer Graphics and Applica- tions 10, 2 (March 1990), 33---40. [14] MAX, NELSON. Light Diffusion 
Through Clouds and Haze. Computer Vision, Graphics, and Image Processing 33 (1986), 280-292. [151 N[SmTA, 
TOMOYUKI, MIYAWAKI, YASUItlRO, AND NAKA- MAE, EIHACHIRO. A Shading Model for Atmospheric Scat- tering 
Considering Luminous Intensity Distribution of Light Sources. Proceedings of SIGGRAPH'87 (Anaheim, Califor- 
nia, July 27-31,1987). In Computer Graphics 21,4 (July 1987), 303-310. [16] PERLIN, KEN. An Image Synthesizer. 
Proceedings of SlG- GRAPH'85 (San Francisco, California, July 22-26,1985). In Computer Graphics 19,3 
(July 1985), 287-296. [17] PERLIN, KEN, AND HOevm(T, ERIC. Hypertexture. Proceed- ings of SIGGRAPH' 89,(Boston, 
Massachusetts, July 31-Aug 4,1989 ). In Computer Graphics 20,3 (july 1989), 253-262. [18] RUSHMmt~R, 
HOLLY, AND TORRANCE, KEN. The Zonal Method for Calculating Light Intensifies in the Presence of a Participating 
Medium. Proceedings of SIGGRAPH'87 (Ana- heim, California, July 27-31,1987 ). In Computer Graphics 21,4 
(July 1987), 293-302. [19] Voss, RICHARD. Fourier Synthesis of Gaussian Fractals: 1/f noises, landscapes, 
and flakes. In SIGGRAPH 83:Tutorial on State of the Art Image Synthesis (1983), vol. 10, ACM SIGGRAPH. 
[20] WmLIS, PJ. Visual Simulation of Atmospheric Haze. Com-puter Graphics Forum 6 (1987), 35--42. opaque 
 -bject I-7 '.%~'.~^~ volume .... boundary' NN pixel ~ semi-transparent object Figure 1: Volume element 
creation. Shaded areas are the three volume elements.  light Figure 2: Shadow table Calculation.  
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97919</article_id>
		<sort_key>367</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Footprint evaluation for volume rendering]]></title>
		<page_from>367</page_from>
		<page_to>376</page_to>
		<doi_number>10.1145/97879.97919</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97919</url>
		<abstract>
			<par><![CDATA[This paper presents a forward mapping rendering algorithm to display regular volumetric grids that may not have the same spacings in the three grid directions. It takes advantage of the fact that convolution can be thought of as distributing energy from input samples into space. The renderer calculates an image plane footprint for each data sample and uses the footprint to spread the sample's energy onto the image plane. A result of the technique is that the forward mapping algorithm can support perspective without excessive cost, and support adaptive resampling of the three-dimensional data set during image generation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computations on matrices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31100406</person_id>
				<author_profile_id><![CDATA[81100374507]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Westover]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Numerical Design Limited, The University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>97910</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abram, Greg, Turner Whitted. Building Block Shaders. Proceedings of SIGGRAPH'90 (Dallas, Texas, August 6-10, 1990). In Computer Graphics 24, 4(August 1990).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B 1 inn, Jim. Light Reflection Functions for Simulation of Clouds and Dusty Surfaces. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 26- 30, 1982). In Computer Graphics 16, 3(July 1982), 21-30.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Drebin, Robert, Lome Carpenter, Pat Hanrahan. Volume Rendering. Proceedings of SIG- GRAPH'88 (Atlanta, Georgia, August 1-5, 1988). In Computer Graphics 22, 4(August 1988), 65-74.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Frieder, Gideon, Dan Gordon, Anthony Reynolds. Back-to-Front Display of Voxel-Based Objects. IEEE Computer Graphics and Applications 5, l(January 1985).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74352</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gallagher, Richard and Joop Nagtega~, An Et~ient 3-D Visualization Technique for Finite Element Models and Other Coarse Volumes. Proceedings of SIGGRAPH'89 (Boston, Massachusetts, July 31 - August 4, 1989). In Computer Graphics 23, 3(July 1989), 185-194.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6023</ref_obj_id>
				<ref_obj_pid>6020</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Greene, Ned, Paul Heckbert. Creating Raster Omnimax Images from Multiple Perspective Views Using the Elliptical Weighted Average Filter. IEEE Computer Graphics and Applications 6, 6(June 1986).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kajiya, Jim, Brian Von Herzen. Ray Tracing Volume Densities. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3(July 1984), 165-174.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lenz, Reiner, Bjom Gudnumdsson, Bjom Lindskog, Per Danielsson. "Display of Density Volumes", IEEE Computer Graphics and Applications 6, 7(Juty 1986).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Levoy, Mark. "Volume Rendering: Display of Surfaces from Volume Data", IEEE Computer Graphics and Applications 8, 5(May 1988).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lorensen, William, Harvey Cline. "Marching Cubes: A High Resolution 3D Surface Construction Algorithm", Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics 21, 4(July 1987), 163-170.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Porter, Thomas, Tom Duff. Compositing Digital Images. Procee~ngs of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3(July 1984), 253-260.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sabella, Paolo. A Rendering Algorithm for Visualizing 3D Scalar Data. Proceedings of SIG- GRAPH'S8 (Atlanta, Georgia, August 1-5, 1988). In Computer Graphics 22, 4(August 1988), 51-58.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Upson, Craig, Michael Keller. VBUFFER: Visible Volume Rendering. Proceedings of SIG- GRAPH'88 (Atlanta, Georgia, August 1-5, 1988). In Computer Graphics 22, 4(August 1988), 59-64.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[VanHook, Tim. Personal Communication. September I986.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>329138</ref_obj_id>
				<ref_obj_pid>329129</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Westover, Lee. "Interactive Volume Rendering" Proceedings of the Chapel Hill Workshop on Volume Visualization, May 1989.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 Footprint Evaluation for Volume Rendering Lee 
Westover Numerical Design Limited The University of North Carolina at Chapel Hill ABSTRACT This paper 
presents a forward mapping rendering algo- rithm to display regular volumetric grids that may not have 
the same spacings in the three grid directions. It takes advantage of the fact that convolution can be 
thought of as distributing energy from input samples into space. The renderer calculates an image plane 
footprint for each data sample and uses the footprint to spread the sample's energy onto the image plane. 
A result of the technique is that the forward mapping algorithm can support perspective without excessive 
cost, and support adaptive resampling of the three-dimensional data set during image generation. KEYWORDS: 
3D Image, Volume Rendering, Recon- strnction, Algorithms.  INTRODUCTION Volume rendering is the direct 
display of data sampled in three dimensions. There are two principle approaches to volume rendering: 
backward mapping algorithms that map the image plane onto the data by shooting rays from pixels into 
the data space, and forward mapping algo- rithms that map the data onto the image plane. * Author's current 
address: Sun Microsystems Inc PO Box 13447 Research Triangle Park NC 27709 Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. This distinction principly manifests 
itself in how and when reconstruction of the three-dimensional signal is done. Convolution can be thought 
of as either generat- ing an output sample from many input samples or as spreading one input sample to 
many output samples. Backward mapping algorithms typically reconstruct the signal at a point in space 
by looking at that point's nearest data samples and performing some type of inter- polation. Forward 
mapping algorithms differ in that they incrementally reconstruct the original signal by spread- ing each 
data sample's energy into space. Forward mapping algorithms are important because they are easily made 
parallel. Sinee each data sample only needs to know about a small surrounding neighborhood of other samples, 
shading and transforming can be done in parallel for sub-sections of the data. With today's parallel 
machines having limited local memory, this data distribution gets around the backward mapping problem 
of having the entire data set at each node. The reconstruction step is the most complicated part of the 
algorithm. The renderer must determine the screen space contribution of each sample point to the final 
image. A brute force method would perform a one-dimensional integration of the reconstruction kernel 
for every pixel for every input sample. If the renderer can calculate the screen space extent of the 
kernel, the number of integrations reduces to the number of samples times the number of pixels that fall 
within the extent. However, this is still an enormous number of integra- tions. In an orthographic view, 
the footprint of the projected reconstruction kernel for any sample is a constant except for a screen 
space offset. This allows the renderer to build a footprint function table once and use the table for 
all samples. Since the table is discrete, the renderer builds it on a fine grid to prevent artifacts. 
Even with this modification, the renderer must perform N 2 integrations of the kernel where N is the 
number of grid ceils in each table dimension. &#38;#169;1990 ACM-0-89791-344-2/90/008/0367 $00.75 367 
O SIGGRAPH '90, Dallas, August 6-10, 1990 This paper presents an algorithm that allows the renderer to 
use a pre-computecl footprint function table to build the view-transformed footprint table for a particular 
view. This pre-computed table is called the generic foot- print table because the renderer uses it to 
calculate the view-transformed table for any particular view. The renderer needs to calculate two things 
to build the view- transformed table. First, the renderer computes the screen space extent of the projection 
of the reconstruc- tion kernel. Second, the renderer computes a mapping of this extent to the extent 
that surrounds the pre-integrated footprint table. Then for each cell in the grid of the view-transformed 
table, the renderer maps the cell to the generic table and samples the generic table to find the cell's 
value. Once the renderer builds the view-transformed table, it can use the table for all input sam- pies. 
The renderer centers the table at the sample's pro- jected screen location and samples the table at the 
center of each pixel that fails within the table's extent. PREVIOUS WORK Researchers have investigated 
the volume rendering problem in the last few years and these algorithms can be divided along many lines. 
Blinn [2], Kajiya [7], VanHook [14], Levoy [9] and Sabella [12] describe methods of ray tracing volume 
densities with algorithms that map pixels onto the data by shooting rays into the data. Frieder [4], 
Lenz [8], Drebin [3], and Westover [15] use compositing techniques that map the data onto the image plane. 
Lorensen [10], Upson [13], and Gal- lagher [7] have investigated various methods of fitting surfaces 
into each data cell and then rendering the volume as surfaces. Another distinction between algorithms 
is whether the original signal is reconstructed and shaded at points of interest or whether the original 
data samples are shaded and then the shaded volume is reconstructed to form an image. Since shading is 
typically a non-linear process, interpolating the shaded volume can be problematic due to the high frequencies 
introduced by the shading model. On the other hand, this method only shades true data samples. Interpolating 
first, then shading, introduces new data samples into the data set, but shading happens at exact query 
samples. An enhancement to the algo- rithm presented in this paper can support either approach. Footprint 
determination has much in common with tex- ture map sampling. It is, however, almost the exact opposite 
problem. In texture mapping, a pixel is mapped into texture space and then all texture samples that lie 
within the mapped pixers footprint are weighted and accumulated to form the single texture color [6]. 
In volume rendering, the footprint is used to spread a single samples contribution onto every pixel that 
lies within the mapped voxel's footprint. In both cases, the mapping of a sample from one space into 
a second space forms an elliptical footprint in the second space. RENDERING ALGORITHM The algorithm 
discussed in this paper is a forward map- ping algorithm that shades at input samples, and recon- structs 
a final image from the shaded volume. This work differs from the original algorithm, described in West- 
over [15], in four ways. First, the initial algorithm com- bined the reconstruction step and the visibility 
step at each voxel. The new algorithm performs reconstruction for all samples in a sheet, where a sheet 
is defined as a plane through the data that is most paraUel to the image plane. Each voxel in a sheet 
is added to a sheet cash. When all the voxels on a sheet are processed, the sheet is matted into the 
working image. Second, the algorithm now uses a generalized shading model, Abram [1], that supports many 
shading techniques including the one from the original algorithm. Third, many of the details of how footprints 
are calculated and used has changed, as described below. Forth, the new footprint method will allow the 
algorithm to support both perspective and adaptive refinement. The algorithm consists of four main parts: 
transforming, shading, reconstruction, and visibility. For the algorithm to run in parallel, it is critical 
that each step in the pro- cess uses only local information. The renderer processes a sample by transforming 
the sample from input <i,j,k> grid space to <x,y,z> screen space. It then shades the sample using some 
shading rule that uses local informa- tion. The shaded sample is a <x,y,z,red,green,blue,tx> tuple. Next 
the renderer determines the portion of the image the sample can affect and adds the sample's contri- 
bution to the sheet accumulator. The determination of the footprint function, the sampling of the footprint 
func- tion, and the spreading of the sample's contribution is called splatting. The efficient determination 
of the effect and an efficient application of the footprint function is the topic of this paper. When 
all the samples that lie in a sheet are processed, the renderer mattes the sheet accu- mulator to the 
working image using a compositing operator [11]. Once all samples are processed, the work- ing image 
becomes the final image. FOOTPRINT FUNCTION The volume reconstruction equation for a regular array of 
density values is: signal 3D =   fffhv(.-x,v-y,w-z) p(x,y,z) Z (x,y,z) auavaw where hvO denotes the 
volume reconstruction kernel, p denotes the density function, ~5 denotes the comb '~' Computer Graphics, 
Volume 24, Number 4, August 1990 function, and u,v,w are the coordinates of the kernel. Moving the summation 
outside the integral and evaluat- ing the integral at point <x, y, z> results in: signalaD(x,y,z) = ~ 
hv (x-Dx, y-Dy.z-D~) p (D) De Vol where D ranges over the input samples that lie within the range for 
which the kernel, hvO is non-zero, and D~Dy, and D, are the screen space coordinates of the sample <D>. 
Instead of considering how multiple samples contribute to a point, consider how a sample can contribute 
to many points in space. The contribution at a point <x, y, z> by a data sample <D> is: contributionD 
(x,y,z) = hv(x-Dx.y-Dy, z-Dz) p (D ) Therefore, the renderer can treat each data sample indi- vidually 
and spread its contributions to the output sam- pies. The total contribution at a given <x,y> location 
is the sum of the contribution along a ray through the kernel that is perpendicular to the screen with 
its origin at <x,y>. The sum is calculated as the integral along z of the ray. Projecting the sample 
onto the image plane at pixel <x,y> is: contributionD(x,y) = 5 hv(x-D~,y-Dy.w) p (D) dw For a given sample, 
p is a constant and since p is independent of w, p can be moved outside the integral: contributiono(x,y 
) = p (D) S hv(x-D~,,y-Dy,w) dw Notice that the integral is independent of the sample's density. Since 
it only depends on the sample's <x, y> projected location, the function footprint is defined: footprint 
(x,y) = S hv(x,y,w) dw where <x,y > denotes the displacement of an image sam- ple from the center of 
the shaded sample's image plane projection. METHOD For orthographic views, the footprint of each sample 
is the same except for a screen space offset. Therefore, the renderer needs only to calculate the footprint 
function once for each view of the data set. Once the footprint is known, the renderer can sample the 
footprint function at each pixel that lies within the footprint's extent and con- tribute the appropriate 
amount to the pixel. The weight at each pixel is: weight (x,y)D = footprint (x-D~,y-Dy) where <D~,Dy> 
denotes the sample's image plane pro- jection and <x,y> denote the pixel's image plane loca- tion. Sampling 
the footprint function involves an integration. Many kernels are difficult to integrate analytically 
and the renderer must use discrete methods. Since the renderer does not want to integrate this function 
many times for each sample, it builds a table on a fine grid and then performs table look-ups to evaluate 
the function. The renderer needs to determine two things to build the footprint table for a particular 
view. First, it calculates the screen space extent of the projection of the kernel, which in an orthographies 
view is constant for each input sample. All pixels that lie within the extent may be affected by the 
given sample. Second, the renderer calcu- lates a mapping from the view-transformed extent to an extent 
that surrounds the projection of a generic kernel. The generic kernel table is calculated by a pre-processing 
program that runs once for a given kernel. Since the pre-processor runs once, it does not matter how 
long it takes to compute the integration of the kernel. By using a pre-computed generic table, the renderer 
can easily change reconstruction kernels by reloading the generic table from disk. Once the renderer 
builds the view-transformed table, the table is used by the renderer for each sample, by center- ing 
the table at each sample's projected screen position and calculating the screen space extent of the kernel 
by offsetting the extent of the projected kernel. For each pixel in the extent, the renderer samples 
the table to determine the amount of contribution for the pixel. The renderer builds the view-transformed 
footprint table on a grid that has many samples per pixel. Without over-sampling rendering artifacts 
will occur.  Building the Generic Footprint Table The method assumes that the extent of the reconstruction 
kernel is a sphere. If the extent is not a sphere, the pre- processor bounds the kernel by a sphere. 
For efficiency reasons, the bounding sphere should be as tight as possi- ble. A loese fitting sphere 
will cause the pre-processor to build a generic table that has many zero entries, which causes the renderer 
to visit many pixels that are not affected by a given sample. For a spherical kernel, the radius of the 
sphere is equal to the width of the recon- struction kernel. This sphere, called the unit region sphere, 
defines the region a sample can affect. Within this region, on a discrete grid, the preprocessor integrates 
the kernel along the z direction and stores the result in a table. This table is called the generic footprint 
table. During image generation, the renderer determines the extent of the projection of the view-~ansformed 
 O SIGGRAPH '90, Dallas, August 6-10, 1990 region sphere. In addition, the renderer determines a mapping 
of each point in that extent onto the extent sur- rounding the unit region sphere in order to build the 
view-transformed footprint table. The projection of the unit region sphere on the image plane is a circle. 
The mapping from view-transformed extent to generic extent is then a mapping from the projection of the 
view- transformed region to a circle. L;; L,;i ; ;; ; ;; ;;; ~k; ; ;; I IWI II I II I II I II I I1~1 
II i ,.i ii , ii i ,,i,i i i, ~11 Jr i II I II Ill Ill i PJ i i i i i i i i i i i i i l i i ii 1111 
11 i ii i i1 i i1 i ii i i1 i ii i ii i ii i ii i ii i 11 i ii ILl Ill I IIIll Ill IJ illl i ii i i1 
i ii i ii i ii i ii l;~,l II ; ;l I ',; l II ; ; LI'I', I II NI I II I 11 I II I l~rl II i i i 1 ~ i 
I1 1 I 1 1 I I gl 1 I [ 1 L~ ./I-.d..l..kZ~ff-k J.,L,~.U Figure 2. Genetic Footprint Function Table 
 EXTENTS AND MAPPINGS There are two basic cases for determining extents and mappings: the unit sphere 
maps to a sphere after apply- ing the viewing transform, or the unit sphere maps to an ellipsoid. The 
result is a sphere when the input volume has equal spacings in each of the grid directions and the viewing 
transform has only uniform scaling. The result is an ellipsoid when the input volume has non-uniform 
spacing in each of the grid directions or the viewing transform has non-uniform scaling. Since a sphere 
is a special case of an ellipsoid, the renderer currently uses the elliptical method described below 
for all volumes. Extent and Mapping for Spherical Kernels Figure 3. Spherical Kernel Even when the kernel 
maps to a sphere, the renderer can not use the generic table directly and must build a view- transformed 
table. If the grid scale value and the view scale value are both 1.0, the generic table is used, other- 
wise the renderer builds a view-transformed. This makes a table access fall exactly at table entries 
and causes all the interpolations to only occur once. Extent Many input volumes have fewer samples per 
face than the desired number of pixels in the image. This means that the input sampling rate is much 
smaller than the out- put sampling rate and each input sample needs to cover many pixels. The renderer 
calculates the extent of a sample's effect by scaling the unit extent by the grid scale value and the 
view scale value. The extent in both the x and y directions is: extent =2.0*kernel_width* grid_scale*view_scale 
 Mapp/ag The mapping from scaled extent to unit extent is trivial in the case of a spherical result. 
The projection of the sphere onto the image plane is a circle. The mapping from one circle to another 
circle is a scaling by the ratio of the radii of the two circles. The mapping is: 1.0 mapping = grid_scale_factor*view_scale_factor 
 The renderer uses the mapping to map ceils of the view- transformed footprint table to the generic footprint 
table. If the view is simply rotated and the scale factors do not change, the view-transformed footprint 
table can be used again. Extant and Mapping for Elliptical Kernels Figure 4. Elliptical Kernel If the 
scalings in grid directions are different, the region sphere transforms into a region ellipsoid. The 
projection of the region ellipsoid is always a screen space ellipse. The extent of a kernel's effect 
is the extent of the pro- jected ellipse, and the mapping from view-transformed table to generic table 
is a mapping from the projected '~' Computer Graphics, Volume 24, Number 4, August 1990 ellipse to the 
unit circle. Extent The region ellipsoid is found by transforming the unit region sphere by the grid 
scale transform and then by the viewing transform. By treating the unit region sphere as a quadrie surface, 
the transformations become matrix multiplications. Let the original unit sphere be U: 1000 U= 0100 eel 
0 000 -1 and let the grid scale transform be S: 000 s= ISi sjoo 0 Sk 0 001 and let the viewing transform 
be V: V= e/hi O0 The grid space region ellipsoid E is: E=S*U To transform the quadric surface the renderer 
calculates both the inverse viewing transform and its transpose. The resulting screen space ellipsoid 
R is: R = V -lr* E* V -1 with A D/2 El2 DI2 B FI2 R= El2 F/2 C 0 0 0 This gives an ellipsoid defined 
by: Ax 2 +By 2 + Cz z + Dxy + Exz + Fyz = K (I) By rearranging terms, completing the square, and solv- 
ing for x and y, the renderer can calculate the screen space extent of the transformed ellipse. The x 
extent is: K x=± ~A- (E DF .}z D 2 . --~-. y=_+ -------~---------- Mapping The renderer also needs to 
calculate the mapping from the projection of the region ellipsoid back to the unit cir- cle. To do this, 
the renderer first calculates the screen space projection of the region ellipsoid which is an ellipse. 
To find the ellipse, first rewrite (1) as a quadratic in z. The quadratic is: Cz 2 + (Ex + Fy)z + (Ax 
~ + By z + Dxy -K) = 0 Points on the edge of the projection of R have only one root in this quadratic. 
There is only one root to the qua- dratic aZ 2 + bZ + c = 0 when b 2 -4ac = 0 or in this case when: (Ex 
+ Fy) 2 - 4C (Ax 2 + By 2 + Dxy -K) = 0 Grouping the x 2, the y2, and the xy terms gives the screen space 
projection ellipse P: Xx2 + Yy2 + Zxy = K (2) where: E 2 F z EF x = r = z = Once the renderer calculates 
the screen space ellipse, it can define a transformation that takes points from the screen space ellipse 
into the unit circle. This is the inverse of the mapping that takes the unit circle into the screen space 
ellipse. To calculate the second mapping, the renderer needs to calculate two things: the amount to scale 
along the x axis and the y axis, and the amount of rotation about the view direction. and the y extent 
is: Figure 5. Ellipse to Circle Mapping   O SIGGRAPH '90, Dallas, August 6-10, 1990 border regions 
where adaptive sampling occurs. Samples within the region of resampling will each have identical . kernel 
projections. The adaptive resampling will help the renderer alleviate the problem of the shading model 
introducing high frequency components. Additionally, the amount of subdivision the renderer performs 
is a time verses quality tradeoff control. Quick views under- sample the volume, and produce coarse images. 
Images .that require better quality just take longer to generate. ACKNOWLEDGEMENTS I would like to thank 
my advisor, Turner Whitted, for our numerous discussions and his helpful insight, and Robert . Whitton, 
for his invaluable help in converting some vague feelings and intuitions into concrete mathematical formulas. 
In addition, I would like to thank Greg Abram and Greg Gilley for helping me with incorporating our company's 
shading library into my volume renderer. I . would like to thank Dana Smith and Greg Gilley for their 
help in proof reading this paper. They are responsible for much of the readability of the paper and none 
of its faults. . The copper chloride p-orbitals data is courtesy of Michael Pique, Scripps Clinic Molecular 
Biology, La Jolla, California. The computed tomography data is 10. courtesy of Radiation Oncology of 
the University of North Carolina at Chapel Hill, North Carolina. The ozone concentration data is courtesy 
of the Regional Oxidant Model group of the Environmental Protection Agency, Research Triangle Park, North 
Carolina. The 11. original Staphylococcus Aureus ribonuclease data is courtesy of Chris Hill of the 
University of York. The shaded Staphylococcus Aureus ribonuclease data is courtesy of Marc Levoy University 
of North Carolina at Chapel Hill, North Carolina. 12. REFERENCES 1. Abram, Greg, Turner Whitted. Building 
Block Shaders. Proceedings of SIGGRAPH'90 (Dallas, 13. Texas, August 6-10, 1990). In Computer Graphics 
24, 4(August 1990). . Blinn, Jim. Light Reflection Functions for Simula- tion of Clouds and Dusty Surfaces. 
Proceedings of 14. SIGGRAPH'82 (Boston, Massachusetts, July 26- 30, 1982). In Computer Graphics 16, 3(July 
15. 1982), 21-30. 3. Drebin, Robert, Lorne Carpenter, Pat Hanrahan. Volume Rendering. Proceedings of 
SIG- GRAPH'88 (Atlanta, Georgia, August 1-5, 1988). In Computer Graphics 22, 4(August 1988), 65-74. 
. Frieder, Gideon, Dan Gordon, Anthony Reynolds. Back-to-Front Display of Voxel-Based Objects. IEEE Computer 
Graphics and Applications 5, l(January 1985). Gallagher, Richard and Joop Nagtegaal, An Efficient 3-D 
Visualization Technique for Finite Element Models and Other Coarse Volumes. Proceedings of SIGGRAPH'89 
(Boston, Mas-sachusetts, July 31 -August 4, 1989). In Com-puter Graphics 23, 3(July 1989), 185-194. Greene, 
Ned, Paul Heckbert. Creating Raster Omnimax Images from Multiple Perspective Views Using the Elliptical 
Weighted Average Filter. IEEE Computer Graphics and Applications 6, 6(June 1986). Kajiya, Jim, Brian 
Von Herzen. Ray Tracing Volume Densities. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 
1984). In Computer Graphics 18, 3(July 1984), 165-174. Lenz, Reiner, Bjorn Gudnumdsson, Bjorn Lindskog, 
Per Danielsson. "Display of Density Volumes",IEEE Computer Graphics and Applica- tions 6, 7(July 1986). 
Levoy, Mark. "Volume Rendering: Display of Surfaces from Volume Data", IEEE Computer Graphics and Applications 
8, 5(May 1988). Lorensen, William, Harvey Cline. "Marching Cubes: A High Resolution 3D Surface Construc- 
tion Algorithm", Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Com-puter Graphics 
21, 4(July 1987), 163-170. Porter, Thomas, Tom Duff. Compositing Digital Images. Proceedings of SIGGRAPH'84 
(Min-neapolis, Minnesota, July 23-27, 1984). In Com-puter Graphics 18, 30uly 1984), 253-260. Sabella, 
Paolo. A Rendering Algorithm for Visualizing 3D Scalar Data. Proceedings of SIG- GRAPH'88 (Atlanta, Georgia, 
August 1-5, 1988). In Computer Graphics 22, 4(August 1988), 51-58. Upson, Craig, Michael Keller. VBUFFER: 
Visi- ble Volume Rendering. Proceedings of SIG-GRAPH'88 (Atlanta, Georgia, August 1-5, 1988). In Computer 
Graphics 22, 4(August 1988), 59-64. VanHook, Tim. Personal Communication. Sep- tember I986. Westover, 
Lee. "Interactive Volume Rendering" Proceedings of the Chapel Hill Workshop on Volume Visualization, 
May 1989.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97920</article_id>
		<sort_key>377</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Light-water interaction using backward beam tracing]]></title>
		<page_from>377</page_from>
		<page_to>385</page_to>
		<doi_number>10.1145/97879.97920</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97920</url>
		<abstract>
			<par><![CDATA[A new two pass approach is presented based on a variation of backward ray tracing backward beam tracing. Advantages include its capability of rendering complex, hitherto unattainable, specular to diffuse phenomenon and its easy insertion into standard renderers. The algorithm is applied to aspects of the interaction of light with water. Within this context a variety of first generation effects, including shadowing and light scattering, are both rendered and animated. Results taken from the treatment of caustics within classical optics are included as they provide valuable insights into the precise nature of specular to diffuse transfer.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31098956</person_id>
				<author_profile_id><![CDATA[81332534448]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Pictures, London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adler, Cyrus. Shadow-sausage effect. American journal of physics, Vol. 35, No. 8, (August 1967), 774-776.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arvo, James. Backward ray tracing. Developments in ray tracing, siggraph course notes, Vol. 12. (August 1986).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Berry &amp; Upstill. Catastrophe optics : morphologies of caustics and their diffraction patterns. Progress in optics, Emil Wolf ed., Elsevier North-Holland, Vol. 18, (1980).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Berry &amp; Hajnal. The shadows of floating objects and dissipating vortices. Optica Acta, Vol. 30, No. 1, (January 1983), 23-40.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Born &amp; Wolf. Principles of optics, Pergamon Press, (1964).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30321</ref_obj_id>
				<ref_obj_pid>30300</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chattopadhyay &amp; Fujimoto. Bi-directional ray tracing. Computer graphics ~ proceedings of CG International 1987, Tosiyasu Ktmii ed., Springer Verlag, Tokyo, (1987), 335-343.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94789</ref_obj_id>
				<ref_obj_pid>94788</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew S. An overview of ray tracing. An introduction to ray tracing, An&amp;ew Glassner ed., Academic Press, (1989), 1-31.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Heckbert &amp; Hanrahan. Beam tracing polygonal objects. Computer graphics, Vol. 18, No. 3, (July 1984), 119-127.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hockney, David. Portrait of an artist ( pool with two figures ). {painting} (1971).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[ImsneL Cohen, &amp; Greenberg. A radiosity method for nondiffuse environments. Computer graphics, Vol. 20, No. 4, (August 1986), 133-142.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T. The rendering equation. Computer graphics, Vol. 20, No. 4, (August 1986), 143-150.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806820</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson L. Vcctorizcd procedural models for natural terrain : waves and islands in the sunset. Computer graphics, Vol. 15, No. 3, (August 1981), 317-324.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37437</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Nishita, Miyawaki &amp; Nakamae. A shading model for atmospheric scattering considering luminous intensity distribution of light sources. Computer graphics, Vol. 21, No. 4, (July 1987), 303-308.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378492</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Shao, Peng, &amp; Liang. A new radiosity approach by procedural refinements for realistic image synthesis. Computer graphics, Vol. 22, No. 4, (August 1988), 93-101.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Siegel &amp; Howell. Thermal radiation heat transfer, second edition, Mcgraw-Hill, (1981), 142-145.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sillione &amp; Puech. A general two pass method integrating specular and diffuse reflection. Computer graphics, Vol. 23, No. 3, (July 1989), 335-344.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Wallace, Cohen. &amp; Greenberg. A two-pass solution to the rendering equation" a synthesis of ray-tracing and radiosity methods. Computer graphics, Vol. 21, No. 4, (July 1987), 311-320.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ward, Rubinstein, &amp; Clear. A ray tracing solution for diffuse interreflection. Computer graphics, Vol. 22, No. 4, (August 1988), 85-92.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Watt, Alan &amp; Watt, Mark. Advanced rendering and animation techniques" theory and practice. Addison- Wesley. To be published Autumn 1990.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Zhu, Peng &amp; Liang. PERIS : a programming environment for realistic image synthesis, computers and graphics, Vol. 12, No. 3/4, (1988), 299-307.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Light-Water Interaction using Backward Beam Tracing Mark Watt Digital Pictures, London Abstract A new 
two pass approach is presented based on a variation of backward ray tracing - backward beam tracing. 
Advantages include its capability of rendering complex, hitherto unattainable, specular to diffuse phenomenon 
and its easy insertion into standard renderers. The algorithm is applied to aspects of the interaction 
of light with water. Within this context a variety of first generation effects, including shadowing and 
light scattering, are both rendered and animated. Results taken from the treatment of caustics within 
classical optics are included as they provide valuable insights into the precise nature of specular to 
diffuse transfer. C.R. Categories L3.3,1.3.5, 1.3.7 Keywords : backward ray tracing, caustics, light 
beam tracing, specular to diffuse transfer. Introduction Computer graphics has now reached the stage 
where all the basic problems of image synthesis - namely, hidden surfaces, shadowing, reflection, basic 
diffuse and specular shading, etc. -have been solved. The advent of stochastic ray tracing, producing 
additional refinements such as motion blur, soft shadowing and depth of field extended the repertoire 
yet further. The development of the radiosity method enabled the subtle effects of diffuse inter-refiections 
to be modeled and firraly established the distinction between view dependent and view independent image 
synthesiz techniques. The former are driven from the eye whereas the latter suffer no such constraint. 
The search for a more complete global illumination model led to the classification [ 17] of four mechanisms 
of light transport between two surfaces. They are as follows : (i) diffuse to diffuse, (ii) diffuse 
to specular,  (iii) specular to specular, (iv) specular to diffuse. Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. (i) and (iv) are view independent, 
(ii) and (iii) view dependent. To some extent this classification is an over simplification as it ignores 
higher order illumination effects that occur when light arrives at a surface via a path involving several 
interactions with several surfaces where any of the above transport mechanisms may be involved in any 
order. Also, eases exist where this approximation of energy interchange breaks down completely -such 
as the lunar surface [15]. Nevertheless to first order it remains a useful concept and shall be used 
here. Both radiosity and ray tracing have attempted to solve for global illumination where any number 
of these binary interactions are involved. Radiosity is recognized as being the most suitable method 
for solving the diffuse to diffuse component, whilst ray tracing is best suited solving for the diffuse 
to specular, and specular to specular components. These associations have given images generated by the 
separate techniques their unique signatures. Radiosity pictures are usually office interiors which tend 
to be softly lit; whereas ray tracing pictures have as their hallmark shiny objects, usually spheres, 
exhibiting sharp multiple reflections. Either method comes up against difficulties when moving into the 
other's domain. They are : (a) Radiosity and the specular eomponenL Radiosity, by attaining equilibrium 
within a closed envirormaent, must, by nec~sity, sample and diseretize the whole environment. In general 
the view dependent specular contribution varies rapidly over adjacent pixels and is not adequately captured 
by interpolating across relatively wide patch vertices. Subdividing the patches to a level such that 
when projected onto the image plane they are roughly the same size as a pixel would overcome this problem 
but is overwhelming computationally, (b) Ray tracing and the diffuse component. In order for ray tracing 
to handle the diffuse to diffuse component, many rays would have to be fired from a ray- object intersection 
in many directions, to many levels of recursion, resulting in significant computational overheads. A 
further objection to such an approach lies in the fact that the diffuse contribution typically changes 
slowly over pixels and a naive ray tracer calculating the diffuse component ab irtitio at each pixel 
performs much urmecessary, repetitive work. By taking advan~ge of the complementary strengths of the 
two approaches, work over recent years has led to the evolution of hybrid two-pass algorithms involving 
a view independent radiosity preprocessing step and a view dependent ray tracing post processing step. 
 &#38;#169;1990 ACM-O-89791-344-2/90/O08/0377 $00.75 377 SIGGRAPH '90, Dallas, August 6-10, 1990 @ 
At one end of the spectrum lies the solution of the specular component within the view independent step 
as proposed by Immel [10]. Here the conventional form factor defining the energy transfer between two 
patches is extended to include bidirectional reflectance by taking into account all directions of one 
patch against all directions of the other. Unfortunately this method fails to address the problem outlined 
in (a) above and consequently it takes weeks to produce even the simplest of pictures. At the other end 
of the spectrum lies the solution of the diffuse component within the view dependent step as proposed 
by Kajiya [11] and subsequently Ward [18]. As noted in (b) however, it is simply too expensive to fire 
huge numbers of rays into the scene -they must be fired intelligently. To this end, Kajiya employed sophisticated 
sampling and variance reduction techniques that monitor the progress of ray ~ees, pruning them if the 
variation amongst the samples is small, and directing them into regions where they make significant contributions 
to the final value of the pixel. Nevertheless computation time is still very long. Within these two extremes 
fall the remainder of the hybrid algorithms including Shao [14], Wallaee [17] and Sillion [16]. Specular 
to diffuse transport Notable by its absence so far is a discussion of the fourth mechanism of light transport 
-specular to diffuse transport. This occurs when light reflecting from, or refracting through, one surface, 
the specular surface, hits a diffuse surface where, by defmition, it is emitted equaUy in all directions. 
It is fair to say that, to date, this is the most elusive and neglected of all transport mechanisms -traditional 
radiosity ignores it completely as do almost all ray tracing techniques. It is the purpose of this work 
to go some way towards redressing the imbalance. What little attention this mechanism has received is 
reviewed below. We consider approaches made from the radiosity and the ray tracing camps separately. 
(a) Radiosity and the specular to diffuse component Wallace et al. [17] treated the specular surface 
as an additional route by which light leaving one diffuse patch may reach another. The method restricts 
the specular surface to be a perfect flat mirror so that the extension can be handled by the traditional 
'ComeR' approach for from factor determination ie. the hemi-cube. If patch A can see patch B in the mirror 
then the mirror form factor between patch A and patch B's reflection is constructedand added to the radiosity 
equation. The construction entails building a 'virtual world' on the other side of the mirror. The method 
was able to model the effect of light from a table lamp bouncing off a mirror and hitting the table top. 
A more general solution was put forward by Sillione [16] who ref'mded the traditional form factor definition 
to be a measure of energy transfer between two patches after any number of intermediary specular reflections 
of refractions. The form factor of a specular patch now becomes a series of form factors - one for each 
direction. A given form factor in a given direction distributes itself amongst objects that intersect 
the ray tracing tree fired in that direction. The method was able to model fight refracting through a 
glass sphere and being focussed on a fiat stuffacc below. Both these implementations still fall foul 
of the fundamental criticism levelled at radiosity techniques as cited in (a) in the introduction. Consequently, 
the pictorial examples of both methods show only the softest of specular to diffuse effects varying slowly 
over pixeLs and both would prove impractical in capturing higher frequency effects examples of which, 
as we shall see later, abound and are far the more interesting. (b) Ray tracing and the specular to diffuse 
component Work done in this field, although meeting with similar limited practical success, provides 
us with a valuable theoretical notion - so we shall consider it in some detail Let us return to the example 
of specular to diffuse transport as modeled by Wallace [17] and shown in figure 1. A table lamp illuminates 
a table directly, along LT, and indirectly by light reflecting off the mirror, along LMT. L milTor M 
 Figure 1. A standard ray tracer fires rays from the eye through the image plane and into the scene. 
Suppose one such ray, ET, hits the table at T. Further rays are then spawned at T to determine its illumination. 
The ray tracer knows that if T can see the light it will contribute to its illumination so a shadow ray 
TL is sent to the light. Unfortunately, it is completely ignorant of light arriving by the second, indirect 
route. The only way it can find this second route is by ' accident ' ie. by firing enough rays in enough 
directions such that one coincides with the direction TM. Clearly, standard ray tracers, in sampling 
the whole envlronmen4 would have to be made to work very hard to capture the specular to diffuse component 
and only the most sophisticated of them all [11] has managed to do so. The problem is fundamental and 
due to the fact that we are travelling in precisely the reverse direction to that which light is propagating. 
This applies to any view dependent algorithm. Only light energy transmitted via the reverse path of the 
ray tracing tree is taken into account. A far more intuitive approach for this transtmrt mechanism at 
least, and one that this work adopts, would be to move over into the view indeopendent domain and to 
start from the light following the rays in their direction of propagation as they bounce around the scene 
-thereby removing our ignorance of indirect illumination at a stxoke. Immediately specular to diffuse 
transport becomes less elusive - our problem above becomes trivial -reducing to the statement that a 
ray from the light travelling along LM is reflected at M and hits the table at T. It was just such a 
consideration of specular to diffuse transfer by Arvo [2] that led to the notion of' backward ray tracing 
' as he coined it, since it is the reverse of conventional ray tracing. Unfortunately a confusion of 
terminology has evolved as subsequent authors, notably Chattopadhyay [6] and Glassner [7], prefer to 
label conventional ray tracing as backwards since its direction is the reverse of light propagation. 
For this work we adopt Arvo's historical convention. Backwards Ray Tracing Any backward ray tracing 
technique will be a two pass algorithm - the backward ray tracing from the light forming the view independent 
step, followed by the forward ray tracing step from the eye. Central to the working of such a strategy 
wilt be how information derived during the first pass is communicated to the second or, to borrow a phrase 
from Arvo, how the rays ' meet in the middle '. Arvo [2] suggests achieving this via an illumination 
map, consisting of a grid of data points, which is pasted onto each object in the scene in much the same 
way as a texture map. A given illumination ray, originating from the light, strikes an object at a point 
and depositing a certain amount of energy in the surrounding data points, continues on its course, reflecting 
and refracting through the scene. The first pass consists of ' showering ' the scene with these illumination 
rays. By ignoring first generation hits, which directly illuminate an object, upon completion of this 
'showering' ,the illumination map will provide a measure of the indirect illumination received by the 
object. During the rendering phase a ray striking the object will pick up a value for this indirect illumination 
using bilinear interpolation between nearby data points. The first phase, by using infinitely thin i11urnination 
rays to deposit quanta of energy, is point sampling the specular to diffuse energy distribution of the 
scene. Again, since there is no reason to assume this distribution to be slowly varying, this approach 
will be highly prone to aliasing problems. This aliasing is compounded further as the diseretization 
of the illumination maps into data points may introduce yet more artifacts. A faithful representation 
of a specular to diffuse effect of a given frequency, will require constructing an illumination map of 
greater frequency of data points and, in turn, showering sufficient illumination rays to ensure that 
hits on the map arc many times as dense as these data points. Other techniques include Zhu ' two-way 
ray tracing ' [20] and Chattopahyay and Fujimoto ' bi-directional ray tracing ' [6]. If the acid test 
for shading algorithms is the quality of the image produced -not an unreasonable criterion -neither technique 
is particularly impressive in that the specular to diffuse effects rendered are, as in the radiosity 
examples, soft and vague. It is dear that backward ray tracing as a relative newcomer to computer graphics 
is still in its infancy. Since the vast bulk of ray tracing methods fall into the forward ray tracing 
category, there exists a disparity in terms of the effort invested between the two. Much work has been 
done on bouncing rays around the scene from the eye but little from the light ( Heckbert and Hanrahan 
[8] were the first to mention this asymmetry ). We will show that backward ray tracing can produce useful 
results and suggest it is a powerful idea and a fruitful area for future research. Light Beam Tracing 
We present a two pass algorithm, the first pass based on a variation of backward ray tracing called backward 
beam tracing, that provides a solution of specular to diffuse transfer in polygonal environments including 
shadowing effects. The algorithm is closest in spirit to a suggestion made by Heckbert and Hanrahan ' 
Beam tracing polygonal objects ' [8] and it is from here that it takes its name. We confine our atlantion 
largely to first generation specular to diffuse transfer only but, theoretically, there is no restriction 
on recursion providing the transport is of nature : specular -> specular -> ..... ->specular -> diffuse 
 In this respect it suffers from exactly the same problems as the two mainstream global illumination 
models in that they too are based on one mechanism of light transfer only. In the algorithm objects in 
the environment are separated into specular objects which retrensmit the light incident upon them, by 
reflection or refraction, onto the diffuse objects. (i) first pass - backward beam tracing For each polygon 
of each specular object we construct a light beam by casting rays from each vortex to the light. Next 
we construct the transmitted light beam, by reflection or refraction with the vertex normals, and sweep 
this beam throughout the entire scene testing for intersections with diffuse polygons. If an intersection 
occurs we project the transmitted light beam onto the plane of the diffuse polygon. Shown in figure 2 
are two such light beams the first of which becomes divergent after refraction, spreading the light over 
a larger area than that of the specular polygon; the second, convergent, focuses the light onto the diffuse 
polygon This projection forms the caustic polygon which is allotted an intensity and a tag signifying 
which diffuse polygon is responsible for its generation. The caustic polygon is added to the polygonal 
database as a surface detail polygon ie. a polygon which does not affect the shape of an object - only 
its shading. This step has the usual advantages of view independence namely it need only be computed 
once providing the spatial relationships between the objects and lights remain unchanged. SIGGRAPH '90, 
Dallas, August 6-10, 1990  lar / l \ \ polygon diffuse polygon Figure 2. Generation of caustic polygons. 
 Since, under this scheme, the resolution of the specular polygons dictates the resolution of the transmitted 
light beam, the size of tho specular polygon is critical. A given specular object may be faithfully represented 
by polygons of a given size. But the resolution required to represent the object may well be inadequate 
when representing the light this object Wansmits. In general it was found that the specular polygons 
had to be much smaller when modeling the light than when modeling the specular object itself. (ii) second 
pass - rendering The rendering phase proceeds largely as it would normally with only one exception. If 
a diffuse polygon is visible under a pixel we check to see if it has any caustic polygons associated 
with it. In general a diffuse polygon may intersect more than one light beam and so can have more than 
one attendant caustic polygon. The intensity of the caustic polygon is simply added to the diffuse component 
of the final shaded value of the diffuse polygon. What intensity are we to assign to the caustic polygon 
? Let us assume distances between the light and objects are large compared to distances between the objects 
themselves. If this is not the case an extension to include 1/r 2 fall off is straightforward. The specular 
polygon, then, has an intensity, I, incident upon it. The fraction of energy, E, arriving on the specular 
polygon is the product of I and the area of the polygon ' seen ' by the light, ie. its area projected 
in the direction of the fight L. Referring to figure 3 then, we have: E = I N.L AreaSpec Where N, the 
normal associated with the plane of the specular polygon, is usually different from the normals at the 
individual vertices. Assuming that the specular polygon absorbs no energy, E will thus be the energy 
incident on the caustic polygon. We can easily include an absorption coefficient into the calculation 
should this assumption not hold. Providing the specular polygon is small enough such that the variation 
of distances between points on the specular polygon and points on the caustic polygon is negligible, 
we can say that this energy will be distributed uniformly over the caustic polygon. The intensity of 
the caustic polygon Icaustic, is thus : Icanstic = E / AreaCaus = I N.L AreaSpec / AreaCaus ( I ) N 
/// AreaSpec AreaCaus Figure 3. Generation of Icaustic. This term resembles the form factor of radiosity. 
This is not surprising since its derivation starts from similar considerations of energy transfer, projected 
areas etc. Indeed, removing the assumptions made about distances in the derivation would take us even 
closer to a form factor definition. This suggests that the step of constructing caustic polygons from 
specular polygons could be construed as constructing special, simplified adaptive form factors that take 
full advantage of an a priori knowledge of light propagation in the environment. Compare this to the 
traditional method of building form factors which entails a somewhat arbitrary dicing up of surfaces 
completely independently of the light distribution. Many radiosity algorithms quote this independence/ignorance 
of lights as an advantage -while it may be good for the algorithm's generality it certainly does nothing 
for the rendering of complex images efficiently. The algorithm has the following advantages over existing 
techniques for rendering specular to diffuse effects : (i) ease of implementation -since the caustic 
polygons translate into surface detail polygons during the second rendering phase, standard depth buffer 
or ray tracing renderers need only minor modification to implement the algorithm. (ii) efficiency - above 
all the algorithm is efficient. As we shall see later, frame times are sufficiently small to enable animated 
caustic sequences to be produced. Reasons for this efficiency include the following : The reduction of 
caustic polygons to surface detail polygons in the second pass removes the need to clip the caustic polygon 
to its diffuse polygon in the first pass. During the rendering a caustic polygon is only rendered if 
its diffuse polygon is behind it. In the case of depth buffer renderers, regions where the caustic polygon 
exists and the diffuse polygon do not, are masked out by the pixel mask of the diffuse polygon. In the 
case of ray tracers these regions are not even considered since ray-caustic polygon intersections are 
only tested for after a ray-diffuse polygon intersection occurs. Optimization techniques developed for 
ray-object intersections in forward ray tracers, such as space partitioning or hounding volumes, can 
be adopted when testing for ~ausmiCed beam-diffuse polygon intersections during the first pass. (iii) 
By replacing rays, which point sample the environment, with beams we avoid aliasing problems associated 
with the former. By using light beams we are effectively tracing a bundle of rays with an intensity varying 
as the density of rays in the bundle changes through the optical system. As shown in (I) this density 
is inversely proportional to the bundle's cross section or, in our terminology, Areacaus, the area of 
the caustic polygon. (iv) The intricacy of the light pattern produced on the diffuse surface is directly 
related to the geometric complexity of the specular surface. The greater the variation in curvature of 
the specular surface the greater the directions over which incident light is dispersed. By driving the 
method from the specular surface, regions over which the curvature varies rapidly can be sampled more 
intensively . Such adaptive sampling enables sharply varying specular to diffuse phenomenon to be represented 
efficiently thereby, extending the range over existing techniques which, hitherto, as we have seen, have 
confined themselves to rendering only the vaguest of effects. We now turn our attention to the term 
caustic. Derived from the fact that a lens can focus sunlight to burn a hole in a surface, it is a term 
taken from classical optics and is completely synonymous and interchangeable with our term specular to 
diffuse transfer. We include a discussion of the treatment of caustics within classical optics here [5], 
since it provides us with valuable insights into the precise nature of specular to diffuse transfer. 
Caustics We start with some definitions. If a curve exists such that it is tangent to family of curves 
but is not itself a member of that family, then it is the envelope of that family. Let the family of 
curves be those rays transmitted from a specular surface then Computer Graphics, Volume 24, Number 4, 
August 1990 Figure 4. Reflected caustic in spherical mirror. the caustic surface is the envelope of 
the transmitted rays. Figure 4 shows an example of a caustic surface formed after reflection, created 
when light Izavelling parallel to the axis of revolution of a spherical mirror is reflected by it. The 
caustic can be shown to be an epieycloid, the cusp of which is at the principal focus of the mirror. 
An everyday example is the bright line on the surface of a cup filled with liquid - due to intersections 
between rays of light reflected from the cylindrical wall of the cup and the liquid. vortex perturbing 
! water surface \ i Figure 5. Refracted caustic through water vortex. I @SIGGRAPH '90, Dallas, August 
6-10, 1990 Figure 5 shows a caustic formed by refraction in water. The surface of the water is deformed 
by a vortex shed from an object, eg. an oar, moving through the water.. A section through the caustic, 
such as would be seen at he bottom of a tank, consists of two concontric circles bounding a bright ring. 
A radial slice of this section in relation to the causticsurface is shown diagrammatically at the foot 
of the figure. The circles on the edges of the ring, caused by intersection with the caustic surface, 
are brightest; the interior of the ring where light is refracted away from the axis of the vortex is 
darkest. Studies of such patterns have enabled Berry and Hajnal in 'The shadows of floating objects and 
dissipating vortices' [4] to predict analytically the shape of the vortex to be a blend of a parabolic 
core surrounded by a hyperbolic surface. Figure 6. Let us look at the caustic surface more closely. 
Consider the specular surface described by curvilinear coordinates (u,v) as shown in figure 6. Each point 
P(u,v) on the surface has associated with it a transmitted ray in the direction of r(u,v). Any point 
p on this ray is given by : p(u,v,s) = P(u,v) + sr(u,v) where s is the length along Pp. Foci occur where 
rays emanating from the surface intersect, or to translate into terms of differential geometry, assuming 
the surface to be differentiable, where points on these rays are separated by a distance that is of second 
or higher order ie. p(u,v,s)= p(u+du,v+dv, s+ds) which, expanding out, gives : Pu du + Pv dv + Psds 
= 0  where Pu,Pv and Ps are the partial derivatives with respect to u,v, and s. This implies that the 
three vectors Pu,Pv and Ps are coplanar which is equivalent to saying that their scalar triple productvanishes 
ie. [Pu, Pv, Ps] = 0 Now p is linear in s, and Ps is independent of s, so the above reduces to quadratic 
in s. This means that there are two loci on each light ray. As u and v vary over the specular surface 
the foci traces out a corresponding caustic surface which comprises of two separate caustic sheets. This 
is a remarkable result, although the transmitted light may create structures rivaling a pinnacled cathedral 
in complexity, each light ray will be Umgent to the two sheets. These caustic sheets meet at cusps or 
folds, which are actually sections of three-dimensional catastrophes, and are the proper study of catastrophe 
optics [3]. Consider figure 4, one of these sheets is a trumpet shaped surface of revolution, whose cross 
section is an epicycloid, the other degenerates to a line segment lying on the axis of revolution. In 
the case of figure 5 the caustic sheets consist of two rougldy cylindrical sheets joined at a cusp edged 
ring. Returning to our algorithm, the diffuse polygon can be interpreted as sampling slices of this partially 
concealed structure. The intersection of the plane of the diffuse polygon with this structure provides 
us with a cross sectional view of it -a picture made up of caustic polygons. This picture will depend 
largely on the orientation and distance between the diffuse polygons and the caustic surface. If a diffuse 
polygon is close to one of the caustic sheets and more or less tangential to it, it will appear approximately 
uniformly lit -the intensity increasing the closer the diffuse polygon gets to the sheet. If the diffuse 
polygon is more or less normal to a caustic sheet the variation of light intensities across it will increase 
the closer it gets to the sheet - until it actually intersects whereupon it will have a bright line running 
through it. The farther the diffuse polygon gets from the caustic surface the more negligible and uniform 
the effect becomes as the light rays become more dispersed ie. as the specular to diffuse effect tends 
to diffuse to diffuse. The latter consideration provides us with a bound beyond which specular to diffuse 
effects can be ignored. For more details on caustics and their treatment within computer graphics, including 
an expanded version of this paper, the reader is referred to [19]. Shadowing The algorithm also solves 
for shadowing effects on the diffuse surface within the context of first generation specular to diffuse 
transfer. There are two distinct cases depending on whether the shadowing object is : (i) between the 
light and the specular surface, or (ii) between the specular surface and the diffuse surface.  These 
cases have to be treated separately, but both produce shadowing effects on the diffuse surface that differ 
from traditional computer graphic shadows. In case (i) a straight silhouette edge may produce a shadow 
on the diffuse surface  parts of the pencil cast typical shadows (cases (i) and (ii) of the shadowing 
section respectively) but the meniscus generates caustics which concentrate tight in the gap area thereby 
washing out the shadow one would expect to fred. Figure 10 shows a good approximation of this phenomenon 
with the front section of the bowl removed for clarity. The meniscus is represented as an e11iptical 
annular region over which the normals are varied from the unperturbed vertical state on the exterior 
lxmndm3, to the contact angle with the shaft at the interior. This contact angle changes round the shaft 
being greatest where the pencil forms an acute angle with the water and least where the angle is most 
obtuse. Both the shadows and caustics were calculated at the view independent phase by adaptively subdividing 
the water surface -performing more work around shadow edges and the meniscus. Conclusions and future 
directions A method of computing specular to diffuse transfer using backward beam tracing has been presented. 
It is shown to have advantages over radiosity and ray tracing approaches. The use of beams originating 
from the light ensures adequate and efficient adaptive sampling. Its application to the interaction of 
light with water is particularly effective. Extensions include applying the algorithm to model other 
instances of specular to diffuse transfer and removing the restriction to first generation effects by 
recursively tracing the beams. This would enable the modeling of, say, the caustics produced on a tablecloth 
when light is refracted through a wine glass. More generally, it is hoped that this work draws attention 
to the pertinence of algorithms driven from the eye, for this transport mechanism at least, and it is 
suggested that work could be done exploiting this notion further. Acknowledgements Thanks to Dr. Alan 
Watt of Sheffield University for background research, reviewing early drafts and continued moral support. 
Thanks also to David Lomax of Digital Pictures for help in the initial stages of the development of the 
algorithm and to Digital Picturesfor their support. References [I] Adler, Cyrus. Shadow-sausage effect. 
American journal of physics, Vol. 35, No. 8, (August 1967), 774-776. [2] Arvo, James. Backward ray tracing. 
Developments in ray tracing, siggraph course notes, Vol. 12. (August 1986). [3] Berry &#38; Upstill. 
Catastrophe optics : morphologies of caustics and their diffraction patterns. Progress in optics,Emil 
Wolf ed, Elsevier North-Holland" VoL 18, (1980). [4] Berry &#38; Hajnal. The shadows of floating objects 
and dissipating vortices. Optica Acta, Vol. 30, No. 1, (January 1983), 23-40. [5] Born &#38; Wolf. Principles 
of optics, Pergamon Press, (1964). [6] Chattopadhyay &#38; Fujimoto. Bi-directional ray tracing. Computer 
graphics : proceedings of CG International 1987, Tosiyasu Kunii ed., Springer Verlag, Tokyo, (1987), 
335-343. [7] Glassner, Andrew S. An overview of ray tracing. An introduction to ray tracing, Andrew 
Glassner ed., Academic Press, (I989), 1-31. [8] Heckbert &#38; Hmarahan. Beam txacing polygonal objects. 
Computer graphics, Vol. 18, No. 3, (July 1984), 119-127. [9] Hockney, David. Portrait of an artist ( 
pool with two figures ). [painting] (1971). [10] ImmeL Cohen, &#38; Greenberg. A radiosity method for 
non- diffuse environments. Computer graphics, Vol. 20, No. 4, (August 1986), 133-142. [11] Kajiya, flames 
T. The rendering equation. Computer graphics, Vol. 20, No. 4, (August 1986), 143-150. [12] Max, Nelson 
L. Vectorized procedural models for natural terrain : waves and islands in ~e sunseL Computer graphics, 
Vol. 15, No. 3, (August 1981), 317-324. [13] Nishita, Miyawaki &#38; Nakamae. A shading model for atmospheric 
scattering considering luminous intensity distribution of light sources. Computer graphics, Vol. 21, 
No. 4, (July 1987), 303-308. [14] Shao, Peng, &#38; Liang. A new radiosity approach by procedural refinements 
for realistic image synthesis. Computer graphics, Vol. 22, No. 4, (August 1988), 93-101. [15] Siegel 
&#38; Howell. Thermal radiation heat transfer, second edition, Mcgraw-Hill, (1981), 142-145. [16] Sillione 
&#38; Puech. A general two pass method integrating specular and diffuse reflection. Computer graphics, 
VoL 23, No. 3, (July 1989), 335-344. [17] Wallace, Cohen, &#38; Greenberg. A two-pass solution to the 
rendering equation : a synthesis of ray-tracing and radiosity methods. Computer graphics, Vol. 21, No. 
4, (July 1987), 311-320. [18] Ward, Rubinstein) &#38; Clear. A ray tracing solution for diffuse interreflecdon. 
Computer graphics, Vol. 22, No. 4, (August 1988), 85-92. [19] Watt, Alan &#38; Watt, Mark. Advanced rendering 
and animation techniques : theory and practice. Addison - Wesley. To be published Autumn 1990. [20] Zhu, 
Peng &#38; Liang. PERIS : a programming environment for realistic image synthesis, computers and graphics, 
Vol. 12, No. 3/4, (1988), 299-307.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97921</article_id>
		<sort_key>387</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[A method of generating stone wall patterns]]></title>
		<page_from>387</page_from>
		<page_to>394</page_to>
		<doi_number>10.1145/97879.97921</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97921</url>
		<abstract>
			<par><![CDATA[Recently, several kinds of mapping technology, such as texture mapping and bump mapping, have played a very important role in the realization of more realistic image synthesis. The textures to be mapped are often obtained by using an optical scanner or a video camera. However, it is not easy to obtain a suitable image by taking a photo. We consider it very important to be able to generate a variety of textures and patterns easily according to the requirements. This paper proposes a new method of generating stone wall patterns as a specific case of a generalized texture generator. The advantage of the method is that it allows the user to generate a variety of stone wall patterns by specifying a few simple parameters. We have applied it to a visual simulation system in order to represent such stone textures as walls, pavements, and steps. This paper also gives some examples of its applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31087105</person_id>
				<author_profile_id><![CDATA[81100338478]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kazunori]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miyata]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research, Tokyo Research Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M.F. Cohen, S. E. Chen, J. R. Wallance, and D. P. Greenberg, "A Progressive Refinement Approach to Fast Radiosity image Generation," Computer Graphics, Vol. 22, No. 4, pp. 75-84, 1988.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Weil, "The Synthesis of Cloth Objects," Computer Graphics, Vol. 20, No. 4, pp. 49-54, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378503</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Prusinkiewicz, A. Lindenmayer, and J. Hanan, "Developmental Models of Herbaceous Plants for Computer Imagery Purposes," Computer Graphics, Vol. 22, No. 4, pp. 141-150, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Y. Gardner, "Visual Simulation of Clouds," Computer Graphics, Vol. 19, No. 3, pp. 297-303, 1985.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Fournier, "A simple model of ocean waves," Computer Graphics, Vol. 20, No. 4, pp. 75-84, 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J.T. Kajiya and T. L. Kay, "Rendering Fur with Three Dimensional Texture," Computer Graphics, Vol. 23, No. 3, pp. 271-280, 1989.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807443</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. I. Yessios, "Computer Drafting of Stones, Wood, Plant and Ground Materials," Computer Graphics, Vol. t3, No. 2, pp. t90-I 98, 1979.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. Mezei, M. Puzin, and P. Conroy, "Simulation of Patterns of Nature by Computer Graphics," Information Processing 74, pp. 861-865, 1974.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808605</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. P. Lewis, "Texture Synthesis for Digital Painting,u Computer Graphics, Vol. 18, No. 3, pp. 245-251, 1984.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Haruyama and B. A. Barsky, "Using Stochastic Modeling for Texture Generation," IEEE CG&amp;A, pp. 7-19, Mar. 1984.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Perlin, "An Image Synthesizer," Computer Graphics, Vol. 19, No. 3, pp. 287-296, 1985.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74359</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[K. Perlin and E. M. Hoffert, "Hypertexture," Computer Graphics, Vol. 23, No. 3, pp. 253-262, 1989.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74360</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J.P. Lewis, "Algorithms for Solid Noise Synthesis," Computer Graphics, VoI. 23, No. 3, pp. 263-270, 1989.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. B. Mandelbrot, "Fractals Form, Chance, and Dimension," Freemann, San Fransisco, 1977.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Fournier, D. Fussel, and L. Carpenter, "Computer Rendering of Stochastic Models," Communications of ACM, Vol. 25, No. 6, pp. 371-384, 1982.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 24, Number 4, August 1990 A Method of Generating Stone Wall Patterns , Kazunori 
Miyata IBM Research, Tokyo Research Laboratory Abstract Recently, several kinds of mapping technology, 
such as texture mapping and bump mapping, have played a very important role in the realization of more 
realistic image synthesis. The textures to be mapped are often obtained by using an optical scanner or 
a video camera. However, it is not easy to obtain a suitable image by taking a photo. We consider it 
very important to be able to generate a variety of textures and patterns easily according to the requirements. 
This paper proposes a new method of generating stone wall patterns as a spe- cific case of a generalized 
texture generator. The ad- vantage of the method is that it allows the user to gen- erate a variety of 
stone wall patterns by specifying a few simple parameters. We have applied it to a visual simulation 
system in order to represent such stone tex- tures as wails, pavements, and steps. This paper also gives 
some examples of its applications. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: 
Picture/Image Generation; 1.3.7 [Computer Graphics]: Three Dimensional Graphics and Realism - color, 
shading, shadowing, and texture. General Terms: Graphics Additional Key Words and Phrases: texture, 
stone wail, simulation of natural phenomena, fractal, texture gen- eration  1. Introduction 1.I Background 
 Recently, there has been a growing tendency for com- puter graphics to be used as a presentation tool. 
Many research papers have been published on methods of rendering various objects realistically in computer 
graphics. Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
In the research field of rendering methods, global illu- mination algorithms such as ray tracing and 
the radiosity method [1] have been developed. These gen- erate very realistic images, and can render 
an enormous variety of objects, including cloth objects [2], trees [3], clouds [4], waves [5], and fur 
objects [6]. In contrast, there have been few research papers on methods of generating realistic textures. 
The main rea- son for this is that it is possible to generate a reasonably satisfactory image by performing 
texture mapping with a real photo instead of a computer-generated image. Moreover, this reduces the calculation 
cost. However, it places a heavy burden on the operator to get the photo image he wants. Furthermore, 
if the input photo image is smaller than the mapping surface, the texture- mapped image will be imperfect, 
because the input photo image is mapped cyclically. Texture generation is therefore a very important 
field in computer graphics. Most conventional texture generation methods are gen- eralized ones and can 
generate various types of texture. But they do not consider the constraints of natural textures, so the 
output images are not so realistic. We are now developing a texture generator that considers the constraints 
of natural textures and can generate highly realistic textures with a few simple parameters. C. I. Yessios 
has presented three methods of drafting stone walls [7], but the output data are only two-dimensional 
line patterns. Our paper describes a method of generating realistic stone wall patterns that can be used 
as textures in architectural design. This method uses a few parameters and the constraints of stone walls. 
The average size of stone, the roughness of its surface, the variance of its size, and so on are used 
as input parameters. The output data are a bump data file, which represents the stone's height data, 
and an attribute data file, which represents the stone's at- tributes. A highly realistic image of a 
castle and its walls can be obtained by mapping the generated pat- terns. 1.2 Previous work on texture 
generation L. Mezei et al. presented the results of a few studies in the simulation of natural patterns 
[8]. In that method, textures can be generated by distributing small symbols on a surface with a dense, 
uniform, random pattern. For example, the texture of rock is generated by dis- tributing curved lines 
on several faces. @1990 ACM-0-89791- 344-2/90/008/0387 $00.75 387 @SIGGRAPH '90, Dallas, August 6-10, 
1990 J. P. Lewis presented a "sparse convolution" procedure for generating random textures with arbitrary 
spectral content [9]. His method generates a texture by inter- preting its frequency domain, using inverse 
Fourier transformation. Sparse convolution is used to avoid some undesirable properties such as periodicity 
and well-defined edges. S. Haruyama and B. A. Barsky developed a method of generating realistic random 
textures to add natural roughness to a surface [10]. Their method can represent complicated random textures 
with few data, which al- lows the operator to control the textural properties eas- ily. K. Perlin designed 
a Pixel Stream Editor that forms the basis for a synthesizer for designing realistic Com- puter Generated 
Imagery [11]. A texture is generated by composition of non-linear functions. K. Pertin and E. M. Hoffert 
modeled phenomena in- termediate between shape and texture by using a space- filling applicative function 
to modulate density [12]. They synthesized various phenomena by combining a set of base-level texture 
functions. J. P. Lewis developed solid noise synthesis algorithms that give improved control over the 
noise power spec- trum and make no artifacts [13]. Wiener interpolation is used for interpolating random 
values on a discrete lattice. A sparse convolution is used to avoid the covariance function constraints 
of the noise lattice in- terpolation approach. 2. A stone wall model The pattern in which the stones 
of a wall are piled together depends on the quarried stone. This section describes a model of a stone 
wall pattern and its data structures. 2.1 A stone wall model A stone wall is created by piling together 
quarried stones. The resulting pattern can be represented by the wall's joint pattern. In this paper, 
a stone wall pattern is represented by a combination of the joint pattern and the stone textures. The 
joint pattern is represented by a meshy model which is called the "node &#38; link model," shown in Figure 
I. Each node has position and link data. Each enclosed space of the joint pattern is equivalent to the 
space occupied by a stone in the wall. The texture of the stone is generated by using a fractal [14] 
technique, and each line segment of an inter- node is subdivided recursively to generate a natural joint 
pattern. 2.2 A data structure Next, the data structures of the "node &#38; link model" are described 
in a Pascal format. Each node has position and link data. The links are restricted to four directions: 
upper, lower, right, and left. The structure "edge" rep- resents the line segment of an inter-node. type 
Position = record x, y : integer end; type Node = record p : Position; upper, lower, right, left : TNode 
end; type Edge = record nl, n2 : TNode; line : TPosition; n : integer { No. of point } end; stone area 
Fig. 1 Node &#38; link model I upper node (x, y) edge t nt -.o  left right -~.¢"~r~--~-~ I lower n 
2 l Fig. 2-1 Data Structure Fig. 2-2 Data Structure of node of edge Fig. 2 Data structure   3. Generation 
of a stone wall pattern In this section, a method of generating stone wall pat- terns is described, using 
the "node &#38; link model." First, the generation procedure is described, and then each procedure is 
explained in detail.  3.1 The generation procedure The generation procedure has the following six steps. 
Figure 3 shows the flow chart. 1. The basic joint pattern is generated by using the average size of a 
stone in the wall and the variance of its size. . The basic joint pattern is deformed by relocating its 
nodes. After node relocation, each line segment is subdivided reeursively, using the fraetal method. 
 ~ Computer Graphics, Volume 24, Number 4, August 1990 . The space occupied by each stone is found by 
using the link information of the basic joint pattern. The stone space is a polygon formed by nodes and 
line segments. 4. The texture of individual stones is generated by subdividing the stone primitive reeursively. 
For this, the fractal method and the roughness value of the stone are used. . The stone texture is clipped 
by cut polygons, which are contracted polygons of the stone spaces. . The height data and the attributes 
of the clipped stones are placed in the bump plane and the at- tribute plane, respectively, by the scan-line 
method. Generation of basic joint pattern [  I Def°rmati°n °f basic j°int pattern ] ] Determination 
of stone area ] I Generation of stone texture I [ Clipping of stone texture I  I or,,o°o,oxt= I I End 
[ Fig. 3 Procedure Ilow 3.2 Generation of the basic joint pattern We now explain the generation of the 
basic joint pat- tern, which contains the basic data of a stone wall pat- tern. The basic pattern is 
generated by using the average size of a stone in the wall and the variance of its size as parameters. 
The procedure for generating the basic joint pattern is similar to the process of piling up the stones. 
First, the stones are placed side by side on the horizontal base line, as shown in Figure 4. The size 
of each stone, Lv and Lh, is varied with a random number, given by Eq. (1). Each node position and its 
link data are then generated. Lv = Lv x Noise (1) ) L h = L h x Noise Noise : Uniform random number After 
this, the next column of stones is piled up. At this time, the following procedure is performed to elim- 
inate vacant space. If the newly added stone leaves vacant spaces, as shown in Figure 5, each vacant 
space becomes a new stone space. This piling up procedure is repeated until the stone wall reaches the 
given height. Figure 6 shows an example of a generated basic joint pattern. Fig. 4 A base-line stone 
placement V~ stone  ~- vacant space i i Fig. 5 Eliminating vacant space Fig. 6 Example o! a basic joint 
pattern 3.3 Deformation of the basic joint pattern To make the joint pattern appear natural, the basic 
joint pattern is deformed by displacing each node, and the final joint pattern is generated by subdividing 
each line segment of the inter-node. When the deformation is done, a concave polygon must not be formed. 
For example, if the node (the black circle) is located, as shown in Figure 7(1), it must be displaced 
upward to form a convex polygon. If the node is displaced downward, it will form a concave L v : average 
vertical length of a stone polygon. Lh : average horizontal length of a stone SIGGRAPH '90, Dallas, 
August 6-10, 1990 After the node displacement, each line segment of the inter-node is subdivided recursively, 
using the fractal method. The subdivision method uses midpoint dis-placement [15]. Figure 8(1) shows 
the deformed joint pattern of Figure 6, and Figure 8(2) shows the final joint pattern, which is generated 
by subdividing each line segment.  --? ?-- Fig. 7-1 Before displacement t I Q m i I I Fig. 7-2 Concave 
case Fig. 7-3 Convex case Fig. 7 Node displacement Fig. 8-1 Before Fig. 8-2 After subdivision subdivision 
Fig. 8 Example of a joint pattern 3.4 Determination of the stone area Next, the area of each stone is 
found by using the link data of nodes. The area of a stone is a polygon that is found by following the 
innermost link clockwise. We illustrate link-following in Figure 9. Each link has the link data U (upper), 
R (right), D (lower), and L (left), as shown in Figure 2. The link-following starts at node A, at the 
U-link. The first candidate of the next link direction on node B is the R-link, and the second is the 
U-link. In this case, the R-link exists, so it is selected as the next link direction. The candidates 
for the next link direction are listed in Table 1. With this candidate table, each stone area is determined 
by following the links so as to form a closed loop. In many cases, the stone area is a quadrangle, pentagon, 
or hexagon. In the case of region G, shown in Figure 9, the link-following starts at node A, and follows 
the path U~R-,R~D~L~L, so the stone area is a hexagon. u i r I ! u C t stone area F \ d Fig. 9 Link-following 
Link Status 1st Candidate 2nd Candidate U R U R D R D L D L U L Table 1 Candidate table  3.5 Generation 
of the stone texture The 3D shape of a stone in a wall is reconstructed by recursively dividing the patch 
triangles of the stone primitive into smaller triangles, as shown in Figure 10 [15]. The stone primitive 
is shown in Figure 11, where Lv, Lh, and H are the vertical length, the horizontal length, and the height 
of the stone, respectively. The midpoint of each side of the triangle is identified, and a point at a 
vertical distance V from one of the mid- points is used to create new triangles, where V is the displacement 
value given by Eq. (2). V ----2 -(n+l)(D-l} x Rnd × L (2) V : Displacement value D : Roughness value 
(fractal dimension, 1.0-2.0) n : Subdivision level L : Edge length  Rnd : Regular random number (0 
mean, unit variance) C A B Fig. 10 Three-dimensional recurslve division of a triangle  '~- Computer 
Graphics, Volume 24, Number 4, August 1990 "~-----.-_._._..._..._.__ patch triangle Fig. 11 A stone 
primilive 3.6 Clipping of the stone texture This section explains the method of clipping the stone texture, 
which is the preprocess for the placing method explained later. When the stone texture is clipped, it 
is required that a joint space should remain. In this method, the joint space is generated by contracting 
the polygon of each stone space. The center of contraction is the center of gravity of the polygon. The 
contraction is performed by translating each vertex Of the polygon inward by d, as shown in Figure 12. 
The contraction ratio t on vertex p is given by Eq. (3). Therefore, the translated vertex q of vertex 
p is given by Eq. (4). For t < 0, we set t to 0. Hereafter, the contracted polygon of the stone space 
is called the cut polygon.  IP - ml-d d t I~ ml 1 (3) -iF = + -  ( ') (4) /: ~'~ / ~ cut polygon 
Ill ~m t'rJ i'_~_ (st°ne area) Fig. 12 Contraction of a polygon 3.7 Placing of the stone texture Each 
item of height data in the generated stone texture is clipped with a cut polygon and placed on the bump 
plane. Each stone texture is located so that its center coincides with the center of gravity of the cut 
polygon. The height data are calculated by using a scan-line method. The attribute plane is cleared 
with the ID of the joint space, 0, initially. The ID of each stone, 1, 2, 3 ..... is then placed on the 
attribute plane at the same time as the stone texture, as shown in Figure 13. These IDs are used to change 
the color of each stone, its optical features, and so on.  generated ~ /  cut polygon J   z2Z;7 
z-'- height data attribute data Fig. 13 Placing of a stone's data 4. Examples In this section, we give 
some examples of generated stone wall patterns. 4.1 Rendering method In this method, a bump data file 
and an attribute data file are used to render a stone wall pattern. A bump data file is used for the 
shading process. A bump data file represents each stone's height data. Therefore, it can be used to calculate 
the normal vector of each point with its adjoining points. An attribute data file is used to change the 
color ot" each stone, its optical features, and so on. These images were generated by using an IBM 3081 
as host computer, an IBM 5080 for graphic display, and C language for programming. Each result is a 512 
X 512 (8 bits per R-, G-, B-plane) image. The calculation time depends on the number of stones piled, 
and averages about four minutes. 4.2 Examples Some examples of generated stone wall patterns are shown 
in Figure 14. The meanings of the parameters listed in Table 2 are as follows: Lv : vertical length 
of a stone  L h : horizontal length of a stone  H : height of a stone  D : roughness value of a stone's 
surface (1.0-2.0)  V v : variance of the vertical length of a stone (0.0-1.0)  SIGGRAPH '90, Dallas, 
August 6-10, 1990 V h : variance of the horizontal length of a stone (0.0-1.0)  By : vertical displacement 
value (0.0-I.0)  B h : horizontal displacement value (0.0-1.0)  J : joint width  First, in Figures 
14(1)-(3), we show how the stone tex- ture changes with the roughness value. As these figures indicate, 
the stone texture gets rougher as its roughness value increases. Figure 14(4) shows an image whose displacement 
value is zero. As this image shows, a block-type stone wall can be generated. Figure 14(5) shows an image 
in which the variance of the horizontal length of stones is high. As this image indicates, the vertical 
length of each stone is almost the same, but the horizontal length is not. Figure 14(6) shows an image 
whose horizontal and vertical displacement val- ues are high. The joint pattern is more complicated than 
in Figures 14(1) and 14(4). Figure 14(7) shows a rough-hewn stone wall. This pattern is generated by 
choosing a large height for the stones. Figure 14(8) shows a brick wall pattern. This kind of image can 
be generated by choosing a low variance and displacement parameter. Finally, we give two sample images 
gener- ated by performing texture mapping with a stone wall pattern. Figure 15 shows an image of Edo 
Castle. The stone wall patterns are mapped on the ramparts. Figure 16 shows an image of the dungeon. 
 5. Conclusions A method of generating highly realistic stone wall pat- terns by using just a few parameters 
is explained. In future, we plan to work on the following areas. Reduction of the calculation time The 
bottleneck of the calculation time is the procedure for generating the stone texture. Therefore, to reduce 
the calculation time, it is necessary to speed up the recursive subdivision method. Generation of a 
more realistic stone texture To generate a more realistic stone texture, it is necessary to consider 
not only the form of a stone but also its composition. Furthermore, we plan to apply this method to gener- 
ating tortoise shell, scales, reptile skins, and rind tex- ture.  Acknowledgment I would like to thank 
researchers at the Tokyo Research Laboratory for their helpful suggestions. I would also like to thank 
Fujita Corporation for providing the model of Edo Castle used for Figure 15. References 1. M.F. Cohen, 
S. E. Chen, J. R. Wallance, and D. P. Greenberg, "A Progressive Refinement Ap-proach to Fast Radiosity 
Image Generation," Com- puter Graphics, Vol. 22, No. 4, pp. 75-84, 1988. 2. J. Weft, "The Synthesis of 
Cloth Objects," Com- puter Graphics, Vol. 20, No. 4, pp. 49-54, 1986. 3. P. Prusinkiewicz, A. Lindenmayer, 
and J. Hanan, "Developmental Models of Herbaceous Plants for Computer Imagery Purposes," Computer Graph- 
ies, Vol. 22, No. 4, pp. 141-150, 1988. 4. G. Y. Gardner, "Visual Simulation of Clouds," Computer Graphics, 
Vol. 19, No. 3, pp. 297-303, 1985. 5. A. Fournier, "A simple model of ocean waves," Computer Graphics, 
Vol. 20, No. 4, pp. 75-84, 1986. 6. J.T. Kajiya and T. L. Kay, "Rendering Fur with Three Dimensional 
Texture," Computer Graphics, Vol. 23, No. 3, pp. 271-280, 1989. 7. C. I. Yessios, "Computer Drafting 
of Stones, Wood, Plant and Ground Materials," Computer Graphics, Vol. 13, No. 2, pp. I90-198, 1979. 
8. L. Mezei, M. Puzin, and P. Conroy, "Simulation of Patterns of Nature by Computer Graphics," In- formation 
Processing 74, pp. 861-865, 1974. 9. J. P. Lewis, "Texture Synthesis for Digital Paint- ing," Computer 
Graphics, Vol. 18, No. 3, pp. 245-251, 1984. 10. S. Haruyama and B. A. Barsky, "Using Stochastic . Modeling 
for Texture Generation," IEEE CG&#38;A, pp. 7-19, Mar. 1984.  I1. K. Perlin, "An Image Synthesizer," 
Computer Graphics, Vol. 19, No. 3, pp. 287-296, 1985. 12. K. Perlin and E. M. Hoffert, "Hypertexture," 
Com- puter Graphics, Vol. 23, No. 3, pp. 253-262, 1989. 13. J.P. Lewis, "Algorithms for Solid Noise 
Synthesis," Computer Graphics, Vol. 23, No. 3, pp. 263-270, 1989. 14. B. B. Mandelbrot, "Fractals Form, 
Chance, and Dimension," Freemann, San Fransisco, 1977. 15. A. Fournier, D. Fussel, and L. Carpenter, 
"Com- puter Rendering of Stochastic Models," Commu- nications of ACM, Vol. 25, No. 6, pp. 371-384, 1982. 
    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97922</article_id>
		<sort_key>395</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[A lighting model aiming at drive simulators]]></title>
		<page_from>395</page_from>
		<page_to>404</page_to>
		<doi_number>10.1145/97879.97922</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97922</url>
		<abstract>
			<par><![CDATA[Many techniques for rendering natural objects such as the sea, terrains, and trees have been developed; they are indispensable for flight simulators. In this paper, techniques for rendering road surfaces under various conditions are discussed. Rendering road surfaces is quite useful for the evaluation of driving safety, and it will play an important part in the development of drive simulators. Light sources with high intensity often disturb drivers especially under wet road surface conditions.This paper proposes two models, a reflection model for road surfaces taking into account weather conditions, and a model on streaks of light taking into account both refraction and diffraction of light. Some examples demonstrate the possibility of applications for drive simulators in the future.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P75905</person_id>
				<author_profile_id><![CDATA[81100145250]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eihachiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakamae]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima University, Saijo-cho, Higashi-hiroshima, 724 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P158352</person_id>
				<author_profile_id><![CDATA[81100412545]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kazufumi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaneda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima University, Saijo-cho, Higashi-hiroshima, 724 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14035917</person_id>
				<author_profile_id><![CDATA[81332519427]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Okamoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hiroshima University, Saijo-cho, Higashi-hiroshima, 724 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36042206</person_id>
				<author_profile_id><![CDATA[81100539710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Tomoyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fukuyama University, Higashimura-cho, Fukuyama, 729-02 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. Simulation of Wrinkled Surfaces. Proceedings of SIGGRAPH '78 (Atlanta, Georgia, August 23- 25, 1978). In Computer Graphics 12, 3 (August 1978), 286-292.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F. Light Refection Functions for Simulation of Clouds and Dusty Surfaces. Proceedings of SIGGRAPH '82 (Boston, Massachusetts, July 26-30, 1982). In Computer Graphics 16, 3 (July 1982), 21-29.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. A Subdivision Algorithm for Computer Display of Curved Surfaces. UTEC-CSc 74-133 (1974), University of Utah.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L. and Torrance, K. E. A Reflectance Model for Computer Graphics. A CM Trans. ou Graphics 1, 1 (1982), 7-24.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808602</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L. Shade Trees. Proceedings of SIGGRAPH '84 (Mianeapolis, Minnesota, July 23-27, 1984). IR Computer Graphics 18, 3 (1984), 223-231.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74361</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T. and Kay, T. L. Rendering Fur with Three Dimensional Textures. Proceedings of SIGGRAPH '89 (Boston, Massachusetts, July 31-August 4, 1989). In Computer Graphics 23, 3 (1989), 271-280.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>90975</ref_obj_id>
				<ref_obj_pid>90967</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kaneda, K., Okamoto, T., Nakamae, E., and Nishita, T. Highly Realistic Visual Simulation of Outdoor Scene under Various Atmospheric Conditions. Prec. CG International '90 (1990) (to be appeared).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35071</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Klassen, R. V. Modeling the Effect of the Atmosphere on Light. A CM Trans. on Graphics 6, 3 (1987), 215- 237.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806817</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Moravec, H. P. 3D Graphics and the Wave Theory. Proceedings of SIGGRAPH '81 (Dallas, Texas, August 3-7, 1981). In Computer Graphics 15, 3 (1981), 289-296.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15900</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Nishita, T. and Nakamae, E. Continuous Tone Representation of Three-Dimensional Objects Illuminated by Sky Light. Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics I~0, 4 (1986), 125-132.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37437</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nishita, T., Miyawaki, Y. and Nakamae, E. A Shading Model for Atmospheric Scattering Considering Luminous Intensity Distribution of Light Sources. Proceedings of SIGGRAPH '87 (Anaheim, California, July 27- 31, 1987). In Computer Graphics 21, 4 (1987), 303-310.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Peachey, D. R. Solid Texturing of Complex Surfaces. Proceedings of SIGGRAPH '85 (San Francisco, California, July 22-26, 1985). In Computer Graphics 19, 3 (1985), 279-286.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Shinya, M., Saito, T., and Takahashi, T. Rendering Techniques for Transparent Objects. Prec. Graphics Interface '89 (1989), 173-182.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 <~ Computer Graphics, Volume 24, Number 4, August 1990 A Lighting Model Aiming at Drive Simulators Eihachiro 
Nakamae*, Kazufumi Kaneda*, Takashi Okamoto* and Tomoyuki Nishita't *Hiroshima University Saijo-cho, 
Higashi-hiroshima, 724 Japan  1"Fukuyama University Higashimura-cho Fukuyama, 729-02 Japan Abstract 
 Many techniques for rendering natural objects such as the sea, terrains, and trees have been developed; 
they are in-dispensable for flight simulators. In this paper, techniques for rendering road surfaces 
under various conditions are dis- cussed. Rendering road surfaces is quite useful for the eval- uation 
of driving safety, and it will play an important part in the development of drive simulators. Light sources 
with high intensity often disturb drivers especially under wet road surface conditions. This paper proposes 
two models, a reflection model for road surfaces taking into account weather conditions, and a model 
on streaks of light taking into account both refraction and diffraction of light. Some examples demonstrate 
the possibility of applications for drive simulators in the future. CR Categories and Subject Descriptors: 
1.3.3 [Computer Graphics]: Picture/Image Generation; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics 
and Realism. General Terms: Algorithms. Additional Key Words and phrases'. Photo-realistic image rendering, 
Drive simulator, Rendering wet roads, Rendering puddles, Reflection model, Streaks of light, Refraction, 
Diffraction, Optical filter.  Introduction Realistic image synthesis, including road surfaces under 
var- ious weather conditions, is an indispensable technique in traffic engineering, especially for the 
development of drive simulators aiming at ensuring safety levels. For example, we are often disturbed 
when driving by complex reflections from both puddles and boundary areas between dry and wet regions 
on a road, and streaks of light (an effect similar to that found in photography when using a special 
camera filter called a 'cross-screen filter', also caused naturally by the eye- lashes) due to high intensity 
lights such as automobile head- lights and street lights also disturb drivers especially under dense 
fog conditions. Photo-realistic image synthesis taking account of these phenomena is quite useful not 
only for drive Permission to copy without fee all or part of this material is granted providedthat the 
copies are not made or distributed for direct commercial advantage, the ACM copyrightnotice and the title 
of the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
simulators but also road design and simulation of a 'light up' effect on buildings such as when floodlights 
are used. This paper proposes a lighting model for photo-realistic image synthesis considering these 
two phenomena; discussions on other natural phenomena such as rain and snow are not in- cluded here. 
In order to render objects with complex surfaces the following mapping techniques have been developed: 
Tex-ture mapping [3], bump mapping [1], solid texturing [12], displacement mapping [5], and texel mapping 
[6]. These techniques are useful for realistic image synthesis, but not enough for rendering regions 
with different attributes such as dry and wet regions on a road. Concerning high intensity lights, most 
traditional meth- ods cannot give appreciations of these high intensity effects because of saturation 
of display intensities; full color CRTs usually have only 256 levels for each primary color, R, G, and 
B. In order to address the problem Shinya, et al. [13] created streaks of refracted light, but no streaks 
of diffracted light are taken into account. Moravec [9] proposed a wave model considering diffraction, 
however, he didn't discuss the streaks of light found when observing objects with high in- tensity. Taking 
into account both diffraction and refraction makes it possible to display the following phenomena: Ef-fects 
of a diffraction grating and a cross-screen filter used in photography to generate radial streaks of 
light when ob- serving objects with high intensity, a blooming effect around objects with high intensity, 
and several streaks of light emit- ted from the objects. In order to solve these two problems; rendering 
road sur- faces under various conditions and rendering various diffrac- tion effects, a new image synthesis 
technique based on the following ideas is proposed. 1. Road surfaces are modeled using procedural bump 
map- ping consisting of several undulation data. The road surfaces are classified into four regions with 
different characteristics of reflection by using a combination of the undulation data. * A two layer 
reflection model consisting of both wa- ter and road surfaces is introduced for rendering puddles. 2. 
Streaks of light are modeled by taking into account both diffraction and refraction. Streaks of light, 
created when using a diffraction grating in photography, are rendered by the use of a diffraction model. 
 @1990 ACM-0-89791- 344-2/90/008/0395 $00.75 395 @SIGGRAPH '90, Dallas, August 6-10, 1990 Figure 1: Transverse 
section of a road. Blooming effect and streaks of light are rendered by employing a diffraction model 
of the pupil and eyelashes, respectively. The proposed models realize the displaying of the follow- 
ing various lighting effects including sky light [10] and a fog effect. 1. Realistic images displaying 
such aspects as the relation- ship between road heights and wet regions (e.g., pud- dles obviously usually 
gather in low-lying sections), and road surface conditions changing with the passage of time (e.g., wet 
regions becoming gradually dry) can be created. 2. Photo-realistic images with various lighting effects 
un- der various conditions can be generated by taking into account both refraction and diffraction of 
light emitted from objects with high intensity.  2 Modeling and Rendering for Wet Road Surfaces 2.1 
Modeling of road surfaces As is well known, the center of a road is usually higher than the shoulders 
to allow for effective drainage (see Fig. 1 and Appendix A), and the smoothness of road surfaces are 
of- ten far from perfect being somewhat undulating, especially in those sections well worn by automobiles, 
and the length of these sections can vary considerably. A closer look at road surfaces may also reveal 
small undulations of asphalt or concrete. Using Fourier series or fractals for modeling road surfaces 
may seem to be useful, but employing Fourier series can be difficult because of lack of local control 
on the height of the road surfaces. We therefore employed fractals as the basis for one of our methods. 
In most approaches using fractals, several undulations at different levels are re- cursively generated, 
and in the final step, one undulation data is calculated by compositing the previous data. In the proposed 
model four types of undulation data are stored separately, as shown in Fig. 2, in order to classify road 
con- ditions into four types mentioned later. These data are then composited to render the road surface 
by using bump map- ping techniques. The conditions of road surfaces depend to a great extent upon the 
weather. For instance, at the onset of rain wet regions on road surfaces are very sparse, but as the 
rain continues whole regions become uniformly wet, and puddles form in any hollows on the surface. After 
the rain road  /b/k  (a) (b) A £  (c) (d) Figure 2: Several undulation data of a road surface. surfaces 
gradually become dry, and the speed of this drying depends upon the height of the road surface; the higher 
the surface, the quicker the drying. Puddles remain for a longer period. Road surfaces are classified 
into the following four types in order to render various road surface conditions; Type 1: 'a dry region', 
Type 2: 'a wet region'; i.e., the region where the road surface is wet but no water gathers, Type 3: 
'a drenched region'; i.e., the region where water remains to some extent but no puddles are formed, or 
the region of the margin of a puddle, and Type 4: 'a puddle region'. Traditionally, both some thresholds 
and only one height data, which does not take into account the varying types and scale of undulations, 
are commonly used for classification into several regions (e.g., classification of a terrain model generated 
by using fractals into two regions, land and sea); this has several disadvantages. For example, let's 
consider how to classify road surface conditions for the beginning of drying just after rain (see Fig. 
3), assuming the road sur-face condition to be that shown in Fig. 3 (1); there are 'dry regions' in the 
high area and 'puddle regions' with different height in the low area, and both 'wet regions' and 'drenched 
regions' exist between these areas. Fig. 3 (2) shows the clas- sification using one height data and some 
thresholds; 'puddle regions' with different height cannot be generated, because with this method of classification 
all 'puddle regions' have the same height. Moreover, the width of the section (B) where 'dry regions' 
and 'wet regions' exist together, the dis- tance from P to Q, is fixed only by the height data. There-fore, 
the height data has to be modified for every change of the width of the mixed region. In order to solve 
these problems, several undulation data as shown in Fig. 2 are used for classification. Several groups 
of undulation data are formed; each group corresponds to each road surface condition such as big puddles 
and mixed areas of 'dry regions' and 'wet regions'. Each group con-sists of an appropriate combination 
of several height data and a threshold of height for the classification. In order to determine which 
regions road surfaces belong to, the num- ber of groups which satisfy the condition that the height, 
composed of all the undulation data in the group, does not exceed the threshold is specified. Again, 
taking as an example, the classification of a road surface at the beginning of drying just after rain 
(see Fig. 3);  @SIGGRAPH '90, Dallas, August 6-10, 1990 Table 2: Example of the classification of road 
surface con-ditions for heavy rain. (1) number of groups satisfying the condition. I number of groups 
saris- region group No. lying the condition puddle 1 1 drenched 1, 2 1 wet 1, 2 I combination of undulation 
data and thresholds. group undulatmn threshold [ram] road surface con- No. data dition el,2 ei,s el,4 
b, d 27.0 12.0 7.0 large 'puddle re-gion' c, d 30.0 4.0 -- mixed area of 'drenched region' and 'wet region' 
(el,2 :wet, ei,3 :drenched, el,4 :puddle) 2.2 Reflection model for road surfaces The Cook-Torrance model 
[4] is employed for rendering road surfaces because of its ability to generate high-fidelity im- ages. 
The procedural bump mapping technique described in the previous section is also employed for calculating 
the direction of reflection on the road surface. With the pro- posed method it is possible to calculate 
reflection of sky light taking into account spectral distributions [7]. Colors of direct sunlight, sky, 
and clouds are calculated by using an atmospheric scattering model [8], and the scenes on the ground 
can be rendered considering sky light [10]. Reflec-tion models for each classified region are discussed 
in this section. For convenience of explanation the reflection model of a 'drenched region' is discussed 
last. 2.2.1 Reflection model for a 'dry region' Diffuse reflection from dry road surfaces is usually 
high, while specular reflection is very low. Road surfaces are rel- atively smooth, and the area of highlight 
is small. 2.2.2 Reflection model for a 'wet region' When road surfaces become wet, the ratio of specular 
reflec- tion increases, while that of diffuse reflection decreases, so that the intensity becomes generally 
lower. From this, we assume that specular reflection and diffuse reflection coeffi- cients in the 'wet 
region' are 5 to 10 times and 0.1 to 0.3 times those of the 'dry region', respectively. For rendering 
mirror images on road surfaces, a ray tracing technique is employed.  2.2.3 Reflection model for a 'puddle 
region' A 'puddle region' is defined as an area where one can recog- nize water staying on a road surface. 
As shown Fig. 4, a two layer reflection model, horizontal surface of water, L1, cov- ering road surface, 
L2, is introduced. The 'puddle regions' are rendered by considering the following conditions: (1) Puddle 
surface, L1, is completely flat, and distributions of microfacets on road surface, L2, are taken into 
account. (2) Both refraction and transmission at points PI and Qi  light source reflected ray at Qx 
viewpoint Figure 4: Two layer reflection model for a 'puddle region'. are taken into account. (3) The 
ray reflecting again at road surface L1 and returning back to road surface L2 is ignored for the purpose 
of simplifying the calculation. (4) Mirror images onto puddles are taken into account. (5) Incident rays 
onto points Pt and Q1 are the same regarding both their strength and direction because the distance between 
these points is very short as puddles are usually very shal- low. (6) Interference of light is ignored. 
In order to calculate reflection onto puddles (item (4)), a ray-tracing technique, casting rays from 
point Qi in the di- rection of regular reflection for the viewpoint, is employed. Puddles are not always 
clear; they are sometimes muddy. In this case scattering and absorption of light due to mud particles 
should be taken into account. Scattering and ab- sorption due to particles in the air [11] can be employed 
for mud particles in puddles; the component of the intensity of light in the direction 7o is expressed 
by _p.._M__ H I = (Iie .... i + h)re-PZzn~~ (1) ~0 H h _ p_._h.__ + (Iie-P~'~';'~¢(8) +.[a)wpe "°" ~o 
dh H H = (/ie-P~-~" + Is)re -p~°~-~o p H + w&#38;(t-e-~z') -r_.Ai_+I1.__~ H u, Ii¢(6) [1 -- e-" .... 
-v, ¢0,~o, ], + l + 1 cos 'Yi cos 70 where p is particle density; li, intensity of light just after transmission 
into Li; I~, intensity of an ambient light; 7i, angle of the incident light; 7o, angle of the reflected 
light; r, reflection coefficient of L~; w, reflection coefficient of parti- cles; 8, angle of reflection; 
¢(8), phase function. Let's assume that (1) mud particles are considerably larger than the wavelength 
of light, (2) particles have per- fect diffuse reflection surfaces, and (3) the shape of particles is 
spherical. The phase function of mud particles is then expressed by the following equation [2]: 8 ¢(6) 
= ~[sin ~ --F (r -~)cos 6]. (2)  2.2.4 Reflection model for a 'drenched region' The intensity of a 'drenched 
region' is calculated by using a weighting function for the reflection models of a 'wet re-gion' and 
a 'puddle region', because the 'drenched region'     O SIGGRAPH '90, Dallas, August 6-10, 1990 . 
Acknowledgment The data on light sources are courtesy of Matushita Electric Works Ltd. We would like 
to thank the reviewers for their helpful comments. References [1] Blinn, J. F. Simulation of Wrinkled 
Surfaces. Proceed- ings of SIGGRAPH '78 (Atlanta, Georgia, August 23- 25, 1978). In Computer Graphics 
12, 3 (August 1978), 286-292. [2] Blinn, J. F. Light Refection Functions for Simulation of Clouds and 
Dusty Surfaces. Proceedings of SIGGRAPH '82 (Boston, Massachusetts, July 26-30, 1982). In Com-puter Graphics 
16, 3 (July 1982), 21-29. [3] Catmull, E. A Subdivision Algorithm for Computer Display of Curved Surfaces. 
UTEC-CSc 74-133 (1974), University of Utah. [4] Cook, I~. L. and Torrance, K. E. A Reflectance Model 
for Computer Graphics. ACM Trans. on Graphics 1, 1 (1982), 7-24. [5] Cook, R. L. Shade Trees. Proceedings 
of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3 (1984), 223-231. 
[6] Kajiya, J. T. and Kay, T. L. Rendering Fur with Three Dimensional Textures. Proceedings of SIGGRAPH 
'89 (Boston, Massachusetts, July 31-August 4, 1989). In Computer Graphics 23, 3 (1989), 271-280. [7] 
Kaneda, K., Okamoto, T., Nakamae, E., and Nishita, T. Highly Realistic Visual Simulation of Out- door 
Scene under Various Atmospheric Conditions. Proe. CG International '90 (1990) (to be appeared). [8] Klassen, 
R. V. Modeling the Effect of the Atmosphere on Light. ACM Trans. on Graphics 6, 3 (1987), 215- 237. [9] 
Moravec, H. P. 3D Graphics and the Wave Theory. Proceedings of SIGGRAPH '81 (Dallas, Texas, August 3-7, 
1981). In Computer Graphics 15, 3 (1981), 289-296. [10] Nishita, T. and Nakamae, E. Continuous Tone Rep- 
resentation of Three-Dimensional Objects Illuminated by Sky Light. Proceedings of SIGGRAPH '86 (Dallas, 
Texas, August 18-22, 1986). In Computer Graphics 20, 4 (1986), 125-132. [11] Nishita, T., Miyawaki, Y. 
and Nakamae, E. A Shading Model for Atmospheric Scattering Considering Lumi- nous Intensity Distribution 
of Light Sources. Proceed- ings of SIGGRAPH '87 (Anaheim, California, July 27-31, 1987). In Computer 
Graphics 21, 4 (1987), 303-310. [12] Peachey, D. R. Solid Texturing of Complex Surfaces. Proceedings 
of SIGGRAPH '85 (San Francisco, Cali- fornia, July 22-26, 1985). In Computer Graphics I9, 3 (1985), 279-286. 
[13] Shinya, M., Suite, T., and Takahashi, T. Rendering Techniques for Transparent Objects. Prec. Graphics 
In- terlace '89 (1989), 173-182.  Appendix A Gradient of Road Surfaces for Drain- ing The outer edge 
of a curved road is higher than the inner edge for reasons of driving safety. The center of a straight 
road is higher than the shoulders for draining. The gradient of the transverse section of a straight 
road is given in Table 3 and is the Japanese standard, having a parabola or a hyperbola shape. B 2D Filter 
Taking as an example the optical image formation system as shown in Fig. '7, let's assume that the angle 
from the incident light to the optical axis of the lens is small, the distance be- tween the lens and 
the focal plane is d, and the ratio of rays diffracted to the direction (c~,,8) is f(c~,/~). The effect 
of an optical filter can be rendered by employing a linear filtering using function f(a, fl) for an image 
without an optical filter. The procedure of 2D filtering is as following: 1. An image without an optical 
filter, E0(x, y), is created. 2. A linear filtering using function f(x, y) is employed.  El(oc, y) 
= / / Eo(xo,Yo).f( x-x° , Y ~Y°)dxodyo ~" (la) The filter is employed only to pixels with a high in- 
tensity. For plural optical filters corresponding linear filterings are employed in order. 3. In order 
to calibrate output images for a display moni- tor, 3, correction is employed. Table 3: The gradient 
of the transverse section of a road for draining. material gradient asphaltconcrete less than 1.5 others 
less than 2.0 %  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>97923</article_id>
		<sort_key>405</sort_key>
		<display_label></display_label>
		<article_publication_date>09-01-1990</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Particle animation and rendering using data parallel computation]]></title>
		<page_from>405</page_from>
		<page_to>413</page_to>
		<doi_number>10.1145/97879.97923</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=97923</url>
		<abstract>
			<par><![CDATA[Techniques are presented that are used to animate and render particle systems with the Connection Machine CM-2, a data parallel supercomputer. A particle behavior language provides an animator with levels of control from kinematic spline motions to physically based simulations. A parallel particle rendering system allows particles of different shapes, sizes, colors and transparencies to be rendered with antialiasing, hidden surfaces, and motion-blur. One virtual processor is assigned to each primitive data element: one to each particle, and during the rendering process, one to each pixel-sized particle fragment, and to each pixel. These tools are used to model dynamic phenomena such as wind, snow, water, and fire.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.2</cat_node>
				<descriptor>Parallel processors**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31096759</person_id>
				<author_profile_id><![CDATA[81332527789]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sims]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Optomystic, 725 N. Highland, Hollywood, CA and Thinking Machines Corporation, 245 First Street, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W., Green, M., "The Dynamics of Articulated Rigid Bodies for Purposes of Animation," Proceedings Graphics Interface '85, pp. 407-415.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15907</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Amburn, P., (}rant, E., Whitted, T., "Managing Geometric Complexity with Enhanced Procedural Methods," Computer Graphics, Vol. 20, No. 4, August 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barr, A., Barzel, R., "A Modeling System Based on Dynamic Constraints," Computer Graphics, Vol. 22, No. 4, 1988, p. 179.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carpenter, L.C., "The A-buffer, an Anti-aliased Hidden Surface Method," Computer Graphics, Vol. 18, No. 3, 1984.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Reeves, W., "A Simple Model of Ocean Waves," Computer Graphics, Vol. 20, No. 4, 1986, pp. 75-84.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Girard, M., Maciejewski, A., "Computational Modeling for the Computer Animation of Legged Figures," Computer Graphics, Vol. 19, No. 3, 1985, pp 263-270.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378530</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hahn, J. K., "Realistic Animation of Rigid Bodies" Computer Graphics, Vol. 22, No. 4, 1988, p. 299.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6519</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hillis, W. D., The Connection Machine, MIT Press, 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>38324</ref_obj_id>
				<ref_obj_pid>38323</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hillis, W. D., "The Connection Machine," Scientific American, Vol. 255, No. 6, June 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lasser, C., Massar, J.P., Mincy, J., Dayton, L., "Starlisp Reference Manual," Thinking Machines Corporation, 1988]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lucasfilm Ltd, The Adventures of Andre and Wally B., (film), August 1984.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378508</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Miller, G., "The Motion of Snakes and Worms" Computer Graphics, Vol. 22, No. 4, 1988, p. 169.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer, P. "Real time design and animation of fractal plants and trees. Computer Graphics, Vol. 20, No. 4, 1986, pp 55-64.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Paramount, Star Trek ii: The Wrath of Kahn, Genesis Demo, also in SIGGRAPH Video Review 1982, ACM SIGGRAPH, New York.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15893</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Peachy, Darwyn R., "Modeling Waves and Surf," Computer Graphics, Vol. 20, No. 4, 1986, pp. 65-84.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Platt, J., Barr, A., "Constraint Methods for Flexible Models," Computer Graphics, Vol. 22, No. 4, 1988, p. 279.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Press, Flannery, Teukolsky, and Vetterling, Numerical Recipes, Cambridge University Press, 1986, p. 248.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378503</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, P., Lindenmayer, A., and Hanan, J., "Developmental Models of Herbaceous Plants for Computer Imagery Purposes," Computer Graphics, Vol. 22 No. 4, 1988, pp. 141-150.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357320</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., "Particle Systems- A Technique for Modeling a Class of Fuzzy Objects," A CM Transactions on Graphics, Vo}. 2, No. 2, April 1983, reprinted in Computer Graphics 1983, pp. 359-376.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., and Blau, R. Approximate and probabilistic algorithms for shading and rendering structured particle systems. Computer Graphics, Vol. 19, No. 3, 1985, pp 313-322.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378505</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Reffye, P., Edelin, C., Francon J., Jaeger, M., Puech, C. "Plant Models Faithfid to Botanical Structure and Development," Computer Graphics Vol. 22, No. 4, 1988, pp 151-158.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Reynolds, Craig W., "Flocks, Herds and Schools: A Distributed Behavioral Model," Computer Graphics, Vol. 21, No. 4, July 1987, pp 25-34.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Simon, H.D., Scientific Applications of the Connection Machine, World Scientific Publishing Co., 1988.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Sims, K., Particle Dreams, SIGGRAPH Video Review 1988, ACM SIGGRAPH, New York.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R., "Plants, Fractals, and Formal Languages," Computer Graphics, Vol. 18, No. 3, pp. 1-10, July 1984.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Studio Base 2, Systeme Particulier, Chesnais, Alain, SIGGRAPH Video Review 1987, ACM SIGGRAPH, New York.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Symbolics, Stanly and Stella in Breakin9 the Ice, SIG- GRAPH Video Review 1987, ACM SIGGRAPH, New York.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Fleischex, K., "Modeling Inelastic Deformation: Viscoelasticity, Plasticity, Fracture," Computer Graphics, Vol. 22, No. 4, 1988, p. 269.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Thinking Machines Corporation, Connection Machine Model CM-2 Technical Summary, technical report, May 1989.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Weil, J., A T &amp; T Bell Labs, Boom Boom Boom, SIG- GRAPH Video review 1987, ACM SIGGRAPH, New York.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J. Baxsky, B., "Using Dynamic Analysis for the Animation of Articulated Bodies Such as Humans and Robots," Proceedings Graphics Interface '85, pp. 97-104.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Wilhelms~ J., Moore, M., "Collision Detection and Response for Computer Animation," Computer Graphics, Vol. 22, No. 4, 1988, p. 289.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15895</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Yaeger, L., Upson, C., "Combining Physical and Visual Simulation - Creation of the Planet Jupiter for the Film 2010," Computer Graphics, Vol. 20, No. 4, 1986, pp 85- 93.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~-Computer Graphics, Volume 24, Number 4, August 1990 Particle Animation and Rendering Using Data Parallel 
Computation Karl Sims Optomystic, 725 N. Highland, Hollywood, CA 90038 Thinking Machines Corporation, 
245 First Street, Cambridge, MA 02142 1 Abstract Techniques are presented that are used to animate and 
ren- der particle systems with the Connection Machine CM-2, a data parallel supercomputer. A particle 
behavior language provides an animator with levels of control from kinematic spllne motions to physically 
based simulations. A parallel particle rendering system allows particles of different shapes, sizes, 
colors and transparencies to be rendered with anti- allasing, hidden surfaces, and motion-blur. One virtual 
pro- cessor is assigned to each primitive data element: one to each particle, and during the rendering 
process, one to each pixeLsized particle fragment, and to each pixel. These tools are used to model dynamic 
phenomena such as wind, snow, water, and fire. 2 Introduction As computers become a more practical 
tool for visual ex- pression, modeling and animation systems need to allow for more abstract, high level 
instructions rather than requiring each object and each motion to be specified individually. Commands 
such as "make a gust of wind," "drop this ob- ject," "grow a tree," or even "make this character walk," 
are beginning to become £easible [2,6,13,18,21,25,31,32]. Particle systems provide for the creation of 
complex struc- ture and motion from a relatively brief abstract description. They can be used to produce 
dynamic and "fuzzy" effects that are dilBcult to achieve with traditional objects made of surfaces and 
animated with non-procedural motion [19]. They have previously been used to model fire in the Gene-sis 
Effect of Star Trek II [14], trees and grass such as those shown in Andre and Wally B. [11,20], breaking 
waves [5,15], fireworks [30], and other abstract effects in Systeme Partic- ulier [26]. A 2D particle 
system was used as part of a fluid simulation for Jupiter's surface in ~010 [33]. The flocks and schools 
in Breaking the Ice might also be considered as par-ticle systems where each particle is a complex object 
[27,22]. The Connection Machine (R) CM-2 is a data parallel computer consisting of between 4K and 64K 
processors with up to 32K bytes of memory per processor, and floating point hardware [8,9,23,29]. A hypercube 
connection architecture and special routing hardware allows general communication  Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. between processors. A 
virtual processor mechanism is used to simulate more processors than the physical number so the virtual 
machine size can vary depending on the number of data elements in the application. For example, if 32K 
particles were created on a CM-2 with 8K physical proces- sors, a virtual processor set with 4 virtual 
processors per processor could contain all 32K particles, one per virtual processor. Sets of virtual 
processors can be configured into n-dimensional grids. For example, a 1D virtual processor set would 
be used to represent particles, but a 2D virtual processor set would be used to represent the pixels 
of an image. Programming a Connection Machine system is similar to progtammlug a single processor except 
that the thousands of processors all execute the same program at the same time, each on different data. 
A parallel language called Starllsp is used in this work [101. Starllsp is a parallel extension of Lisp 
that allows the same power of combination and abstraction as Lisp, but consists of parallel instructions 
that operate on parallel variables. Because of the parallel nature of particle systems, they are well 
suited for highly parallel computation. A parallel language is convenient to use in building a particle 
anima- tion language, and conversely this system is a good example of some basic data parallel techniques. 
Instructions or rules of behavior are described as if addressing a single particle, but they are applied 
to all particles (or a subset of them) in parallel. The result of the instruction will usually be differ- 
ent for each particle because it uses the state of the particle to determine its effect. The three main 
sections of this paper describe a language containing some basic tools for animating particles, a system 
for rendering 3D particles, and finally, some specific appli- cations that demonstrate how the animation 
and rendering is used to produce some natural phenomena effects.   3 Particle Animation: A Particle 
Behavior Language Although many applications of particle animation will still require their own special 
software, a general set of tools is used to create a wide variety of effects. Starlisp and Lisp provide 
an environment that allows existing particle opera- tions to be easily combined into new higher level 
operations. Physical simulations can create motion that is much more complex and realistic looking than 
motion achieved by mov- ing objects along spline curves or through keyframes [1,3,7, 12,16,28]. Objects 
animated kinematically often are not per- ceived as dynamically correct, whereas objects 8nlrnated by 
true physical simulation will look correct. However, ending up with a desired motion by specifying only 
forces and ac- &#38;#169;1990 ACM -0-89791-344-2/90/098/0405 $00.75 405 SIGGRAPH '90, Dallas, August 
6-10, 1990 celerations can be very difficult. Just as in reality, where it is hard to toss a coin and 
make sure it lands heads up, or make a legged robot run without falling over, it is di~cult to predict 
the motion resulting from applied forces. This particle animation system attempts to supply sev- eral 
levels of operations along the spectrum between detailed kinematic control and physically based sim-lation. 
The goal is not to strictly obey physics and reality, but to provide a range of tools that allow a variety 
of effects to be easily created that appear correct. The equations of motion for a particle in ~a with 
position P, velocity V and an externally exerted acceleration A are: V = Vo + /Adt P = Po + ./Vdt Euler's 
method of integration allows the state of the par- ticle to be updated using a simple approximation of 
these equations for a small discrete time interval ~t: V' = V + AAt V+V' . P' = P + ----7 &#38;t Although 
other methods of integration are known to be more computationally efficient, Euler's was chosen for its 
simplic- ity and is usually sufficient. A Particle is created by allocating a new CM virtual processor 
to contain the in.formation about that particle. Particles can either be newly created, or created by 
dupli- cating existing particles and copying their state. Particles cam be killed and removed from their 
processors to make those processors available for new particles. Each virtual processor in the CM representing 
a particle contains a data structure whose elements are the particle's state variables. A particle has 
both a head position and a tail position. The head position is usual.ly animated and the tail position 
follows along for motion blurring. The parti- cle structure also contains other variables such as velocity, 
radius, color, and opacity. Animation operations on particles can either initialize or alter the position 
or velocity of particles. In a purely physical simulation, these values would first be initialized, then, 
for each time interval ~t, the velocity would be altered by external accelerations such as gravity, and 
finally the position would be updated as shown above. However, for kinematically controlled motion, the 
position may be set directly, regardless of the previous position or velocity. It is also sometimes useful 
to set the position relative to the previous position or to alter the velocity in ways other than applying 
a simple translational acceleration. Operations used to move particles are divided into four categories: 
those that set the position, those that set the velocity, those that alter the position or "apply" a 
velocity, and those that alter the velocity or apply an acceleration. Some examples of each are given 
in the following sections. 3.1 Position Operations The positions of particles can be set in the following 
ways: - Randomly within a rectangular solid. - Randomly within a sphere. - Randomly on the surface 
of a sphere.  406 -One particle on each vertex of a polygonal object. -Randomly on the surface of a 
polygonal object. -3D Transformation from the local coordinates. These operations are usually performed 
only once at the beginning of a particle's life, except the 3D transformation operation which is usually 
performed at every frame if used. 3.2 Velocity Initialization Operations The velocity is usually initialized 
only once at the start of a particle's life lmless jerky motion is desired. The velocity of particles 
can be initialized in much the same ways that the position can be initialized. The commonly used velocity 
initialization operations are: -In a constant direction. - Randomly within a rectangular solid. - Randomly 
within a sphere. - Randomly on the surface of a sphere.  3.3 Applied Velocity Operations An "applied" 
velocity alters the position parameter of the particle depending on the previous position and affects 
the apparent velocity, but does not change the velocity parame- ter of the particle. This allows velocity 
operations and accel- eration operations to act independently on particles without interfering with each 
other, and can help enable combination of dynamic simulation with other motion. For example, par- ticles 
fall;rig due to gravity might also be moved randomly from side to side using applied velocity operations. 
Operations that are used to alter the position or "apply" a velocity are: -Translate by a constant. -Rotate 
by a constant. -Scale by a constant. -Translate Randomly. -Vortex. 3.3.1 The Vortex The vortex operation 
is worth further description. The pa- rameters given to it are: azis of rotation, center, magnitude, 
and tightne88. The positions of particles are rotated about the axis through the center of the vortex 
by an amount dependent on their distance from the center. Higher tightness causes the angle of rotation, 
0, to fade more quickly in the radial direction: 0-magnitude Rtlghtnes$ where R is the distance from 
the center of rotation, and tightness is usually between 1.0 and 2.0. Other options to the vortex operation 
are useful. A range of influence can cause 0 to decrease to zero beyond a certain distance, and a translation 
along the vortex axis that is also dependent on R can create tornado-like motion. This operation by no 
means creates a physical simula- tion of a vortex, but it is much easier to create specific dy- namic 
fluid-like motions using choreographed vortices than it would be to simulate fluid flow through complex 
physi- cal equations. There is often a tradeoff between animator control and physically accurate simulations. 
This vortex operation is an example of sacrificing some physical correct- ness in favor of animator control, 
while still allowing realistic looking motions to be achieved.    ~ Computer Graphics, Volume 24, 
Number 4, August 1990 3.4 Acceleration Operations Acceleration operations alter the particle's velocity. 
Forces can be converted to accelerations by: A : F/m. "Acceler-ations" can increment, scale, rotate, 
or reflect the velocities of particles. These operations usually use other parame-ters of the particle 
such as position, velocity, spiral-axis, or mass to find the acceleration and adjust the velocity. They 
can produce a wide variety of interesting and dynamically correct-looking motions. Some examples of acceleration 
op- erations are: - Constant acceleration (gravity). - Random acceleration. - Accelerate towards a point 
(orbit). - Accelerate towards a line. - Accelerate towards the local coordinates.  -Damp -Undamp -Spiral. 
- Bounce off a plane. -Bounce off a sphere. The first five of these are basic translational accelerations 
where the velocity is simply incremented by the acceleration: V' = V+AAt. The acceleration can be constant, 
random, or may be directed towards a point or a line, and the magnitude of acceleration may depend on 
the distance of the particle's position from the point or line. For example an acceleration: O-P A = 
9mo i0 _ pl s will create inverse-square law orbits where 0 is the fixed center of the orbit with mass 
too, g is a constant, and P is the particle position. This equation is a form of Newton's F = gmlm2/~ 
,2. (In this example the acceleration can change very rapidly near O, which, unless At is very small, 
causes errors that fling the particles out of their orbits.) 3.4.1 Damping A simple approximation to 
damping is used to simulate ef- fects such as air friction on particles. A deceleration propor- tional 
to the current velocity magnitude is applied to the particle in the direction of the current velocity. 
A damp- ing parameter d typically ranges between 0.0 and 10.0. The damping deceleration is clamped so 
as not to reduce the velocity below a given threshold. V ~ = V mar( 1 - dAt min(1.O, threshold.. , " 
A more physically accurate model for damping could be im- plemented with damping forces non-linearly 
related to ve-locity, and not necessarily proportional to mass. Undamping is used to cause acceleration 
instead of de- celeration in the direction of the current velocity (d < 0), and can be performed on particles 
below a tl~eshold value to smoothly accelerate them to some minimum speed. 3.4.2 The Spiral Spiral motions 
contribute to many different effects such as swirling fire or twirling snowflakes. Each particle to be 
spi- raled is given a spiral axis which can be initialized using the same set of methods for initializing 
velocities shown above. The spiral operation causes the velocity vector to be rotated Axis a. b. Figure 
1: Spiral. about the spiral axis. For a given spiral speed, s, the veloc- ity is rotated by an angle 
0 = sz~t, for each time interval At. [See figure la]. A particle can move in a variety of helix shaped 
paths depending on the relative angle of its velocity to its spiral axis [figure lb]. If they are perpendicular 
the particle will remain within a circle. If they are parallel there will be no effect. Notice that when 
particles are spiraling, they move in the general direction of plus or minus their spiral axes. 3.4.3 
The Bounce Particles can be bounced off primitive shapes made of planes and spheres. A simple bounce 
with no energy loss could be performed by just reflecting the velocity of particles that have passed 
beyond the boundary of the surface by the nor- mal N: V' = V -2(V-N)N This method allows particles to 
penetrate the surface for at least one iteration, and the effective position they bounce from is usually 
slightly below the surface unless many iter- ations are calculated per frame. A more complete bouncing 
method considers friction and resilience of the particle and sets the new position and ve-locity as if 
the bounce occured exactly on the surface. All other operations are performed before any bounce opera-tions, 
and the positions are updated by the new velocities. Then, particles are tested and bounced off any surfaces 
that they have penetrated. If a particle has penetrated a sur-face a bounced-flag is set, and the velocity 
is broken into its normal and tangential components, Vn and Vt: Vn= (V. N)N =v-v. {See figure 2.1 A friction 
parameter,/~, reduces the tartgen- tial component, and the normal component is reflected and scaled by 
a resilience parameter, e, (both can range from 0.0 to 1.0): v' = (I -~)v, -ev~ If it is desirable to 
prevent particles from getting entirely stopped by friction, it is necessary to provide a velocity mag- 
nitude value below which friction has no effect. Particles have both bead and tail positions, Ph and 
Pt, to be used for motion blur. They are both flipped about the surface to account for the bounce. If 
S is any point on the surface: PL = P. -2I(P. -s). NIN 4O7  SIGGRAPH '90, Dallas, August 6-10, 1990 
V' l!!ii!iiiiiiiii !i   iiiiiiiiiiilr Figure 2: Bounce. P~ = Pt -2[(P~ -S). N]N The tail is also 
flipped because the particle renderer can not motion blur particles with kin.ks in their motion. Finally 
the tall is pulled up to the point of contact on the surface so it doesn't hang below the surface. Bouncing 
off spheres is performed in the same way as bouncing off planes, except N and S are calculated for the 
closest point on the surface of the sphere to the particle. If C is the center of a sphere of radius 
r: Ph -C Y -- IPh -CI S--C÷rN More accurate physical models for bouncing could proba- bly be implemented, 
but this method is sufficient for creating reasonable bouncing effects. 3.5 Particle Animation Summary 
Particles have state variables in addition to position and velocity that are used by some animation operations 
but not by others. For example: type, age, mass, spiral-axis, color, opacity, and size can be used. Other 
spare slots exist for information such as initial velocity, a color to fade to, or an age to die at. 
A valuable component of this particle animation system is a particle preview capability. Particles can 
be animated as shown above, and viewed with a quick vector display at near real time speeds. Fast turnaround 
time for particle motion experimentation is very helpful. An outline of an animation loop for creating 
particle mo- tion is as follows: Create particles. Initialize particles. For each frame: Set tails to 
previous heads. For each simulation time increment: Select subset of particles. Perform operations. Update 
positions using velocities. Select subset of particles. Perform bounce operations. Adjust tails for motion 
blur shutter speed. Render or preview. 4 Particle Rendering This section describes a data parallel method 
used to render large numbers of anti-aliased, motion blurred particles of variable sizes, colors, and 
transparencies. Every particle has a head and a tail, and the following parameters are passed from the 
particle animation system to the renderer for both the head and the tail of each particle: -position 
(¢, y, z) -radius -color (r, g, b) -opacity  [See figure 3a.] Motion blur is accomplished by linearly 
blurring each particle independently. The animation system sets the head and tail appropriately for the 
desired shutter speed. The renderer produces a blurred streak for each particle such that all the parameters 
above are interpolated between the head and the tail. Alternatively, the ability of the radius, color, 
and opacity to vary between the head and tail of particles, can allow some variety in particle shape, 
such as might be used to approximate comets, sparks, or water droplets. [See figure ~.] Particles occupy 
an area in which the opacity falls off from 1.0 at the center to 0.0 at the extremes. The func-tion that 
determines the falloff of the opacity can vary, and is used to perform out-of-focus or blurry effects 
as well as spatial anti-aliasing. Linear or Gaussian shapes are usually used. The rendering system first 
transforms the particles' head and tall positions and radii into screen coordinates. Then it dices the 
particles into fragments (in two stages) such that for each particle there is one fragment for every 
pixel that it will affect. These fragments containing color, opacity, and depth are then sorted by depth 
and the final pixel colors are calculated. This method has similarities to a simple a-buffer polygon 
rendering algorithm [4], but does not use coverage masks and does not perform texturing or lighting. 
An overview of the rendering process is given below: Update particles (animation). Transform to screen 
coordinates. For each horizontal patch: Determine effective patch height. Dice particles into spans. 
For each vertical patch: Determine effective patch width. Dice spans into fragments. Sort fragments by 
pixel and depth. Perform hidden surface calculation. Send colors to pixels. Add background color. Output 
pixels. 4.1 Dicing into Fragments The particle animation operations described above only re- quire a 
single data type, the particle, to exist in a virtual processor set within the CM. The rendering system, 
how- ever, generates multiple data types as it proceeds. Parti-cle spans, particle fragments, and pixels 
each are created in virtual processor sets with one data element per virtual processor.  ~ Computer 
Graphics, Volume 24, Number 4, August 1990 II "~ / i/ Y J i-T/' / I~ I . \ / I\ /I I~I ~.J  a.Particle 
b.Spa~$ c. Fra ~ments Figure 3: Particle Dicing.  First, each particle processor determines the number 
of scan lines that the particle will occupy and the particle is diced into spans. Multiple span processors 
are allocated for each particle processor, and the particle information is sent to them. Then, each span 
processor similarly determines the num- ber of fragments it will occupy, allocates fragment processors 
and sends the particle information to them. When particles are diced into fragments, there are often 
more total fragments than will fit into Connection Machine memory. To compensate for this, the image 
is rendered in subsections or patches. The size of each patch is adjusted such that all the fragments 
in that patch will fit into memory at once. The patch height is chosen before allocating span proces- 
sors such that the number of span processors will not exceed a limit. Likewise, for that horizontal section 
of the image, patch widths are chosen such that the number o£ fragment processors will not exceed a limit 
for each patch. It is also desirable to fill as many fragment processors as possible up to the limit 
since empty processors sit idle while the others compute. The processor usage "efllciency" for a given 
patch size is the total number of data elements (spans or fragments) within the patch divided by the 
maximum number permitted. The false position method [17] is used to search for patch widths and heights 
that result in an efficient use of span and fragment processors. After the fragment processors are set 
for a given patch size, the color, opacity and depth of that fragment are cal- culated by finding the 
closest point to the fragment on the line between the head and tail of the particle. The particle radii, 
depths, colors and opacities are interpolated between the head and tail to give values at that point. 
The final frag- ment opacity is set as a function of the interpolated opacity, the interpolated radius, 
and the distance from the center of the particle. Spatial anti-aliasing of particles is performed by 
ramping the opacity to zero near the edges of the particle, l~adii below one pixel are clamped to one 
pixel and the opacity is lowered to compensate to prevent aliasing due to sub-pixel sized particles. 
Coverage-masks or multiple samples per pixel were not used because unlike polygons whose edges often 
touch each other to make a continuous surface, the edges of particles usually do not line up. 4.2 Sorting 
Fragments and Calculating Transparency After the color, opacity and depth are calculated for all the 
fragments in the image patch being rendered, the fragments are reordered within the CM to make all the 
fragments cov- ering the same pixel adjacent to each other. They are also sorted within the pixel groups 
by depth. The parallel operator 8can operates on values in 1D ar- rays of processors. It allows each 
processor to receive the sum (or product) of all the values in the preceding pro- cessors. A segmented 
scan can be performed on groups of processors to prevent the results from spreading beyond the group. 
Local s,m.q and products can be efficiently calculated for groups of processors of variable sizes. Within 
each plxel group scan with multiply is applied to the fragment's transparencies from front to back to 
deter- mine the total pixel contribution of each fragment. Then, scan with add is applied to each color 
component and the opacity, each scaled by the fragment's pixel contribution. The last processor in each 
pixel group receives the final pixel color and opacity. The pixel colors are then sent to processors 
in the 2D image patch virtual processor set. Each virtual processor representing one pixel of the image 
patch being rendered receives the final color and opacity from the fragments cov- erring it, if any. 
Background color is added if necessary, and the patch is finally output to a frame buffer or file.  
4.3 Mixing with Other Data Types A recent addition to this system allows particles to be mixed with other 
renderable data types such as polygons. The frag- ments of both particles and polygons are depth sorted 
to- gether and rendered simultaneously. This permRs any num- ber of layers of particles and polygonal 
objects to move in front of and behind each other with correct hidden surfaces. This can be preferable 
to rendering the different data types separately and then compositing the images together after- wards. 
 5 Results The animated film Particle Dreams [24] was created entirely using the animation and rendering 
tools described above. It contains orbiting fire, an explosion, a snow storm, a crashing head, and a 
waterfall. These tools are also being used in a commercial production environment to create "burning 
logos," galaxies, and other effects. 5.1 Snow and Wind A snow storm was created using white snowflake 
particles, spirals, and vortices. Some snowflakes were created and dropped above the field of view at 
each iteration. They were given an initial velocity and sp~al axis straight down but with some random 
variation, and were bounced off the plane of the ground with zero bounce and high friction, so that once 
they hit, they stuck. [Figure 6a.] Gravity and air friction were not considered because the air friction 
damping and gravity would have canceled out at a steady critical velocity. Gusts of wind were made by 
moving pairs of vortices across the field of view. A gust procedure was built from two vortex operations 
so that gusts could be moved between given start and end positions. Gusts were choreographed and tested 
until the desired swirling effects were achieved. Finally, "splat" shapes were created by duplicating 
par- ticles into several particles when they hit a vertical plane.  StGGRAPH '90, Dallas, August 6-10, 
1990 The fire particles leave the surface and spiral upward while changing color. After they fade and 
die, they are recreated again at the initial position on the surface to start another cycle. The spiral 
axis slowly rotates to prevent du- plicate motion, and the flickers have slightly different fire- quencies 
to create a pseudo-random rhythm that natural fire can have. 6 Conclusion Some general tools for animating 
and rendering particle sys- tems are implemented that permit both kinematic and dy- namic control of 
particles. They are used to create effects that would probably be difficult to achieve using traditional 
techniques, but there are still many potential additions to this set of particle system utilities. Future 
work in this area might include operations that cause particles to influence each other: N-body types 
of sim- ulations might be used for galaxy simulations, more natural fluid motion, or collision avoidance. 
In the current imple-mentation particles ignore each other and only follow global rules, sometimes resulting 
in interpenetration. More efficient collision detection of surfaces would be beneficial. Currently every 
particle is tested against every surface element. The ability to create procedural motion for more complex 
objects (other than particles) including rigid body dynamic simulations would also be desirable. It would 
be interesting to compare the parallel speed of particle rendering with that of a serial computer. This 
was not done because of the unique parallel software implemen- tation. Rendering speed is approximately 
proportional to the number of processors, and inversely proportional to the number and sizes of the particles. 
Frame times commonly vary from several seconds to several minutes. Since data parallel computers have 
potential for growth in both the speed of processors and the number of proces- sors, they should become 
more powerful and more available in the future. Techniques that permit computer animation of complex 
structure and motion automatically and can uti- lize data parallelism, such as those presented here, 
may soon be more frequently used. 7 Acknowledgments Thanks to Lew Tucker for continuing support, Thanks 
to all the folks at Whitney/Demos Productions for a unique learning experience. Thanks to Thinking Machines 
Corpo- ration for building Connection Machines computers and be- ing generous. Thanks to Jim Salem, Brewster 
Kahle, Gary Oberbrunner, and Peter Schroeder for discussions and en-couragement. Thanks to J.P.Masser, 
Jeff Mincy, and Cliff Lasser for Starlisp and its support. Thanks to Arlene Chung and Debbie Mahe for 
layout and figures. And finally, thanks to John Whitney Jr., Jerry Well, and Optomystic for the en- vironment 
to put this work to use. References [1] Armstrong, W., Green, M., "The Dynamics of Artic- ulated Rigid 
Bodies for Purposes of Animation," Pro- ceedings Graphics Interface '85, pp. 407-415. [2] Amburn, P., 
Grant, E., Whitted, T., "Managing Ge- ometric Complexity with Enhanced Procedural Meth- ods," Computer 
Graphics, Vol. 20, No. 4, August 1986. 412 [3] Burr, A., Barzel, R., "A Modeling System Based on Dy- 
namic Constraints," Computer Graphics, Vol. 22, No. 4, 1988, p. 179. [4] Carpenter, L.C., "The A-buffer, 
an Anti-aliased Hidden Surface Method," Computer Graphics, Vol. 18, No. 3, 1984. [5] Fournier, A., Reeves, 
W., "A Simple Model of Ocean Waves," Computer Graphics, Vol. 20, No. 4, 1986, pp. 75-84. I6] Girard, 
M., Maeiejewski, A., "Computational Model- ing for the Computer Animation of Legged Figures," Computer 
Graphics, Vol. 19, No. 3, 1985, pp 263-270. [7] Hahn, J. K., "Realistic Animation of Rigid Bodies" Computer 
Graphics, Vol. 22, No. 4, 1988, p. 299. [8] HillJs, W. D., The Connection Machine, MIT Press, 1985. [9] 
Hillis, W. D., "The Connection Machine," Scientific American, Vol. 255, No. 6, June 1987. [10] Lasser, 
C., Massar, J.P., Miney, J., Dayton, L., "Starlisp Reference Manual," Thinking Machines Cor- poration, 
1988 [11] Lucasfilm Ltd, The Adventures of Andre and Wally B., (film), August 1984. [12] Miller, G., 
"The Motion of Snakes and Worms" Com-puter Graphics, Vol. 22, No. 4, 1988, p. 169. [13] Oppenheimer, 
P. "Real time design and animation of fractal plants and trees. Computer Graphics, Vol. 20, No. 4, 1986, 
pp 55-64. [14] Paramount, Star Trek II: The Wrath off Kahn, Genesis Demo, also in SIGGRAPH Video Review 
1982, ACM SIGGRAPH, New York. [15] Peachy, Darwyn R., "Modeling Waves and Surf," Com-puter Graphics, 
Vol. 20, No. 4, 1986, pp. 65-84. [16] Platt, J., Burr, A., "Constraint Methods for Flexible Models," 
Computer Graphics, Vol. 22, No. 4, 1988, p. 279. [17] Press, Flannery, Tenkolsky, and Vetterling, Numerical 
Recipes, Cambridge University Press, 1986, p. 248. [18] Prnsinklewicz, P., Lindenmayer, A., and Hanan, 
J., "Developmental Models of Herbaceous Plants for Com- puter Imagery Purposes," Computer Graphics, Vol. 
22 No. 4, 1988, pp. 141-150. [19] Reeves, W. T., "Particle Systems --A Technique for Modeling a Class 
of Fuzzy Objects," ACM Transactions on Graphics, Vol. 2, No. 2, April 1983, reprinted in Computer Graphics 
1983, pp. 359-376. [20] Reeves, W. T., and Blau, R. Approximate and proba- bilistic algorithms for shading 
and rendering structured particle systems. Computer Graphics, Vol. 19, No. 3, 1985, pp 313-322. [21] 
Reffye, P., Edelin, C., Francon J., Jaeger, M., Puech, C. "Plant Models Faithful to Botanical Structure 
and Development," Computer Graphics Vol. 22, No. 4, 1988, pp 151-158.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1990</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

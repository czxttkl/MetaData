<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date></start_date>
		<end_date></end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>54852</proc_id>
	<acronym>SIGGRAPH '88</acronym>
	<proc_desc>Proceedings of the 15th annual conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-275-6</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1988</copyright_year>
	<publication_date>06-01-1988</publication_date>
	<pages>356</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3.0</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
		<other_category>
			<cat_node>I.3.3</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
		<other_category>
			<cat_node>I.3.5</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
		<other_category>
			<cat_node>I.3.7</cat_node>
			<descriptor></descriptor>
			<type></type>
		</other_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010371.10010396</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010352</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
			<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010372</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10003752.10010061.10010063</concept_id>
			<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10003752.10010061</concept_id>
			<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371.10010382</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Design</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP74022629</person_id>
			<author_profile_id><![CDATA[81407594230]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Richard]]></first_name>
			<middle_name><![CDATA[J.]]></middle_name>
			<last_name><![CDATA[Beach]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Xerox PARC, Palo Alto, CA]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1988</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>378457</article_id>
		<sort_key>17</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[A parallel algorithm for polygon rasterization]]></title>
		<page_from>17</page_from>
		<page_to>20</page_to>
		<doi_number>10.1145/54852.378457</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378457</url>
		<abstract>
			<par><![CDATA[A parallel algorithm for the rasterization of polygons is presented that is particularly well suited for 3D Z-buffered graphics implementations. The algorithm represents each edge of a polygon by a linear <b>edge function</b> that has a value greater than zero on one side of the edge and less than zero on the opposite side. The value of the function can be interpolated with hardware similar to hardware required to interpolate color and Z pixel values. In addition, the edge function of adjacent pixels may be easily computed in parallel. <b>The</b> coefficients of the "Edge function" can be computed from floating point endpoints in such a way that sub-pixel precision of the endpoints can be retained in an elegant way.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[linear edge function]]></kw>
			<kw><![CDATA[parallel processing]]></kw>
			<kw><![CDATA[polygon rasterization]]></kw>
			<kw><![CDATA[sub-pixel vertices]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Parallel algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Parallelism and concurrency</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Parallel processing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761.10003762</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency->Parallel computing models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010170</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Parallel algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169.10010170</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies->Parallel algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334887</person_id>
				<author_profile_id><![CDATA[81100366504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Juan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pineda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Computer Inc., Chelmsford, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. Algorithm for Computer Control of Digital Plotter. IBM Systems Journal 4,1 (1965), 25-30.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Foley, J. and A. Van Dam, "Fundamentals of Interactive Computer Graphics."]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H. and Poulton J. PIXEL-PLANES: A VLSI-Oriented Design for a Raster Graphics Engine. VLSI DESIGN (Third Quarter 1981), 20-28.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fujimoto, A. and Iwata, K. Jag-Free Images on Raster Displays. IEEE Computer Graphics and Applications 3,9 (December 1983), 26-34.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Whitton, M. Memory Design for Raster Graphics Displays. iEEE Computer Graphics and Applications 4,3 (March 1984), 48-65.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 A Parallel Algorithm for Polygon Rasterization 
Juan Pineda Apollo Computer Inc. Chelmsford, iVIA 01824 juan@apollo.uucp Abstract A parallel algorithm 
for the rasterization of polygons is presented that is particularly well suited for 3D Z-buffered graphics 
implementations. The algorithm represents each edge of a polygon by a linear edge function that has a 
value greater than zero on one side of the edge and less than zero on the opposite side. The value of 
the function can be interpolated with hardware similar to hardware required to interpolate color and 
Z pixel values. In addition, the edge function of adjacent pixels may be easily computed in parallel. 
The coefficients of the "Edge function" can be computed from floating point endpoints in such a way that 
sub-pixel precision of the endpoints can be retained in an elegant way. CR catagories and subject descriptors: 
1.3.1 [Computer Graphics]: Hardware Architecture -Raster display devices; 1.3.3 [Computer Graphics]: 
Picture/Image Generation -Display algorithms. General terms: Algorithms. Additional keywords and phrases: 
Polygon rasterization, sub-pixel vertices, linear edge function, parallel processing. 1. Introduction 
The fast rendering of 3D Z-buffered linearly interpolated polygons is a problem that is fundamental to 
state of the art workstations. In general, the problem consists of two parts: 1) the 3D transformation, 
projection and light calculation of the vertices, and 2) the rasterization of the polygon into a frame 
buffer. This paper deals with one aspect of the latter problem: the computation of the boundaries of 
the polygon. Traditionally, the edges of a polygon are computed by a line interpolation algorithm, and 
each scan line is filled with linearly interpolated color and Z values [2]. This method is generally 
scan line serial, and is consequently not so convenient for frame buffers with more desirable rectangular 
word organizations [5]. The "PIXEL-PLANES" [3] system uses a parallel multiplier tree to simultaenousty 
compute, for all pixels in the frame buffer, a linear function which is used to define edges. This method 
has the nice property that it is highly parallel, but it has the disadvantage that it requires dedicated 
logic for each pixel, and consequently requires custom memory chips. The algorithm presented in this 
paper also uses a linear function to define polygon edges, but it allows for painting algorithms that 
are Permission to copy without fee all or part of this material is granted provided that the copies are 
not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the 
publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
&#38;#169;1988 ACM-0-89791-275-6/88/008/0017 $00.75 better suited to frame buffers using conventional 
DRAM and VRAM technology. The algorithm is inherently parallel, so that the rendering performance is 
memory bandwidth limited, rather than computation limited. The edge function is a linear function which 
can be used to classify points on a 2D plane that is subdivided by a line, into three regions: the points 
to the "left" of the line, the points to the "right" of the line, and the points on the line, The function 
has the property that points to the "left" of the line have a value greater than zero, points to the 
"right" have a value less than zero, and points exactly on the line have a value of zero. Since the function 
is linear, it can be computed incrementally in the same way as color and Z values. Subdivision of plane 
by line Triangle formed by union of through points A and B right sides of AB, BC and CA Figure 1. A Triangle 
Can be Formed by Combination of Edges Figure 1 shows how it is possible to define a triangle by the union 
of three edges which are specified by edge functions. It is possible to define more complex polygons 
by using boolean combinations of more than three edges. Note that a tie breaker rule must be applied 
to the points that lie exactly on any of the edges to determine whether the points are to be considered 
interior or exterior to the polygon. With this formalism, it is possible to compute at each pixel center 
on the plane an n-tupple: (R, G, B, Z, E1...En), where R, G, B and Z components form the fill value, 
and E1...En are the values of the edge functions which are used to determine whether the pixel is interior 
or exterior to the polygon. Given the value of this n-tupple at a single pixel position, the n-tupple 
of adjacent pixels can be computed by simple linear interpolators that require one addition per component 
per iteration. EI..En can then be used as a "stencil" that allows a pixel to be modified only if it is 
interior to the polygon. The process of painting the polygon can then be reduced to an algorithm that 
traverses an area that includes the interior of the triangle, but that does not have  f SIGGRAPH '88, 
Atlanta, August 1-5, 1988 to be particularly careful about the edges because the "stencil" forms the 
actual edge. The particular order of traversal is not important, only that each interior pixel is covered 
once and only once. Any traversal algorithm that touches all interior points once and only once will 
produce the correct result, but some may be more efficent than others, depending on how many pixels are 
covered by the traversal that are not actually drawn. The elegance of this approach is in the way that 
it orthogonalizes and unifies the traversal of a polygon and the filling of interior pixels. The orthogonality 
is convenient for the formulation of efficient strategies for painting a polygon with the least number 
of memory cycles and is especially useful with parallel rectangular memory organizations. 2. The Edge 
Function Consider, as shown in figure 2, a vector defined by two points: (X,Y) and (X+dX,Y+dY), and the 
line that passes through both points. This vector and line can be used to divide the two dimensional 
space into three regions: all points to the "left" of, to the "right" of, and exactly on the line. ~, 
Y÷dY dde Figure 2. An Edge is Defined by a Vector We define the edge function E(x,y) as: E(x,y) = (x-X) 
dY-(y-Y) dX This function has the useful property that its value is related to the position of the point 
(x,y) relative to the edge defined by the points (X,Y) and (X+dX, Y÷dY): E(x,y) > 0 if (x,y) is to the 
"right" side E(x,y) = 0 if (x,y) is exactly on the line E(x,y) < 0 if (x,y) is to the "left " side To 
convince oneself that this is true, recognize that the formula given for E(x,y) is the same as the formula 
for the magnatude of the cross product between the vector from (X,Y) to (X+dX, Y+dy), and the vector 
from (X,Y) to (x,y). By the well know property of cross products, the magnatude is zero if the vectors 
are colinear, and changes sign as the vectors cross from one side to the other. This function is convenient 
for rasterization algorithms, since it can be computed incrementally by simple addition: E(x+l,y) = E(x,y) 
+ dV E(x,y+l) = E(x,y) -dX  The edge function is related to the error value or "draw control variable" 
(DCV) in Bresenham line drawing algorithms [1,2]. The difference is that Bresenham line drawing algorithms 
maintain the DCV value only for pixels within 1/2 pixel of the line, while E(x,y) is defined for all 
pixels on the plane. In addition, the value of the DCV at a given point differs from E(x,y) by a constant 
offset. In any case, the reason that both algorithms work is fundamentally the same. As mentioned earlier, 
this same property of E(x,y) is used by the "PIXEL-PLANES" [3] graphics system, where this function is 
computed in parallel for all pixels in the frame buffer by a multiplier tree.  3. Incremental Classification 
of Points around a Convex Polygon Consider a convex polygon defined by the vertices (Xi, Yi) 0< i <=N. 
For the convenience of notation, take (X0, Y0) = (XN, YN), and consider the i'th edge as the edge between 
the i'th and the [i-1] vertex. The initial values of the edge function interpolators at a starting point 
(Xs, Ys) would then be: dXi = Xi -X[i-1] dYi = Yi -Y[i-1] Ei(Xs, Ys) = (Xs -Xi) dYi -(Ys -Yi) dXi for 
O< i <=N The edge functions may then be computed incrementally for a unit step in the X or Y direction: 
Ei(x+l, y) = Ei(x, y) + dYi, Ei(x-1, y) = Ei(x, y) -dYi, Ei(x, y+l) = Ei(x, y) -dXi, Ei(x, y-l) = Ei(x, 
y) + dXi.  If we use a tie breaker rule that considers a point on an edge as interior to the edge, then 
a point is interior to the convex polygon if: Ei >= 0 for all i : O<i<=N .  4. Traversing the Polygon 
 Given the initialized edge interpolators, the interpolation coefficients, the tie breaker rule, and 
the Boolean function for combining the edges, we still need to traverse the area of the triangle in order 
to paint it. The polygon can be traversed by any algorithm that is guaranteed to cover all of the plxeis. 
Figure 3 shows two simple algorithms. Simply traversing the bounding box is perhaps the simplest strategy, 
but generally not the most efficient. A smarter algorithm would advance to the next line when it walked 
off the edge of a triangle. Traversing the Bounding Box A More Efficient Traversal Al- gorithm Figure 
3. Simple Traversal Algorithms One complicaton of the smart algorithm is that when it advances to the 
next line, it may advance to a point inside the triangle. In that case, the algorithm must search for 
the outside of the edge before it begins the next scan line. An example of this problem is shown on the 
top right hand edge of the triangle in figure 4.  ~ Computer Graphics, Volume 22, Number 4, August 
1988 Left clip Right clip Figure 4. Traversal Algorithms May Have to Search for Edge A smarter algorithm 
is shown in figure 5. It proceeds down from the starting point, working its way outward from a center 
line. The advantage of this algorithm over the simpler algorithm is that it never has to search for an 
edge, then double back. The tradeoff is that the interpolator state for the center line must be saved 
while traversing the outer points, since the interpolators must be restarted back at the center line. 
Notice that at the bottom, the "center" line shifts over if it ends up exterior to the triangle. Figure 
S. Smarter Algorithm Proceeds Outward From Center Line There are many traversal algorithms possible. 
The best algorithm will depend on the cost/performance tradeoffs in the implementation. 5. Clipping Left 
and right clipping can be viewed as additional polygon edges that are part of the pixel's value: (R, 
G, B, Z, E1..En, El, Er), where El and Er represent the left and right clip "edge functions". If the 
traversal algorithm views them as edges, then a smart traversal algorithm will turn back when it crosses 
a clip boundary and it will not spend time rendering clipped areas of a polygon, The top clip boundary 
can be used to control the starting point, while the bottom clip boundary can be used to control the 
last scan line rendered, Figure 6 shows clipping. Top clip Bottom clip Figure 6. Clipping a Triangle 
 6. Sub-pixel Accuracy of Vertices Typically in 3D graphics rendering, polygon vertices are in floating 
point format after 3D transformation and projection. Some implementations round the X and Y floating 
point ordinates to integer values, so that simple integer line algorithms can be used compute the triangle 
edges. This rounding can leave gaps on the order of 1/2 pixel wide between adjacent polygons that do 
not share common vertices. Gaps also occur as a result of the finite precision used in specifying the 
endpoints, but these gaps are much narrower. Some implementations attempt to eUminate these gaps by growing 
the edges of triangles to insure overlap, but these solutions cause other artifacts. In order to minimize 
these artifacts, it is desirable to render triangle edges as close as possible to the real line between 
two vertices. This is conveniently done with this algorithm by performing the interpolator setup computations 
in floating point, and converting to fixed point at the end: dXi = Xi -X[i-1] dYi = Yi -Y[i-1] Ei(Xs, 
Ys) = (Xs-Xi) dYi-(Ys-Yi) dXi dXi' = FtX(dXi) dYi' = FIX(dYi) El' = FlX(Ei) Note that as in any digital 
interpolator, the fractional precision used in the iteration must be chosen to give an acceptable error 
across the interpolation. While this computation does require five floating point additions and two floating 
point multiplies per edge, the cost is small when compared with the other computations required to transform 
and set up a 3D triangle. Notice that the computation only modifies the setup values of the El's, hut 
does not require any special treatment of the endpoints, except to insure that the traversal algorithm 
covers the entire area including the endpoints. 7. Parallel Implementation Since the edge function is 
linear, it is possible to compute the value of the edge function for a pixe! an arbitrary distance L 
away from a given point (x,y) : E(x+L, y) = E(x) + L dy  SIGGRAPH '88, Atlanta, August 1-5, 1988 This 
property allows a group of interpolators, each responsible for a pixel within a block of contiguous pixels, 
to simultaneously compute the edge function of an adjacent block in a single cycle. If the blocks were 
L pixels wide, then there would be L interpolators. In order to compute the edge function of the block 
L pixels away in the ÷x direction, each interpolator would increment by (L dx). Since color and Z components 
are linear as well, they may also be computed in parallel. Graphics frame buffers are usually organized 
to provide simultaneous access to a block of adjacent pixels [5]. The block is usually called a word, 
and the pixels within the block are called interleaves. If a group of interpolators are dedicated to 
each interleave, then the RGBZ value and whether the pixel should be drawn can be computed in parallel 
for an entire word, If the interpolator cycle time is at least as fast as the memory cycle time (which 
is the case with current, gate array and DRAM technology), then shaded triangles can be rendered at the 
memory cycle time. pixel d access Figure 7. Covering a Triangle by Rectangular Accesses 8. Future Work 
and Extensions The edge functions described in this paper have been linear. It is possible to compute 
higher order edge functions. A second order edge function would yield conic edges such as circles or 
elipses. Combined with more interesting Boolean functions, it would be possible to efficiently compute 
complex shapes, such as wide lines with rounded endpoints. By proper normalization of the partial derivatives 
and intial value of E(x,y), it is possible to perform the interpolation of the edge functions in a floating 
point like manner, thus maximizing the precision obtained from a finite width interpolator. This method 
has the desirable property that it gradually looses precision as triangles get larger, rather than abruptly 
breaking. Because triangle edges are specified by the coefficients in the edge function, rather than 
end points, it is actually possible to transform the coefficients directly, rather than forming a triangle 
from the transformed and projected vertices. While this does not directly save computation, it may reduce 
some of the computational difficulties encountered in perspective projection. Specifically, since the 
objects being transformed are edges rather than points, the precision and dynamic range problems encountered 
with perspective projection of points near the eye point or behind the hither plane can be eliminated. 
This means that it may be possible to transform polygons without the need for exception cases for vertices 
behind the hither plane. This property could be useful in pipeline implementations where the exception 
case would limit performance. Since the value of the edge function is proportional to the distance of 
a point from the edge, it is possible to use this value to anti-alias edges. This could be performed 
using a method proposed by Fujimoto and Iwata [4]. In this method, the Bresenham DCV value and increments 
for a polygon edge are put through a lookup table that performs a divide and computes a low precision 
estimate of the distance of the pixel center from the edge center line. This distance is then used to 
adjust the contribution of the fill value to the background value. Going one step further with anti-aliasing, 
it is possible to have the lookup table produce a crude sub-pixel resolution bitmap for each edge. The 
bitmaps of all edges would then be anded together, and the number of set sub-pixels would be counted 
to determine the contribution for that pixel. Since the method aproximates the actual sub-pixel bitmap 
for the triangle, it has excellent behavior at verticies, and at places where edges are less than 1 pixel 
apart.  9. Conclusion An algorithm for rasterization of polygon edges has been presented. The algorithm 
has several useful properties: 1) it can be conveniently computed in parallel and used with common refresh 
buffer word organizations, 2) it can be computed with hardware similar to hardware required to interpolate 
color and Z values for 3D solids, and 3) it elegantly maintains the subpixel accuracy of vertices. These 
properties make the algorithm particularly attractive for use in 3D solid graphics implementations. 
10. Acknowledgements I would like to give special thanks to Bill Brandt for time spent on numerous discussions 
during the intial formulation of the ideas presented here. I would also like to thank Casey Dowdell, 
Bill Brandt, John Beck, Jane Critchlow and the conference reviewers for their time spent reviewing this 
text and for their helpful suggestions. Finally, I would like to thank Kathy Ford for help in the preparation 
of the final copy for publication.  References 1. Bresenham, J. Algorithm for Computer Control of Digital 
Plotter. IBM Systems Journal 4,1 (1965), 25-30. 2. Foley, J. and A. Van Dam, "Fundamentals of Interactive 
Computer Graphics." 3. Fuchs, H. and Poulton J. PIXEL-PLANES: A VLSI-Oriented Design for a Raster Graphics 
Engine. VLSI DESIGN (Third Quarter 1981), 20-28. 4. Fujimoto, A. and Iwata, K. Jag-Free Images on Raster 
Displays.  IEEE Computer Graphics and Applications 3,9 (December 1983), 26-34. 5. Whitton, M. Memory 
Design for Raster Graphics Displays. [EEE Computer Graphics and Applications 4,3 (March 1984), 48-65. 
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378468</article_id>
		<sort_key>21</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[The triangle processor and normal vector shader]]></title>
		<subtitle><![CDATA[a VLSI system for high performance graphics]]></subtitle>
		<page_from>21</page_from>
		<page_to>30</page_to>
		<doi_number>10.1145/54852.378468</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378468</url>
		<abstract>
			<par><![CDATA[Current affordable architectures for high-speed display of shaded 3D objects operate orders of magnitude too slowly. Recent advances in floating point chip technology have outpaced polygon fill time, making the memory access bottleneck between the drawing processor and the frame buffer the most significant factor to be accelerated. Massively parallel VLSI system have the potential to bypass this bottleneck, but to date only at very high cost. We describe a new more affordable VLSI solution. A pipeline of <i>triangle processors</i> rasterizes the geometry, then a further pipeline of <i>shading processors</i> applies Phong shading with multiple light sources. The triangle processor pipeline performs 100 billion additions per second, and the shading pipeline performs two billion multiplies per second. This allows 3D graphics systems to be built capable of displaying more than one million triangles per second. We show the results of an anti-aliasing technique, and discuss extensions to texture mapping, shadows, and environment maps.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphics VLSI]]></kw>
			<kw><![CDATA[hardware lighting models]]></kw>
			<kw><![CDATA[interpolation]]></kw>
			<kw><![CDATA[real-time image display]]></kw>
			<kw><![CDATA[shading]]></kw>
			<kw><![CDATA[triangle processor]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>B.2.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.3</cat_node>
				<descriptor>Pipeline processors</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.2.1</cat_node>
				<descriptor>Pipeline</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600.10010615</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits->Logic circuits</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010633</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010633.10010659</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design->VLSI system specification and constraints</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010522.10010526</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Serial architectures->Pipeline computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600.10010615.10010616</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits->Logic circuits->Arithmetic and datapath circuits</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P196764</person_id>
				<author_profile_id><![CDATA[81100240083]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Deering]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems Inc., 2550 Garcia Avenue, Mountain View, CA and Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31048378</person_id>
				<author_profile_id><![CDATA[81332535902]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stephanie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Winner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apple Computer Inc., 20525 Mariani Avenue, Cupertino, CA and Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334619</person_id>
				<author_profile_id><![CDATA[81100061589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bic]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schediwy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hewlett Packard Labs (3-U), 1501 Page Mill Road, Palo Alto, CA and Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334655</person_id>
				<author_profile_id><![CDATA[81547322856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Duffy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207965</person_id>
				<author_profile_id><![CDATA[81100258641]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Neil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hunt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15897</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Gary Bishop and David M. Weimer. Fast Phong shading. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics, pages 103-106, 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[James. H. Clark. The geometry engine, a VLSI geometry system for graphics. Proceedings of SIC- GRAPH'82 (Boston, Massachusetts, July 26-30, 1982). In Computer Graphics, pages 127-133, 1982.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Robert. L. Cook. Stochastic sampling in computer graphics. A CM Transactions on Computer Graphics, 5(1):51-72, January 1986.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Stefan Demetreseu. High speed image rasterizatlon using scan llne access memories. In 1985 Chapel Hill Conference on Very .Large Scale Integration, pages 221-243, Computer Science Press, 1985.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Henry Fuchs and John Poulton. Pixel-planes: a VLSI-oriented design for a raster graphics engine. VLSI Design, 2(3):20-28, 1981.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Nader Gharachorloo and Christopher Pottle. SUPER BUFFER: a systolic VLSI graphics engine for real time raster image generation. In 1985 Chapel Hill Conference on Very Large Scale Integration, pages 285-305, Computer Science Press, 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Paul S. Heckbert. Survey of texture mapping. IEEE Computer Graphics and Applications, 6(11):56- 67, November 1986.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808581</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Adam Levinthal and Thomas Porter. Chap - a SIMD graphics processor. Proceedings of SIC- GRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics, pages 77-82, 1984.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Leonard MeMillan. Graphics at 820 MFLOPS. ESD: THE Electronic Systems Design Magazine, 17(9):87-95, September 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Teiji Nishlzawa et al. A hidden surface processor for 3-dimension graphics. In Proceedings of ISSCC'88, pages 166-167,351, 1988.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[John Poulton et al. PIXEL-PLANES: building a VLSI-based graphic system. In 1985 Chapel Hill Conference on Very Large Scale Integratlon, pages 35-60, Computer Science Press, 1985.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37435</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[William T. Reeves, David H. Salesin, and Robert L. Cook. Rendering antialiased shadows with depth maps. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics, pages 283-291, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Roger W. Swanson and Larry J. Thayer. A fast shaded-polygon renderer. Proceedings of SIG- GRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics, pages 95-101, 1986.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37426</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[John G. Torborg. A parallel processor architecture for graphics arithmetic operations. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics, pages 197-204, 1987.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Andries van Dam et al. PHIGS+ functional description rev. 2.0. July 20 1987. Jointly developed PHIGS+ specification.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ Computer Graphics, Volume 22, Number 4, August 1988 The Triangle Processor and Normal Vector Shader: 
A VLSI System for High Performance Graphics Michael Deering* Stephanie Winner t Bic Schediwy ~ Chris 
Duffy Nell Hunt Schiumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA 94304 Abstract 
Current affordable architectures for high-speed display of shaded 3D objects operate orders of magnitude 
too slowly. Recent advances in floating point chip technology have out- paced polygon fill time, making 
the memory access bottle- neck between the drawing processor and the frame buffer the most significant 
factor to be accelerated. Massively parallel VLSI systems have the potentiai to bypass this bottleneck, 
but to date only at very high cost. We de- scribe a new more affordable VLSI solution. A pipeline of 
triangle processors rasterizes the geometry, then a fur- ther pipeline of shading processors applies 
Phong shading with multiple light sources. The triangle processor pipeline performs 100 billion additions 
per second, and the shading pipeline performs two billion multiplies per second. This al- lows 3D graphics 
systems to be built capable of displaying more than one million triangles per second. We show the results 
of an anti-allasing technique, and discuss extensions to texture mapping, shadows, and environment maps. 
GR Categories and Subject Descriptors: B.2.1 [Arith- metic and Logic Structures]: Design Styles - pipeline. 
C.1.1 [Computer Systems Organization]: Single Data Stream Ar- chitectures -pipeline processors. 1.3.1 
[Computer Graph- ics]: Hardware Architecture -raster display devices. 1.3.3 [Computer Graphics]: Picture/Image 
Generation -display algorithms. 1.3.7 [Computer Graphics]: 3D Graphics and Realism -color, shading, shadowing 
and texture, visible lines / surface algorithms. Additional Keywords: real-time image display, triangle 
processor, interpolation, hardware lighting models, shad-ing, graphics VLSL * Current address: Sun Microsystems 
Inc., 2550 Gareia Avenue, Mountain View, CA 94043. t Current address: Apple Computer Inc., 20525 Mariani 
Avenue, Gu- pertino, CA 95014. Current address: Hewlett Packard Labs (3-U), 1501 Page Mill Road, Palo 
Alto, CA 94304. Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. @ 1988 ACM-0-89791-275-6/88/008/0021 $00.75 1 INTRODUCTION Computer graphics has become an 
integral component of the modern concept of a general purpose computer. The graphical metaphor is more 
intuitive, flexible, and efficient than the old text-only man machine interface. Also, much of the usefulness 
of modern computing is the ability of the computer to simulate the real world to more and more ex- acting 
degrees. The graphics interface must support this, by portraying the three dimensional dynamic world 
more and more accurately. Currently affordable architectures for realistic display of three dimensional 
objects have severe constraints on scene complexity and display rates. The improvements needed are far 
beyond the factor of two or three typical of incremen- tal improvements on existing techniques. We re-examined 
the whole process of image generation, looking for an im- provement of at least an order of magnitude 
over conven- tional state of the art systems. After describing the prior art, we will introduce the con-cept 
of the Triangle Processor and Normal Vector Shader chips, and show how they can be configured into a 
high per- formance 3D display system. Certain important details of the architecture and chips are examined 
in more depth, fol- lowed by a discussion of extensions to support more sophis- ticated effects, including 
anti-aliasing and texture maps. 2 PRIOR WORK Most commercial 3D graphics systems are based on DRAM Z-buffers. 
Until very recently, almost all reasonable cost systems (less than $100 000) rasterized polygons one 
pixel at a time, with read-modify-write cycle times of approxi- mately one micro-second. Coupled with 
geometry trans-form systems capable of processing no more than 10 000 triangles a second, such systems 
take many seconds or even minutes to draw complex scenes containing large numbers of small triangles. 
This is so even though most modern systems include some form of VLSI support [2, 13]. Re-cently announced 
systems employ parallelism to rasterize polygons several pixels at a time [14]. But as detailed in Appendix 
A, the pixel write efficiency does not scale lin- early, and overall performance is increased by less 
than an order of magnitude. To get around the Z-buffer write limit, a number of mas- sively parallel 
VLSI systems have been proposed. Most have an array of intelligent pixel processors, through wlfich edges 
of polygons are broadcast; each pixel processor ex-amines the polygon geometry, and sets its pixel color 
to the polygon's color if the polygon both contains this pixel  @ ,i~ Computer Graphics, Volume 22, 
Number 4, August 1988 I host [ F-----] triangle processor pipe NVS pipe workstationA display list lq.ll'lner 
RAM I I I , Figure 2: Block diagram of the GSP-NVS system. avoids the "flat flash" problem associated 
with Phong shad- ing of flat surfaces by planar light sources. SYSTEM OVERVIEW We now describe a complete 
graphics system based on "graphical signal processing" with "normal vector shading" (GSP-NVS), which 
achieves a processing rate of one million triangles per second. A block diagram of the overall system 
is shown in Figure 2. Up to the Y-buffer, the processing is fairly conventional, although the computations 
must be performed at a rate of several million triangles per second. A display list runner (DLR) extracts 
geometry and display commands from the memory of the host workstation. The DLR handles viewing matrix 
manipulation, simple subrou- tine jumps, picks, bounding box tests, mode bit settings, and so on, but 
passes triangle and line stroke (vector) com- mands to the next stage Without interpretation, keeping 
the overhead to a minimum. The transform, clip, and set-up stage (XTC) performs the usual calculations 
on triangles and vectors. The resulting 448 bits of "pre-digested" triangle data are then passed to the 
Y-buffer. A much higher throughput (nearly a Gi- gaflop) than past systems is required here to support 
the rest of the architecture. The Y-buffer is organized as 1024 (or more) linked lists, one for each 
scan line on the display. The Y-buffer input process accepts triangles from the XTC, sorts them into 
bins indexed by their first active scan line number, and holds them in DRAM storage until all of the 
triangles in a given frame have been buffered. Then the output process feeds these triangles into the 
triangle pipe for rasterization, but now in scan line order. The Y-buffer also sequences the rasterizing 
within the tri- angle pipe. First, data representing all the triangles that become active on the current 
line are sent into the triangle pipe. Then the Y-buffer sends (1280) "blank" plxels for one scan line 
into the triangle pipe. This is repeated for all the scan fnes in the frame (1024). The triangle pipe 
accepts the triangle data, and converts the "blank" pixels into a stream of rasterized (and depth sorted) 
pixels in scan line order, as described above. Once the data for a triangle has been entered into the 
pipe, it will remain lodged in a Triangle Processor somewhere within, without need for any additional 
control, for as many scan lines as the triangle is tall. The NVS pipe takes the rasterized output of 
the triangle pipe, and converts the surface normal vector pixels to RGB pixels. These are finally stored 
in an RGB frame buffer prior to display on a CRT. 6 SYSTEM PROPERTIES The GSP-NVS system has several 
advantages. The amount of silicon required by the custom rendering pipelines is re- alistic, and indeed 
is less than needed elsewhere in a bal- anced system. This is partly due to the compact layout of the 
Triangle Processor cell, allowing as many as ten trian- gle processors per (inexpensive) chip. The hardware 
is not restricted to any fixed size image for output. To a first approximation, the rasterization time 
for a com- plete image is the time taken to load all the triangle data, plus the time to send through 
a screen-full of pixels. Thus in many normal cases, the rasterlzation time is independent of the sizes 
of the triangles. The load time is short, because each triangle need only be entered into the pipe once, 
and special care has been taken to make this entry as fast as possible (8 cycles of 50as). The time to 
send pixels into the pipe is also very small, at 50ns per pixel. Typical load time might be 20% of the 
rasterization time. There are some disadvantages. As is the case with the Super-Buffer, a Y-buffer is 
required to pre-sort the geom- etry. Unlike the processor-per-pixel architectures, geome- try overflow 
is possible if too many triangles are active on the same scan line. This is not a fundamental limit, 
as the pixels can be passed through the triangle pipe multiple times, effectively increasing the number 
of Triangle Proces- sors available.  7 TRIANGLE PROCESSOR INTERNAL ARCHITECTURE The feasibility of 
a machine with a processor per triangle is dependent on such processors being relatively inexpen- sive. 
We have designed a complete Triangle Processor in full custom CMOS VLSI, using less than 25000 transis-tors; 
prototype chips containing one triangle processor have been fabricated, tested and shown to be fully 
operational at expected speed. Modern VLSI densities allow upwards of ten such processors to be instanced 
onto a single die; fur- thermore, as VLSI densities increase, additional Triangle Processors can be added 
to the chip with little effort and without modifying the chip pin-outs. Because these chips are made 
to be directly wired together in a linear pipe (with no support chips required), upwards of 1 000 Triangle 
Pro- cessors occupy less than a square foot of PC board space (assuming 8 processors per chip in 1.2~ 
technology). Figure 3 shows the external data flow between individual Triangle Processor chips, and the 
internal data flow be- tween Triangle Processors within the same chip. The z pixel location is locally 
generated within each chip by the G-unit; consequently, this value does not have to be passed between 
the chips, reducing the pin count. Another factor of two reduction in pin count is obtained by double 
clocking ¢, Figure 3: External data flow and internal organization of the Triangle Processors chip. 
(Note that only 30 data input pins are needed for the 60 signals shown, as the pins are double clocked.) 
the I/O pins*, enabling the Triangle Processors and NVS chips to be housed in 68-pin leaded chip carrier 
packages. Each Triangle Processor is broken down into a number of function units, also shown in Figure 
3. Each unit operates on a different component of the pixel value flowing past. The X channel propagates 
the 24-bit fixed point number in- dicating the m location of the current pixel. The Z channel also propagates 
a 24-blt fixed point number, representing the z depth generated for the current pixel. The 18-bit N channels 
(N=, Nu, and Nz) propagate the interpolated (de- normalized) surface normal vector. The M channel prop- 
agates the associated "material index" (information about color and other triangle surface properties). 
The processor control unit interprets the command instructions, which se- quence the loading of initial 
values and incremental param- eters into the function units, and control the rasterization of the image. 
7.1 The X-Unit. Figure 4 shows the X-unit, which interpolates the points where the edges of the tri- 
angle cross each scan line in turn. Before the first scan line on which the triangle is active, m coordinates 
of the left and right edges of the triangle, and y-increment values are loaded. At the end of each scan 
line, the X-unit updates the left and right z coordinates by adding the y increment, thus obtaining the 
coordinates where the edges cross the nezt scan llne. Also, a counter is decremented; when the counter 
goes neg- ative, either the current triangle has expired, or one of the edges has reached a vertex. In 
the former case, the triangle processor becomes passive, and awaits the next packet of new triangle data 
to arrive. If a vertex has been reached on one of the edges, new initial and incremental values axe set 
for that edge, and also a new counter value, from local * Data is transferred on both rising and falling 
phases of the clock, using each pin twice per clock cycle. @ @ 0 x_in I I ~ x out rl I -I I Figure 
4: Schematic of the X-unit, used to track left and right edges of triangles, relative to the current 
scan line. z_in z_out= Figure 5: Schematic of the Z-unit, used to interpolate and compare Z depth values. 
n in r n_ouL r Figure 6: Schematic of the N-unit, used to interpolate sur- face normal vectors. backup 
registers. Whether it is the left or right edge which changes direction is known at set-up time, and 
indicated by a triangle "type" bit in the da.ta initially loaded for the triangle. The X-unit continuously 
compares the pixel m coordinate (which increases on each incoming pixel) with the m posi- tions of the 
left and right edges of the local triangle on the current scan line. (The values of z are generated by 
a sin- gle G unit on each chip, and are then pipelined through all the X-units on that chip.) Other units 
of the processor are signalled whenever the current plxd falls within the local triangle.  ~ Computer 
Graphics, Volume 22, Number 4, August 1988 7.2 The Z-Unit. Figure 5 shows the Z-unit sch- ematic, which 
interpolates the z depth in both x and y directions across the triangle. The data loaded for a trian- 
gle before the scan line on which the triangle first becomes active is the initial z value, and also 
x- and y-lncrements. At the start of each scan line, the z value is stored in the left register. On every 
pixel clock cycle, the x-increment is added to the current z value, interpolating triangle surface depth 
from left to right across the image. At the end of each scan line, the y-increment value is added to 
the stored z value from the left register, and this is used for subse- quent x-interpolation on the next 
scan line. In this way, the z depth at each pixel in the triangle is computed. Note that the interpolation 
is across the entire scan line, regardless of where the triangle is actually active. This saves having 
to activate the interpolation part way through a scan line, without affecting the interpolated value 
within the triangle in any way*. Each Z-unit compares the z value input from the preceding Triangle Processor 
to that locally computed. When the current pixel falls within the local triangle (as determined by the 
X-unit), and when the z depth of the local triangle is less than that for triangles computed by preceding 
Triangle Processors for thls pixel, the local triangle "wins", and will be visible in the image (unless 
some other triangle later in the pipeline subsequently wins over it). For a winning triangle, the interpolated 
z depth at this pixel is propagated to the next Triangle Processor in the pipeline; otherwise, the previous 
best z from the preceding Triangle Processors will be passed forward unchanged. If a pixel is unclaimed 
by any triangle, the z value is unde- fined, and is usually set to the back clipping plane value. 7.3 
The N-Unit. Figure 6 shows a schematic of an N-unlt. Three such units N~, Nv, and N= are used to interpolate 
the surface normal vector N over the triangle. Before the triangle becomes active, an initial N vector 
is loaded, along with x-and y-increments. The x-increment updates the N vector across each scan fine, 
while the y-increment updates the N vector at the end of each scan line, just as in the Z-unit. The output 
multiplexer selects the locally interpolated N normal vector if the local tri- angle plxel "wins", and 
is to be substituted; otherwise the input N normal value from the previous best triangle is propagated. 
The value interpolated is the normal vector to the surface of the winning triangle at the point center 
of the current pixel. Implementing the interpolation in this fashion ensures that all triangles are uniformly 
sampled and avoids a number of aliasing artifacts and 'tholes" in the image. 7.4 The M-Unit. The M-unit 
latches the 9-bit material index of the local triangle during load time. At each pixel, the input material 
index is propagated, unless the local triangle wins, in which case the stored material index is substituted. 
* Small triangles having large curvatures have very large increment values; this is not a problem~ as 
we simply subtract enough from the initial values allowing for the overflow wrap-around which may occur, 
so that the value is correct within the area of the triangle. 7.5 Commands. The Triangle Processor control 
unit sequences the N, Z, X, and M-units in response to commands received via the command data bus. Only 
nine commands are needed: RESET Global reset. Force all Triangle Processors to state free. ENABLE Global 
enable. Set the enable bit in all Triangle Processors. IDLE No operation. Used to pad processing. NEW 
Header of an eight word packet of new triangle data. SOL Start of line. Used to mark an eight word header 
starting rasterization for each line. EOL End of line. Used to terminate rasterization of each line. 
RAZ Rasterization command. Represents a back-ground pixel to be processed. RAZD Rasterization command 
with data. Represents a pixel previously claimed by some triangle. EXT External commands. Normal Vector 
Shader commands and other user defined non-Triangle Processor commands. 7.6 Additional Features. The 
Triangle Processor includes support for simple 2 x 2 "screen-door" translucency.  Line strokes can be 
displayed efficiently by converting them to parallelograms (a special case of a triangle with parallel 
sides, with the point cut off prematurely).  Because the fixed-point bit position is externally se-lectable, 
the 24-blts of accuracy in x and y values allow a large variety of screen address ranges. Note that the 
internal registers and data paths of the Triangle Pro- cessor chip have a few more bits than the width 
of the data paths off-chip, to maintain interpolation accuracy, while keeping the pin-count down.  A 
number of features facilitate testing of the chips. These include the ability to map out defective proces- 
sors, which can reduce the cost of building the chips, as those with some fabrication defects are still 
usable.  8 SIMPLIFIED LIGHTING MODEL The GSP-NVS lighting model is similar to that used in most software 
based polygon display systems, but is more sophis- ticated than any other video rate hardware systems 
to date. Most high speed graphics systems only apply their lighting model at the vertices of polygons, 
obtaining an RGB value for each vertex. These color values are interpolated across the face of the polygon 
(Gouraud shading). We apply our full Phong fighting model to each pixel, for inherently su-perior shading. 
Our "Normal Vector Shader" (NVS) chips implement, in silicon, all interior shading methods, and full 
lighting and depth cueing equations, as specified by the PHICS+ proposal [15], except point and cone 
light sources. Five planar, colored light sources are simultaneously sup- ported at full speed. Given 
as input the un-normalized surface normal vector N', and the internally interpolated un-normalized view-point 
vector V t, we first compute re-normalised values N and V, and also a reflection vector R: N r V I N--x/~" 
V--V/~_~, R=2(N.V)N-V. From these values, the RGB color is computed: i=5 RGB = ~ [(N. Li + lai)mc + 
(a. L,) ~'1 le,. i=l Here Li~ lei~ and la i are the normal to, color of, and ambient component, respectively, 
of the i ~h light source, and me and sp are the color of, and specular power of the material under illumination, 
looked-up with the material index of the pixel. The square root, power function, and specular reflection 
coefficient (not shown) are implemented via on-chip ROM tables. It is beyond the scope of this paper 
to describe all the details of the full lighting model~ which include depth cueing, intensity of specular 
illumination, built-in simple environment map (including reflections -as seen in Figure 1), and hooks 
for texture maps~ shadows, and local light sources. 9 LIGHTING MODEL CHIP The illumination pipe of the 
GSP-NVS system consists of 16 identical NVS chips, with pin-outs identicalto the Trian- gle Processors 
chip. Each is capable of applying the entire five light source lighting model to a single pixel (surface 
normal vector N I + depth z + material index M) in 16 clock cycles. Round robin scheduling enables the 
16 chips in the pipe to shade a stream of pixels at the full clock rate. Internally the NVS chips are 
heavily pipelined, and in fact take 64 clock cycles to shade each pixel. However, four pix- els can be 
at various stages of shading at the same time, providing the 16 clock cycle throughput per chip. Figure 
7 displays the specialized vector function units of the NVS chip, which are the key to the efficiency 
of the NVS pipeline (two billion multiplies per second with 16 chips). They al- low for efficient area 
layout, as well as simplified scheduling. An alternative to building a custom lighting model engine would 
be to use a general purpose DSP chip. However, such chips typically contain only a single scalar function 
unit, and for a given area of silicon, will tend to be at least an order of magnitude slower than our 
custom chips. For example: the DSP32 chips employed in the Pixel Machine [9] individually run at 10 million 
multiply-adds per second, and it would take at least 200 of these chips (with several support chips each) 
to perform the equivalent computation. 10 TRIANGLE PIPE OVERFLOW The previous discussion has assumed 
that there were a suf- ficient number of Triangle Processors to handle all the tri- angles active on 
a particular scan line; in other words, no overflow. Our strategy for dealing with overflow is to al-ways 
detect it before it occurs. This allows us to split the problem into two tasks: overflow detection and 
overflow correction. For detection, we must know the number of Triangle Pro- cessors in the free state 
at any time. To this end, the 26 m o u t t b a f f e r integer control ] function unit unit Figure 7: 
Block diagram of the Normal Vector Shader chip, displaying the internal function units and their (simplified) 
interconnection. Y-buffer keeps a free counter and an auxiliary table. The free counter represents the 
number of Triangle Processors known to be free (initially all of them), and the auxlllary table records 
the number of Triangle Processors scheduled to become free on a particular scan line. Whenever a new 
triangle is to be entered into the pipe, the free counter is tested: if it is zero, the triangle is not 
entered, and over-flow processing commences; otherwise, the counter is decre- mented, showing one less 
free Triangle Processor. When a triangle is successfully entered into the pipeline, the scan line on 
which that triangle ends is computed (by adding the height of the triangle to the current scan line number), 
and the entry in the auxiliary table corresponding to that line is incremented. After each scan line 
has been processed, the free counter is incremented by the auxiliary table entry for the current llne, 
representing the number of Triangle Pro- cessors somewhere within the pipe that have just become free. 
When an overflow condition is detected, the first action is to stop entering new triangles into the pipe, 
as there are no free Triangle Processors waiting for them. The overflowed triangles are left in the Y-buffer 
for a second rendering pass, while processing continues for triangles already in the pipe; the resulting 
pixels are stored in the RGBZ buffer, along with their associated z depth values, which will be used 
to merge later passes. Subsequent scan lines may or may not also overflow, depending upon the local triangle 
population * Computer Graphics, Volume 22, Number 4, August 1988 growth. At the end of the frame some 
of the triangles have been rendered into the RGBZ buffer, while the remainder are still waiting in the 
Y-buffer. Another pass is made, rasterizing some or all of these overflowed triangles; the z values generated 
by the pipeline are compared with those stored in the RGBZ buffer from previous passes, the pixel with 
the nearer z value being stored in the buffer as a result. This is repeated as many times as necessary 
to rasterize all the triangles in the Y-buffer. While it appears that the machine will take a factor 
of two hit if even one triangle overflows~ and linearly more for each additional pass required, such 
is not the case. Overflows tend to be localized to a few areas. Hence, the second pass need not rasterize 
an entire frame of pixels, but only those scan lines touched by overflowed triangles. System simulations 
have statistically validated this~ showing that small overflows tend to increase rasterization time by 
less than 20%. Large overflows imply large numbers of input triangles, and the extra rasterization passes 
are overlapped by extra XTC computation time. One must have enough Triangle Processors in the system 
to match the throughput of the XTC section. For non-pathological display lists, there is a balance point 
where the time taken by the XTC to deliver the triangles will al- ways exceed the time taken by the total 
rasterization pro- cess, including multiple overflow passes. This is because both times grow approximately 
linearly in the number of triangles to be processed. As a specific example, at one million renderable 
triangles per second, the balance point is on the order of one thousand triangle processors. The balance 
point also places an upper bound on the required size of the Y-buffer, limiting costs. In support of 
multiple rendering passes, the Y-buffer uses a servoing control algorithm that balances overflows of 
the triangle pipe, the Y-buffer storage, and the XTC. For dis- play lists small enough to be rendered 
at frame rates (in other words, no overflows), the Y-buffer double buffers frames of triangle data. For 
larger display lists, the Y-buffer switches into single buffer mode m and after a high water mark, sets 
the triangle pipe to rasterizing, even though the XTC is still delivering triangles for the current frame. 
The assumption here is that multiple passes will be required, so the Y-buffer becomes a quantized FIFO 
between the XTC process and the triangle pipe. Detailed systems simulations have shown this approach 
to be viable and capable of sus- taining full performance. 11 ANTI-ALIASING While everyone is for anti-aliasing, 
few wish to pay large amounts extra for it. Thus versions of the Triangle Proces- sor with circuitry 
to generate pixel percent coverage data were rejected as too inaccurate when high quality was re- quired, 
and too expensive when only speed was desired. The single sample per pixel model used by the Triangle 
Processors avoids a number of smooth-surface aliasing arti- facts in previous hardware implementations. 
This accuracy allows high quality anti-aliased images to be produced by a variety of oversampling techniques. 
Within the system, there are two general anti-aliasing hard- ware support features. Where speed is essential, 
the system computes 960 × 1280 images, and then averages blocks of 2 × 2 pixels in real-time to NTSC 
video. When accuracy is required, a stochastic sampling is obtained by filtering together multiple renderings 
of the same display list, but from sub-pixel jitters in viewpoint position. By using a 24-bit per color 
component accumulator frame buffer, as many different pseudo-random samplings can be summed together 
as desired. Within each pass the pixel sample po- sitions are coherent with each other, making the technique 
somewhat more restricted than software implementations of stochastic anti-aliasing [3]. Figure 8: Demonstration 
of anti-a]iasing technique. The image is of a fan of cylinders of random thickness, in the range of 0.6 
to 1.6 pixels in width. Figure 8 displays an example of this technique. The data base is a fan of cylinders 
of varying thickness, from 0.6 to 1.6 pixels in width. The leftmost image is a single sampling with no 
anti-aliasing, rendered at 256 × 96. The upper right insert is a blowup of a portion of this. The middle 
image is the result of 16 pseudo-stochastic samplings weighted by a Gaussian low-pass filter. To the 
right is the correspond- ing blowup of it. This technique was also employed in the making of Figure 1. 
Other techniques based on stochastic sampling may be implemented on a GSP-NVS system using variations 
of this approach.  12 SOPHISTICATED EFFECTS Historically, hard-wired graphics has implied limited ren-dering 
models; general purpose machines have had to be used to get most of the recent improvements in graphics 
algorithms. While machines such as the Pixar [8] and the Pixel Machine [9] seem to cross this line, at 
heart they are built on top of general purpose processors. Without graph- ics specific VLSI, the speeds 
are only fast relative to full general purpose computers. The intent of this section is to show how simple 
enhancements of the GSP-NVS system can support some very sophisticated options~ at speeds or- ders of 
magnitude faster than existing hardware. One way or another, such sophisticated options will emerge in 
hard- ware systems of the future. Texture mappings environment mapping, and shadowing can all be implemented 
in a related fashion. Each re-quires an additional frame store, and hardware for a num- ber of transformation 
functions to generate addresses for this store from rendering information. The data output from the store 
forms additional lighting model input pa-rameters. These processes must be combined with multiple anti-aliasing 
passes to sample the data properly. Texture mapping requires an auxiliary texture map frame store, storing 
the desired texture(s) at multiple levels of resolution. Three intermediate values a, b, and c, derived 
from the values of the texture addresses at the corners of the triangles, must be interpolated across 
the faces of trian- gles. The final u,v texture map addresses are obtained by performing a perspective 
division: u = a/c, v = b/e. The texture map of the appropriate resolution is chosen as a function of 
the local scale, and can involve a filtered combi- nation of two scales [7]. The three additional interpolations 
can be performed by a second triangle pipe in parallel with the first, interpolating a, b, and c in place 
of the surface normal vector. An alternative is to make two passes using a single triangle pipe, once 
for normals, and then once for a, b, and c, buffering the outputs until needed. The u, v image is sent 
as a stream of addresses for the texture frame store, resulting in an RGB pixel stream to be sent into 
the NVS pipe in place of the RGB color indexed by the material tag. Environment mapping requires the 
vector computed as the reflectance of the v~ewpoint vector by the surface normal vector. This value is 
generated within the NVS chips as part of their normal processing, and a mapping function converts this 
vector into an environment map address. A simple mapping function is u = tan -x R~/R,, v = R=. The RGB 
output from the environment map is then aver-aged into the results of the regular lighting model computa- 
tion, with a mixing factor proportional to surface reflectiv- ity. (Indeed, a simplified version of environment 
mapping is implemented within the NVS chips for simple color ramps, as seen in Figure 1.) For shadows, 
the vector from each light source to the sur-face must be computed for each pixel. These vectors are 
used to generate addresses into precomputed depth buffer tables containing the maximum distance to which 
the light source reaches in each direction. A comparison of the length of the vector with the stored 
value is used to enable or dis- able each light source at each pixel in the regular lighting model computation. 
(Reeves et al. [12] discuss depth buffer shadowing with anti-aliasing.) Since these look-up process for 
texture, environment map- ping and shadowing involve random pixel addressing, the full pipeline rate 
of the machine will not be sustained. How- ever, with complex images, the rendering stage normally requires 
multiple passes, balancing the time taken for the table accesses which are only performed once per output 
pixel. 13 SIMULATORS The development of a set of simulator tools was tightly cou- pled with the evolution 
of the GSP-NVS architecture. The simulators span the range from a high level simulation fast enough to 
create short video test sequences, to a low level transistor by transistor simulation of the custom graphics 
chips. All of these simulators maintain the same numerical precision as the real hardware. We used the 
simulators to verify the algorithms, and also to generate the performance numbers. All the color images 
in this paper were generated by the high level simulator, from very complex data bases. Of course, the 
ultimate simulation is the real silicon. An incremental approach to the VLSI layout was taken, with individual 
function units fabricated as separate test chips. This allowed each unit to be fully verified in silicon 
as the design progressed. Test patterns for the design fragments, and for a complete Triangle Processor, 
were generated by the software simulators. 14 PERFORMANCE The GSP-NVS concept and family of VLSI chips 
can be used to build a variety of high performance graphics sys- tems. We have been designing such a 
system capable of sus- tained rendering of one million triangles per second. This system uses twenty 
40-Megaflop floating point chips within the transform and clip subsystem to process 1.6 million triangles 
per second, ensuring adequate throughput at the triangle pipe after various overheads. The display region 
is split into left and right halves, each with its own 20MHz triangle and NVS pipes. This effectively 
halves the total time taken to load triangles and rasterize pixels. Thus tri- angles are loaded at 200ns 
each, and then the whole region is rendered at 25ns per pixel. The Y-buffer allows trans- formation and 
rasterization to be 100% overlapped most of the time. Figure 9 shows a comparatively simple scene generated 
by a simulation of the GSP-NVS system. The data base used contained 24784 triangles, of which 11327 were 
visible. Rendered at a resolution of 1280 × 1024, the 1.25 million pixel image would be generated in 
less than one twenti-eth of a second. Note that the triangle load time was less than 5% of the total 
frame time, indicating that the system was running at only a quarter of its capacity. Simulations of 
larger display lists involving multiple triangle pipe over- flows have shown rendering times to scale 
almost linearly. More aggressive uses of additional rendering pipes can lead to processing rates upwards 
of five million triangles per sec- ond. 15 CONCLUSIONS We have described a highly parallel 3D graphics 
architec- ture based upon a pipeline of VLSI chips, which overcomes the frame-buffer DRAM access bottleneck 
present in all of today's general commercial systems. Our architecture achieves at least an order of 
magnitude increase in render- ing rate over previous systems, so that much more complex scenes can be 
rendered in a reasonable time. A further pipe- line of dedicated lighting model chips enhances the reality 
of the output with no loss in speed. An additional improvement in speed over present systems is achieved 
by decoupling the transformation process from the rendering process using a large buffer; this keeps 
both processes running in parallel for the majority of the time. The architecture has been tuned to support 
the statistical mix of geometry encountered in real applications, rather than simplified benchmarks. 
Our sampling model is built on a mathematically sound basis, similar to that used in ray-casting techniques. 
This avoids a number of aliasing artifacts and holes inherent in ones (the flat faces of the cubes), 
a number of long thin ones (the rounded edges), and a large number of very small ones (the rounded corners), 
of which many are sub-pixel in size. While this scene was somewhat artificial, experiments with a number 
of other objects from real mechanical CAD data bases bore out similar results. This chart gives part 
of the reason why real world applications typically run at least two to four times slower than the theoretical 
peak rate of the graphics system. The activity of the transform and cllp section is proportional to the 
height of the left boxes in each group, while rasterization activity is proportional to the height of 
the right boxes. For any given triangle size, typically only one of the two processes is active. Thus 
most polygons are either transform bound or polygon fill bound, resulting in significant idle time for 
the other process. This is responsible for nearly a factor of two reduction is speed over the "perfect" 
case. Additional reductions arise from idle rasterization cycles due to long chains of triangles that 
are back-facing or outside the clipping window, as well as overhead for starting a new triangle, moving 
to the next scan line, et cetera. An increase in graphics performance is more likely to cause users to 
display more complex objects, rather than the same objects faster. This is the so-called "four second" 
rule. Fig-ure 10 (1280 × 1024) displays an extremely large CAD ob- ject (by present standards). It represents 
a 70 000 triangle simplification of a 1 000 000 triangle satellite. Two trends appear in this and other 
similar objects that we have exam- ined: realistic background environments will almost always cover every 
pixel in the frame at least once; and more de- tailed, more complex objects will involve large numbers 
of small polygons. Furthermore, the mid-size polygons tend to be long and very thin, bordering on sub-pixel. 
From statistics of these objects we have concluded that pixel fill architectures using n × m block write 
schemes wl]l be less effective than might be assumed. We simulated a number of different block sizes, 
applied to the data base of Figure 1 (without ground pattern), and the resulting write cfficicn- cies 
are given in Table 1. Total Write Efficiency Block Size Pixels written/cycle 1 × 1 0.69 2 × 1 1.04 
2 × 2 1.57 4 × 1 1.41 4 x 2 2.22 4 × 4 3.10 8 × 4 4.04 8 × 8 5.27 Table 1: Efficiency of various parallel 
write architectures. The statistics are only for rendered triangles. The 1 × 1 number is less than unity 
because of triangles not con-raining valid sample points on every scan llne. All these numbers would 
be even lower if back-facing and clipped triangles were to be counted.   References [1] Gary Bishop 
and David M. Weimer. Fast Phong shading. Proceedings of SIGGRAPH'86 (Dal- las, Texas, August 18-22, 1986). 
In Computer Graph- ics, pages 103-106, 1986. [2] James. H. Clark. The geometry engine, a VLSI geometry 
system for graphics. Proceedings of SIC- GRAPH'82 (Boston, Massachusetts, July 26-30, 1982). In Computer 
Graphics, pages 127-133, 1982. [3] Robert. L. Cook. Stochastic sampling in computer graphics. A CM Transactions 
on Computer Graphics, 5(1):51-72, January 1986. [4] Stefan Demetreseu. High speed image rasteri-zatlon 
using scan llne access memories. In 1985 Chapel Hill Conference on Very .Large Scale Integra- tion, pages 
221-243, Computer Science Press, 1985. [5] Henry Fuchs and John Poulton. Pixel-planes: a VLSI-oriented 
design for a raster graphics engine. VLSI Design, 2(3):20-28, 1981. [6] Nader Gharachorloo and Christopher 
Pottle. SUPER BUFFER: a systolic VLSI graphics engine for real time raster image generation. In 1985 
Chapel Hill Conference on Very Large Scale Integra- tion, pages 285-305, Computer Science Press, 1985. 
[7] Paul S. I-Ieckbert. Survey of texture mapping. IEEE Computer Graphics and Applications, 6(11):56-67, 
November 1986. [8] Adam Levinthal and Thomas Porter. Chap -a SIMD graphics processor. Proceedings of 
SIC-GRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics, pages 77-82, 1984. [9] 
Leonard MeMillan. Graph]cs at 820 MFLOPS. ESD: THE Electronic Systems Design Magazlne~ 17(9):87-95, September 
1987. [10] Teiji Nishlzawa et al. A hidden surface processor for 3-dimension graphics. In Proceedings 
of ISSCC'88, pages 166-167,351, 1988. [11] John Poulton et al. PIXEL-PLANES: building a VLSI-based graphic 
system. In 1985 Chapel Hill Con- ference on Very Large Scale [ntegratlon, pages 35-60, Computer Science 
Press, 1985. [12] William T. Reeves, David H. Salesin, and Robert L. Cook. Rendering antialiased shadows 
with depth maps. Proceedings of SIGGRAPI-t'87 (Anaheim, CMifornia~ July 27-31, 1987). In Computer Graphics, 
pages 283-291, 1987. [13] Roger W. Swanson and Larry J. Thayer. A fast shaded-polygon renderer. Proceedings 
of SIG- GRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics, pages 95-101, 1986. [14] 
John G. Torborg. A parallel processor architec-ture for graphics arithmetic operations. Proceedings of 
SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics, pages 197-204, 1987. [15] 
Andries van Dam et al. PHIGS+ functional de-scription rev. 2.0. July 20 1987. Jointly developed PHIGS+ 
specification.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378472</article_id>
		<sort_key>31</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[An efficient algorithm for finding the CSG representation of a simple polygon]]></title>
		<page_from>31</page_from>
		<page_to>40</page_to>
		<doi_number>10.1145/54852.378472</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378472</url>
		<abstract>
			<par><![CDATA[We consider the problem of converting boundary representations of polyhedral objects into constructive-solid-geometry (CSG) representations. The CSG representations for a polyhedron <i>P</i> are based on the half-spaces supporting the faces of <i>P</i>. For certain kinds of polyhedra this problem is equivalent to the corresponding problem for simple polygons in the plane. We give a new proof that the interior of each simple polygon can be represented by a monotone boolean formula based on the half-planes supporting the sides of the polygon and using each such half-plane only once. Our main contribution is an efficient and practical <i>O(n</i> log <i>n</i>) algorithm for doing this boundary-to-CSG conversion for a simple polygon of <i>n</i> sides. We also prove that such nice formul&amp;aelig; do not always exist for general polyhedra in three dimensions.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[boundary-to-CSG conversion algorithms]]></kw>
			<kw><![CDATA[constructive solid geometry]]></kw>
			<kw><![CDATA[simple polygons]]></kw>
			<kw><![CDATA[solid modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Computations on discrete structures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P61269</person_id>
				<author_profile_id><![CDATA[81100388507]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dobkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15025666</person_id>
				<author_profile_id><![CDATA[81452606669]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Leonidas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guibas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University and DEC Systems Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39051547</person_id>
				<author_profile_id><![CDATA[81100630389]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hershberger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DEC Systems Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39024749</person_id>
				<author_profile_id><![CDATA[81100047211]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jack]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Snoeyink]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Boyse and J. Gilchrist. GMSolid: interactive modeling for design and analysis of solids. IEEE Computer Graphics and Applications, 2:86-97, 1982.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Brown. PADL-2: a technical summary. IEEE Computer Graphics and Applications, 2:69-84, 1982.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. M. Chazelle. Computational Geometry and Convexity. Technical Report CMU-CS-80-150, Carnegie-Mellon University, Department of Computer Science, Pittsburgh, PA, 1980.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>28905</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Edelsbrunner. Algorithms in Combinatorial Geometry. Volume 10 of EATCS Monographs on Theoretical Computer Science, Springer-Verlag, 1987.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>41969</ref_obj_id>
				<ref_obj_pid>41958</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. Franklin. Polygon properties calculated from the vertex neighborhoods. In Proceedings of the 3rd ACM Symposium on Computational Geometry, pages 110-118, ACM, June 1987.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. L. Graham and F. F. Yao. Finding the convex hull of a simple polygon. Journal of Algorithms, 4:324-331, 1983.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L. Guibas, J. Hershberger, D. Leven, M. Sharir, and R. Tarjan. Linear time algorithms for visibility and shortest path problems inside triangulated simple polygons. Algorithmica, 2:209-233, 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. Guibas, L. Ramshaw, and J. Stolfi. A kinetic framework for computational geometry. In Proceedings of the 24 th Annual IEEE Symposium on Foundations of Computer Science, pages 100-111, IEEE, 1983.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>323259</ref_obj_id>
				<ref_obj_pid>323233</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. Hoffmann, K. Mehlhorn, P. Rosenstiehl, and R. E. Tarjan. Sorting Jordan sequences in linear time. In Proceedings of the ACM Symposium on Computational Geometry, pages 196-203, ACM, 1985.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. T. Lee. On finding the convex hull of a simple polygon.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>539884</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. M. Mano. Digital Logic and Computer Design. Prentice- Hall, 1979.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>39278</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Mantyla. An Introduction to Solid Modeling. Computer Science Press, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. McCallum and D. Avis. A linear algorithm for finding the convex hull of a simple polygon. Information Processing Letters, 9:201-206, 1979.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31183</ref_obj_id>
				<ref_obj_pid>31181</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Melkman. On-line construction of the convex hull of a simple polyline. Information Processing Letters, 25:11-12, 1987.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4159</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Mortenson. Geometric Modeling. John Wiley &amp; Sons, 1985.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. Newell. Solid modelling and parametric design in the Medusa system. In Computer Graphics '82, Proceedings of the Online Conference, pages 223-235, 1982.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>40599</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. O'Rourke. Art Gallery Theorems and Algorithms. Oxford University Press, 1987.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[T. Pavlidis. Analysis of set patterns. Pattern Recognition, 1:165-178, 1968.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Peterson. Hal fspace Representation of Extrusions, Solids of Revolution, and Pyramids. SANDIA Report SAND84- 0572, Sandia National Laboratories, 1984.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[F. P. Preparata and M. I. Shamos. Computational Geometry. Springer Verlag, New York, 1985.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>356833</ref_obj_id>
				<ref_obj_pid>356827</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[A. Requicha. Representations for rigid solids: theory, methods, and systems. ACM Computing Surveys, 12:437-464, 1980.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>32800</ref_obj_id>
				<ref_obj_pid>32795</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. A. Sch~ffer and C. J. Van Wyk. Convex hulls of piecewisesmooth Jordan curves. Journal of Algorithms, 8:66-94, 1987.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[W. Tiller. Rational B-splines for curve and surface representation. IEEE Computer Graphics and Applications, 3, 1983.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357348</ref_obj_id>
				<ref_obj_pid>357346</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. B. Tor and A. E. Middleditch. Convex decomposition of simple polygons. ACM Transactions on Graphics, 3(4):244- 265, 1984.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807400</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[H. Voelcker, A. Requicha, E. Hartquist, W. Fisher, J. Metzger, R. Tilove, N. Birrell, W. Hunt, G. Armstrong, T. Check, R. Moote, and J. McSweeney. The PADL-1.0/2 system for defining and displaying solid objects. ACM Comput. Gr., 12(3):257-263, 1978.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[J. R. Woodwark and A. F. Wallis. Graphical input to a Boolean solid modeller. In CAD 82, pages 681-688, Brighton, U.K., 1982.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 An Efficient Algorithm for Finding the CSG Representation 
of a Simple Polygon* David Dobkin 1, Leonidas Guibas 2,3, John Hershberger 3, and Jack Snoeyink 2 1Princeton 
University, 2Stanford University, 3DEC Systems Research Center Abstract We consider the problem of converting 
boundary representations of polyhedral objects into constructive-solid-geometry (CSG) representations. 
The CSG representations for a polyhedron P are based on the half-spaces supporting the faces of P. For 
certain kinds of polyhedra this problem is equivalent to the correspond- ing problem for simple polygons 
in the plane. We give a new proof that the interior of each simple polygon can be represented by a monotone 
boolean formula based on the half-planes sup- porting the sides of the polygon and using each such half-plane 
only once. Our main contribution is an efficient and practical O(n log n) algorithm for doing this boundary-to-CSG 
conversion for a simple polygon of n sides. We also prove that such nice formulae do not always exist 
for general polyhedra in three di- mensions. CR Categories and Subject Descriptions: F.2.2 [Analysis 
of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems-Geometrical problems and 
computa- tions; Computations on discrete structures; 1.3.5 [Computer Graphics]: Computational Geometry 
and Object Modeling-Curve, surface, solid, and object representations; Geometric al- gorithms, languages, 
and systems General Terms: Algorithms, theory Additional Key Words and Phrases: Solid modeling, constructive 
solid geometry, boundary-to-CSG conversion algo- rithms, simple polygons *The first author would like 
to acknowledge the support of the National Science Foundation under Grant CCR87-00917. The fourth author 
was sup- ported in part by a National Science Foundation Graduate Fellowship. This work was begun while 
the first author was visiting the DEC Systems Re- search Center. Permission to copy without fee all or 
part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169;1988 AC M-0-89791-275-6/88/008/0031 
$00.75 1 Preliminaries One of the most important topics in solid modeling is the math- ematical representation 
of solid objects. It is desirable that such representations be compact and efficient in the simulation 
of the real-world operations that we may wish to perform on the ob- jects. Over the years two different 
styles of representation have emerged; these are used by nearly all geometric modeling sys- tems currently 
in existence. The first style of representation de- scribes an object by the collection of surface elements 
forming its boundary: this is a boundary representation. In effect, bound- ary representations reduce 
the solid modeling problem to that of representing surface elements. This is a somewhat simpler prob- 
lem, since we work in one dimension less. The second style of representation describes a solid object 
as being constructed by regularized boolean operations on some simple primitive solids, such as boxes, 
spheres, cylinders, etc. Such a description is re- ferred to as a constructive solid geometry representation, 
or CSG representation, for short. Each style of representation has its advantages and disadvantages, 
depending on the operations we wish to perform on the objects. The reader is referred to one of the standard 
texts in solid modeling [12, 15], or the review article [21] for further details on these representations 
and their relative merits. If one looks at modelers in either camp, for example the ROMU- LUS [15], GEOMOD 
[23], and MEDUSA [16] modelers of the bound- ary persuasion, or the PADL-1 [25], PAOLi2 [2], and GMSOLID 
[1] modelers of the CSG persuasion, one nearly always finds provi- sions for converting to the other 
representation. This is an impor- tant and indispensable step that poses some challenging compu- tationM 
problems 1. In this paper we will deal with certain cases of the boundary-to-CSG conversion problem and 
present some efficient computational techniques for doing the conversion. Peterson [19] considered the 
problem of obtaining a CSG rep- resentation for simple polyhedral solids, such as prisms or pyra- mids 
(not necessarily convex), based on the half-spaces support- ing the faces of the solid. Such solids are 
in effect two-dimensional objects (think of the base of the prism or pyramid) in which the third dimension 
has been added in a very simple manner. Thus Peterson considered the problem of finding CSG represen- 
tations for simple polygons in the plane; this problem is related to the problem of finding convex decompositions 
of simple poly- 1To quote from [21]: "..the relative paucity of known conversion algo- rithms poses significant 
constraints on the geometric modeling systems that we can build today." f SIGGRAPH '88, Atlanta, August 
1-5, 1988 gons [3, 17, 18, 24, 26]. By a complicated argument, Peterson proved that every simple polygon 
in the plane admits of a rep- resentation by a boolean formula based on the half-planes sup- porting 
its sides. This formula is especially nice in that it is monotone (no complementation is needed) and 
each of the sup- porting half-planes appears in the formula exactly once. We call such a formula a Peterson-style 
formula. In this paper we first give a short and elegant new proof that every polygon has a Peterson-style 
formula (Section 3). Peter-son did not explicitly consider algorithms for deriving this CSG representation 
from the polygon. A naive implementation based on his proof would require O(n 2) time for the conversion, 
where n is the' size (number of sides or vertices) of the polygon. We provide in this paper an efficient 
O(n log n) algorithm for doing this boundary-to-CSG conversion (Section 4). We regard this algorithm 
as the major contribution of our paper; the algorithm uses many interesting techniques from the growing 
field of com- putational geometry [4, 20]. Nevertheless, it is very simple to code--its subtlety lies 
in the analysis of the performance and not in the implementation. Finally (Section 5), we show that Peterson-style 
formul~e are not always possible for general poly- hedra in three dimensions and discuss a number of 
related issues. We believe that the work presented in this paper illustrates how several of the concepts 
and techniques of computational ge- ometry can be used to solve problems that are of clear impor- tance 
in solid modeling and computer graphics. The solution that we obtain is both mathematically interesting 
and practical to implement. We expect to see more such applications of com- putational geometry to other 
areas in the future and hope that this paper will motivate some researchers in the graphics area to study 
computational geometry techniques more closely. 2 Formulation and history of the problem Let P be a simple 
polygon in the plane; in this context, simple means non-self-intersectlng. By the Jordan curve theorem, 
such a polygon subdivides the plane into two regions, its interior and its exterior. In general, we identify 
the polygon with its interior. Let us orient all the edges of P so that the interior of P lies locally 
to the right of each edge, and give each such oriented edge a name. We will call these names literals. 
To each literal we also give a second meaning. A literal m also represents the half-plane bounded by 
the infinite line supporting the edge m and extending to the right of that line. We will speak of such 
a half-plane as supporting the ..... :,::::::i:~:~:~;~i~i~i~i::iiiili~i~i~;~i~ili~i~i~i~ii:i:i::::::.:.: 
.... polygon (even though P might not all liein the half-plane). See Figure 1 for an illustration of 
these concepts. Notice that, for each point x of the plane, if we know whether x lies inside or outside 
each of Figure 1: A simple polygon the half-planes supporting P, P and the half-plane sup-then we know 
in fact if x is in- porting side m side P. This follows, because each of the regions into which the plane 
is subdivided by the infinite extensions of the sides of P lies either wholly inside P, or wholly outside 
it. As a result, there must exist a boolean for- mula whose atoms are the literals of P and which expresses 
the 32 interior of P. For example, if P is convex, then this formula is simply the "and" of all the literals. 
 Since "and"s and "or"s are somewhat cumbersome to write, we will switch at this point to algebraic notation 
and use mul-tiplication conventions for "and" and addition conventions for "or". Consider the two simple 
polygons shown in Figure 2. For- mul~e for the two polygons axe uv(w(x + y) + z) for polygon (a) and 
uvw(x + y + z) for polygon (b). The associated boolean ex- pression trees axe also shown in Figure 2. 
Notice that these are Peterson-style formulae: they are monotone and use each literal exactly once. The 
reader is invited at this point to make sure that these formulm axe indeed correct. w u  (a) /\ + w 
  /\ - x y (b) u v w X y Z Figure 2: Formulae for two polygons A more complex formula for a simple 
polygon was given by Cuibas, Ramshaw, and Stolfi [8] in their kinetic framework pa- per. That style of 
formula for the two polygons of Figure 2 is u~ @ v~ ~ w~ @ ~y @ ~z z~. Here @ denotes logical "xor" 
and the overbar denotes complementation. As explained in [8], that type of formula is purely local, in 
that it depends only on the convex vs. concave property of successive angles of the polygon. The rule 
should be obvious from the example: as we go around, we complement the second literal corresponding to 
a vertex if we are at a convex angle, and the first literal if we are at a concave angle. Thus the formula 
is the same for both of the example polygons. Although a formula of this style is trivial to write down, 
it is not as desirable in solid modeling as a Peterson-style formula~ be- cause of the use of complementation 
and the "xor" operator. The Peterson formula is more involved to derive, because it captures in a sense 
how the polygon nests within itself and thus is more global in character. It can be viewed naively as 
an inclusion-exclusion style formula that reflects this global structure of the polygon. We caution the 
reader, however, that this view of the Peterson formula is too nai've and gave rise to a couple of flawed 
approaches to this problem. In general there are many boolean formulae that express a sim- ple polygon 
in terms of its literals. Proving the equivalence of two boolean formulae for the same polygon is a non-trivial 
exer- cise. The reason is that of the 2 '~ primitive "and" terms one can  ~i~ Computer Graphics, Volume 
22, Number 4, August 1988 form on n literals (with complementation allowed), only O(n ~) are non-zero, 
in the sense that they denote non-empty regions of the plane. Thus numerous identities hold and must 
be used in proving formula equivalence. The decomposition of a simple polygon into convex pieces [3, 
17, 18, 24, 26] gives another kind of boolean formula for the polygon, one in which the literals are 
not half-planes, but convex polygons. Depending on the type of decomposition desired, the convex polygons 
may or may not overlap; in the overlapping case, the formula may or may not contain negations. If we 
expand the literals in a convex decomposition into "and's of half-planes, the result need not be a Peterson-style 
formula: negations, repeated literals, and half-planes that do not support the polygon are all possible. 
If we leave the boolean domain and allow algebraic formulae for describing the characteristic function 
of a simple polygon, then such formul2e that are purely local (in the same sense as the above "xor" formula) 
are given in a paper of Franklin [5]. Franklin gives algebraic local formulze for polyhedra as well. 
We do not discuss this further here as it goes beyond the CSG representations we are concerned with. 
The existence of monotone formulae In this section we will prove that the interior of every simple polygon 
P in the plane can be expressed by a Peterson-style for- mu]a, that is, a monotone boolean formula in 
which each literal corresponding to a side of P appears exactly once. As it turns out, it is more natural 
to work with simple bi- infinite polygonal chains (or chains, for short) than with simple polygons. An 
example of a simple bi-infinite chain c is shown in Figure 3. Such a chain c is terminated by two semi-infinite 
rays and in between contains an arbitrary number of finite sides. Because it is simple and bi-infinite, 
it subdivides the plane into two regions. We will in general orient c in a consistent manner, so we can 
speak of the region of the plane lying to the left of c, or to the right of c, respectively. By abuse 
of language, we will refer to these regions as half-spaces. left ha/f-space Figure 3: A simple bi-infinite 
chain The interior of a simple polygon P can always be viewed as the intersection of two such chain half-spaces. 
Let l and r denote respectively the leftmost and rightmost vertex of P. As in Fig- ure 4, extend the 
sides of P incident to l infinitely far to the left, and the sides incident to r infinitely far to the 
right. It is clear that we thus obtain two simple bi-infinite chains and that the interior of P is the 
intersection of the half-space below the up- per chain with the hail-space above the lower chain. Notice 
also that the literais used by the upper and lower chains for these two half-spaces form a partition 
of the literals of P. Thus it suffices to prove that a chain half-space admits of a monotone formula 
using each of its literals exactly once. Figure 4: The interior of a simple polygon P We will prove this 
fact by showing that, for any chain c, there always exists a vertex v of c such that if we extend the 
edges incident to v infinitely far to the other side of v~ these extensions do not intersect c anywhere. 
In particular, the extensions cre- ate two new simple bi-infinite chains cl and c2 that, as before~ partition 
the literals used by c. See Figure 5 for an example. It is easy to see that the half-space to the right 
(say) of c is then either the intersection or the union of the half-spaces to the right of c x and c2. 
It will be the intersection if the angle of c at v in the selected half-space is convex (as is the situation 
in Figure 5), and the union if this angle is concave.  "%% '~ Figure 5: The splitting vertex v for a 
chain c The existence of the desired vertex v is relatively easy to es-tablish. Of the two half-spaces 
defined by e there is one that is bounded by the two semi-infinite rays in a "convex" fashion. What we 
mean by this is that when we look at this half-space from a great distance above the xy-plane (so we 
can only discern the semi-infinite rays bounding it) it appears as a convex angle (< ~-). For example, 
in Figure 5, the right half-space R of c is the convex one. If we now look at the convex hull h(R), this 
hull will be a polygon whose vertices are vertices of c. Clearly at least one such vertex has to exist, 
and any vertex on this hull is a good vertex at which to break c~ that is, it can serve as the vertex 
v of the previous argument. The reason is clear from Figure 6: at any such vertex the extensions of the 
sides incident upon it cannot intersect c again. It is worth remarking here that the determination of 
the split- ting vertex v in the above manner is not at all influenced by SIGGRAPH '88, Atlanta, August 
1-5, 1988 Figure 6: The convex hull h(R) whether we are are trying to obtain a boolean formula for the 
right half-space of c or the left half-space of c. The choice of which half-space to take the convex 
hull of is determined solely by the behavior of the seml-infinite rays of c. Indeed, if we were to choose 
the wrong ("concave") half-space, its convex hull would be the whole plane and would contain no vertices. 
We can sum- marize the situation by saying that we always split at a vertex of the convex hull of the 
polygonal chain c; this definition auto- matically selects the correct half-space. By recnrsively applying 
this decomposition procedure until each subchain becomes a single bi-infinite straight line we can conclude 
the following theorem. Theorem 3.1 Every half-space bounded by a simple bi-infinite polygonal chain has 
a monotone boolean formula using each of the llterals of the chain exactly once. The same holds for the 
interior of any finite simple polygon. If we are given a polygonal chain c, such as the one in Figure 
3, then certain aspects of the boolean formula of (say) the right half-space R of c can be immediately 
deduced by inspection. For example, it follows from the above arguments that there exists a boolean formula 
for R that not only uses each literal exactly once, but in fact contains these literals in the order 
in which they appear along c: if we were to omit the boolean operators and parentheses in the formula, 
we would just get a string of all the literals in c in order. Furthermore, the boolean operators between 
these literals are easy to deduce. As the previous discussion makes clear, between two literals that 
define a convex angle in R the corresponding operator has to be an "and", and between two literals that 
define a concave angle the corresponding operator has to be an "or". Thus, with parentheses omitted, 
the boolean formula for the chain c in Figure 3 has to look like a + bcde + f + gh + ij + kl + m. This 
shows that the crux of the difficulty in the boolean formula problem is to obtain the parenthesization, 
or equiva-lently, the sequence of the appropriate splitting vertices. We call this the recursive chain-splitting 
problem for a simple bi- infinite chain. The solution of this problem is the topic of the next section. 
For the chain of Figure 3 a valid solution is ((a + bc)(de + f) + g(h + i))(j + k(l + m)). We conclude 
by noticing that our procedure for solving this problem is non-deterministic, since in general we will 
have a choice of several splitting ver-tices. We can in fact simultane- ously split at any subset of 
them. Still, not all valid Peterson-style formalae for a simple polygon are obtained in this fashion. 
Our formulm all have the property Figure 7: Our methods can- that the ]iterals appear in the not obtain 
all valid formulae formula in the same order as in for this polygon the polygon. Figure 7 shows an example 
of a Peterson-style for- mula where that is not true: a valid formula for the polygon shown is (a + e)(d 
+ f)(g + 4) + beh. 4 The conversion algorithm We have seen in Section 3 that we can find a monotone boolean 
formula for a simple polygon if we can solve the following recur-sire chain-splitting problem: Given 
a simple bi-infinite polygonal chain with at least two edges, find a vertex z of its convex hull. Split 
the chain in two at z and extend to infinity the two edges incident to z, forming two new chains. Because 
z is on the convex hull, both chains are simple. Recnrsively solve the same problem for each chain that 
has at least two edges. This section presents an O(n log n) algorithm to solve the chain- splitting problem, 
where n is the number of vertices of the poly- gon P. The algorithm uses only simple data structures 
and is straightforward to implement. Before we describe our algorithm, let us consider a naive alter- 
native to it. Many algorithms have been published that find the convex hull of a simple polygon in linear 
time [6, 14, 10, 13, 22]. With slight modifications, any of these algorithms can be used to find a vertex 
on the hull of a simple bi-infinite polygonal chain. ]f we use such an algorithm to solve the recursive 
hull splitting problem, the running time is O(n) plus the time needed to solve the two subproblems recursively. 
The worst-case running time t(n) is given by the recurrence t(=) = m~ (t(k) + t(~ - k)) + o(~), O<k<rt 
which has solution t(n) = O(n2).   ~~ ~ Computer Graphics, Volume 22, Number 4, August 1988 This quadratic 
behavior occurs in the worst case, shown in Figure 8a, because each recursive step spends linear time 
splitting a single edge off the end of the path. In the best case, on the other hand, each split divides 
the current path roughly in half, and the algorithm runs in O(n log n) time. This asymptotic behavior 
can be obtained for the path shown in Fig- 09 ure 8b, if the splitting vertices axe chosen Figure 8: 
Paths wisely. with worst-and The best case of tb~s n~ive algorithm best-case splitting is like a standard 
divide-and-conquer ap- behavior proach: at each step the algorithm splits the current path roughly in 
half. In general, however, it is diffi- cult to guarantee an even division, since all vertices on the 
convex huh might be extremely close to the two ends of the path. Thus, to avoid quadratic behavior, we 
must instead split each path us-ing less than linear time. Other researchers have solved similar problems 
by making the splitting cost depend only on the size of the smaller fragment [7, 9]. If the running time 
~(n) obeys the recurrence t(n) = max (t(k ) + t(n -k)) + O(min(k, n -k)), 0<k<n then t(n) = O(nlogn). 
Our method uses a similar idea: the splitting cost is O(log n) plus a term that is linear in the size 
of one of the two fragments. The fragment is not necessarily the smaller of the two, but we can bound 
its size so as to ensure an O(n log n) running time overall. The details of this argument appear in Section 
4.5. We present our algorithm in several steps. We first make a few definitions, then give an overview 
of our approach. We fol- low the informal overview with a pseudo-code description of the algorithm. Section 
4.3 gives more detail on one of the pseudo- code operations, and Section 4.4 describes the data structure 
used by the algorithm. Section 4.5 concludes the presentation of the algorithm by analyzing its running 
time. 4.1 Definitions As shown in Section 3, we can find a boolean formula for P by splitting the polygon 
at its leftmost and rightmost vertices to get two paths, then working on the two paths separately. We 
denote by ~r the current path, either upper or lower. If u and v are vertices of r, we use the notation 
r(u,v) to refer to the subpath of r between u and v, inclusive. The convex hull of a set of points A 
is denoted by h(A); we use h(u,v) as shorthand for h(~(u,v)). A path ~r(u,v) has I~'(u,v)l edges; similarly, 
Ih(u,v)l is the number of edges on h(u, v). We can use the path ~-(u, v) to specify a bi-infinite chain 
by extending its first and last edges. Let eu be the edge of ~r(u, v) incident to u, and let ~ be the 
ray obtained by extending e~ beyond u. Let e, and ~ be defined similarly. Then ~-(u,v) specifies the 
bi-infinite polygonal chain obtained by replacing e= by ~ and ev by ~. In generM, for arbitrary u and 
v, this bi- infinite chain need not be simple. Our algorithm, however, will guarantee the simplicity 
of each bi-infinite chain it considers. We assume in what follows that ~ and ~ are not parallel, but 
only slight modifications to the algorithm are needed if this is not true.  4.2 The algorithm This section 
presents the algorithm that recnrsively splits a polygonal chain. We first outline the algorithm and 
then present it in a pseudo-code format. Subsequent sections give the details of the operations sketched 
in this section. We now outline the algorithm. Given a polygonal path 7r(u, v) with at least two edges, 
we partition it at a vertex x to get two pieces r(u, x) and ~r(x, v) with roughly the same number of 
edges. Note that z is not necessarily a vertex of h(u,v); this partitioning is merely preparatory to 
splitting ~r(u,v) at a hull vertex. In O(l~r(u,v)l ) time we compute the convex hulls of r(u,x) and ~r(x,v) 
in such a way that for any vertex z of 7r(u,v), we can easily find h(x,z). Our data structure lets us 
account for the cost of finding h(x, z) as part of the cost of building h(u, x) and h(x, v). The details 
of this accounting appear in Section 4.5. The next step of the algorithm locates a vertex z of the convex 
hull of the bi-infinite chain ~r(u, v) U ~ U ~. We will split v(u, v) at z. The vertex z can be on the 
path ~-(u,z) or on the path lr(x,v). Without loss of generality let us assume that z is a vertex of ~r(u,x); 
note that z cannot be u. We reeursively split a'(u,z), partitioning it at its midpoint, building convex 
hulls, and so on. However, and this is the key observation, we do not have to do as much work for re(z, 
v) if z ~ x. We already have the hull h(x,v), and we can easily find h(z,x) from our data structure for 
h(u, x). Thus we can recursively split ~r(z, v) without recomputing convex hulls. Intuitively speaking, 
we do a full recursion (including convex hull computation) only on pieces whose length is less than half 
the length of the piece for which we last computed convex hulls. The key to our algorithm's efficiency 
is avoiding the recom-putation of convex hulls. The naive algorithm builds O(n) hulls whose average size 
can be as much as n/2; our algorithm also builds O(n) hulls, but their average size is only O(logn). 
Our al- gorithm locates n splitting vertices in O(log n) time apiece, which contributes another O(nlog 
n) term to the running time. These two terms dominate the time cost of the algorithm, as Section 4.5 
SHOWS. We present the algorithm more formally in the pseudo-code below. The pseudo-code uses a data structure 
called the path hull~ PH(x,v), to represent the convex hull of the path 7r(x, v). This structure stores 
the vertices of h(z,v) in a linear array. The path hull PH(x,v) is used to produce PH(x,z) efficiently, 
for any splitting vertex z in ~r(x,v). The algorit~lm consists of two mutually recursive subroutines, 
.f0 and P0, whose names stand for full and partial. The routine f(u,v) partitions ~r(u, v) at x to get 
two equal parts, builds a path hull structure for each, and calls p( u, x, v ). The subroutine p( u, 
x, v) uses PH ( x, u) and PH(z,v) to find the splitting vertex z; Section 4.3 gives the details of this 
operation. The routine then splits ~r(u, v) at z and recurses on each fragment; it ensures that the required 
path hulls have been built whenever P0 is called. We start the algorithm by invoking f0 on the entire 
path n. f(u,~) /* Precondition: u ~ v */  begin 1. if ~r(u, v) is a single edge then return; else begin 
 2, Let x be the middle vertex of r(u, v); 3. Build PH(x, u) and PH(x, v); 4. p(u, =, ~); end end p(u,x,v) 
/* x is a vertex of ~r(u, v), not equal to u or v. Path hulls PH(x, v) and PH(x, u) have been computed. 
*/ begin 5. Find a vertex z of h(Tr(u, v) U ~ U ~), the convex hull of the bi-infinite chain specified 
by ~r(u, v); 6: ifx = z then begin f(u,x); f(x,v); end else begin 7. Build PH(~, z) from PH(x, u) or 
PH(x, v), as appropriate; ifz is a vertex of ~r(u,x) then 8. begin f(u, z); p(z,x,v);end  else 9. beginp(u,x,z); 
](z,v);end end end The chain-splitting algorithm 4.3 Finding a splitting vertex This section shows 
how to use the path hull data structure to find the splitting vertex z. Our method exploits the fact 
that PH(x,v) represents h(x,v) as a linear array of convex hull ver- tices: we perform binary seaxch 
on the array to find the splitting vertex. Given a path ~r(u, v), we want to find a vertex of the convex 
hull of the bi-infinite chain that w(u,v) specifies. Each such vertex belongs to the finite convex hull 
h(u, v); we solve our problem by finding a vertex of h(u, v) that is guaranteed to belong to the infinite 
hull. The edges of the infinite hull h(r(u, v)U~U~) have slopes in a range bounded by the slopes of ~ 
and ~. Vertices of the hull have tangent slopes in the same range. We simply find a vertex of h(u, v) 
with a tangent slope in the range. Let du and dv be the direction vectors of the rays ~ and ~. Because 
e--: and ~ are not parallel, d~ and d, define an angular range of less than 180 degrees; define d to 
be the negative of the bisector of this angular range. An extreme vertex of h(u~ v) in direction d is 
guaranteed to be a vertex of the infinite hull. 2 See Figure 9 2To avoid computing square roots, in practice 
we do not compute the bisector of the angle defined by d~ and d~. lnstead~ we find the normals to for 
an example. 0 u 0 V Figure 9: We find an extremal vertex in the direction d We use binary search on each 
of the two path hulls PH(u, x) and PH(x, v) to find an extreme vertex in direction d. We com- pare the 
two vertices and pick the more extreme of the two. If we break ties consistently in the binary searches 
and in the com- parison of the two extreme vertices (say, by preferring the left vertex of tied pairs), 
the vertex we find is guaranteed to be a vertex of the infinite hull.  4.4 Implementing path hulls In 
this section we describe the path hull data structure used in the previous two sections. The path hull 
PH(x, v) represents the convex hull of ~r(x, v). It is not symmetric in its arguments: it implicitly 
represents h(x, v') for all vertices v' in 7r(x, v), but does not represent h(v I,v) for any v p not 
equal to x. The structure PH(x, v) has three essential properties: 1. PH(x, v) represents h(x,v) by alinear 
array of vertices. Let be the vertex of h(x,v) closest to v on 7c(x,v). Then the array lists the vertices 
of h(x, v) in clockwise order, starting and ending with 9. 2. Given fill(x, v), we cain transform it 
into PH(x, v') for any vertex v' in 7r(x, v), destroying PH(x, v) in the process. Let the vertices of 
lr(v,x) be numbered v = vt,v2,...,v~ = x; we can successively transform fH(x,v) into PH(x, v~) for each 
vi in sequence from Vl = v to vk = x in totM time proportional to lTr(x, v)l. 3. PH(x,v) can be built 
from 7r(x,v) in O(br(x,v)l) time.  We get these properties by adapting Melkman's algorithm for finding 
the convex hull of a polygonal path [14]. We satisfy re- quirement 2 by "recording" the actions of Melkman's 
algorithm as it constructs h(x, v), then "playing the tape backwards." Many linear-time algorithms have 
been proposed to find the convex hull of a simple polygon [6, 14, 10, 13~ 22]. Some of these algorithms 
need to find a vertex on the hull to get started; we use Melkman's algorithm because it does not have 
this require- ment. It constructs the hull of a polygonal path incrementally: it processes path vertices 
in order, and at each step it builds the hull of the vertices seen so far. The algorithm keeps the vertices 
of the current convex hull in a double-ended queue, or deque. The deque lists the hull ver-tices in clockwise 
order, with the most recently added hull ver- tex at both ends of the deque. Let the vertices in the 
deque be v~,vb+t,... ,v~-t,vt, where vb = vt. The algorithm operates on the deque with push and pop operations 
that specify the end of du and d~ that point away from the infinite hull, then add the two to get a direction 
d strictly between these normals.  ~' Computer Graphics, Volume 22, Number 4, August 1988 the queue, 
bottom or top, on which they operate. The algorithm appears below; it assumes that no three of the points 
it tests are collinear, though this restriction is easy to lift. Get the first three vertices of the 
path with the func- tion Next Vertex() and put them into the deque in the correct order. while v ~ NextVertex 
0 returns a new vertex do if v is outside the angle Zvt-lvtvb+l then begin while v is left of vbv~+l 
do pop(vb, bottom); while v is left of vt-~t do pop(v~, top); push(v, bottom); push(v, top); end Melkman's 
convex hull algorithm We now sketch a proof of correctness; for a full proof see [14]. We first con- 
sider the case in which v is discarded. !i!i!i!i!i!i!~ This happens when v is inside the an-gle Zv~-lvtvb+l. 
(See Figure 10.) We iiiiiiiiill know that Vb+l is connected to we-1 by a polygonal path, and that v is 
con-nected to vb by a polygonal path. The two paths do not intersect, so v must lie inside the current 
hull. When v is Figure 10: Discard v not discarded, it lies outside the cur- if it lies in the shaded 
rent hull, and the algorithm pops hull sector vertices until it gets to the endpoints of the tangents 
from v to the current hull. The algorithm is linear: if it operates on a path with n vertices, it does 
at most 2n pushes and 2n -3 pops. We can use the algorithm to build an array representation of the hull. 
The algorithm does at most n pushes at either end of the deque, so we can implement the deque as the 
middle part of an array of size 2n. Pushes and pops increment and decrement the array indices of the 
ends of the queue; pushes write in a new element, pops read one out. The resulting deque contains the 
vertices of the convex hull in a contiguous chunk of an array. The algorithm described so far satisfies 
requirements 1 and 3; how can we use it to satisfy requirement 2? When the algorithm builds h(x,v) starting 
from x and working toward v, at inter- mediate steps it produces h(x, v') for every vertex v r in rr(x, 
v). We need to be able to reconstruct these intermediate results. To do this, we add code to the algorithm 
to create a transcript of all the operations performed, recording what vertices are pushed and popped 
at each step. The structure PH(x,v) stores not only the deque that represents h(x,v), but also the transcript 
of the operations needed to create the deque from scratch. To reconstruct PH(x,v') from PH(x,v), we read 
the transcript in reverse order, performing the inverse of each recorded operation (pushing what was 
popped, and vice versa), until the deqne rep- resents h(x,v'). We throw away the part of the transcript 
we have just read, so that PH(x, v I) stores only the transcript of the operations needed to create h(x,vr). 
Because we discard every step we have read over, we look at each step of the transcript at most once 
during the playback. Therefore, reconstructing the intermediate results takes time proportional to the 
original cost of finding PH(x,v). This completes the proof that the path hull data structure satisfies 
all three of its requirements. 4.5 Analyzing the running time In this section we analyze the running 
time of the chain-splitting algorithm. The analysis uses a "credit" scheme, in which each call to f() 
or P0 is given some number of credits to pay for the time used iu its body and its reeursive calls. We 
give O(n log n) credits to the first call to f0, then show that all calls have enough credits to pay 
for their own work and that of their recursive calls. We begin the analysis by proving that f0 and p() 
are called O(n) times: Every call to p(u,x, v) splits ~r(u, v) into two non- trivial subpaths, and every 
call to f(u, v) for which 7r(u, v) has more than one edge passes r(u,v) on to p(). The initial path ~r 
can only be split O(n) times, so the recursion must have O(n) calls altogether. How much work is done 
by a call to f(u, v), exclusive of re- cursive calls? We assume that the vertices of re are stored in 
an array. Therefore line 2 of ]() takes only constant time. Line 3 is the only step of f0 that takes 
non-constant time; as shown in Section 4.4, line 3 takes O(llr(u,v)l) time. We define the value of a 
credit by saying that a call f(u,v) needs ]Tr(u,v)] credits--one credit per edge of 7r(u,v)--to pay for 
the work it does, exclusive of its call to p(). The constant-time steps in f0 take O(n) time altogether 
and hence are dominated by the rest of the running time. A call to p(u,x,v) does accountable work in 
lines 5 and 7. The cost of line 5 is dominated by two binary searches, which take O(log n) time. Line 
5 therefore takes O(nlog n) time over the whole course of the algorithm. Section 4.4 shows that the cost 
of building PH(x,z) at line 7 can be accounted as part of the construction cost of the path hull from 
which PH(x,z) is derived. Thus we can ignore the work done at line 7 of p(); its cost is dominated by 
that of llne 3 of f0- To complete our analysis of the running time, we must bound the cost of all executions 
of line 3 of f0- In a single call to I(~, v), line 3 nses I~(u, .)p credits. The sum of an credits used 
by line 3 is proportional to the time spent executing that line. We give n[log 2 n] credits to the first 
call to f0, then show that this is enough to pay for all executions of line 3. We use the following two 
invariants in the proof: i. A call to f(u, v) is given at least mrlog s m] credits, where rn = [rr(u,v)[, 
to pay for itself and its recursive calls. 2. A call to p(u,x,v) is given at least (I + r)[log2 max(l,r)] 
credits, where l = ]rr(u,x)l and r = Iw(x,v)[, to pay for its recursive calls. Lemma 4.1 If a call to 
fO or PO is given credits in accordance with invariants I and 2, it can pay for all executions of line 
3 it does explicitly or in its recursive calls. Proof: Let m, l, and r be as defined above. The proof 
is by induction on m. A call to f(u,v) with m --1 gets no credits and needs none, since it does not reach 
line 3. There are no calls to P0 with rn = 1.  SIGGRAPH '88, Atlanta, August 1-5, 1988 A call to f(u,v) 
with m > 1 gets at least rn~log2 m ] credits and spends m of them executing line 3. It has m~og2(m/2)] 
to pass on to its call to p(u,x,v). The larger of l and r is [m/2], and [log2(m/2)] = [log2 rm/2]], so 
the call to p(u,x,v) gets at least m[log~(m/2)] = (z + ~)Vlog:max(Z,r)] credits, as re-quired by invaxiant 
2. A call to p(u, x, v) splits ~r(u, v) into two paths ~r(u, z) and 7r(z, v) with a and b edges, respectively. 
The call to p(u,x,v) divides its credits between its recursive calls evenly according to subpath size. 
If z = x, then the two calls to f0 get at least l[log 2 max(l, r)] > lWlog 2 l] and r~log2ma~x(l,v)] 
_> r~log2 r] credits, satisfying in- variant 1. If z ¢ x, then without loss of generality assume that 
z belongs to 7r(u,x) and line 8 is exe-cuted; the other case is symmetric. The cal_[ to f(u, z) gets 
at least a[log~ max(l, r)] > a[log 2 a], as required. The call to p(z,x,v) gets at least b[log2max(l,r)] 
> brlog 2 max(b- r,r)], as required by invaxiant 2. This completes the proofi | Altogether the calls 
to f0 and p() take O(nlog n) time, plus the time spent building path hulls at line 3. The preceding lemma 
shows that all the executions of line 3 take only O(nlog n) time, and hence the entire algorithm runs 
in O(nlog n) time. 4.6 Implementation The algorithm described in this section has been implemented. The 
implementation is more general than the algorithm we have so fax described: it correctly handles the 
cases of collinear ver- tices on convex hulls and parallel rays on bi-infinite chains. These improvements 
are not difficult. Handling collineax vertices re-quires two changes: the program detects and merges 
consecu-tive co]linear polygon edges, reporting them to the user, and the while loop tests in Melkman~s 
algorithm are changed from "v is left of" to "v is on or to the left of the line supporting." When a 
chain has parallel infinite rays, the direction d (see Section 4.3) is perpendicular to the rays, and 
the program needs a special case to avoid selecting u or v as the splitting vertex. As input the pro- 
gram takes a list of polygon vertices in order (either clockwise or counterclockwise), specified as x-y 
coordinate pairs. As output the program produces a list of the splitting vertices in the order they are 
computed, as well as a correctly parenthesized boolean formula for the input polygon. When the program 
is applied to the polygon shown in Fig- ure 11, it produces the following (slightly abbreviated) output: 
main: Calling f() on 8..17 p: splitting at vertex 16, 15, 9, i0, 13, II, 12, 14 main: Calling f() on 
17..25, 0..8 p: splitting at vertex 18, 19, 20, O, 25, 24, 21, 22, 23, 7, 1, 6, 5, 2, 3, 4 Boolean 
formula is: (8 * 9 * (10 * (li + 12) + 13 * 14) + 15) * 16 * 17 * 18 * 19 * (20 * (21 + 22 * 23) + 24 
+ 25 + (0 + (1 ÷ 2 + 3 * 4) * S * 6) * 7) 16 10 1 11 13 2 17 19 Figure 11: Sample prograxa input, displayed 
as a polygon In this formula, the number i refers to the edge joining vertex i to vertex (i + l) mod 
n; here n is 26.  5 Formulae for polyhedra We have shown that the interior of a simple polygon can be 
represented by a Peterson-style formula: a monotone boolean formula that uses each literal once. We would 
like to find such a formula for a polyhedron P in space. Here, the literals are half-spaces bounded by 
the planes supporting the faces. In this section we will prove that not all polyhedra have a Peterson-style 
formula. Figure 12 illustrates a simplicial poly- hedron (each face is a triangle) with eight vertices 
and twelve faces. Six of the faces are labeled; the six unlabeled faces lle on the convex hull of P. 
The edge between C and C' is a convex angle. The half-spaces defined by faces A and B intersect the faces 
A' and _B r. Similarly, the half-spaces A' and B r intersect faces A and B. After we establish a couple 
of lemmas, we will prove that P has no Peterson-style formula by assuming that it has one and deriving 
a contradiction. We begin by observing that any collection of planes divides space into several convex 
regions. (In the mathematical liter- ature, this division is usually called an arrangement [4].) If a 
polyhedron P has a CSG representation in terms of half-spaces, then we can specify a subset of the planes 
bounding these half- spaces and derive a representation for the portion of P inside any convex region 
determined by the subset. More precisely, let f be a boolean formula on the half-spaces of P; we can 
think of f as an expression tree. If the tree for f has nodes a and b, then we will denote the least 
common ancestor of a and b in f by Iea/(a,b). Let H1;H2,...,Hn be a subset of the half-spaces of P. Each 
point in space can be assigned a string a C {0,1} '~ such that the i-th character of a is 1 if and only 
if the point is in half-space Hi. All the points assigned the string a are said to be in the region Ra. 
We use f]a to denote the formula obtained by setting each Hi = al in f and simplifying the result by 
using algebraic rules: al = la = a, a0 = 0a = 0, a+ 1 = l+a = 1, and a+0 = 0+a--a. The expression tree 
for f]~ inherits several important properties from the expression tree for f: ~  Figure 12: Two views 
of a simplicial polyhedron with no Peterson-style formula Lemma 5.1 Let f be a formula that uses the 
half-spaces H1,H2 .... ,Hn (and perhaps others) and let ~ be a string in {0,1} n. Then the derived formula 
f[= has the following three properties: 1. if f is monotone or Peterson-style, then so is fl~, 2. if 
the expression tree for ftc~ has nodes a, b, and c, with c = lca/l~(a,b), then c = lcal(a,b) in the tree 
for f, and 3. if the expression tree for f[~ contains a node a at depth k, then the tree for f contains 
the node a at depth > k.  Proof: All three properties are maintained by the rules that form the expression 
tree for fin by simplifying the expression tree for f. | The next lemma shows the interaction between 
the region R~ and boolean formulae fla. Lemma 5.2 If a polyhedron P has a formula f that uses half-spaces 
H1,H2,...,H~ {and others) then, for any string c~ E {0~ 1} =, the portion of P inside the region Roe 
is described by the formula fief. Proof: The above statement simply says that formulae f and f[o agree 
inside the region R~. This follows from the definition of f]= and the fact that the simplification rules 
do not change the value of the formula. | Two corollaries of Lemma 5.2 give us constraints on the for- 
mula of a polyhedron based on its edges and faces. In these corollaries and the discussion that follows, 
we will add an argu-ment to a formula rio to emphasize which half-spaces are not fixed by the string 
a. Computer Graphics, Volume 22, Number 4, August 1988 Corollary 5.3 Let P be a polyhedron with Peterson-style 
for-mula f . If faces A and B of P meet at an edge, the operator in f that is the least common ancestor 
of A and B, lca/(A,B), is an "and" if and only if A and B meet in a convez angle. Proof: Let Hi,H2,... 
,Hn be the half-spaces of P ex-cept for the two defined by A and B. Choose a point on the edge formed 
by faces A and B, and let a be its string. The two-variable formula f[a(AB) must de- scribe the edge, 
so by Lemma 5.1(2), leaf(A, B) is an "and" if and only if A and B meet in a convex angle. | Corollary 
5.4 Let P be a polyhedron with Peterson-style for-mula f using half-spaces Ha,H2,... ,H,~ and A and B. 
If the half-space defined by face B intersects face A at some point with string a then f]~(AB) = A. Proof: 
The two-variable formula f[a(AB) must de- scribe the face A both inside and outside the half-space of 
B, so B cannot appear in the formula. | Now we are ready to look at the polyhedron P in Figure 12. Suppose 
P has a Peterson-style formula f. Then it has a for- mula flllllll(ABCA'BtC ~) that describes the region 
inside the unlabeled faces. We will look at the constraints on this formula and derive a contradiction. 
Consider the three fmces A, B, and C. By Corollary 5.3 we know that lca(B,C) = "or" and lca(A,B) = "and". 
Corol-lary 5.4 applied to faces A and C implies that the formula de- scribing these three faces is f[ol(aBC) 
= A(B + C), (1) where the string ~I appropriately fixes ~ the half-spaces except A, B, and C. Similarly, 
the formula describing A', B', and C' is fl~z(A'BIC ') = A'(B' + C'). (2) Now consider the region inside 
all unlabeled hail-spaces and outside C and C ~. The portion of P within this region can be described 
by a Karnaugh map [11]: AB O0 0 0 1 0 AIB t 011 0 0 1 0 11! 1 1 ? 1 10 I 0 0 1 0 The ~7' appears because 
four planes cut space into only fifteen regions; since we want a monotone formula, Lemma 5.1(1) forces 
us to make it a 'l'. Examining all Peterson-style formulae on A, B, A ~, and B I reveals that the only 
formula with the above map is f[a3(ABAtB') = (AB) + (A'B'). (3) In order to combine the formulae 1, 2, 
and 3 into a single formula on six variables, we must determine which operators are repeated in the three 
formulae. We knew from formulae 1 and 2 that the operators leaf(A, B) and leay(A', B') were both "and"s--now 
we know that they are distinct "and"s because lca/(lcay(A, B),lca](A', B')) = "or" in formula 3. The 
"or"s of the first two formulae are distinct because they are descendents of distinct "and"s. Finally, 
by Lemma 5.1(3), the "or" of for- mula 3 is different from the other "or's because it is not nested as 
deeply as the "amd"s. Thus, all five operators of the formula on the six labeled hath spaces appear in 
the formulm 1, 2, and 3. Using the nesting depth of the operators, we know that the formula looks like 
([]([] + D)) 4- ([](D 4- i~)). Filling in the half-space names gives the formula for the portion of P 
inside the unlabeled faces: f[lllHi(ABCA'B'C') = ( A(B + C)) 4- (A'(B' + C')). Notice, however, that 
in this formula the lea of C and C ~ is an "or". Thus lcal(C,C I) = "or". But this contradicts Corol-lary 
5.3, so the above formula cannot represent the portion of P inside the convex hull of P. This contradiction 
proves that P has no Peterson-style formula. There are two natural questions that we will leave open. 
First, can the interior of a polyhedron with n faces be ~epresented by a formula using O(n) literals? 
The trivial upper bound on the size of a formula is O(n3). In fact, the interiors of any set of cells 
formed by a collection of n planes can be described by a formula that represents each convex cell as 
the "and" of its bounding planes and "or"s the ceil representations together. The size of the formula 
is at worst the total number of sides of the cells formed by n planes, which is known to be O(n 3) [4]. 
Second, can we characterize polyhedra that can be represented by Peterson-style formulae? Peterson [19] 
showed that the rep- resentation of polygons gives such formulae for extrusions and pyramids. We would 
like to extend this class. References [1] J. Boyse and J. Gilehrist. GMSolid: interactive modeling for 
design and analysis of solids. IEEE Computer Graphics and Applications, 2:86-97, 1982. [2] C. Brown. 
PADL-2: a technical summary. IEEE Computer Graphics and Applications, 2:69-84, 1982. [3] B. M. Chazelle. 
Computational Geometry and Convexity. Technical Report CMU-CS-80-150, Carnegie-Mellon Uni-versity, Department 
of Computer Science, Pittsburgh, PA, 1980. [4] H. Edelsbrunner. Algorithms in Combinatorial Geometry. 
Volume 10 of EATCS Monographs on Theoretical Computer Science, Springer-Verlag, 1987. [5] W. Franklin. 
Polygon properties calculated from the vertex neighborhoods. In Proceedings of the 3rd A CM Symposium 
on Computational Geometry, pages 110-118, ACM, June 1987. [6] R. L. Graham and F. F. Yao. Finding the 
convex hull of a simple polygon. Journal of Algorithms, 4:324-331, 1983. [7] L. Guibas, J. Hershberger, 
D. Leven, M. Sharir, and R. Tar- jan. Linear time algorithms for visibility and shortest path problems 
inside tria~agulated simple polygons. Algorithmica, 2:209-233, 1987. [8] L. Guibas, L. Ramshaw, and J. 
Stolfi. A kinetic frame-work for computational geometry. In Proceedings of the 24 th Annual IEEE Symposium 
on Foundations of Computer Sci- ence, pages 100-111, IEEE, 1983. [9] K. Hoffmann, K. Mehlhorn, P. Rosenstiehl, 
and R. E. Tar- jan. Sorting Jordan sequences in linear time. In Proceed-ings of the A CM Symposium on 
Computational Geometry, pages 196-203, ACM, 1985. [10] D. T. Lee. On finding the convex hull of a simple 
polygon. [nternat. J. Comput. Inform. Sci., 12:87-98, 1983. [11] M. M. Mano. Digital Logic and Computer 
D.esign. Prentice-Hall, 1979. [12] M. M~ntyl£. An Introduction to Solid Modeling. Computer Science Press, 
1987. [13] D. McCailum and D. Avis. A linear algorithm for finding the convex hull of a simple polygon. 
Information Processing Letters, 9:201-206, 1979. [14] A. Melkman. On-line construction of the convex 
hun of a simple polyline. Information Processing Letters, 25:11-12, 1987. [15] M. Mortenson. Geometric 
Modeling. John Wiley &#38; Sons, 1985. [16] R. Newell. Solid modelling and parametric design in the Medusa 
system. In Computer Graphics '82, Proceedings of the Online Conference, pages 223-235, 1982. [17] J. 
O'Rourke. Art Gallery Theorems and Algorithms. Oxford University Press, 1987. [18] T. Pavlidis. Analysis 
of set patterns. Pattern Recognition, 1:165-178, 1968. [19] D. Peterson. Hal fspace Representation o] 
Extrusions, Solids of Revolution, and Pyramids. SANDIA Report SAND84-0572, Sandia National Laboratories, 
1984. [20] F. P. Preparata and M. I. Shamos. Computational Geome-try. Springer Verlag, New York, 1985. 
[21] A. Requicha. Representations for rigid solids: theory, meth- ods, and systems. ACM Computing Surveys, 
12:437-464, 1980. [22] A. A. Sch~i.ffer and C. J. Van Wyk. Convex hulls of piecewise- smooth Jordan curves. 
Journal of Algorithms, 8:66-94, 1987. [23] W. Tiller. Rational B-splines for curve and surface repre- 
sentation. IEEE Computer Graphics and Applications, 3, 1983. [24] S. B. Tor and A. E. Middleditch. Convex 
decomposition of simple polygons. A CM Transactions on Graphics, 3(4):244-265, 1984. [25] H. Voelcker, 
A. Requicha, E. Hartquist, W. Fisher, J. Met- zger, R. Tilove, N. Birrell, W. Hunt~ G. Armstrong, T. 
Check, R. Moote, and J. McSweeney. The PADL-1.0/2 sys- tem for defining and displaying solid objects. 
ACM Comput. Gr., 12(3):257-263, 1978. [26] J. R. Woodwark and A. F. Wallis. Graphical input to a Boolean 
solid modeller. In CAD 82, pages 681-688, Brighton, U.K., 1982.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378474</article_id>
		<sort_key>41</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Subanosecond pixel rendering with million transistor chips]]></title>
		<page_from>41</page_from>
		<page_to>49</page_to>
		<doi_number>10.1145/54852.378474</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378474</url>
		<abstract>
			<par><![CDATA[The desire for higher performance and higher resolution continuously increases the pixel update rates needed in high performance graphics systems. The increasing density of memory chips on the other hand reduces the pixel update rate that can be provided by the frame buffer. We present the design of a VLSI chip and a graphics system that can sustain sub-nanosecond pixel rendering rates for three-dimensional polygons and can be used to render about a million Z-Buffered and Gourard shaded polygons per second. The chip has been designed at the IBM Research Division's Thomas J. Watson Research Center.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>C.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010633</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010633.10010659</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design->VLSI system specification and constraints</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39052421</person_id>
				<author_profile_id><![CDATA[81100648858]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nader]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gharachorloo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31023759</person_id>
				<author_profile_id><![CDATA[81332502486]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Satish]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334732</person_id>
				<author_profile_id><![CDATA[81100009062]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Erden]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hokenek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335039</person_id>
				<author_profile_id><![CDATA[81100342663]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peruvemba]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Balasubramanian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334620</person_id>
				<author_profile_id><![CDATA[81100214072]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bogholtz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP33023665</person_id>
				<author_profile_id><![CDATA[81543507756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mathieu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334664</person_id>
				<author_profile_id><![CDATA[81100579647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zoulas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Demetrescu. High Speed Image Rastcrization Using Scan Line Access Memories. Proc. 1985 Chapel Hill Conference on VLSI, pages 221-243, Computer Science Press, 1985.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs and J. Poulton. Pixel Planes: A VLSl-Oriented Design for a Raster Graphics Engine. VLSI Design, 2(3):20-28, 3rd. Quarter 1981.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Garcia. ACE: A High Performance Multiprocessor Workstation, IBM Internal Communication, IBM Thomas J. Watson Research Center, 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>912314</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Gharachorloo. Super Buffer: A systolic VLSI Graphics Engine for Real Time Raster Image Generation, Ph.D. Thesis, Electrical Engineering Department, Cornell Univ., Ithaca, NY. August 1985.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Gharachorloo, S. Gupta, E. Hokenek, P. Balasubramanian, W. Bogholtz, C. Mathieu, and C. Zoulas. A Million Transistor Systolic Array Graphics Engine. Proceedings of International Conference on Systolic Arrays, San Diego, May 1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[N. Gharachorloo and C. Pottle. SUPER BUFFER: A Systolic VLSI Graphics Engine for Real Time Raster Image Generation. Proc. 1985 Chapel Hill Conference on VLSI, pages 285-305, Computer Science Press, 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807486</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J.H. Jackson. Dynamic Scan-converted images with a Frame Buffer Display Device. Computer Graphics, 14(3):163-169, July 1980.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bart Locanthi. Object Oriented Raster Displays. Proceedings of Caltech Conference on VLSI, pages 215-225, January 1979.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A.J. Myers. An Efficient Visible Surface Program, Ohio State University, Report to the NSF, July 1975.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808580</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Niimi, Y. Imai, M. Murakami, S. Tomita, and H. Hagiwara. A Parallel Processor System for Three Dimensional Color Graphics. Computer Graphics, 18(3):67-76, July 1984.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R.W. Swanson and L.J. Thayer. A Fast Shaded- Polygon Renderer. Computer Graphics, 20(4):95-101, August 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G.S. Watkins. A Real Time Visible Surface Algorithm, University of Utah, Computer Science Department, June 1970.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806789</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Richard Weinberg. Parallel Processing Image Synthesis and Anti-Aliasing. Computer Graphics, 15(3):55-61, August 1981.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801274</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Daniel S. Whelan. A Rectangular Area Filling Display System Architecture. Computer Graphics, 16(3):147-153, July 1982.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Subnanosecond Pixel Rendering with Million Transistor Chips Nader Gharachorloo, Satish Gupta, Erdem 
Hokenek, Peruvemba Balasubramanian, Bill Bogholtz, Christian Mathieu, Christos Zoulas IBM Research Division 
Thomas J. Watson Research Center Yorktown Heights, NY 10598 Phone: (914) 789-7100  Abstract The desire 
for higher performance and higher resolution continuously increases the pixel update rates needed in 
high performance graphics systems. The increasing den-sity of memory chips on the other hand reduces 
the pixel update rate that can be provided by the frame buffer. We present the design of of a VLSI chip 
and a graphics system that can sustain sub-nanosecond pixel rendering rates for three-dimensional polygons 
and can be used to render about a million Z-Buffered and Gourard shaded polygons per second. The chip 
has been designed at the IBM Research Division's Thomas J. Watson Research Center. Introduction Computer 
graphics users have an ever-increasing desire for higher performance, more functionality and better picture 
quality which is constantly fueled by rapid im-provements in semiconductor technology. This has re-sulted 
in better and faster yet cheaper and smaller graphics systems. Today's graphics systems utilize a vast 
number of specialized chips such as graphics processors, fast floating point processors, customized video 
memories with separate serial ports (popularly called VRAMs), and fast video lookup tables with digital-to-analog 
converters. VRAM based frame buffers have become the basis for all high-performance graphics systems 
which then use dedicated graphics processors or specialized hardware for operations such as line drawing 
and polygon filling. An accompanying Z-buffer is often used to assist the system in removing hidden surfaces 
for three dimensional primi- tives. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permi, 
ssion of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee 
and/or specific permission. &#38;#169;1988 ACM-0-89791-275-6 $00,75 / 88/008/0041 The frame buffer is 
capable of displaying arbitrary im-ages without imposing any limits to their complexity. However as users 
demand faster interactivity and migrate from line drawing graphics applications to shaded polygonal images, 
the frame buffer is becoming a bottle- ncck in its ability to change the picture rapidly. This bottleneck 
arises because area filling an object updates significantly more pixels than outlining the same object. 
If the average length of an edge is N pixels, then drawing the wireframe scene requires O(N) operations, 
whereas area-filling the scene would require O(N 2) operations. As a result of this fundamental difference 
between linear operations count for line drawing and quadratic oper-ations count for polygon filling, 
rendering polygonal scenes is significantly slower than outlining wire frame pictures. Figure i shows 
the pixel update rates required to update various scene complexities against various frame rates. The 
scene complexity is the total number of pixels that need to be updated to redraw the scene and it is 
a func- tion of the number of polygons in the scene, average area of the polygons, and the screen resolution. 
For example, a 1024x1024 screen displaying a scene with 10,000 polygons of 1,000 pixels each would contain 
10 million pixels in each frame. The same scene rendered on a 2048x2048 screen would contain 40 million 
pixels! It is not uncommon to render scenes at 4 or even 8 times the screen resolution and then filter 
the resulting image to produce a high quality anti-aliased picture. The pixel update time is a measure 
for both sccne complexity and frame update time and is given by: Fram e Tim e Tpixel-PixelslnFrame Figure 
1 illustrates the desire for pixe/update times in the nanosecond to sub-nanosecond range to sustain dynamic 
pictures high resolution displays. f SIGGRAPH '88, Atlanta, August 1-5, 1988 Pixels/ 1 1/10 1/30 1/60 
frame sec. see. sec. see. IM 1,000 100 33 17 5 M 200 20 6.7 3.3 IOM I00 10 3.3 1.7 25M 40 ,4 1.3 0.7 
50M 20 2 0.7 0.3 Figure 1. Required pixel update time in nanoseconds. To compare the limitations imposed 
by the frame buffer memory bandwidth on pixel update time, we have to ex- amine the underlying frame 
buffer implementations. Figure 2 shows the available frame buffer memory band- width using memory chips 
with different densities and organizations for a display with one million pixels. The memory chip organization 
determines the number of bits available in parallel in every memory access. The pixel update time is 
given by: MemoryCycle Time x MemoryChipSize Tpixel'= PixelsOnScreen x MemoryBitWidth We have assumed 
a memory cycle time of 256 nanoseconds, which is usually difficult to achieve because 3D rasterization 
involves a read-modify-write cycle to read, compare, and update the Z-buffer. Current systems which use 
64Kx4 memory chips can achieve up to 16 nsec/pixel. As seen in Figure 2, with higher density memory chips, 
the frame buffer is unable to sustain the pixel rates needed, even in wide memory organizations. High 
performance graphics systems can either continue to use low density memory chips, or look for alternative 
VLSI architectures capable of utilizing the higher densi- ties of technology and providing the required 
perform- ance. Density 256K IM 4M IdM Width X 16 t6ns. 64ns. 256ns. X 8 32ns. 128ns. 512ns. X 4 16ns. 
64ns. 256ns. lps. X i 64ns. 256ns. l~s. 4~s. Figure 2. Available Memory Pixel Update Time  The Rendering 
Primitive Rendering pixels as the basic primitive into frame buffers leads to an enormously high pixel 
update rate which cannot be economically supported by the existing or fu- ture memory technologies. Changing 
the basic hardware rendering primitive from low level pixels to higher level primitives such as horizontal 
spans, trapezoids, or trian-gles has two advantages. First it reduces the interchip communication bandwidth 
in the system because of the smaller number of primitives transmitted. Second the chips can render the 
primitives in parallel by exploiting the wider and faster on-chip bussing structures. Many other researchers 
and commercial graphics systems have chosen a higher level primitive instead of the pixel primitive. 
Some machines have chosen polygons and tri-angles as their primitive [2], some have provided rectan- 
gles [8, 14], others have tried trapezoids [13], and along with others [1, 7, 10] we have chosen the 
horizontal span as our lowest level hardware primitive. Different primitives lead to different system 
architectures, which are tuned to maximally exploit the parallelism in the primitive. Filling three dimensional 
horizontal spans is the inner most loop of any polygon rendering algorithm. We have chosen the horizontal 
span as our rendering primitive for three reasons. First it is simple enough to be executed in hardware. 
Second it is powerful enough that if executed in parallel, it has the potential to achieve the nanosecond 
pixel rendering goal. And third, it is general enough to represent other non-polygonal shapes such as 
ellipsoids and curved surfaces, as well as allow for more sophisti-cated polygon edge interpolations. 
Horizontal Figure 3. Projection of 3D polygons on a scanline. in ii i ill ill PROCEDURE FILLSPAN (XI, 
Xr,Z,AZ,RGB, ARGB) static int ZBuf [0.. 1023], RGBBuf [0.. I023] FOR x := Xl to Xr DO BEGIN IF Z < ZBuf[x] 
THEN BEGIN ZBuf[x] := Z; RGBBuf[x] := RGBBuf; END; Z := Z + AZ; RGB := RGB + ARGB; END; Figure 4. Span 
Command Figure 3 shows a horizontal plane cutting through a three dimensional polygonal scene. The intersection 
of the plane with each polygon yields a three dimensional hori- zontal span. Rendering all the horizontal 
spans for a given cutting plane yields the final picture for the corre- sponding scanline on the screen. 
Figure 4 shows the procedure FillSpan with its input arguments which de- scribe a three dimensional horizontal 
span. A span is de- scribed by the position of its two end points, its depth at the left end point, and 
change in depth with respect to unit pixel change along the scanline, and similarly a color triplet value 
at the left end point and rate of change for each color value. Using the horizontal span as our primitive, 
the polygon rendering problem can be broken down into two pieces: a horizontal filling inner loop which 
transforms span primitives into pixels, and a vertical interpolation outer loop which breaks individual 
polygons into horizontal spans. The next section describes the process of mapping the horizontal span 
rendering loop into a parallel hard- ware algorithm which was then implemented on a million transistor 
custom CMOS chip called SAGE (Systolic Ar- ray Graphics Engine). The following section will then describe 
the Vertical Interpolation Processor (VlPs) XIm Address ' Address Xrm Z m AZ---~ t~vth D Depth SetZ 
m ~----..D, ~. PROCEDURE FILLSPAN (XI, Xr,Z,AZ, RGB, ARGB) static int ZBuf [0..1023], RGBBuf [0..1023] 
FOR x .'= 0 to 1023 DO BEGIN IF xl < x ~ xr THEN BEGIN IF Z ~ ZBuf[x] THEN BEGIN ZBuf[x] := Z; RGBBuf[x] 
:= RGBBuf" END; Z := Z + AZ; RGB := RGB + ARGB; END; END; Figure 5. Span Command unrolled for systolic 
mapping. which break polygons into spans, and combined with SAGE form a high performance polygon rendering 
graphics system.  SAGE: A Systolic Array Graphics Engine SAGE maps the horizontal span rendering loop 
into a systolic array of pixel processors; one for every pixel on a scanline. Figure 5 shows the FiilSpan 
loop modified to operate with fixed loop bounds. Execution of this modi- fied loop always takes a fixed 
number of iterations (1024 iterations for l Kxl K screen) where as the execution speed of the unmodified 
loop is proportional to the length of the span being rendered. This fixed execution speed which is independent 
of the ~ength of the span, allows us to fully unroll the loop and assign a fixed length array of processors 
for executing the loop, as shown in Figure 6. Note that the first processor executes the first iteration 
of the loop, and passes the results to the second processor which executes the second iteration and so 
on. This con- tinues in a pipclined manner, allowing the array to accept a new span command every clock 
cycle. ~ Address ~ Address ID b ID D I, Depth p Depth D D OQD RGB -- -D Color II Color !---~i Ib Color 
~ Color ARGB -- R~frcsh --P DVideo Video Video Vkloo RGB Video Out 0 1 ° " 1022 1023 Figure 6. Systolic 
array of pixel processors m SAGE. SIGGRAPH '88, Atlanta, August 1-5, 1988 IIIII Figure 7 shows the input 
and outputs of a pixel processor for executing the body of the loop in the FillSpan proce- dure. If the 
state of the procedure is input at one end, then the output of the pixel processor corresponds to one 
iteration of the loop in FillSpan. The address block is composed of two comparators which compare the 
loop counter x (in this case processor number) against the left and right end points of the span xl and 
xr. The depth block contains a register for holding ZBuf, a comparator for comparing the input Z against 
ZBuf, connections for loading Z into ZBufif the comparison is successful, and an adder for adding Z with 
AZ. The color block contains three registers for storing the input RGB values into RGBBufif the depth 
comparison is successful, and three adders for adding RGB with ARGB. For initialization at the beginning 
of every scan line, the SetZ control bit forces an unconditional loading of both ZBt~f and RGBBufindependent 
of the result of the depth compar- ison. Address !I ] ~ ~ XI' Xr' Z J ~Z SetZ Depth ................41,,,. 
AZ' SeiZ' RGB ARGB -- Color ~ RGB' ARGB' Refresh RGB Video Out ---Ill.---.--- Video .4------- Refresh 
RGB Video in Figure 7. SAGE Pixel Processor Block Diagram. The refresh block of the pixel processor 
allows the shifting out of the RGBBuf from the SAGE chip. After all the spans for a given scan line have 
been clocked in, a one bit refresh token is sent which causes the contents of the scanline to be outputted 
on the video port at the rate of one pixel every clock cycle. All processors behind the re- fresh token 
have completed rendering of their pixet values and have already loaded the final pixel value into the 
video pipeline. The processor currently holding the re-fresh token is loading its pixel value into the 
pixel pipe- line, and the processors ahead of the pixel token are still rendering the current scan line. 
Processors behind the re- fresh token that have completed rendering the current scan line, and may immediately 
start rendering spans for the next scan line. Figure 8 shows clock cycle snapshots of the SAGE pipeline 
and demonstrates how SAGE ren-ders a number of horizontal spans, and then outputs the pixel values for 
that scan line. 4,4 Figure 9 shows a plot of the SAGE chip with 256 pixel processors. SAGE was implemented 
on 12.7 mm. by 12.7 mm. chip using 1.2p CMOS technology and contains about one million transistors. The 
array of 256 processors is broken down into three rows which are connected at the break points. All inputs 
and outputs to the array are through the first pixel processor. Aside from power, ground, and two complementary 
clocks, there are no other global signals. All the pixel processors are identical copies and were de- 
signed such that they could be replicated in an array without any external connections. After the chip 
was completed, a post-layout hard wired the pixel address of each processor into its address comparator 
block. The cells used to construct each processor are: shift register, address compare, adder, comparator, 
buffer cell, video cell, and a random logic control cell. To achieve the fastest possible clock speed, 
pipelining is used both in the horizontal and vertical directions. In the horizontal direction, a 256 
stage pipeline allows neigh- boring processors to communicate data in a systolic fash- ion. In the vertical 
direction, a three stage pipeline allows independent operation of the address block, the depth block, 
and the color and refresh blocks. A data skewer at the input of the array delays the depth parameters 
by one clock cycle, and the color parameters by two clock cycles in order to maintain proper operation 
of the pixel processors. As a result of both horizontal and vertical pipelining as well as purely nearest 
neighbor data communication, the chip can operate at a 40 nanosecond clock cycle, which allows the processing 
of up to 25 million spans per second [5.]. SAG E Configurations Each SAGE chip only contains 256 pixel 
processors, and multiple chips need to be used to build a system with a higher horizontal resolution. 
For example, four chips would be needed to build a 1024x1024 system. This can be done by either connecting 
the chips in series or in parallel (Figure 10). When the chips are connected in series, the first chip 
contains processors 0 through 255, the second contains processors 256 through 511, and so on. Span commands 
are processed in the first chip and passed to the second, the video is similarly shifted out in the reverse 
direction. In this configuration spans are passed in at rate of 40 nsec/span, and video is output at 
the same rate. When the chips are connected in parallel, each chip contains pixel processors for every 
fourth pixel. The first chip contains processors 0,4,8,t2 and so on, the second contains processors 1,5,9,13, 
and so on. Com-mands arc passed in at rate of 40 nsec/span, but now video is output at 4 pixels every 
clock cycle or 10 nsec/pixel.  ii i i ] i SpanC ..... ds [~[[~1 video output SAGE ~[[[~~[[[~ (0..255) 
SAGE l~[~r~3~ (512..767), Serial Configuration Span Commands Video Output Parallel Con.figuration Figure 
10. SAGE Configurations for 1024 processors. SAGE Graphics System A complete polygon rendering system 
also includes con-verting polygons into spans and managing the active polygon list for each scan line 
[4, 6, 9, 12]. Figure l l shows the simplified PolySpan procedure for breaking a 3D trapezoids into a 
set of horizontal spans. Other prim- itives like triangles and polygons can be similarly broken into 
spans. The procedure receives the slopes for the polygon edges, sets up the parameters for the left and 
right polygon edges, and within the loop incrementally computes the change in the span parameters for 
the next scanline which correspond to a unit vertical change in screen coordinates. PROCEDURE TrapezoidSpan 
(Yt, Yb, xt, v~xt, xr, V~Xr, z, V~,Z,RGB, vyn a B, a~Z, A~RGB) FOR y := yt to yb DO BEGIN SpanFill( X1,Xr,Z, 
A,~Z,RG B, A,RG B ) ; xt:= xt + vyx# Xr := Xr + VyXr; Z:= Z + VyZ; RGB := RGB + VrRGB; END; Figure 1 
1. Polygon to Span Conversion. A planar three dimensional polygon, i.e. xyZ, xyR, xyG, xyB planes, has 
a fixed slope with respect to the horizon- tal axis for all the horizontal spans in the polygon and does 
not change from scanline to scanline. Therefore out of the ten parameters of the SpanFill procedure, 
the four slopes are constants and don't change from scanline to scanline, and the other six parameters 
are incrementally computed for every scanline. This process is often called the six axis interpolation 
[1 !] Figure 12 shows the internal configuration of the Vertical Interpolation Processor, and Figure 
13 shows the system diagram with an array of 8 identical VIPs which execute the PolySpan procedure and 
provide SAGE with all its input parameters. The VIPs are responsible for supplying SAGE with all the 
horizontal span primitives on a given scanline by incrementally computing the intersection of a horizontal 
cutting plane with the three dimensional polygons in the scene. Since SAGE expects all the spans for 
a given scanline before it starts to compute the next scanline, the VIPs have internal storage to save 
the com- plete state of the interpolation loop. The internal memory of the VIPs can hold up to 512 active 
polygons. To gen- erate all the spans for a given line, the VIPs go through a load state, interpolate 
span, and save new state se-quence for all the active polygons in their internal mem-ory. Six VIPs are 
used for performing the six axis interpolation and the other two are used are used as memories for storing 
the four constant slopes. The polygon manager computes the slopes for the polygons and loads this information 
into the VIPs through the 32 bit bus. The polygon manager is respon- sible for setting up the state for 
newly activated polygons, updating the state information at polygon vertices, and SIGGRAPH '88, Atlanta, 
August 1-5, 1988 Input Bus T X I 7X Address 512 RAM Controller RAM X AX Figure 12. Vertical Interpolation 
Processor. I Polygon Manager R X1 Xr z deactivating the polygons from the internal state memory of the 
VIPs. The polygon manager may wait for the VIPs to do the interpolation for the current scanline and 
then update the internal state of the VlPs. Alternatively by allowing the polygon manager to update the 
state infor-mation for any polygon which has been interpolated by the VlPs on the current scanline, one 
can achieve faster transparent loading of V1Ps. The VIPs are synchronized with the SAGE chips, span converting 
and rendering a span every 40 nanoseconds. For an average polygon height of 32 lines (1000 pixel polygons), 
the system is capable of rendering close to one million polygons per second. To supply this rendering 
system at this rate, we plan to use a floating point multi- processor workstation, currently being prototyped 
For an average span width of 32 pixels, SAGE updates pixets at an average rate of 1.25 nanoseconds/pixel. 
For spans longer than 40 pixels, SAGE achieves subnanosecond pixel update times. [3].  Status The SAGE 
chip is due back from fabrication in January 1988, and the rest of the rendering system is being de- 
signed. We hope to demonstrate a working system by the summer of 1988. The SAGE chip and system are IBM 
Research Division prototypes for research purposes, and are not planned to be part of IBM products. Polygon 
] Memory I G B ~Z AR AG AB Span Commands for SAGE Figure 13. Polygon to Span Interpolation. Bibliography 
 1. S. Demetrescu. High Speed Image Rastcrization Using Scan Line Access Memories. Proc. 1985 Chapel 
Hill Conference on VLSI, pages 221-243, Computer Science Press, 1985. 2. H. Fuchs and J. Poulton. Pixel 
Planes: A VLSl-Oriented Design for a Raster Graphics En-gine. VLSI Design, 2(3):20-28, 3rd. Quarter 1981. 
 3. A. Garcia. ACE: A High Performance Multi-processor Workstation, IBM Internal Communi-cation, IBM 
Thomas J. Watson Research Center, 1987. 4. N. Gharachorloo. Super Buffer: A systolic VLSI Graphics Engine 
for Real Time Raster ]mage Generation, Ph.D. Thesis, Electrical Engineering Department, Corneil Univ., 
Ithaca, NY. August 1985. 5. N. Gharachorloo, S. Gupta, E. Hokenek, P. Balasubramanian, W. Bogholtz, 
C. Mathieu, and C. Zoulas. A Million Transistor Systolic Array Graphics Engine. Proceedings of International 
Conference on Systolic Arrays, San Diego, May 1988. 6. N. Gharachorloo and C. Pottle. SUPER BUFFER: 
A Systolic VLSI Graphics Engine for Real Time Raster Image Generation. Proc. 1985 Chapel Hill Conference 
on VLSI, pages 285-305, Computer Science Press, 1985. 7. J.H. Jackson. Dynamic Scan-converted images 
with a Frame Buffer Display Device. Computer Graphics, 14(3):163-169, July 1980.  . Bart Locanthi. Object 
Oriented Raster Displays. Proceedings of Caltech Conference on VLSI, pages 215-225, January 1979. 9. 
A.J. Myers. An Efficient Visible Surface Program, Ohio State University, Report to the NSF, July 1975. 
10. H. Niimi, Y. Imai, M. Murakami, S. Tomita, and H. Hagiwara. A Parallel Processor System for Three 
Dimensional Color Graphics. Computer Graphics, 18(3):67-76, July 1984. 11. R.W. Swanson and L.J. Thayer. 
A Fast Shaded- Polygon Renderer. Computer Graphics, 20(4):95-101, August ! 986. 12. G.S. Watkins. A 
Real Time Visible Surface Algo- rithm, University of Utah, Computer Science De- partment, June 1970. 
 13. Richard Weinberg. Parallel Processing Image Synthesis and Anti-Aliasing. Computer Graphics, 15(3):55-61, 
August 1981. 14. Daniel S. Whelan. A Rectangular Area Filling Display System Architecture. Computer 
Graphics, 16(3):147-153, July 1982.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378476</article_id>
		<sort_key>51</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[A rendering algorithm for visualizing 3D scalar fields]]></title>
		<page_from>51</page_from>
		<page_to>58</page_to>
		<doi_number>10.1145/54852.378476</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378476</url>
		<abstract>
			<par><![CDATA[This paper presents a ray tracing algorithm for rendering 3D scalar fields. An illumination model is developed in which the field is characterized as a varying density emittter with a single level of scattering. This model is equivalent to a particle system in which the particles are sufficiently small. Along each ray cast from the eye, the field is expressed as a function of the ray parameter. The algorithm computes properties of the field along the ray such as the attenuated intensity, the peak density, and the center of gravity, etc., These are mapped into HSV color space to produce an image for visualization.Images produced in this manner are perceived as a varying density 'cloud' where color highlights the computed attributes. The application of this technique is demonstrated for visualizing a three dimensional seismic data set.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D image]]></kw>
			<kw><![CDATA[light scattering]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[thresholding]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor>Intensity, color, photometry, and thresholding</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39052895</person_id>
				<author_profile_id><![CDATA[81100653930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paolo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sabella]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Visual Edge Software, 37 Dragon St., Kirkland, PQ H9J-3B3, Canada and Schlumberger-Doll Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Blinn and M. Newell, "Texture and Reflection in Computer Generated Images," Comm. ACM, Oct. 1976, pp. 542-547.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Blinn, "Light Reflection Functions for Simulation of Clouds and Dusty Surfaces",Computer Graphics 16(3), July 1982, pp. 21-29.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Chen, G. Herman, R. Reynolds and J. Udupa, "Surface Shading in the Cuberille Environment", IEEE Computer Graphics and Applications 5(12), December 1985, pp.33-43.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807436</ref_obj_id>
				<ref_obj_pid>965103</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. Dugan, "A terrain and cloud computer image generation model", Computer Graphics 13(2), 1979, pp.143-150.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Farrell, "Color Display and Interactive Interpretation of Three- Dimensional Data", IBM J. Res. Develop 27(4), July 1983, pp.356-366.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[B. Fishman and B. Schacter, "Computer display of height fields", Computers and Graphics 5, 1980, pp.53-60.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. Frieder, D. Gordon, R. Reynolds, "Back-to-front Display of Voxel-based Objects", IEEE Computer Graphics and Applications, 5(1), Jan. 1985, pp.52-60.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Hohne and R. Bernstein, "Shading 3D-Images from CT Using Gray-Level Gradients", IEEE Trans. on Medical Imaging MI-5, 1, March 1986, pp.45-47.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Kajiya, B. Von Herzen, "Ray Tracing Volume Densities", Computer Graphics 18(3), July 1984, pp.165-174.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35071</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. Klassen, "Modeling the Effect of Atmosphere on Light", ACM Trans. on Graphics, 6(3), July 1987, pp.215-237.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[W. Lurensen and H. Cline, "Marching Cubes: A High Resolution 3D Surface Constructio n Algorithm", Computer Graphics 21(4), July 1987, pp. 163-169.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[X. Mat, T. Kunii, I. Fuhishiro and T. Noma, "Hierarchical Representations of 2D/3D Gray-Scale Images and Their 2D/3D Two-Way Conversion", IEEE Computer Graphics and Applicalions 7(12), December 1987 pp. 37-44.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5515</ref_obj_id>
				<ref_obj_pid>5513</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. Max, "Light Diffuson through Clouds and Haze", Computer Vision, Graphics and Image Processing 33, 1986, pp.280-292.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. Meagher. "Geometric Modeling Using Octree Encoding" Computer Graphics and Image Processing 19(2), June 1982, pp 129-147.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807502</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. Meyer and D. Greenberg, "Perceptual Color Spaces for Computer Graphics", Computer Graphics 14, 1980, pp.247-261.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801167</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[W. Reeves, "Particle Systems- a technique for modeling a class of fuzzy objects", Computer Graphics 17(3), July 1983, pp.359-373.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[W. Reeves and R. Blan, "Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems", Computer Graphics 19(3), July 1985, pp.313- 322.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6117</ref_obj_id>
				<ref_obj_pid>6116</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[P. Robertson and J. O'Callaghan, "The Application of Scene Synthesis Techniques to the Display of Multidimensional Image Data", ACM Trans. on Graphics, 4(4), Oct. 1985, pp.247-275.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37417</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Snyder and A. Barr, "Ray Tracing Complex Models Containing Surface Tesseilations", Computer Graphics 21(4), July 1987, pp.119-128.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August t988 II |1 I III II I I A Rendering Algorithm for 
Visualizing 3D Scalar Fields Paolo S abelIa* Schlumberger-Doll Research  Abstract This paper presents 
a ray tracing algorithm for rendering 3D scalar fields. An illumination model is developed in which the 
field is characterized as a varying density emittter with a single level of scattering. This model is 
equivalent to a particle system in which the particles are sufficiently small. Along each ray cast from 
the eye, the field is expressed as a function of the ray parameter. The algorithm computes properties 
of the field along the ray such as the attenuated intensity, the peak density, and the center of gravity, 
etc.. These are mapped into HSV color space to produce an image for visualization. Images produced in 
this manner are perceived as a varying density 'cloud' where color highlights the computed attributes. 
The application of this technique is demonstrated for visualizing a three dimensional seismic data set. 
CR Categories: 1.3.3 [Computer Graphics]: Picture/Image Generation; 1.3.7 [Computer Graphics]: Three-Dimensional 
Graphics and Realism; 1.4.0 [Image Processing]: General General Terms: Algorithms Additional Key Words 
and Phrases: 3D image, ray tracing, thresholding, light scattering. *Author's curent affiliation: Visual 
Edge Software Author's current address: 37 Dragon St. Kirkland, PQ HgJ-3B3 Canada Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. @1988 ACM-O-89791-275-6/88/O08/O051 
$O0.75 1, Introduction. Computer graphics has made an irreplaceable contribution in the presentation 
of scientific dam. The computer is indispensable as an aid in the visualization of certain kinds of functions. 
This paper focuses on the display of single valued functions of three variables, i.e. scalar fields. 
Such functions can be analytically defined but more commonly are computed numerically using finite difference 
or finite element techniques. Examples of such fields are the stress distribution over a mechanical part 
or the pressure distribution within a fluid reservoir. Alternately, the field can be empirically measured. 
For example, sonic waveforrns or tomography radiation measurements can be processed to obtain density 
samples of a solid over a three dimensional volume. A convenient representation for this is a three dimensional 
array of samples referred to as a 3D image. The sample points are called voxels (volume elements). The 
cuberille [3] is a special case of the 3D image in which all the voxels are identical cubes. The retangular 
prism that is the spatial extent of the array is called the image extent. The 3D image is not the only 
representation for sampled scalar fields. Octrees [14, 12] provide a more compact, structured means of 
encoding fidd samples in which both the spatial extent and the image are hierarchically organized. In 
finite element analysis, samples of a field are computed at the mesh nodes. Hence the mesh itself serves 
as a representation for the field. In this paper we use the 3I) image representation. Figure 7 shows 
a 3D image of sub-soil density obtained from surface seismic measurements. The density value is mapped 
into a gray scale. Notice that most of the cube, i.e. the interior, is not readily visible. Although 
the objectives of manipulation 3D data is application dependent, the goal when visualizing the data is 
to understand the spatial distribution of the field values over the domain on which the function is defined. 
It is important to be able to see the location of the occurrence of any range of values, such as, for 
example, high values or 'hot spots' or changes in the field gradient. It is also important to perceive 
the manner in which the function varies from it's minimum to maximum va/ues. This is especially true 
for geophysical imaging in which there is hardly any spatial correlation in the data and which does not 
lend itself to existing visualization techniques. In this paper a new rendering model for visualizing 
scalar fields is proposed. In it, the field is rendered as a varying density emitter (DE) object. It 
is related, but not restricted, to the modeling of light in naturally occurring cloud-like objects. The 
goal here is the perception and understanding of the field, not the realistic rendering of natural phenomena. 
The visualization technique is unique in three ways: i) A color map is utilized to visualize individual 
attributes. it) The use of a phase function to visualize the field gradient. iii) The Kajiya and Von 
Herzen ray tracing algorithm is recasted for computational efficiency, eliminating shadowing while retaining 
occlusion. We first review the two existing rendering models of 3D images. Variations of these account 
for all attempts to date at rendering scalar fields. Next we look at scattering models and particle systems 
used to render realistic looking clouds and natural phenomena. We then propose the varying density emitter 
(DE) object which is actually a special case of a general scattering emitter and a generalization of 
the particle system. Finally, a ray tracing algorithm is described for rendering the DE object incorporating 
false coloring in order to present multidimensional information. Although the data presented in the figures 
actually represent a sampled  SIGGRAPH '88, Atlanta, August 1-5, 1988 density field, the visualization 
model is intended to be used on any field. It can be adapted to render analytically defined fields or 
to incorporate bounding surfaces such as those of a solid over which the field is defined. It can also 
be extended to render octrees or finite element meshes. 2. Rendering Models for 3D images There are two 
common techniques to date for rendering 3D images, cross- section rendering and threshold rendering. 
Each of these implicitly are models of the interaction of light on the 3D model. It is important to place 
the DE rendering model within the context of existing schemes. 2.1 Cross-section rendering In cross-section 
rendering, the 3D image is considered to be an opaque array of voxels packed inside the image extent. 
A user can interactively remove portions of the image in order to see interior voxels. The rendering 
model is that of light illuminating the cross-sectional surfaces, or slices. Good response time is valuable 
here in order to perceive the field in three dimensions. This perception is achieved by the user sequentially 
viewing multiple slices and mentally interconnecting the features of interest. For example, in order 
to search for a region of maximum value the user may scan through slices until one is found. Then many 
sections taken in possibly different orientations are viewed to see the extent of the peak region. An 
important consideration is the coloring of the voxels. Color is used both to indicate the field value 
at a voxel as well as to provide surface orientation cues. The cross-section is therefore a texture mapped 
surface [1]. Usually the intensity is varied according to a shading model while the base color, either 
hue or gray scale is used to indicate field value. 2.2 Threshold rendering Threshold rendering is common 
in medical applications when dealing with 3D images of densities measured by computer aided tomography 
(CAT) scanners. In this application there are different categories of materials each falling within a 
specific density range. In order to render a particular category, for example the bones, the rendering 
model considers voxels falling outside the range to be non-existent. Consequently, the resulting view 
is of the surface of a constant field value. Figure 8 shows a threshold rendering of the same 3D image 
shown in figure 7. Thresholding is important since it is a three dimensional view of iso- value surfaces. 
There are three categories of rendering techniques for thresholding, back to front traversal of the 3D 
image [7], ray tracing [5], and surface reconstruction [11]. A variation of the threshold illumination 
model is to assume that the iso-value surface has a normal vector, computed from the field gradient. 
This allows the iso-valued surface to be shaded using Gouraud or Phong shading [8]. The threshold rendering 
model throws away much of the data held in the 3D image. Except for applications, like medical imaging, 
in which a small number of density ranges are of interest, it is like cross-section rendering in that 
it requires many views of the field which have to be mentally combined in order for a user to entirely 
perceive the field. In an application like geophysical imaging, a 3D seismic image does not portray as 
much coherence as a medical image. Hence a threshold rendering is not satisfactory because it generates 
fragmented pieces instead of cohesive surfaces.  3. Scattering Models We wish to see more than just 
iso-value surfaces when rendering a 3D image. It is natural therefore to establish a model for viewing 
three dimensional translucent solids. We do not often encounter such solids with varying translucency 
in every day circumstances. However clouds, smoke, mist and other systems of suspended particles are 
common. Through these we do have experience in perceiving variations of density. A haze in the alanosphere 
has been modeled by Dugan [4] and opaque clouds, represented as elipsoidal height fields, was modeled 
by Fishman and Schaeter [6]. However true cloud-like scenes are achieved by modeling the scattering of 
light. Although the goal here is not the rendering of natural clouds, it is important to consider the 
interaction between light and a medium that occurs in clouds so that it may be used to exploit our ability 
to perceive density fields. 3.1 Background Blinn's model [2] of the rings of Saturn was the first graphics 
model of the scattering through a thin uniform density cloud of low albedo. Max [13] modeled clouds bounded 
by quadric surfaces. The emphasis was in modeling the enclosing volume within which the particles reside. 
More recently, Kajiya and Von Herzen [9] introduced a ray tracing technique for rendering 'volume density' 
models, their term for a 3D image of a density field. They presented a solution for multiple radiative 
scattering. Another amorphous class of model is the particle system introduced by Reeves [16,17]. While 
they have been used to model many natural phenomena, such as blades of grass, the use of particle systems 
to model fire is most striking. This is because the particles are point light sources that are additively 
combined when rendered. There are three effects observed when illuminating translucent objects. i) Occlusion 
of a portion of the model occurs when light is scattered by the portions of the cloud closer to the observer. 
ii) Shadows are created depending on the position of the light source. iii) Color variations are caused 
by separation due to differing amounts of scattering at different wavel~ngths. All of these are highly 
desirable cues for the realistic rendering of clouds. Computationally however, they are expensive; especially 
when combined with secondary effects like multiple scattering. 3.2 Varying Density Emitters For the 
purpose of viewing scientific data, shadowing and scattering color variations, while visually appealing, 
may actually detract from perception of the density variation. On the other hand, since occlusion is 
proportional to density, it enhances this perception. A system that solely exhibits occlusion would be 
a good one to use, at the same time keeping the computation cost low. Such a system is a field of varying 
density emitters. A DE object is a system of particle light sources. Unlike Reeve's particle system in 
which particles are modeled individually the DE object models the density of particles, not the particles 
themselves. The size of the particle is sufficiently small compared to other dimensions so that the density 
of the particles can be regarded as a continuous function. For convenience we define the density p(x,y,z) 
non-dimensionally as the ratio of the volume occupied by particles, Vp to the total volume of the cloud 
V. Since the ratio is only valid locally we have dVp   p(x,y,z)--oV This is actually the probability 
that a particle is present at the point (x,y,z). Each particle has a volume ~p. The expected number of 
particles within a region 12 is .~dVp ~p dV ND= Vp -Up t Figure 1 The volume encountered before the ray 
parameter t. 3.3 The Brightness Equation Figure 1 sketches the path of a ray traversing the cube. We 
follow a derivation for the intensity of light, of a fixed wavelength, reaching the eye that is similar 
to Blinn [2] but allow for varying density and ignore self illumination. The density field p(x,y,z) can 
be parameterized along the ray as p(x(t),y(t),z(t)), or simply p(t). If each particle has an intensity 
~:, a cylindrical volume element of cross sectional area ff and length dt at a point t along the ray 
contributes dV = ~ P~ ~ dt KNcr= ~'Pvp K~ "t" -p  ~ Computer Graphics, Volume 22, Number 4, August 
1988 to the intensity of light emitted toward the eye. This light emitted by the volume element is scattered 
backward when traveling on it's way toward the eye due to the particles lying within the volume between 
t and t 1 . The expected number of particles N in this volume, V, is The intensity of light reaching 
the eye is equal to the light emitted, attenuated by the probability, P(0;V), that there exists zero 
particles in the volume V. Assuming p is small, this can be approximated by a Poisson distribution P(O;V) 
= e "N . The intensity of the light reaching the eye from the point t is thus -N K~ I(t) = P(0;V) rN 
o = e -~-p(t) dt ( 1 ) The total intensity due to all contributions along the ray between t 1 and t 
2 is the integral of (1) I t t . o ~p(Z) dZ EE. e ~P tl p(l) dt (2) B = Vp 1 G The term ~ can be replaced 
by one constant ~. It has dimensions iJ 1/length and is related to the optical length. We can normalize 
the entire equation by choosing Vp since we are not dealing with actual radiation measurements. Equation 
(2) simplifies to I t t - Jp(X) d~ B = e t 1 p(t) dt (3)1 This is a simplified version of Kajiya and 
Von Herzen's brightness equation, omitting the line integrals from the light source [9]. In order for 
this to hold we have assumed that p(t) is small. We can adjust the value of to scale p(t) in the exponent 
integral. Higher values of z increases the attenuation producing a medium that darkens more rapidly. 
Finally, taking advantage of the fact that p lies between 0 and 1, the transformation  p' =pY ~s Bsed 
to corttrol the spread of detasity values. Higher y intensifies the appearance of dense portions relative 
to the more diffuse regions while lower y makes the entire cloud appear more diffuse. This transformation 
is order preserving, i.e. the ordering of two values P'(~,I) and p'(;L2) is the same as that of p(3,1) 
and P(h2). It is useful to spread out the function p since not all density variations are perceptible. 
The total brightness along a ray is: it l -= j'pY(~) dX B = 1 e tl pY(t) dt (4) In figure 5 the field 
in figure 7 is ray-traced using equation (4). The results of varying the two parameters y and x are show. 
Each image is normalized to use the full intensity range. The image lies within a unit cube. As expected, 
the images on the upper row, in which "t = 1, are not sufficiently attenuated. This is corrected by making 
the value of x larger than the distance t2-t 1 in the second and third rows x = 2 and "~ = 3. The density 
spread, controlled by 7, is highest in the first column in which y = 1. In the adjacent columns Y equals 
5 and 10 respectively. We observe, as predicted in figure 2a, the spread narrows and the higher densities 
dominate.  1 y < 1 (moa~ di£fiu~) I ~ 1 pr~el) 0=exP 0 0 o p I o p 1 Figure 2a Transformations on p 
Figure 2b Transmittance functions 3.4 Equivalence to Discrete systems. The model utilized in discrete 
systems for transmission of light through translucent surfaces or particles in a particle system is equivalent 
to equation (3). The total intensity remaining after traversing n translucent particles or  surfaces, 
is n i-1 b i ]~IlO j , (5) i=1 j Where b i is the amount of light emitted from the i th surface either 
by reflecting light received from light sources or due to the fact that the surface is itself a light 
source. The transmittance factor of the ith surface, i.e. the proportion of entering light allowed to 
go through the surface, is 0 i. It varies between 0 and 1. Since the i th surface is seen through the 
preceding i-1 surfaces, the total attenuation of b i is the product of the preceding i-I 0 terms. Equation 
(5) is actually equivalent to the discrete form of equation (3) i n -x 5"ptt.~ at. B =.~.,e j=l~ "J" 
Ip(ti ) 8t i i=1 n i -~p(tj) 6tj = i=l~"P (ti) 8tij r[e=l (6), in which the surface for i=l is at t=t 
I and the surface for i=n is at t=t 2. The i th surface has a thickness 5t i over which the density can 
be assumed constant. The equivalent terms are b i = P(ti) 8t i , and 0j e-,C p (tj) atj  = (7) The 
threshold rendering model explicitly controls the relationship between 0 and p. Figure 3a is an example 
of a threshold window on p and figure 3b shows the corresponding 0, p relationship. The equivalent functions 
for the DE model are shown in figures 2a and 2b. The shapes of these graphs indicate that the DE model 
is a continuous version of the threshold model. In the limit, as y goes to infinity, we obtain a threshold 
model with a range of zero width around p = 1. f SIGGRAPH '88, Atlanta, August 1-5, 1988 e(p) p' o o 
 o p i i Figure 3a. A threshold window Figure 3b. The corresponding transmittance function   4. Mapping 
into Color Space Since we have ruled out the color variations caused by differential wavelength scattering 
we are left with the question of whether or not to incorporate the use of color at all. Color can be 
the result of a realistic model of light or it can be utilized symbolically. Even though models of color 
space are three dimensional, human perception of color is not. Robertson and O'Callaghan in [18] give 
detaits of their scheme to simultaneously display multiple 2D image data sets, In it, one image is rendered 
realistically as the surface of a height field while another is used to determine the hue of the displayed 
surface. The rendering of a DE object is different from their application in that here we are interested 
in rendering one 3D image. However, we can adapt the idea that realism cues the human visual system thereby 
enhancing the perception of additional variables. In ray tracing a surface model, a ray is fired from 
the eye through a pixel to determine the pixel color. The closest surface that is encountered is the 
one whose color is chosen as a base color for the pixel. Even though the final color is computed by taking 
into account light sources and the shading model, the surface color indicates symbolically which surface 
was encountered. The same is true recarsively for reflected and refracted rays. EYE [,~z Figure 4. Properties 
along the ray We have a moi'e difficult problem when ray tracing a field. Instead of choosing a color 
that indicates which surface was hit, the ray encounters the density function p(t). Since it is not possible 
to choose one color that will uniquely represent all the values of the function over the ray, we use 
color to indicate certain characteristic properties of the function. The properties chosen to compute 
along the ray are (see figure 4): t 1 M = (Max(p(t)))t2Peak value encountered along the ray, D = Distance 
at which the peak value is encountered, I = The attenuated intensity, equation (4), C = tl The centloid 
or center of gravity. tZ t] In Robertson and O'Callaghan's scheme, the underlying model is that of rendering 
a surface whose height was determined by one data set and whose color was based on a model of paint pigmentation. 
The colors chosen were evenly spaced in the uniform color space proposed by Meyer and Greenburg [15]. 
We take a simpler view with regard to the choice of color scale. The goal in our scheme is the rough 
identification of extrema such as 'hot spots'. It is important to realize that such a scale is symbolic 
and are not intended for reading absolute values or distances. Our scheme was implemented in HSV space. 
In it the Value component, corresponding to the light intensity, was obtained from the I variable and 
the Hue component from the peak encountered along the ray, M. The hue scale was reversed to be a scale 
in which 'hot' colors, reds, represent high values. Saturation can be a strong depth cue because decreasing 
saturation gives the effect of seeing in a fog [10]. Hence a depth parameter such as D or C was chosen 
for the Saturation component. To illustrate the scheme a charge field was computed for two point charges. 
Figure 6 shows the M, D and I properties computed as gray images as well as the (M->H, D->S, I->V) color 
image. Notice that the charge to the left which is further away appears more saturated. Figure 9a shows 
in gray scale, the M property for the (~=2, y=5) image. Similarly, figures 9b and 9c show the D and I 
properties and figure 9d the (M->H, D->S, I->V) color image. In this image, if the appearance of a hue 
is unsaturated, i.e. appears gray, it indicates that it is further away. If it is darker, it is in a 
diffuse region. Using the centroid, C property (figure 10a) for saturation is illustrated in figure 10b. 
This gives the effect of having a denser fog when the centroid is farther. Therefore a hue appears unsaturated 
due to the average densities, not just the peak, being further. In both cases, the existence of any 'hot 
spot' or high value can be detected by the appearance of a region colored with a hue representing the 
value, or higher. Unfortunately, this implies that regions of 'low values' are hidden and more difficult 
to observe; an obvious result of mapping peak values. The existence of any 'hot spot' or high value is 
detected by the appearance of a region colored with a hue representing that value, or higher. Unfortunately, 
this implies that regions of 'low values' are hidden and more difficult to observe; an obvious result 
of mapping peak values. 4.1 Incorporating Phase functions To this point, the fact that the DE object 
is itself a distribution of backward scattering light sources meant that we could ignore the effects 
of the phase function &#38;(s,s), the function characterizing the amount of scattering from the direction 
s to direction s. Actually, any backward scattering phase function would be adequate for such a model. 
In a system of a large number of particles, such as we have assumed for the DE object, the phase function 
is not dependent on local properties of the medium. This is the isotropic case. The anisotropic case 
occurs when there is a preference in orientation as occurs in the case of Lambertian surfaces. We diverge 
from the model of a physical system and assume that the DE object is anisotropic and has a phase function 
equal to the dot product between a preferred direction, the field gradient, and the direction of lighting. 
This provides a further attenuation in the brightness equation (3) of j(s) giving I t t -~ {p(;~) d~ 
B = e tl p(t) j(S)(x,y,z) dt (8). 1 We assume that j(s) is given by n v - j(S)(x,y,z) = ~ P.Li , i=1 
 where there are n external light sources and L i is the direction from the point (x,y,z) to the i th 
external light source. Figure 1 la is a gray scale rendering of the DE object shown in figure 9 ~ Computer 
Graphics, Volume 22, Number 4, August 1988 using equation (8) with two light sources. The combined HSV 
image using the centrold image of figure 10a for Saturation is shown in figure 1 lb. The main difference 
between this figure and figure 9d is the darkening of the image in regions where the gradient points 
away from the light sources and there is a high density. 5. The ray tracer The ray tracing algorithm 
is very straight forward. It consists of three steps, ray generation, computation, and display. The ray 
generator fires rays from the eye through each screen pixel toward the scene. When a ray intersects the 
extent of the 3D image it is stepped through the image extent and the four properties M, D, I and C are 
evaluated. The stepping algorithm is essentially identical to the one described by Snyder and Burr [19]. 
Since the centroid C requires the denominator line integral, this is also calculated and the final value 
for C is computed when the ray exits the image extent. The four properties are stored as a temporary 
four dimensional image. When the entire image has been ray traced, an image may be created mapping functions 
of any three of the properties to the HSV components. As discussed in the previous section, the more 
intuitive combinations are the (M->H,D->S,I->V) and (M->H,C->S,I->V) mappings. The reason for storing 
the properties first is to establish a scale for the range of variation of each property. This allows 
the fullest usage of the HSV components. Spatial col~erence within the 3D image allows stepping the ray 
in the direction of increasing ray parameter. If there were a terminating criterion, such as minimum 
attenuation factor, the algorithm could stop the stepping before traversing the entire span of the extent. 
Unfortunately, with the exception of the intensity, all the properties have no such criterion. This is 
the price paid to be able to see the peak value behind even dim regions. Even though there are no other 
types of rays fired, such as shadow or reflection rays, ray tracing was chosen as the rendering technique 
due to the simplicity in computing the attenuated integral in equation (3). Ray tracing matches well 
with the physical paradigm of light propagation and scattering in a non-homogeneous medium. 5.1 Results 
The 3D images rendered in figures 5, 7, 8, 9, 10 and ll have dimensions 64 x 64 x 400. The 256 x 256 
images in figure 7 each took 450 seconds on a Sun 4 workstation to compute. The 512 x 512 images in the 
figures 9 and 10 took on the order of 2550 seconds to compute while figure 11 which took 4530 seconds. 
The 512 x 512 images in figures 2 and 3 took on the order of 76 seconds to compute, showing that thresholding, 
being a surface technique, is relatively fast. The image generation phase takes on the order of 1 second 
on a Sun 3/160. 6. Conclusion The technique presented for rendering a scalar field in color is by no 
means exhanstive. Color is added to the intensity computed in order to identify high valued regions, 
'hot spots'. Even though the intensity calculation is a continuous generalization of the threshold rendering 
model, the full color image is superior since important hot spots cannot be occluded. One obvious extension 
is the x-ray illumination model. In an x-ray, an attenuated line integral is computed similar to the 
brightness given in equation (3). This allows high density regions to be detected by the absence of light 
due to higher scattering. Another extension is to go toward greater realism and perform shadowing and 
color scattering on non-density emitter models, i.e models that only scatter. This would allow the combination 
of backward and forward illumination. Discrete light sources could be placed within such a model to highlight 
regions of interest. Another technique of visualization, which is important for three dimensional perception, 
is animation. As in particle systems, a fuzzy object 'comes alive' when animated. 7. Acknowledgements 
The author thanks Schlumberger-Doll Research and in particular Stun Vestal, director of the systems science 
department, for providing the environment in which this work was possible. Indranil Chakravarty has always 
been there to discuss and help and has made suggestions in reviewing this paper. go References [1] J. 
Blinn and M. Newell, "Texture and Reflection in Computer Generated Images," Comm. ACM, Oct. 1976, pp. 
542-547. [2] J. Blinn, "Light Reflection Functions for Simulation of Clouds and Dusty Surfaces",Computer 
Graphics 16(3), July 1982, pp. 21-29. [3] L. Chen, G. Herman, R. Reynolds and J. Udupa, "Surface Shading 
in the Cuberille Environment", IEEE Computer Graphics and Applications 5(12), December 1985, pp.33-43. 
[4] W. Dugan, "A terrain and cloud computer image generation model", Computer Graphics 13(2), 1979, pp.143-150. 
[5] E. Farrell, "Color Display and Interactive Interpretation of Three- Dimensional Data", IBM J. Res. 
Develop 27(4), July 1983, pp.356-366. [6] B. Fishman and B. Schacter, "Computer display of height fields", 
Computers and Graphics 5, 1980, pp.53-60. [7] G. Frieder, D. Gordon, R. Reynolds, "Back-to-front Display 
of Voxel-based Objects", IEEE Computer Graphics and Applications, 5(0, Jan. 1985, pp.52-60. [8] K. Hohne 
and R. Bernstein, "Shading 3D-Images from CT Using Gray-Level Gradients", IEEE Trans. on Medical Imaging 
MI-5, 1, March 1986, pp.45-47. [9] J. Kajiya, B. Von Herzen, "Ray Tracing Volume Densities", Computer 
Graphics 18(3), July 1984, pp.165-174. [1o] R. Klassen, "Modeling the Effect of Atmosphere on Light", 
ACM Trans. on Graphics, 6(3), July 1987, pp.215-237. [11] W. Lurensen and H. Ctine, "Marching Cubes: 
A High Resolution 3D Surface Constructio n Algorithm", Computer Graphics 21(4), July 1987, pp. 163-169. 
[12] X. Mat, T. Kunii, I. Fuhishiro and T. Noma, "Hierarchical Representations of 2D/3D Gray-Scale Images 
and Their 2D/3D Two-Way Conversion", IEEE Computer Graphics and Applicalions 7(12), December 1987 pp. 
37-44. [13] N. Max, "Light Diffuson through Clouds and Haze", Computer Vision, Graphics and Image Processing 
33, 1986, pp.280-292. [14] D. Meagher. "Geometric Modeling Using Octree Encoding" Computer Graphics and 
Image Processing t9(2), June 1982, pp 129-147. [15] G. Meyer and D. Greenberg, "Perceptual Color Spaces 
for Computer Graphics", Computer Graphics 14, 1980, pp.247-261. [16] W. Reeves, "Particle Systems- a 
technique for modeling a class of fuzzy objects", Computer Graphics 17(3), July 1983, pp.359-373. [17] 
W. Reeves and R. Blan, "Approximate and Probabilistic Algorithms for Shading and Rendering Structured 
Particle Systems", Computer Graphics 19(3), July 1985, pp.313- 322. [18] P. Robertson and J. O'Callaghan, 
"The Application of Scene Synthesis Techniques to the Display of Multidimensional Image Data", ACM Trans. 
on Graphics, 4(4), Oct. 1985, pp.247-275. [19] J. Snyder and A. Burr, "Ray Tracing Complex Models Containing 
Surface Tesseilations", Computer Graphics 21(4), July 1987, pp.119-128.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378482</article_id>
		<sort_key>59</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[V-buffer]]></title>
		<subtitle><![CDATA[visible volume rendering]]></subtitle>
		<page_from>59</page_from>
		<page_to>64</page_to>
		<doi_number>10.1145/54852.378482</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378482</url>
		<abstract>
			<par><![CDATA[This paper presents rendering techniques that use volumes as the basic geometric primitives. It defines data structures composed of numerous subvolumes, in excess of 100,000. Over each subvolume, a scalar field describes the variation of some physical quantity. The two rendering methods described herein assume a trilinear variation of this scalar field within each volume element, unlike voxel-based techniques that assume a constant value for each subvolume. The result is a higher order approximation of the structures within the volume. In addition, solid texture mapping, atmospheric attenuation, and transfer functions relating the dynamic range of the scalar field to color and opacity are used to isolate important data features. The result is a new method for the visualization of three-dimensional data resulting from numerical simulations and observations of natural phenomena. This method continuously covers the gap between surface-based and voxel-based techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[isosurface]]></kw>
			<kw><![CDATA[natural phenomena]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[volume rendering]]></kw>
			<kw><![CDATA[voxel]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39049151</person_id>
				<author_profile_id><![CDATA[81100573310]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Craig]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Upson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stellar Computer, Inc., Milpitas, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334975</person_id>
				<author_profile_id><![CDATA[81100564496]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keeler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ardent Computer Corp., Sunnyvale, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Artzy, E., Frieder, G., Herman, G., "The Theory, Design, Implementation and Evaluation of a Three-Dimensional Surface Detection Algorithm", Computer Graphics and Image Processing, Vol 15, No 1, Jan. 1981, p. 1-24.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bergman, L., Fuchs, H., Grant, E., "Image Rendering by Adaptive Refinement", Computer Graphics, Vol 20, No 4, Aug. 1986, p. 29-37]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chen, L., Herman, G., Reynolds, R., Udupa, J., "Surface Shading in the Cuberille Environment", IEEE Computer Graphics and Applications, Vol 5, No 12, Dec. 1985, p. 33-43.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807388</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H., Sederberg. T., "Conversion of Complex Contour Line Definitions into Polygonal Element Mosaics", Computer Graphics, Vol 12, No 3, 1978, p. 187-192.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H., Stephenson, M., Nay, B., Grimsrud, A., "Movie.BYU Training Text", Graphics Utah Style, Provo, Utah, 1987.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cook, L., Dwyer, S., Batnitzky, S., Lee, K., "A Three-Dimensional Display System for Diagnostic Imaging Applications", IEEE Computer Graphics &amp; Applications, Vol 3, No 5, Aug. 1983. p. 13-19.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cook, R., Porter, T., Carpenter, L., "Distributed Ray Tracing", Computer Graphics, Vol 18, No 3, 1984, p. 137-145.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z., Uselton, S., "Optimal Surface Reconstruction from Planar Contours", CACM, Vol 20, 1977, p.693-712.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hall, R., "A Characterization of Illumination Models and Shading Techniques", Visual Computer, Vol 2, No 5,1986, p. 268-277.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Herman, G., Lui, H., "Three-Dimensional Display of Human Organs from Computed Tomograms", Computer Graphics and Image Processing, Vol 9, No 1, Jan.1979, p. 1-21.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J., Von Herzen, B., "Ray Tracing Volume Densities", Computer Graphics, Vol lg, No 3, 1984, p. 165-173.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Keppel, E., "Approximating Complex Surfaces by Triangulation of Contour Lines", IBM J. Res. Development, Vol. 19, 1975, p.1-21.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lee, M., Redner, R., Usetton, S., "Statistically Optimized Sampling for Distributed Ray Tracing", Computer Graphics, Vol 19, No 3, 1985, p. 61-67.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Lorensen, W., Cline, H,, "Marching Cubes: A High Resolution 3D Surface Construction Algorithm", Computer Graphics, Vol 21, No 4, 1987, p. 163-169.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Peachey, D., "Solid Texturing of Complex Surfaces", Computer Graphics, Vol 19, No 3, 1985, p. 279-286.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[PIXAR, "ChapVolumes Volume Rendering Package, Technical Summary", July, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6771</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Press, W., Flannery, B., Teukolsky, S., Vettering, W., "Numerical Recipes: The Art of Scientific Computing", Cambridge Univ. Press, 1986.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Upson, C., "The Visual Simulation of Amorphous Phenomena", Visual Computer, Vol 2, No5, 1986, p.321-326.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Watts, A., "Cloud-Hidden, Whereabouts Unknown; A Mountain Journal", Pantheon, New York, 1973.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wright, T., "A One-pass Hidden-line Remover for Computer Drawn Three-Space Objects", Proc. 1972 Summer Computer Simulation Conference, 1972, p.261-267.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Yost J., "Computational Fluid Dynamics for Realistic Image Synthesis", M.S. Thesis, University of Utah, Dept of Computer Science, August 1987]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 V-BUFFER: Visible Volume Rendering Craig Upson 
Stellar Computer, Inc. Milpitas, California Michael Keeler Ardent Computer Corp. Sunnyvale, California 
  1. Abstract This paper presents rendering techniques that use volumes as the basic geometric primitives. 
It defines data structures composed of numerous subvolumes, in excess of 100,000. Over each subvolume, 
a scalar field describes the variation of some physical quantity. The two rendering methods described 
herein assume a trilinear variation of this scalar field within each volume element, unlike voxel-based 
techniques that assume a constant value for each subvolume. The result is a higher order approximation 
of the structures within the volume. In addition, solid texture mapping, atmospheric attenuation, and 
transfer functions relating the dynamic range of the scalar field to color and opacity are used to isolate 
important data features. The result is a new method for the visualization of three-dimensional data resulting 
from numerical simulations and observations of natural phenomena. This method continuously covers the 
gap between surface-based and voxel-based techniques. CR Categories: 1.3.3, 1.3.5, 1.3.7 Keywo rds: Volume 
Rendering, Voxel, ]sosarface, Natural Phenomena, Ray Tracing 2. Introduction In ever increasing numbers, 
data sets are being generated that represent three-dimensional, volumetric information. These data are 
coming from complex computational simulations in many fields -from scientific experiments and sophisticated 
observations, particularly medical imaging. These volume datasets present a challenge to current imaging 
techniques to display clearly as much information contained throughout the domain as possible but not 
to restrict interpretation and analysis by simplifying the data for the sake of rendering ease. The fact 
that these datasets are very large and that numerical simulations can easily produce numerous data volumes 
as a time series in a single run compounds the problem. Volumelric data are typic011y a set of scalar 
or vector values defined on a grid in three-space. In most cases the grid is rectilinear and the data 
are either point values at the nodes or voxels representing a constant value for that volume element. 
Computational cells differ from voxels in that they are defined as the volume contained within the rectangular 
box bounded by eight comer nodes and, importantly, that the scalar function varies throughout the cell. 
Traditional techniques for visualizing such 3D volumes have consisted of either constructing wireframes 
or surfaces at a threshold value of the scalar field within the volume or using a cuberille representation 
for the constant-valued voxel. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and)or 
specific permission. &#38;#169; 1988 ACM-0-89791-275-6/88/008/0059 $00.75 One of the first methods of 
representing isosurfaces was to draw a mesh or net of vectors from sets of 2D line contours from each 
of two or three orthogonal planes (20). Because many datasets originate as a series of planar slices, 
especially in medical imaging, other algorithms were developed to generate polygonal surfaces from stacks 
of 2D contours. These processes work well enough on cases where the connectivity is fairly obvious (8,12), 
but they become complicated by ambiguous branching situations and must be resolved either by user interaction 
(4) or with a heuristic approach (6). A more general approach is to tile a surface using the cell information 
and to perform surface-volume intersection calculations at specific threshold levels (5,18,21). Recently, 
the Marching Cubes algorithm has been used to generate detailed surfaces and shading information from 
medical imaging data (14). Surface representations are appropriate when the goal is to show a boundary 
layer or a specific threshold within the volume. They are less useful in attempts to understand the whole 
of the volume, especially of an amorphous dataset, because by their nature, they display a small sample 
of the overall data and ignore the rest. Furthermore, the polygonal geometry of the surface is derived 
data created by a binary classification of the data (either the cell contains the surface threshold value, 
or it doesn't), and this limitation introduces biases and aliasing that can interfere with correct interpretation. 
The polygonal representation frequently requires more disk space (by a factor of four to ten for the 
examples in this papert) which presents an added burden on computational, and especially I/O, capabilities. 
Medical imaging technologies, such as computed tomography and other scanners, generate three-dimensional 
data by assigning intensity values to small, contiguous regions in the domain of interest. A cuberille 
model represents such data by decomposing the spatial extent with three regularly spaced, mutually orthogonal 
sets of parallel planes (10). Boundary surfaces are detected (1) and rendered as planar faces on voxel 
boundaries. Improvements to the shading algorithms have resulted in much smoother surface appearances 
(3). Recent hardware advances in computational power and especially in large and cheaper memories have 
spurred the development of other voxel- based rendering. PIXAR has developed a software package for its 
machine that enables a user to visualize volumetric data by classifying each voxeI with a constant value 
for color, opacity, and/or refractive index. Structures in the domaln's interior are displayed by deriving 
the optical depth from the opacity of the voxels along the viewing path and then summing their colors 
(16). In this method the resolution of the computed image is determined by the spatial resolution of 
the data, not by the sampling density of the pixels. Thus small data sets result in a very "blocky" image, 
and the only way to improve this is to resample the data at a higher frequency (in three space). Voxel-based 
renderers work directly upon the volume data and are therefore better at presenting a holistic view of 
the dataset. However, visualizations of smaller datasets suffer from the discretization and inherent 
implication that the variation from voxel to voxel is a discontinuous step function. A more sophisticated 
approach, using ray tracing to determine optical depth, is presented by Kayija and Von Herzen (tl). Their 
work is oriented toward modeling the scattering of light and energy within the volume to create visually 
realistic scenes with less emphasis on the enhancements needed for scientific visualization. t Volume 
data: 100 x 40 x 25 = 100K nodes, x 4 bytes/node = 4ooKbytes. As a surface of 50K polygons: 3 vertices/poly 
x 24 bytes/vertex x 50K polygons = 3.6Mbytes.  f SIGGRAPH '88, Atlanta, August 1-5, 1988 We present 
a visualization method that displays datasets of computational cells, that is, a scalar function S on 
a rectilinear (although not necessarily uniformly spaced) net of nodes: S(xi,Yj,Zk) i = 1, Ni j = 1, 
Nj k = 1,Nk ~xi = Cxi Ayj = Cyj ~ = Czk In numerical simulations, as in nature, there are few discontinuities 
and fewer step functions. Thus we can be assured that there is some smooth variation in this function 
between nodes of the domain mesh. However the actual form of this variation is not known. In fact the 
only statement that can be made concerning this variation is that it is not constant. In this work we 
assume that the variation between any two adjacent nodes is linear in space, and by assuming this simple 
functional form, we have minimized the amount of subjective interpretation of the data. By assuming that 
the variation is not constant, but rather a higher order interpolation, we can generate smoother representations 
of the underlying data - something that is essential for lower resolution datasets resulting from numerical, 
simulations. 3. The Visible Volume Method 3.1 Overview Two independent methods are employed for visibility 
detection. One method, ray-casting, processes all cells encountered by a view ray before moving onto 
the next ray (or pixel). The second method processes all pixels into which a cell projects before moving 
onto the next cell. A general summary of the method is as follows: First, a correlation is made between 
the screen coordinate system and the volume data. The cell/pixel combination that is to be processed 
is then determined by one of the two visibility detection methods. A traversal path within the cell is 
calculated and scalar values along the path are generated using a trilinear interpolation of the values 
at the cell's node points. At each evaluation point of the scalar field the object's properties are determined 
by mapping the scalar value to color and opacity via independent transfer functions, and additional data 
is added using three-dimensional texture mapping. Finally, these values are accumulated by integrating 
through the cell until either opacity reaches unity or the entire cell has been traversed, the algorithm 
then picks the next pixel or cell, depending on which algorithm is used. Other traditional cues for three-dimensional 
shape recognition are also used, such as depth cueing and illumination from light sources. Currently 
only ambient and diffuse shading have been implemented but an extension to other illumination models 
is straightforward. The traditional compromise between image quality and rendering time is handled by 
employing the two visible volume determination algorithms. In general, the faster method is a simplified 
ray casting technique while the higher-quality (and usually, but not always, slower) method is au object 
space-based celt-by-cell algorithm. 3.2 Interpolation Form As mentioned previously, the variation within 
a cell is linear in each axis, or trilinear in 3-space. The equation for this C 1 function is: S(x,y,z) 
= a 1 + a2x + a3Y + a4z + a5xY + a6xz + a7Yz + a8xYz (1) where the coefficients, ai, are determined 
by the matrix system: XijA j = S i (2) where Xij is an 8-by-8 matrix containing products of the coordinates 
of the corner nodes, Aj is the coefficient vector, and S i is the scalar value at the nodes. This system 
can be solved with an L-U decomposition method or by direct substitution. The advantage of the decomposition 
is that it is also used with a different fight-hand-side to determine the variation of the shading coefficients 
within the cell (us well as the texture map). It is more efficient simply to interpolate in 3-space to 
evaluate the scalar field within a cell, but this speed advantage rapidly disappears with repeated evaluations 
in the volume integration. When parameterized in distance from the viewpoint, the trilinear form becomes 
a cubic equation, and it is in this form that the interpolation takes place. 3.3 Object Properties and 
Transfer Functions Transparency, color, shading, and texture mapping are essential to effectively visualize 
the scalar field using a volume-based renderer. Opacity, the inverse of transparency, is defined as a 
transfer function of the scalar field. Thus there is a mapping from the dynamic range of the variation 
in the scalar field into a range of opacities: O(S(x,y,z)). Similarly there is a mapping from the range 
of the scalar field into color space via additional transfer functions: R(S(x,y,z)), G(S(x,y,z)), B(S(x,y,z)). 
In this manner, relevant structures in the domain can be isolated via a variation in opacity and highlighted 
via color. The transfer functions can be specified to show a variation in the scalar field as a smooth 
gradation in color or opacity (Figure la), or object features occuring at particular scalar ranges may 
be highlighted by a mapping such as that in Figure lb. Isosurfaees at a particular threshold are obtained 
by specifying the opacity transfer function as a step function with a large discontinuity on the opacity 
axis over a relatively narrow range of scalar values (Figure lc). In addition, solid-texture mapping 
(15) is used to facilitate the correlation of multiple scalar fields at one time. 3.4 Visible Volume 
Detection 3.4.1 Method 1: Ray Casting Two techniques are employed for the determination of visibility. 
The faster method is similar to a ray tracing method (11) but with higher order interpolation, subeell 
quadrature, and enhanced efficiency due to the simple data structure (and no interobject effects such 
as shadowing). In this method, rays emanate from the viewpoint, pass through pixels in the view plane, 
and intersect the data volume. At each pixel, a ray is tracked through the volume until either the accumulated 
opacity reaches unity or the volume is exhausted, at which time the accumulated colors and opacity are 
stored and " the processing moves onto the next pixel. The scalar function is evaluated at the nearest 
face of each cell along its path and is stepped along until it traverses the entire cell with evaluations 
of the scalar field, shading function, opacity, texture map, and depth cueing at each stepping point. 
As the slope of the ray determines which three of six faces it can penetrate on any given cell, the probability 
of a ray intersecting a given face perpendicular to a coordinate axis is inversely proportional to the 
slope of the ray with respect to that axis. In this manner, the testing for penetration can be minimized. 
The intersections of the ray with respect to each set of parallel planes (aligned with the coordinate 
axis) can also be generated and the three lists merged after all have been calculated. Although this 
requires no testing during the intersection generation, it is slower in the merge stage. This technique 
also generates the entire traversal through the data volume when, in fact, the ray will probably terminate 
early due to its accumulated opacity. At the expense of vectorization, we have chosen to integrate the 
pixel color and opacity as the ray is lrackeed, rather than to generate the entire traversal list for 
several pixels and integrate them at once in vector loops. In this manner the reduced efficiency of scalar 
processing is more than compensated by the saved operations. The integration to determine opacity and 
color is snnin $rnax '01 ~ smin ~J ~ ~, smax smin Smax A B C Figure 1. Examples of transfer functions 
mapping scalar value m color or opacity.    ~' ~ Computer Graphics, Volume 22, Number 4, August 1988 
 I II similar to the second method and will be presented in another section of this paper. 3.4.2 Method 
2: Celt-by-Cell Processing The alternative method of visibility determination is object-space oriented 
and is based on sweeping through the domain processing one cell at a time. Because the database is very 
simple in structure, it is possible to determine a cell processing order that completely determines which 
cells occlude, or partially occlude, others. Cells are processed starting with those on the plane closest 
to the the viewpoint and progress plane by plane until the farthest cells have been processed. The processing 
order of cells within each plane proceeds from the closest cell to those adjoining this cell according 
to their distance from the viewpoint. This results in a concentric sweep about the initial cell (Figure 
2). After the first cell's contribution is computed several other cells can be processed concurrently 
because they will not overlap in screen space. i!i!i!i!iii!i!i!i!i!i!!!i!i!iii!!i~ii!!! .......... i:i:i:i:i:~>'i:i:i: 
~ili!ii!iiiiii!iiiiiii 2 3 .....,-.-.-.,~..~ ::::::::::::::::::: ".'-'-'-'-"~'.'~ ::::::::::::::::::: 
!iiiilil;iiiiiiiiiil;i 3 i i!!iiiiiiiiii!iii~iii~: 4 ............. ,,~ ;i!~!iiiiiilililililili 5 Figure 
2. Cells numbered by processing priority. Cells with the same number do not affect each other and thus 
may be processed in parrallel. In this technique the trilinear interpolation coefficients are computed 
for the scalar, shading, and texture mapping functions, and a bounding box for the cell is determined. 
The bounding box is clipped to each scanline creating pixel runs. Integration (in depth) occurs at the 
four comers of each pixel in the run into which the cell projects. These evaluations are then averaged 
resulting in the current pixel color and opacity. For each scanline in the bounding box, the cell is 
intersected with the scan plane and the resulting convex polygon is broken down into at most five spans 
(Figure 3). The pixels are then integrated from front to back similarly to the ray casting method. However, 
all spatial functions -opacity, shading, and texture mapping -vary as a cubic function within the cell 
making evaluations efficient and vectorizable. Because the functional form is known, an explicit variable-stepsize 
quadrature method can be used for depth integration, thus further reducing the computations. Once a cell 
has been processed, the technique moves onto the next cell in its predetermined order. In this manner 
the visibility determination is the volumetric analog of a traditional Z-Buffer algorithm, and as such, 
it might be possible to implement in hardware. In addition, because this is a front to back algorithm, 
it lends itself to incremental display during the visibility determination. In this method a large fraction 
of the visible image is computed early in the process while refinements occur later and more slowly. 
This is different than other methods of adaptive refinement (2) in that the representation (volumetric) 
remains the same during the refinement process, and improvements later on add information farther from 
the viewpoint. Thus the user is able to terminate a rendering process early either if any of the viewing 
parameters are obviously wrong or if only qualitative behavior is required. The effect on the screen 
as each cell is processed and pix¢ls are updated is visually akin to what one might experience watching 
a fog-shrouded hillside as the fog recedes and ever more detail of the landscape is revealed (19). 3.4.3 
Comparison of the two Methods Three criteria have been chosen to compare the two methods: memory requirements, 
antialiasing, and computational efficency. Memory requirements: The ray casting method requires that 
the scalar, shading, and texture map function coefficients for all active cells projecting into the current 
pixel be in memory at once. For some images in which the object occupies a small amount of screen space, 
these coefficients could consume a substantial amount of memory (up to 16MB for a 64*64*64 cell domain). 
The cell-by-cell method, on the other hand, needs only the current cells' interpolation coefficients 
in memory, but it may require the entire frame buffer if a single cell projects into the entire screen 
(1.3MB for video resolution). Antinliasing: Because the ray casting technique is essentially a point 
sampling method, the only straight forward approach to antialias the image is by way of distributed ray 
casting (7,13) with several ray samplings per pixel. However the cell-by-cell method does lend itself 
to a nearly analytic solution in the integration. With this method one can choose a small number of sample 
points within a cell to analytically integrate the function exactly. Our current implementation does 
not go to this effort because the images produced by this volumetric renderer are generally without distinct 
boundaries. Thus we find the object-space non-analytic antialiasing currently implemented in the cell-by-cell 
method to be sufficient for our needs. Computation efficiency: A comparison of computational efficiency 
between the two methods falls into two catagories: image-space and object-space issues. The image-space 
criteria are based on coherency, veectorization, and parallelism. The object-space issues are based on 
volume culling and optical depth issues. Vectorization of the ray caster is difficult because there are 
few occasions when enough information has been collected to make vectorization pay off. In the cell-by-cell 
method, vectorization occurs along a span within a cell. This method most naturally parallelizes at the 
scan line level while the ray caster, like its ray tracing relatives, parallelizes at the pixel level. 
The cell-marching method could be implemented on a highly parallel machine in which each floating point 
processor has only a modest amount of local memory. The ray caster would require a global shared memory. 
Both techniques examine each cell prior to processing to determine whether or not there is any visible 
material. The dynamic range of the scalar field within the cell is mapped into its corresponding opacity 
range. Both methods cull the volume if the summation of the opacity is zero while the cell method also 
tests on the scan plane and pixel levels to farther reduce possible work. Another object space concern 
that affects the efficiency of the two methods is the average optical depth. This is the number of cells 
that an average pixel must traverse before it becomes opaque. In general the ray caster is much more 
efficient when the object is fairly opaque, and the cell- by-cell method can reach the same efficiency 
when the object is quite transparenL The latter technique also improves as the field of view decreases 
and thus the average span length does not decrease much with depth. In conclusion, the ray caster is 
generally more efficient for conventional machine architectures and opaque data volumes while the cell 
by cell method holds the greatest potential for vector and highly parallel machines, Image Plum Sem Llm 
Intersection Prok,ctJon~ seal P~,~e Figure 3. Determination of the spans for the cell-by-cell technique. 
 SIGGRAPH '88, Atlanta, August 1-5, 1988 3.5 Nodal Shading Function The shading coefficients are determined 
on a node-by-node basis prior to the visibility calculation. These coefficients are a function of the 
dot product of the surface normal at the node point and the light sources. Because the rendering technique 
is not surface oriented, a normal vector does not exist and is replaced by a normal space of dimensionality 
three. For illumination effects, however, we assume that the sample point lies on a level surface. The 
normal at a point on a level surface is the gradient, and this is used for the dot product with the light 
source. Because the interpolation function is continuous within the cell, the gradient (or normal) could 
be analytically calculated from this. However, the interpolation form is not differentiable at the cell 
boundaries, and thus any shading based on this analytical differentiation will show anomalies from cell 
to cell. To avoid this problem, finite differences are used to approximate the gradient of the field 
at the node points. The normal function, when interpolated similar to the scalar field, is then a continuous 
function over the cell and continuous but not differentiable between cells. The dot product of the normal 
vector at a node and the light source vector(s) is then stored as the nodal shading function. If the 
light sources and the object remain in the same orientation relative to each other, then this shading 
function is not recomputed from frame to frame. 3.6 Integration and the Illumination Model The intent 
of this visualization technique is to represent abstract datasets of natural phenomena while minimizing 
the amount of subjective aesthetics during the image creation process. In this regard, this work differs 
from others whose goals are to simulate the visual aspects of the phenomena realistically. Our goal allows 
us to simplify the illumination model to the bare minimum needed to represent the data. On the other 
hand, we desire to have as much flexibility as possible with regard to feature isolation, and therefore 
we have additional transfer functions imbedded in the illumination model. Hall (9) has categorized illumination 
models into three basic types: empirical (incremental), true geometric (ray tracing), and analytical 
(radiosity). The illumination model used here is empirical, employing true geometry for pixel calculations 
with some simplifications: I( X ) = Ka( X )1 a + Kd( % )~.,(N*I.3)Ij (a) Here I( ~ ) is the perceived 
intensity as a function of wavelength (%), K a is the ambient coefficient, t a is the ambient intensity, 
K d is the diffuse coefficient, N is the local gradient, L i is the jth light source vector, and Ij is 
the diffuse int~hsity of the i th light source.We have chosen to leave out the specular term as it adds 
few visual cues in an object without distinct surfaces (although it is easy to add).In actuality the 
diffuse coefficient is a function of more than the wavelength: Where K is the actual diffuse coefficient, 
T d is the object color transfer function, and M is the solid texture map color. The determination of 
a pixers color is the result of a three-dimensional integration from front to back.The cell-by-cell method 
sums contributions from all ceils that project into the pixel, while the ray caster may miss some cells 
due to sampling errors. For some pixels the integration will terminate before all cells have been included 
because the amount of material already encountered has summed to the maximum opacity. The two visibility 
methods perform essentially the same integration with the exception that the ray caster is a point sampling-technique 
and the cell-by- cell is a volume-approximation method. We present the integration details for the cell 
method because the ray caster is a simplification of the former. The integral is as follows: I(%) = J'x 
Jy Sz[ l(d)O(S)iKa( % )ta + Kd( X,,S,M)~(N*Li)Ii] + (1 - f(d))bg( % )]dxdydz (5) where f(d) is the normalized 
atmospheric attenuation as a function of distance (depth cueing), O is the optical depth per unit density 
and is a transfer function of the scalar field O(S(x,y,z)), and bg(X) is the background intensity as 
a function of frequency. The limits of integration are determined by clipping the pixel to the span (Figure 
4). The integral is approximated as a discrete summation by evaluating the scalar, opacity, texture map, 
depth cuing, and shading functions at the corners of the clipped pixel on the nearest face and then by 
stepping through the sub-volume in depth accumulating intensity and opacity using trapezoid rule quadrature 
(17). This summation is continued until either the cell is exhausted or the accumulated opacity reaches 
unity. If the opacity exceeds the fftaximum in a step, then the correct termination point at which opacity 
reaches unity is determined and the functions are evaluated at that point. Once a pixel is opaque, it 
is flagged and not processed again, A voxel apprd~ximation is used ff the entire cell projects into a 
pixel. In this case, the functions (scalar field, opacity, shading, and texture maps) evaluated at the 
corner points of the cell are averaged into a single contribution that is multiplied by the pixel coverage 
and stored. Traditional voxel rendering has also been implemented as an option of the cell-by-cell technique. 
In this case, a cell will be processed as a constant-valued voxel or as a continuous cell depending on 
criteria supplied by the user. 4. Examples Two examples taken from the computational sciences have been 
chosen to illustrate this technique. All figures were rendered with the cell-by-cell technique for maximum 
image quality. The first, from computational fluid dynamics, is the result of a three- dimensional, 
transient calculation of turbulent shear flow of two fluids on a 50 by 40 by 100 cell grid. The top fluid 
is traveling at roach 1.1 while the lower fluid is stationary. The result of their interaction is a turbulent 
interface along the shear plane. The scalar quantity depicted is a derivation of the mass fraction of 
one fluid with respect to the other. In this image (Figure 5), simple piece-wise linear variation is 
used for the nodal color and opacity transfer functions with shading effects. Cells containing only one 
fluid or the other are completely transparent, while those with a mixture are semi-opaque. This representation 
is contrasted with a surface technique (using a polygonal tiler (18)) in Figure 6 in which the stationary 
fluid is shown, Evident in the volumetric rendering is that the mixing is not confined to a narrow region 
in space and that the thickness of the mixing layer is far from uniform as seen in the color variation. 
The second example, from computational meterology, is the result of a finite difference simulation on 
a grid of 109 by 109 by 31 ceils. In this numerical experiment a severe storm resembling a tornado is 
simulated. The variable shown in Figure 7 is the rain water content as a function of three space during 
the storm's evolution. In this image three spikes are used in the color and opacity transfer functions 
to isolate a range of water content within the cloud with no shading effects. This is contrasted with 
Figure 8 in which shading from a light source is used to give a better three-dimensional perception. 
A step function in the opacity transfer function is used (in the red region) to show a distinct, opaque 
surface, thus demonstrating the surface rendering capabilities of the method. In Figure 9 the rain water 
field is texture mapped with another field variable, the vertical vorticity. In this manner one can 
correlate the destructive wind effects (due to the intense circulation) with the most obvious visual 
representation of a cloud: the moisture content due to rain water. The red color indicates high values 
of vertical vorticity, especially apparent in the tornado's funnel region. The funnel image is nearly 
~ansparent at the ground tevet, implying low moisture contetat, a phenomenon commonly observed in tornados. 
At the top of the funnel the Dat| Cell Figure 4. Integration volume for a single cell.  SIGGRAPH '88, 
Atlanta, August 1-5, 1988 color transitions to white denoting a drop to near zero vertical vorticity. 
At this point the image is opaque due to high rain water content. The conclusion is that atmospheric 
material enlrained in the funnel is swept up vertically until it reaches the anvil of the cloud. Here 
the storm weakens and water precipitates, thus forming a squall-line behind the tornado. 5. Conclusion 
The V-Buffer has several advantages over other methods of visualizing volumetric data sets. Of primary 
importance is that the data are considered point samples at nodes and that the scalar field is assumed 
to vary within each computational cell. This is a more accurate representation of the real world and 
allows for smooth, continuous representations of even small datasets. Analysis and exploration of the 
data is enhanced by easily modified transfer functions for color and opacity. Depth information is conveyed 
by both attenuation and shading. Three-dimensional texture mapping is available to correlate multiple 
scalar fields at once. The effects possible with this volumetric technique range continuously from a 
surface representation, by using a step function in the opacity transfer function and shading, to an 
amorphous transparent wisp of form, with the opacity nearly zero and no shading. This method uniquely 
combines the capabilities of volumetric rendering with variable transparency and solid texture mapping 
to provide the visual cues required for insight into complex three-dimensional phonenomena, such as the 
tornado example above. The V-Buffer is designed as an analytic tool, not as a technique to synthesize 
realistic images. The illumination model is sufficient to render a smooth image and minimizes other visual 
effects that may bias the interpretation. This algorithm, while inefficient for some very large volamelric 
datasets where projected voxels are sufficiently small relative to pixels, can be accurately used in 
such cases. Obvious enhancements would be to provide boolean operations on volume datasets that will 
allow additional viewing options, such as cut- away sections and internal clipping. Although such operations 
may be performed ~ a preprocessing step, the size of the data calls for these abilities to be built into 
the renderer. Also, this volume technique could be integrated with traditional surface renderers so that 
various types of data can be displayed simultaneously. 6. Acknowledgement This work was done at the 
National Center for Supercomputer Applications, Champaign, Illinois, and the San Diego Supercomputer 
Center, San Diego, California. 7. References 1. Artzy, E., Frieder, G., Herman, G., "The Theory, Design, 
Implementation and Evaluation of a Three-Dimensional Surface Detection Algorithm", Computer Graphics 
and Image Processing, Vol 15, No 1, Jan. 1981, p. 1-24. 2. Bergman, L., Fuchs, H., Grant, E., "Image 
Rendering by Adaptive Refinement", Computer Graphics, Vol 20, No 4, Aug. 1986, p. 29-37 3. Chen, L., 
Herman, G., Reynolds, R., Udupa, J., "Surface Shading in the CuberiUe Environment", IEEE Computer Graphics 
and Applications, Vol 5, No 12, Dec. 1985, p. 33-43. 4. Christiansen, H., Sederberg. T., "Conversion 
of Complex Contour Line Definitions into Polygonal Element Mosaics", Computer Graphics, Vol 12, No 3, 
1978, p. 187-192. 5. Christiansen, H., Stephenson, M., Nay, B., Grimsrud, A., "Movie.BYU Training Text", 
Graphics Utah Style, Provo, Utah, 1987. 6. Cook, L., Dwyer, S., Batnitzky, S., Lee, K., "A Three-Dimensional 
Display System for Diagnostic Imaging Applications", IEEE Computer Graphics &#38; Applications, Vol 3, 
No 5, Aug. 1983. p. 13-19. 7. Cook, R., Porter, T., Carpenter, L., "Distributed Ray Tracing", Computer 
Graphics, Vol 18, No 3, 1984, p. 137-145.  8. Fuchs, H., Kedem, Z., Uselton, S., "Optimal Surface Reconstruction 
from Planar Contours", CACM, Vol 20, 1977, p.693-712. 9. Hall, R., "A Characterization of Illumination 
Models and Shading Techniques", Visual Computer, Vol 2, No 5,1986, p. 268-277. 10. Herman, G., Lui, 
H., "Three-Dimensional Display of Human Organs from Computed Tomograms", Computer Graphics and Image 
Processing, Vol 9, No 1, Jan.1979, p. 1-21. 11. Kajiya, J., Von Herzen, B., "Ray Tracing Volume Densities", 
Computer Graphics, Vol lg, No 3, 1984, p. 165-173. 12. Keppel, E., "Approximating Complex Surfaces by 
Triangulation of Contour Lines", IBM J. Res. Development, Vol. 19, 1975, p.l-21. 13. Lee, M., Redner, 
R., Usetton, S., "Statistically Optimized Sampling for Distributed Ray Tracing", Computer Graphics, Vol 
19, No 3, 1985, p. 61-67. 14. Lorensen, W., Cline, H,, "Marching Cubes: A High Resolution 3D Surface 
Construction Algorithm", Computer Graphics, Vol 21, No 4, 1987,  p. 163-169. 15. Peachey, D., "Solid 
Texturing of Complex Surfaces", Computer Graphics, Vol 19, No 3, 1985, p. 279-286. 16. PIXAR, "ChapVolumes 
Volume Rendering Package, Technical Summary", July, 1987. 17. Press, W., Flannery, B., Teukolsky, S., 
Vettering, W., "Numerical Recipes: The Art of Scientific Computing", Cambridge Univ. Press, 1986. 18. 
Upson, C., "The Visual Simulation of Amorphous Phenomena", Visual Computer, Vol 2, No5, 1986, p.321-326. 
 19. Watts, A., "Cloud-Hidden, Whereabouts Unknown; A Mountain Journal", Pantheon, New York, 1973. 20. 
Wright, T., "A One-pass Hidden-line Remover for Computer Drawn Three-Space Objects", Proc. 1972 Summer 
Computer Simulation Conference, 1972, p.261-267. 21. Yost J., "Computational Fluid Dynamics for Realistic 
Image Synthesis", M.S. Thesis, University of Utah, Dept of Computer Science, August 1987   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378484</article_id>
		<sort_key>65</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Volume rendering]]></title>
		<page_from>65</page_from>
		<page_to>74</page_to>
		<doi_number>10.1145/54852.378484</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378484</url>
		<abstract>
			<par><![CDATA[A technique for rendering images of volumes containing mixtures of materials is presented. The shading model allows both the interior of a material and the boundary between materials to be colored. Image projection is performed by simulating the absorption of light along the ray path to the eye. The algorithms used are designed to avoid artifacts caused by aliasing and quantization and can be efficiently implemented on an image computer. Images from a variety of applications are shown.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer tomography]]></kw>
			<kw><![CDATA[image processing]]></kw>
			<kw><![CDATA[magnetic resonance imaging (MRI)]]></kw>
			<kw><![CDATA[medical imaging]]></kw>
			<kw><![CDATA[non-destructive evaluation (NDE)]]></kw>
			<kw><![CDATA[scientific visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P335091</person_id>
				<author_profile_id><![CDATA[81410595901]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Drebin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31024422</person_id>
				<author_profile_id><![CDATA[81100040066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Loren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carpenter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15033698</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pixar, San Rafael, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA["Why Abalones Don't Find Otters Cute," Discover, p. 10 (April 1988).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[ADAMS, JOHN B., MILTON O. SMITH, AND PAUL E. JOHNSON, "Spectral Mixture Modeling: A New Analysis of Rock and Soil Types at the Viking 1 Lander Site," Journal of Geophysical Research 91(B8) pp. 8098-8112 (July 1986).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[BLINN, JAMES F., "Light Reflection Functions for Simulation of Clouds and Dusty Surfaces," Computer Graphics (SIG- GRAPH '82 Proceedings) 16(3) pp. 21-29 (July 1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BLOOMENTHAL, JULES, "Polygonization of Implicit Surfaces," Report CSL-87-2, Xerox PARC (May 1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807505</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[CATMULL, EDWIN AND ALVY RAY SMITH, "3-D Transformations of Images in Scanline Order," Computer Graphics (SIG- GRAPH '80 Proceedings) 14(3) pp. 279-285 (July 1980).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807388</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[CHRISTIANSON, H. N. AND T. W. SEDERBERG, "Conversion of Complex Contour Line Definitions into Polygonal Element Mosaics," Computer Graphics (SIGGRAPH '78 Proceedings) 12 pp. 187-192 (1978).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[CLINE, HARVEY E., WILLIAM E. LORENSEN, SIGWALT LUDKE, CARL R. CRAWFORD, AND BRUCE C. TEETER, "Two Algorithms for the Reconstruction of Surfaces from Tomograms," Medical Physics, (June, 1988).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[COOK, ROBERT L. AND KENNETH E. TORRANCE, "A Reflection Model for Computer Graphics," ACM Transactions on Graphics 1(1) pp. 7-24 (1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[DREBIN, ROBERT A., ELLIOT K. FISHMAN, AND DONNA MAGID, "Volumetric Three-dimensional Image Rendering: Thresholding vs. Non-thresholding Techniques," Radiology 165p. 131 (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[FISHMAN, E. K., R. A. DREBIN, D. MAGID, AND ET. AL., "Volumetric Rendering Techniques: Applications for 3- Dimensional Imaging of the Hip," Radiology 163 pp. 737-738 (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[FUCHS, H., Z. M. KEDEM, AND S. P. USELTON, "Optimal Surface Reconstruction for Planar Contours," CACM 20(1977).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>13044</ref_obj_id>
				<ref_obj_pid>13043</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[FUJIMOTO, AKIRA, TAKAYUKI TANAKA, AND KANSEI IWATA, "ARTS: Accelerated Ray-Tracing System," IEEE Computer Graphics and Applications, pp. 16-26 (Apr. 1986).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801264</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[GANAPATHY, S. AND T. G. DENNEHY, "A New General Triangulation Method for Planar Contours," Computer Graphics (SIGGRAPH '82 Proceedings) 16 pp. 69-75 (1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[HARRIS, LOWELL D., R. A. ROBB, T. S. YUEN, AND E. L. RIT- MAN, "Non-invasive numerical dissection and display of anatomic structure using computerized x-ray tomography," Proceedings SPIE 152 pp. 10-18 (1978).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[HERMAN, GABOR T. AND H. K. LIU, "Three-Dimensional Display of Organs from Computed Tomograms," Computer Graphics and Image Processing 9(1) pp. 1-21 (January 1979).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[HOEHNE, KARL HEINZ, ROBERT L. DELAPAZ, RALPH BERN- STEIN, AND ROBERT C. TAYLOR, "Combined Surface Display and Reformatting for the Three-Dimensional Analysis of Tomographic Data," Investigative Radiology 22(7)pp. 658- 664 (July 1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[JAFFEY, STEPHEN M. AND KALYAN DUTTA, "Digital Perspective Correction for Cylindrical Holographic Stereograms," Proceedings of SPIE 367(August 1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, JAMES T. AND BRIAN P. VON HERZEN, "Ray Tracing Volume Densities," Computer Graphics (SIGGRAPH '84 Proceedings) 18(3)(July 1984).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[KEPPEL, E., "Approximation of Complex Surfaces by Triangulation of Contour Lines," IBM Journal of Research and Development 19 pp. 2-11 (1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[LEVOY, MARC, "Display of Surfaces from Volume Data," IEEE Computer Graphics and Applications, (May, 1988).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[LORENSEN, WILLIAM E. AND HARVEY E. CLINE, "Marching Cubes: A High Resolution 3D Surface Construction Algorithm," Computer Graphics (SIGGRAPH '87 Proceedings), (July 1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[MAZZIOTTA, J. C. AND K. H. HUANG, "THREAD (Three- Dimensional Reconstruction and Display) with Biomedical Applications in Neuron Ultrastructure and Display," American Federation of Information Processing Society 45 pp. 241-250 (1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[MEAGHER, DONALD J., "Efficient Synthetic Image Generation of Arbitrary 3-D Objects," Proceedings of the IEEE Computer Society Conference on Pattern Recognition and Image Processing, pp. 473-478 (June 1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801263</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[NORTON, ALAN, "Generation and Display of Geometric Fractals in 3-D," Computer Graphics (SIGGRAPH '82 Proceedings) 16(3) pp. 61-67 (July 1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[PHONG, BUI-THONG, "Illumination for Computer Generated Images," CACM 18(6) pp. 311-317 (June 1975).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[PORTER, THOMAS AND TOM DUFF, "Compositing Digital Images," Computer Graphics (SIGGRAPH '84 Proceedings) 18(3) pp. 253-260 (July 1984).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[SCHLUSSELBERG, DANIEL S., WADE K. SMITH, AND DONALD J. WOODWARD, "Three-Dimensional Display of Medical Image Volumes," Proceedings of NCGA, (March 1986).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[SCOTT, W. W. JR., E. K. FISHMAN, AND D. MAGID, "Acetabular Fractures: Optimal Imaging," Radiology, pp. 537-538 (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807390</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[SUNGURUFF, A AND D. GREENBERG, "Computer Generated Images for Medical Applications," Computer Graphics (SIG- GRAPH '78 Proceedings) 12 pp. 196-202 (1978).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[TOM, VICTOR T., "Adaptive Filter Techniques of Digital Image Enhancement," SPIE Digital Image Processing: Critical Review of Technology 528(1985).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[TUY, HEANG K. AND LEE TAN TUY, "Direct 2-D Display of 3-D Objects," IEEE Computer Graphics and Applications 4(10) pp. 29-34 (October 1984).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>801157</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[VANNIER, MICHAEL W., JEFFREY L. MARSH, AND JAMES O. WARREN, "Three Dimensional Computer Graphics for Craniofacial Surgical Planning and Evaluation," Computer Graphics" (SIGGRAPH '83 Proceedings) 17(3)pp. 263-273 (July 1983).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807442</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[WRIGHT, THOMAS AND JOHN HUMBRECHT, "ISOSURF - An Algorithm for Plotting Iso-Valued Surfaces of a Function of Three Variables," Computer Graphics (SIGGRAPH '79 Proceedings) 13(2) pp. 182-189 (August 1979).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[WYVILL, BRIAN, CRAIG MCPHEETERS, AND GEOFF WYVILL, "Data Structure for Soft Objects," The Visual Computer 2(4) pp. 227-234 (1986).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[ZUCKER, STEVEN W., "Relaxation Labelling and the Reduction of Local Ambiquities,'" Proceedings 3rd International Conference on Pattern Recognition, pp. 852-861 (November 1976).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 i uu DRill li i Volume Rendering Robert A. Drebin, 
Loren Carpenter, Pat Hanrahan Pixar San Rafael, CA Abstract A technique for rendering images Of volumes 
containing mixtures of materials is presented. The shading model allows both the interior of a material 
and the boundary between materials to be colored. Image projection is performed by simulating the absorption 
of light along the ray path to the eye. The algorithms used are designed to avoid artifacts caused by 
aliasing and quantization and can be efficiently implemented on an image computer. Images from a variety 
of applications are shown. CR Categories: 1.3.3 [Computer Graphics] Computational Geometry and Object 
Modeling -Curve, surface, solid, and object representations. 1.3.5 [Computer Graphics] Three-Dimensional 
Graphics and Realism -Color, shading, shadow- ing and texture; Visible line/surface algorithms. Additional 
Keywords and Phrases: Medical imaging, com-puted tomography (CT), magnetic resonance imaging (MRI), non-destructive 
evaluation (NDE), scientific visualization, image processing. Introduction Three-dimensional arrays 
of digital data representing spa- tial volumes arise in many scientific applications. Computed tomography 
(CT) and magnetic resonance (MR) scanners can be used to create a volume by imaging a series of cross 
sec-tions. These techniques have found extensive use in medicine, and more recently, in non-destructive 
evaluation (NDE). Astrophysical, meteorological and geophysical measurements, and computer simulations 
using finite element models of stress, fluid flow, etc., also quite naturally generate a volume data 
set. Given the current advances in imaging devices and computer processing power, more and more applications 
will generate Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. &#38;#169; 1988 ACM-0-89791-275-6/88/008/0065 $00.75 volumetric data in the future. Unfortunately, 
it is difficult to see the three-dimensional structure of the interior of volumes by viewing individual 
slices. To effectively visualize volumes, it is important to be able to image them from different viewpoints, 
and to shade them in a manner which brings out surfaces and subtle variations in density or opacity. 
Most previous approaches to visualizing volumes capital- ize on computer graphics techniques that have 
been developed to display surfaces by reducing the volume array to only the boundaries between materials. 
Two-dimensional contours from individual slices can be manually traced (Mazziotta, 1976) or automatically 
extracted (Vannier, 1983) and con-nected to contours in adjacent slices to form triangle strips (Keppel, 
1975,Fuehs, 1977, Christianson, 1978, Ganapathy, 1982) or higher order surface patches (Sunguruff, 1978). 
These techniques have problems with branching structures, particularly if the distance between serial 
sections is large rela- tive to the size of the volume elements or voxels. Other surface techniques output 
polygons at every voxel. The cuberille tech-nique first sets a threshold representing the transition 
between two materials and then creates a binary volume indicating where a particular material is present. 
Each solid voxel is then treated as a small cube and the faces of this cube are output as small square 
polygons (Herman, 1979). Adjacent cubes can be merged to form an oct-tree; this representation compresses 
the original voxel array and reduces the subsequent processing requirements (Meagher, 1982). The marching 
cubes technique places the sample values at the vertices of the cube and esti- mates where the surface 
cuts through the cube (Lorensen, 1987). A variation of this technique, called the dividing cubes algorithm, 
approximates the polygon with points (Cline, 1988). These techniques are analogous to algorithms used 
to extract surfaces from implicit functions (Norton, 1982, Bloomenthal, 1987,Wyvill, 1986), or to produce 
three-dimensional contour maps (Wright, 1979). Several researchers have developed methods which directly 
image the volume of data. The additive reprojection technique computes an image by averaging the intensities 
of voxels along parallel rays from the rotated volume to the image plane (Harris, 1978,Hoehne, 1987). 
This has the effect of simulating an x-ray image. The source-attenuation reprojec- tion technique assigns 
a source strength and attenuation coefficient to each voxel which allows for object obscuration (Jaffey, 
1982, Schlusselberg, 1986). Attenuation coefficients are often referred to as opacities. Depth shading 
algorithms trace rays through the volume array until they hit a surface and  SIGGRAPH '88, Atlanta, 
August 1-5, 1988 then assign an intensity inversely proportional to the distance to the eye (Vannier, 
1983). This is usually referred to as depth cueing in the computer graphics literature. Radiation transport 
equations have been used to simulate transmission of light through volumes (Kajiya, 1984). The low-albedo 
or single scattering approximation has also been applied to model reflectance functions from layered 
volumes (Blinn, 1982). Several of these algorithms require the ability to trace rays in any direction 
through a volume array. Various algorithms for ray tracing volumes are described in (Fujimoto, 1986,Tuy, 
1984,Levoy, 1988, Schlusselberg, 1986) An implicit assumption in surface rendering algorithms is that 
a model consisting of thin surfaces suspended in an environment of transparent air accurately represents 
the origi- nal volume. Often the data is from the interior of a fluid-like substance containing mixtures 
of several different materials. Subtle surfaces that occur at the interface between materials, and local 
variations in volumetric properties, such as light absorption or emission, are lost if the volume is 
reduced to just surfaces. Also, since a voxel represents a point sample, infor- mation about the exact 
position and orientation of microsur- faces may be lost in the sampling process, and it is not reason- 
able to expect to be able to recover that information. The technique presented in this paper deals with 
volumes directly. The volume array is assumed to be sampled above the Nyquist frequency, or if this is 
not possible, it is assumed that the continuous signal is low-pass filtered to remove high frequencies 
that cause aliasing. If this criterion is met, the ori- ginal continuous representation of the volume 
can be recon-structed from the samples. The sampled volume will look smooth and realistic, and artifacts 
such as jagged edges will not be present. Each stage in the volume rendering algorithm is designed to 
preserve the continuity of the data. Thresholding and other highly non-linear operations are avoided, 
and when geometric transformations are applied to the data, the result is resampled carefully. The goal 
is to avoid introducing compu- tational artifacts such as aliasing and quantization, since these interfere 
with the viewer's ability to interpret the data. Overview of the Algorithm Figure 1 shows a process diagram 
of the volume render- ing algorithm. Associated with each stage is a slice from a volume corresponding 
to the stage. The first step in using the volume rendering algorithm is to convert the input data volume 
to a set of material percentage volumes. The values in each voxel of the material percentage volumes 
are the percentage of that material present in that region of space. These material percentage volumes 
either can be input directly, or can be determined from the input data volumes using probabilistic classification 
techniques. Many different classification tech- niques are possible and the one of choice depends on 
the type of input data. The classification of a CT volume data set is shown in Figure 1. Given any material 
property and the material percentage volumes, a composite volume corresponding to that property can be 
calculated by multiplying the percentage of each material times the property assigned to that material, 
For example, a composite color volume is formed by summing the product of the percentage of each material 
times its color. An opacity volume is computed by assigning each material an opa- city value. In Figure 
1, the color volume shown is actually the product of the color and the opacity volume. Boundaries between 
materials are detected by applying a three-dimensional gradient to a density or p volume. The p volume 
is computed from the material percentage volumes by assigning a 19 value to each material, The gradient 
is largest where there are sharp transitions between materials with dif- ferrent p's. The magnitude of 
the gradient is stored in a surface strength volume and is used to estimate the amount of surface present. 
The direction of the gradient is stored in the surface normal volume and is used in shading computations. 
The shaded color volume represents the sum of the light emitted by the volume and scattered by the surfaces. 
The rela- tive contributions of volume emission and surface scattering can be varied depending on the 
application. The reflected component is computed using a surface reflectance function whose inputs are 
the position and color of the light sources, the position of the eye, the surface normal volume, the 
surface strength volume, and the color volume. The amount of emitted light is proportional to the percentage 
of luminous material in the voxet. To form an image, the shaded volume is first transformed and resampled 
so that it lies in tl'ie viewing coordinate system. In many cases the transform is just a rotation. Figure 
I shows the result as the transformed volume. In this coordinate system the eye is at infinity, so all 
rays are parallel to an axis of the volume. An image of the rotated volume can be formed by projecting 
the volume onto the image plane taking into account the emission and attenuation of light through each 
voxel. This projection may be calculated using a simple compositing scheme modeled after an optical film 
printer (Porter, 1984). Voxel Mixtures and Classification The volume rendering algorithm presented in 
this paper operates on volumes which are modeled as a composition of one or more materials. Examples 
include: a set of physical substances, such as bone, soft tissue, and fat in the muscu-loskeletal system; 
a set of simulated measurements, such as stress and strain in a finite element model; or a set of signals, 
such as the individual spin echoes of magnetic resonance. A voxel's composition is described by the percentage 
of each material present in the voxel. When the material composition at each voxel is not pro- vided, 
classification is used to estimate the percentages of each material from the original data. It is very 
important when clas- sifying the data not to make all-or-none decisions about which material is present, 
but rather to compute the best estimate of how much is present within each voxel. Making material deci- 
sions by thresholding introduces artifacts in the material per- centages which are easily visible in 
the final images (Drebin, 1987). Probal:fflistic classifiers work particularly well, because the probability 
that a material is present can be used as an esti- mate of the percentage of the material present in 
the voxel. The first probabilistie classifier developed for this volume rendering technique was a maximum-likelihood 
classifier for musculoskeletal CT volumes. In this case the intensities in the input volume represent 
x-ray radiation absorption. The classification yields volumes containing the percentages of air, bone, 
soft-tissue, and fat. A histogram of the x-ray absorption of the input volume is the sum of three overlapping 
distribu- tions, corresponding, in increasing order of intensity, to fat, soft-tissue, and bone. In the 
general case, the probability that any voxel has value (intensity) ! is given by   SIGGRAPH '88, Atlanta, 
August 1-5, 1988 n P (I) = ~__~Pi Pi (I) where n is the number of materials present in the volume, Pl 
is the percentage of material i in a given voxel, and Pi([) is the probability that material i has value 
1. In the case of muscu- loskeletal CT, the distribution functions Pi (it) represent the x- ray absorption 
of each material, and are known a-priori. Once the individual distribution functions are known, the Bayesian 
estimate of the percentage of each material contained within a voxel of value I is given by: pi(I)-ei(1) 
i__~Pj ([) Note that when the classification is a function of only a single intensity volume, as in this 
case, the classification can be per- formed by using table lookup on the input values. Further-more, 
if no more then two material distributions overlap, the percentage of each material varies linearly between 
their peaks. This is roughly the case with musculoskeletal CT, because bone and fat intensity distributions 
rarely overlap, so voxels are either linear combinations of fat and soft-tissue or soft-tissue and bone. 
Figure 2 shows a hypothetical histogram, material distributions, and resulting classification functions. 
The first step in Figure 1 shows an actual classification of a CT data set. Maximum likelihood classifiers 
can be built that handle more than one input data volume; these are like the multispec- tral classification 
algorithms commonly employed in remote sensing and statistical pattern recognition. However, max-imum 
likelihood methods will not always work well. In per- forming the musculoskeletal classification described 
above, voxels are never classified as being a mixture of air and bone since the soft-tissue distribution 
lies between the air and bone distributions. However, within nasal passages mixtures of air and bone 
are common. Using knowledge about what combina- tions of materials may potentially mix will improve the 
classification and hence the estimates of the material percen- tages. Adaptive classification algorithms 
which take advantage of local neighborhood characteristics (Tom, 1985), multi-spectral mixture analysis 
(Adams, 1986), or probabilistic relax- ation algorithms (Zucker, 1976) can all be used with the volume 
rendering algorithm. However, it should be stressed again, that only probabilistic classification algorithms 
should be used, since binary classification algorithms will introduce artifacts in the subsequent renderings. 
Once material percentage volumes are available, volumes corresponding to other properties can be easily 
computed. As an example, consider creating a RGB~ color-opacity volume. In this paper, a piece of colored 
material is modeled with four coordinates: R, G, B are the intensities of red, green and blue light, 
and ~x is the opacity. An t~=l implies that the material is completely opaque, and t~-----0 implies that 
it is completely tran- sparent. (A more accurate model of transparency would use three color components 
because a real material will filter red, green and blue light differently.) The color of a mixture of 
materials is given by C = ~=~ Pi Ci where Ci = (~iRi,(tiGi,~iBi,~i) is the color associated with material 
i. Note that in this representation, the colors are # Original histogram  # Constituent's distributions 
/~ soft tissue air~,~'~b °n k I 100% --~ Material assignme~nts soft tissu bone 0%' CT Number~-4~ Figure2. 
CT Classification premultiplied by their opacities. This representation of colors and the advantages 
of premultiplying colors by opacity are is discussed in (Porter, 1984). Matting After the volume is classified, 
it is often helpful to remove sections or lessen the presence of certain regions or materials. Matte 
volumes are created for these operations. Each voxel of a matte is a scalar fraction, which defines the 
percentage of the voxel contained by the matte. Matte volumes can be simple geometric shapes, such as 
wedges or halfplanes, or regions computed from other volumes, such as an air matte volume which is the 
region not contained in any material percentage volumes. Matting operations correspond roughly to fuzzy 
set opera- tions. This allows spatial set operations to be performed on volumes. An example of this is 
merging multiple volumes into a single volume using union. Another example is to carve a shape out of 
a solid. One of the most common uses of matte volumes is to perform cut-aways; another is to remove regions 
where the data is unreliable or uninteresting. Finally, since matte values are fractional, they can be 
used to lower the per- centage of material in a region, or to change the material pro- perties in different 
regions. Depth cueing is done by matting a ramp in z with the final shaded color volume before projection. 
This has the effect of making near colors brighter than the far colors.  ~ Computer Graphics, Volume 
22, Number 4, August 1988 Each voxel of a matte volume M contains a value between 0 and 1 which indicates 
the presence or absence of the matte. A volume, V, is combined with a matte, M, with the following operations: 
V inM =MV V out M = (1-M)V The in operator yields the portion of V inside of M. Set inter- section is 
accomplished by multiplying the two volumes. The out operator returns the portion of V outside of M. 
This is done by complementing M and then forming the set intersec- tion. Complementing M is performed 
by subtracting M from 1. By making mattes fractional instead of binary, the boun- daries between inside 
and outside are smooth and continuous. This is important if the continuity of the data is to be preserved. 
Binary mattes will lead to artifacts in the final images. Surface Extraction The shading model described 
below requires information about surfaces within each voxel, including their normal and "strength." The 
strength of a surface is a combination of the percentage of surface within the voxel and the reflection 
coefficient of that surface. In this paper, the surface physics is approximated by assigning to each 
material a density charac- teristic p. A surface occurs when two or more materials of dif- ferent O's 
meet. The strength of the surface is set equal to the magnitude of the difference in p. A p volume is 
computed by summing the products of the percentage of each material in the voxel times the material's 
assigned p, such that: D = "~Pi Pi where D is the total p of a voxel and Pi is the density assigned to 
material i. The material p assignments can be arbitrary; they do not have to be related to the actual 
mass of the materials or the imaged intensities. By assigning two materials the same p's they are effectively 
coalesced into a single material and the surface between them will not be detectable. The surface nor- 
real and strength volumes are derived from the P volume's gra- dient. The strength of a surface is proportional 
both to the magnitude of the difference in P and to the sharpness of the transition from one material 
to the other. The surface strength volume is used to indicate the presence of surfaces. The surface normal,/~, 
is defined as: N x=v xD =Dx+l-Dx Ny = VyD = Dy+l - Dy Nz = VzD =Dz+l-Dz This vector is normalized to 
have unit length and stored in a surface normal volume. The magnitude of the gradient is stored in a 
surface strength volume. S=lYl Since a derivative is a high-pass filter, noisy volumes will have very 
noisy derivatives. When this is a problem, more accurate estimates of the derivatives can be computed 
by first blurring or running a low-pass filter over the material volume. This is directly analogous to 
the two-dimensional problem of L   cF{( cB / Figure 3. Voxel shading model detecting edges in the 
presence of noise. Figure 1 shows a p volume and the resulting surface nor- real and strength volumes. 
Note that surfaces are represented by a surface strength and not a binary value indicating whether surfaces 
are present or not. This allows diffuse transitions between material to be represented, and positions 
of surfaces in the final image often appear to lie between voxel boundaries. Lighting Model Figure 3 
shows the lighting model used in each voxel. A light ray traveling towards the eye enters the voxel from 
behind with incoming intensity I, and exits from the front with outgoing intensity I'. The light intensity 
changes due to the following effects: i) materials may act as translucent fiIters, absorbing the incoming 
light, ii) they may be luminous and emit outgoing light, and iii) they may contain surfaces or parti- 
cle scatterers which both attenuate the incoming light and also reflect light from light sources towards 
the eye. Light transmission through a volume can be modeled as a radiation transport problem (Kajiya, 
1984). However, in this paper only a single scattering of radiation from a light source to the eye is 
assumed. Light rays from the light source are also not attenuated as they travel through the volume. 
These assump- tions make the lighting model very easy to implement. If a light ray travels through a 
colored translucent voxel, the resulting color is I" = C over I = C + (1-etc)I where ok: is the alpha 
component of C. The first term models the emitted light and the second term the absorption of incom- 
ing light. In order to include surface shading, the voxel is sub- divided into two regions: the region 
in front and behind a thin surface region. Each of these regions is assigned an RGB~ color so that it 
can both emit and absorb light. The outgoing intensity is then I' = (CF over (Cs over (CB over/))) = 
C over/ Since the over operator is associative, the three color volumes corresponding to front CF, back 
CB and surface Cs can be combined into a single volume C =CF over Cs over CB before the integration is 
performed. SIGGRAPH '88, Atlanta, August 1-5, 1988 The reflected surface color, Cs, is a function of 
the sur-face normal, the strength of the surface, the diffuse color of the surface Co, the direction 
L ~ and color CL of the light source, and the eye position ft. The color of the reflected light has two 
components, a diffuse component whose color is given by the color of the surface, and a specular component 
whose color is given by the color of the light. The formula is C s = (f (~,L~)CD + g (E~,L~)CL) in S 
 where f and g are diffuse and specular shading functions, and Co is the diffuse color of the surface. 
Appropriate functions for f and g are discussed in (Phong, 1975, Blinn, 1982, Cook, 1982). Note that 
the amount of surface shading is proportional to the strength of the surface. No rettected light will 
appear in the interior of a homogeneous material. The simplest approach is to set the surface diffuse 
color equal to CD =CF+Cs; that is, treat the color of the surface as the color of the mixture, and to 
just add it into the mixture. C is then set equal to CsoverCD . The problem with this approach is that 
color from neighboring materials bleed into the surface. For example, if white bones are next to red 
muscle tissue, the bleeding will cause the surfaces of the bones to appear pink. The best choice for 
Co is CB, but this is techni- cally difficult because it is not known which of the materials in the mixture 
is the back material and which is the front. One solution to this problem is to examine the sign of the 
density gradient in the direction of view. If it is positive, the front of the voxel has a lower 9 than 
the back; otherwise the front has a higher p. Once the materials are ordered from front to back, the 
colors can be assigned accordingly. Viewing and Projection An image is computed by projecting the volume 
onto the image plane. One common method used to perform this pro- jection is to cast rays through the 
volume array. The problem with this approach is that sampling artifacts may occur and it is computationally 
expensive since it requires random access to the volume data. The approach used in this algorithm is 
to first transform the volume so that the final image lies along the front face of the viewing pyramid, 
and so that rays through the vantage point are all parallel and perpendicular to the image plane. The 
transformation of the volume can be done efficiently in scanline order which also allows it to be properly 
resampled. Modeling light transmission during projection is also particularly convenient in this coordinate 
system. After the shading calculation, there exists a RGBct volume C. As the projection occurs, the intensity 
of light is modeled according to the equations described in the previous section. Each colored plane 
of the volume is overlaid on top of the planes behind it from back to front using the over operator. 
The orthographic projection through the z'th plane of the volume can be expressed as: Iz = Cz over lz+l 
 where I is the accumulated image, Cz is the color-opacity of plane z. The initial image In is set to 
black and the final image is I0. This algorithm need not store the I volume, just the final image. This 
multi-plane merge could just as easily be done from front to back using the under operator (A underB 
=- B over A). It is important to be able to view the volume with an arbi- trary viewing transformation, 
which includes translation, rota- tion, scaling, and perspective. In order to preserve the simpli- city 
of the parallel merge projection, the viewing coordinate system is fixed, and the volume is geometrically 
transformed and resampled to lie in that coordinate system. This is done as a sequence of 4 transformations, 
T=ez (Ze ) Rz (~)Ry ( ~ )Rz (0) where Rz and Ry are rotations about the z and y axes, respec- tively, 
and Pz is the perspective transformation. The transfor- mations are parameterized by the Euler angles, 
(0,~,xg), and Ze, the z coordinate of the eye point. In many applications, a sequence of orthographic 
views corresponding to a rotation about only single axis is required, so that only one of the rotates 
is required, and the viewing transformation can be done in 1/4 the time. Since each rotation is perpendicular 
to an axis of the volume, the volume rotation can be performed by extracting individual slices along 
the axis perpendicular to the rotation axis, rotating them individually as images, and then placing them 
into the result volume. Performing a three-dimensional rotation using a sequence of three rotates requires 
the ability to extract planes perpendicular to at least two axes (y and z). This requires either an intermediate 
transposition of the volume, or a storage scheme which allows fast access along two perpendicular directions. 
Pz is a perspective transforma- tion with the eye point on the z-axis. This can be efficiently implemented 
by scanning sequentially through slices in z, and resizing the x-y images by ll(ze-z) -that is, magnifying 
images near the eye relative to images far from the eye. Rota-tions and scalings are both special cases 
of an affine transfor- mation. Two-dimensional affine transformations can be per- formed using the two-pass 
scanline algorithms discussed in (Catmui1, 1980). For the viewing transformation outlined above, this 
requires as many as 8 resampling operations. It should be possible to generalize the two-pass image transformation 
to a three-pass volume transformation and reduce the number of resarnpling operations. It is important 
when performing these geometric manipulations that the images be reconstructed and resampled using either 
triangular or bicubic filters to preserve the continuity of the data. Poor reconstruction and resampling 
will introduce artifacts in the final images. Results Figures 4-12 show images of various volumes rendered 
with the above techniques. Figures 4-6 are medical images based on CT data sets. Figure 4 shows four 
images rendered with different material properties and variations of the algo- rithms presented in this 
paper. Figure 5 illustrates an applica- tion of a matte volume to cut-away a wedge from the child's head. 
Figure 6 shows a whole body reconstruction of an adult male with different colors and opacities on the 
left and fight halves. The volume rendering technique has been shown to be valuable in clinical applications 
CFishman, 1987, Scott, 1987). A biological application of the volume rendering algorithm is shown in 
Figure 7: a whole body image of a sea otter. This image lead to the discovery that adult sea otters have 
an exa~a wrist bone not present in young otters (Discover, 1988). Fig-ure 8 shows a physical sciences 
application of volume render- ing. Figure 8 is a rendered image of a smoke puff. The origi- nal input 
data set was acquired as a sequence of images from a CCD camera. Each image was a cross section of the 
smoke   ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 References "Why Abalones Don't Find Otters Cute," 
Discover, p. l0 (April 1988). ADAMS, JOHN B., MILTON O. SMITH, AND PAUL E. JOHNSON, "Spectral Mixture 
Modeling: A New Analysis of Rock and Soil Types at the Viking 1 Lander Site," Journal of Geophysi- cal 
Research 91(B8) pp. 8098-8112 (July 1986). BLINN, JAMES F., "Light Reflection Functions for Simulation 
of Clouds and Dusty Surfaces," Computer Graphics (SIG- GRAPH '82 Proceedings) 16(3) pp. 21-29 (July 1982). 
BLOOMENTHAL, JULES, "Polygonization of Implicit Sur- faces," Report CSL-87-2, Xerox PARC (May 1987). 
CATMULL, EDWIN AND ALVY RAY SMITH, "3-D Transforma- tions of Images in Scanline Order," Computer Graphics 
(SIG- GRAPH '80 Proceedings) 14(3) pp. 279-285 (July 1980). CHRISTIANSON, H. N. AND T. W. SEDERBERG, 
"Conversion of Complex Contour Line Definitions into Polygonal Element Mosaics," Computer Graphics (SIGGRAPH 
'78 Proceedings) 12 pp. 187-192 (1978). CLINE, HARVEY E., WILLIAM E. LORENSEN, SIGWALT LUDKE, CARL R. 
CRAWFORD, AND BRUCE C. TEETER, "Two Algorithms for the Reconstruction of Surfaces from Tomo- grams," 
Medical Physics, (June, 1988). COOK, ROBERT L. AND KENNETH E. TORRANCE, "A Reflection Model for Computer 
Graphics," ACM Transactions on Graphics 1(1) pp. 7-24 (1982). DREBIN, ROBERT A., ELLIOT K. FISHMAN, AND 
DONNA MAGID, "Volumetric Three-dimensional Image Rendering: Thresholding vs. Non-thresholding Techniques," 
Radiology 165p. 131 (1987). FISHMAN, E. K., R. A. DREBIN, D. MAG1D, AND ET. AL., "Volumetric Rendering 
Techniques: Applications for 3- Dimensional Imaging of the Hip," Radiology 163 pp. 737-738 (1987). FUCI4S, 
H., Z. M. KEDEM, AND S. P. USELTON, "Optimal Sur- face Reconstruction for Planar Contours," CACM 20(1977). 
FUJIMOTO, AKIRA, TAKAYUKI TANAKA, AND KANSEI IWATA, "ARTS: Accelerated Ray-Tracing System," IEEE Computer 
Graphics and Applications, pp. 16-26 (Apr. 1986). GANAPATHY, S. AND T. G. DENNEHY, "A New General Tri- 
angulation Method for Planar Contours," Computer Graphics (SIGGRAPH '82 Proceedings) 16 pp. 69-75 (1982). 
HARRIS, LOWELL D., R. A. ROBB, T. S. YUEN, AND E. L. RIT- MAN, "Non-invasive numerical dissection and 
display of ana- tomic structure using computerized x-ray tomography," Proceedings SPIE 152 pp. 10-18 
(1978). HERMAN, GABOR T. AND H. K. LtU, "Three-Dimensional Display of Organs from Computed Tomograms," 
Computer Graphics and Image Processing 9(1) pp. 1-21 (January 1979). HOEHNE, KARL HEINZ, ROBERT L. DELAPAZ, 
RALPH BERN- STEIN, AND ROBERT C. TAYLOR, "Combined Surface Display and Reformatting for the Three-Dimensional 
Analysis of Tomographic Data," Investigative Radiology 22(7)pp. 658- 664 (July 1987). JAFFEY, STEPHEN 
M. AND KALYAN DUTTA, "Digital Perspec- tive Correction for Cylindrical Holographic Stereograms," Proceedings 
of SPIE 367(August 1982). KAJIYA, JAMES T. AND BRIAN P. VON HERZEN, "Ray Tracing Volume Densities," Computer 
Graphics (SIGGRAPH '84 Proceedings) 18(3)(July 1984). KEPPEL, E., "Approximation of Complex Surfaces 
by Tri- angulation of Contour Lines," IBM Journal of Research and Development 19 pp. 2-11 (1975). LEVOY, 
MARC, "Display of Surfaces from Volume Data," 1EEE Computer Graphics and Applications, (May, 1988). LORENSEN, 
WILLIAM E. AND HARVEY E. CLINE, "Marching Cubes: A High Resolution 3D Surface Construction Algo- rithm," 
Computer Graphics (SIGGRAPH '87 Proceedings), (July 1987). MAZZIOTTA, J. C. AND K. H. HUANG, "THREAD 
(Three-Dimensional Reconstruction and Display) with Biomedical Applications in Neuron Ultrastructure 
and Display," American Federation of Information Processing Society 45 pp. 241-250 (1976). MEAGHER, DONALD 
J., "Efficient Synthetic Image Generation of Arbitrary 3-D Objects," Proceedings of the IEEE Computer 
Society Conference on Pattern Recognition and Image Pro- cessing, pp. 473-478 (June 1982). NORTON, ALAN, 
"Generation and Display of Geometric Frac- tals in 3-D," Computer Graphics (S1GGRAPH '82 Proceed- ings) 
16(3) pp. 61-67 (July 1982). PHONG, BUI-THONG, "Illumination for Computer Generated Images," CACM 18(6) 
pp. 311-317 (June 1975). PORTER, THOMAS AND TOM DUFF, "Compositing Digital Images," Computer Graphics 
(SIGGRAPH '84 Proceedings) 18(3) pp. 253-260 (July 1984). SCHLUSSELBERG, DANIEL S., WADE K. SMITH, AND 
DONALD J. WOODWARD, "Three-Dimensional Display of Medical Image Volumes," Proceedings of NCGA, (March 
1986). SCOTT, W. W. JR., E. K. FISHMAN, AND D. MAGID, "Aceta- bular Fractures: Optimal Imaging," Radiology, 
pp. 537-538 (1987). SUNGURUFF, A AND D. GREENBERG, "Computer Generated Images for Medical Applications," 
Computer Graphics (SIG- GRAPH '78 Proceedings) 12 pp. 196-202 (1978). TOM, VICTOR T., "Adaptive Filter 
Techniques of Digital Image Enhancement," SPIE Digital Image Processing: Criti- cal Review of Technology 
528(1985). TUY, HEANG K. AND LEE TAN "IVY, "Direct 2-D Display of 3-D Objects," 1EEE Computer Graphics 
and Applications 4(10) pp. 29-34 (October 1984). VANNIER, MICHAEL W., JEFFREY L. MARSH, AND JAMES O. 
WARREN, "Three Dimensional Computer Graphics for Craniofacial Surgical Planning and Evaluation," Computer 
Graphics" (SIGGRAPH '83 Proceedings) 17(3)pp. 263-273 (July 1983). WRIGHT, THOMAS AND JOHN HUMBRECHT, 
"ISOSURF - An Algorithm for Plotting Iso-Valued Surfaces of a Function of Three Variables," Computer 
Graphics (S[GGRAPH '79 Proceedings) 13(2) pp. 182-189 (August 1979). WYVILL, BRIAN, CRAIG MCPIqEETERS, 
AND GEOFF WYVILL, "Data Structure for Soft Objects," The Visual Computer 2(4) pp. 227-234 (1986). ZUCKER, 
STEVEN W., "Relaxation Labelling and the Reduc- tion of Local Ambiquities,'" Proceedings 3rd International 
Conference on Pattern Recognition, pp. 852-861 (November 1976). 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378487</article_id>
		<sort_key>75</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[A progressive refinement approach to fast radiosity image generation]]></title>
		<page_from>75</page_from>
		<page_to>84</page_to>
		<doi_number>10.1145/54852.378487</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378487</url>
		<abstract>
			<par><![CDATA[A reformulated radiosity algorithm is presented that produces initial images in time linear to the number of patches. The enormous memory costs of the radiosity algorithm are also eliminated by computing form-factors on-the-fly. The technique is based on the approach of rendering by progressive refinement. The algorithm provides a useful solution almost immediately which progresses gracefully and continuously to the complete radiosity solution. In this way the competing demands of realism and interactivity are accommodated. The technique brings the use of radiosity for interactive rendering within reach and has implications for the use and development of current and future graphics workstations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[adaptive subdivsion]]></kw>
			<kw><![CDATA[backward ray tracing]]></kw>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[progressive refinement]]></kw>
			<kw><![CDATA[radiosity]]></kw>
			<kw><![CDATA[z-buffer]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP77026366</person_id>
				<author_profile_id><![CDATA[81406592138]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14048866</person_id>
				<author_profile_id><![CDATA[81451598765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shenchang]]></first_name>
				<middle_name><![CDATA[Eric]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P146446</person_id>
				<author_profile_id><![CDATA[81414601063]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Wallace]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arvo, James, "Backward Ray Tracing," Developments in Ray Tracing(SIGGRAPH '86 Course Notes), Vol.12, August 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bergman, Larry, Henry Fuchs, Eric Grant, Susan Spach, "Image Rendering by Adaptive Refinement," Computer Graphios(SIGGRAPH '86 Proceedings), Vol.20, No.4, August 1986, pp.29-38.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, "A Radiosity Solution for Complex Environment," Computer Graphics(SIGGRAPH '85 Proceedings), Vol.19, No.3, July 1985, pp.31-40.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, Vol.6, No.2, March 1985, pp.26-35.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter, Loren Carpenter, "Distributed Ray Tracing," Computer Graphics(SIGGRAPH '84 Proceedings), Vol.18, No.3, July 1984, pp.137-145.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry, et. al., "Fast Spheres, Shadows, Textures, Transparencies, and Image Enhancements in Pixel- Planes," Computer Oraphics(SIGORAPH '85 Proceedings), Vo1.19, No.3, July 1985, pp.111-120.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Coral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Craphics(SIGGRAPH '84 Proceedings ), Vol.18, No.3, July 1984, pp.213-222.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H., "Continuous Shading of Curved Surfaces," IEEE Transactions on Computers, Vol.20, No.6, June 1971, pp.623-628.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808588</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul S. and Pat Hanrahan, "Beam Tracing Polygonal Objects," Computer Graphics (SIGGRAPH '84 Proceedings), Vol.18, No.3, July 1984, pp.119-128.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hornbeck, Robert W., Numerical Methods, Quantum Publishers, New York, NY, 1974, pp.101-106.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Immel, David S., Michael F. Cohen, Donald P. Greenberg, "A Radiosity Method for Non-Diffuse Environments," Computer Graphics(SIGGRAPH '86 Proceedings), Vol. 20, No.4, August 1986, pp.133-142.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation," Computer Graphics(SIGGRAPH '86 Proceedings), Vol.20, No.4, August 1986, pp.143-150.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki, Eihachiro Nakamae, "Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection," Computer Craphics(SIGGRAPH "85 Proceedings), Vol. 19, No.3, July 1985, pp.22-30.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Phong, Bui Tuong, "Illumination for Computer Generated Pictures," Communications of the ACM, Vol.18, No.6, June 1975, pp.311-317.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert, John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger W. and Larry J. Thayer, "A Fast Shaded- Polygon Render," Computer Graphics(SIGGRAPH '86 Proceedings), Vol.20, No.4, August 1986, pp.95-102.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Michael F. Cohen, Donald P. Greenberg, "A Two-pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radiosity Methods," Computer Graphics(SIGGRAPH '87 Proceedings), Vol. 21, No.4, July 1986, pp.311-320.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Watkins, G. S., "A Real-Time Visible Surface Algorithm," University of Utah, UTECH-CSC-70-101, 1970.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display," Communication of the ACM, Vol.23, No.6, June 1980, pp.343-349.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 f SIGGRAPH '88, Atlanta, August 1-5, 1988 solution of fhe diffuse component of reflection. Thus the 
re-finement process may continue uninterrupted as the user views the scene from different directions. 
Unfortunately, the conven- tional radiosity algorithm provides no usable results until after the solution 
is complete, a computation of order n '2, ( where n is the number of discrete surface patches). The original 
algorithm has the additional disadvantage of using Urn 2) storage. In the revised radiosity algorithm 
presented here, an initial ap- proximation of the global diffuse illumination provides a starting point 
for refinement. A reorganization of the iterative solution of the radiosity equations allows the illumination 
of all surfaces in the environment to be updated at each step and ensures that the correct solution is 
approached early in the process. In addi- tion to providing a basis for graceful image refinement, the 
new algorithm requires only O(n) storage. 2 The Cost of Realism for the Conven-tional Radiosity Algorithm 
The radiosity algorithm is a method for evaluating the intensity or radiosity at discrete points and 
surface areas in an environ- ment. The relationship between the radiosity of a given discrete surface 
area, or patch, and the radiosity of all other patches in the environment is given by: BiAi = EiAi + 
Pl ~, BjFjiAi (1) 3=1 where Bi --radiosity of patch i (energy/unit area/unit time), El = emission of 
patch i (energy/unit area/unit time), Ai = area of patch i, A s --area of patch j, j~ = form-factor from 
j to i (fraction of energy leavlng patch j which arrives at patch i), p~ = reflectivity of patch i, and 
n = number of discrete patches. Using the reciprocity relationship for form-factors [15], FijA, = FjiAj 
(2) and dividing through by Ai, the more familiar radiosity equation is obtained: B, = E, + p~ ~ BjF~ 
(3) j=l or in matrix form: -raP21 1 - p2F22 -p2F2. I B2 E2 (4) .... I iilt .... I = L -p.F,~ -p,~F,~2 
 .1 -pnFn,~J ~ ,~ The computation involved in the conventional hemi-cube ra-diosity algorithm is divided 
into three major sections as follows: 1. Computing the form-factors (Fij). This requires deter- mining 
the patches visible to each patch over the entire hemisphere of directions above the patch. For each 
patch, all the other patches of the environment are projected onto the five faces of a hemi-cubeplaced 
over the patch and a z-buffer hidden-surface operation is performed for each face [3]. Using standard 
scan conversion and hidden sur- face routines, the cost of each hemi-cube is proportional to the number 
of discrete patches as well as the resolution of the hemi-cube. This results in an O(n 2) computation 
for the whole environment. 2. Solving the radiosity matrix equation (4) using the Gauss- Siedel method. 
Due to the strict diagonal dominance of the matrix, the solution converges in a few iterations and its 
cost is thus proportional to square of the number of patches [10]. The solution is performed for each 
color band. Since the form-factors are dependent on geometry only, this does not have a significant impact 
on the cost of the radiosity algorithm. 3. Displaying the results. This involves selecting viewing pa- 
rameters, determining hidden surfaces, and interpolating the radiosity values. Current workstations are 
capable of rapidly displaying high resolution radiosity images from any vantage point through the use 
of Gouraud shading and z- buffer hardware.  The overwhelming cost of the radiosity method lies in the 
com- putation of the form-factors. To reduce this cost, the form- factors are calculated once and stored 
for repeated use during the iterative matrix solution. The total ntLmber of form-factors to be stored 
is potentially the number of patches squared, al- though the matrix of coefficients is normally quite 
sparse since many patches cannot see each other. Even so, the n by n ma- trix of coefficients will quickly 
exceed a reasonable storage size. For example, assuming a matrix that is 90 percent sparse and four bytes 
of memory per form-factor, an environment of 50,000 patches will require a gigabyte of storage. For rendering 
by progressive refinement, an important criterion is the time required to achieve a useful as opposed 
to complete solution. In the conventional radiosity algorithm, all the form- factors for the entire environment 
are pre-calculated before the solution begins at a cost of Urn2). Furthermore, using the Gauss-Siedel 
solution for the system of radiosity equations, an estimate of the radiosity of all patches is not available 
until after the first complete iteration cycle. This clearly cannot be implemented at interactive speeds 
and is not the graceful first step required for progressive refinement. 3 Progressive Refinement Methods 
for the Radiosity Algorithm The radiosity algorithm can be restructured to achieve the goals of progressive 
refinement. In the restructured algorithm, form- factors are calculated on-the-fly 1o eliminate the Urn 
2) storage and startup costs. Although the basic Gauss-Siedel approach still remains, the order of operations 
of the iteration cycle has been modified so that a good approximation of the final results can be displayed 
early in the solution process. The restructured algorithm differs from the previous ones pri- marily 
in two aspects. First, the radiosity of all patches is up- dated simultaneously. Second, patches are 
processed in sorted order according to their energy contribution to the environment. ~ Computer Graphics, 
Volume 22, Number 4, August 1988 To further improve the quality of the images generated during the earliest 
stages of the algorithm, an estimate of globai illu- mination is determined directly from the known geometric 
and reflective characteristics of the environment. This estimate is gradually replaced by more exact 
information as the solution progresses, providing a graceful and continuous convergence to a realistic 
image. 3.1 Simultaneous Update of Patch Radiosities: Shooting vs. Gathering Light In the conventional 
radiosity algorithm, the Gauss-Siedel method is used to obtain the solution to the simultaneous equations(4). 
This iterative approach converges to the solution by solving the system of equations one row at a time. 
The evaluation of the i'th row of the equations provides an estimate of the radiosity of patch i based 
on the current estimates of the radiosities of all other patch radiosities: B~ = El + m ~ BjF~ (5) j=l 
In a sense, the light leaving patch i is determined by gathering in the light from the rest of the environment 
(figure 1). A single term from the summation in (5) determines the con- tribution to the radiosity of 
patch i from patch j: Bi due to B.i = piBjFij (6) It is possible to reverse this process by determining 
the contri- bution made by patch i to the radiosity of all other patches. The reciprocity relationship 
(2) provides the basis for reversing ~--i-- 1 V Y GATHERING vs. SHOOTING  LIJL J L JL For all j: N 
Bl =Et ÷Z (Pil~.j)BJ 5 =Bj +h (Pj  J=t rUAi/A j Figure 1: Gathering vs. Shooting Gathering light through 
a hemi-cube allows one patch radiosity to he up- dated. In contrast, shooting light through a single 
hemi-cube allows the whole environment's radiosity values to be updated simultaneously. this relationship. 
The contribution of the radiosity from patch i to the radiosity of patch j is: Bj due to Bi = pjB;FijA~/Aj 
(7) This is true for all patches j. Thus the total contribution to the environment from the radiosity 
of patch i is given by: For all patches j : Bj due to Bi = pjB~F~A,/Aj (8) It should be noted that while 
this equation adds radiosity to patches j, the form-factors used, Fij, are still the form-factors calculated 
using the hemi-cube placed at patch i. Thus, each step of the solution now consists of performing a single 
hemi- cube over a patch and adding the contribution from the radiosity of that patch to the radiosities 
of all other patches, in effect, shooting light out from that patch into the environment. Ouring the 
course of the iterative solution this step may be repeated for patch i several times as the solution 
converges. Each time the estimate of the radiosity of patch i will be more accurate. However, the environment 
will already include the contribution of the previous estimate of Bi. Thus, only the dif- ference, ,~Bi, 
between the previous and current estimates of Bi needs to be considered. ABi represents the unshot radiosity. 
The solution step may be restated as follows: for each iteration, for each patch i: calculate the form-factors 
Fij using a hemi-cube at patch i; for each patch j: ~Rad = pjABiFijAi/Aj; ABj = ~Bj + ~Rad; /* update 
change since last time patch j shot light */ B 1 = Bj ÷ ~Rad; /* update total radiosity of patch j */ 
z~B'i = 0; /*reset unshot radiosity for patch i to zero*/ All radiosities, Bi and ~B;, are initialized 
to zero for all non- light sources and are set to the emission values for emitting patches. The above 
step continues until the solution converges to within the desired tolerance. Each intermediate step simultaneously 
improves the solution for many patches, providing intermediate results which can be displayed as the 
algorithm proceeds. This approach bears some relationship to backward ray-tracing solutions [1] which 
shot light out from light sources onto diffuse surfaces, but did not propagate the reflected light any 
further into the environment. A recursive extension of the Atherton- Weiler shadow algorithm was proposed 
and briefly described by Heckbert and Hanrahan [9] as a way of propagating light from light sources through 
the environment, but light reflected from diffuse surfaces was likewise not propagated further. 3.2 
Solving in Sorted Order In addition to converging gracefully, it is desirable for the solu- tion to improve 
in accuracy as quickly as possible. The final radiosity B i of a given patch j consists of the sum of 
the contributions from all other patches. The final value of this sum will be approached earliest in 
the process if the f SIGGRAPH '88, Atlanta, August 1-5, 1988 largest contributions are added first. 
These will tend to come from those patches which radiate the most energy, i.e. have the largest product 
B;A;. Stated intuitively, those patches radiating the most light energy typically have the greatest effect 
on the illumination of the environment and should be treated first. The algorithm is implemented by always 
shooting from the patch for which the difference, ~BiAi, between the previous and the current estimates 
of unshot radiant energy is greatest. Most light sources are automatically processed first by this rule, 
since initially all other patches will have a radiosity of zero. Since lights are typically the most 
significant source of illumination for many patches, following the initial processing of light sources 
much of the environment will already be well illuminated. The next set of patches processed according 
to this rule will be those patches that received the most light from the light sources, and so on. When 
solving in sorted order, the solution tends to proceed in approximately the same order as light would 
propagate through the environment. A similar approach was taken by Immel [11] in order to increase the 
efficiency of the view-independent specular radiosity algorithm. The reordering of the patches generally 
provides an accurate solution in less than a single iteration, substantially reducing computation costs. 
3.3 The Ambient Term Using the procedures described above, intermediate images will progress from a dark 
environment, continuously brightening to a fully illuminated scene including all diffuse interref[ection. 
The illumination of the scene during early stages of the solution pro- cess will be inadequate, particularly 
for regions which do not receive direct illumination, since global illumination is not yet accurately 
represented. In earlier lighting models, the effect of global illumination was approximated by adding 
an arbitrary ambient term. Similar use is made of an ambient term here, but its value at any given point 
during the solution is based on the current estimate of the radiosities of all patches and the reflectivity 
of the environment. The ambient term is added for display purposes only and is not taken into account 
by the so- lution itself. The contribution of the ambient term gracefully decreases as the solution continues, 
providing a useful image al- most immediately which unobtrusively progresses to an accurate rendering. 
3.3.1 Computation of the Ambient Term A reasonable first approximation to the form-factors can be made 
without any knowledge of the visibility or the geomet- ric relationships between patches. The form-factor 
from any patch i to patch j can be approximated as the fraction of the total area of the environment 
taken up by the area of patch j. As with the correct form-factors the total will sum to unity. Thus, 
Aj  F.j ~ (9) Ej~ Aj An average reflectivity for the environment can be computed as an area weighted 
average of the patch reflectivities: n Ei=l piA, (10) For any unit energy sent into the environment, 
pat,, will on average be reflected, and some of that will be reflected, etc. Thus, an overall interreflection 
factor R is simply the geometric sum: 1 R = I + p_o + pL~ + pL, + .... -- --(11) 1 --p~, From these 
assumptions an Ambient radiosity term is derived. It is simply the area average of the radiosity which 
has not yet been shotvia form-factor computation times the reflection factor R. Ambient = R ~( A BjF.~) 
(12) j=l Thus at any point in the computation, the estimate of the ra- diosity of each patch can be 
improved by adding the contribution of the ambient radiosity. If Bi is the radiosity of patch i due to 
the radiosity received via shooting from other patches, an improved estimate is given by: JB;= Bi + piAmbient 
(13) This estimate of B~ is used for display purposes only since the ambient contribution is not added 
to ~Bi and thus is not shot during the solution. As the solution progresses the average unshot energy 
decreases and thus the ambient term decreases along with it. The values of Bi and B~ converge and the 
initial ambient image yields gracefully to the more accurate estimate of global illumination provided 
by the radiosity equations. 3.4 Adaptive Subdivision: Achieving an Appropri-ate Surface Discretlzation 
There are competing influences on how fine the subdivision of the surfaces of the environment should 
be. k finer subdivision means more computation but results in a more accurate rep- resentation of the 
sharp radiosity gradients that can occur at shadow boundaries. The original hemi-cube algorithm solved 
this problem by using a two level subdivision in which patches are further subdivided into elements [4]. 
In the revised algorithm as in the originat algorithm, patch sub- division is kept coarse since the specific 
distribution of radiosity is less important for the patches, which act as the illuminators of the environment. 
The patches are subdivided into smaller ele- ments. It is the elements which act as the receivers of 
light from the patches. The elements are projected onto a single hemi-cube for each patch to determine 
patch-to-element form-factors, F~,. The tight is thus shot from the patch to all elements. The ra- diosity 
of a patch is determined as the area weighted average of its element radiosities. The number of patches, 
and thus the number of hemi-cubes, generally will grow very little during the radiosity analysis. Large 
patches need to be subdivided only if the radiosity varies greatly across the surface causing iBumination 
inaccuracies or if the ratio of the areas in equation (7) causes the form-factor term (FijAi/Aj) to grow 
larger than unity.   ~ Computer Graphics, Volume 22, Number 4, August 1988 I I I The elements are 
free to be adaptively subdivided based on ra- diosity gradients without changing the patch geometry and 
thus no additional hemi-cube computation is required. The number of elements projected onto the hemi-cubes 
will grow as high gradients such as shadow boundaries are discovered. Images are generated by rendering 
the elements themselves as Gouraud shaded polygons with the radiosity at the vertices interpolated from 
adjacent elements. Implementation The complete algorithm is summarized in the following pseudo- code 
description: /* initialization */ determine reflection factor, R; /* determine initial ambient from given 
emission */ Ambient= R~i=l( i i)/~i=lAi; /* initialize unshot radiosity to given emission */ for each 
patch: ~Bi = El; /* element e is a sub-unit of patch i */ for each element: B~ = Ei -4- piAmbient; [* 
initialize change in ambient radiosity */ ,~Ambient = O; /* radiosity solution */ Until convergence 
{ select patch i with greatest unshot energy, AB~Ai; t project elements onto hemi-cube located at patch 
i to compute patch i to element form-factors, -Fie; for each element e { /* determine increase in radiosity 
of element c due to ABi */ ARad = p~ABiFi~Ai/A~; /* add area weighted portion of increased radiosity 
of element e to radiosity of the patch j which contains element e */ Be = Be + ARad + p~AAmbient; ~Bj 
= ABj + ~RadA~/Aj; } interpolate vertex radiosities from neighboring elements; if( gradient from neighboring 
vertices is too high ) subdivide elements and reshoot patch i; AB~ = 0; determine ,5.Ambient from new 
unshot radiosities, ABj; display environment as Gouraud shaded elements; tProcesses which can take advantage 
of current graphics hard- ware for scan conversion and hidden surface calculation. The algorithms described 
above were implemented initially on a VAX 8700 and then on an HP 825 with an SRX graphics accel- erator. 
The herni-cube algorithm was performed in software and alternatively with the use of graphics hardware 
for the hidden surface determination and scan conversion portions of the form- factor routines. The ability 
to perform transformations, clipping and scan conversion on the HP workstation can potentially ac- celerate 
the hemi-cube computation and allows the intermediate results to be interactively displayed as a fully 
rendered image. 5 Results The methods described above were compared experimentally in several combinations 
to determine the effect on the solution process. Tests included comparing the use of Gathering vs. Shooting, 
Sorted vs. Unsorted Patches, and With and Without Ambient effects. All the methods converged to the same 
final radiosity results in different amounts of time and with different intermediate results. The final 
converged results were used as a control with which to measure the error at stages in the image refinement. 
Individual errors were determined as the absolute differences between the converged and estimated radiosities 
of each element. (The average radiosity values of the color bands was used for the purposes of error 
measurement.) The square root of the area weighted mean of the square of individual errors (RMS) is used 
as a quantitative measure of overall radiosity inaccuracy. m , 2 A Eo=,((Bo -Bo) ,) (14) RMS Error --~---- 
~=1 A~ where B~ is the converged radiosity and Be is the intermediate radiosity of element e. m is the 
total number of elements. The images themselves offer a qualitative basis for comparison, 5.1 A Test 
Environment Test were performed on a model of two office cubicles subdi- vided into ,500 patches and 
7000 elements. Four iterative ap- proaches to solving the radiosity equations were run. After each hemi-cube, 
images using the current radiosity estimates were displayed as hardware Gouraud shaded polygons on a 
Hewlett Packard 825SRX workstation. The four approaches were: 1. Gathering Only: This is the traditional 
radiosity method using a Gauss-Siedel solution. One hemi-cube is placed at each element. 2. Shooting 
Only: This method consists of reversing the pro- cess by shooting light to each element through a herni-cube 
placed at each patch. 3. Shooting with Sorting: The same as the second approach, but with the patch 
with the largest unshot energy being used at each step. 4. Shooting with Sorting and Ambient: This time 
the ra-diosity clue to an estimated ambient term is included for display.  Figures 2 through 5 each 
contain eight images from methods 1 through 4 respectively. From top to bottom they show the re- sults 
after 1, 2, 24, and 100 hemi-cubes. The right hand image is a pseudo-color version. Gray indicates an 
accurate solution when comparing each of these images to the converged result in figure 6. The blue intensity 
indicates under-estimated ra- diosity values and red indicates an over-estimate. The inclusion of the 
ambient term provides an immediately useful image as illustrated in figure 5, (repeated on the cover). 
Note that as the algorithm progresses, the over-estimates in the shadowed regions due to the ambient 
term are continuously redistributed     f SIGGRAPH '88, Atlanta, August 1-5, 1988 Acknowledgements 
The research in this paper was carried out under a grant from the National Science Foundation #DCR82039?9 
with equip- ment generously donated by Digital Equipment Corporation and Hewlett Packard. The office 
model was originally created by Keith Howie and modified by Shenchang Eric Chen. The Steel Mill was modeled 
through a great effort by Stuart I. Feldnnan. The photography was done by Emil Ghinger. Special thanks 
to Holly Rushmeier for technical discussions and to Julie O'Brien and Helen Tahn for helping assemble 
the paper.  References [1] Arvo, James, "Backward Ray Tracing," Developments in Ray Tracing(SIGGRAPH 
'86 Course Notes), Vol.12, August 1986. [2] Bergman, Larry, Henry Fuchs, Eric Grant, Susan Spach, "Image 
Rendering by Adaptive Refinement," Computer Graphios(SIGGRAPH '86 Proceedings), Vol.20, No.4, August 
1986, pp.29-38. [3] Cohen, Michael F., Donald P. Greenberg, "h Radiosity Solution for Complex Environment," 
Computer Graph-ics(SIGGRAPH '85 Proceedings), Vol.19, No.3, July 1985, pp.31-40. [4] Cohen, Michael F., 
Donald P. Greenberg, David S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Re- alistic 
Image Synthesis," IEEE Computer Graphics and Applications, Vol.6, No.2, March 1985, pp.26-35. [51 Cook, 
Robert L., Thomas Porter, Loren Carpenter, "Dis-tributed Ray Tracing," Computer Graphics(SIGGRAPH 'SJ 
Proceedings), Vol.18, No.3, July 1984, pp.137-145. [6] Fuchs, Henry, et. al., "Fast Spheres, Shadows, 
Tex- tures, Transparencies, and Image Enhancements in Pixel-Planes," Computer Oraphics(SIGORAPH '85 Proceed- 
ings), Vo1.19, No.3, July 1985, pp.111-120. [7] Coral, Cindy M., Kenneth E. Torrance, Donald P. Green- 
berg, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Craphics(SIGGRAPH '8~ Proceed- 
ings ), Vo1.18, No.3, July 1984, pp.213-222. [8] Gouraud, H., "Continuous Shading of Curved Surfaces," 
IEEE Transactions on Computers, Vol.20, No.6, June 1971, pp.623-628. [9] Heckbert, Paul S. and Pat Hanrahan, 
"Beam Trac-ing Polygonal Objects," Computer Graphics (SIGGRA PH '84 Proceedings), Vol.18, No.3, July 
1984, pp.119-128. [10] Hornbeck, Robert W., Numerical Methods, Quantum Publishers, New York, NY, 1974, 
pp.101-106. [11] Immel, David S., Michael F. Cohen, Donald P. Green-berg, "A Radiosity Method for Non-Diffuse 
Environments," Computer Graphics(SIGGRAPH '86 Proceedings), Vol. 20, No.4, August 1986, pp.133-142. [12] 
Kajiya, James T., "The Rendering Equation," Computer Graphics(SIGGRAPH '86 Proceedings), Vol.20, No.4, 
August 1986, pp.143-150. [13] Nishita, Tomoyuki, Eihachiro Nakamae, "Continuous Tone Representation 
of Three-Dimensional Objects Taking Ac- count of Shadows and Interreflection," Computer Craph- ics(SIGGRAPH 
"85 Proceedings), Vol. 19, No.3, July 1985, pp.22-30. [14] Phong, Bui Tuong, "Illumination for Computer 
Generated Pictures," Communications of the ACM, Vo1.18, No.6, June 1975, pp.311-317. [15] Siegel, Robert, 
John R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981. [16] 
Swanson, Roger W. and Larry J. Thayer, "A Fast Shaded- Polygon Render," Computer Graphics(SIGGRAPH '86 
Proceedings), Vol.20, No.4, August 1986, pp.95-102. [17] Wallace, John R., Michael F. Cohen, Donald P. 
Greenberg, "A Two-pass Solution to the Rendering Equation: A Syn- thesis of Ray Tracing and Radiosity 
Methods," Computer Graphics(SIGGRAPH '87 Proceedings), Vol. 21, No.4, July 1986, pp.311-320. [18] Watkins, 
G. S., "A Real-Time Visible Surface Algorithm," University of Utah, UTECH-CSC-70-101, 1970. [19] Whitted, 
Tur,ner, "An Improved Illumination Model for Shaded Display," Communication of the A CM, Vol.23, No.6, 
June 1980, pp.343-349.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378490</article_id>
		<sort_key>85</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[A ray tracing solution for diffuse interreflection]]></title>
		<page_from>85</page_from>
		<page_to>92</page_to>
		<doi_number>10.1145/54852.378490</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378490</url>
		<abstract>
			<par><![CDATA[An efficient ray tracing method is presented for calculating interreflections between surfaces with both diffuse and specular components. A Monte Carlo technique computes the indirect contributions to illuminance at locations chosen by the rendering process. The indirect illuminance values are averaged over surfaces and used in place of a constant "ambient" term. Illuminance calculations are made only for those areas participating in the selected view, and the results are stored so that subsequent views can reuse common values. The density of the calculation is adjusted to maintain a constant accuracy, permitting less populated portions of the scene to be computed quickly. Successive reflections use proportionally fewer samples, which speeds the process and provides a natural limit to recursion. The technique can also model diffuse transmission and illumination from large area sources, such as the sky.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Monte Carlo technique]]></kw>
			<kw><![CDATA[caching]]></kw>
			<kw><![CDATA[diffuse]]></kw>
			<kw><![CDATA[illuminance]]></kw>
			<kw><![CDATA[interreflection]]></kw>
			<kw><![CDATA[luminance]]></kw>
			<kw><![CDATA[radiosity]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[rendering]]></kw>
			<kw><![CDATA[specular]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P99980</person_id>
				<author_profile_id><![CDATA[81100633003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Ward]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lighting Systems Research, Lawrence Berkeley Laboratory, 1 Cyclotron Rd., 90-3111, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334758</person_id>
				<author_profile_id><![CDATA[81100218211]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Francis]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Rubinstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lighting Systems Research, Lawrence Berkeley Laboratory, 1 Cyclotron Rd., 90-3111, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335089</person_id>
				<author_profile_id><![CDATA[81100573338]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Clear]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lighting Systems Research, Lawrence Berkeley Laboratory, 1 Cyclotron Rd., 90-3111, Berkeley, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>356797</ref_obj_id>
				<ref_obj_pid>356789</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bentley, Jon Louis and Jerome Friedman, "Data Structures for Range Searching," ACM Computing Surveys, Vol. 11, No. 4, 1979, pp. 397-409.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael and Donald Greenberg, "A Radiosity Solution for Complex Environments," Computer Graphics, Vol. 19, No. 3, July 1985, pp. 31-40.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael, Donald Greenberg, David Immel, Phillip Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, Vol. 6, No. 2, March 1986, pp. 26-35.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L. and Kenneth E. Torrance, "A Reflection Model for Computer Graphics," ACM Transactions on Graphics, Vol. 1, No. 1, January 1982, pp. 7-24.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert, Thomas Porter, Loren Carpenter, "Distributed Ray Tracing," Computer Graphics, Vol. 18, No. 3, July 1984, pp. 137-147.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., "Stochastic Sampling in Computer Graphics," ACM Transaction8 on Graphics, Vol. 5, No. 1, January 1986, pp. 51-72.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Immel, David S., Donald P. Greenburg, Michael F. Cohen, "A Radiosity Method for Non-Diffuse Environments," Computer Graphics, Vol. 20, No. 4, August 1986, pp. 133-142.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T., "The Rendering Equation," Computer Graphics, Vol. 20, No. 4, August 1986, pp. 143-150.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kaufman, John, IES Lighting Handbook, Reference Volume, IESNA, New York, NY, 1981.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki and Eihachiro Nakamae, "Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection," Computer Graphics, Vol. 19, No. 3, July 1985, pp. 23-30.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>539488</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rubenstein, R.Y., Simulation and the Monte Carlo Method, J. Wiley, New York, 1981.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Siegel, R. and J. R. Howell, Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Michael F. Cohen, Donald P. Greenburg, "A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radlosity Methods," Computer Graphlcs, Vol. 21, No. 4, July 1987, pp. 311-320.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357335</ref_obj_id>
				<ref_obj_pid>357332</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Weghorst, Hank, Gary Hooper, Donald P. Greenburg. "Improved computational methods for ray tracing" ACM Transactions on Graphics, Vol. 3, No. 1, January 1984, pp. 52-69.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display," Communications of the ACM, Vol. 23, No. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ,1~ Computer Graphics, Volume 22, Number 4, August 1988 ± A Ray Tracing Solution for Diffuse Interreflection 
Gregory J. Ward Francis M. Rubinstein Robert D. Clear Li#htin 9 Systems Research Lawrence Berkeley Laboratory 
1 Cyclotron Rd., 90-3111 Berkeley, CA 9~720 (415) $s~-4 7sz Abstract An efficient ray tracing method 
is presented for calculating interreflections between surfaces with both diffuse and specular com- ponents. 
A Monte Carlo technique computes the indirect contribu- tions to illuminance at locations chosen by the 
rendering process. The indirect illuminance values are averaged over surfaces and used in place of a 
constant "ambient" term. Illuminance calculations are made only for those areas participating in the 
selected view, and the results are stored so that subsequent views can reuse common vMues. The density 
of the calculation is adjusted to maintain a constant accuracy, permitting less populated portions of 
the scene to be computed quickly. Successive reflections use proportionally fewer samples, which speeds 
the process and provides a natural limit to recnrsion. The technique can also model diffuse transmission 
and illumination from large area sources, such as the sky. General Terms: Algorithm, complexity. Additional 
Keywords and Phrases: Caching, diffuse, illuminance, interreflection, luminance, Monte Carlo technique, 
radiosity, ray tracing, rendering, specular. 1. Introduction The realistic computer rendering of a geometric 
model requires the faithful Simulation of light exchange between surfaces. Ray tracing is a simple and 
elegant approach that has produced some of the most realistic images to date. The standard ray tracing 
method follows light backwards from the viewpoint to model reflection and refraction from specular surfaces, 
as well as direct diffuse illumina- tion and shadows [15]. Accuracy has been improved with better reflection 
models [4] and stochastic sampling techniques [6]. Unfor-tunately, the treatment of diffuse interreflection 
in conventional ray tracers has been limited to a constant "ambient" term. This approximation fails to 
produce detail in shadows, and precludes the use of ray tracing where indirect lighting is important. 
We present a method for modeling indirect contributions to illumination using ray tracing. A diffuse 
interreflection calculation replaces the ambient term directly, without affecting the formulas or algorithms 
used for direct and specular components. Efficiency is obtained with an appropriate mix of view-dependent 
and view-independent techniques. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and~or 
specific permission. &#38;#169; 1988 ACM-0-89791-275-6/88/008/0085 $00.75 2. Interreflection in Ray 
Tracing Ray tracing computes multiple reflections by recursion (Fig-ure 1). At each level, the calculation 
proceeds as follows: 1. Intersect the ray with scene geometry-. 2. Compute direct contributions from 
light sources. 3. Compute specular contributions from reflecting surfaces. 4. Compute diffuse contributions 
from reflecting surfaces.  The complexity of the calculation is closely related to the difficulty of 
step 1, and the number of times it is executed as determined by the propagation (recursion) of steps 
2 through 4. Step 2 requires as many new rays as there are light sources, but the rays do not pro-pagate 
so there is no growth in the calculation. Step 3 can result in a few propagating rays that lead to geometric 
growth if unchecked. Methods for efficient specular component computation have been described by [8], 
[5] and [14]. The diffuse contributions in step 4, however, require many (>100) propagating rays that 
quickly overwhelm a conventional calculation. Most methods simply avoid this step by substituting a constant 
ambient term. Our goal is to find an efficient method for computing diffuse interreflection and thereby 
complete the ray tracing solution. We start with a sum-mary of previous work in this area. An advanced 
ray tracing method developed by Kajiya follows a fixed number of paths to approximate global illumination 
at each pixel [8]. Using hierarchical "importance" sampling to reduce vari- ance, the illumination integral 
is computed with fewer rays than a naive calculation would require. This brings ray tracing closer to 
a full solution without compromising its basic properties: separate geometric and lighting models, view-dgpendence 
for efficient render- ing of specular effects, and pixel-independence for parallel implemen- tations. 
Unfortunately, the method is not well suited to calculating diffuse interreflection, which still requires 
hundreds of samples. A high-resolution image simply has too many pixels to compute global illumination 
separately at each one. The radiosity method, based on radiative heat transfer, is well suited to calculating 
diffuse interreflection [12][10][2]. Surfaces are discretized into patches of roughly uniform size, and 
the energy exchange between patches is computed in a completely view-independent manner. The method makes 
efficient use of visibility information to compute multiple reflections, and sample points are spaced 
so that there is sufficient resolution without making the cal- culation intractable. In areas where illumination 
changes rapidly, the patches can be adaptively subdivided to maintain accuracy [3]. However, the standard 
radiosity method models only diffuse sur-faces, which limits the realism of its renderings. Immel extended 
the approach to include non-diffuse environments, adding bidirectional reflectance to the energy equations 
[7]. Unfortunately, the view-independent solution of specular interreflection between surfaces requires 
samp]ing radiated directions over very smal] (approaching pixel-sized) surface patches. The resulting 
computation is intract- able for all but the simplest scenes.  SIGGRAPH '88, Atlanta, August 1-5, 1988 
 x~Io Incoming ray ]nco " ~ Is_ ~- ~Surface location 1. Ray intersection with surface 2. Rays to compute 
direct component Incoming ray Incoming ray 3. Rays to compute specular 4. Rays to compute diffuse component 
component Figure 1: The four steps of ray tracing. A combined ray trueing and radiosity approach was 
designed by Wallace to take advantage of the complementary properties of the two techniques [13]. Wallace 
divides energy transport into four "mechanisms:" diffuse-diffuse, specular-dlffuse, dlffuse-specular, 
and specular-specular. He then proceeds to account for most of these interactions with clever combinations 
of ray tracing and radioslty techniques. Unfortunately, there are really an infinite number of transport 
mechanisms, such as specular-specular-diffuse, which are neglected by his calculation. The generalization 
Wallace suggests for his approach is equivalent to view-~ndependcnt ray tracing, which is even more expensive 
than general radiosity [7]. 3. Diffuse Indirect Illumination Our development of an efficient ray tracing 
solution to diffuse interrefleetion is based on the following observations: Because reflecting surfaces 
are widely distributed, the compu- tation of diffuse indirect illumination requires many sample rays. 
 The resulting "indirect illuminance" value t is view-independent by the Lambertian assumption [9]. 
 The indirect illuminance tends to change slowly over a surface because the direct component and its 
associated shadows have already been accounted for by step 2 of the ray tracing calcu- lation.  For 
the sake of efficiency, indirect illuminance should not be recalcu- lated at each pixel, but should instead 
be averaged over surfaces from a small set of computed values. Computing each value might require many 
samples, but the number of values would not depend on the number of pixels, so high resolution images 
could be pro-duced efficiently. Also, since illuminance does not depend on view, the values could be 
reused for many images. How can we benefit from a view-independent calculation in the inherently view-dependent 
world of ray tracing? We do not wish to limit or burden the geometric model with illuminanc¢ information, 
as required by the surface discretization of the radiosity method. By the same token, we do not wish 
to take view-independence too far, calculating illuminance on surfaces that play no part in the desired 
view. Instead we would like to take our large sample of rays only whcn and whcrc it is necessary for 
the accurate computation of an image, storing the result in a separate data structure that puts no constraints 
on the surface geometry. "aWe define indirect, it|urnluance ~ ~,he |isht tt~t~c per uult area arriving 
at a surface location via non-self-lumlnous surfaces. In our enhancement of the basic ray tracing technique, 
indirect illuminance values are cached in the following manner: If one or more yalues is stored near 
this point Use stored value(s) E[se Compute and store new value at this point The computation of a new 
value uses the "primary method." The technique for finding and using stored values is called the "secondary 
method." The primary method is invoked to calculate a new value the first time it is needed, which is 
when the secondary method fails to produce a usable estimate from previous calculations (Figure 2). Determining 
the appropriate range and presenting a surface-independent storage technique are the two main points 
of this paper, Before we explore these issues, we present a basic com- putation of indirect illuminance. 
r ¸ ., ,,_ -.._...... Figure 2: Illuminances E1 and E£ were calculated pre- viously using the primary 
method. Test point A uses an average of E1 and EP. Point B uses E~. Point C results in a new indirect 
illuminance value at that loca- tion.   SIGGRAPH '88, Atlanta, August 1-5, 1988 The inverse of the 
estimated error is used in a weighted aver-age approximation of illuminance: Z Wi (~) Ei (5)E(F) i~ 
w i (F) i~s 1 where: w i (~) =  "~-~" + ~l-g(~).~(~i) R i = computed illutrtinance at ~i E i = harmonic 
mean distance to objects visiblc from ~i R i S = {i:wi(~) > lla } a = user select~J const~,t The approximate 
illuminance, E (P), is given by the weighted mean of all "adjacent" illuminance values. The weight of 
a value is equal to the inverse of its estimated error, without the constant terms that are valid only 
for the split~phere (4/~._and x/2). An itluminance value with an error of zero (P~ equal to P) will have 
infinite weight. All values with an estimated error less than a will be included in the set of adjacent 
illuminances, S. If S is empty, a new primary illuminance value must be calculated at ~. (An efficient 
method for determining the members of S is given in the next section.) The constant a is directly related 
to the maximum approxima- tion error. When the approximation is applied to the split sphere, the error 
is less than 1.4aE, where E is a straight average of Ei over 5'. In general, the illuminance gradient 
may be larger or smaller than the split sphere, but it will always be roughly propor- tional to a. It 
is interesting to note that for a less than or equal to 1, S will not contain any value farther than 
the average spacing or with a surface normal more than 90 degrees from the test location. Intuitively, 
such a value would be expected to have 100% error. In practice, additional tests are required to restrict 
the values included in S. The ray recursion depth must be considered so that values computed after one 
or more bounces are not substituted for final illuminances. This is easily prevented by keeping separate 
value lists at each recursion level. A different problem arises from our generalization of the split 
sphere model. Equation (4) assumes that motion in any direction is equivalent to motion in z. As a result, 
the set S can include illuminance values that tie on objects shadowing the test point, P (Figure 4). 
We therefore introduce a test to reject illuminanee values that are "in front" of if: (6) If d~(P) is 
less than zero, then ~,. is in front of/~ so the value is excluded. / / Figure 4: Po sees few close-by 
surfaces, so its estimated error at ~ is small. But ~ i3 shadowed by the surface under/~o, and the true 
illuminance is different. Caching indirect illuminance is simple and efficient. The error estimate results 
in a minimum of primary evaluations and a nearly constant accuracy. Sections of the scene that do not 
contribute to the image, directly or indirectly, are not examined since no rays reach them. Areas where 
the indirect illuminance varies rapidly, from changing surface orientation or the influence of nearby 
objects, will have a higher concentration of values. Flat areas without nearby influences will have only 
a few values. Dynamic evaluation obviates surface discretization and presampling, so scene representa- 
tion is not restricted. Figure 5a shows three colored, textured blocks on a table illuminated by a low-angle 
light source. Figure 5b shows the place- ment of indirect illumlnance values. Note that the values crowd 
around inside corners, where surfaces are in close visual contact, and outside corners, where the surface 
curvature is large. Also, the space between and immediately surrounding the blocks is more densely populated 
than the background, where only a few values are spread over a wide area. This distribution is different 
from the stan- dard radiosity technique, which computes values at grid points on each surface. By selecting 
value locations based on the estimated illuminance gradient, a more accurate calculation is obtained 
with fewer samples. Averaging illuminance values over surfaces results in lower pixel variance than produced 
by standard ray tracing techniques. Figure 5e was produced by a pure Monte Carlo computation that used 
as many rays as the calculation of Figure 5a. The speckling results from inadequate integration of the 
indirect contributions at each pixel. Since every pixel requires a separate calculation, only a few diffuse 
samples are possible over the hemisphere. ]f a sample happens to catch a bright reflection, the illuminance 
computed at that point will be disproportionately large. Caching permits a better integration to be performed 
less frequently, thereby obtaining a more realistic rendering than is feasible with pixel-independent 
ray tracing. 3.3. Illumlnance Storage For the secondary method to be significantly faster than the primary 
method, we need an efficient technique for finding the members of S (Equation 5). Without placing any 
restrictions on scene geometry, an octrce permits efficient range searching in three dimensions [1]. 
A global cube is identified that encompasses all finite surfaces in the scene. When the primary method 
calculates a new indirect illuminanee at a scene location, the global cube is sub- divided as necessary 
to contain the value. Each illuminance, E i , is stored in the octree node containing its position, /~i, 
and having a size (side length} greater than twice but not more than four times the appropriate "valid 
domain," aR~. This guarantees that the stored illuminance value will satisfy the condition for S in no 
more than eight cubes on its own octree level, and a value with a small valid domain will only be examined 
in close-range searches. Each node in the octree will contain a (possibly empty) list of illuminance 
values, and a (possibly nil) pointer to eight children. (A two- dimensional analogy is given in Figure 
6.) To search the tree for values whose valid domain may contain the point P, the following recumive 
procedure is used: For each illuminanee value at this node Ifwe(P)>l/a and di(J~)~O Include value For 
each child If/~ is within half the child's size of its cube boundary Search child node This algorithm 
will not only pick up the nodes containing ~, but will also search nodes having boundaries within half 
the cube size of ~. In this way, all lists that might have an illuminance value whose valid domain contains 
/~ will be examined. The worst case performance of this algorithm is O (N), where N is the number of 
values. Performance for a uniform distribution is O (log (N)). The scale of the sorting algorithm can 
be changed so' that the octree cubes are either larger or smaller than the domains of the values they 
contain. If the cubes are smaller, each examined list will be more likely to contain usable values. However, 
many of the cubes will be empty. If the cubes are larger, more of the values will have to be examined, 
but less searching through the tree will be necessary. In any case, changing the scale does not affect 
the func- tioning of the algorithm, only its performance in a given situation.    SIGGRAPH '88, Atlanta, 
August 1-5, 1988 5. Discussion Because our averaging technique was derived from a simplified model (the 
split sphere), it is important to study its performance in situations where the model is not predictive. 
Two such cases are illustrated in Figure 11. They are both related to bright, localized reflections, 
such as those that might result from a spotlight or mir- ror. If a bright spot is partially hidden by 
an occluding surface, or on the horizon, then small changes in element location and orienta- tion can 
result in large changes in illuminance. The averaging tech- nique we have developed will not respond 
appropriately, and the error related to a will be much larger than the original split sphere model. However, 
bright spots also make trouble for the Monte Carlo calculation, which requires a higher sample density 
to find and integrate such luminance spikes. There is no known lighting calcu- lation that can track 
these small "secondary sources" efficiently. Our technique uses a smaller value for a together with a 
higher Monte Carlo sample density to model these effects, with a corresponding increase in complexity. 
Bright reflection partially occluded by dark object Bright reflection on horizon Surface e}ement Figure 
11: Two cases of indirect illumination that are difficult to model. Besides diffuse interreflection, 
the caching technique can also be applied to illumination from large sources, such as a window or the 
sky. Wide area sources present a problem for conventional ray tracing cMculations because they are diffmult 
to sample adequately. Normally, when a ray participating in the diffuse interreflection cal- culation 
hits a light source, it is ignored. This prevents counting light sources twice, since they participate 
in a separate direct com-ponent calculation. By moving a large source from the direct to the indirect 
step of the computation, it is possible to obtain a more accurate sampling of its area. We have found 
this approach effective for sources with a solid angle greater than 1 steradian. The calculation of diffuse 
transmission can also be accelerated by caching. Translucent surfaces become more difficult to model 
with conventional point sampling techniques as they become more nearly diffuse. The indirect calculation 
can be used to obtain a more accurate integral of light striking a translucent surface on either side. 
If the transmission function is not purely diffuse, scat- tered specular rays can be used to supplement 
the Monte Carlo cab culation, just as they are for reflection. 6. Conclusion We have developed an efficient 
ray tracing method for calcu- lating diffuse interreflection, which when combined with standard computations 
of direct and specular contributions results in a com- plete simulation of global illumination. Only 
those illuminance com- putations required for accurate reridering are performed, and the values can be 
reused in other images. Thus the method provides an good mix of view-dependent and view-independent qualities. 
The criterion for evaluation of diffuse interreflection is an estimate of the illuminance gradient from 
convenient measures of scene geometry. The separation of lighting and geometric models is a basic strength 
of ray tracing, and it is preserved in this technique. The method can also model diffuse transmission 
and illumination from large area sources. 7. Acknowledgements Our thanks go to the reviewers for their 
comments, and to Sam Berman for his continuing support. We would also like to thank the LBL Computer 
Science Research Department and the UCB Center for Environmental Design for the use of their equip- meut. 
Our special thanks go to Bill Johnston and Paul Heckhert. This work was supported by the Assistant Secretary 
for Conserva- tion and Renewable Energy, Office of Building Energy Research and Development, Buildings 
Equipment Division of the U.S. Department of Energy under Contract No. DE-AC03-76SF00098. 8. References 
1. Bentley, Jon Louis and Jerome Friedman, "Data Structures for Range Searching," ACM Computing Surveys, 
Vol. 11, No. 4, 1979, pp. 397-409. 2. Cohen, Michael and Donald Greenberg, "A Radiosity Solution for 
Complex Environments," Computer Graphics, VoL 19, No. 3, July 1985, pp. 31-40. 3. Cohen, Michael, Donald 
Greenberg, David Immel, Phillip  Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis~" 
IEEE Computer Graphics and Applications, Vol. 6, No. 2, March 1986, pp. 26-35. 4. Cook, Robert L. and 
Kenneth E. Torrance, "A Reflection Model for Computer Graphics," ACM Transactions on Graph-its, Vol. 
1, No. 1, January 1982, pp. 7-24. 5. Cook, Robert, Thomas Porter, Loren Carpenter, "Distributed Ray 
Tracing," Computer Graphics, Vol. 18, No. 3, July 1984, pp. 137-147. 6. Cook, Robert L., "Stochastic 
Sampling in Computer Graph- ics," ACM Transaction8 on Graphics, Vol. 5, No. 1, January 1986, pp. 51-72. 
 7. Immel, David S., Donald P. Greenburg, Michael F. Cohen, "A Radiosity Method for Non-Diffuse Environments," 
Computer Graphics, Vol. 20, No. 4, August 1986, pp. 133-142. 8. Kajiya, James T., "The Rendering Equation," 
Computer Graphics, Vol. 20, No. 4, August 1986, pp. 143-150. 9. Kaufman, John, IES Lighting Handbook, 
Reference Volume, IESNA, New York, N-Y, 1981. 10. Nishita, Tomoyuki and Eihachiro Nakamae, "Continuous 
Tone Representation of Three-DimensionM Objects Taking Account of Shadows and Interreflection," Compu-tcr 
Graphics, Vol. 19, No. 3, July 1985, pp. 23-30. 11. Rubenstein, R.Y., Simulation and the Monte Carlo 
Method, J. Wiley, New York, 1981. 12. Siegel, R. and J. R. Howell, Thermal Radiation Heat Transfer, 
Hemisphere Publishing Corp., Washington DC., 1981. 13. Wallace, John R., Michael F. Cohen, DonMd P. 
Greenburg, "A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radlosity Methods," 
Computer Graphlcs, Vol. 21, No. 4, July 1987, pp. 311-320. 14. Weghorst, Hank, Gary Hooper, Donald P. 
Greenburg. "Improved computational methods for ray tracing" ACM Transactlon8 on Graphics, Vol. 3, No. 
1, January 1984, pp. 52-69: 15. Whitted, Turner, "An Improved Illumination Model for Shaded Display," 
Communfcations of the ACM, Vol. 23, No. 6, June 1980, pp. 343-349.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378492</article_id>
		<sort_key>93</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[A new radiosity approach by procedural refinements for realistic image sythesis]]></title>
		<page_from>93</page_from>
		<page_to>99</page_to>
		<doi_number>10.1145/54852.378492</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378492</url>
		<abstract>
			<par><![CDATA[According to the rendering equation, the diffuse and the specular components of the outgoing intensity of each surface patch should be solved simultaneously. Rather than establishing a huge set of linear equations defining the unknown directional intensities for all directions and all surface patches, we expand the concept of the delta form-factor which concerns the light energy transfer of a surface patch along a respective direction. As the delta form-factor for non-diffuse surface patches are dependent on the spatial and spectral distributions of light energy, they could not be calculated geometrically. In this paper, we present a new radiosity approach which progressively approximates the delta form-factors and the light energy distributions within a general environment to the correct solution. The nucleus of our approach is procedural iteration. Statistics indicate the potentials of this method for complex non-diffuse environments.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[distributed ray tracing]]></kw>
			<kw><![CDATA[form-factors]]></kw>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[hemi-cube]]></kw>
			<kw><![CDATA[procedural iteration]]></kw>
			<kw><![CDATA[progressive refinement]]></kw>
			<kw><![CDATA[radiosity]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39039473</person_id>
				<author_profile_id><![CDATA[81542180356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Min-Zhi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[CAD/CAM Research Center, Zhejiang University, P. R. OF CHINA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P228943</person_id>
				<author_profile_id><![CDATA[81451598508]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Qun-Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[CAD/CAM Research Center, Zhejiang University, P. R. OF CHINA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310140500</person_id>
				<author_profile_id><![CDATA[81540682956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[You-Dong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[CAD/CAM Research Center, Zhejiang University, P. R. OF CHINA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F., and Greenberg, D.P., The Hemi- Cube: h Radiosity Solution for Complex Environments, Computer Graphics (Proceedings SIGGRAPH 85), Voi.19, No.3, July 1985, pp.31-40.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cohen, M. F., Greenberg, D. P., Immel, D. S., and Brock, P. J., An Efficient Radlosity Approach for Realistic Image Synthesis, IEEE CG&amp;A, Vol.6, No.3, March 1986, pp.26-35.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Stochastic Sampling in Computer Graphics, ACM Transactions on Graphics, Vol.5, No.I, January 1986, pp.51-7Z.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, R.L., Porter, T., and Carpenter, L., Distributed Ray Tracing, Computer Graphics (Proceedings SIGGRAPH 84), Vol.18, No.3, July 1984, pp.137-I45.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Goral, C. M., Torrance, K. E., Greenberg, D. P., and Battaile, B., Modeling the Interaction of Light Between Diffuse Surfaces, Computer Graphics (Proceedings SIGGRAPH 84), Vol.18, No.3, July 1984, pp.213-2Z2.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hall, R. A., and Greenberg, D. P., A Testbed for Realistic Image Synthesis, IEEE CG&amp;A, Vol.3, No.8, November 1983, pp.10-20.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Immel, D. S., Cohen, N. F., and Greenberg, D. P., A Radiosity Method for Non-Diffuse Environments, Computer Graphics (Proceedings SIGGRAPH 86), Vol.20, No.4, August 1986, pp.133-142.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T., The Rendering Equation, Computer Graphics (Proceedings SIGGRAPH 86), Vol.20, No.4, August 1986, pp.143-150.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Rogers, D. F., Procedural Elements for Computer Graphics, McGraw-Hill, New York, 1985.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Siegel, R., and Howell, J. R., Thermal Radiation Heat Transfer, Hemisphere Publishing Corporation, Washington DC., I981.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sparrow, E. M., and Cess, R. D., Radiation Heat Transfer, Hemisphere Publishing Corporation, Washington DC., 1978.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Varga, R. S., Matrix Iterative Analysis, Prentice-Hall, New Jersey, 196Z.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wallace, J. R., Cohen, M. F., and Greenberg, D. P., A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radiosity Methods, Computer Graphics (Proceedings SIGGRAPH 87), Vol.21, No.4, July 1987, pp.311-320.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Whitted, T., An Improved Illumination Model for Shaded Display, Comm. ACM, Vol.23, No.6, June 1980, pp.343-349.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ Computer Graphics, Volume 22, Number 4, August 1988 A NEW RADIOSITY APPROACH BY PROCEDURAL REFINEMENTS 
FOR REALISTIC IMAGE SYNTHESIS Min-Zhi Shao, Qun-Sheng Peng, You-Dong Liang CAD/CAM Research Center 
Zhejiang University P. R. OF CHINA ABSTRACT According to the rendering equation, the diffuse and the 
specular components of the outgoing intensity of each surface patch should be solved simultaneously. 
Rather than establishing a huge set of linear equations defining the unknovn directional intensities 
for all directions and all surface patches, we expand the concept of the delta form-factor which concerns 
the light energy transfer of a surface patch along a respective direction. As the delta form-factor for 
non-diffuse surface patches are dependent on the spatial and spectral distributions of light energy, 
they could not be calculated geometrically. In this paper, we present a new radtosity approach which 
progressively approxisates the delta form-factors and the light energy distributions within a general 
environment to the correct solution. The nucleus of our approach is procedural iteration. Statistics 
indicate the potentials of this method for complex non-diffuse environments. CR Categories and Subject 
Descriptors: 1.3.3 [Computer Graphical: Picture/Image Generation; 1.3.7 [Computer Graphics): Three-Dimensional 
Graphics and Realism General Terms: Algorithms Additional Key ¥ords and Phrases: Distributed ray tracing, 
form-factors, global illumination, hemi-cube, procedural iteration, progressive reftnement,radiostty 
INTRODUCTION In recent years, along with the vigorous developments of computer graphics, ray tracing 
and radiosity methods have gradually become the tee main techniques for realistic Image synthesis. Permission 
to copy without fee all or part of this material is granted provided that the copies are not made or 
distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 
ACM-0-89791-275-6/88/008/0093 $00.75 Ray tracing is used as a method of determining the global illumination 
information that is relevant to the image plane. It correctly simulates the light outgoing a smooth surface 
by mirror reflection and regular transmission. Since the methodology sam introduced by Yhitted [14) in 
1980, it has been widely used and has generated some of the most realistic images to date. However, there 
are many scenes that cannot be adequately modeled by ray tracing. The illumination model posed by ray 
tracing method ignores the interaction of light between diffusely reflecting surfaces. Furthermore, the 
ray tracing methodology, which just provides limited point-sampled information, is not sufficient for 
the application of energy equilibrium models to light behavior. Only the tntra-environment specular effects 
are considered. [6) In 1984, Goral et el. [51 introduced a so called radtosity method from thermal engineering 
[10) [11) to computer graphics. This method models the interaction of light between diffusely reflecting 
surfaces and accurately presents the global Illumination effects. Since then, Cohen et al. successively 
proposed tee famous algorithms to make the radlomity method a practical rendering technique. One is the 
hemi-cube algorithm which extends the radiosity solution to environments with occluded surfaces so as 
to render complex scenes (I); the other is the aubstructurtng algorithm vhtch provides means for local 
discretization of critical portions of the environment vithout affecting the remainder of the global 
solution CZ~. Honorer, the ideal diffuse reflection is assumed in all those algorithms and specular reflections 
from non-diffuse surfaces are not considered. This unfortunately limited the extensive use of the radiosity 
method. Since the form-fectors in non-diffuse environments are dependent on the spatial and spectral 
distributions of light energy and should be evaluated conforming to the specific illumination attributes 
of each surface, a modified hemi-cube algorithm shfch successively approximates the correct form-factors 
of general complex environments is introduced in this paper. The nucleus of our method is procedural 
iteration. First, we obtain a sketchy light distribution of the environment by applying a standard radlostty 
method. Then, the nee form-factors of non-diffuse patches are calculated according to this distribution. 
They In turn propose a more accurate light distribution within the environment. After several repetitions 
ef the iteration, we arrive at the correct solution. Note that a constant radically is assummed for 
 each surface patch and an accurate light radiation distribution at the sample point of each patch is 
retained. This may suggest a direct scan line cenversion to generate the desired image, However, since 
the specular component of the outgoing intensity typically changes very quickly over the patch, a view- 
independent solution may require that the specular surfaces be subdivided into fine details, invoking 
enormous amount of computations. Rather, we adopt a two-pass approach and employ distributed ray tracing 
 to evaluate the specular components of the outgoing intensities of the concerned surface patches which 
contribute to the final vies-dependent image. Statistics indicate the potentials of this procedure for 
complex non-diffuse realistic image synthesis. GLOBAL ILLUMINATION NODBLS FOR GENERAL BNVlRONRBNTS Although 
both ray tracing and radiosity are recognized as global illumination solutions, they describe only the 
two extreme situations of light energy distributions within ideal environments. Nuch efforts were made 
to remedy the deficiencies of the twe methods to cover a more general situatien. From the angle of ray 
tracing: In 1984, Cook et al. [3) [4] presented the algorithm of distributed ray tracing. This algorithm 
provides a correct and easy solution to some previously unsolved or partially solved difficult problems 
in ray tracing, including fuzzy reflections. In 1986, Kajiya [8) made some further advances on the idea 
of Cook's method. He described an algorithm that solves a so called rendering equation using Nonte Carlo 
and variance reduction techniques for stochastic ray tracing. Although, theoretically, thls approach 
could eventually converge to the accurate solution, the computation time would preclude the substantial 
increase of the sample points. Then, the inefficiency of point-sampling becomes the main problem. It 
has not been well solved for general complex environments, especially concerning the diffuse reflection. 
From the angle of radiosity: In 1986, Immel et al. [7) firstly introduced a general radiosity method 
accounting for all interreflections of light between diffuse and non-dlffuse surfaces in complex environments. 
The relationship between a patch and all other patches in the environment becomes, in this method, a 
relationship between a given outgoing direction for a patch and all outgoing directions for all other 
patches. Unfortunately, the computational resources te be expended are too huge to make this method a 
practical approach. In 1987, Yallace et al. [13) presented a two-pass  approach that integrates ray 
tracing and radiosity into a whole. It is thus capable of dealing with complex environments (including 
mlrror surfaces). The first pass is based on the hemi-cube radiosity algorithm with extension to include 
the light energy transfer via diffuse to specular, specular to specular and specular to diffuse mechanism, 
the second pass is based on an alternative to distributed ray tracing. The two-pass approach which 
combines ray tracing and radically organically, takes advantages of both the classic methods and avoids 
their shortcomings. This is a successful scheme indeed. By careful analysis ef the two-pass approach, 
we can easily see that the crux step is the first pass which calculates the vlew-independent illumination 
effects for a non-diffuse environment. According to the rendering equation, the outgoing intensity of 
a surface is composed of three components, namely an emission term, a diffuse term and a specular term: 
Iout(Oou t) = E(Oou t) + Id,ou t (i) + Is,out(Oou t)  where Id,°ut = <dOd I Iin(Oin)C°S(e)d~ (2) Is,out(Oou 
t) = (3) Ks [ Os(Oout'@in)Iin(Oin)C°S(O)d~  with K d , K s indicating respectively the diffuse and 
the specular reflection coefficients of the surface, Kd + ~s = i . Obviously, the outgoing diffuse and 
specular terms each depend on all incoming intensities of the surface. As these incoming intensities 
are just the eutgolng intensities from other surfaces, they in turn contain both diffuse and specular 
components.(13) Thus it is impossible to derive an accurate diffuse energy distribution of the environment 
without precisely determining the specular reflection component of each surface. In other words, both 
diffuse and specular terms of the outgoing intensity of each patch should be solved simultaneously by 
one integrated process. Yallace et al. simplified the situation by assuming all non-dlffuse surfaces 
to be planar mirror surfaces. To incorporate the effects of these mirror surfaces, Yallace adopted a 
so called image method (11) from thermal engineering. The principle is simple and straightforward, namely 
that the light reflected from a plane mirror appears to come from an image located behind the mirror 
(Figure I). Apparently, each mirror introduces an additional virtual world into the environment. F q' 
D q I I I I I t E A p B Figure I. Enclosure with one specular surface (AD).  @ Computer Graphics, Volume 
22, Number 4, August 1988 Now let us make a brief analysis on the image method (Figure 2). If AD is a 
mirror, then one projection of all patches in front of AD turns the entire environment into EBCF, in 
which the number of the patches almost increases by one time. If DC is also a mirror, the further mirror 
reflections turns the environment into EBHI, and the number of the patches within EBHI increases nearly 
three times. Note that the total computation time of form-factors Is of O(N2) (N is the number of patches 
in the environment, representing the complexity of the environment). As the calculation of form-factors 
will cost about 90g of computation tlme in the implementation of the radlosity method, the image method 
may turn to be a very expensive solution when the mirror surfaces introduced into the environment are 
increased. In general, with multiple interreflections between mirror surfaces, the computation time may 
go up in exponential order. This is because the images have their images too. Consequently, a simple 
environment may get very complicated after several mirror reflections. I G H [ F-1 I I ] \\\\\\ \\ \\ 
k\\ \\\V  Ft I I I I I E A B Figure 2. Enclosure with two adjacent (AD,DC) and three arbitrarily positioned 
(X,Y,Z) specular surfaces.  This paper presents a new radiosity approach and solves the problem effectively. 
The concept of delta form-factors is developed to simulate both the diffuse and specular reflections 
of each surface patch. The correct light energy distribution of the environment is determined by a single 
pass. Non-diffuse surfaces in such an environment may possess arbitrary illumination attributes and need 
no longer be limited to perfect planar mirrors. PROCEDURAL REFINEMENT Firstly, we define the form-factor 
between any two patches in a general complex environment. The form-factor of patch i to patch j can be 
defined as follows: B.. F.. = ~O (4) l~ B. 1 where B.. represents the light energy that is iJ  transfered 
directly to patch j from patch i, and B. i  represents the total radiant light energy of patch i. Generally, 
in an ordinary non-diffuse environment,  we have: d s Fij = <idFij + KisFij (5)  where F d ij represents 
the fraction of light energy transfer to patch j via diffuse reflections of patch i and can be calculated 
using the standard hemi-cube algorithm, F-s- 13 represents the other portion of light  energy transfer 
to patch j via spicular reflections of N d s patch i ( ~ F I. = I , E F I. = i , so  N j =l 3 j =l J 
F i. = 1 are coefficients regarding  j=l J )" Kld' Kis the diffuse and the specular reflection of patch 
i respectively ( Kid + Kis = I). Note that the definition of form-factor in our approach is different 
from that in the previous two-pass method. This leads to a series of differences between the two algorithms. 
The following points are then listed: I. Bij is not limited to the radiant light energy transfered 
from patch i to patch j by diffuse reflection. It also includes the light energy which is transfered 
from patch i via self specular reflection to patch J (if patch i is a specular patch). Thus, Bij represents 
the total energy that is directly transfered from patch i to patch j. 2. Bij concerns the direct radiant 
light energy transfer only. The light energy being transfered from patch i to patch j via any other 
intermediate patches is not included. For instance, the light energy radiated from patch i then reflected 
by mirror k and landed on patch j is not included in Bij . This part of energy, according to our definition 
of the form-factor, is determined by B k and Fk~ J . (Figure 3) 3. For an ideal diffuse patch i, the 
form-factor Fij (j may be any other patch in the environment) depends only on the relative locations 
of patch i and patch j and accounts for nothing with the distribution of light energy in the environment. 
 Though B. may vary (which happens during a 1 disturbance of the enclosure), the fraction of its energy 
which is transfered to any other patch in the environment remains the same. In other words, its form-factor 
is purely geometrical. (Figure 4) 4. If patch i is a specular patch, however, the form-factor Fi~a will 
depend on the spatial and  SIGGRAPH '88, Atlanta, August 1-5, 1988 .,  Figure 3. The light energy 
from patch i which is reflected by mirror k and then transfered to patch j is not included in B... 13 
 N i  Figure 4. Form-factor geometry Figure 5. Light energy distribution and form-factor. spectral 
distributions of light energy in the environment. For example, in Figure 5, patch j and patch k are reflection 
symmetrical about patch i. If i is an ideal diffuse patch, then Fij = Fik But if i is a mirror patch, 
the matter will not be so simple. If k is a light source, Fij turns greater. On the other hand, if k 
is a blackbody, Fi~ J will turn smaller. Since the total distribution of light energy in the environment 
is unknown (in fact, this is exactly what we want to resolve), it is difficult to evaluate the specular 
form-factors of non-diffuse patches in a immediate way. Therefore the nucleus of our ~ork is to approximate 
these form-factors first, then successively refining them by procedural iterations. Finally, we obtain 
the correct distribution of light energy within a general complex environment Analogous to the traditional 
radiosity method, we have: N Bi = Ei + B'F''A'/A'[-31 3 i ' i=l'N (6) Pij[l 3  where B i = radiosity 
of patch i which is the total rate of radiant energy leaving the patch per unit time per unit area (watts/meter,,2) 
E i = rate of direct energy emission from patch i per unit time per unit area (watts/meter*,2) Oi = reflectivity 
of patch i and represents the fraction of incident light which is reflected back into the hemispherical 
space (unitless) F.. = form factor which represents the fraction of J l radiant energy leaving patch 
~ and impinging on patch i (unitless) A. = area of patch i (meter,,2) 1 Note that in general non-diffuse 
environments, the following identical equation: F..A. : F..A. (7) 1J i ~i J is not tenable, hence expression 
(6). In this equation, BjFjiA j represents the radiant light energy leaving patch j and impinging on 
patch i. After being divided by A i and then multiplied by Pi ' it represents a portion of the radioslty 
of patch i which is contributed by patch j. Denote Aji = Aj/A i and Dij = FijAij, we obtain the following 
set of linear equations: " -I " i-PlDii -OLD21 .... oiDNi Bi I E1  -P2Di2 i-P2D22~'" -P2DN2 B 2 E 
2 = (8) I I ° "PNDiN -PND2N"  i-PND~:N .BN] S2~ Note: The matrix is formed and solved for the radiostties 
regarding each color band of interest. It is usually solved for three channels (R, G, B) but could be 
done on a wavelength basis if desired. Not only Oi but also Fij may have different values for each channel 
@ Computer Graphics, Volume 22, Number 4, August 1988 I | Next, we discuss the calculation of form-factors 
of specular patches. An imaginary hemi-cube is created around the center (sample point) of each specular 
patch, all other patches in the environment are then projected onto the cube. (Figure 6) Each pixel on 
the hemi-cube relates to a specific patch index, and each patch index refers to a certain radiosity. 
So a hemi-cube retains not only the geometrical, but also the physical characteristics of the related 
patches in the environment. In fact, it has the global light energy distribution of the environment projected 
onto its faces. Therefore, the form-factor of patch k to every other patch in the environment can be 
easily obtained as soon as the delta form-factor is calculated which concerns the light energy transfer 
along a direction from the sample point to every pixel on the hemi-cube within a solid angle. Z q i 
 Y ~_~ ,"    qqT f I % k  Figure 6. The distribution of light energy in the environment is projected 
on the hemi-cube. Now let us consider the delta form-factor associated with any pixel p on the imaginary 
hemi-cube of a specular patch k (Afkp). Firstly, we find out the pixel q which is reflection symmetrical 
with p on the hemi-cube. Apparently, the radiant energy which is transfered towards pixel p by specular 
reflection of patch k is released by surface patches recorded in pixel q and pixels around q. If k is 
a perfect mirror patch, we have the following expression: PkBqAA B hfkp = = % {9) Pk Z (BsAA) Z B s 
s s  where B is the partial radiosity of a surface patch s recorded in pixel s reaching patch k from 
a corresponding direction, thus Z (BsAA) represents S  the total energy landed on patch k. As O k is 
the reflectivity of patch k, Afkp represents the fraction of energy leaving patch k in a specified direction. 
Obviously, nZ Afkp = I. If k is not a perfect mirror patch (e.g. it satisfies the Phong distribution, 
see Figure 7), we sample pixel q and pixels around q, and calculate the weighted average (weights are 
determined by the specified bidirectional reflectance of patch k). sampling area ,l_pixel q Nk pixel 
p B C.  ¢////[/////// M k Figure 7. Weighted sampling according to the related bidirectional reflectance. 
 In general, for each patch k in the environment, we havel + < af~ (10) Afkp = KdAf p s p in which, 
Af~p is the diffuse delta form-factor, Af~p is the specular delta form-factor. Since , A s = i, then 
~ Afkp = i. Z hf = i E fkp p P p P It satisfies the normal condition for form-factors. Particularly, 
if K d = 0 , k is a perfect mirror = patch; if K s 0 , patch k is ideal diffuse. Finally, we give the 
basic program structure o5 our procedural iterative and progressive refined radiosity method. STEP [. 
Assume the whole environment to be an ideal diffuse environment first, The form-factors between all pairs 
of patches within the environment are calculated using the standard hemi-cube algorithm, and the radiosity 
of each patch is then obtained. Meanwhile, the hemi-cube of every non-diffuse patch is preserved as an 
item buffer with each item retaining the information of patches visible from the corresponding pixel 
on the cube. All form-factors are then calculated. The results are correct for the ideal diffuse patches 
but just rough estimations for the non-diffuse patches. Since specular reflections account for only a 
small proportion of the total radiant light energy within the environmeat, we have obtained a relatively 
correct radiosity solution for the whole environment, although in some directions (e.g. the mirror reflecting 
direction of light source) the error might be very large.  STEP 2. Now we take the radiosity of each 
patch obtained in the first step as the initial value (the distribution of light energy on the hemi-eube), 
recalculate the form-factors (R, G, B) of the non-diffuse patches. We firstly find out the pixel q which 
is reflection symmetrical with each pixel p on the hemi-cube (Figure 6). If the index of visible patch 
preserved in pixel q is i, then BiFikis the radiosity of plxel q to patch k. Calculate the weighted average 
of delta form-factors at pixels around q according to the distribution function of bidirectional reflectance 
of patch k and evaluate the delta form-factor Afkp (R, G, B) using formular (9) and (I0). Since the hemi~eube 
Of every non-diffuse patch has been preserved in a data file, this step involves only reading from the 
data file and sampling pixels on the hemi-cube, avoiding the more expensive process of patch clipping 
projecting and hidden surface removal. (9~ SEPT 3. Solve the global systems of linear equations again 
with the more accurate form-factors of the non-diffuse patches and obtain a new solution of light energy 
distribution of the environment. Comparing the radioslty of each patch with its previous value. If the 
difference is smaller than a given tolerance, then the iteration process is accomplished, otherwise, 
go to step 2 and repeat the above processes. It should be mentioned that every environment in the radiosity 
method is assumed to be an enclosure. No energy could be transfered in, and no energy might be scattered 
out. The enclosure always maintains its light energy balance. Furthermore, it is a stable equilibrium, 
namely once the balance is disturbed, it will reach the next equilibrium simultaneously. A simple example 
serves to illustrate this phenomenon. Let us construct two equivalent processes regarding the light energy 
transfer in an environment. (see Figure 8) ¥ithout losing generality, the situations of three patches 
A, B and C among the surfaces in the enclosure will be illustrated. In case I, patch A, B, and C are 
always treated as mirrors and the environment keeps in a certain equilibrium. In case 2, patch A, B, 
and C are treated as ideal diffuse reflectors first, but are gradually transformed into mirrors (the 
reflectivities remain the same). Therefore, the original balance is broken. As a fraction of light energy 
emitted by the light source will gradually transfer to these patches via their specular reflection, the 
form-factors FAB , FBC and the radiosities B A , B B , B C in Figure 8 will C o B A  Figure 8. The 
conservation of light energy in an enclosure. successively increase. Nevertheless, the scale of increments 
are gradually decreased as little of the light energy which is emitted by the source will transfer back 
to it again. And this happens to all patches in the enclosure. So case 2 is convergent. Clearly, our 
progressive refinement procedure is exactly the same with the energy conservation process mentioned above 
an~ will successively converge to the correct distribution. Implementations have demonstrated that the 
convergent speed of our algorithm is very fast. For general complex environments, the accurate light 
energy distribution may be obtained after four to six iterations. The time required by these iterations 
is less than 205 of that by STEP 1 which invokes a standard radiosity procedure. Compared with the image 
method, our approach is regular and fast. It is a breakthrough to the traditional method in radiative 
heat transfer. RESULTS Figure g (A) and (B) show a test environment. The left object is a volume light 
source. All of its surfaces emit light energy except the top one (in green). In the right side, the blue 
object is a light- shelter. It shields off the direct illumination by the volume light source to the 
right wall. Overall illumination of the room is provided by two dim area light sources on the ceiling. 
In Figure 9(A), all patches in the environment are ideal diffuse. The image is generated using the standard 
radiosity method. In Figure 9(B), the floor is treated as a non-diffuse surface (<d = 0.~ , <S = 0.6 
). The image is generated using our progressive refined radiosity method. The effect of specular to 
diffuse reflection is accounted for. Please pay attention to the difference of the light energy distribution 
on the right wall and the subtle variation of the intensity of the blue light-shelter between image (A) 
and image (B). The number of iterations accomplished is five. The implementation data are listed in Table 
|, in which, MAXIMUM (AVERAGE) ERROR represents the maximum (average) errors of radiosities within all 
patches between two successive iterations. The fuzzy images on the floor are generated using a distributed 
ray tracing technique in the post-process. Figure 10 (~), (B) and (C) show a simple and crude room. In 
the middle of the front wall, there is a nearly perfect mirror ( ~d = 0.02 Ks = 0.98 ). A very bright 
light source (in blue) whose backface scatters light to the front wall is located at the left-top corner 
of the room. Figure ]O(A) is the top view. Figure IO(B) shows the environment in which all patches are 
treated as ideal diffuse reflectors. In Figure lO(C), the specular reflection of the mirror has been 
accounted for. Please pay attention to the differences of light spot on the floor, the right wall and 
the top of the table between these two images. Also note the changes of light intensity on the legs and 
the backface of the table appeared in the mirror. The implementation data about Figure ]0 are listed 
in Table 2, ~ Computer Graphics, Volume 22, Number 4, August 1988 For each mirror surface in Figure 
I0 (A), (B) and (C), the distributed ray tracing is used in the post-process. Since the main storage 
of our microcomputer is I Nb, we have no choice but to simplify the complexity of our test environments 
as far as possible, All lanterns are carefully made light enough to be suspended in midair. The program 
was written in C under an UNOS  operating system and ran on an gNIVERSE 68000. All images were displayed 
on a 640X480 resolution E&#38;S PS340 color screen. CONCLUSIONS The outgoing intensity of a surface 
patch in a general environment may consist of three components, namely an emission term, a diffuse term 
and a specular term. With the inclusion of the emission term and the specular term, the outgoing intensity 
of a surface becomes direction dependent. According to the rendering equation, the radiative intensity 
along an outgoing direction is the function of all incoming intensities arrived at the surface patch 
from the other directions and these incoming intensities, radiated by other surfaces in the environment, 
can also be decomposed into the above three terms. Thus, the diffuse and the specular components of light 
energy transfer between surface patches should be solved by one integrated process. Rather than establishing 
a huge set of linear equations defining the unknown directional intensities for all directions and all 
surface patches and solving them simultaneously, we expand the concept of the delta form-factor which 
concerns light energy transfer of a surface patch along a respective direction. @hile the delta form-factors 
for ideal diffuse surface patches are evaluated using the standard hemi-cube algorithm, the delta form-factors 
for non-diffuse surface patches are calculated by distributedly sampling the incoming incident rays within 
a solid angle. Apparently, these delta form-factors for non-diffuse surface patches are dependent on 
the spatial and spectral distributions of light energy and cannot be determined geometrically. An iterative 
solution is then developed. We first calculate the form-factors of all surface patches, ignoring specular 
reflections between them, and solve for the radiosity for each surface patch. The more accurate form-factors 
for non-diffuse surface patches are obtained based on the light energy distribution of the environment 
just derived. Thus, both the delta form-factors for non-diffuse surface patches and hence the light energy 
distribution of the environment can be successively approximated to the correct solution by procedural 
iterations. Statistics indicate the potentials of this approach for solving complex non-diffuse environments. 
Although we have obtained the average radiosity of each surface patch, the spatial and spectral distributions 
of the outgoing intensity is accurate at the sample point of each non-diffuse surface patch only. Thus, 
instead of conducting a further discretization, we adopt distributed ray tracing as a post-process to 
evaluate the emission and the specular components of the outgoing intensities of the concerned surface 
patches which contribute to the final view-dependent image. Our approach is thus a two-pass solution. 
There are two main methods in solving systems of linear equations. One is the direct method (e.g. Gaussian 
elimination scheme): the other is the iterative method (e.g. Gauss-Siedel iteration scheme). The time 
required by Gaussian eliminatlve approach is of O(N 3) (N represents the order of linear equations). 
Therefore, for solving large systems of linear equations, the direct method is too awkward to be invoked 
and the iterative method is commonly used. It can greatly reduce the computation time in general cases. 
[12) This should give us some enlightenment. When the specular surfaces are included in the environment 
and the computation time increases hopelessly, why don't we try to use a seemingly unassured but actually 
smart progressive refined radioslty method? In fact, our approach is fast and effective for rendering 
non-diffuse environments (see Table | and Table 2). By the way, as a procedural iterative radiosity method 
proposed for computer graphics, we believe, it can also be effectively applied to thermal engineering 
for calculating the radiative heat transfer. Computer graphics is a new interdiscipline. Pursuing some 
well-painted non-existent pictures is not the whole purpose. Computer graphics ought to make greater 
contributions to the developments of other disciplines. This problem should, at least partially, be paid 
attention to in the future research. ACKNOWLEDGEMENTS We thank all those who helped in the preparation 
of this article. In particular, we are grateful to Prof. Tong-Guang lin for helpful suggestions and encouragement 
during this study. Thanks also go to Guo-Zhao Wang, Yi-Ning Zhu, Hue Xu and Ping-Ping Shun for many valuable 
discussions. Finally, we would llke to thank the reviewers for their helpful comments. This research 
was performed in the CAD/CAM Research Center at Zhejiang University. iTE ATfON FORM MATRIX MAXIMUM ERROR 
AVERAGE ERROR NUMBER FACTOR SOLUTION R I I G B R G B STANDARD RADIOSITY 207.6 Min 3,6 Min Ist 4.6 Min 
3.9 Min 178 161 167 29.307 23.071 26.941 2nd 4.6 Min 3,9 Min 9 4 4 1.054 0.602 0.741 3rd 4.6 Min 3.9 
Min 1 1 1 0.036 0.030 0.030 4th 4.6 Min 3.9 Min 1 1 1 0.012 0.012 0.012 5th 4.6 Min 3.9 Min 0 0 0 0.000 
0.000 0.000 TOTAL 23.0 Min 19.5 Min Table i ITERATION FORM MATRIX MAXIMUM ERROR AVERAGE ERROR NUMBER 
FACTOR SOLUTION RlOi R G B STANDARDRADIOSITY 326.8 Min 3.9 Min ist 2.5 Min 4.1 Min 338 ~ 339 342 64.430 
68.774 62.439 2nd 2.5 Min 4.1 Min ii 16 5 0.529 0.783 0.362 3rd 2.5 Min 4.1 Min 2 3 -1 0.015 0.021 O.010 
4th 2.5 Min 4.1 Min 0 1 1 0.000 0.005 0.005 5th 2.5 Min 4.1 Min 0 0 0 0.000 0.000 O.000 TOTAL 14.5 Min 
20.5 Min Table 2 REFERENCES CI3 Cohen, M. F., and Greenberg, D.P., The Hemi- and Battaile, B., Modeling 
the Interaction of Cube: h Radiosity Solution for Complex Light Between Diffuse Surfaces, Computer Graphics 
Environments, Computer Graphics (Proceedings (Proceedings SIGGRAPH 84), Vol.18, No.3, July SIGGRAPH 85), 
Voi.19, No.3, July 1985, pp.31-40. 1984, pp.213-2Z2. Cz) Cohen, M. F., Greenberg, D. P., Immel, D. S., 
and (6) Hall, R. A., and Greenberg, D. P., A Testbed for Brock, P. J., An Efficient Radlosity Approach 
for Realistic Image Synthesis, IEEE CG&#38;A, Voi.3, Realistic Image Synthesis, IEEE CG&#38;A, Vol.6, 
No.8, November 1983, pp.10-20. No.3, March 1986, pp.26-35. [7) Immel, D. S., Cohen, N. F., and Greenberg, 
D. P., [3) Cook, R.L., Stochastic Sampling in Computer A Radiosity Method for Non-Diffuse Environments, 
Graphics, ACM Transactions on Graphics, Vol.5, Computer Graphics (Proceedings SIGGRAPH 86),No.I, January 
1986, pp.51-7Z. Voi.20, No.4, August 1986, pp.133-142. [4) Cook, R.L., Porter, T., and Carpenter, L., 
(8~ Kajiya, J. T., The Rendering Equation, Computer Distributed Ray Tracing, Computer Graphics Graphics 
(Proceedings SIGGRAPH 86), Vol.20, No.4, (Proceedings SIGGRAPH 84), Vol.18, No.3, July August 1986, pp.143-150. 
1984, pp.137-I45. (9) Rogers, D.F., Procedural Elements for Computer (5) Goral, C. M., Torrance, K. 
E., Greenberg, D. P., Graphics, McGraw-Hill, New York, 1985. IOO   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378494</article_id>
		<sort_key>103</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[ConMan]]></title>
		<subtitle><![CDATA[a visual programming language for interactive graphics]]></subtitle>
		<page_from>103</page_from>
		<page_to>111</page_to>
		<doi_number>10.1145/54852.378494</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378494</url>
		<abstract>
			<par><![CDATA[Traditionally, interactive applications have been difficult to build, modify and extend. These integrated applications provide bounded bounded functionality, have a single thread of control and a fixed user interface that must anticipate everything the user will need.Current workstations allow several processes to share the screen. With proper communication between processes, it is possible to escape previous models for application development and evolution.<i>ConMan</i> is a high-level visual language we use on an IRIS workstation that lets users dynamically build and modify graphics applications. To do this, a system designer disintegrates complex applications into modular components. By interactively connecting simple components, the user constructs a complete graphics application that matches the needs of a task. A connection manager controls the flow of data between individual components. As a result, we replace the usual user-machine dialog with a dynamic live performance that is orchestrated by the user.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[visual programming languages]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>User interfaces</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Languages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.3.2</cat_node>
				<descriptor>Data-flow languages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.3.2</cat_node>
				<descriptor>Nonprocedural languages**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.1.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003128</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011058</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Visual languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009.10011016</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types->Data flow languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011069</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Integrated and visual development environments</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P335034</person_id>
				<author_profile_id><![CDATA[81100466522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Haeberli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics, Inc., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[David Blythe, John Kitamura, David Galloway and Martin Snelgrove, "Virtual Patch-Cords for the Katosizer", Computer Systems Research Institute, University of Toronto, Toronto, Ontario, Canada, 1986.]]></ref_text>
				<ref_id>Blythe 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Luca Cardelli, "Fragments of Behavior", Personal Communication. DEC Systems Research Center, Palo Alto, CA, 1985.]]></ref_text>
				<ref_id>Cardelli 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325238</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Luca Cardelli, and Pike, R., "Squeak: a language for communicating with mice", Computer Graphics, 1985.]]></ref_text>
				<ref_id>Cardelli 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[David Galloway, David Blythe and Martin Snelgrove, "Graphical CAD of Digital Filters", Proceedings of IEEE Conference on Computers, Communications, and Signal Processing, June 1987.]]></ref_text>
				<ref_id>Galloway 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Paul Haeberli, "A Data-Flow Manager for an Interactive Programming Environment", Proceedings of Usenix Summer Conference, 1986.]]></ref_text>
				<ref_id>Haeberli 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37411</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Paul S. Heckbert, "Ray Tracing dell-O Brand Gelatin", Computer Graphics, 1987. {Hoare 78} C.A.R. Hoare, "Communicating Sequential Processes", Communications of the ACM 21(8), August 1978.]]></ref_text>
				<ref_id>Heckbert 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Takayuki Dan Kimura, "Determinancy of Hierarchical Dataflow Model", Technical Report WUSC- 86-5, Department of Computer Science, Washington University, March 1986.]]></ref_text>
				<ref_id>Kimura 86a</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Takayuki Dan Kimura, Julie W. Choi, and Jane M. Mack, "A Visual Programming Language for Keyboardless Programming", Technical Report WUSC- 86-6, Department of Computer Science, Washington University, June 1986.]]></ref_text>
				<ref_id>Kimura 86b</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16576</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Brad A. Myers, "What are Visual Programruing, Programming by Example, and Program Visualization?", Proceedings of Graphics Interface 1986.]]></ref_text>
				<ref_id>Myers 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Rocky Rhodes, Paul Haeberli, and Kipp Hickman, "Mex - A Window Manager for the IRIS", Proceedings of Usenix Winter Conference, 1985.]]></ref_text>
				<ref_id>Rhodes 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>317489</ref_obj_id>
				<ref_obj_pid>317456</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Andrew J. Schulert, George T. Rogers and James A. Hamilton, "ADM A Dialog Manager", Proceedings of SIGCHI 1985.]]></ref_text>
				<ref_id>Schulert 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Silicon Graphics Inc., IRIS User's Guide, 1984.]]></ref_text>
				<ref_id>Silicon 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Alvy Ray Smith, "Plants, Graftals, and Formal Languages", Computer Graphics, 1984.]]></ref_text>
				<ref_id>Smith 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Randal. B. Smith, "The Alternate Reality Kit: An Environment for Creating Interactive Simulations." Proceedings of the IEEE Computer Society Workshop on Visual Languages, 1986.]]></ref_text>
				<ref_id>Smith 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15913</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Peter B. Tanner, Stephen A. MacKay, Darlene A. Stewart, and Marceli Wein, "A Multitasking Switchboard Approach to User Interface Management", Computer Graphics, 1986.]]></ref_text>
				<ref_id>Tanner 86</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ ~ Computer Graphics, Volume 22, Number 4, August 1988 ConMan: A Visual Programming Language for Interactive 
Graphics Paul E. Haeberli Silicon Graphics, Inc. Mountain View, CA 94043 ABSTRACT Traditionally, interactive 
applications have been difficult to build, modify and extend. These integrated applications provide bounded 
functionality, have a single thread of control and a fixed user interface that must anticipate every- 
thing the user will need. Current workstations allow several processes to share the screen. With proper 
com- munication between processes, it is possible to escape previous models for application develop- 
ment and evolution. ConMan is a high-level visual language we use on an IRIS workstation that lets users 
dynamically build and modify graphics applica- tions. To do this, a system designer dis-integrates complex 
applications into modular components. By interactively connecting simple components, the user constructs 
a complete graphics application that matches the needs of a task. A connection manager controls the flow 
of data between individual components. As a result, we replace the usual user-machine dialog with a dynamic 
live performance that is orches- trated by the user. CR Categories and Subject Descriptors: D.2.2 [Software 
Engineering]: Tools and Techniques - User interfaces, D.3.2 [Pro-gramming Languages]: Language Classifications 
-Data-flow languages, Nonprocedural languages; 1.3.6 [Computer Graphics]: Methodology and Techniques 
- Interaction techniques, Languages; Additional Key Words and Phrases: Visual Programming Languages. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 
ACM-0-89791-275-6/88/008/0103 $00.75 Introduction Often we think of a user interface toolkit as a set 
of facilities that a developer can use to shape the feel of an application. For example, to make a choice 
available a developer can use a pop-up menu or a screen button. But after the developer compiles an application, 
the user is left with a static user-interface that reflects the developer's vision. If the user's task 
doesn't fit into the developer's model, then the user must use a different approach or try to find another 
application that does a better job. An alternative is to present users with a toolkit and let them match 
it to a given task. In the UNIX* world, there are lots of simple tools a user can combine to solve different 
problems. The mechanism that joins these tools is a pipe, a simple one-directional interprocess communi- 
cation (IPC) facility. This is an approach where the power of the sum is much greater than the power 
of the indivi- dual parts. ConMan (Connection Manager) provides a conceptually similar graphical facility 
for connecting visually-oriented tools. With ConMan, developers can concentrate on the purity of simple 
components. With good components that perform individual tasks well, a user can find a combination to 
solve problems that the designers didn't envision. To escape the mechanical world of tools and tool_kits, 
we'll use the culinary metaphor of a sandwich. Conven-tional systems present you with a ready made sandwich. 
You can add mustard and relish, but most choices have been made by the sandwich maker and your job is 
to find a sandwich that is closest to your needs. ConMan gives you the ingredients for the sandwich and 
leaves it to you to design a good one. This glosses over an important point: if you aren't a good cook, 
then the sandwich won't be very tasty. This isn't entirely facetious -the tradeoff between an expressive 
system and a ready-made system will always benefit some users and leave others unsatisfied. Background 
 Although there have been amazing advances in graphics display hardware in the last ten years, applica- 
tions have been slow in using the new capabilities pro- * UNIX is a trademark of Bell Laboratories. ¢SIGGRAPH 
'88, Atlanta, August 1-5, 1988 vided by the current generation of interactive graphics workstations. 
The structure of interactive applications has changed very little. A typical application is integrated 
and self-contained with a single process and address space. The user interface is compiled into the program, 
or read in from an external description as in [Schulert 85]. The behavior of the application is described 
by a textual language that is compiled into an executable program. Functional binding happens at compile 
time and is static. Users are prevented from expanding the design space interactively because the scope 
of an application is often limited by the vision of its designer. Also, traditional graphics applications 
are anti-social because they don't play nicely with other applications. These characteristics often result 
in the user being dominated by applications. Instead of the user driving an application, the user is 
often driven and constrained by the application. We want to use the facilities of the modern interac- 
tive medium more effectively to give the user more expressive power and freedom to construct and modify 
applications in a flexible way. Why isn't application development more like making a bacon, lettuce, 
and tomato, cucumber, salami, avocado, OolI-O®t [Heckbert 87] and sushi sandwich? Can't we use the interactive 
medium itself to help us? Visual Programming Visual programming describes any system that lets the user 
specify a program using a two dimensional nota- tion. Instead of editing a one dimensional stream of 
char- acters, the user interacts with a two dimensional represen- tation. A good discussion of various 
visual programming languages is given in [Myers 86]. Smith's Alternate Reality Kit [Smith 86] is a dynamic 
simulation environment with a visual interface. Objects have mass, velocity and a visual representation. 
The user can interact with the objects and change how one object influences another, Other interesting 
visual programming systems are described in [Kimura 86a], [Kimura 86b], [Cardelli 86], [Blythe 86], and 
[Galloway 87]. These use two dimen- sional data-flow constructs to describe program behavior. Kimura's 
system, Show and Tell, runs on the Macintosh computer. It's a general purpose system that handles pic- 
torial and textual data. It has some interesting graphical constructs for conditionals and iteration. 
Cardelli has developed a conceptual framework for a system he calls Fragments of Behavior. In his system, 
each fragment has an interface for communicating with other fragments and possibly a dialog for communicating 
with users. The behavior of each fragment is described in the Squeak language [Cardelli 85], which resembles 
Hoare's language for communicating sequential processes [Hoare 78]. "~ JotI-O is a trademark of General 
Foods. The systems by' Blythe and Galloway use data-flow constructs to control music synthesis and design 
digital filters interactively. Tanner's Switchboard [Tanner 86] supports flexible communication between 
a population of processes run-ning under the Harmony operating system. The World of ConMan In ConMan, 
we also use a data flow metaphor. The user constructs and modifies applications by creating com- ponents 
that are interconnected on the screen. The win- dow manager supports creation and deletion of individual 
components, while the user changes the interconnection by interacting with ConMan, the connection manager. 
Figure 1 shows how this interconnection can be described by a directed graph with components as nodes, 
and connections as edges. Connections establish depen- dencies between one component and another. Each 
com- ponent can have up to eight input ports and up to eight output ports. By interacting with the connection 
manager, the user may alter this dependency graph at any time, without the knowledge of the components. 
Figure 1. A directed graph representation. Any dynamic interaction is easier to demonstrate than to describe. 
To show how ConMan works, we'll discuss a composite application that lets the user interactively design 
swept surfaces. This example will use six simple components: view-ed with sliders. This component controls 
the view of a surface with a set of sliders.  view-ed with hemispherical control. This com- ponent allows 
the user to control the view of a surface with hemispherical control.  curv-ed. A simple curve editor 
lets the user interactively enter or modify two dimensional shapes.  sweep. The sweep component takes 
a shape, for example a curve from curv-ed, and sweeps it through space to create a surface.     SIGGRAPH 
'88, Atlanta, August 1-5, 1988 buttons, or position. System events notify a component that it should 
redraw because its window has received additional exposure. IPC events indicate that a message is available 
from another component. Communication between components is accom-plished by typed, variable sized, synchronous 
messages. To send a message, data is written into a file that is associ- ated with the output port. Then 
the component notifies the system that there is new data available from this particular output port. 
This blocks the sender and places notification tokens in the input queues of all the components that 
are dependent on this output port. When a component receives an IPC event, it reads the message from 
the appropriate file, and explicitly replies. In the current implementation, all data is transferred 
using a textual interchange format. System performance could be improved by using binary messages. The 
IPC mechanism described briefly above, using files and special system calls has recently been reimplemented 
to use stan- dard UNIX sockets.  Conclusions By providing graphical support for communicating sequential 
processes we create a primitive visual language that lets users interactively construct and modify applica- 
tions on the fly. The connection manager lets the user create dynamic visual expressions out of interactive 
com- ponents. Currently, the only data types (nouns) being transmit- ted between components are transformations, 
geometric shapes, RGB colors and bitmap images. We plan to extend the vocabulary by adding data types 
to describe text, fonts, and streams of input events. We also expect the vocabulary of data-flow components 
(verbs) to grow to support key frame animation, solid deformations and image processing. ConMan has many 
implications for application developers and users of interactive workstations. Applica- tions are really 
programmed at two distinct levels. A developer uses a conventional programming language at the component 
level. Both the user and the developer use a visual language at the level of the application. Developers 
are encouraged to break monolithic appli- cations into functional components that communicate with each 
other using high level data structures. Careful design of components makes them usable in many different 
con- texts, and communication between applications is easy. ConMan promotes software modularity and healthy 
com- petition between components. For example, if a better view editor becomes available, it can easily 
be used by everyone. In this system, sharing of functionality happens at the component level. Instead 
of supporting a single interaction frame with a single process, we use multiple processes in a windowed 
environment to provide multiple interaction frames, each with their own user interface state. An application 
is an orchestrated collection of interaction frames. Components and the data passed between them form 
a vocabulary that is used to express the behavior of an application. This allows the user to explore 
the design space instead of being limited by the vision of the system implementors. The functionality 
of applications is open- ended. Control over the application is returned to the user. Components of the 
user interface can be easily exchanged with each other. In this system, multiple simultaneous interaction 
techniques may be dynamically bound to an application. The functional binding of an application is completely 
dynamic. That applications must be monolithic and self-contained is an illusion. We use the interactive 
medium itself to let the user design and extend applications. Acknowledgement I would like to thank 
Rob Myers for his continued enthusiasm for this project. Eric Brechner now at RPI implemented a version 
of ConMan that uses UNIX sockets for interprocess communication. Thanks to John Danskin at Digital Equipment 
Corporation in Pain Alto for allow- ing me to use their digital film recorder for the illustra- tions. 
Special thanks also to Dan Sears and Amy Smith for help with the manuscript. References [Blythe 86] 
David Blythe, John Kitamura, David Gallo- way and Martin Snelgrove, "Virtual Patch-Cords for the Katosizer", 
Computer Systems Research Institute, Univer- sity of Toronto, Toronto, Ontario, Canada, 1986. [Cardelli 
85] Luca Cardelli, "Fragments of Behavior", Personal Communication. DEC Systems Research Center, Pain 
Alto, CA, 1985. [Cardelli 85] Luca Cardelli, and Pike, R., "Squeak: a language for communicating with 
mice", Computer Graphics, 1985. [Galloway 87] David Galloway, David Blythe and Martin Snelgrove, "Graphical 
CAD of Digital Filters", Proceed- ings of IEEE Conference on Computers, Communications, and Signal Processing, 
June 1987. [Haeberli 86] Paul Haeberli, "A Data-How Manager for an Interactive Programming Environment", 
Proceedings of Usenix Summer Conference, 1986. [Heckbert 87] Paul S. Heckbert, "Ray Tracing dolI-O ® 
Brand Gelatin", Computer Graphics, 1987. [Hoare 78] C.A.R. Hoare, "Communicating Sequential Processes", 
Communications of the ACM 21(8), August 1978. [Kimura 86a] Takayuki Dan Kimura, "Deterrninancy of Hierarchical 
Dataflow Model", Technical Report WUSC- 86-5, Department of Computer Science, Washington University, 
March 1986.  t~ ~(~ Computer Graphics, Volume 22, Number 4, August 1988 I I [Kimura 86b] Takayuki Dan 
Kimura, Julie W. Choi, and Jane M. Mack, "A Visual Programming Language for Keyboardless Programming", 
Technical Report WUSC- 86-6, Department of Computer Science, Washington University, June 1986. [Myers 
86] Brad A. Myers, "What are Visual Program- ruing, Programming by Example, and Program Visualiza- tion?", 
Proceedings of Graphics Interface 1986. [Rhodes 85] Rocky Rhodes, Paul Haeberli, and Kipp Hickman, "Mex 
-A Window Manager for the IRIS", Proceedings of Usenix Winter Conference, 1985. [Schulert 85] Andrew 
J. Schulert, George T. Rogers and James A. Hamilton, "ADM A Dialog Manager", Proceedings of SIGCHI 1985. 
[Silicon 84] Silicon Graphics Inc., IRIS User's Guide, 1984. [Smith 84] Alvy Ray Smith, "Plants, Graftals, 
and Formal Languages", Computer Graphics, 1984. [Smith 86] Randal. B. Smith, "The Alternate Reality 
Kit: An Environment for Creating Interactive Simulations." Proceedings of the IEEE Computer Society Workshop 
on Visual Languages, 1986. [Tanner 86] Peter B. Tanner, Stephen A. MacKay, Dar- lene A. Stewart, and 
Marceli Wein, "A Multitasking Switchboard Approach to User Interface Management", Computer Graphics, 
1986. Ill 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378495</article_id>
		<sort_key>113</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Graphical search and replace]]></title>
		<page_from>113</page_from>
		<page_to>120</page_to>
		<doi_number>10.1145/54852.378495</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378495</url>
		<abstract>
			<par><![CDATA[<i>Graphical search</i> is a technique for finding all instances of a graphical pattern in a synthetic picture in which objects are regions bounded by lines and curves. The pattern may descirbe shape, color and other properties. Matched objects may be allowed to differ from the pattern in rotation and scale or may differ in shape by a specified tolerance. <i>Graphical replace</i> is a technique for replacing the shape, color, or other properties of matched objects with new properties described in a replacement pattern. Combined, the two techniques are similar to textual search and replace in text editors. Graphical search and replace can be used to make global changes to illustrations with repetitive patterns, independent of the means used to make those patterns. It can also be used to create a class of iterative or recursive shapes that can be specified by replacement rules.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[curve matching]]></kw>
			<kw><![CDATA[graphical editing]]></kw>
			<kw><![CDATA[graphical grammars]]></kw>
			<kw><![CDATA[graphical macros]]></kw>
			<kw><![CDATA[search and replace]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Languages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003128</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Languages</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14026309</person_id>
				<author_profile_id><![CDATA[81100041571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kurlander]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, Columbia University, New York, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39026440</person_id>
				<author_profile_id><![CDATA[81100084142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Bier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox PARC, 3333 Coyote Hill Rd., Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15912</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bier, Eric A., and Stone. Maureen C. Snap-Dragging. Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4 (August 1986), 233-240.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burr, D. J. A Technique for Comparing Curves. In IEEE Conference on Pattern Recognition and linage Processing (Chicago, Illinois, August 6-8, 1979), 271-277.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chang, Shi-Kuo, Shi, Qing-Yun, and Yan, Cheng-Wen. Iconic Indexing by 2D Strings. In 1EEE Computer Society Workshop on Visual Languages (Dallas, Texas, June 25-27, 1986). 12-21.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Freeman, Herbert. Shape Description Via The Use of Critical Points. Pattern Recognition 10. 3 (1978), 159-166.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gips, James. Shape Grammars and Their Uses." Artificial Perception. Shape Generation. and Computer Aesthetics. Birkhauser, Verlag, Basel, Switzerland. 1975.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Levine, Martin D. Vision in Man and Machine. chapter 10. McGraw Hill. New York, New York, 1983.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>743177</ref_obj_id>
				<ref_obj_pid>647953</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Palermo, Frank and Weller, Dan. Some Database Requirements for Pictorial Applications. Data Base Techniques for Pictorial Applications (Florence, Italy, June 1979). Edited by A. Blaser. In Lecture Notes in Computer Science. 81. Springer-Verlag, Berlin, West Germany. 1980.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Pavlidis, Theo. A Review of Algorithms for Shape Analysis. Computer Graphics and Image Processing 7, 2 (April 1978), 243-258.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801663</ref_obj_id>
				<ref_obj_pid>800046</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Pier, Kenneth A. A Retrospective on the Dorado, a High- Performance Personal Computer. In Proceedings of the 10th Symposium on Computer Architecture. SIGARCH/IEEE, (Stockholm, Sweden. June 1983), 252-269.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>51309</ref_obj_id>
				<ref_obj_pid>51292</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Pier, Kenneth A., Bier, Eric A., and Stone, Maureen C. An Introduction to Gargoyle: An Interactive Illustration Tool. In van Vliet, J.C. (editor), Proceedings of the International Conference on Electronic Publishing. Document Manipulation and Typography (EP88), (Nice. France, April 1988), Cambridge University Press, 223-238.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Smith, Alvy Ray. Plants, Fractals, and Formal Languages. Proceedings of SIGGRAPH "84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3 (July 1984), 1-10.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Stiny, George. Pictorial and Formal Aspects of Shape and Shape Grammars, Birkhauser, Verlag, Basel, Switzerland, 1975.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sutherland. Ivan E. Sketchpad: A Man-Machine Graphical Communication System. In AFIPS Conference Proceedings, Spring Joint Computer Conference. 23. Spartan Books, Washington, 1963, 329-346.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6466</ref_obj_id>
				<ref_obj_pid>6465</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Swinehart, Daniel, Zellweger, Polle, Beach, Richard, and Hagmann, Robert. A Structural View of the Cedar Programming Environment. ACM Transactions on Programming Languages and Systems 8, 4 (October 1986). 419-490.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563309</ref_obj_id>
				<ref_obj_pid>563274</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Weller, Dan, and Williams, Robin. Graphic and Relational Data Base Support for Problem Solving. Proceedings of SIGGRAPH '76 (Philadelphia, Peniasylvania, July 14-16, 1976). In Computer Graphics 10, 2 (Summer 1976), 183-189.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Wolfson, Haim. On Curve Matching. Technical Report #256. Courant Institute of Mathematical Sciences, New York, New York, November 1986.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Graphical Search and Replace David Kurlander 
Computer Science Department Columbia University New York, NY 10027 Eric A. Bier Xerox PARC 3333 Coyote 
Hill Rd. Palo Alto, CA 94304 A bst ract Graphical search is a technique for finding all instances of 
a graphical pattern in a synthetic picture in which objects are regions bounded by lines and curves. 
The pattern may describe shape, color and other properties. Matched objects may be allowed to differ 
from the pattern in rotation and scale or may differ in shape by a specified tolerance. Graphical replace 
is a technique for replacing the shape, color, or other properties of matched objects with new properties 
described in a replace-ment pattern. Combined, the two techniques are similar to textual search and replace 
in text editors. Graphical search and replace can be used to make global changes to illustrations with 
repetitive patterns, independent of the means used to make those patterns. It can also be used to create 
a class of iterative or recursive shapes that can be specified by replacement rules. CR Categories: 1.3.6 
[Computer Graphics]: Methodology and Techniques-interaction techniques; 1.5.4 [Pattern Recogni-tion]: 
Applications - graphical editing Additional Keywords and Phrases: Search and replace, graphical editing, 
curve matching, graphical grammars, graphi- cal macros  I. Introduction Most graphic arts quality illustrations 
Contain some degree of coherence. For example, the same font, color or stroke width is used throughout 
a set of shapes, or a particular shape is used repeatedly at different translations, rotations, or sizes. 
Changing one of the coher- ent properties of an illustration (e.g., changing all red circles into orange 
ellipses), requires making the change throughout the illustra- tion. Pictures can be structured to make 
such changes easy. For ex- ample, some editors allow objects to be grouped into a cluster that can be 
selected as a unit, making it easy to change properties of the clustered objects all at once. Other editors 
allow the user to declare that an object is an instance of a library object: changes to the library object 
are reflected in all of its instances at once. However, both of these techniques require the user to 
decide at an early stage what properties will need to be edited coherently, and to structure the il- 
lustration accordingly. We propose an alternative technique, Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169; 1988 ACM-0-89791-275-6/88/008/0113 
$00.75 graphical search and replace, that allows graphical scenes to be edited coherently without special 
structuring of the illustration. Graphical search and replace works much like text substitution in a 
word processor. The user first describes a search pattern com- posed of a set of synthetic shapes (regions 
bounded by lines, conics, and splines), a set of style properties such as stroke width, stroke color, 
and fill color, and a set of search parameters including an error tolerance and an indication of whether 
or not a match may be a rota- tion of the pattern. Next, the user describes a replacement pattern made 
up of synthetic shapes and style properties. The graphics edi- tor then searches in the illustration 
for an object that matches the pat- tern. If the user requests a replacement, the editor replaces the 
shape, changes its style properties, or both. This can be done one shape at a time, in a top to bottom, 
left to right order, or can be performed on all matching shapes at once. Graphical search and replace 
has a number of applications. It can be used to make changes to many objects at once. If the re-placement 
pattern is more elaborate than the search pattern, these multiple changes can turn a simple repetitive 
picture, used as a tem- plate, into an elaborate composition. Furthermore, if the replace- ment pattern 
contains parts that match the search pattern, graphical search and replace can be used repeatedly to 
build up a recursive shape. If an editing macro is performed on each set of matched objects instead of 
a replacement, graphical search leads to an even more general way to modify illustrations. Finally, if 
performed on multiple files, graphical search can be used to find those picture files containing specified 
graphical features. Graphical search and replace is related to a wide variety of other topics. It can 
be viewed as an interface to a graphical database, where typical transactions include queries for objects 
with a particular set of graphical properties and modifications of these properties. The rep- resentation 
of graphical information in databases has been studied [7, 15]. Graphical search and replace can also 
be viewed as a method for specifying graphical grammars that generate recursive shapes. Shape grammars, 
a subset of graphical grammars, have been analyzed extensively [5.12], and grammars have been used in 
graphics to make realistic imagery [11]. Pattern recognition algorithms have been used to search for 
occurrences of a particular shape [6, 8]. Some of these algorithms are appropriate for use in graphical 
search and replace. Instancing was used in the earliest of drawing systems. Sketchpad [13], and continues 
to be used in many current systems. Graphical search and replace is proposed as an alternative to instancingfor 
producing coherent changes in graphical documents. Graphical search and replace has been implemented 
in the MatchTool. a companion to the Gargoyle two-dimensional illustrator [1, 10] running in the Cedar 
programming environment I14] on the Xerox Dorado high-performance personal workstation [9]. The MatchTool 
is similar in user interface to the EditTool, a textual search and replace tool that works with Tioga. 
the Cedar text editor, I13   f SIGGRAPH '88, Atlanta, August 1-5, 1988 to edit multi-font tree-structured 
documents. All figures in this paper were created with the MatchTool and Gargoyle. In section 2, we describe 
the MatchTool from the users point of view, showing graphical search and replace in action. In section 
3, we describe the implementation of the MatchTool, including the control structures needed to search 
the scene in top to bottom, left to right order and the algorithm that determines whether or not two 
objects match, in section 4. we discuss some of the applications of graphical search and replace. In 
section 5, we present our conclusions and future research directions. 2. User Interface 2.1 Search and 
Replace for Shapes In this section, we describe how graphical search and replace can be used to make 
changes to an illustration. We need two windows on our workstation display. In the Gargoyle editing window 
is the illus- tration that we are editing. In the MatchTool window, we specify search and replace requests. 
At the top of the MatchTool are two panes (sub-windows), each of which is a small Gargoyle editing window. 
In the first of these, the Search Pane, we construct the pat- tern that we wish to search for in our 
illustration. In the second of these, the Replace Pane, we construct the replacement pattern. Figure 
1 shows an illustration of a map that is being edited in a Gargoyle window. This is a synthetic picture; 
the highway sign borders are represented as arcs, line segments and parametric curves, and the roadways 
are parametric curves. The text is represented as an ASCII string, a font name and an afffine transformation. 
Recently, sections of Highway 17 have been renamed Interstate 880. We can use the MatchTool to make the 
substitutions. Figure 1. An illustration of the freeways near San Jose, California. Figure 2 shows the 
two panes of the MatchTool. In the Search Pane, we put a Highway 17 sign, copying it from the illustration. 
In the Replace Pane, we put an Interstate 880 sign, drawing it in place or copying it from a different 
illustration. We make sure that the centers of both signs are at the same coordinates, so that no offset 
will be introduced when replacements are performed. The centers can be aligned, for instance, by positioning 
both signs in the Search Pane, and then moving the Interstate 880 sign into the Replace Pane with a "move" 
operation that preserves coordinates. Search Replace   Inll l Figure 2. Search and replacement patterns 
in the MatehTool. The MatchTool user interface has four buttons that initiate search actions: Search, 
Yes, No, and ChangeAII. If we press the Search button at this point, the MatchTool will search the illustration 
in top to bottom, left to right order, looking for Highway 17 signs. When it finds the topmost one, it 
selects it. If we then press the Yes button, the MatchTool will delete the Highway 17 sign, add an Interstate 
880 sign, and initiate another search. This search finds the second sign. Pressing Yes again, we replace 
the second Highway 17 sign and select the third. Since Highway 17 has only been renamed north of Interstate 
280, we are done. If we press the No button at this point, the MatchTool will leave the third Highway 
17 sign as it is and report that there are no further matches. The resulting picture is shown in Figure 
3. Had we wished to replace all of the Highway 17 signs at once, we could have used the ChangeAII button. 
 Figure 3. The San Jose freeways after the northern sections of Highway 17 have been relabeled. In the 
example above, we searched for a collection of shapes of known size, shape and orientation. Less restrictive 
searches can be achieved by varying one or more of six search parameters-Granularity, Rotation lnvariance, 
Scale Invariance. Polarity, Context Sensitivity, and Tolerance. The user interface for these features 
is shown in Figure 4. The first four search parameters will be discussed in this section, the last two 
in section 2.3. "1 Granularity:l Anywhere ' 'mm m/1 mva ll"~r~elm ~/tl | I 'olarity | I CohtextSensitive 
I / T°lerance: I A ]J Figure 4. The six search parameters. Options that are white on black are active. 
All of the regions bordered with a black rectangle are mouse-sensitive. Granularity may take on the values 
"cluster", "object", or "anywhere". It tells the MatchTool how much of the structure of the illustration 
may be ignored when performing matches. If Granularity is set to "cluster", then a group of objects that 
have been clustered in Gargoyle will only match a similar complete cluster in the MatchTool; the individual 
objects in the cluster cannot match separately. At the "object" granularity, a Gargoyle object A will 
match a similar object B in the pattern, even ira is part of a cluster. At this granularity, A must be 
matched in entirety; a pattern containing only a subset of A's parts will not match. At the "anywhere" 
granularity, parts of an object A may be matched by a pattern object B if all of B's parts match corresponding 
parts in A. At this granularity, an entire object in the MatchTool search pane can match a portion of 
a single object in the editor scene. In an "anywhere" match, the lowest-level scene elements, segments, 
are treated as atomic; it is impossible to match on parts of them. This certainly has performance benefits, 
but also avoids other problems inherent in replacing portions of particular object classes. For example, 
it is impossible to replace portions of some segment types, such as non-local splines, without potentially 
causing changes to the entire segment. When Rotation Invafiance is turned on, the pattern matches a configuration 
of scene objects if some combination of translation and rotation will bring the pattern and configuration 
into correspon- dence. If more than one rotation is possible, the MatchTool will  '~ "~' Computer Graphics, 
Volume 22, Number 4, August 1988 algorithm that we use to compare two curves for shape equality will 
be discussed in section 3.2. Once we have found a match for the leading object, we attempt to find thatches 
for all of the other elements in the pattern list. If we succeed, we are done. Otherwise, we try to match 
the leadingobject differently. If Rotation lnvariance is on. we try matching the leading object against 
the same object in the search list at a different orientation. When all possible orienta- tions are exhausted, 
we move on to the next object on the search list. If we are matching on shape, we use two techniques 
to improve performance. First, when we have found a match for the leading ob- ject, we know where in 
the scene to look for the remaining shapes in the pattern list. We use bounding boxes to quickly rule 
out many of the objects on the search list. For instance, we compute where one point of a given pattern 
object would have to match in the scene and rule out all objects on the search list whose bounding boxes 
do not contain that point. If the search is not exact, we enlarge the bounding boxes by an amount proportional 
to the tolerance before testing the point for inclusion. Furthermore, the search list is ordered by the 
upper left hand corner of the bounding boxes, so we can quickly rule out entire sections of the search 
list. Second, we choose a good leading object. If possible, we choose an open curve to be the leading 
object because open curves can match other curves at no more than two different orientations. If all 
of the pattern objects are closed curves, we choose the curve with the least number of potential matching 
orientations (see section 3.2). When Granularity is set to "anywhere", the search mechanism is more elaborate. 
Objects in the pattern list are matched against both entire objects and portions of objects in the search 
list. When a match is found, information is saved indicating precisely where the search terminated, so 
the next search can continue with another part of the same search list object if any unexamined parts 
remain. Note that it is possible to invoke a search on an object, part of which has already been changed 
by a prior search and replace. Let there be m objects in t__he editor scene and n objects in the search 
pattern. The worst case complexity of the search algorithm to find all matches of the pattern in the 
scene is O(m2n) object to object comparisons, assuming that the search is being made at either the "cluster" 
or "object" granularity, and the leading object matches no scene object at more than a constant number 
of orientations. If the granularity of the search is set to "anywhere", then we are effectively matching 
against a greater number of scene objects, since each object and its eligible subsets (continuous runs 
of segments) must be considered in the match process. In this case, we redefine m to be the sum over 
all objects in the scene of the number of eligible subsets in each object, and the complexity expression 
remains valid. The expected number of object to object comparisons required to find all matches of a 
pattern in the scene is no worse than O(m2). It is rare for the first few elements of the pattern list 
to match objects in the scene without a complete match occurring. When a complete match does occur, the 
scene objects participating in the match are removed from further consideration, so no more than m/n 
matches can be found. Together, these observations lead to the tighter bound. In addition, the use of 
bounding boxes to narrow down the matching process for shape searches does much to speed up the search. 
In practice, we have found the speed of this algorithm to be acceptable for our applications. After a 
match is found, the search list is updated to disallow future matches on the same objects. The objects 
in the Gargoyle window that were found by the search are selected, and all other objects are deselected. 
Selection performs a dual function. First, the selection feedback indicates to the user which set of 
objects has been matched. Second, it prepares the matched objects to be modified by any of the Gargoyle 
operations that act on selected objects, including deletion, color changes, and transformations. The 
caret is relocated to the position of the match, lfa Yes or ChangeAII is in progress, a replacement or 
macro operation will be performed at this point. Macro operations are described in section 4.3. If a 
replacement is to be performed, we examine the Replace Column. If we are replacing only non-shape properties, 
the values of these properties are extracted from the shapes in the Replace Pane and applied to the matched 
objects. If we are replacing shape, the matched objects are deleted and the objects in the Replace Pane 
are copied into the scene. The new scene objects inherit from the matched shapes the properties not specified 
in the Replace Column. The new scene objects are positioned in the scene as follows: If we are matching 
on shape, we have found a transformation that maps the pattern objects onto the matching scene objects: 
we apply this same transformation to the Replace Pane shapes. Otherwise, we position the replacement 
so that the center of its bounding box coincides with the bounding box center of the match. 3.2 Curve 
Matching At the core of our searching algorithm is a set of routines for comparing two curves for equality. 
We wish to be able discover that two curves are the same even if the two curves are at different sizes 
and orientations and even if the curves have different representa- tions. For example, one curve might 
be a B-spline and the other a collection of B6zier cubic pieces, or one curve might be made of two small 
arcs and the other a single large arc. Our method is simple and general at the expense of performance. 
We discuss a technique for improving performance in section 5.2. To compare two curves, we begin by approximating 
each curve by a piecewise linear path-a polyline. We construct polyline approximations adaptively, so 
that areas of high curvature are represented by more line segments than flatter areas. To keep poly- 
lines from having too many segments, we enforce a minimum length on the polyline segments. Many graphics 
systems already perform this vectorization, a common step in rendering curves. As shown in Figure 12, 
the polylines for copies of a curve at different scales may not be scales of one another. The test for 
equality must tolerate this error (see below).  ;A_, Figure 12. A curve and a scaled down copy of the 
curve, approximated as polylines. The roughness of the polylines is exag- gerated for clarity. Polylines 
are transformed to a canonical form so that they can be quickly compared. The nature of the canonical 
form depends upon whether the match is to be rotation-invariant, scale-invariant, neither, or both, as 
shown in Figure 13, One point of the polyline is chosen as the starting point. For open curves, the first 
endpoint is used. For closed curves, we use the point of greatest distance from the center of mass of 
a wire of uniform density lying along the curve (Figure 13(a)). A closed curve may have several points 
farthest from the center of mass: in this case the curve will have several canonical positions. The polyline 
is transformed so that its starting point lies at the origin (Figure 13(b)). lfa rotation-invariant match 
is chosen, the polyline is rotated so that the center of mass lies along the positive axis (Figure 13(c)). 
If a scale-invariant match is desired, then the polyline of the curve is normalized to have a particular 
arc length (Figure 13(d)). SlGGRAPH '88, Atlanta, August 1-5, 1988 |, pointoCenter I f mass  startin 
gI J "~ (d)I Figure 13. Polyline canonical forms, (a) The original polyline. (b) For all matches, the 
starting point is translated to the origin. (c) For rotation-invariant matches, the center of mass is 
rotated onto the positive x axis. (d) For scale-invariant matches, the curve is scaled to have a known 
total arc length. A set of quick-reject tests can now be applied to the poiylines to avoid further computation 
on pairs of curves that obviously do not match. Several quantities, including arc length, the maximum 
dis- tance from a curve to its center of mass, and the position &#38;the center of mass relative to the 
starting point, can now be compared. If these values for two polylines differ by more than a minimal 
quantity (accounting for floating point error or differences in quantization), then we conclude, without 
further computation, that the curves do not match. If these quantities are similar enough, then it is 
still possible for the two polylines to represent equivalent shapes and a more comprehensive comparison 
is made. For each vertex of both poly- lines, we examine the Manhattan ([-norm) distance to the point 
of parametrically equivalent distance along the other polyline, found by interpolating between vertices 
if necessary. If this distance ever exceeds a certain threshold the match fails. This threshold, and 
the quantities used in the quick-reject tests can be adjusted to reflect a user-specified match tolerance. 
We use a 1-norm metric because it can be computed quickly, and always produces correct responses with 
respect to exact shape matches. Other metrics may provide better measures of inexact shape matches, as 
evaluated by the human eye; however, inexact shape matches are selected relatively infrequently. It may 
be desirable to have several shape metrics: one for exact matches, and one or more for inexact matches. 
In the conclusion we mention an inexact shape metric that we are currently investigating. It is important 
to note that the 1-norm metric together with the quick- reject tests form our shape-matching criteria. 
In the case of inexact matches, it is possible for curves that would have passed the 1-norm test for 
equality to fail at least one of the initial tests, and thus be considered unequal. When comparing two 
closed curves with the 1-norm metric, we must examine every canonical orientation of one of the curves 
with a single canonical orientation of the other before declaring a mismatch, unless the arc length or 
maximum distance to center of mass tests indicate this is not necessary. Although this algorithm for 
comparing curves is linear with respect to the number, n, of samples in the poly- lines for all open 
and some closed curves, there are certain closed shapes that will slow it down to O(n2). Other representations 
such as sampling the distance of a curve from its centroid [4] or sampling the curve's curvature [16] 
can be used to improve this bound. 4. Applications In addition to coherent changes in illustrations with 
repeated components, graphical search and replace can be used to make recursive and iterative shapes, 
to create pictures that have a standard form by modifying graphical templates, to apply graPhical editing 
macros, and to search for picture files based on graphical content. We discuss these applications in 
this section. 4.1 Graphical Grammars Graphical search and replace can interactively generate complex 
shapes described by graphical grammars, an extension of shape grammars that allows graphical properties 
other than shape, such as color and line width, to participate in production rules. The Search Pane and 
Column specify the left side of a production rule, and the Replace Pane and Column specify the right 
side. Each replacement operation amounts to a single expansion of the production. For example, Figure 
14 shows the Search and Replace panes for a replacement rule that builds a spiral. We activate area color 
(in addition to shape and object class) in the Search Column and in the Replace Column. We turn on Rotation 
Invariance and Scale lnvariance. If the initial scene is the same as the picture in the Search Pane. 
then by clicking the ChangeAll button 27 times, we produce the picture in Figure 15. The, innermost copy 
of the word "MATCHTOOL" is grey. Search Replace o~\ OOt. Figure 14. The Search and Replace patterns for 
a graphical grammar that makes a word spiral.  OOL,14 c,~oOLM~ ~ . ~ M~A T O C 1 ~ o ~ ,To 6,.,5., 
0 0 o . .~o.2,--" "~'.t,. O 'e.- o.~o o O w-~. 4'. @~"~oo~-.OL.X ~ ~  -ZHo Figure 15. A spiral made 
of the word "MATCHTOOL" repeated 28 times. As another example, Figure 16(a) describes a rule that replaces 
a grey line segment by a brown line segment of the same size, with two grey branches attached. Line Color 
and Shape are selected in both the Search Column and in the Replace Column. Rotation lnvariance and Scale 
lnvariance are turned on. Beginning with a single vertical grey line, we apply the rule five times to 
produce a leafless brown tree with grey outermost branches. Figure 16(b) describes a second rule that 
replaces all grey branches by brown branches attached to green leaves. Applying this rule produces the 
simple graftal tree shown in Figure 16(c). For grammars with more than one rule, it is useful to have 
multiple pairs of Search and Replace Panes.  SIGGRAPH '88, Atlanta, August 1-5, 1988 pane. In addition, 
there are six parameters that are used only for the search operation. This user interface is relatively 
easy to understand and provides a great deal of power. Furthermore, graphical search and replace can 
be added to an existing graphical editor with little modification to the editor or its data structures. 
 Graphical search and replace can accomplish any coherent change that can be accomplished using instancing, 
and it can be applied more widely. Because it requires no special structuring of the illustration, our 
technique can be used in editors that do not support instancing and in situations where only a "flat" 
description of a pic- ture is available. Furthermore, it can be used to modify a collection of objects 
with identical shapes but different style properties, while instancing schemes tend to require that the 
instances of a library ob- ject be identical in all respects expect for an affine transformation. Graphical 
search and replace can consider replacements on a case by case basis, allowing changes to some objects 
but not others. In addition to making coherent changes, graphical search and replace can be used to make 
recursive shapes and to copy shapes to positions specified in a graphical template. It extends shape 
gram- mars by allowing style properties to appear on each side of the pro- duction as well as shapes. 
Finally, graphical search can be combined with operations other than replacement. More general coherent 
modifications can be achieved by playing back a macro on each match. Searching in multiple files provides 
graphical grep, a means for retrieving graphi- cal documents by content instead of name. 5.2 Future Work 
Graphical search could be improved by allowing for more general patterns. We would like to be able to 
search for all angles of a certain value, or junctions with a certain number of lines radiating from 
them. We would also like to be abte to capture positional relationships such as finding all circles above 
squares. Such relational metrics have appeared in the literature [31. We would also like a better way 
to search for objects that "look like" the search pat- tern. We may be able to apply string matching 
techniques [2] to this problem. Exact pattern matches on curves of known type are an important special 
case for graphical search. By comparing the curve control points directly instead of comparing polyline 
representations, we could significantly speed up the majority of searches. It appears that graphical 
search and replace can be used as a user interface paradigm for systems that use instancing internally. 
In fact. for scenes that have an instancing hierarchy it should be possible to speed up graphical search 
by using pointer comparisons, where pos- sible, in place of geometric comparisons. Likewise, graphical 
replace can take advantage of instancing by replacing matched objects with library object instances, 
where possible, instead of allocating new data structures. Finally, graphical search could serve as the 
basis for a tool that compares two graphical scene files and reports their differences. Such a tool would 
be useful for regression testing of graphical editors and for understanding how one picture was changed 
to make another. Acknowledgments. We are grateful to Xerox PARC for providing the environment that made 
this research possible. We would like tO thank Ken Pier. Maureen Stone, Subhana Menis, and Jock Mackinlay 
for comments that lead to an improved paper. We give special thanks to Maureen Stone and Ken Pier for 
their encouragement during the project.  References 1, Bier, Eric A., and Stone. Maureen C. Snap-Dragging. 
Proceedings of SIGGRAPH '86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4 (August 1986), 
233-240. 2. Burr, D. J. A Technique for Comparing Curves. In IEEE Conference on Pattern Recognition and 
linage Processing (Chicago, Illinois, August 6-8, 1979), 271-277. 3. Chang, Shi-Kuo, Shi, Qing-Yun, and 
Yan, Cheng-Wen. Iconic Indexing by 2D Strings. In 1EEE Computer Society Workshop on Visual Languages 
(Dallas, Texas, June 25-27, 1986). 12-21. 4. Freeman, Herbert. Shape Description Via The Use of Critical 
Points. Pattern Recognition 10. 3 (1978), 159-166.  5. Gips, James. Shape Grammars and Their Uses." 
Artificial Perception. Shape Generation. and Computer Aesthetics. Birkhauser, Verlag, Basel, Switzerland. 
1975. 6. Levine, Martin D. Vision in Man and Machine. chapter 10. McGraw Hill. New York, New York, 1983. 
 7. Palermo, Frank and Weller, Dan. Some Database Requirements for Pictorial Applications. Data Base 
Techniques for Pictorial Applications (Florence, Italy, June 1979). Edited by A. Blaser. In Lecture Notes 
in Computer Science. 81. Springer-Verlag, Berlin, West Germany. 1980.  8. Pavlidis, Theo. A Review of 
Algorithms for Shape Analysis. Computer Graphics and Image Processing L 2 (April 1978), 243-258. 9. 
Pier, Kenneth A. A Retrospective on the Dorado, a High-Performance Personal Computer. In Proceedings 
of the lOth Symposium on Computer Architecture. SIGARCH/1EEE, (Stockholm, Sweden. June 1983), 252-269. 
 10. Pier, Kenneth A., Bier, Eric A., and Stone, Maureen C. An Introduction to Gargoyle: An Interactive 
Illustration Tool. In van Vliet, J.C. (editor), Proceedings of the International Conference on Electronic 
Publishing. Document Manipulation and Typography (EP88), (Nice. France, April 1988), Cambridge University 
Press, 223-238. 11. Smith, Airy Ray. Plants, Fractals, and Formal Languages. Proceedings of SIGGRAPH 
"84 (Minneapolis, Minnesota, July 23-i7, 1984). In Computer Graphics 18, 3 (July 1984), 1-.10. 12. Stiny, 
George. Pictorial and Formal Aspects of Shape and Shape Grammars, Birkhauser, Verlag. Basel, Switzerland, 
1975. 13. Sutherland. Ivan E. Sketchpad: A Man-Machine Graphical Communication System. In AFIPS Conference 
Proceedings, Spring Joint Computer Conference. 23. Spartan Books, Washington, 1963, 329-346. 14. Swinehart, 
Daniel. Zellweger, Polle, Beach, Richard, and Hagmann, Robert. A Structural View of the Cedar Programming 
Environment. ACM Transactions on Programming Languages and Systems 8, 4 (October 1986). 419-490. 15. 
Weller, Dan, and Williams, Robin. Graphic and Relational Data Base Support for Problem Solving. Proceedings 
of SIGGRAPH "76 (Philadelphia, Peniasylvania, July 14-16, 1976). In Computer Graphics lO, 2 (Summer 1976), 
183-189.  16, Wolfson, Haim. On Curve Matching. Technical Report #256. Courant Institute of Mathematical 
Sciences, New York, New York, November 1986.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378497</article_id>
		<sort_key>121</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[A study in interactive 3-D rotation using 2-D control devices]]></title>
		<page_from>121</page_from>
		<page_to>129</page_to>
		<doi_number>10.1145/54852.378497</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378497</url>
		<abstract>
			<par><![CDATA[This paper describes and evaluates the design of four virtual controllers for use in rotating three-dimensional objects using the mouse. Three of four of these controllers are "new" in that they extend traditional direct manipulation techniques to a 3-D environment. User performance is compared during simple and complex rotation tasks. The results indicate faster performance for complex rotations using the new continuous axes controllers compared to more traditional slider approaches. No significant differences in accuracy for complex rotations were found across the virtual controllers.A second study compared the best of these four virtual controllers (the Virtual Sphere) to a control device by Evans, Tanner and Wein. No significant differences either in time to complete rotation task or accuracy of performance were found. All but one subject indicated they preferred the Virtual Sphere because it seemed more "natural".]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3-D graphics]]></kw>
			<kw><![CDATA[I/O devices]]></kw>
			<kw><![CDATA[input devices]]></kw>
			<kw><![CDATA[interactive graphics]]></kw>
			<kw><![CDATA[mouse]]></kw>
			<kw><![CDATA[real-time graphics]]></kw>
			<kw><![CDATA[rotation control]]></kw>
			<kw><![CDATA[user performance]]></kw>
			<kw><![CDATA[virtual controllers]]></kw>
			<kw><![CDATA[virtual sphere]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human factors</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided manufacturing (CAM)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>User interfaces</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.4.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011069</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Integrated and visual development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010483</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Computer-aided manufacturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
			<gt>Management</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14048510</person_id>
				<author_profile_id><![CDATA[81100109648]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Electrical Engineering, University of Toronto, Toronto, Ontario, Canada, M5S 1A4 and Department of Electrical Engineering/Dynamic Graphics Project, Universitty of Toronto]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31049543</person_id>
				<author_profile_id><![CDATA[81100604755]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[Joy]]></middle_name>
				<last_name><![CDATA[Mountford]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apple Computer Inc., 20525 Mariani Ave MS 27A0, Cupertino, CA and Human Interface Group, Apple&#174; Computer Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14113159</person_id>
				<author_profile_id><![CDATA[81100309669]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Abigail]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sellen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute for Cognitive Science, C-015, University of California, San Diego, La Jolla, CA and Institute for Cognitive Science, University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>319135</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bier, Eric A. Skitters and Jacks: Interactive 3-D Positioning Tools. In Proceedings 1986 Workshop on Interactive 3-D Graphics (Chapel Hill, North Carolina, October 1986), 183-196.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Buxton, William. There's More to Interaction than Meets the Eye: Some Issues in Manual Input. In User Centred System Design: New Perspectives on Human-computer Interaction, D. A. Norman, &amp; S. W. Draper Eds. Lawrence Erlbaum Associates, Hillsdale, N.J, 1986. pp. 319-337.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chen, Michael. A Technique for Specifying Rotations in Three Dimensions Using a 2D Input Device. In Proceedings IEEE Montech'87 - Compint'87 (Montr6al, Qu6bec, November 1987), 118- 120.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806794</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Evans, Kenneth B, Tanner, Peter P. &amp; Wein, Marceli. Tablet Based Valuators that Provides One, Two or Three Degrees of Freedom. Proceedings of SIGGRAPH'81 (Dallas, Texas, August 1981). In Computer Graphics 15, 3 (August 1981), 91-97.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Mounfford, S. Joy, Spires, Shannon &amp; Korner, Kim. Visage: A Three- Dimensional Graphics Editor - Evaluation and Review. MCC Technical Report #HI-105-86-P, Microelectronics and Computer Technology Corporation, Austin, Texas, 1986. Data presented at 31st Annual Meeting of Human Factors Society in New York, October 19- 22, 1987.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319134</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Nielson, Gregory M, Olsen, Dan R. Jr. Direct Manipulation Techniques for 3-D Objects Using 2D Locator Devices. In Proceedings 1986 Workshop on Interactive 3-D Graphics (Chapel Hill, North Carolina, October 1986), 175-182.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319139</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Pique, Michael E. Semantics of Interactive Rotations. In Proceedings 1986 Workshop on Interactive 3-D Graphics (Chapel Hill, North Carolina, October 1986), 259-269.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 A Study in Interactive 3-D Rotation Using 2-D 
Control Devices Michael Chen Department of Electrical Engineering/ Dynamic Graphics Project Universitty 
of Torontot S. Joy Mountfurd Haman Interface Group Apple ® Computer Inc.:~ Abigail Sellen Institute 
for Cognitive Science University of California, San Diego # ABSTRACT This paper describes and evaluates 
the design of four virtual controllers for use in rotating three-dimensional objects using the mouse. 
Three of four of these controllers are "new" in that they extend traditional direct manipulation techniques 
to a 3-D environment. User performance is com- pared during simple and complex rotation tasks. The results 
indicate faster performance for complex rotations using the new eontinuoos axes con- trollers compared 
to more traditional slider approaches. No significant dif- ferences in accuracy for complex rotations 
were found across the virtual controllers. A second study compared the best of these four virtual controllers 
(the Virtual Sphere) to a control device by Evans, Tanner and Wein. No signifi- cant differences either 
in time to complete rotation task or accuracy of per- formance were found. All but one subject indicated 
they preferred the Virtual Sphere because it seemed more "natural". CR Categories and Subject Descriptors: 
1.3.6 [Computer Graph- ics]: Methodology and Techniques - interaction techniques; D.2.2 [Software Engineering]: 
Tools and Techniques - User interfaces; H.1.2 [Models and Principles]: User/Machine Systems - Human factors; 
B.4.2 [Input/Output devices]; J.6 [Computer-Aided Engineering]: Computer-aided manufacturing. General 
Terms: Algorithms, Experimentation, Performance, Human Factors. Additional Key Words and Phrases: input 
devices, virtual con-trollers, I/O devices, virtual sphere, mouse, interactive graphics, 3-D graphics, 
real-time graphics, rotation control, user performance. ~" Department of Electrical Engineering, University 
of Toronto, Toronto, Ontario, Canada, M5S 1A4. Tel # (416) 978-6619. ~: Apple Computer Inc., 20525 Mariani 
Ave MS 27A0, Cupertino, CA, 95014. Tel # (408) 973-4801. # Institute for Cognitive Science, C-015, University 
of California, San Diego, La Jolla, CA, 92093. Tel # (619) 534-2541. Permission to copy without fee all 
or part of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM-0-89791-275-6/88/008/0121 
$00.75 1. INTRODUCTION The recent increase in the available power of special purpose computer graphics 
machines has extended the operational range of capabilities for users. Objects can now be more easily 
generated in 3-D (in wireframe, solid and shaded forms), and manipulated in real-time. Despite advances 
in the ability to display 3-D objects, there is a lack of methods by which the user can easily manipulate 
and control the position of an object on the screen. Currently, simple direct manipulation controllers 
do not exist for 3-D object positioning. The design of such controllers could be important interface 
contributions for application environments such as manufacturing, architecture, and engineering design, 
which rely heavily on the display and control of three dimensions. The mouse is a successful interface 
tool, performing well for direct manipulation control of two-axis problems, either through manipulation 
of x and y separately, or the coupled control of x and y axes together. However, the issue of how best 
to extend the use of the mouse to accommodate the additional capabilities afforded by three-dimensional 
graphics is still relatively unexplored. The ultimate goal is to provide users with an easy way of performing 
translation, rotation and sizing operations for complete manipulation of 3-D objects. This current performance 
study focuses on the use of virtual controllers in conjunction with a mouse to perform tasks involving 
rota- tion. In performing rotations users can manipulate aU three axes simultaneously, whereas in performing 
translations and sizing operations users more often tree fewer axes. Most 3-D graphics machines use a 
mouse with one to three discrete buttons as the main input control device. Currently, there are four 
popular display techniques used to control object rolations: 1) Sliders: Typically the user adjusts the 
x, y and z sliders graphically displayed on the screen to indicate the amount of rotation in each axis 
independently. (Alternatively, physical sliders can be used). 2) Menu selection: The user first selects 
the axis from a text menu and then holds down the mouse button while moving the mouse in one dimension 
to indicate the amount of rotation. 3) Button press: The user holds down one of three buttons on the 
mouse or keyboard, and moves the mouse in one dimension to indi- cate the amount of rotation. 4) Two-axes 
valuator: The user moves the mouse in two dimensions to control rotation in two of the three axes. The 
first three conventional approaches do allow access to rotation on all three axes but use the mouse as 
a one-dimensional input device. For ex- ample, the same left-and-right motion is used to control different 
rotation directions. However, there is little stimulus-response (S-R) compatibility or kinesthetic correspondence 
between the direction of mouse movement and direction of object rotation [7] Pique, 1986. The fourth 
conventional technique, (the two-axis valuator), does provide better S-R correspondence.  SIGGRAPH 
'88, Atlanta, August 1-5, 1988 |1 The amount of left-and-right and up-and-down movement of the mouse 
can proportionally rotate the object left-and-right and up-and-down on screen. Rotation about an arbitrary 
axis on a plane can also be done by moving the mouse diagonally. However, this technique does not allow 
the user to rotate the object clockwise or counter-clockwise. Therefore systems that use this technique 
often require the user to work with 3 independent orthogonal views to execute complete 3-D manipulations. 
One possible solution to permit full object manipulation is to use in- put devices with additional degrees 
of freedom. However, few people seem able to construct reliable mental models about the relative contributions 
and effects of all the coupled axes which are associated with these extra degrees of freedom. An earlier 
study described by [5] Mounfford, Spires and Komer, 1986, showed how much time subjects spent using all 
the different axes involved in 3-D control (i.e. the single axes x, y, z; the coupled axes xy, yz, xz; 
and all axes, xyz attached/coupled together). In this study, subjects performed translation, rotation 
and sizing operations during an object construction task. The results indicated that during rotation 
operations subjects used mostly the single independent axis, x, y or z; during translation mostly the 
coupled xy axis; and during sizing, all three axes together, xyz. Very few subjects i, this study used 
(or had use for) coupled axes of control, except for the familiar xy coupled axis. Subjects did not use 
either of the other pairs of axes (xz, yz) to move, rotate or size objects. This performance evaluation 
study suggests that users did not have enough familiarity or experience with coupled axes 0e xz, yz, 
or xyz) to successfully perform fully integrated 3-D control manipulations using all the different combinations 
of axes. Users are particularly unfamiliar with the visual appearance and movement associated with rotating 
an object around xz or yz. If this is indeed the case, then it is unlikely that users will want to have 
new devices that make simultaneous use of all of the additional degrees of freedom that can be provided 
for 3-D object manipula- tion. It is possible that for more complex manipulation tasks such as docking, 
a device with some extra degrees of freedom may be appropriate. A full six degrees-of-freedom controller 
called the IIISPACE TM Digitizer (Polhemus) is available, but such input devices are not yet affordable 
for most users. Traditional 2-D input devices will continue to be the most available and dominant devices. 
Thus it is important to design 3-D manipulation techniques assuming such a 2-D device. The current paper 
describes the conventional slider approach as well as three alternate "virtual rotational conuollers" 
that allow users to directly manipulate 3-D objects using a one-button mouse, These controllers were 
designed not to have any knobs, drag boxes or menus that could distract the user from the task of rotating 
the object. Furthermore, each controller was designed to be overlaid on top of the object to be rotated, 
helping the user focus attention on the object being manipulated. This suggested another constraint, 
that the controllers be as transparent as possible for a clear view of the object. Finally, the intention 
was that the controllers be easily understood by novices and be as natural to use as possible. That is, 
the goal was to make them "transparent" and easy to use. We designed the controller operations to perform 
as analogously to real object manipulations as possible. This was achieved by extending the use of successful 
2-D direct manipulation techniques to a 3-D environment. This paper also describes two studies which 
were carried out to evaluate the controllers by comparing subjects' performance in rotating object in 
3-D. The first study compares relative performance of all four controllers, the traditional slider and 
the 'new' three virtual controllers developed by Chen. The second study compares the best of these conlxollers 
to a controller developed by [4] Evans, Tanner and Wein, 1981. 2. DESCRIPTION OF VIRTUAL ROTATIONAL CONTROLLERS 
Figure 1 shows a representation of the displayed house used in all rota- tion tasks. Rotations in x, 
y and z correspond to rotating the object up-and- down, left-and-fight and clockwise-counter-clockwise, 
respectively. Thus, in this study, rotation is with respect to ale user's (camera's) frame of reference. 
Even though there are systems that perform rotations about the object's frame, (e.g. [1] Bier, 1986, 
[6] Nielson and Oisen, 1986l, it has been suggested that inexperienced users can perform rotations more 
easily in the user's reference frame [5] Mounfford et at, 1986. Y x Z (ore of pap) Figure 1. Definition 
of the coordinate axes. The four controller displays used in the evaluation test are shown in Figure 
2. Note that the Continuous XY with additional Z and the Virtual Sphere controllers have the same displays. 
They differ in the rotation axes available inside the circular region (described later). &#38;#169; Xl 
I  !i! I "1 I Zl I ......... I ................. a) Sliders b) Overlapping Sliders O c) Continuous 
XY+ Z d) Virtual Sphere Figure 2. Screen displays of the four virtual controllers with object in centre. 
 2.1. Graphical Sliders Controller The Graphical Sliders controller uses a traditional approach to allow 
users to perform 3-D rotations and serves as a control for performance comparisons. In this study, we 
chose horizontal sliders and placed them below the object to be rotated (see Figure 2a), similar to other 
graphical control interfaces. The sliders simulate "treadmills" and therefore provide relative control 
over the amount of rotation. A full sweep across a slider provides 180 degrees of rotation about an independent 
axis. As long as the mouse button is initially depressed inside one slider, the user can rotate about 
the corresponding axis even if accidentally crossing into another slider.  ~ Computer Graphics, Volume 
22, Number 4, August 1988 2.2. Overlapping Sliders Controller The Overlapping Sliders controller [3] 
Chen, 1987, is a modification of the conventional slider approach in three rrcspects: 1) The x, y, and 
z axes are represented by a vertical, horizontal and circular slider, respectively. 2) All three sliders 
are overlapped (as shown in Figure-3a) and then simplified to look like a nine-square grid (Figure 3b). 
3) The grid is superimposed over the object to be rotated (Figure 2b) In this implementation, a full 
sweep of the vertical or horizomal slider rotates the object 180 degrees about the x or y axis respectively. 
A full cir-cle around the outside squares rotates the object 360 degrees about z (see Figure 3b). Note 
that only near vertical, horizontal and circular movement of the mouse inside the middle column, middle 
row and outside squares (respectively) are recognized by this controller. A diagonal movement in the 
middle square, for example, is ignored since this is a coupled rotation in x and y (i.e. the rotation 
axis lying somewhere on the x-y plane). Thus, this controller still operates on the basis of single axis 
control. The difference between this controller and conventional sliders, though, is increased con- troller-display 
compatibility. The direction of movement of the mouse more closely corresponds with the direction of 
rotation. In addition, super- imposing the controller on the object is intended to give the user more 
of a sense of directly manipulating the object.  @ \.L/ Figure 3. a) Three overlapped sliders, b) idealized 
version 2.3. Continuous XY with Additional Z Controller The Continuous XY with added Z conwoller (Figure 
2c) operates in two modes. If the mouse button is depressed while the mouse cursor is inside the circle, 
left-and-right and up-and-down movement of the mouse will rotate the object left-and right and up-and-down 
on the screen. Diagonal move- meat will rotate the object the proportional amount about the x-axis and 
y- axis (i.e. the axis of rotation is on the x-y plane and is perpendicular to the direction of mouse 
movement). If the mouse button is depressed while the mouse cursor is outside the circle, the user can 
rotate the whole object clockwise by going around the outside of the circle. Thus, this controller provides 
either 1) continuous rotation on the x-y plane, or 2) exact rotation about the z-axis. In this implemcmation, 
a full sweep of the mouse across the circle rotates the object 180 degrees about the corresponding axis 
in the x-y plane. A full circle around the outside rotates the object 360 degrees about z. 2.4. Virtual 
Sphere Controller The virtual sphere controller simulates the mechanics of a physical 3-D trackball that 
can freely rotate about any arbitrary axis in 3-space. On the display screen (see Figure 2d), the user 
can imagine viewing an object en- cased in a glass sphere. Rotation is then a matter of rolling the sphere 
and therefore the object with the mouse cursor. Up-and-down and left-and-right movement at the cent/e 
of the circle is equivalent to "rolling" the irnaginmy sphere at its apex and produces rotation about 
the x-axis and y-axis respectively. Movement along (or completely outside) the edge of the circle is 
equivalent to rolling the sphere at the edge and produces rotation about z. The amount of rotation is 
adjusted so that a full sweep of the mouse across the circle rotates the object 180 degr~s about the 
corresponding axis in the x-y plane; a full circle around the outside rotates the object 360 degrees 
about z. The implementation of the Virtual Sphere is outlined in Appendix A. The difference between this 
and the Continuous XY with additional Z, is that the Virtual Sphere allows continuous rotation about 
all three axes inside the circle I while the latter only allows continuous control of two axes inside. 
To rotate in z, the user must go outside the circle. 3. EXPERIMENT 1 This first experiment was designed 
to compare the subject performance using the four controllers described above. The main performance 
measures recorded were time to complete rotation task and accuracy in performing that task. The experimenter 
gave minimal instruction in the use of each controller, so that no explicit conceptual model was imparted 
to the subjects. For example, the subjects were not told that the Virtual Sphere controller simulated 
a physical 3-D trackball. The previously described four controllers were presented to subjects in order 
of increasing computational and cognitive complexity. It may be reasonable to assume that users would 
have more difficulty in grasping the idea behind the latter controllers. We were especially interested 
in how novices would peffc~rn without first being told the conceptual models of the controllers. We wanted 
to fred out how easy the controllers were to learn by allowing subjects to just start trying to use them. 
3.1. Method 3.1.1. Subjects Twelve right-handed, male subjects were tested, consisting of both un- dergraduate 
and graduate students at the University of Toronto. All were fa- miliar with using a mouse while none 
had any experience with any of the four controllers. Only three of the twelve had any experience with 
3-D graphics systems. 3.1.2. Apparatus The experiment was run entirely on an Silicon Graphics IRIS 3020 
workstation. The IRIS (Inregrated Raster imaging System) is a high-per- formance, high-resolution (1024 
by 768) colour computing system for 2-D and 3-D graphics. The heart of the IRIS is a custom VLSI chip 
called the Geometry Engine. A pipeline of ten or twelve Geometry Engines accepts points, vectors, polygons, 
characters and curves in user-defined coordinate systems and transforms them to screen coordinates, with 
rotations, transla- tion, scaling and clipping. The four virtual controllers, the solid rendered house 
and the testing programs were written in C. In addition m the Geometry Pipeline, an IRIS system consists 
of a general-purpose microprocessor, a raster sub-system, a high-resolution colour monitor, a keyboard 
and a three-button optical mouse. Only the left button of the mouse was used for these controllers and 
the mouse worked best using stroke-lift-stroke tactics. The mouse acceleration algorithm was disabled 
so that the amount of cursor movement was not affected by the speed of the mouse movement. An IRIS was 
used because it is a very fast machine and runs in real-time and can provide full colour rendering of 
solid objects. 1The Virtual Sphere controller may actually be better than a real physical 3-D trackball 
in at least one respect. With a physical trackball, it . is impossible to have the entire top hemisphere 
of the ball exposed. This is because one of the rotation sensors must be placed at the "equator" of the 
sphere. Thus it is nearly impossible for the user to physically twist the trackball while rolling it. 
Accordingly, a 3-D trackball is better described as a 2+lD device (Buxtoa, 1986). ~  Computer Graphics, 
Volume 22, Number 4, August 1988 [] Simple I indicates one standard deviation [] Complex o.og 0.08 LLI 
0.07 0.06 0.05 v b 0.04 ~- 0.03 o< 0.02 ,~ o.ol CD z " 0.00 Slider Overlap XY * Z Sphere Controller 
Figure 6. Mean accuracy for simple and complex rotations. As a result of observing subjects performing 
single-axis rotation with the slider controllers, it was clear that when subjects selected the correct 
slider, the time to complete the match was short. However, subjects would often begin by selecting the 
wrong slider and then spend their time correcting the error. However, for the continuous controllers 
(XY + Z and the Virtual Sphere), initial movement was almost always in the correct direction, but the 
extra degrees of freedom made single axis rotation more difficult, so more time was needed to compensate 
for small deviations from rotation about that axis. This suggests that allowing the user to work with 
independent axes of control may be best when precise rotation is required around one axis. The real word 
situations in which such rotations may be required, however, seem limited. When subjects performed complex 
rotations, the Virtual Sphere was clearly superior in terms of speed. On the basis of these data, we 
can expect an average savings of almost twelve seconds for a single, complex rotation task by using the 
Virtual Sphere as compared to conventional slider con- trollers. Furthermore, most subjects commented 
that they preferred the Vir- tual Sphere of the four controllers that they used, while two subjects preferred 
the Continuous XY with Additional Z controller. Subjects remarked that the Virtual Sphere seemed "more 
natural" and that they felt like they were actually rotating the object directly, rather than manipulating 
a controller which in turn rotated the object. It seems that the use of continuous control is one important 
aspect in the design of virtual controllers for this kind of task. A further point of interest is that 
the overlapping sliders, while not producing performance as fast as the continuous controllers, did give 
a shorter mean task completion time than the traditional slider approach. This performance difference 
is probably due to the increased S-R compatibility of this controller versus the traditional slider controller. 
Subjects performing simple rotations were significantly less accurate using the continuous controllers 
compared to the two slider controllers (p<0.05). These results are shown in Figure 6. However, the actual 
magmtude of these differences was small (at most a squared deviation of 0.003). There were no significant 
differences in accuracy for the complex rotations. Again, variances across controllers were fairly constant, 
both simple and complex rotations indicated the same trends. The data suggest that if the task to be 
performed is extremely simple, and if it is important that the rotation be accurate, then sliders may 
be most suitable. However, given any increase in the complexity of the task, con- trollers designed based 
on the principles of direct manipulation produce faster and just as accurate performance. 4. EXPERIMENT 
2 In experiment 1 the Virtual Sphere produced the best user performance of the four controllers in complex 
rotations. It seemed of interest to know how the Virtual Controllers would perform relative to a similar 
controller developed by Evans et al. [4]. This further experiment was prompted by some experts in the 
area claiming that the two eontroUers were very similar. However, it was our opinion that several differences 
existed between these two controllers, both in terms of technical implementation and in visual presentation 
style. Technically, the Evans et al. technique is a combination of the "two- axis trackball" and the 
"stirrer" techniques described in their paper. Their implementation recognizes straight line (continuous 
rotation in x and y) and circular (rotation in z) gestures. To detect the different motions, a "stirring 
angle" is calculated based on the change in movement of the last three positions of the input device. 
This value is then compared to a threshold to decide whether the movement is in a "relatively" straight-line 
or not. Unfortunately, the threshold is dependent on two interrelated variables: the speed with which 
each individual user likes to draw the circle and the frequency of taking a reading from the input device. 
If the sampling rate is too fast or the user prefers to draw the circle slowly, the three readings would 
tend to indicate that a straight line is drawn. Thus, threshold adjustments may be needed for different 
systems and different users with th~ technique 1. The Virtual Sphere, on the other hand, allows rotation 
about an arbitrary axis in 3-space. The direction and amount of rotation is based only on the last two 
locations of the input device, and no user dependent adjustment is necessary. The two techniques also 
have different visual presentations. With the Evans et al. technique, the location of the cursor which 
is controlled by the input device is not important; the user can ignore the cursor and just concentrate 
on the object being rotated. With the Virtual Sphere, the cursor must stay inside the "circle" to control 
rotation about all three axes. This technique works best when the circle is surrounding the object being 
rotated, so as to take advantage of the direct manipulation quality that the controller affords. With 
respect to the cursor, the Evans et al device is a relative controller whereas the Virtual Sphere is 
an absolute controller. Our Virtual Controller provides the user with some additional visual guidance 
as to where to concentrate their manipulation movements. To implement the Evans et al. technique, we 
invited one of the co- authors, Peter Tanner, to help us reproduce the "feel" of their original implementation. 
The following adjustments were made to deal with the sampling problem mentioned above: Cursor movement 
is only recognized if the change is greater than a 3 pixels radius.  The largest stirring angle (rotation 
in z) is limited to approximately 33 degrees per screen update.  * The stirring angle is scaled proportional 
to the amount of cursor movement, The stirring threshold was set to approximately 13 degrees so that 
an angu- lar change in movement of less than 13 degrees is considered movement along a straight line. 
Quantatively, a 360 degrees of rotation of an object requires about 3200 degrees of quick small cirealar 
motion or 1100 degrees of quick large circular motion. For the same rotation in x-y, the implementation 
required about 2.5 times the movement distance as the Virtual Sphere controller. 1The Evans et al paper 
suggested that it is possible to perform rotations in x, y and z together, by reducing the x and y rotations 
when the stirring motion is large, and reducing z rotation when stirring motion is small. However, Tanner 
informed us [personal communication] that their implementation did use an angular threshold to decide 
whether to perform rotation in x-y or in z. f SIGGRAPH '88, Atlanta, August 1-5, 1988 4.1. Method The 
method for this experiment was identical to that used in the previous experiment 1, with the following 
exceptions: Six different, right-handed, male subjects were used instead of twelve. Again, all were 
familiar with the mouse while only two of the six had used any 3-D computer graphics systems. Only two 
controllers were used in this experiment. Half the sub- ject used the Virtual Sphere first, while the 
other half used the Evans et al. controller firsL  The entire session lasted about 45 minutes.  An 
IRIS 2400 Turbo with a mechanical mouse was used in this experiment. The mechanical mouse provided about 
the same con- troller-display ratio as the optical mouse used in experiment 1.  4.2. Results and Discussion 
Figure 7 shows the average time in seconds to complete rotations for simple versus complex orientations 
collapsed across subjects. Figure 8 shows the mean accuracy scores for both simple and complex rotations. 
The results under all conditions show the Virtual Sphere and the Evans et al. technique to be similar. 
Statistical tests showed there were no significant differences between the two controllers at the 0.05 
level. Note that Figure 7 and 8 also show the result for the Virtual Sphere from experiment 1. Some performance 
variations between the experiments using the same controller are to be expected, see Figure 7, and these 
differ- ences are relatively small. However, Figure 8 shows noticeably different standard deviations 
for the Virtual Sphere between the two experiments, larger in the second than the first. This may be 
a result of using different subjects who used only two controllers in experiment 2, compared with four 
in experiment 1, or because of using two different Iris machines with two different types of mice [] 
Simple indicates one standard deviation [] Complex 50 40 3O I-- I0 o Sphere: Expt i Sphere: Expt 2 , 
Evans et al. Controller Figure 7. Mean time to complete simple and complex rotations. I Simple indicates 
one standard deviation [] Complex A o,og L 0.08 (-- uJ 0.07 ~r 0.05 ~. 0.04 0.03 o 0.02 < g o.ol 0.00 
Sphere: Expt I Sphere: Expt 2 Evans et al. Controtler Figure 8. Mean accuracy for simple and complex 
rotations. Comments from the subjects indicated that the majority (5 out of 6) preferred the Virtual 
Sphere over the Evans et al. controller. They com- mented that the Virtual Sphere felt more "natural", 
even though only two subjects were explicit about comparing the controller to manipulating a sphere. 
The one subject that tzreferred the Evans et ~ controller indicated he liked it because he did not have 
to watch the cursor, only the object being manipulated. However, all the subjects said that they had 
difficulty in mak- ing fine rotation in z, since this required quick but short circular motions. Also 
a large rotation in z requires a lot of circular motion since the controller has a built-in maximum rotation 
speed. Large circles were also said to be less effective because often the stirring threshold was not 
reached, and resulted in x-y rotations. 5. CONCLUSIONS The data reported in the first study Support the 
use of continuous-axes controllers for complex multi-axis object manipulations. Observation of the subjects 
confirmed that moving between axes is cumbersome with the sliders, since there is no inherent direct 
manipulation capability. However, the slider controllers are just as good for simple single axis rotation, 
where the axes are already constrained to only one axis movement at a time, a situation which simplifies 
the user's control options. This would indicate that some constraint mechanism should be provided to 
limit the axis of rotation for more continuous-type controllers, if they are to be used in a real system. 
In both of our experiments, the new controllers have a "one-to-one" controller to display (C-D) ratio. 
This created the impression that when using the Virtual Sphere controller, subjects thought they could 
actually grab the corners of the house and move it. A smaller C-D ratio might have made fine adjustments 
easier. However, subjects had more difficulty in judging orientation accurately than in performing fine 
mouse movements. Nevertheless, it would be useful to test the effects of different C-D ratios or dynamic 
ratios which would vary with the speed of motion. It might also be worthwhile to re-test our subjects 
to examine any performance changes now they know the conceptual model behind the controllers. The fact 
that the results in experiment 2 showed no significant differ- ence between Evans et al.'s technique 
and the Virtual Sphere in itself is significant. It would be tempting to regard these controllers as 
competitors, where one controller could be chosen and then used by all users. However as we mentioned 
before, these two techniques differ both in implementation and more importantly, in their visual presentation. 
Note also that both techniques deal with only one aspect of rotation manipulation. We have ignored the 
processes involved with the user having to actually select the object as well as selecting it's centre 
of rotation. Designing these additional performance features and integrating them successfully into the 
entire interface design is an important and critical next step. The results indicate that either of the 
techniques would perform better relative to other existing @ ~ Computer Graphics, Volume 22, Number 4, 
August 1988 I I I III III II techniques for 3-D interface rotations. The ultimate decision should be 
based on user's preference, and on which technique fits in better with the entire interface design for 
the broadest range of different user tasks. The Evans et al. paper presented a catalogue of interesting 
techniques, but gave no supporting behavioural data comparing these techniques, or to other existing 
techniques that were common at the time. While some of the techniques described were novel and appeared 
to be fairly powerful, they are not in common usage. For example, we are not aware of any commercial 
system that makes use of their technique that we replicated in this experi- ment. One of the driving 
forces in the current work was not just to introduce another interaction technique, but to provide objective 
comparative user data which allows the reader to quantatively access the relative strengths and weaknesses 
of the different controllers. We plan to further develop ~ese techniques and to explore their use in 
a range of more complex tasks. More complex and diverse tasks may further indicate where the advantages 
for different controllers exist Furthermore, the "complex" rotations subjects performed in these studies 
may be viewed as relatively simple when compared to the kinds of tasks that may be required in real-world 
settings. Users need to rotate objects in the context of other objects as well as to perform translation 
and sizing operaations in the 3-D graphics environment. Our virtual, alternative continuous-axes controllers 
did not require the use of special purpose 3-D control devices, nor did they require the use of a multi-button 
mouse. The performance value of the continuous controllers, (Continuous XY with additional Z and the 
Virtual Sphere), lies both in their intuitive easy-to-learn features and their direct manipulation capabilities. 
These controllers are worthy of further experimental validation and refinement for use in designing interfaces 
by extending the user interface principle of WYSIWYG, What You See is What You Get, to WYDIWYS, What 
You Do Is What You See! Acknowledgements This research was supported in part by the Natural Sciences 
and Engi- neering Research Council of Canada and with a grant and internship program from Apple Computer 
Inc. It was undertaken at Apple Computer Inc., Cupertino, and at the Dynamic Graphics Project and the 
Department of Landscape Architecture, both at the University of Toronto. We are especially indebted to 
Prof. John Danahy and his students at the Department of Landscape Architecture, as well as Jim Batson 
in the Advance Technology Group (Apple Computer Inc.) for the use of their IRIS' on short notice. We 
would like to thank Peter Tanner for helping us reproduce their in- teraction technique for the experiment. 
We also thank Bill Buxton, Eric Hulteen, and Bill Gaver for suggestions and comments on this paper. APPENDIX 
A: The Implementation of the Virtual Sphere Controller A.1. Rotation of a 3-D Trackball On a 3-D trackbali 
(see Figure 9), if one touches the ball at point P, and rotates it in a tangential direction d, the axis 
of positive rotation a, can be computed by the cross product: ----) ) ----) a=OPxd ) where O is the centre 
of the trackball, and O P is a vector from the point O to P. Figure 9. Rotation of a 3-D trackball. A.2. 
Emulation of a 3-D Trackball Using a 2-D Control Device The computation of the corresponding axis of 
rotation using a 2-D control device is done in three steps as shown in Figures 10, 11 and 12. Step 1 
: Figure 10 shows the top hemisphere of the 3-D trackball coneeptually being flattened into-a disk. Let 
O' be the centre of the disk. Let P' be the -_> starting point where the 2-D control device is first 
moved, and d' be the direction of movement. If P' = O' and d' makes angle x' with the x-axis, .._.~ the 
axis of rotation is on the x-y plane perpendicular to d' and can be obtained from equation (I): a (x,y,z)= 
[-sin(x')cos(x') 0] (1) y , d' z (out) Figure 10. Movement of a 2-D device where P' = O'. #SIGGRAPH 
'88, Atlanta, August 1-5, 1988 Step 2: If P' is on the positive x-axis along the line O'R' as show in 
Figure 11, the axis of rotation is that obtained from equation (1) but rotated I t t by 00 ffi f degrees 
about the y-axis. Namely, kl~'lJ r cos f(<o) o -sin f(o>) ] 7(x,y,z) : [-sin('I') cos('f') O] ° / 0 1 
v / (2) L sin f(eo) 0 cos f(o0) d ) -> where I O'P'I and I O'R'I are the length of the (2-D) vector 
O'P' and the line O'R' respectively, and f(x) can be any monotonically-increasing function with conditions: 
0 if x~O f(x)= 90 ° if x >_ 1 The function f(x) describes how the hemisphere is distorted into the flat 
disk. The Virtual Sphere controller in the experiments used f(x) = x, with > the above constraints. Note 
that if IO'P't = 0, equation (2) is the same as > equation (1). If IO'P'I = IO'R'I, then the axis of 
rotation is on the y-z plane. R' z (out) Figure 11. Movement of the 2-D device where P' is on O'R'. 
Step 3: In the general case (see Figure 12), ) O'P' makes angle 0' with the x-axis, and d " 0'+'~' " 
" . Since Figure 12 is just Figure 1 1 rotated by 0' degrees about the z-axis, the axis of rotation 
is that obtained from equation (2) excepted rotated by 0' degrees about z. Namely, a~(x,y,z) = [-sin(x') 
cos(,') 0]. [ cos f(co)0 01 -sin f(t0) ]0 sin f(00) 0 cos f(0)) COS0' -sin0' O slnO' cos0' 0 0 ] 0 1 
(3) z (out) Figure 12. Movement of the 2-D device where P' is arbitrarily located. Once the axis of 
rotation is obtained from equation (3), the rotation matrix R can be computed by: [2 ] tax+C taxay÷Sa 
z taxaz-Say 2 a T (~) = taxay-sa z tay~ tayaz+sa x (4) 2 taxaz+Say tayaz-Sax taz+C where ax, ay and 
a z are the components of a , s = sin(p, c = cos(p, and t = 1-cos(p, and ~p is the amount of rotation 
about a [7]. The angle of rotation ~p can simply be the distance of cursor movement times a suitable 
scaling factor. However, we decided to model the rolling of the sphere more precisely. We scaled the 
amount of rotation such that: 1) a full sweep of the mouse across the circle (passing through O') produces 
1 80 degrees of rotation; 2) a full circle around the edge (or outside) the circle produces 360 degrees 
of rotation. The following formula for tp in degrees (obtained empirically) was used in the experiment, 
and provides a good approximation to the two desirable properties described above: 121 02 0o .. ,'1)} 
~=9oo * Ibtrff'l { 1-(1- -7-)~u-lcos ~:~ ~ Computer Graphics, Volume 22, Number 4,August 1988 I Illll 
 References 1. Bier, Eric A. Skitters and Jacks: Interactive 3-D Positioning Tools. In Proceedings 1986 
Workshop on Interactive 3-D Graphics (Chapel Hill, North Carolina, October 1986), 183-196. 2. Buxton, 
William. There's More to Interaction than Meets the Eye: Some Issues in Manual Input. In User Centred 
System Design: New Perspectives on Human-computer Interaction, D. A. Norman, &#38; S. W. Draper Eds. 
Lawrence Erlbaum Associates, Hillsdale, N.J, 1986. pp. 319-337. 3. Chen, Michael. A Technique for Specifying 
Rotations in Three Dimensions Using a 2D Input Device. In Proceedings IEEE Montech'87 -Compint'87 (Montr6al, 
Qu6bec, November 1987), 118- 120.  4. Evans, Kenneth B, Tanner, Peter P. &#38; Wein, Marceli. Tablet 
Based Valuators that Provides One, Two or Three Degrees of Freedom. Proceedings of SIGGRAPH'81 (Dallas, 
Texas, August 1981). In Computer Graphics 15, 3 (August 1981), 91-97. 5. Mounfford, S. Joy, Spires, 
Shannon &#38; Korner, Kim. Visage: A Three- Dimensional Graphics Editor -Evaluation and Review. MCC Technical 
Report #HI-105-86-P, Microelectronics and Computer Technology Corporation, Austin, Texas, 1986. Data 
presented at 31st Annual Meeting of Human Factors Society in New York, October 19- 22, 1987. 6. Nielson, 
Gregory M, Olsen, Dan R. Jr. Direct Manipulation Techniques for 3-D Objects Using 2D Locator Devices. 
In Proceedings 1986 Workshop on Interactive 3-D Graphics (Chapel Hill, North Carolina, October 1986), 
175-182. 7. Pique,/vlichael E. Semantics of Interactive Rotations. In Proceedings 1986 Workshop on Interactive 
3-D Graphics (Chapel Hill, North Carolina, October 1986), 259-269.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378502</article_id>
		<sort_key>131</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Harnessing chaos for image synthesis]]></title>
		<page_from>131</page_from>
		<page_to>140</page_to>
		<doi_number>10.1145/54852.378502</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378502</url>
		<abstract>
			<par><![CDATA[Chaotic dynamics can be used to model shapes and render textures in digital images. This paper addresses the problem of how to model geometrically shapes and textures of two dimensional images using iterated function systems. The successful solution to this problem is demonstrated by the production and processing of synthetic images encoded from color photographs. The solution is achieved using two algorithms: (1) an interactive geometric modeling algorithm for finding iterated function system codes; and (2) a random iteration algorithm for computing the geometry and texture of images defined by iterated function system codes. Also, the underlying mathematical framework, where these two algorithms have their roots, is outlined. The algorithms are illustrated by showing how they can be used to produce images of clouds, mist and surf, seascapes and landscapes and even faces, all modeled from original photographs. The reasons for developing iterated function systems algorithms include their ability to produce complicated images and textures from small databases, and their potential for highly parallel implementation.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[fractals]]></kw>
			<kw><![CDATA[geometric modeling]]></kw>
			<kw><![CDATA[iterated function systems]]></kw>
			<kw><![CDATA[textures]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Wavelets and fractals</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.7</cat_node>
				<descriptor>Chaotic systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003728</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Ordinary differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P196297</person_id>
				<author_profile_id><![CDATA[81100182877]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Barnsley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iterated Systems Inc. and School of Mathematics, Georgia Institute of Technology, Atlanta, Ga]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14080048</person_id>
				<author_profile_id><![CDATA[81100202167]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arnaud]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jacquin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School of Mathematics, Georgia Institute of Technology, Atlanta, Ga]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334759</person_id>
				<author_profile_id><![CDATA[81319496952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Francois]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Malassenet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School of Mathematics, Georgia Institute of Technology, Atlanta, Ga]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334926</person_id>
				<author_profile_id><![CDATA[81339524112]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Laurie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reuter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dept. of Electrical Engineering and Computer Science, George Washington University, Washington, D.C. and School of Mathematics, Georgia Institute of Technology, Atlanta, Ga]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P12783</person_id>
				<author_profile_id><![CDATA[81100524614]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Sloan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iterated Systems Inc. and School of Mathematics, Georgia Institute of Technology, Atlanta, Ga]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15907</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amburn, P., Grant, E., Whitted, T., "Managing Geometric Complexity with Enhanced Procedural Methods," Computer Graphics, 20 (4) (August 1986).]]></ref_text>
				<ref_id>Ambu 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F. and Demko, S., "Iterated Function Systems and the Global Construction of Fractals," The Proceedings of the Royal Society of London A 399, pp. 243-275 (1985).]]></ref_text>
				<ref_id>Barn 85a</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F., Ervin, V., Hardin, D. and Lancaster, J., "Solution of an Inverse Problem for Fractals and Other Sets," Proceedings of the National Academy of Science, Vol. 83 (April 1985).]]></ref_text>
				<ref_id>Barn 85b</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F., "Fractal Functions and Interpolation," Constructive Approximation, 2, pp. 303-329 (1986).]]></ref_text>
				<ref_id>Barn 86a</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F., Elton, J., "A New Class of Markov Processes for Image Encoding, " to appear in the Journal of Applied Probability (1986).]]></ref_text>
				<ref_id>Barn 86b</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61159</ref_obj_id>
				<ref_obj_pid>61153</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F., (SIGGRAPH tutorial) "Fractal Modelling of Real World Images," to appear in The Science of Fractals, Springer-Verlag, Berlin (1988).]]></ref_text>
				<ref_id>Barn 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>59931</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Barnsley, M. F., Fraetals Everywhere, to appear, Academic Press (1988).]]></ref_text>
				<ref_id>Barn 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bedford, T. J., "Dimension and Dynamics for Fractal Recurrent Sets," Journal of the London Mathematical Society 2 (33), pp. 89-100 (1986).]]></ref_text>
				<ref_id>Bedf 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325245</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Demko, S., Hodges, L., and Naylor, B., "Construction of Fractal Objects with Iterated Function Systems," Computer Graphics 19 (3), pp. 271-278 (July 1985). SIGGRAPH '85 Proceedings.]]></ref_text>
				<ref_id>Demk 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Diaconis, P., Shahshahani, M., "Products of Random Matrices and Computer Image Generation," Contemporary Mathamatics, 50, pp. 173-182 (1986).]]></ref_text>
				<ref_id>Diac 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Elton, J., "An Ergodic Theorem for Iterated Maps," To appear in the Journal of Ergodic Theory and Dynamical Systems (1986).]]></ref_text>
				<ref_id>Elto 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Fussell, D., Carpenter, L., "Computer Rendering of Stochastic Models," Communications of the ACM 25 (6) (June 1982).]]></ref_text>
				<ref_id>Four 82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hata, M. "On the Structure of Self-Similar Sets," Japan Journal of Applied Mathematics, 2 (2), pp. 381-414 (Dec. 1985).]]></ref_text>
				<ref_id>Hata 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hutchinson, J., "Fractals and Self-similarity," Indiana University Journal of Mathematics, 30, pp. 713-747 (1981).]]></ref_text>
				<ref_id>Hutc 81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801284</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kawaguchi, Y., "A Morphological Study of the Form of Nature," Computer Graphics, 16 (3), (July 1982). SIGGRAPH '82 Proceedings.]]></ref_text>
				<ref_id>Kawa 82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, B., The Practal Geometry of Nature, W. H. Freeman and Co., San Francisco (1982).]]></ref_text>
				<ref_id>Mand 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15890</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Miller, G. S. P., "The Definition and Rendering of Terrain Maps," Computer Graphics, 20 (4), (August 1986). SIGGRAPH '86 Proceedings.]]></ref_text>
				<ref_id>Mill 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer, P. E., "Real Time Design and Animation of Fractal Plants and Trees," Computer Graphics, 20 (4), (August 1986).]]></ref_text>
				<ref_id>Oppe 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>913956</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Reuter, L., "Rendering and Magnification of Fractals using Iterated Function Systems", Ph.D. Thesis, Georgia Institute of Technology, Dec 1987.]]></ref_text>
				<ref_id>Reut 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R., "Plants, Fractals, and Formal Languages," Computer Graphics 18 (3), pp. 1-10 (July 1984). SIGGRAPH '84 Proceedings.]]></ref_text>
				<ref_id>Smit 84</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Harnessing Chaos for Image Synthesis I Michael 
F. Barnsley 2, Arnaud Jacquin, Francois Malaasenet, Laurie Reuter 3, Alan D. Sioan 2 School of Mathematics, 
Georgia Institute of Technology, Atlanta, Ga 30332 Abstract Chaotic dynamics can be used to model shapes 
and render textures in digital images. This paper addresses the problem of how to model geometrically 
shapes and textures of two dimensional images using iterated function systems. The successful solution 
to this problem is demonstrated by the production and processing of synthetic images encoded from color 
photographs. The solution is achieved using two algorithms: (1) an interactive geometric modeling algorithm 
for finding iterated function system codes; and (2) a random iteration algorithm for computing the geometry 
and texture of images defined by iterated function system codes. Also, the underlying mathematical framework, 
where these two algorithms have their roots, is outlined. The algorithms are illustrated by showing how 
they can be used to produce images of clouds, mist and surf, seascapes and landscapes and even faces, 
all modeled from original photographs. The reasons for developing iterated function systems algorithms 
include their ability to produce complicated images and textures from small databases, and their potential 
for highly parallel implementation. Key Words and Phrases: Iterated Function Systems; Fractals; Textures; 
Geometric Modeling. 1 Research supported in part by DARPA, Applied and Computational Mathematics Program, 
through grant #N00014-86- C-0446. 2 Barnsley and Sloan are also affiliated with Iterated Systems Inc. 
3 Dept. of Electrical Engineering and Computer Science, George Washington University, Washington D.C. 
20052. Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
 &#38;#169;1988 ACM-0-89791-275-6/88/008/0131 $00.75  1. Introduction The mathematical theory of Iterated 
Function Systems (IFS) has unique advantages for addressing a broad class of modeling problems including 
the modeling of natural objects and scenes. The feasibility of using IFS theory in computer graphics 
was reviewed previously at SIGGRAPH [Demk 85, Barns 87]. The present work concerns the development of 
IFS as a practical tool for the production of images including clouds and smoke, seascapes and landscapes, 
and even facss. Specifically, it addresses the problem of how IFS may be used to geometrically model 
the shapes and textures of two-dimensional objects. The approach presented here has its roots in fractal 
geometry, whose applications in computer graphics have been investigated by a number of authors including 
Mandelbrot [Mand 82], Kawaguehi [Kawa 82], Oppenheimer [Oppc 86], Fournier et al. [Four 82], Smith [Smit 
84], Miller [Mill 86], and Amburn et al. [Ambu 86]. In all cases the focus has been on the modeling of 
natural objects and scenes. Both deterministic and random geometries have been used. The present work 
is based on the use of iterated function systems. This provides a single framework which can reach a 
seemingly unlimited range of images. It is distinct from earlier work in that it concentrates on measure 
theory rather than geometry. The mathematical basis of the theory can be found in a rapidly growing literature 
[Hutc 81], [Bata 85], [Dine 86], [Barn 86], [Barn 88]. We introduce two new IFS-based algorithms. The 
first one, the Collage algorithm, is a geometric modeling tool for interactively finding iterated function 
system codes. The second one is called the Measure Rendering algorithm. It applies chaotic dynamics to 
the computation of the geometry and texture of IFS encoded images. The Collage algorithm is based on 
Collage Theorem [Barn 85], [Barn 88]. It provides a means for interactive geometric modeling using IFS. 
In the two-dlmensional ease, the input to the ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 algorithm is 
a target image; for example, a polygonal approximation to the boundary of a leaf, a digitized image of 
a leaf, or a representation of leaves on a branch. The output from the algorithm is an IFS cede which, 
when input to the Measure Rendering algorithm, produces a textured version of the original target. The 
closeness of this rendition to the desired image depends on the accuracy with which the user is able 
to solve interactively a certain geometric problem. The Measure Rendering algorithm starts from an input 
IFS code, explained in §2, and with the aid of random iteration produces a deterministic geometric object 
together with rendering values. Despite the use of random iteration, a unique final image is obtained 
once the viewing window, resolution and a color assignment function, have been specified. The usage of 
our two algorithms in the geometric modeling and rendering of two-dimenslonal images is demonstrated 
in § 4, 5. In these two sections we show how to produce images of clouds, a field of sunflowers, a forest 
scene, and the face of a girl. 2. Textured Objects from IFS Codes §2.1 What an IFS Code Is An affine 
transformation w : R 2 --~ R z from two dimensional space R ~ into itself is defined by I/} .~ x2 L a~l 
xl -}- a22 Y2 "b b2 where the aij~s and bi's are real constants. Let A denote the matrix ( al / ), _b 
denote the vector ( b 1 , b~ )t, where t denotes the transposition operator, and _~ denotes the vector 
( x 1 , x 2 )t. We write w(x) = Ax_ + b. An affine transformation is thus completely specified by six 
real numbers. Given an affine transformation, one can always find a nonnegative number s so that Iw(x_)-~(y)l<_s-I_~-~_l 
for all x and y_ in R z. The smallest number s for which this is true is called the Lipshitz constant 
for to. In this paper we use the usual Euclidean norm [ (=l,=~)t 1= ~ =12 +=~ Such an affine transformation 
is called contractive if s < 1, and it is called a symmetry if ix-el for all _z and y in R z. It is 
ezpansive if its Lipshitz constant is greater than one. A two-dimensional IFS consists of a set of N 
affine transformations, where N is an integer. The set is denoted by {wl, w2, wa, ... , WN}, where each 
wn takes R 2 into R ~. Also required is a set of probabilities {Pl, Pu, Pa ..... Phr}, where each Pn 
> 0 and N ~Pn = 1. Let s n denote the Lipshitz constant for wn for each n = 1, 2, ... , N. Then we say 
that the IFS obeys the average contractivity condilion if sl pl. $2 p2 .s a pa. ....sNPN< 1. An IFS 
code is a set {Wn, Pn : n = 1, 2, ..., N } such that the average contractivity condition is obeyed. § 
2.2 The Underlying Model Associated with an [FS Code Let {Wn, Pn : n = 1, 2, ..., N } be an IFS code. 
Then by a theorem of Barns]ey and Elton [Barn 86b] there is a unique associated geometric object, subset 
of R 2, that is called the attractor of the IFS and is denoted by A. A has the property of being invariant 
under application of the N affine transformations {wl, w 2, w s, ... , wN}. In set-theoretic notation, 
 A= Nu to.(A). raml There is also an unique associated invariant measure, supported by A and denoted 
by /u. This measure assigns a non-negative number to each subset of R 2. It may be thought of as a distribution 
of infinitely fine sand, of fixed total mass, lying upon A. The measure of a subset fl of A is the weight 
of sand which lies upon fl . It is denoted by p(fl). The underlying model associated with an IFS code 
 '~" Computer Graphics, Volume 22, Number 4, August 1988 consists of the attractor A together with the 
measure p, and is symbolized by (A, p) . The structure of A is controlled by the affine maps {wl, w 2, 
... , WN} in the IFS code. That is, the 6xN numbers in the affine maps specify the geometry of the underlying 
model that in turn determine the geometry of associated images. The measure p is governed by the probabilities 
{Pl, P~, ..- , PN} in the 1FS code. It is this measure which provides the rendering information for images. 
The underlying model (A,p) may be thought of as a subset of the two-dimensional space, whose geometry 
and texture (fixed by the measure) are defined at the finest imaginable resolution. The way in which 
it defines images, via projection through viewing windows onto pixels, is described in the next section. 
The algorithm for the computation of these images is given in § 2.4. §2.3 How Images are Defined from 
the Underlying Model Let (A,p) be the underlying model associated with an IFS code. Let a viewing window, 
V, be defined by v={(x,Y):a <_ x <_ b,e <_ Y <_ d}. It is assumed that Vt"IA is not empty and has positive 
measure, namely #(V) > 0. Let a viewing resolution be specified by partitioning V into a grid of L x 
M rectangles as follows. The interval [a, b) is divided into L subintervals [X~_i, XI) for I = 1, 2, 
... , L where X t = a + (b--a).l/L. Similarly [c, d) is divided into M subintervals lYre-l, Ym) for m 
---- 1, 2,..., M where Ym ---- c + (d--c).m/M. Let Vt, m denote the rectangle V~,m ={(X , Y ) : X~_i_< 
X < X1, Ym_l_< Y< Y,~ }. Then the discretized model associated with V at resolution L x M is denoted 
by I (A, /~, V, L, M ). It consists of all those rectangles VI, m such that /u ( Vi, m ) ~ O, (that is 
, all those rectangles upon which there resides a positive mass of sand). The discretized model [ (A, 
/~, V, L, M ) is rendered by assigning an RGB index to each of its rectangles Vh, ~. To achieve this 
color assignment, one specifies a color map ] which associates integer color indices with real numbers 
in [0,1]. Let num-eols be the number of different colors which are to be used. One might choose for example 
eight greytones on an RGB system; then num-cols = 8 and color index i is associated with 12.5.i % Red, 
12.5.i % Green, and 12.5.i % Blue, for i = 0, 1, 2, ..., 7. The interval [0,1] is broken up into subintervals 
defined by real numbers C i that satisfy 0 = C O < C1< C 2 < ... < C,,,n_,ol,= 1. The color map is 
defined by i, if Ci_ 1 ~ x <~ el, for i = 0, l, 2, ..., num-cols-1; f(x) = { num-cols-1, if x = 1. I 
(A, #, V, L, M ) is rendered by assigning color index f (~( Vt.m)/p (tO)) to the rectangle Vt.m. In summary, 
the underlying model is converted to an image, corresponding to a viewing window V and resolution L x 
M~ by discretizing at resolution L x M the part of the attractor which lies within the viewing window. 
The rendering values for this discretization are determined by the relative measure lu( Vz,m)/p(lO, (which 
corresponds to the proportion of sand which lies upon the pixel). § 2.4 The Measure Rendering Algorithm 
The Measure Rendering Algorithm starts from an IFS code { Wn, Pn : n =1,2,..., N } together with a specified 
viewing window V and resolution L x M. It computes the associated IFS image, as defined in the previous 
section. In effect a random walk in R 2 is generated from the IFS code, and the measures I~(Vi,m) for 
the pixels are obtained from the frequencies with which the different rectangles Vl, m are visited. A 
theorem by Elton [Elto 86] guarantees that the algorithm always produces the correct result. An initial 
point (z0, y0)ER 2 needs to be fixed. For simplicity assume that the affine transformation w 1 ( z ) 
= A 1 _x + b_ 1 is a contraction. Then, (zo, Y0) is obtained by solving the following linear system for 
the fixed point of wl: [0] 0 A1 ]bl   = E bl1 2 An L × M array I of integers is associated with the 
discretized window. A total number of iterations, hum-its, large compared to L x M, also needs to be 
specified. The L x M array I is initialized SIGGRAPH '88, Atlanta, August 1-5, 1988 to zero. The random 
walk part of the algorithm now proceeds as follows for n = 0 to hum_its hegiu rand = a ramlonl unliiber 
in [U, Ii; total= Pl; k-~ I; while ( total < rand ) begin k=k+l: total = total + p~.; end; __--trip 
Yn+l yn   [1 [].... nl ~ int ( x,+ l ); n2 = Jut ( Yn+l ) ; ! [,,l][n2] = I [,tl][,,21 -4- 1; end. 
Finally the elements of the array I are normalized by dividing by the maximum entry in the array, J. 
Colors are then assigned to the array according to ] [al]in2] = ] ( I [n11[=21 / ,1 ). Provided that 
hum-its is sufficiently large (see examples in ~ 5), the ergodie theorem of Elton ensures that the rendering 
values I [nl][n2], assigned to the pixels, stabilize to the unique values defined in §2.3. It is this 
algorithm which is used to calculate all of the images given with this paper.  3. Determination of IFS 
Codes In an IFS code {~n, Pn : n = 1, 2, ..., N }, the w~'s determine the geometry of the underlying 
model, i.e. the structure of the attractor A, while the p='s provide rendering information through the 
intermediary of the measure /.~. Here we describe an interactive two-dimensional geometric modeling algorithm 
for determining the w=~s that correspond to a desired model. The algorithm has its mathematical basis 
in the Collage Theorem [Barn 85b]. The algorithm starts from a target image T which lies within a viewing 
window V, here taken to be [0,1]x[O,1]. T may be either a digitized image (for example a white leaf on 
a black background) or a polygonal approximation (for example a polygonized leaf boundary). T is rendered 
on the graphics workstation monitor. An affine transformation Wl(~)-~ AlL -4- b 1 is introduced, with 
coefficients initialized at all = a~2= 0.25, a~2 = a~l---- b~- 0 (the superscripts correspond to the 
indexes of the transformations). The image wl(T) is displayed on the monitor in a different color from 
T. wl(T ) is a quarter-sized copy of T, centered closer to the point (0, 0). The user now interactively 
adjusts the a I i.j ")s by specifying changes with a mouse or some other interaction technique, so that 
the image wl(T ) is variously translated, rotated, and sheared on the screen. The goal of the user is 
to transform w I (T) so that it lies over part of T. It is important that the dimensions of wx(T ) are 
smaller than those of T, to ensure that w~ is a contraction. Once wl(T) is suitably positioned, it is 
fixed, and a new subcopy of the target, w2(T)) is introduced, w~ is interactlvety adjusted until t% (T) 
covers a subset of those pixels in T which are not in wl(T ). Overlap between wl(T) and w2(T) is allowed, 
but in general it should be made as small as possible. In this way the user determines a set of contractive 
affine transformations {w 1 , w 2 , ... , wAr} with this property: the original target T and the set 
N T= u wn(W) )1=1 are visually close, while N is as small as possible, w, (T) is called the n ~h tile 
of the collage. The mathematical indicator of the closeness of T and 7' is the Hausdorff distance h (T, 
T ) defined below; and by "visually close ~ we really mean "h (T, T ) is small ~. The maps {w t , w 2 
, ... ~ WAr } thus determined are stored. The Collage Theorem, stated below, then assures us that the 
attractor A of any IFS code {Wn, Pn : n = l, 2 ..... N }, which uses these maps, will also be "visuMly 
close" to T. Moreover if T = T, that is, if h (T, ~') ~-0 , then A = T. The algorithm produces IFS codes 
such that the geometry of the underlying model resembles that of the target. The algorithm is illustrated 
in Figure 1 which shows a polygonal leaf target T at the upper and lower left. In each case T has been 
approximately covered by four affine transformations of itself. The task has been poorly carried out 
in the lower image and well done in the upper image. The corresponding attractors are shown on the right 
hand side : the upper one is much closer to the geometry of the target because the collage is better. 
The process is also illustrated in Figure 2 which shows a collagc of a square. The resulting coefficients 
are displayed in Table 1. The precise statements which govern the above algorithm are as follows. The 
Hausdorff distance h (A, B) between two closed bounded subsets A and B of R ~ is defined as:  @ ~ Computer 
Graphics, Volume 22, Number 4, August 1988 h( A,B) = Max{ Max Min I_~-~1; Max Min i_~-zl ~. _~ ~A L¢B 
y CB ~.~A J Figure 1 Illustrations of the Collage Algorithm. The upper collage is good, so the corresponding 
attractor, shown upper right resembles the leaf target. 0 1 x Figure 2 Application of the Collage Algorithm 
applied to a classical square. The resulting IFS code is shown in Table 1. W a b c d e f p 1 0.5 0 0 
0.5 0 0 0.25 2 0.5 O 0 0.5 0.5 0 0.25 3 0.2 0 0 0.5 0 0.5 0.10 4 0.8 0 0 0.5 0.2 0.5 0.40 Table 1 IFS 
code for a Square. Figure 3 shows a portion of [0,1] x [0,1] painted by the Hausdozff distance between 
different points and a fern-like image F. The point z is colored according to the value of Min ] x --Y 
I' --y~F -- Collage Theorem [Barn85b] Let {wn, Pn : n= 1, 2 .... , N} be an [F$ code of contractive affine 
maps. Let s < 1 denote the largest Lipshitz constant for 1he maps. Let e > 0 be any posilive nnmber. 
Let T be a given closed bounded subset of R 2, and suppose the wn's have been chosen so that h(T, ~ w.(T))< 
e, then h(T, A) < (t -s)" where A denotes the attractor of the IFS.  4. From Forests to Faces At this 
point, we know how to obtain ifs codes for simple two-dimensional objects and how to recreate them as 
textured sets from the codes. We will now see how this encoding/decoding scheme is an extremely powerful 
tool for the modeling of any two- dimensional color image. § 4.1 Clouds and Mist Figure 5 shows the image 
of a cloud which is the attractor of a two-dimensional IFS code made of five affine transformations obtained 
by the Collage algorithm. The probabilities p, were chosen proportional to the areas of the corresponding 
tiles w,(T). A color map f (z) which assigns a linear grey-scale, from black to white, to the interval 
0 < z < 1 was used. An IFS model can provide visually meaningful images on several different scales. 
This is illustrated in Figures 12 and 13 where we show a zoom on an IFS encoded image. These images are 
discussed in § 5.2. The number of iterations nun_its must be increased with magnification to keep the 
number of points landing within the viewing window constant. This requirement ensures the consistency 
of the textures in an image throughout the magnification process. An efficient texture-preserving magnification 
algorithm has been developed [Reut 87]. There are three classes of free parameters that can be adjusted 
to modify a texture. The first class consists of the set of probabilities, {Pn : for n=l, 2, ..., N }. 
Typically, each probability Pn is initially assigned a value that is proportional to the relative area 
of the tile wn(T). The result is a uniform distribution of the measure p. If a probability pj is increased 
then p(wj(T)) f SIGGRAPH '88, Atlanta, August 1-5, 1988 increases as well. Another class of free parameters 
is obtained by introducing redundant maps into the collage of the target set. For example, an extra map 
may be added to an already satisfactory collage of a cloud. The coefficients and probability associated 
with this map provide a control which does not effect the geometry of the image. This control is convenient 
for animation where the position of the extra tile in the collage can be moved in time. If the movement 
of the tile is smooth, then the resulting attractors show smooth changes in the measure rendering. The 
third class of free parameters is provided by the color assignment function. This may be specified by 
a piecewise linear function, whose coefficients are adjusted to change the rendering of the image. Smooth 
interpolations from one color to another are often used in the specification of the color look-up table. 
By mapping interpolated colors to incremental changes in the measure, images appear smoothly shaded. 
Figures 6 and 7 are examples of simple scenes representing clouds and mist over a lake. The IFS codes 
for Figure 7 were obtained by slightly altering those in Figure 6. However the process is very different 
from keyframe animation. One moves smoothly from Figure 6 to Figure 7, by combining changes to the free 
parameters described above. This process is also illustrated in Figure 8. 4.2 Basics of image modeling 
An IFS code can be viewed as a dynamical entity that can be interactively modified to give rise to a 
whole class of related images. Suppose that {Wn~ Pu : n = 1, 2, ..., N } is an IFS code with associated 
attractor "A, and invariant measure p, and that t is an invertihle transformation from R 2 to R2. For 
example, t might be a translation, a rotation, a contraction, or a shear. The IFS code for the mapping 
of A under t is simply { t°wn°fl~ Pn : n = 1, 2, .., N }. In particulars this means that if an IFS code 
for a leaf is available in a library of codes, images of the same leaf from any viewpoint or any distorted 
copy of that leaf, can be readily encoded, decoded and displayed. Figures 9, 11, 12, 13, and 14 were 
encoded from color photographs taken from National Geographic. Segmentation according to color was performed 
on the originals to define textured pieces. IFS codes for these components were obtained via the Collage 
algorithm. The Measure Rendering algorithm was then applied to those codes to synthesize the images. 
The IFS data base contained less than 180 maps for the Monterey seascape, and less than 160 maps for 
the Andes Indian girl.  5. Hierarchical structures §5.1 Patterns in Nature The modeling of natural scenes 
is a difficult issue in computer graphics. Photographs of natural scenes contain redundant information 
in the form of subtle patterns and variations. The analysis of these patterns is the focus of ongoing 
research in computer graphics. Two characteristic features of natural scenes have already become clear 
from this research. They are (i) the presence of complex geometrical structure at all scales of observation, 
and (ii) the hierarchical layout of primitive objects. (i) Natural boundaries and textures are not smoothed 
out under magnification; they preserve some degree of ruggedness. (ii) Natural scenes are organized in 
hierarchical structures: A forest is made of trees, that consist of branches along trunks. On these branches, 
pine needles or leaves cluster into bundles. Each bundle is a group of individual entities. These two 
important intuitive aspects can be integrated into IFS modeling. §5.2 Condensation Sets and Hierarchical 
IFS Here we describe some aspects of IFS with condensation which can be used for hierarchical structure 
rendering. A detailed treatment can be found in [Barn 88]. As in the previous sections, the underlying 
metric space is tho Euclidean plane R 2. An IFS with condensation is denoted by {w0, wz, w 2 ..... wN}. 
It consists of an IFS {wl, wz, w a ..... WN}, together a set-valued map w 0. This set-valued map is defined 
by a closed bounded subset C in R 2 according to Wo(Z)= Cfor all z ER 2. C is called the condensation 
sei C of the IFS. It can be shown that its attractor A C is uniquely defined by the equation : N A =U 
w, C .=o (AC) If C is the empty set this reduces to the usual situation. If C is nonempty then it can 
be shown that A c= closure of { CU ~ w°n( C)} n=1  where W ( C ) denotes the union of the images of 
the set C under the N affine transformations wl, wz, t% .... , w N. That is N w(c)= u ~.(c).  ~ Computer 
Graphics, Volume 22, Number 4, August 1988 IIIII I IIII II Note that w 0 is not an afflne transformation, 
but, as a set map, it is a contraction. An IFS with condensation may be used to provide a global model 
of a structured set of geometric objects such as a field of flowers, a tree, an orchard or a forest. 
This is feasible because the Collage Theorem can be extended to the case of an IFS with condensation. 
When implemented in software this provides the user with a means for finding a collection of contractive 
affine transformations {wl, w 2, ws, ... , w N} along with a condensation set C such that so that the 
attractor of the associated IFS with condensation is visually "close to" a given target set T. A formal 
statement of the theorem is given below: Collage with Condensation [Barn 88] Let {wn: n = 1, 2 ..... 
N } be an IFS code of contractive affine maps. Let C be a closed bounded subset of R 2. Let w o denote 
the set transformation associated with C, defined by Wo( B ) = C for all nonempty closed bounded subsets 
B C R 2. Let s < 1 be the largest Lipshitz constant for the maps. Let e > 0 be any positive number. Let 
7' be a given nonempty closed bounded subset of R 2, and suppose the wn's have been chosen so that h 
(T, NO wn(T)) < e. rim0 Then h(T, AC) < c (1 -s) where A C denotes the attractor of {wn: n = O, 1, 2 
..... N }. In Figure 4, we illustrate the application of the Condensation Collage Theorem. On the left-hand 
side top and bottom we show a shaded target image on which we have overlayed in white a condensation 
collage consisting in each case of a "trunk" condensation set and two affine transforms of the target. 
In each case the collage determines a different IFS with condensation. On the right-hand side of each 
image we show the attractor of this associated IFS. The theorem tells us that the closer the "white image" 
(i.e. the union of the condensation set together with the afffine transformed copies of the target) is 
to the shaded image (i.e. the target), the closer the attractor of the associated IFS "with condensation" 
will be to the shaded image. Closeness is measured objectively with the Hausdorff distance. The top collage 
is better than the bottom collage, and this is echoed in the improved subjective match of the top right 
attractor to the original tree image. To obtain a hierarchical IFS we choose C to be the attractor of 
an IFS, say {Vm: m = 1, 2, ..., M}. In this way the ordered pair of IFS ({Vm}, {wn}) defines a unique 
subset of ~2. Here again we can choose {vn} to be an IFS with condensation and the process can be repeated 
to obtain an ordered triple of IFS, and so on. This allows us to build up more and more complicated models, 
while maintaining the smooth dependence of images on the parameters in the IFS. Two primitives, a leaf 
and a flower, in Figure 10 were used as condensation sets in the picture Sunflower Field, Figure 11. 
Here we see the hierarchical structure: the leaf is itself the attractor of an IFS; and the flower is 
an overlay of four IFS attractors. In the pictures Sunflower Field and Black Forest, shown in Figures 
11 and 12, the primitives were displayed from back to front. The data bases for the Sunflower Field and 
Black Forest contain less than 100 and 120 maps respectively. A zoom on the Black Forest is shown in 
Figure 13.   6. Conclusion In this paper we have presented some theorems that are the basis of methods 
for encoding images using IFS theorem. The methods described apply to all types of images, and are not 
restricted to those which display typical "fractal" features. The IFS approach is very different from 
the random fractal geometry approach. The latter consists of random recursive refinement algorithms to 
produce terrain models, stochastic procedures used to produce clouds and textures, and random branching 
and growth models for plants. In all these cases the final product depends upon the precise random number 
sequence generated during computation. The Measure Rendering algorithm presented in this paper has the 
feature that small visual changes in the parameter values of the input IFS code yield only small changes 
in the resultant image. This is important for system independence, interactive usage and animation. Furthermore, 
images vary consistently with respect to changes of viewing window and resolution. Images can be generated 
from the same data base to a very high resolution or equivalently viewed within a small window, without 
reducing to blocks of solid color. The are several reasons for the continuing development of IFS algorithms 
in computer graphics. First, IFS codes are powerful data amplification primitives: very small data bases 
are used to generate complex images. Second, IFS algorithms are such that they can be implemented in 
a highly parallel manner. This means that images could be generated and manipulated in real time.  
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378503</article_id>
		<sort_key>141</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Development models of herbaceous plants for computer imagery purposes]]></title>
		<page_from>141</page_from>
		<page_to>150</page_to>
		<doi_number>10.1145/54852.378503</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378503</url>
		<abstract>
			<par><![CDATA[In this paper we present a method for modeling herbaceous plants, suitable for generating realistic plant images and animating developmental processes. The idea is to achieve realism by simulating mechanisms which control plant growth in nature. The developmental approach to the modeling of plant architecture is extended to the modeling of leaves and flowers. The method is expressed using the formalism of L-systems.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[L-system]]></kw>
			<kw><![CDATA[development morphology]]></kw>
			<kw><![CDATA[parallel graph grammar]]></kw>
			<kw><![CDATA[physiology of plants]]></kw>
			<kw><![CDATA[realistic image synthesis]]></kw>
			<kw><![CDATA[scientific visualization]]></kw>
			<kw><![CDATA[turtle geometry]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>F.4.2</cat_node>
				<descriptor>Parallel rewriting systems (e.g., developmental systems, L-systems)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.1.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011058</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Visual languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003766.10003767.10003769</concept_id>
				<concept_desc>CCS->Theory of computation->Formal languages and automata theory->Formalisms->Rewrite systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14162862</person_id>
				<author_profile_id><![CDATA[81100465812]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Przemyslaw]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Prusinkiewicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of Regina, Regina, Saskatchewan, Canada S4S 0A2]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P21449</person_id>
				<author_profile_id><![CDATA[81100265695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Aristid]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lindenmayer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Theoretical Biology Group, University of Utrecht, Padualaan 8, 3584 CH Utrecht, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P132414</person_id>
				<author_profile_id><![CDATA[81100171997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of Regina, Regina, Saskatchewan, Canada S4S 0A2]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abelson, H., and diSessa, A. A. Turtle geometry. M.I.T. Press, Cambridge (1982).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Aono, M., and Kunii, T. L. Botanical tree image generation. IEEE Computer Graphics and Applications 4, 5 (1984), 10-34.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Aono, M., and Kunii, T. L. Botanical tree image generation. {Video tape}, IBM, Tokyo (1985).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W. W. The dynamics of tree linkages with a fixed root link and limited range of rotation. Actes du Colloque laternationale rlmaginaire Numrique '86 (1986), 16-21.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Baker, R., and Herman, G. T. Simulation of organisms using a developmental model, Parts I and II. Int. J. of Bio-Medical Computing 3 (1972), 201-215 and 251-267.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Beyer, T., and Friedell, M. Generative scene modelling. Proceedings of EUROGRAPHICS '87 (1987), 151-158 and 57I.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325249</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. Modeling the Mighty Maple. Proceedings of SIG- GRAPH '85 (San Francisco, CA, 1uly 22-26, 1985). In Computer Graphics 19, 3 (1985), 305-311.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Eiehhorst, P., and Savitch, W. I. Growth functions of stochastic Lindenmayer systems. Inf. and Control 45 (1980), 217-228.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Erickson, R. O. The geometry of phyllotaxis. In J. E. Dale and F. L. Milthrope (Eds.): The growth and functioning of leaves, Cambridge University Press (1983), 53-88.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Eyrolles, G. Synth~se d'images figuratives d'arbres par des m~thodes combinatoires. Ph.D. Thesis, Universit~ de Bordeaux I (1986).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>697933</ref_obj_id>
				<ref_obj_pid>646593</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Frijters, D., and Lindenmayer, A. A model for the growth and flowering of Aster novae-angliae on the basis of table (1, 0) L- systems. In G. Rozenberg and A. Salomaa (Eds.): L Systems, Lecture Notes in Computer Science 15, Springer-Verlag, Berlin (1974), 24-52.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Frijters, D., and Lindenmayer, A. Developmental descriptions of branching patterns with paracladial relationships. In A. Lindenmayer and G. Rozenberg (Eds.): Automata, languages, development, North-Holland, Amsterdam (1976), 57-73.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Frijters, D. Principles of simulation of inflorescence development. Annals of Botany 42 (1978), 549-560.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Frijters, D. Mechanisms of developmental integration of Aster novae-angliae L., and Hieracium murorum L. Annals of Botany 42 (1978), 561-575.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>730205</ref_obj_id>
				<ref_obj_pid>647559</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Habel, A., and Kreowski, H.-J. On context-free graph languages generated by edge replacement. In H. Ehrig, et al. (Eds.): Graph grammars and their application to computer science; Second Int. Workshop, Lecture Notes in Computer Science 153, Springer- Verlag, Berlin (1983), 143-158.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hall~, F., Oldeman, R., and Tomlinson, P. Tropical trees and forests: an architectural analysis. Springer-Verlag, Berlin (1978).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Herman, G. T., and Liu, W. H. The daughter of CELIA, the French flag, and the firing squad. Simulation 21 (1973), 33-41.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578742</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Herman, G. T., and Rozenberg, G. Developmental systems and languages. North-Holland, Amsterdam (1975).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Hogeweg, P., and Hesper, B. A model study on biomorphological description. Pattern Recognition 6 (1974), 165-179.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Janssen, J. M., and Lindenmayer, A. Models for the control of branch positions and flowering sequences of capitula in Mycelis muralis (L.) Dumont (Compositae). New Phytologist 105 (1987), 191-220.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801284</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Kawaguchi, Y. A morphological study of the form of nature. Proceedings of SIGGRAPH '82 (July 1982). In Computer Graphics 16, 3 (1982), 223-232.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Lienhardt, P. Modelisation et ~volution de surfaces libres. Ph.D. Thesis, Universit~ Louis Pasteur, Strasbourg (1987).]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Lienhardt, P., and Francon, J. Synth~se d'images de feuilles v~g~tales. Technical Report R-87-1, D~partement d'informatique, Universit~ Louis Pasteur, Strasbourg (1987).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Lindenmayer, A. Mathematical models for cellular interaction in development, Parts I and II. J. Theor. Biol. 18 (1968), 280-315.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Lindenmayer, A. Positional and temporal control mechanisms in inflorescence development. In P. W. Barlow and D. J. Carr (Eds.): Positional controls in plant development, Cambridge University Press (1984).]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>36217</ref_obj_id>
				<ref_obj_pid>36207</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Lindenmayer, A. Models for multicellular development: characterization, inference and complexity of L-systems. In A. Kelmenov~ and L Kelmen (Eds.): Trends, techniques and problems in theoretical computer science. Lecture Notes in Computer Science 281, Springer-Verlag, Berlin (1987), 138-168.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>730348</ref_obj_id>
				<ref_obj_pid>647560</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Lindenmayer, A. An introduction to parallel map generating systems. In H. Ehrig, et al. (Eds.): Graph grammars and their application to computer science; Third Int. Workshop, Lecture Notes in Computer Science 291, Springer-Verlag, Berlin (1987), 27-40.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Lindenmayer, A., and Prusinkiewicz, P. Developmental models of multi-cellular organisms: A computer graphics perspective. Paper submitted to the Proceedings of the ArtOicial Life Workshop held in Los Alames, NM, September 1987,]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[M~ller-Doblies D., and U. Cautious improvement of a descriptive terminology of inflorescences. Monocot newsletter 4, Institut f~r Biologic, Technical University of Berlin (West), 13 (1987).]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Nishida, T. KOL-systems simulating almost but not exactly the same development - the case of Japanese cypress. Memoirs Fac. Sci., Kyoto University, Ser. Bio. 8 (1980), 97-122.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer, P. Real time design and animation of fractal plants and trees. Proceedings of SIGGRAPH "86 (Dallas, Texas, August 18-22, 1985). In Computer Graphics 20, 4 (1986), 55-64.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578799</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Preparata F. P., and Yeh, R. T. Introduction to discrete structures. Addison-Wesley, Reading (1973).]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16608</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, P. Graphical applications of L-systems. Proc. of Graphics Interface '86 - Vision Interface '86 (1986), 247-253.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_obj_id>730363</ref_obj_id>
				<ref_obj_pid>647560</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Prusinklewicz, P. Applications of L-systems to computer imagery. In H. Ehrlg, et al. (Eds.): Graph grammars and their application to computer science; Third Int. Workshop, Lecture Notes in Computer Science 291, Springer-Verlag, Berlin (1987), 534-548.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, P., and Hanan, J. Lindenmayer systems, fractals, and plants. In D. Sanpe (Ed.): Fractals: Introduction, basics and applications. {Course notes} SIGGRAPH '88 (Atlanta, Georgia, August 1-5, 1988).]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., and Blau, R. Approximate and probabilistic algorithms for shading and rendering structured particle systems. Proceedings of SIGGRAPH '85 (San Francisco, CA, July 22-26, 1985). In Computer Graphics 19, 3 (1985), 313-322.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Robinson, D. F. A symbolic notation for the growth of inflorescences. New Phytologist 103 (1986), 587-596.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578416</ref_obj_id>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Rozenberg, G., and Salomaa, A. The mathematical theory of L- systems. Academic Press, New York (1980).]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R. About the cover: "Reconfigurable machines". Computer 11, 7 (1978), 3-4.]]></ref_text>
				<ref_id>39</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R. Plants, fractals, and formal languages. Proceedings of SIGGRAPH '84 (Minneapolis, Minnesota, July 23-27, 1984). Computer Graphics 18, 3 (1984), 1-10.]]></ref_text>
				<ref_id>40</ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R. Grammars for generating the complexity of reality. {Video tape}, Lucasfilm/PIXAR, San Rafael (1985).]]></ref_text>
				<ref_id>41</ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Stevens, P. S. Patterns in nature. Little, Brown and Co., Boston (1974).]]></ref_text>
				<ref_id>42</ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Szilard, A. L., and Quinton, R. E. An interpretation for DOL systems by computer graphics. The Science Terrapin 4 (1979), 8-13.]]></ref_text>
				<ref_id>43</ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Thompson, d'Arcy. On growth and form. University Press. Cambridge (1952).]]></ref_text>
				<ref_id>44</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Troll, W. Die Infloreszenzen, Vol. I. Gustav Fischer Verlag, Stuttgart (1964).]]></ref_text>
				<ref_id>45</ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Yokomori, T. Stochastic characterizations of EOL languages. Information and Control 45 (1980), 26-33.]]></ref_text>
				<ref_id>46</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Zimmerman, M. H., and Brown, C. L. Trees - structure and function. Springer-Verlag, Berlin (1971).]]></ref_text>
				<ref_id>47</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Developmental Models of Herbaceous Plants for 
Computer Imagery Purposes Przemyslaw Prusinkiewicz t, Aristid Lindenmayer ~ and James Hanan t t Department 
of Computer Science University of Regina Regina, Saskatchewan, Canada $4S 0A2 ~t Theoretical Biology 
Group University of Utrecht Padualaan 8, 3584 CH Utrecht, The Netherlands ABSTRACT In this paper we 
present a method for modeling herbaceous plants, suit- able for generating realistic plant images and 
animating developmental processes. The idea is to achieve realism by simulating mechanisms which control 
plant growth in nature. The developmental approach to the modeling of plant architecture is extended 
to the modeling of leaves and flowers. The method is expressed using the formalism of L-systems. CR Categories 
and Subject Descriptors: F.4.2 [Mathematical Logic and Formal Languages]: Grammars and Other Rewriting 
Systems: Parallel rewriting systems. 1.3.5 [Computer Graphics]: Computational Geometry and Object Modeling: 
Curve, surface, solid and object representation. 1.3.7 ]Computer Graphics]: Three-Dimensional Graph- 
ics and Realism. J.3 [Life and Medical Sciences]: Biology. Keywords: realistic image synthesis, L-system, 
parallel graph grammar, turtle geometry, developmental morphology and physiology of plants, scientific 
visualization. 1. INTRODUCTION, In recent years, the modeling of plants has received considerable attention. 
The problem was approached from two directions. Kawagu-chi [21], Aono and Kunii [2], Reeves and Blau 
[36], Bloomenthal [7] and Oppenheimer [31] defined branching structures primarily in geometrical terms, 
such as the lengths of branches and branching angles. Smith [39, 40], Prusinkiewicz [33, 34], Beyer and 
Friedel [6] and Eyrolles [10] concentrated on the specification of plant topology. In all cases, plants 
were defined by a small number of rules applied repeti- tively to produce complex structures. Some approaches 
made it possible to create forms which looked "younger" or "older", and even produce an impression of 
plant growth, as witnessed in the fills of Aono and Kunii [3] and Smith [41]. However, the simulation 
of development was not a focal point of any of these methods. We present a plant modeling method in which 
the simulation of development is the key to realism. Thus, in order to model a particular form, we attempt 
to capture the essence of the developmental process which leads to this form. The view that growth and 
form are interre- lated has a long tradition in biology. D'Arcy Thompson [44] traces its origins to the 
late seventeenth century, and comments: The rate of growth deserves to be studied as a necessary preliminary 
to the theoretical study of form, and organic form itself is found, mathematically speaking, to be a 
func- tion of time... We might call the form of an organism an event in space-time, and not merely a 
configuration in space. This concept is echoed by Hallt, Oldeman and Tomlinson [16]: The idea of the 
form implicitly contains also the history of such a form. Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. Q 1988 ACM-0-89791-275-6/88/008/0141 $00.75 
The developmental approach to plant modeling has two distinctive features: Emphasis on the space-time 
relation between plant parts. In many plants, various developmental stages can be observed at the same 
time. For example, some flowers may still be in the bud stage, others may be fully developed, and still 
others may have been transformed into fruits. If the developmental technique is consistently used down 
to the level of individual organs, such phase effects are reproduced in a natural way.  Inherent capability 
of growth simulation. The mathematical model can be used to generate biologically correct images of plants 
of different ages and to provide animated growth sequences.  We reenact plant development by simulating 
natural control mechanisms. Emphasis is put on the modeling and generation of growth sequences of herbaceous 
or non-woody plants, since the internal control mechanisms play a predominant role in their development. 
In contrast, the form of woody plants is determined to a large extent by the environ- ment, competition 
between trees and tree branches, and accidents [47], which are unrelated to the mechanisms considered 
in this paper. We express control mechanisms and simulate developmental processes using the formalism 
of L-systems [24]. In this sense, our approach to the modeling of plants has its origin in biological 
studies expressed in terms of L-systems [11-14, 20, 28]. Other approaches using L-systems for modeling 
purposes are also possible. For example, Hogeweg and Hesper [19] and Smith [40] searched a particular 
class of context-sensitive L-systems and selected those which generated interest- ing shapes. 2. BRANCHING 
STRUCTURES AND L-SYSTEMS, 2.1. Graph-theoretical and botanical trees, In the context of plant modeling, 
the term "tree" must be carefully defined to avoid ambiguity. To this end, we introduce the notion of 
an axial tree (Fig. 1) which complements the graph-theoretic notion of a rooted tree [32] with the botanically 
motivated notion of branch axis. A rooted tree has edges which are labeled and directed, and form paths 
from a distinguished node called the root or the base to the termi- nal nodes. In the biological context, 
these edges are referred to as branch segments. A segment followed by at least one more segment in some 
path is called an internode. A terminal segment (with no follow- ing edges) is called an apex. An axial 
tree is a special type of rooted gee. At each of its nodes we distinguish at most one outgoing straight 
segment. All remaining edges are called lateral or side segments. Within an axial tree, a sequence of 
segments is called an axis if: (a) the first segment in the sequence originates at the root of the tree 
or as a lateral segment at some node, Co) each subsequent segment is a straight segment, and (c) the 
last segment is not followed by any straight segment in the tree. Together with all its descendants, 
an axis constitutes a branch. A branch is itself an axial tree. Axes and branches are ordered. The axis 
originating at the root of the entire plant has order zero. An axis originating as a lateral segment 
of an n-order parent axis has order n+l. The order of a branch is equal to the order of its lowest-order 
or main axis. The terminal node of this axis is called the branch top. SIGGRAPH '88, Atlanta, August 
1-5, 1988  Tree Top %. Zero Order (Main) Axis !:ii/ First Order  OTerminal Node " OBranchlng Point 
.... ~ Apex ) Internode  w..":~ Lateral ,Segment It]t -\ Branc~Second~rder ,~J TreeRoot Figure I. An 
axial tree. Axial trees are purely topological objects. The geometric connota- tion of such terms as 
straight segment, lateral segment and axis should be viewed at this Ixfint as an intuitive link between 
the graph-theoretic formalism and real plant structures. 2.2. Definition of tree L-systems. An essential 
aspect of plant development is the process in which some segments (usually the apices) are transformed 
into more complex structures. We model this process by a graph-rewriting mechanism which operates on 
axial trees. From the viewpoint of graph grammar theory, this is a special case of edge rewriting [15].A 
rewriting rule, or tree production, replaces an edge, specified as the production predeces-sor, by an 
axial tree called the successor, in such a way that the starting node of the predecessor is identified 
with the successor's base and the ending node is identilied with the suecessor's top (Fig. 2). In the 
case of context-free rewriting the label of the replaced edge determines the production to be applied. 
In contrast, a context-sensitive production requires context, or the neighbour edges of the replaced 
edge, to be tested as well. Thus, a predecessor of a context-sensitive pr(xluc- tion p consists of three 
components: a path ! called the left context, an edge S called the strict predecessor, and an axial tree 
r called the right context (Fig. 3). The asymmetry between the left context and the right context reflects 
the fact that there is only one path from the root of a tree to a given edge, while there can be many 
paths from this edge to various terminal nodes. Production p matches a given occurrence of the edge S 
in a tree T if I is a path in T terminating at the starting node of S, and r is a subtree of T originating 
at the ending nede of S. The pro- duction can then be applied by replacing S with the axial tree specified 
as the production successor. A rewriting system can operate either in a sequential or in a paral- lel 
manner. The former type of rewriting is found in Chomsky gram- mars. However, parallel rewriting is more 
appropriate for the modeling of biological development, since development takes place concurrently in 
all parts of the organism. Parallel rewriting systems are. commonly referred to as L-systems. Specifically, 
a tree L-system G is specified by three components: a set of edge labels called the alphabet and denoted 
by V, an axial tree m with labels from V called the axiom, and a set of tree productions P. If for any 
edge label A and any context (l, r) there exists exactly one applica- ble production in P, the L-system 
is deterministic; otherwise it is non- deterministic. Nondeterministic L-systems provide a convenient 
tool for representing general features of a developmental process without consid- ering mechanisms which 
control production selection (Section 4.3). Given an L-system G, an axial tree T2 is directly derived 
from (or generated by) a tree Tl, TroT2, if T 2 is obtained from T I by simultane- ously replacing each 
edge in T1 by its successor according to the pro- duction set P. A tree T is generated by an L-system 
G in a derivation of length n if there exists a developmental sequence of trees To,T 1 ..... T. such 
that T O = 0), T. = T and To-~Ti~-'.~T A (see Section 2.4 for examples).  End T c B A Start n T, T~ 
Figure 2. A tree production p and its application to the edge S in a tree T~. a Right b L~I  Context 
K / J j ii!iiiiiiiiiiliiii~  ~ Strict ~<:::::::~ Predecessor s ~Left A  Context Figure 3. The predecessor 
of a context-sensitive production (a) matches the edge S in a tree T Co). 2.3. Repr~entafion of tree 
L-systems. The definition of a tree L-system docs not specify the data struc- tare for representing axial 
trees. One possibility is to use a list represen- tation with a tree topology. A different representation 
makes use of bracketed strings as introduced by Lindenmayer [24]. In this case, a tree with edge labels 
from alphabet V is represented by a string over alpha- bet V ~ {[, ]}, where the bracket symbols [ and 
] enclose branches. For example, the tree shown in Fig. 3b is represented by the bracketed string: . 
ABC[DE] [SG[HI[JKIL]MNO] (*) A context-free production is denoted A ~ w, where A belongs to V and w 
is a (tmssibly empty) bracketed suing over V. A derivation step from string x = ala 2 . - a n to string 
y = wlw z  w~ is performed by concatenating terms wl,w2 ..... w. obtained from productions with predecessors 
al,a2 ..... a.. The brackets are rewritten into themselves. In the case of a context-sensitive production, 
symbols < and > separate the strict predecessor from the left and fight context, respectively. Since 
the string representation of axial trees does not preserve segment neigh- bourhood, the context matching 
procedure must skip over branches or branch portions when necessary. For example, a production with the 
predecessor BC < S > G[H]M can be applied to symbol S in the string (*) (compare with Fig. 3). 2.4. L-systems 
and control mechanisms in plants. The mechanisms which control plant development in nature can be divided 
into two classes, called lineage and interactive mechanisms. The term lineage refers to the transfer 
of genetic information from an ancestor cell to its descendants. Interaction is a mechanism in which 
information is exchanged between neighboufing cells (for example, in the form of nutrients or hormones). 
Within the formalism of L-systems, lineage mechanisms are represented by context-free productions, while 
interactive mechanisms correspond to context-sensitive productions. Two simple L-systems which simulate 
development controlled by lineage mechanisms are given below. L-system (a) L-system (b) co: S o: A p: 
S ~ S[S]S[S]S Pl: A --) S[A]S[A]A P2: S --> SS  SIGGRAPH '88, Atlanta, August 1-5, 1988 The list of 
attribute symbols can be augmented to contxol color, diameter and length of segments, incorporate predefined 
surfaces and objects in the model, and perform other functions as required. The extensions related to 
organ definition are discussed further in Section 6. Symbols without a specified interpretation are ignored 
by the turtle, which means that they can be used in the derivation process without affecting the interpretation 
of the resulting string. Geometric extensions of L-systems (a) and (e) actually used to generate the 
left-hand structures in Figs. 4 and 5 are given below. L-system (a') L-system (c') ~: S o: J[+fl/[-/y[+fl/ 
p: S ~ S[-'S]S[+'S]S p: J < I ~ J In case (a'), the edge length d is constant, the angle increment 8 
= 27.5 °, and the derivation lengths n are equal to 4 and 5. The auri- bute symbol ' increments the index 
to the color table. In case (e'), d is constant, 8 = 45 ° and n = 0-3. The symbols + and -are ignored 
while context matching. A more complex L-system generating the three-dimensional bush taken from [34] 
and shown in Fig. 7 is given below. ¢o: /la Pt: a ~ [[&#38;sl[a]l/lll'[&#38;sl!a]l/t/I//'[&#38;sl!a]] 
P2: s ----> SI P3: S ----> S/H/Is p,: l ~ ['~{-S+S+S-I-$+S+S]] The attribute symbol t decreases the 
diameter of segments S. The sym- bois a, s and l are not interpreted geometrically. The system operates 
as follows. Production p~ creates three branches from an apex a. A branch consists of a stem s, a leaf 
l and an apex a which will subsequently create three new branches. Productions P2 and P3 specify the 
growth process of a stem; in subsequent derivation steps it gets longer by acquiring new segments S and 
produces new leaves I (in violation of the subapical growth rule, but with an acceptable visual effect 
in a still pic- ture). Production P4 describes the leaf as a filled polygon with six edges (see Section 
6). More examples of completely specified L-systems which generate two-dimensional figures and three-dimensional 
objects are given in [33, 34, 35]. A characteristic feature of turtle interpretation is that directions 
axe relative to the current orientation. However, absolute directions play an important role in the development 
of plants. For example, the axes may bend up towards the source of light, or down due to gravity. We 
simu- late these effects by rotafinng the Imtle slightly in the direction of a predefined tropism vector 
T after drawing each selzment (Fig. 8). The angle a is calculated using the formula a = e if× ~. where 
e is a parameter capturing axis susceptibility to bending. This heuristic for- mula has a physical tutti_ration;if 
T is interpreted as a force applied to the endpoint of segLnent H and H can rotate around its starting 
point, the torque is equal to H x T. A detailed analysis of tree dynamics for simu- lation purposes is 
presented in [41. 4. DEVELOPMENTAL MODELS OF PLANT ARCHITECTURE. In this section we use the formalism 
of L-systems to present developmental models of herbaceous plants on the topological level. The geometric 
aspects are discussed in sections 5 and 6. We put partic- ular emphasis on the modeling of compound flowering 
structures or inflorescences. As there is no commonly accepted terminology referring to inflorescence 
types, we chose to follow the terminology of Ml~ller- Doblies [29], which in turn is based on extensive 
work by Troll [45]. Our presentation is organized by the comrol mechanisms which govern inflorescence 
development. 4.1. Racemes, or the phase beauty of sequential growth. The simplest possible flowering 
structures with multiple flowers are those with a single stem on which an indefinite number of flowers 
are produced sequentially, lnflorescences of this type are called racemes. Their development can he described 
by the following L-system: to: A P1: A ~/o[IoFo]A P2: Ii "-'> Ii+1 i _> 0 P3: Fi -~ F~+1 i _> 0 The 
symbol A denotes the apex of the main (zero-order) axis, li denotes the i-th stage of interuode elongation, 
and F i is the i-th stage of flower development. The indexed notation, such as Fi ~ Fi+l, stands for 
a set of productions F 0 ~ Fi, F i ~ F2, F 2 ~ F3, "  The developmental seqt~ence begins as follows: 
A lo[/oF0]A 11[llF1]lo[loFo]A 12[12Fz]11 [11F1][o[loFo]A 13[13F3]12[12Fz]ll[ltF1]lo[loFo]A At each developmental 
stage, the inflorescence contains a sequence of flowers of different ages. The flowers newly created 
by the apex are delayed in their development with respect to the older ones situated at the stem base. 
This effect is illustrated in Fig. 9, to which the following quotation from d'Arcy Thompson [44] applies: 
A flowering spray of lily-of-the-valley exemplifies a growth-gradient, after a simple fashion of its 
own. Along the stalk the growth-rate falls away; the florets are of des- tending age, from flower to 
bud; their graded differences of age lead to an exquisite gradation of size and form; the time-interval 
between one and another, or the "space-time relation" between them all, gives a peculiar quality -we 
may call it phase-beauty - to the whole. A similar phase effect can be observed in other plants. For 
exam- ple, consider the fern-like structure shown in Fig. 10. In this case, nine zero-order branches 
grow subapically and produce new first-order branches, which also grow suhapically and produce leaves. 
These processes are described by the following L-system: ~: [A][A][A][A][A][A][A][A][A] Pl: A ----> Io[B]A 
P2: B ~/0[Lo][Lo]B P3: li ~ li+l i _> 0 P4: Li ~ Li+l i >_ 0 A and B denote apices of zero-order and 
first-order axes, Io,11,12,... denote the internodes, and Lo,L~,L2,  denote the subsequent stages of 
leaf development. 4.2. Cymose inflorescences, or the use of delays. In racemes the apex of the main 
axis produces lateral branches and continues to grow. In contrast, the apex of the main axis in cymes 
turns to a flower shortly after a few lateral branches have been initiated. Their apices turn into flowers 
as well and second-order branches take over. In time, branches of higher and higher order are produced. 
Thus, the basic structure of a cymose inflorescence is captured in the produc- tion A ~ I[A][A]IF According 
to this de~ription, the two branches are identical and grow in concert. In reality, this need not be 
the case, and one lateral branch may start growing before the other. This effect can be modeled by assuming 
that apices undergo a sequence of state changes which delay their further growth until a particular state 
is reached. For example, the development of the rose campion (Lychnis coronaria) shown in Fig. 11 is 
described by the following L-system: oo: A 7 Pl: A7 ~ Io[Lo][Ld[Ao][Aa]loFo P2: Ai ~ Ai+l O ~_ i < 7 
P3: Xi ~ Xi+l i -> O, X~ {I, L, F} Production pl specifies that, at their creation time, the lateral 
apices have different states A0 and A 4. Production P2 advances the apex states. Thus, the first apex 
requires eight derivation steps to produce a flower and new branches, while the second requires only 
four steps. Con-currently internodes elongate, leaves grow and each flower undergoes a sequence of changes, 
progressing from the bud stage to an open flower to a fruit. These processes are captured in production 
P3. For a further analysis of the above model see [37]. 4.3. Modeling qualitative changes of developmental 
processes. The developmental sequences considered so far are homogeneous in the sense that the same slxucture 
is produced repeatedly at fixed time intervals. However, in many cases a qualitative change in the nature 
of development can be observed at some point in time. For example, con- sider the shepherd's purse (Capsella 
bursa-pastoris) shown in Fig. 12. In principle, its development can be described as follows: co: A Pt: 
A --> Io[Lo]A P2: A ~ to[LoW P3: B ~ lo[[oFo]B P4: Xi ---> Xi+l i ~ O, X~ {1, L, F] The initial vegetative 
growth is represented by production p~ which describes creation of successive internodes and leaves by 
apex A. At some point in time, production P2 changes the apex from the vegetative state A to the flowering 
state B. From then on, flowers are produced instead of leaves (production P3), forming a raceme as discussed 
in Sec- tion 4.1. However, the moment in which this change occurs is not specified; the L-system is a 
nondeterministic one. Thus, for modeling purposes it must be complemented with an additional control 
mechanism which will determine the developmental switch time. Three applicable mechanisms are outlined 
below. Each of them is biologically motivated, and corresponds to a different class of L-systems. 4..3.1, 
A delay mechanism. The apex undergoes a series of state changes which delay the swimh until a particular 
state is reached: o3: A o Pl: A i -->/0[L0]A/+i 0 _< i < n P2: A, ---> Io[Lo]B P3, P4: as before According 
to this model, the apex counts the leaves it produces. While it may seem strange that a plant counts, 
it is known that some plant species produce a fixed number of leaves before they start flowering. 4.3.2. 
A stochastic mechanism. The vegetative apex has a probability nl of staying in the vegetative state, 
and r~ of transforming itself into a flowering apex: o3: A Pl: A ~ "I Io[Lo]A P2: A ~ ~/o[Lo]B P3, P4: 
as before For a formal definition of stochastic L-systems see [8, 46]. 4.3.3. Environmental change. 
Many plants change from a vegetative to a flowering state in response to an environmental factor (such 
as the number of daylight hours or temperature). We can model this effect by using one set of productions 
(called a ruble) for some number of deriva- tion steps before replacing it by another table. Table 1 
co: A Pl: A ~ lo[Lo]A P2: Xl ~ Xi+l i -> O, X~ {I, L} Table 2 P1: A ~ 10[Lo]B P2: B ~ IO[IoFo]B P3: 
Xi ~ Xi+ l i _> O, Xe {L L} The concept of table L-systems is formalized in [28, 38]. The developmental 
switch mechanism can also be applied to transform an apex from producing lateral flowers to producing 
a terminal flower which stops axis development. A raceme with a terminal flower is called a closed raceme, 
in contrast to the open racemes considered so far. 4.4. Inflorescence development with interactions. 
Even in the presence of delays, the phase effects discussed so far reflect the sequential creation of 
branches, flowers and leaves by the subapical growth process. Consequently, organs near the plant roots 
develop earlier and more extensively than those situated near the axis ends. Such development results 
in basitonic plant structures (heavily developed near the base) with acropetal flowering sequences (the 
zone of blooming flowers progresses upwards along each branch). However, nature also creates acrotonic 
structures (heavily developed near the apex) and basipetal flowering sequences (progressing downwards). 
These structures and developmental patterns cannot be viewed as a sim- ple consequence of subapical growth; 
for example, basipetal flowering sequences progress in the direction which is precisely opposite to that 
of plant growth. An intuitively straightforward and biologically wall founded explanation can be given 
in terms of signals (Section 2.4) which propagate through the plant and control the timing of develop- 
mental switches. Below we consider two developmental models with signals. The first model employs a single 
acropetal signal, while the second one uses both acropeml and basipetal signals. 4.4.1. Developmental 
model with a single aeropetal signal. Let us assume that a flower-inducing signal (which represents the 
hormone florigen) stops axis development and causes production of a terminal flower upon reaching the 
apex. In this case, the overall phase effect results from an interplay between growth and control signal 
propa- gation [25, 20]. Assuming that only the first-order lateral branches ale present, the development 
can be described by the following L-system: m: DoAo Pl: Ai ~ Ai+l 0 _< i < m-1 P2: A,,,-1 --> I[Lo][Bo]Ao 
 P3: Bi --> Bi+l 0 _< i < n-I P4: B,,-4 ~ J[Lo]Bo Ps: Di ~ Di+l 0 _< i < d-1 Pr: Dd--~ SO t77: Si ---> 
S/+1 0 -< i < max{u, v} - 1 Ps: S, ~ e z = max{u, v} - I Pg: Su-I < I ~ IS 0 P10: S~-1 < J ~ YSo Pll: 
So < Ai ~ Fo 0 _< i _< m-1 P12: So < Bi --> Fo 0 -< i S n-1 P13: Xi --> Xm i _> 0, Xe {L, F} This L-system 
operates as follows (Fig. 13). The apex A produces seg- ments of the main axis I, (optional) leaves L 
and the lateral apices B (Pb P2)- The time between the production of two consecutive segments of the 
main axis, called its plastochron, is equal to m units (derivation steps). In a similar way, the first-order 
apices B produce segments J of the lateral axes and leaves L with plastochron n (P3, P4). After a delay 
of d time units a signal S is sent from the tree base towards the apices (p~. The signal is Wansported 
along the main axis with a delay of u time units per internode 1 (PT, Pg), and along the first-order 
axes with a delay of v units per internode J (PT, Pro)- Production Ps removes the signal from a node 
after it has been transported further along the slruc- ture (e stands for the empty string). When the 
signal reaches an apex (either A or B), the apex is transformed into a terminal flower F (PH, Pl~. Leaves 
and flowers undergo the usual developmental sequence (P13). In order to analyze the plant structure and 
flowering sequence resulting from the above development, let us denote by tt the time at which the apex 
of the k-th first-order axis is Iransformed into a flower, and by I t the length of this axis (expressed 
as the number of internodes) at the traifsformation time. Since it takes km time units to produce k internodes 
along the main axis and 1~ time units to produce l, inter- nodes on the first-order axis, we obtain tt 
= kra+ltn. On the other hand, the transformation occurs when the signal S reaches the apex. The sig- 
nal is sent d time units after the development starts, uses/at time units to travel through k zero-order 
internodes and ltv time units to travel through Ik first-order internodes, resulting in &#38; = d+ku+lkv. 
Solving the above system of equations for lk and tk (and ignoring for simplicity some inaccuracy due 
to the fact that this system does not guarantee integer solutions), we obtain: &#38;=k un-vm + d n , 
&#38; k m-___y~ + I'l--V n-v II ll--V I'l--V In order to analyze these solutions, let us first notice 
that the signal u'an- sportation delay v must be less than the plastochron of the first-order axes n 
(if this were not the case, the signal would never reach the apices). Under this assumption, the sign 
of the expression A = un-vm determines the flowering sequence, which is acmpetal for A > 0 and basipetal 
for A < 0 (Fig. 13). If A = 0, all flowers occur simultaneously. The sign of the expression m-u determines 
whether the plant has a hasi- tonic (m-u < 0) or acrotohic (m-u > 0) structure. Two stages of the development 
of an aster, modeled using the above L-system with A < 0, are shown in Fig. 14. 4.4.3. Developmental 
model with several signals. The development of some inflorescences is controlled by several signals, 
which may propagate with different delays and lrigger each other. The use of more than one signal is 
instrumental in the modeling of a large class of inflorescences (found, for instance, in the family Compositae) 
characterized by terminal flowers on all apices, indefinite   '~' Computer Graphics, Volume 22, Number 
4, August 1988 order of branching and basipetal flowering sequence. Figure 15 illus- trates this type 
of development with an example of wall lettuce (Mycelis muralis). The underlying L-system operates as 
follows. First, the main axis is formed in a process of subapieal growth which produces subse- quent 
internodes and lateral apices. At this stage further development of lateral branches is suppressed (in 
botany, this effect is known as apical dominance). At some moment a flowering signal $1 is sent from 
the bottom of the inflorescence up along the main axis. When this signal reaches its apex, the terminal 
flower is initiated and a basipetal signal $2 enabling the growth of lateral axes is sent down the main 
axis. After a delay, a secondary basipetal signal $3 is sent from the apex of the main axis. Its effect 
is to send the flowering signal S~ along subsequent first- order axes as they are encountered on the 
way down. This entire pro- cess repeats recursively for each axis: its apex is transformed into a flower, 
the growth of lateral axes of the next order is successively enabled, and the secondary basipetal signal 
is sent to induce the flower- ing signal $1 in these lateral axes. The resulting structure depends heavily 
on the values of plastochrons, delays, and signal propagation times. In the example under consideration, 
signal $2 travels faster than $3. Consequently, the time interval between the arrival of siguals $2 and 
$3 increases while moving down the plant, potentially allowing the lower axes to grow longer then the 
upper ones. On the other hand, the lower branches start developing later, so in younger plants (in the 
middle of Fig. 15) they have not yet reached their full length. A detailed biologi- cal analysis of the 
above developmental pattern is given by Janssen and Lindenmayer [20]. 4~, Adding variation to models. 
All plants generated by a deterministic L-system are identical. An attempt to include them in the same 
picture would produce a striking, artificial regularity. In order to prevent this effect it is necessary 
to introduce specimen-to-specimen variation which preserves the general aspects of a plant while modifying 
its details. We employ stochastic L- systems [8, 46] for this purpose. For example, Fig. 16 presents 
a field consisting of sixteen flowers generated by an L-system in which inter- node elongation is described 
by three stochastic rules: to: A Pt: I ~ ~1 1 P2: [ ~ ~ [1 P3: 1" ~ ~ IiL][LII where the probabilities 
nl, ~2 and n3 ure equal to 1/3. The resulting field appears to consist of various specimens of the same 
(albeit ficti- tious) plant species. For more details on the use of stochastic L-systems for plant modeling 
purposes see [30, 34]. 5. A NOTE ON PHYLLOTAX1S. The longitudinal and angular displacement of consecutive 
branches or appendages with respect to each other is an important attribute of plant form, known as phyllotaxis 
[9, 42, 44]. In terms of the turtle interpretation of axial trees, these parameters represent the segment 
length and the divergence angle corresponding to the turtle's rotation about the heading vector/7. Abstracting 
from the mechanisms which govern the formation of phyllotactic patterns, two situations can be distinguished. 
In alter-hating patterns and whorls the angular positions of branches are repeated after o* a few nodes. 
In these cases, the diver- gence angle is equal to 360°/n, where n is a small integer. This type of arrange- 
ment occurs in lilac (Fig. 17), where consecutive pairs of (n+l)-order axes lie in the planes passing 
through the n-order axis and perpendicular to each other (Fig. lg). The divergence angle of 90 ° is also 
found in the rose campion (Fig. 11). On the other hand, in spiral pat-terns repetition occurs after a 
long period or cannot be detected at all. In these cases, the divergence angle is often close to the 
Fibonacci angle Figure 18. Branch (approximately 137.5°). For examples, arrangement in see shepherd's 
purse (Fig. 12), aster lilac inflorescences. (Fig. 14) and wall lettuce (Fig. 15). 6. MODELING OF ORGANS. 
So fur we have discussed the modeling of "skeletal" trees with branches consisting of mathematical lines. 
In this section we extend the model to include surfaces and volumes. Conceptually, the simplest approach 
is to incorporate predefined surfaces in the tree, with positions and orientations specified by the tur- 
tle. For example, leaves of the lily-of-the-valley (Fig. 9), buds, flowers and fruits of the rose campion 
(Fig. 11), buds, petals and fruits of the aster (Fig. 14) as well as leaves and flowers of the lilac 
(Fig. 17) were modeled using bicubic patches, Bicubic surfaces were also applied to model cylindrical 
stem segments in all these structures. Patches make it easy to manipulate and modify surface shapes interactively, 
but are incompatible with the developmental approach to modeling since they do not "grow". Consequently, 
each developmental stage of an organ must be modeled separately. In order to fully simulate plant development 
and model phase effects present in plant structures, it is necessary to provide a mechanism for changing 
the size and shape of surfaces in time. A simple approach is to fill a polygon made of lines defined 
by an L-system. For example, leaves of the fern (Fig. 10) the shepherd's purse (Fig. 12) and the aster 
(Fig. 14) were modeled using the following L-system: to: L Pl: L ~ {-SX+X+SX-I-SX+X+SX} P2: X ~ SX Production 
Pt defines a leaf as a closed planar polygon. The parentheses { and } indicate that the polygon should 
he filled. Production P2 linearly increases the lengths of the polygon edges. The tracing of polygon 
boundaries leads to acceptable effects in the case of small, fiat surfaces. In other cases it is more 
convenient to define surfaces using an underlying tree structure as the frame. The entire surface consists 
of polygons bounded by tree segments and extra edges inserted between appropriate terminal nodes of the 
tree to form closed contours. The three leaf shapes shown in Fig. 19 were obtained by modifying branching 
angles and growth rates of axes. Specifically, the blade of the cordate leaf (the leftmost one) was generated 
by the fol- lowing L-system: 00: [a][8] Pl: A ~ [+A?]C# P2: B ~ [-B?]C# P3: C ~ IC The axiom contains 
symbols A and B which generate the left-hand side and the right-hand side of the blade. Each of the productions 
Px and P2 creates a sequence of axes starting at the leaf base and gradually diverg- ing from the midrib. 
Prodnetion P3 increases the axis lengths. The axes close to the midrib are the longest since they were 
created first (thus, the leaf shape is yet another manifestation of the phase effect). The sym- bols 
? and # indicate the endpoints of edges to be inserted while forming closed polygons. The following string 
represents the left-hand side of the leaf after four derivation steps: [+[+[+[+A ?]C#?]1C#?]11C#?]111C# 
L.~ L.~ L_./ k__d The arrows indicate the inserted edges (the first one has zero length, the second 
is collinear with an axis, and the subsequent ones bound trian- gles). The developmental sequence is 
shown in Fig. 20. Leaves gen- erated in a similar way were incorporated in the model of the rose cam- 
pion (Fig. 11). The frame-based approach can he extended to three-dimensional organs. The right-hand 
images in Fig. 19 illustrate construction of the flowers for the lily-of-the-valley in Fig. 9. The L-system 
generates a supporting framework composed of five curved lines which spread radi- ally from the flower 
base and are connected by a web of inserted edges. In this ease each polygon is a trapezoid bounded by 
two "regular" and two inserted edges. Another developmental approach to leaf modeling was recently proposed 
by Lienhurdt and Fran~on [23] and Lienhurdt [22]. 7. IMPLEMENTATION. The concepts described in this paper 
were implemented using a modeling program called pfg designed for an IRIS 3130 workstation. The input 
to the program consists of an L-system specified in the brack- eted string notation and approximately 
30 parameters, most of which control rendering and ,viewing. Additionally, an urbitrary number of '~' 
Computer Graphics, Volume 22, Number 4, August 1988 A number of problems are open for further research. 
 Addition of texture. The surfaces shown in this paper lack tex- ture. Specifically, a major component 
of leaf texture is its vena- tion. For consistency with the developmental approach to model- ing, the 
venation itself should be generated by a developmental algorithm. The problem is that veins may form 
closed cycles and therefore cannot be described in terms of axial trees. An exten- sion of tree L-systems 
to graphs with cycles (map L-systems) was proposed by Lindenmayer [26, 27] bnt has not been applied yet 
to model venation.  Improved surface models. The described model of surface development is difficult 
to apply to complex three-dimensional surfaces, such as snap-dragon flowers or wrinkled petals of petunias. 
A difficult situation also occurs when organs composing a larger structure are crowded, for example cabbage 
leaves, or the petals in rose and peonia flowers. More flexible developmental surface models would be 
very useful in these cases.  Time step control. The formalism of L-systems is discrete in nature. A 
developmental model can be const;ucted assuming longer or shorter time intervals, but once the choice 
has been made, the time step is a part of the model and cannot be changed easily. From the viewpoint 
of computer animation it would be preferable if the time step were controlled by a single parameter, 
deconpled from the underlying L-system.  Analysis of simulation complexity. Various data structures 
can be used to represent axial trees and carry out the derivation pro- cess (Section 2.3). Although bracketed 
strings appear to be more memory-efficient than list representations, no formal analysis of time and 
space trade-offs related to the choice of data structure has been made. Such analysis could lead to optimal 
algorithms.  Addition of a graphical interface. In the present implementation of the pfg program, input 
L-systems are specified in the bracketed string notation. In some applications, such as computer-assisted 
inslruction of developmental morphology, it may be preferable to avoid the textual interface and define 
productions graphically, as shown in Fig. 2a. The formalism of lree L-systems, which disso- ciates the 
grapb-theoretie concept from the sUing implementation, could lend itself to such an interface.  ACKNOWLEDGMENTS 
The aster flowers were modeled by Debbie Fowler. The generous support from the Department of Computer 
Science, University of Regina, and the Natural Sciences and Engineering Research Council of Canada is 
gratefully acknowledged. REFERENCES 1. Abelson, H., and diSessa, A. A. Turtle geometry. M.I.T. Press, 
Cambridge (1982). 2. Aono, M., and Kunii, T. L. Botanical tree image generation. IEEE Computer Graphics 
and Applications 4, 5 (1984), 10-34. 3. Aono, M., and Kunii, T. L. Botanical tree image generation. 
[Video tape], IBM, Tokyo (1985). 4. Armstrong, W. W. The dynamics of tree linkages with a fixed root 
link and limited range of rotation. Actes du Colloque later- nationale rlmaginaire Num~rique '86 (1986), 
16-21. 5. Baker, R., and Herman, G. T. Simulation of organisms using a developmental model, Parts I 
and II. Int. J. of Bio-Medical Com-puting 3 (1972), 201-215 and 251-267. 6. Beyer, T., and Friedell, 
M. Generative scene modelling. Proceed-ings of EUROGRAPHICS '87 (1987), 151-158 and 57I. 7. Bloomenthal, 
I. Modeling the Mighty Maple. Proceedings of SIC- GRAPH '85 (San Francisco, CA, 1uly 22-26, 1985). In 
Computer Graphics 19, 3 (1985), 305-311. 8. Eiehhorst, P., and Savit~h, W. I. Growth functions of stochastic 
Lindenmayer systems. Inf. and Control 45 (1980), 217-228. 9. Erickson, R. O. The geometry of phyllotaxis. 
In J. E. Dale and  F. L. Milthrope (Eds.): The growth and functioning of leaves, Cambridge University 
Press (1983), 53-88. 10. Eyrolles, G. Synth~se d'images figuratives d'arbres par des rn~thodes combinatoires. 
Ph.D. Thesis, Universit6 de Bordeaux I 0986). 11. Frijters, D., and Lindenmayer, A. A model for the growth 
and llowering of Aster novae.angliae on the basis of table (1, 0) L- systems. In G. Rozenberg and A. 
Salomaa (Eds.): L Systems, Lecture Notes in Computer Science 15, Springer-Verlag, Berlin (1974), 24-52. 
 12. Frijters, D., and Lindenmayer, A. Developmental descriptions of branching patterns with paracladlal 
relationships. In A. Linden- mayer and G. Rozenberg (Eds.): Automata, languages, develop- ment, North-Holland, 
Amsterdam (1976), 57-73. 13. Frijters, D. Principles of simulation of inflorescence development. Annals 
of Botany 42 (1978), 549-560.  14. Frijters, D. Mechanisms of developmental integration of Aster novae-angliae 
L., and Hieracium murorum L. Annals of Botany 42 (1978), 561-575. 15. Habel, A., and Kreowski, H.-J. 
On context-free graph languages generated by edge replacement. In H. Ehrig, et al. (Eds.): Graph grammars 
and their application to computer science; Second lnt. Workshop, Lecture Notes in Computer Science 153, 
Springer= Verlag, Berfin (1983), 143-158. 16. Hall6, F., Oldeman, R., and Tomlinson, P. Tropical trees 
and forests: an architectural analysis. Springer-Verlag, Berlin (1978). 17. Herman, G. T., and Liu, 
W. H. The daughter of CELIA, the French flag, and the firing squad. Simulation 21 (1973), 33..41.  Ig. 
Herman, G. T., and Rozenberg, G. Developmental systems and languages. North-Holland, Amsterdam (1975). 
19. Hogeweg, P., and Hesper, B. A model study on biomorphological description. Pattern Recognition 6 
(1974), 165-179. 20. Janssen, L M., and Lindenmayer, A. Models for the control of branch positions and 
flowering sequences of capitula in Mycelis muralis (L.) Dumont (Compositae). New Phytologist 10J (1987), 
191-220. 21. Kawaguchi, Y. A morphological study of the form of nature. Proceedings of SIGGRAPH '82 
(July 1982). In Computer Graph- ics 16, 3 (1982), 223-232. 22. Lienhardt, P. ModMisation et bvolution 
de surfaces libres. Ph.D. Thesis, Universit6 Louis Pasteur, Strasbourg (1987). 23. Lienhardt, P., and 
Franc.on, J. Synth~ese d'images de feuilles v~g~tales. Technical Report R-87-1, Drpartement d'informatique, 
Universit6 Louis Pasteur, Strasbourg (1987). 24. Lindenmayer, A. Mathematical models for cellular interaction 
in development, Parts I and II. J. Theor. Biol. 18 (1968), 280-315. 25. Lindenmayer, A. Positional and 
temporal control mechanisms in inflorescence development. In P. W. Barlow and D. J. Carr (Eds.): Positional 
controls in plant development, Cambridge University Press (1984). 26. Lindenmayer, A. Models for multicellular 
development: charac- terization, inference and complexity of L-systems. In A. Kelmenov[t and L Kelmen 
(Eds.): Trends, techniques and prob- lems in theoretical computer science. Lecture Notes in Computer 
Science 281, Springer-Verlag, Berlin (1987), 138-168. 27. Lindenmayer, A. An introduction to parallel 
map generating sys- tems. In H. Ehrig, et al. (Eds.): Graph grammars and their appli- cation to computer 
science; Third Int. Workshop, Lecture Notes in Computer Science 291, Springer-Verlag, Berlin (1987), 
27-40. 28. Lindenmayer, A., and Prusinkiewicz, P. Developmental models of multi-cellular organisms: 
A computer graphics perspective. Paper submitted to the Proceedings of the ArtOicial Life Workshop held 
in Los Alames, NM, September 1987, 29. Mllller-Doblies D., and U. Cautious impmvemant of a descriptive 
terminology of inflorescences. Monocot newsletter 4, Institut ftir Biologic, Technical University of 
Berlin (Wes0, 13 (1987). 30. Nishida, T. KOL-systems simulating almost but not exactly the same development 
-the case of Japanese cypress. Memoirs Fac. $ci., Kyoto University, Ser. Bio. 8 (1980), 97-122. 31. 
Oppenheimer, P. Real time design and animation of fractal plants and trees. Proceedings of SIGGRAPH "86 
(Dallas, Texas, August 18-22, 1985). In Computer Graphics 20, 4 (1986), 55-64. 32. Preparata F. P., 
and Yeh, R. T. Introduction to discrete structures. Addison=Wesley, Reading (1973). 33. Prusinkiewicz, 
P. Graphical applications of L-systems. Proc. of Graphics Interface '86 - Vision Interface '86 (1986), 
247-253.  I III I II I1 I 34. Prusinklewicz, P. Applications of L-systems to computer imagery. In I-L 
Ehrlg, et al. (Eds.): Graph grammars and their application to computer science; Third lnt. Workshop, 
Lecture Notes in Com- puter Science 291, Springer-Verlag, Berlin (1987), 534-548. 35. Prusinkiewicz, 
P., and Hanan, J. Lindenmayer systems, fmctals, and plants. In D. Sanpe (Ed.): Fractals: Introduction, 
basics and applications. [Course notes] SIGGRAPH '88 (Atlanta, Georgia, August 1-5, 1988). 36. Reeves, 
W. T., and Blau, R. Approximate and probabilistic algo- rithms for shading and rendering structured particle 
systems. Proceedings of SIGGRAPH '85 (San Francisco, CA, July 22-26, 1985). In Computer Graphics 19, 
3 (1985), 313-322. 37. Robinson, D. F. A symbolic notation for the growth of inflorescences. New Phytologist 
103 (1986), 587-596. 38. Rozenberg, G., and Salomaa, A. The mathematical theory of L- systems. Academic 
Press, New York (1980). 39. Smith, A. R. About the cover: "Reeonfigurable machines". Com-puter 11, 7 
(1978), 3-4. 40. Smith, A. R. Plants, fractals, and formal languages. Proceedings of SIGGRAPH '84 (Minneapolis, 
Minnesota, July 23-27, 1984). Computer Graphics 18, 3 (1984), 1-10. 41. Smith, A. R. Grammars for generating 
the complexity of reality. [Video tape], Lucasfilm/PIXAR, San Rafael (1985). 42. Stevens, P. S. Patterns 
in nature. Little, Brown and Co., Boston (1974). 43. Szilard, A. L., and Quinton, R. E. An interpretation 
for DOL sys- tems by computer graphics. The Science Terrapin 4 (1979), 8-13. 44. Thompson, d'Arcy. On 
growth and form. University Press. Cam- bridge (1952). 45. Troll, W. Die lnfloreszenzen, Vol. I. Gustav 
Fischer Vcriag, Stuttgart (1964). 46. Yokomori, T. Stochastic characterizations of E0L languages. Information 
and Control 45 (1980), 26-33. 47. Zimmerman, M. H., and Brown, C. L. Trees - structure andfanc- tion. 
Springer-Verlag, Berlin (1971).  [50  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378505</article_id>
		<sort_key>151</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Plant models faithful to botanical structure and development]]></title>
		<page_from>151</page_from>
		<page_to>158</page_to>
		<doi_number>10.1145/54852.378505</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378505</url>
		<abstract>
			<par><![CDATA[Some very impressive results have been obtained in the past few years in plants and trees image synthesis. Some algorithms are largely based on the irregularity and fuzziness of the objects, and use fractals, graftals or particle systems. Others focus on the branching pattern of the trees with emphasis on morphology. Our concern here is the faithfulness of the models to the botanical nature of trees and plants. We present a model which integrates botanical knowledge of the architecture of the trees: how they grow, how they occupy space, where and how leaves, flowers or fruits are located, etc. The very first interest of the model we propose is its great richness: the same procedural methods can produce "plants" as different as weeping willows, fir trees, cedar trees, frangipani trees, poplars, pine trees, wild cherry trees, herbs, etc. Another very important benefit one can derive from the model is the integration of time which enables viewing the aging of a tree (possibility to get different pictures of the same tree at different ages, accurate simulation of the death of leaves and branches for example). The ease to integrate physical parameters such as wind, the incidence of factors such as insects attacks, use of fertilizers, plantation density, and so on makes it a useful tool for agronomy or botany.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[botany]]></kw>
			<kw><![CDATA[database amplification]]></kw>
			<kw><![CDATA[growth simulation]]></kw>
			<kw><![CDATA[plant]]></kw>
			<kw><![CDATA[tree]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P335049</person_id>
				<author_profile_id><![CDATA[81100268444]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Phillippe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[de Reffye]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Centre de Coop&#233;ration Internationale en Recherche Agronomique pour le D&#233;veloppement, BP 5035, 34032 Montpellier C&#233;dex, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334670</person_id>
				<author_profile_id><![CDATA[81387605390]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Claude]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Edelin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institut de Botanique, Universit&#233; des Sciences et Techniques du Langudoc, 163, Rue Auguste Broussonnet, 34000 Montpellier, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P136110</person_id>
				<author_profile_id><![CDATA[81100598628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fran&#231;on]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[D&#233;partament d'Informatique, Universit&#233; Louis Pasteur, 7 Rue Ren&#233; Descartes, 67084 Strasbourg C&#233;dex, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14224346</person_id>
				<author_profile_id><![CDATA[81100654846]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jaeger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Centre de Coop&#233;ration Internationale en Recherche Agronomique pour le D&#233;veloppement, BP 5035, 34032 Montpellier C&#233;dex, FRANCE and D&#233;partament d'Informatique, Universit&#233; Louis Pasteur, 7 Rue Ren&#233; Descartes, 67084 Strasbourg C&#233;dex, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31024721</person_id>
				<author_profile_id><![CDATA[81100047435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Claude]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Puech]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Laboratoire d'Informatique, Ecole Normale Sup&#233;rieure, 45 Rue d'Ulm, 75230 Paris C&#233;dex 05, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aono M., Kunii T. L., "Botanical Tree Image Generation" IEEE Computer Graphics and Applications, vol. 4, No 5, 1984, pp. 10-33.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bell A., "Computerized Vegetative Mobility in rhizomatous plants", in Automata, Languages, Development, Lindenmayer A. &amp; Rozenberg G. (Eds.), North-Holland, 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325249</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal I., "Modeling the Mighty Maple", Computer Graphics, vol. 19, No. 3, 1985, pp. 305-311.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Edelin C., Larchitecture Monopodiale: l'Exemple de Quelques Arbres d'Asie Tropicale. These de Doctorat es Sciences, Universite des Sciences et des Techniques du Languedoc, Montpellier, France, 1984.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Eyrolles G., Francon J., Viennot G., "Combinatoire pour la Synthese d'Images Realistes de Plantes", Actes du Deuxieme Colloque Image, CESTA, 1986, pp. 648-652.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fischer J. B., Honda H., "Computer Simulation of Branching Pattern and Geometry in Terminalia (Combretaceae), a Tropical Tree", 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fournier A., "Prolegomenon", Unpublished course notes, Fournier A. ed., The Modeling of Natural Phenomena (SIGGRAPH'87 course notes #16, Anaheim, CA, July 1987) pp. 3-37.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>697933</ref_obj_id>
				<ref_obj_pid>646593</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Frijters D., Lindenmayer A., "A Model for the Growth and Flowering of Aster Novae-Anglia on the Basis of Table (0,1)-Systems", in L-Systems, Rozenberg G., Salomaa A. (Eds.), LNCS, 15, Springer-Verlag, Berlin, 1974, pp. 24-52.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Halle, Oldeman, Tomlinson, Tropical Trees and Forest: an Architectural Analysis, Springer-Verlag, Berlin/Heidelberg/New-York, 1978.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Jaeger M., Reprdsentation et Simulation de Croissance de V(gdtaux, These de Doctorat, Universite Louis Pasteur, Strasbourg, France, Dec. 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801284</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kawaguchi Y., "A Morphological Study of the Form of Nature", Computer Graphics, vol. 16, No. 3, 1982, pp. 223-232.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lienhardt P., "Free-form Surfaces Modeling by Evolution Simulation", to appear, Proceedings Eurographics'88.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lindenmayer A., "Paracladial Systems", in Automata, Languages, Development (Lindenmayer A., Rozenberg G. Editors), North-Holland Publishing Company, Amsterdam/New-York/Oxford, 1976.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[L~ck, "Elementary Behavioural Rules as Foundation for Morphogenesis", J. Theor. Biol., 54, 1975, pp. 23-24.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Oidemann R.A.A., "L'architecture de la Foret Guyanaise", Memoire 73, ORSTOM, 1974.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer P. E., "Real Time Design and Animation of Fractal Plants and Trees", Computer Graphics, vol 20, No. 4, 1986, pp. 55-64.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>730363</ref_obj_id>
				<ref_obj_pid>647560</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz P., "Applications of L-systems to Computer Imagery", in Proceedings of the Third Workshop on Graph Grammars and their Applications to Computer Science, Warrenton, Dec. 1986, pp. 534-548.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Reeves W. T., Blau R., "Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems", Computer Graphics, vol. 19, No. 3, 1985, pp. 313-322.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Reffye (de) P., Modrlisation de l'Architecture des Arbres Tropicaux par des Processus Stochastiques, These de Doctorates Sciences, Universite de Paris-Sud, Orsay, France, 1979.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Reffye (de) P., "Moddle Mathrmatique Alratoire et Simulation de la Croissance et de rArchitecture du Cafrier Robusta", Premiere partie, Cafd-Cacao-Thd, vol. 25, No. 2,1981, pp. 83-104. Deuxieme pattie, Cafd-Cacao-Thr, vol. 25, No. 4, 1981, pp. 219-230. Troisieme partie, Cafd-Caeao-Thd, vol. 26, No. 2, 1982, pp. 77-96. Quatribme pattie, Cafd-Cacao-Thr, vol. 27, No. 1, 1983, pp. 3-20.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Reffye (de) P., Edelin C., Jaeger M., Cabart C., "Modelisation de l'Architecture des Arbres", in Proc. Int. Conf. "The tree", Montpellier, Sept. 85.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Rouane, "Un Modele de la Ramification de la Croissance Vegetale en tant qu'Image de la Differentiation Cellulaire", Comptes-Rendus de l'Academic des Sciences, Paris, T. 285, 26, Sept. 1977.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Smith A. R., "Plants, Fractals and Formal Languages", Computer Graphics, vol. 18, No. 3, 1984, pp. 1-10.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Smith A. R., Unpublished course notes, Fournier A. ed., The Modeling of Natural Phenomena (SIGGRAPH'87 course notes #16, Anaheim, CA, July 1987).]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Stoker J.J., Nonlinear Elasticity, Gordon et Breach, New York, NY, 1968.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~l~ Computer Graphics, Volume 22, Number 4, August 1988 Plant Models Faithful to Botanical Structure 
and Development Philippe de Reffye 1 , Claude Edelin 2, Jean Fran¢on 3, Marc Jaegerl, 3 , Claude Puech 
4 1. CIRAD, Montpellier, FRANCE. 2. Institut de Botanique, USTL, Montpellier, FRANCE. 3. DqSpartement 
d'Informatique, Universit6 Louis Pasteur, Strasbourg, FRANCE. 4. Laboratoire d'Informatique, Ecole Normale 
Su~rieure, Paris, FRANCE. Abstract: Some very impressive results have been obtained in the past few years 
in plants and trees image synthesis. Some algorithms are largely based on the irregularity and fuzziness 
of the objects, and use fractals, graftals or particle systems. Others focus on the branching pattern 
of the trees with emphasis on morphology. Our concern here is the faithfulness of the models to the botanical 
nature of trees and plants. We present a model which integrates botanical knowledge of the architecture 
of the trees: how they grow, how they occupy space, where and how leaves,flowers or fruits are located, 
etc. The very first interest of the model we propose is its great richness: the same procedural methods 
can produce "plants" as different as weeping willows, fir trees, cedar trees, frangipani trees, poplars, 
pine trees, wild cherry trees, herbs, etc. Another very important benefit one can deriw from the model 
is the integration of time which enables viewing the aging of a tree (possibility to get different pictures 
of the same tree at different ages, accurate simulation of the death of leaves and branches for example). 
The ease to integrate physical parameters such as wind, the incidence of factors such as insects attacks, 
use of fertilizers, plantation density, and so on makes it a useful tool for agronomy or botany. CR Categories 
and Subject Descriptors: 1.3.5 [Computer Graphics]: Computational Gemetry and Object Modeling; 1.3.7 
[Computer Graphics]: Three-Dimensional Graphics and Realism; 1.6.3 [Simulation and Modelingl: Applications; 
J.3 [Life and Medical Sciences] Biology. General Terms: Trees, Models, Algorithms. Additional Keywords 
and Phrases: plant, tree, botany, growth simulation, database amplification. l. Centre de Cool,ration 
Internationale en Recherche Agronomique pour le Dtveloppement, BP 5035, 34032 Montpellier Ctdex, FRANCE 
- Tel.: (33) 67 61 58 O0 2. Irtstitut de Botanique, Universit6 des Sciences et Techniques du Langudoc, 
163, Rue Augusta Broussonnet, 34000 Montpelliex, FRANCE - Tel.: (33) 67 63 17 93 3. Dtpartament d*l_rfformatique, 
Urdversit6 Louis Pasteur, 7 Rue Rent Descartes, 67084 Stxasbourg Ctdex, FRANCE - Tel.: (33) 88 41 63 
00 4. Laboratoire d'Informatique, Eeole Normale Suptrieure, 45 Rue d'Ulm, 75230 Paris C~dex 05, FRANCE 
- Tel.: (33) (l) 43 29 12 25 - e-mail: puech@frulm63 (hither), pueeh@ens.enz.fr (uucp)  Permission to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM-0-89791-275-6/88/008/0151 
$00.75 1. Introduction. The past few years have seen much effort devoted to image generation of natural 
phenomena by procedural methods. In this context, our interest lies in the generation of trees and plants 
images. Some very impressive results have already been obtained, using particular branching patterns 
(Kawaguchi [11], Aono and Kunii [1]), graftals (Smith [23]), particle systems (Reeves and Blau [18]), 
fractals (Oppenheimer [16]), extensions of graftals (Prusinkiewicz [17]) or combinatorics of trees (Eyrolles, 
Fran~on and Viennot [5]). Our concern here is to produce images of plants and trees which should be faithful 
to their botanical nature and so to build a model which should include the known botanical laws which 
explain plants' growth and architecture. Such a concern is shared by Aono and Kunii in [1] but their 
study is limited to the cases of monopodial, dichotomic or ternary branching patterns which prove to 
be insufficient for the representation of a rich variety of plants and trees. In [7], Fournier proposed 
a taxonomy for the modelling of natural phenomena, categorizing the different models as empirical, purely 
physical, morphological, structural, impressionistic or self-models. As he noted in his course notes, 
our approach can be seen as a structural model; it can also be seen as a kind of physical model with 
botanical laws instead of physical ones as our approach integrates as much "knowledge" about the plant 
and its environment as possible: age of the plant, growing conditions, physics of the branches (for example, 
in our approach branches are bent by gravity or wind strength as opposed to their simulation by inhibitom 
and attractors by Aono and Kunii [1]). From a botanical standpoint, the growth of plants has been studied 
by several authors. An extensive bibliography can be found in [24] and [17]. A "macroscopic" study of 
plant shapes more directly related to their "architecture" can be found in Fischer and Honda's paper 
([6]) in the case of Terminalia; their work has been taken into account for image synthesis by Aono and 
Kunii [1]. A macroscopic approach can also be found in one of the authors' thesis (De Reffye [19]) where 
the mathematical model is applied to the simulation of the growth of the coffee-tree. The model has been 
enriched since and its domain of relevance widely enlarged; the aim of the present paper is to present 
its potential consequences in image synthesis of trees and plants. As we want to emphasize here the topologic, 
not geometric model, its functioning and relation to the botanical and physical reality, we will not 
deal in this paper with important but somewhat different problems related to the graphical aspect of 
the image such as the smoothing of the limbs, the precise shape of the trunk, the rendering of the bark's 
texture, etc. These problems have been studied in the case of the maple tree by Bloomenthal ([3]). The 
general idea of the method is to model the activity of buds at dicretized times: a bud, at a given clock 
signal can -either become a flower and die (and disappear), - or go into sleep (pause, break), - or become 
a so called internode at the extremity of which one or several leaves appear with new so called lateral 
buds at their axil and a new so called apical bud at the end of the internode, - or die (and disappear). 
These events occur accordingto specific stochastic laws characteristic for each variety and each species. 
The geometric parameters, such as the length and diameter of an internode or the branching angles are 
also calculated according to specific stochastic characteristic laws.  SIGGRAPH '88, Atlanta, August 
1-5, 1988 These simulations rely on recent work on plant architecture. The plan of the paper is as follows. 
In section 2, we give several simplified notions from botany on which the stochastic growth model explained 
in section 3 is founded. In section 4, we deal with the method used to simulate the growth of plants, 
and in section 5 we show how the model can be used to simulate other phenomena. The next section explains 
how the visualization is done and the last section gives results and conclusions. 2. A few simplified 
notions from Botany The growth of a plant is the result of the evolution of some specific cellular tissues 
(internal part of the bud), the so called meristems. A bud can, at a given time, die (abort), and it 
will not produce anything any longer, or it can give birth to a flower, or an inflorescence (and then 
the bud dies) or to an internode. apical bud node -leaf internode axiilary bud Figure 1: The leaves'axis. 
 The leaves' aMs is the fundamental element of the architectural approach. It is the result of the activity 
of the bud situated at its tip, which is called the apical bud. It is made of a series of internodes; 
an internode is a (part of a) stem made of a ligneous material at the tip of which one can find one or 
several leaves. An internode's length can be very short (around 1 mm) in the case of some plants such 
as the fir tree, but can also measure up to several tenth of cms in the case of bamboo. Between two internodes 
there is a node which bears leaves and buds; each node bears at least one leaf (it is the symptom of 
the existence of a node); at each leafs axil, one finds a so-called axillary bud. These notions are illustrated 
on Figure 1. An axillary stem can either grow immediately (sylleptic ramification) or with some delay 
(proleptic ramification). The growth of the leaves' axes of a plant is the result of the evolution of 
their apical buds. A central notion for the model is the notion of growth ,~.-~ ~:..~~ order 3 ~xis ,,~v 
' ~'~., .- --"k' k ]~ / . . order 2 axis Figure 2: The notion of order of an axis. unit which is a 
sequence of intemodes and nodes produced (usually in a very short period of time) by the apical bud of 
the previous node. We will distinguish between two cases: short growth units with few intemodes (one 
sometimes) and long growth units which are made of numerous internodes (each of which is usually short), 
Another important notion is the notion of the order of an axis (see Figure 2). The order 1 axis of a 
plant is the sequence of growth units such that each of these growth units is born of the apical bud 
of the previous one, and such that the first one of the axis is grown out of the seed of the plant. An 
order i axis, for/>/, is a sequence of growth units such that the first internode of the sequence is 
born of an axillary bud on an order i-I axis, called the bearing axis. In the absence of traumatisms, 
the relative position of the lateral buds (and, as a consequence of the leaves) of a node with respect 
to the lateral buds of the previous node follow regular laws known for each variety of each species and 
each order; this phenomenon is called phyllotaxy. The spiraled and distic cases are illustrated on Figure 
3. UOU   ,=, %%% Figure 3: Phyllotaxy: (I) spiraled, (II) distic. As regards the ramification process, 
in a growth unit, one can encounter (see Figure 4): -continuous ramification: every node of an axis is 
the root of an axis of greater order, -rhythmic ramification: some nodes (but not all of them) are the 
root of an axis of greater order, or -diffuse ramification: the nodes forming roots of an axis of greater 
order are located at random. These kinds of ramifications are functions of the order of the axis for 
a given variety and species. A monopod is a ramified system which includes a unique number I axis and 
a finite number of axes of higher order; if the orders go up to k (included), the monopod is said an 
order k rnonopod. Figure 4: Ramification ([) continuous, (II) rhythmic The geomelric txend of an axis 
with respect to its bearing axis is also an important parameter; it is characterized usually by a general 
trend. If the latter is horizontal the development is said plagiotropic, if it is vertical it is said 
orthotropic (see Figure 15). An order 1 axis is usually orthotropic. The trend frequently effects the 
phyltotaxy: orthotropy is usually associated with a spiraled phyllotaxy whereas plagiotropy is associated 
with distic phyllotaxy. Some plants do not grow as monopods: when the apical bud of an order i axis dies, 
some axillary buds of the previous node produce an axis whose behaviour is of an order i instead of i+1 
axis. Such a behaviour is called sympodial growth. A similar phenomenon can be observed after the pruning 
of a tree (see figure 5 and Photo 2). The observed phenomenon is called traumatic reiteration. Another 
phenomenon alters the shape of "old" trees; it is called reiteration (see [4], [15]). It accounts for 
the following behaviour: an axillary bud can ~ Computer Graphics, Volume 22, Number 4, August 1988 produce 
an axis which behaves as an order 1 axis (a new "young" tree) or, in a few cases as an axis of greater 
order. These are "natural" occurences of recursion! Reiteration is still very badly understood from a 
botanical point of view and will be ignored here except in the case of traumatic reiteration. !J Figure 
5: Traumatic reiteration. Tree architecture has been studied rather recently from a scientific point 
of view, in a systematic way. Botanists HallE, Oldeman and Tomlinson ([9]) studied the growth of tropical 
trees and sifted out the notion of architectural model, which can be seen as a growth strategy to occupy 
space. A surprisingly large variety of plants and trees grow and build their shape in the same kind of 
way, although the results seem very different from one to another. Altogether, there are only 23 different 
architectural types, called architectural models. The classification relies mainly on the presence/absence 
of sympodial growth, on ramification, continuous growth or not, and development trend (plagiotropy/orthotropy). 
Let us describe briefly four of these, among the most frequently encountered: Figure 6: Comer model. 
-in Corner's model (see Figure 6), there is one order 1 axis and no ramification at all. These plants 
arc monopods; examples include coconut trees (see Photo 8) and date palm trees (see Figure 16). Figure 
7: Leeuwenberg model. - in Leeuwenberg's model (see Figure 7), the apical buds systematically die after 
one growth unit so that the growth is sympodial; examples include the frangipani tree (see Photo 13) 
and the mistletoe. - in Massart's model (see Figure 8). the order 1 axis is orthotropic, the other ones 
are plagiotropic. These plants are monopods with a rhythmic ramification growth; examples include fir 
trees (Photo 1), spruce trees and cedar trees (Photo 10).  - in Rauh's model (see Figure 9), every axis 
is orthotropic. These plants are monopods with a rhythmic ramification growth; examples include poplar 
trees (Photo 4), aspen trees (Photo 3), pine trees (Photo 5) and fruit trees of temperate regions (photos 
6, 7 and 9). , ¢., Figure 8: Massart model. Figure 9: Rauh model. To end this botany section, let us 
mention that the same architectural concepts are relevant to other botanical phenomena: the rhizome of 
some herbs can be considered as an underground monopod; an inflorescence can be viewed as a monopod whose 
apical buds are replaced by flowers. This will be used in section 4 for simulation purposes. 3. The growth 
model. Our approach is based on a mathematical simulation of botanical .~chitectural models which originated 
in Philippe de Reffye's thesis [19]. It is based on a botanically accurate simulation of the functioning 
of meristems. Although related botanical studies are of a qualitative nature, the proposed model is quantitative. 
In this section, we will ignore the sexual organs of the plants (flowers and inflorescences). As shown 
by botanical studies, three important phenomena characterize the functioning of meristems: -growth, -ramification, 
-mortality. They heavily depend on time so that models of plant architectures have to integrate time 
in growth, ramification and mortality processes. In de Reffye's mathematical macroscopic model of plants' 
growth, the unit of discretized time is the time taken by the growth of a growth unit, this length of 
time being supposed constant for the axes a given order of a given plant As a consequence, axes of different 
order of the same plant can grow with different speeds (see Figure 14). Moreover, each bud is given two 
probabilities (stochastic parameters of the model): its probability to abort, and its probability to 
make a break, i.e. to wait during a unit of time without growing (if it is not dead). The "non-abort" 
probability of an axillary bud is, in fact, a ramification probability, that is the probability of birth 
of an axiUary stem which is the start of a new axis. Let us call the age of a node or a bud its date 
of birth according to the clock of the model, with time 0 being the time when the seed begins to grow; 
the dimension of a node or a bud is its age relative to the birthday of its axis. We will give now several 
examples of the functioning of the model, starting with a very trivial one. Example 0: Let us draw a 
growth unit as a straight segment and suppose that the seed has produced a growth unit at time 1. Then, 
at time 2, if the break and death probabilities are different from 0, the 3 cases depicted on #SIGGRAPH 
'88, Atlanta, August 1-5, 1988 Figure 10 can occur. I   1 I I dead break two growth units Figure 10: 
Growth model. Example O. To explain the branching process, let us recall that at each node two types 
of axillary buds can appear. Those which correspond to "standard" branching can give birth to an new 
axis of greater (by one) order; reiteration buds give birth to a reiteration. Moreover, these axillary 
buds become visible only if the apical bud is not dead or in a break phase. The number of buds of each 
type can be calculated by using a probability law called the branching law, but is usually constant for 
axes of a given order of a given plant (in our simulations). With very straightforward hypotheses on 
the probabilities involved, a few simulations can be easily done. Let us suppose, for example, that the 
maximum order is 3 (this can be obtained when the ramification probability of axillary buds on order 
3 axes is equal to 0, or when the buds on order 4 axes die systematically). With one axillary bud on 
the last node of each growth unit, with no axillary bud elsewhere, with the standard ramification probability 
equal to 1 and with growth speed identical on every axis, one can obtain the results of examples 1 to 
4 (the geometry is very straightforward) below. Example 1 (see Figure 11): break and death probabilities 
equal to 0. Example 2 (see Figure 12): break probability equal to 0, death probabilities different from 
0. Example 3 (see Figure 13): death probability equal to 0, break probability equal to 0 on order I axis, 
different from 0 and large on the other axes. [/ ( ( I 3 4 5 Figure 11: Growth model. Example 1 (age 
1, 2, 3, 4, 5). I I I 2 3 4 5 Figure 12: Growth model. Example 2 (age 1, 2, 3, 4, 5). I \1  I I \\} 
I I/ [/ I/ I I I 1 I 6 2 3 4 5 Figure 13: Growth model. Example 3 (age 1, 2, 3, 4, 5, 6). Example 4: 
order 1 and 2 axes only, one internode per growth unit, 2 axillary buds per node on axis 1, distie phyllotaxy, 
death probability equal to 0, break probability equal to 0 on order I axis, different from 0 on order 
2 axes, growth speed ratio (order 1 axis over order 2 axis) equal to r. For ages around 20 units of time 
on the order I axis, with a geometry similar to that of the robusta coffee tree, and fall of the leaves 
simulated, the architectures shown on Figure 14 can be obtained. Figure 14: Growth of order I and order 
2 axes, with growth ratio r (with break). In the growth model, it is supposed that the probabilities 
are only functions of the age, dimension and order of the bud, for a given variety and species. It has 
been proved experimentally, for example, that the mortality of an apical bud is a monotonic increasing 
function of its dimension for a given order. As another example, the probability for a bud to make a 
break can be chosen as a monotonic increasing function of age, for a given order. For image synthesis 
purposes these hypotheses prove to be sufficient (even 0 and 1 probabilities produce a wide variety of 
forms). For a greater fidelity to botany, one has to take into account the dependence on other parameters 
such as the number of nodes in a growth unit. All the probability laws involved can be measured experimentally; 
this has been done in several cases (for example the coffee-tree) for agronomic purposes, and the measures 
validate the model (cf. [20]). Moreover, with different choices of the probability laws, one can obtain 
the architectural types of HallE, Oldeman and Tomlinson's classification. 4. Growth simulation. Computer 
simulation of the growth of plants according to our model is possible as the model is a numerical one. 
Results of the first experiments appear in [20] and [21]. In order to simulate the growth of a plant, 
the following parameters have to be given: - the age, - the clocks or growth speeds of the axes, - 
the number of possible buds at each node, as a function of order, - the probabilities of death, pause, 
ramification and reiteration given as functions of age, dimension and order (see section 3). These probabilities 
are sufficient to generate images of great realism; a rather wide variety of forms can even be obtained 
with probabilities restricted to 0 and 1. The probability laws chosen for the simulation can either be 
the result of experimental measures or calculated from mathematical laws taken as hypotheses, or completely 
arbiu, ury, according to the objective of the simulation (although, up to no~v, the model has been used 
to give more faithful images of plants, it would be of interest, and very easy, to simulate the effect 
of "strange" growth laws), Most of the time, the probabilities are the same for all the buds of axes 
of a given order of a given plant; usually, the laws are uniform or exponential laws. - the type of 
the growth unit and the number of nodes per growth unit, given as functions of the same parameters as 
the previous probabilities (if one seeks still greater fidelity to botany, one has to define these parameters 
as random variables which depend on various other parameters (see [10])); - the geometric parameters 
of an internode: length and diameter as a function of the same parameters and of the age of the plant 
for the diameter (for cylindrical intemodes) or diameters (for cone-shaped intemodes);  -for every axis 
order, the development trend (orthotropy or plagiotropy), the insertion angle with the bearing axis (with 
the ground for order ] axis), the phyllotaxy, which is also characterized by an angle. For a greater 
fidelity to botany, one has, as has been indicated above for the growth unit parameters, to define the 
insertion angle and the phyllotaxy as random variables, functions of various parameters and to consider 
the development Irend as composite (see [10]). @ ~ Computer Graphics, Volume 22, Number 4, August 1988 
The insertion angle and the development trend are used to smooth out the shape of an axis according to 
its trend. For example, in the case of a vertical order I axis bearing an order 2 axis, the orthotropic 
and plagiotropic case are dealt with as shown in Figure 15. ! Figure 15: Development trend of a tree 
(left:orthotropy, right: plagiotropy). In order to obtain images with great fidelity to nature, the choice 
of the important parameters and their experimental measurement has to be done with particular care. This 
usually requires a good knowledge of botany and of the model. The simulation consists in going through 
each instant of diseretized time from the birth of the plant to the given age, and, for each of these 
instants, to consider all the buds which are alive at that moment. Each bud undergoes a mortality test; 
if necessary, a break test; and lastly, if necessary, a ramification test. According to the results of 
these tests, the bud can be suppressed from the set of living buds or a new internode can (if there is 
no break of the growth at that point) be created (with a new apical bud and new axillary buds with a 
given order and geometric position). The simulation can be expressed in pseudo-code as follows: for each 
clock signal do for each bud which is still alive do {order, age, dimension, position, etc. are known 
attributes of the bud} if bud doesn't die then if bud doesn't make a pause then create intemode {with 
position in space} create apical bud for each possible bud do if ramification then create axillary buds 
{with age, order and dimension} endfor endif endif endfor endfor Up to now, such a simulation of time 
has not been used in the actual implementation of the algorithm because of its requirements in memory 
space. A prefix traversal of the tree has been preferred: the axillary buds of a node are numbered 1, 
2 ..... k in any order, the apical bud is numbered k+l; a prefix traversal is the chain of prefix traversals 
of the "trees" stemmed from bud i, for i=1 ..... k. This kind of traversal can be used for simulation 
purposes since, because of the hypotheses, when the traversal visits a bud, by previous processing its 
age, dimension, order (and, possibly others structural parameters if needed) and position are known. 
Since, in nature, the order of an axis is very rarely bigger than five, the size of the stack used for 
the simulation of the traversal is moderate. The prefix traversal we used up to now is not suited to 
an animation of growth as it imposes that the whole plant is calculated again at each age used in the 
animation. Moreover, with such a traversal, one cannot take into account some significant botanical phenomena 
such as growth obstruction (growing of mortality or break, for example) due to fixed obstacles or to 
part of the plant against another part, or the effect of the shade cast by the tree on its own buds. 
A more accurate simulation of growth and its application to obstruction is in progress. The growth simulation 
program manages the tests of death, break or ramification by calling a random number generator and the 
laws procedures for the probabilities. It also manages the geometric parameters. Its output is a file 
whose records' fields include a tag characteristic of the component (short or long internode, leaf,...), 
a position in space, and two 3D directions for the component. The described generator is an architecture 
generator; for ease of exposition we have not mentioned, up to now, how to deal with the simulation of 
other phenomena. This will be done in the next section. 5. Other simulations. Autumn's fall of leaves 
can be very easily simulated; one has only to define a life length for leaves, which is usually taken 
as constant for a given plant In a similar way, botanists know the laws that rule the birth of flowers 
and inflorescences, their life. length and the fruits' life-time. The accordance with the botanical model 
insures that the leaves and fruits are inserted in the right places on the branches (according to the 
age of the tree). This implies that the model is also accurate when one looks at a precise part of the 
tree, instead of looking at its overall shape. As for the pruning of trees, it is simulated by saying 
that when all the buds of the same branch are dead the branch itself is dead and falls after some time. 
Lastly, the calculation of the bending of a branch under the action of forces like gravity or wind can 
be done according to the theory of material strength (see [20], [25]); it is done using the geometrical 
shape of internodes and the elasticity parameter (Young's modulus) which characterizes the wood of the 
branch. As regards wind effects no images are included here but an animation is in progress. Although 
in a few cases other models exist ([8], [2]), the same plant generator can also be diverted to output 
parts of a plant instead of its overall architecture (according to [7] our modeling for image synthesis 
purposes is, in this case, structural but not physical). For example, an inflorescence is considered 
by the plant generator as a small tree bearing axes of order at most 2 or 3, very regular, the last node 
on every axis bearing a flower. In a similar way, the sepals, petals, stamens and stigmas of a flower 
can be generated as specific internodes or growth units (for another approach, see [12]). A palm tree's 
palm can also be generated as structure I: trunk | I ! !    ' N i J structure 2: .palm III1111II11 
structure 3: inflorescence q ~11/ I \\1/ I \1 / V I / structure ~: flower i Figure 16: Four structures 
used for a date palm tree.  SIGGRAPH '88, Atlanta, August 1-5, 1988 a growth unit with specific internodes 
(see figure 16). As a last example, let us mention that an underground rhizome can be calculated as a 
monopod with a rather simple architecture; at its nodes, herbs, which are monopods with another architecture, 
grow. 6. Visualization. The plant generator's output is a file of records whose fields are the following 
ones: a tag which characterizes a'botanical component (short or long internode, leaf, flower, fruit, 
and, if one enlarges the simulation, cL sect. 5, rhizome internode, palm internode, petal internode, 
sepal internode, etc.) and geometric information needed to position the component in space. A form taken 
from a library of forms is associated with every tag: for example, straight cylinders, hexagonal cylinders 
or straight truncated cones for internodes, polygons for leaves or flower petals,.... Moreover, the library 
of forms can be parameu'ized by age. For the photos we generated, we only used cones with hexagonal bases 
or even segments for internodes; for leaves, petals or sepals, we used an assembly of at most 4 convex 
plane polygons (in a few cases a vector is sufficient) with an associated normal if needed. Small fruits 
are made with a few vectors. To each form a color is associated. The visualization is then the visualization 
of a set of vectors and faces. Basic rudimentary methods have then been used for the rendering: perspective, 
no antialiasing, uniform color for faces .... In a few cases a light source was used to change the polygons' 
luminosity according to the angle between the source direction and the normal to the polygon. Hidden 
surface removal is done by the use of a Z-buffer. The use of such primitive rendering techniques proved 
to be sufficient for obtaining images with great realism: the richness of forms is such that antialiasing 
or texture is usually not necessary; the only exception is for close-ups of a part of a tree, of its 
trunk or of one of its branches. Usually using a tough Z-buffer (with a unique depth for all the pixels 
of a leaf for example) is enough. Let us mention that the complexity of the structure grows rapidly with 
the age of the plant. A few tens of components are enough to describe a small plant, hot several hundreds 
of thousands are needed to describe tail Lees. In such cases, the computer time needed to generate the 
model and visualize can be important (a few tens of minutes instead of a few minutes for a small tree). 
7. Conclusion. We have presented a model for the growth of plants and trees which incorporates botanical 
knowledge of their architecture. The very first interest of the model is its great richness: the same 
procedural methods can produce "plants" as different as weeping willows, fir trees, cedar trees, frangipani 
trees, poplars, pine trees, wild cherry trees, herbs, etc. Another very important benefit from the model 
is the integration of time which enables to view the aging of a tree (accurate simulation of the death 
of leaves and branches for example). Using the model, a short movie showing the evolution of a tree from 
birth to death has been produced. Let us also stress that part of the study has been developed for agronomic 
purposes: mathematical models of the architecture of plants and trees turn out to be very useful for 
studying land crops; the production is very often dependent on plant growth and architecture. The incidence 
of factors such as insect attacks, use of fertilizers, planting density, etc. can be studied using the 
architectural models combined with other mathematical models. This ability to put together different 
models should also be investigated for image synthesis purposes. Another very promising study would be 
to simulate the growth with "arbritary" non botanic parameters in order to obtain non existing architectures, 
strange shapes, etc. In doing so, one could benefit from the richness of the model for animation purposes. 
Acknowledgements. The authors would like to thank C. Schmitt, H. Brisse, and M. Hoff from Strasboarg 
University, who introduced the~omputer scientists (authors) to the work of botanists, CNRS Computer Center 
at Cronenbourg and its graphics group, CIRAD's Computer Center and its staff in Montpellier, the "Institut 
de Botanique" in MompeUier who provided several figures and the anonymous referees who suggested several 
improvements in the presentation of the paper. References. 1. Aono M., Kunii T. L., "Botanical Tree Image 
Generation" IEEE Computer Graphics and Applications, vol. 4, No 5, 1984, pp. 10-33. 2. Bell A., "Computerized 
Vegetative Mobility in rhizomatous plants", in Automata, Languages, Development, Lindenmayer A. &#38; 
Rozenberg G. (Eds.), North-Holland, 1976. 3. Bloomenthal I., "Modeling the Mighty Maple", Computer Graphics, 
vol. 19, No. 3, 1985, pp. 305-311. 4. Edelin C., L~rchitecture Monopodiale: l'Exemple de Quelques Arbres 
d~4sie Tropicale, Th~se de Doctorat ~s Sciences, Universit6 des Sciences et des Techniques du Languedoc, 
Montpellier, France, 1984. 5. Eyrolles G., Franqon J., Viennot G., "Combinatoire pour la Synthbse d'Images 
Rralistes de Plantes", Aetes du Deuxi~me Colloque Image, CESTA, 1986, pp. 648-652. 6. Fischer J. B., 
Honda H., "Computer Simulation of Branching Pattern and Geometry in Terminalia (Combretaceae), a Tropical 
Tree", 1977. 7. Fournier A., "Prolegomenon", Unpublished course notes, Fournier A. ed., The Modeling 
of Natural Phenomena (SIGGRAPH'87 course notes #16, Anaheim, CA, July 1987) pp. 3-37. 8. Frijters D., 
Lindenmayer A., "A Model for the Growth and Flowering of Aster Novae-Anglia on the Basis of Table (0,1)-Systems", 
in L-Systems, Rozenberg G., Salomaa A. (Eds.), LNCS, 15, Springer-Verlag, Berlin, 1974, pp. 24-52. 9. 
Halld, Oldeman, Tomlinson, Tropical Trees and Forest: an Architectural Analysis, Springer-Verlag, Berlin/Heidelberg/New-York, 
1978. 10. Jaeger M., Reprdsentation et Simulation de Croissance de V(gdtaux, Thbse de Doctorat, Universit6 
Louis Pasteur, Strasbourg, France, Drc. 1987. 11. Kawaguchi Y., "A Morphological Study of the Form of 
Nature", Computer Graphics, vol. 16, No. 3, 1982, pp. 223-232. 12. Lienhardt P., "Free-form Surfaces 
Modeling by Evolution Simulation", to appear, P~ceedings Eurographics'88. 13. Lindenmayer A., "Paraeladial 
Systems", in Automata, Languages, Development (Lindenmayer A., Rozenberg G. Editors), North-Holland Publishing 
Company, Amsterdam/New-York/Oxford, 1976. 14. Lfick, "Elementary Behavioural Rules as Foundation for 
Morphogenesis", J. Theor. Biol., 54, 1975, pp. 23-24. 15. Oidemann R.A.A., "L'arcbitecture de la For~t 
Guyanaise", Mrmoire 73, ORSTOM, 1974. 16. Oppenheimer P. E., "Real Time Design and Animation of Fractal 
Plants and Trees", Computer Graphics, vol 20, No. 4, 1986, pp. 55-64. 17. Prusinkiewicz P., "Applications 
of L-systems to Computer Imagery", in Proceedings of the Third Workshop on Graph Grammars and their Applications 
to Computer Science, Warrenton, Dec. 1986, pp. 534-548. 18. Reeves W. T., Blau R., "Approximate and 
Probabilistic Algorithms for Shading and Rendering Structured Particle Systems", Computer Graphics, vol. 
19, No. 3, 1985, pp. 313-322. 19. Reffye (de) P., Modrlisation de l'Architecture des Arbres Tropicaux 
par des Processus Stochastiques, Th~.se de Doctorat ~s Sciences, Universit6 de Paris-Sud, Orsay, France, 
1979. 20. Reffye (de) P., "Moddle Mathrmatique Alratoire et Simulation de la Croissance et de rArchitecture 
du Cafrier Robusta", Premiere partie, Cafd-Cacao-Thd, vol. 25, No. 2,1981, pp. 83-104. Deuxi~me pattie, 
Cafd-Cacao-Thr, vol. 25, No. 4, 1981, pp. 219-230. Troisi~me partie, Cafd-Caeao-Thd, vol. 26, No. 2, 
1982, pp. 77-96. Quatribme pattie, Cafd-Cacao-Thr, vol. 27, No.l, 1983, pp. 3-20. 21. Reffye (de) P., 
Edelin C., Jaeger M., Cabart C., "Modrlisation de rArchitecture des Arbres", in Proc. Int. Conf. "The 
tree", Montloellier, Sept. 85. 22. Rouane, "Un ModUle de la Ramification de la Croissance Vrg6tale en 
tam qu'Image de la Diffdrentiation Cellulaire", Comptes-Rendus de rAcad¢mie des Sciences, Paris, T. 285, 
26, Sept. 1977. 23. Smith A. R., "Plants, Fractals and Formal Languages", Computer Graphics, vol. 18, 
No. 3, 1984, pp. 1-10. 24. Smith A. R., Unpublished course notes, Fournier A. ed., The Modeling of Natural 
Phenomena (SIGGRAPH'87 course notes #16, Anaheim, CA, July 1987). 25. Stoker J.J., Nonlinear Elasticity, 
Gordon et Breach, New York, NY, 1968.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378507</article_id>
		<sort_key>159</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Spacetime constraints]]></title>
		<page_from>159</page_from>
		<page_to>168</page_to>
		<doi_number>10.1145/54852.378507</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378507</url>
		<abstract>
			<par><![CDATA[Spacetime constraints are a new method for creating character animation. The animator specifies <i>what</i> the character has to do, for instance, "jump from here to there, clearing a hurdle in between;" <i>how</i> the motion should be performed, for instance "don't waste energy," or "come down hard enough to splatter whatever you land on;" the character's <i>physical structure</i>---the geometry, mass, connectivity, etc. of the parts; and the physical <i>resources'</i> available to the character to accomplish the motion, for instance the character's muscles, a floor to push off from, etc. The requirements contained in this description, together with Newton's laws, comprise a problem of constrained optimization. The solution to this problem is a <i>physically valid</i> motion satisfying the "what" constraints and optimizing the "how" criteria. We present as examples a Luxo lamp performing a variety of coordinated motions. These realistic motions conform to such principles of traditional animation as anticipation, squash-and-stretch, follow-through, and timing.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[constraints]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P18516</person_id>
				<author_profile_id><![CDATA[81100295587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Witkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032842</person_id>
				<author_profile_id><![CDATA[81100215003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kass]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[William W. Armstrong and Mark W. Green, The dynamics of articulated rigid bodies for purposes of animation, in Visual Computer, Springer-Verlag, 1985, pp. 231-240.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Ronen Barzel and Alan H. Barr, Dynamic Consiraints, Topics in Physically Based Modeling, Course Notes, Vol. 16, Siggraph 1987]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>577897</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Michael Brady et. el., eds, Robot Motion: Planning and Control, MIT Press, Cambridge, MA, 1982]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Charles E. Buckley, The Application of Continuum Methods to Path Planning, Doctoral Dissertation, Dept. of Mechanical Engineering, Stanford University, Stanford, CA, 1985]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102331</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kurt Fleischer and Andrew Witkin, A modeling testbed, Proc. Graphics Interface, 1988.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Phillip Gill, Welter Murray, and Margret Wright, Practical Optimization, Academic Press, New York, NY, 1981]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Michael Girard and Anthony a Maciejewski, Computataional Modeling/or the Computer Animation of Legged Figures, Proc. SIGGRAPH, 1985, pp. 263- 270]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Herbert Goldstein, Classical Mechanics, Addison Wesley, Reading, MA, 1950]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[David Haumarm, Modeling the Physical Behavior of Flezible Objects, Topics in Physically Based Modeling, Course Notes, Vol. 16, Siggraph 1987]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Paul Isaacs and Michael Cohen, Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics, Proc. Siggraph 1987, pp. 215-224]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Charles Klein and Ching-Hsiang Huang, Review of Pseudoinverse Control for Use with Kinematically Redundant Manipulators, IEEE Trans. SMC, Vol. 13, No. 3, 1983]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37407</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[John Lasseter, Principles of Traditional Animation Applied to 3D Computer Animation, Proc. Siggraph 1987, pp. 35-44]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pixar, Luzo, Jr., (film,) 1986]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[William Press et. al., Numerical Recipes, Cambridge University Press, Cambridge, Engiemd, 1986]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>26887</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Robert S. Stengel, Stochastic Optimal Control, John Wiley and Sons, New York, 1986.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Demetri Terzopoulos, John Platt, Alan Barr, and Kart Fleischer, Elastically Deformable Models, Pros. SIGGRAPH, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms and Brian Barsky, Using Dynamic Analysis To Animate Articulated Bodies Such As Humans and Robots, Graphics Interface, 1985.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Andrew Witkin, Kurt Fleischer, and Alan Barr, Energy constraints on parameterized models, Computer Graphics, 21 (4) July 1987, pp. 225-232 (Proc. SIG- GRAPH '87).]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 l, Spacetime Constraints Andrew Witkin Michael Kass Schlumberger Palo Alto Research 3340 Hillview Avenue, 
Palo Alto, CA 9~30~ Abstract Siggraph '87 [12]. Although £uzo, Jr. showed us that the team of animator, 
keyframe system, and renderer can be Spacetime constraints are a new method for creating char- a powerful 
one, the responsibility for defining the motion acter animation. The animator specifies what the char- 
remains almost entirely with the animator. acter has to do, for instance, "jump from here to there, Some 
aspects of animation--personality and appeal, clearing a hurdle in between;" how the motion should be 
for example---will surely be left to the animator's artistry performed, for instance "don't waste energy," 
or "come and skill for a long time to come. However, many of the down hard enough to splatter whatever 
you land on;" the principles of animation are concerned with making the character's physical structure--the 
geometry, mass, con-character's motion look real at a basic mechanical level nectivity, etc. of the parts; 
and the physical resources, that ought to admit to formal physical treatment. Con-available to the character 
to accomplish the motion, for sider for example a jump exhibiting anticipation, squash- instance the 
character's muscles, a floor to push off from, and-stretch, and follow-through. Any creature--human or 
etc. The requirements contained in this description, to- lamp--can only accelerate its own center of 
mass by push- gether with Newton's laws, comprise a problem of con- ing on something else. In jumping, 
the opportunity to con- strained optimization. The solution to this problem is a trol acceleration only 
exists during contact with the floor, phyJically valid motion satisfying the "what" constraints because 
while airborne there is nothing to push on. Antici-and optimizing the "how" criteria. We present as exam- 
pation prior to takeoff is the phase in which the needed mo- pies a Luxo lamp performing a variety of 
coordinated mo- mentum is acquired by squashing then stretching to push tions. These realistic motions 
conform to such principles of off against the floor. Follow-through is the phase in which traditional 
animation as anticipation, squash-and-stretch, the momentum on landing is absorbed. follow-through, and 
timing. Such physical arguments make nice poJt hoe explana-tions, but can physics be brought to bear 
in creating theKeywords Animation, Constraints -- complex active motions of characters like Luxo? If 
so, how much of what we regard as "nice" motion follows directly I. Introduction from first principles, 
and how much is really a matter of style and convention? Computer animation has made enormous strides 
in the This paper presents a physically-based approach to past several years. In particular, Pixar's 
Luzo, Jr. [13] character animation in which coordinated, active motion marked a turning point as perhaps 
the first computer- is created automatically by specifying: generated work to compete seriously with 
works of tra- ditional animation on every front. Key among the reasons What the character has to do, 
for instance "jump from for Luzo, .)'r. 's success is that it was made by a talented here to there." 
animator who adapted the principles of traditional anima- How the motion should be performed, for instance 
tion to the computer medium. Luzo, Jr., in large measure, "don't waste energy," or "come down hard enoughis 
a work of traditional animation that happens to use a to splatter whatever you land on." computer to 
render and to interpolate between keyframes. What the character's physical structure is--what the John 
Lasseter speUed this out clearly in his presentation to pieces are shaped llke, what they weigh, how 
they're Permission to copy without fee all or part of this material is granted connected, etc. provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
and the title of the What physical resources are available to the charac- publication and its date appear, 
and notice is given that copying is by ter to accomplish the desired motion, for instance the permission 
of the Association for Computing Machinery. To copy character's muscles (or whatever an animate lamp 
has otherwise, or to republish, requires a fee and/or specific permission. in place of muscles,) a floor 
to push off from, etc. @ 1988 ACM-0-89791-275-6/88/008/0159 $00.75 "Luxo" is a trademark of Jac Jacobsen 
Industries AS. SIGGRAPH '88, Atlanta, August 1-5, 1988 Our initial experiments with this approach have 
aimed at making a Luxo lamp execute a convincing jump just by telling it where to start mad where to 
end. The results we present in this paper show that such properties as an- ticipation, follow-through, 
squash-and-stretch, and timing indeed emerge from a bare description of the motion's pur- pose and the 
physical context in which it occurs. Moreover, simple changes to the goals of the motion or to the phys- 
ical model give rise to interesting variations on the basic motion. For example, doubling (or quadrupling) 
the mass of Luxo's base creates amusingly exaggerated motion in which the base 1oo~ heavy. OvLr method 
entails the numerical solution of laxge constrained optimization problems, for which a variety of standard 
algorithms exist. These algorithms, while rela- tively expensive, spend most of their time solving sparse 
linear systems, and are therefore amenable to accelera-tion by array processors and other commonly available 
hardware. The greatest difficulty arises not in comput- ing the numerical solution, but in setting up 
the intricate sparse matrix equations that drive the solution process. To address this problem we implemented 
an object-oriented symbolic algebra system that automates this difficult task almost entirely. We therefore 
believe the method described here can become a practical animation tool requiring no more mathematical 
sophistication of the end user than do current keyframlng systems. The remainder of the paper is organized 
as follows: the following section discusses the previous use of physical methods in animation. The spacetime 
method is then in- troduced using a moving particle as a toy example. Next, our extension of the method 
to complex problems is dis- cussed. Finally, the Luxo model and the results obtained with it are described. 
 II. Background and Motivation Recently, there has been considerable interest in incorpo- rating physics 
into animation using simulation methods. [10, 17, 18, 2, 16, 7, 9] The appeal of physical simulation 
as an animation technique lies in its promise to produce re- alistic motion automatically by applying 
the same physical laws that govern real objects' behavior. Unfortunately, the realism of simulation comes 
at the expense of control. Simulation methods solve initial value problems: the course of a simulation 
is completely deter- mined by the objects' initial positions and velocities, and by the forces applied 
to the objects along the way. An an- imator, however, is usually concerned as much with where the objects 
end up and how they get there as where they begin. Problems cast in this form are not initial value problems. 
For instance, while simulating a bouncing ball is easy enough, making the ball bounce to a particular 
place requires choosing just the right starting values for posi- tion, velocity, and spin Making these 
choices manually is a painful matter of trial and error. Problems such as this one, in which both initial 
and final conditions are partially or completely constrained, are called two-point boundar!l problems, 
requiring more elaborate solution methods than forward simulation.[6] Character animation poses a still 
more difficult prob- lem. Animals move by using their muscles to exert forces that vary as a function 
of time. Calculating the motion by simulation is straightforward once these tlme-dependent force functions 
are known, but the difficult problem is to calculate force functions that achieve the goals of the mo- 
tion. Specifying these functions by hvaad would be hope- less, equivalent to making a robot move gracefuLly 
by man- ually varying its motor torques. In an effort to reconcile the advaaatages of simula- tion with 
the need for control, several researchers [2, 10] have proposed methods for blending positional constraints 
with dynamic simulations. The idea behind these meth- ods is to treat kinematic constraints as the consequences 
of unknown "constraint forces," solve for the forces, then add them into the simulation, exactly canceling 
that com-ponent of the applied forces that fights against the con-straints. Constraint force methods 
permit parts, such as a character's hands or feet, to be moved along predefined keyframed trajectories, 
but provide no help in defining the trajectories, which is the central problem in creat-ing character 
animation. While allowing a character to be dragged around manually like a marionette, constraint forces 
sidestep the central issue of deciding how the char- acter should move. These shortcomings led us to 
adopt a new formula- tion of the constraint problem, whose central characteris- tic is that we solve 
for the character's motion and time- varying muscle forces over the entire time interval of in- terest, 
rather than progressing sequentially through time. Because we extend the model through time as well as 
space, we call the formulation spacetim¢ constraints. The spacetime formulation permits the imposition 
of constraints throughout the time course of the motion, with the effects of constraints propagating 
freely back- ward as well as forward in time. Constraints on initial, final, or intermediate positions 
and velocities directly en- code the goal~ of the motion, while constraints limiting muscle forces or 
preventing interpenetration define prop- erties of the physical situation. Additionally, Newtouian physics 
provides a constraint relating the force and po- sition functions that must hold at every instant in 
time. Subject to these constraints we optimize functions that specify how the motion should be performed, 
in terms of efficiency, smoothness, etc. Solving this constrained opti- mization problem yields optimal, 
physically valid motion that achieves the goals specified by the animator.  III. A spacetlme particle 
 As a gentle but concrete introduction to the spacetime method, this section describes a minimal example 
involv- ing a moving particle, influenced by gravity, and equipped with a "jet engine" as a means of 
locomotion. With no restrictions on the forces exerted by its engine, the parti- cle can move any way 
it likes. The problem we formulate here is that of making the particle fly from a given start- ing point 
to a given destination in a fixed period of time, with minimal fuel consumption. This toy problem is 
too simple to produce any really interesting motion, but it ex- hibits all the key elements of the method, 
and will aid in understanding what follows. A. Problem formulation Let the particle's position as a function 
of time be x(t), and the time-varying jet force be f(t). Suppose for sim- plicity that the mass of the 
fuel is negligible compared to that of the particle, so the total mass may be treated as a constant, 
ra, with a constant gravitational force rag. Then the parrticle's equation of motion is m~-f-mg = 0, 
(1) where i is the second time derivative of position. Given the function f(t), and initial values for 
x and ± at some time to, the motion x(t) from to could be obtained by integrating equation 1 to solve 
the initial value problem. Instead we wish to make the particle fly from a known point a to a known point 
b in a fixed period of time. Sup- pose for simplicity that the rate of fuel consumption is Ill z. In 
that case, we have constraints x(t0) = a and x(tl) = b subject to which R = If(t)l 2 dt must be minimized. 
The problem then is to find a force function f(t), defined on the interval (t0, tl), such that the position 
function x(t) obtained by solving equation I satis- fies the boundary constraints, and such that the 
objective function R is a constrained minimum. There exist a variety of standard approaches to solv- 
ing problems of this form. Prevalent in the optimal con- trol literature are iterative methods that solve 
the initial value problem within each iteration, using the equations of motion to obtain the position 
function from the force function (see [15] for a good survey.) We choose instead to represent the functions 
x(t) and f(t) independently. The equation of motion then enters as a constraint that re-lates the two 
functions, to be satisfied along with the other constraints during the so]ation process. Each function 
is discretized, that is, represented as a sequence of values, with time derivatives approximated by finite 
differences. This approach leads to a classical problem in constrained optimization, for which a variety 
of standard solution al- gorithms are available. Let the discretized functions x(t) and f(t) be repre- 
sented by sequences of values xl and fi, 0 < i < n, with h the time interval between samples. To approximate 
the time derivatives of x(t) we use the finite difference formulas Xi = Xi hXi--1 (2) xi = Xi+l -- 2xi+xi-1 
 h~ (3) Substituting these relations into equation 1 gives n "physics constraints" relating the zi's 
to the fi's, Xi+l--2xi+xi-l--fi--Tng=O , l<i<n. (4) Pl ---- ra h2 In addition we have the two boundary 
constraints Ca=Xl--a=O and Cb=Xn--b=0. Assuming that f(t) is constant between samples, the ob- jective 
function R becomes a sum R = h~ If~l' (5) i which is to be minimized subject to the constraints. The 
discretized objective and constraint functions are now ex- pressed in terms of the xi's and the fi's, 
which are the independent variables to he solved for. B. Numerical Solution From the standpoint of the 
numerical solution process it is useful to suppress the structure of tbe particular problem, reducing 
it to a canonical form consisting of a collection of scalar independent variables Sj, 1 ~ j ~ n, an objective 
function R(Sj) to be minimized, and a collection of scalar constraint functions Ci(Sj),1 < i < m, which 
must be driven to zero. In the current problem, the Sj's are the z, y, aud z components of the xi's 
and the fi's, while the Ci's are the components of the pi's, ca, and cb. TypicMly, setting up the Hnearlzed 
indices is the responsibility of a program that keeps track of the independent variables and the constraint 
functions. In these terms, the standard constrained optimiza- tion problem is "Find Sj that minimizes 
R(Sj) subject to Ci(Sj) = 0. For the sake of modtdarity, the humeri- cat method that solves the problem 
is best regarded as an object that requests answers to certain standard questions about the system, and 
iteratively provides updated vMues for the solution vector Sj. Any method must be permitted to request 
the values of R and C~ at a given Sj. In addi- tion, most effective methods require access to derivativeJ 
of R and Ci with respect to Sj, in order to move toward a solution. The solution method we use is a variant 
of Sequential Quadratic Programming (SQP), described in detail in [6]. Essentially, the method computes 
a second-order Newton- Raphson step in R, and a first-order Newton-Raphson step in the Ci's, and combines 
the two steps by projecting the first onto the null space of the second (that is, onto the hyperplvme 
for which all the Ci's are constant to first or- der.) Because it is first-order in the constraint functions 
 and second-order in the objective function, the method re- quires that we be able to compute two derivative 
matrices: the dacobian of the constraint functions, given by Jq = ~, and the Hessian of the objective 
function, O2 R In addition, the first derivative vector OR/OSj must be available. The SQP step is obtained 
by solving two linear systems in sequence. The first, OR J  yields a step S$ that minimizes a second-order 
approxima- tion to .R, without regard to the constraints. The second, J yields a step Sj that drives 
linear approximations to the Ci's simultaneously to zero, and at the same time projects the optimization 
step Sj onto the null space of the con- straint Jacobian. The final update is AS s = S# + ~#. The algorithm 
reaches a fixed point when Ci = 0 and when any further decrease in R requires violating the constraints. 
 C. Linear system solving The choice of a method for solving these linear systems is critically important, 
because the matrices can be large. Although inverting a general n x n matrix is O(ns), the matrices arising 
in spacetime problems are nearly al- ways extremely sparse. Exploiting the sparsity is essen- tial to 
make the problem tractable. Moreover, over- and under-constrained systems, whose matrices are non-square 
and/or rank-deficient, can easily arise, in which case the inverse is undefined and the system cannot 
be solved. The latter problem is well treated by the pseudo-inverse [11, 7], which provides least-squares 
solutions to overconstrained problems, and minimal solutions to underconstrained ones. To compute the 
pseudo-inverse while exploiting random sparslty, we adapted a sparse conjugate gradient (CG) algorithm 
described in [14}, which is O(n z) for typical problems. The CG algorithm solves the matrix equation 
a = Mb by iteratively minimizing [a- Mb[ z, giving a least-squares solution to overconstrained problems. 
Pro-vided that a zero starting-point is given for b, the solution vector is restricted to the null-space 
complement of M. D. Matrix evaluation. Applying the SQP algorithm to the moving particle exam- ple requires 
evaluation of the sparse derivative matrices, as well as the objective and constraint functions them- 
selves. Apart from the bookkeeping required for indexing, these evaluations are straightforward. The 
Jacobian of the physics constraint is given by Opi _ 2ra/h2 ' i-- j Oxi = -m/h 2, i=jrkl = O, otherwise 
Opt = 1, i =j 0fj = 0, otherwise. The Jacobians of the boundary constraints are trivial. The gradient 
of R is OR =  2f,, and the Hessian is = 2, i=j 0fi0fi = O, otherwise. Although it happens that the 
toy problem we chose constrains initial and final positions, nothing in the solu- tion approach depends 
on this configuration: initial and final conditions could be left free, and constraints at arbi- trary 
internal points could be added. Moreover, arbitrary constraints of the form F(S~) = 0, not just position 
con- straints, may be added provided that the constraint func- tions and their derivatives can be evaluated. 
IV. Extension to complex models In principle, the procedure described in the last section ex- tends to 
complex models, constraints, and objective func- tions. In practice, as the model grows more complex, 
the problem becomes prohibitively difficult. The difficulty lies not so much in calculating the numerical 
solution as in cre- ating code to evaluate the constraint and objective func- tions and their sparse 
derivatives, and in coercing the eval- uatlons into the form of a canonical constrained optimiza- tion. 
In particular, the required differentiations can lead to enormous algebraic expressions that are all 
but impossible to derive and code by hand. To make the method practical, we developed a lisp- based 
system that performs these difficult tasks automat- ically. The system consists of three principle elements: 
a specialized math compiler that performs symbolic differ- entiation and simplification of tensor forms, 
and generates optimized code to perform the evaluations; a runtime sys- tem that allows the generated 
functions to be composed dynamically, automatically building the vectors and sparse matrices that drive 
the numerical solution; and an SQP solver. Because the mathematical operations required to de- fine a 
new primitive object or constraint are highly styl- ized, it is possible to reduce the programmer's job 
to a simple cookbook procedure. Once the primitives are de-fined, a user with little or no knowledge 
of the underlying mathematics can wire them together dynamically to cre- ate animation. Although a full 
description is beyond the scope of this paper, this section briefly outlines the system and the operations 
it performs. A. Function Boxes A function boz, the lowest level construct in the system, consists of 
a set of input quantities, which may be scalars, vectors, matrices, or higher-order re,sots, and a collection 
of output quantities each defined as a mathematical func- tion of the inputs. To define a function box, 
the program- mer specifies the inputs, the outputs, and the functions that relate them. The function 
definitions are mathemati- cal expressions that may include differentiations as well as algebraic operations. 
Non-scalar quantities are expressed and manipulated using index notation with the summation convention. 
For each output, the system performs sym- bolic differentiation as called for, simplifies the resulting 
expression, extracts common sub-expressions, and gener- ates an optimized lisp function that evaluates 
the output given the inputs. In addition, the system symbolically dif- ferentiates each output with respect 
to each input on which it depends, creates a lisp function to evaluate the deriva- tive, and analyzes 
its sparsity. These functions form the Jacobians of the outputs. The generated functions, input- output 
dependencies, spaxsities, etc., are recozded in a data structure accessible to the runtime system. B. 
User Interface Once defined, function boxes are manipulated using a graphical interface in which they 
appear as literal boxes on the screen, with ports representing the input and out- put quantities.[5] 
The user may instaatiate boxes, con-necting the ports to form a graph whose ares represent function composition. 
In this way, complex systems are built dynamically by composing pre-compiled primitives. By default, 
input ports to which nothing has been con-nected axe treated as internal constants whose values may be 
inspected and modified interactively, and unconnected output ports are ignored. However, inputs may also 
be flagged by the user as state variables to be solved for, and outputs may be flagged either as constraints 
or as terms to be summed into the objective function. C. Runtime System Once the graph representing 
the model has been con-structed, and the state-variables, constraints, and objec- tive terms declared, 
a pre-runtime computation is per- formed to set up the constrained optimization. The user- declared state 
vaxiables, constraints, and objective terms axe collected and indexed to form the quantities Sj, C~, 
and R required by the solver. The sparse derivatives are formed by propagation through the graph using 
the chain rule, with the individual Jacobian functions associ- ated with function boxes combined by a 
hierarchy of sparse matrix multiplications and additions. An optimal sequence of adds and multiplies 
is pre-computed for each sparse ma- trix operation, and the sparslty patterns of the resulting global 
matrices are also precomputed. Evaluation of Ci, R, and their derivatives, then proceeds by recursing 
through the graph, calling the individual value and 3acobian func- tions, and performing the sparse matrix 
operations. The solver communicates with the model by requesting these evaluations and updating the state 
vector. D. Defining Objects ~ullt on top of the basic system is a layer handling the specifics of physical 
object models, whose main job is to construct the object's equations of motion. In the case of the moving 
particle this just involved direct application of f = ma. However, deriving the equations of motion for 
more complicated objects can be difficult. We derive the equations automatically using La-granglan Dynamics 
[8], a classical cookbook procedure in which an expression for a body's kinetic energy is sub- jected 
to a series of symbolic differentiations. Lagrange's equations of motion are given by d 0T 0T ~(~q) --qo"-- 
- q = 0, (6) where T is kinetic energy, q is a vector of generalized co-ordinates, and Q is a generalized 
force. The components of the generalized coordinates axe whatever variables con- trol the positions and 
orientations of parts of the body (e.g. translations, rotations, joint angles, etc.) The gen- eralized 
force is just the sum of ordinary forces applied to body, transformed into generalized coordinates. For 
point forces, this transformation is accomplished by multiplying the force vector by the Jacobin" of 
the point at which the force is applied with respect to q. To define an object, the user is required 
to supply ex- pressions for T, and for the coordinates of points on the body to which forces or constraints 
may be applied. Al-though T must be derived manually, this is a manageable job and need only be done 
once when a primitive object is defined. Given these expressions, automatic construction of a function 
box representing the objects is straightfor- ward: the kinetic energy expression is subjected to the 
rote symbolic differentiations called for in equation 6, with an additional derivative with respect to 
q used to define the 3acobian of the physics constraint. The expressions for material points are also 
differentiated with respect to q to create "force converter" functions, small Jacobin, matri- ces that 
map applied forces into generalized coordinates. The function box takes as inputs values for q, el, and/t, 
for applied forces, and for constants such as masses and di- mensions. It produces outputs for the "physics 
constraint" defined by the equations of motion, and for the positions and velocities of the material 
points defined by the user. Figure 1: Luxo E. Discretized functions of time In developing the particle 
example of the last section, dis- cretized functions representing forces and positions over time were 
incorporated into the equations of motion by di-. rect substitution. Given the ability to compose functions 
and their sparse Jacohians automatically, we adopted the alternative of constructing specialized function 
boxes to represent discretized functions. These boxes contain the sequence of values representing the 
function, and output the values and the time-derivatives obtained using finite- difference formulas. 
The Jacobians of these output func-tions are trivial constant diagonal or banded matrices. The values 
and derivatives are connected to the corresponding inputs on the object model, causing the discretization 
to be effected automatically at runtime. V. Spacetime Luxo We axe now equipped to proceed to a spacetime 
model of an animate Luxo Lamp. The model is composed of r/gid bodies of uniform mass connected by frictionless 
joints. Each joint is equipped with a "muscle" modded as an an- gular spring whose stiffness and rest 
angle are free to vary with time. The lamp is subject to the forces of its own muscles, in addition to 
the external force of gravity and the contact forces arising from its interaction with objects such as 
floors and skijumps. A picture of the model ap- pears in Figure 1. In our initial examples, Luxo's motion 
is restricted to a plane. This expedient simplifies the mathe- matics, while still allowing the creation 
of complex, subtle, and interesting motion. Extension of the model to three dimensions involves no fundamental 
difficulties, although it leads to systems that axe somewhat laxger, somewhat slower, and more difficult 
to debug. The definition of the model consists of less than a page of tensor expressions, which expand 
into roughly 4000 lines of automatically gen- erated lisp code. A. Kinetic Energy As discussed in the 
last section, our principle task in defin- ing the model was to formulate an expression for the kinetic 
P~ 02 Pl o I 0 0 Figure 2: Luxo's paxameters: P0 is a translation, and 01 is the orientation of the 
i-th link. Points Pl-P3 axe com- puted from these parameters. energy, T. In general, T is the volume 
integral over the body of the kinetic energy of each paxticle, 1 ~p I±i z, where p is the mass density 
at point =. The kinetic energy of an articulated object is the sum of the kinetic energies of the parts. 
Each of Luxo's links is modeled as a rigid body ro- tating about an axis of fixed direction that passes 
through the origin in body coordinates (see Figure 2.) Because the axis is fixed, the orientation of 
the i-th link may be denoted by a single angle 01, with angular velocity wi = 0is, where a is a unit 
vector in the direction of the axis. In addition to rotation, the body origin undergoes a translation 
Pl, with translational velocity vl = dpi/dt. Each link has mass ml, a constant moment of inertia _ri 
about the rotation axis, and a center of mass ci expressed as a displacement from the body origin. In 
these terms, the kinetic energy of the i-th link is Ti = ~m,1 Ivil 2 + mlwi Vi × Ci "1- 1 [wilzZi. (r) 
 To connect the links, each link inherits as its translation the position of the previous Unk's endpoint, 
with the base's translation, P, serving as a translation paxameter for the whole modal. The translational 
velocity v~ of the i-th link is thus dP Vi --i=0 dt ' = Vi_ 1 + ri_ 1 X Wi--l, otherwise where ri-1 
is a vector from the (i -1)-th link's center of rotation to its point of attachment with the i-th link. 
The total kinetic energy T is obtained by recursively substitut- ing this expression into equation 7 
to obtain the Ti's, and summing over i. B. Muscles Luxo's muscles are three angular springs, one situated 
at each joint. The spring force on the joint connecting the i-th and (i + 1)-th links is defined by F~ 
= k~(¢~ - p~), where ki is the stiffness constant, ¢i is the joint angle, and pi is the rest angle. 
Our model is parameterlzed by ]ink orientations rather than joint angles. The joint angle is ~bi ---- 
0i+t -01, the difference between the orientations of the surrounding links. The generalized force on 
01, the orientation of the i-th link, due to the j-th muscle is dOj J = k~(¢~-p~), j=i+l = -k~(~ -p~), 
j = i = O, otherwise Unlike passive springs whose stiffness and rest state are constants, /el and Pl 
vary freely over time, allowing arbi- trary time-dependent joint forces to be exerted. VI. Results A. 
Jumping Luxo Jumping motion was created using kinematic constraints to specify initial and final poses, 
with linear interpolation between the poses to create a trivial initial condition for the spacetime iteration. 
Another constraint was used to put Luxo on the floor during the initial and final phases of the motion. 
Subject to these and the physics constraint, we minimized the power due to the muscles, Fs0. In one variation, 
we adjusted the mass of Luxo's base, leaving the situation otherwise unchanged. In another, we additionally 
constrained the force of contact with the floor on landing, to produce a relatively soft landing. In 
a final variation, we added a hurdle, together with a constraint that the jump clear the hurdle. The 
pose constraints consisted of values for the three joint angles, and were applied to the first two and 
last two fraxnes of motion. Because we measure velocity using a finite difference, this incorporates 
the additional constraint that Luxo be at rest at the beginning and end of motion. Initial values for 
the orientations were obtained by linear interpolation between the two poses. The floor enters both as 
a kinematic constraint and as a force. In general, collision constraints appear as inequal- ities, but 
to simplify matters, we chose to specify explicitly the time intervals during which Luxo was on the floor, 
im- posing during those times the equality constraints 7f 80 -~ = 0,P -P/= 0 where 00 is the orientation 
of the base, P is the position of the center of the base, and P/is a constant point on the floor. In 
other words, the position and orientation of the base are nailed. The limitation of this formulation, 
com- pared to an inequality, is that the times at which contact occurs must be pre-specified, rather 
than allowing things to bounce freely. The floor constraint was enabled for the first and last five frames 
, allowing time for anticipation and follow-through. Of course, two different values were used for P! 
at the start and finish, defining the start end points of the jump. The floor constraint represents a 
mechanical interac- tion involving the transmission of force between the base and the floor. This contact 
force must be taken into ac- count to satisfy the physics constraint. The simple contact model used for 
the jump has the base colliding with the floor inelastically with infinite friction, which means that 
the base comes to rest, losing its kinetic energy, at the mo- ment of contact. The contact force is therefore 
whatever arbitrary force on the base specifically, on P and 0e--is required to satisfy physics in light 
of the :floor constraint. No special provision need be made to solve for the contact forces beyond introducing 
additional state variables to rep- resent them. Their values are then determined during the constraint-solving 
process. This method of solving for con- straint forces applies to other mechanical constraints, such 
as joint attachments, and is closely related to the method of Lagrange multipliers. The choice of optimization 
criteria is an area we have just begun to explore. In the examples shown, we sought to optimize a measure 
of the morton's mechanical efficiency by minimizing the power consumed by the muscles at each time step, 
which for each joint is the product of the muscle force and the joint's angular velocity. Our preliminary 
observation is that this criterion produces relatively fluid and natural motion, compared to kinematic 
smoothness criteria in terms of velocity and acceleration, which tend to come out looking somewhat arthritic. 
Figure 3 shows a series of iterations leading from an initial motion in which Luxo translates, floating 
well above the floor, to a finished jump in which all the constraints are met and the objective function 
is minimized. Note that the elements of realistic motion already appear after the first iteration. The 
final motion shows marked an-ticipation, squash-and-stretch, and follow-through. From its pre-defined 
initial pose, Luxo assumes a crouch provid- ing a pose from which to build momentum. The crouch is followed 
by a momentum-building forward-and-upward ex- tension to a stretched launching position. While in flight, 
the center of mass moves ballistically along a parabolic arc determined by the launch velocity and by 
the force of grav- ity. Toward the end of the flight, Lu.xo once again assumes a crouched position in 
anticipation of landing, extending sIightly while moving toward impact. This "stomp" ma-neuver has the 
effect of transferring kinetic energy into the base, where it vanishes in the inelastic coUision with 
the floor. Following impact, luxo extends forward while com- pressing slightly, dissipating the remaining 
momentum of flight, then rises smoothly to its pre-specified final pose. SIGGRAPH '88, Atlanta, August 
1-5, 1988 L Figure 3: From top to bottom, a series of iterations leading from an initial motion in which 
Luxo translates, floating above the floor, to a finished jump in which aR the constraints axe met and 
the optimlzation function is minimized. The final motion shows marked anticipation, squash-and-stretch, 
and follow-through. In the first variation on the basic jump, we add an additional constraint fixing 
the contact force on landing. The value we choose provides control over a hard-to-soft landing dimension--a 
large landing force leads to an exag- gerated stomp, as if trying to squash a bug, while a small value 
leads to a soft landing, as if trying to avoid breaking 166 / / / Figure 4: A variation on the basic 
jump in which the contact force on landing is conscralned to be small. The force of impact is reduced 
by squashing just before land- ing, reducing the velocity and l:.ence the kinetic energy of the base. 
In contrast, the jump in Figure 3 ex-hibits a slight ~tretch before impact, producing an en-ergy-absorbing 
stomp. Figure 5: The mass of Luxo's base has been doubled. In other respects, the conditions are the 
same as those pro- ducing the basic jump. something fragile. Figure 4 shows a relatively soft landing, 
generated under the same conditions as the basic jump except for the contact force constraint. Comparing 
the motion to the basic jump, we see that Luxo softened the blow of impact by squashing while moving 
toward impact, reducing the velocity, and hence the kinetic energy of the base. In contrast, the basic 
jump has a small atreteh before impact, producing an energy-absorbing stomp. The next variation has the 
same conditions as the ba- sic jump, but the mass of the base has been doubled. The final motion is shown 
in Figure 5. As expected, both the anticipation and follow-through are exaggerated in com-pensation for 
the greater mass. A final variation, shown in Figure 6, has the conditions of the soft-landing jump, 
but with a hurdle interposed be- tween start and finish, and an additional constraint that Luxo clear 
the hurdle. As one would expect, the extra height required is gained by squashing vigorously on ap-proaching 
the wall. The jumping examples each took under 10 minutes to compute on a Symbolics 3640. While this 
is hardly interactive speed, it constitutes a tiny fraction of the cost of high-quality rendering. I 
IIII ~ II IIIII I Figure 6: Hurdle Jump Figure 7: Ski Jump B. Ski Jumping Figure 7 shows Luxo d,~scending 
a ski jump. As in the previous case, Luxo is constrained to be on the ski jump and the landing at particular 
time samples. The biggest difference between the ski-jump and the infinite-friction goor of the previous 
example is that Luxo is free to slide~ with the exact positions on the ski jump and the landing left 
unspecified except at the top and bottom of the ski jump. In addition, there is a constraint that the 
orientation of the base must be tangent to the surface it is resting on. Both the ski jump and landing 
exert forces on Luxo. There is a normal force which keeps him from falling through and a frictional force 
which is tangent to the sur- face and proportional to the tangential velocity. The coef- ficients of 
friction were state variables in the optimization. At one time instant while Luxo is in the air, the 
height of his base is constrained. In addition, there is a term in the objective function which gives 
him a preference for a particular pose while in the air. This is a "style" optimiza- tion without which 
Luxo is content to go through the air in a bent position. Luxo is also given pose constraints at the 
beginning and end of the motion. Unlike the previous jumps, how- ever, his initial velocity is unconstrained. 
 Figure 8: Spacetime constraints: a cartoonist's view. (c) 1988 by Laura Green, used by permission. The 
initial condition for the optimizatior ~as ~ uni-form translation in the air above both the ski jump 
and the landing. In the first iteration, Luxo puts hi~ feeet on the ski jump and landing. By iteration 
4, there is signifi- cant anticipation and follow through. Figure 7 is the result after 16 iterations. 
Both the ski jump and landing are built from two B- spline segments. The entire jump was computed with 
28 time samples in the optimization. There were 223 con-straints and 394 state variables. The Jacobian 
contained 3587 non-zero entries, about 4~ of the total number of en- tries. The entire motion was computed 
in 45 minutes on a Symbollcs 3600. VII. Discussion Our results show that spacetime methods axe capable 
of producing realistic, complex and coordinated motion given only minimal kinematic constraints. Such 
basic attributes as anticipation, squash-and-stretch, follow-through, and timing emerge on their own 
from the requirement that the kinematic constraints be met in a physically valid way sub- ject to simple 
optimizat.lon criteria. The principle advantage of spacetime methods over simple keyframing is that they 
do much of the work that the animator would otherwise be required to do, and that only a skilled animator 
can do Motions that would require highly detailed keyframe information may be sketched out at the level 
of "start here" and "stop there." This is a profoundly different and more economical means of control 
than conventional keyfrarning affords, an advantage that easily outweighs the greater mathematical complexity 
and computational cost of the method. Beyond sparser keyframing, spacetime methods offer really new forms 
of motion control. For example, we saw in the previous section that constraints on forces, such as the 
force of a collision, can be used in a direct and simple way to say "hit hard" or "hit softly," producing 
subtle but very effective changes in the motion. Of the new opportunities for motion control, perhaps 
the most exciting is the selection of optimization criteria to affect the motion globally, an area we 
have only begun to explore. With a little thought, it is clear that a magic SIGGRAPH '88, Atlanta, August 
1-5, 1988 "right" criterion, whether based on smoothness, efficiency or some other principle, is unlikely 
to emerge and would in any case be undesirable. This is because the "optimal" way to perform a motion, 
as with any optimization, de- pends on what you're trying to do. Consider for example several versions 
of a character crossing a room: in one case, walking on hot coals; in another, welklng on eggs; in an- 
other, carrying a full bowl of hot soup; and in still another, pursued by a bear. Plainly the character's 
goals--and at- tendant cr~te~a of optimallty--are very different in each case. We would hope to see these 
differing goals reflected in the motion. The possibility of controlling motion di- rectly in terms of 
its goals, not just where it goes but how, is one we intend to explore. References [1] William W. Armstrong 
and Mark W. Green, The dy- namics of articulated rigid bodies for purposes of an- imation, in Visual 
Computer, Springer-Verlag, 1985, pp. 231-240. [2] Ronen Barzel and Alan H. Barr, Dynamic Con-siraints, 
Topics in Physically Based Modeling, Course Notes, Vol. 16, Siggraph 1987 [3] Michael Brady et. el., 
eds, Robot Motion: Planning and Control, MIT Press, Cambridge, MA, 1982 [4] Charles E. Buckley, The Application 
of Continuum Methods to Path Planning, Doctoral Dissertation, Dept. of Mechanical Engineering, Stanford 
University, Steax£ord, CA, 1985 [5] Kurt Fleischer and Andrew Witkln, A modeling testbed, Proc. Graphics 
Interface, 1988. [6] Philllp Gill, Welter Murray, and Margret Wright, Practical Optimization, Academic 
Press, New York, NY, 1981 [7] Michael Girard and Anthony a Maciejewski, Com. putataional Modeling/or 
the Computer Animation of Legged Figures, Proc. SIGGRAPH, 1985, pp. 263-270 t8] Herbert Goldstein, Classical 
Mechanics, Addison Wesley, Reading, MA, 1950 I9] David Haumarm, Modeling the Physical Behavior of Flezible 
Objects, Topics in Physically Based Modeling, Course Notes, Vol. 16, Siggraph 1987 [10] Paul Isaacs and 
Michael Cohen, Controlling Dy-namic Simulation with Kinematic Constraints, Be-havior Functions and Inverse 
Dynamics, Proc. Sig- graph 1987, pp. 215-224 [11] Charles Klein and Ching-Hsiang Huang, Review of Pseudoinverse 
Control for Use with Kinematically Re- dundant Manipulators, IEEE Trans. SMC, Vol. 13, No. 3, 1983 [12] 
John Lasseter, Principles of Traditional Animation Applied to 3D Computer Animation, Proc. Siggraph 1987, 
pp. 35--44 [13] Pixar, Luzo, Jr., (film,) 1986 [14] William Press et. al., Numerical Recipes, Cambridge 
University Press, Cambridge, Engiemd, 1986 [15] Robert S. Stengel, Stochastic Optimal Control, John Wiley 
and Sons, New York, 1986. [16] Demetri Terzopoulos, John Platt, Alan Barr, and Kart Fleischer, Elastically 
Deformable Models, Pros. SIGGRAPH, 1987. [17] Jane Wilhelms and Brian Barsky, Using Dynamic Analysis 
To Animate Articulated Bodies Such As Hu- mans and Robots, Graphics Interface, 1985. [18] Andrew Witkin, 
Kurt Fleischer, and Alan Barr, En-ergy constraints on parameterized models, Computer Graphics, 21 (4) 
July 1987, pp. 225-232 (Proc. SIG- GRAPH '87).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378508</article_id>
		<sort_key>169</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[The motion dynamics of snakes and worms]]></title>
		<page_from>169</page_from>
		<page_to>173</page_to>
		<doi_number>10.1145/54852.378508</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378508</url>
		<abstract>
			<par><![CDATA[Legless figures such as snakes and worms are modelled as mass-spring systems. Muscle contractions are simulated by animating the spring tensions. Directional friction due to the surface structure is included in the dynamic model and legless figure locomotion results. Various modes of locomotion are described.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[deformation]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[elasticity]]></kw>
			<kw><![CDATA[locomotion]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[rendering]]></kw>
			<kw><![CDATA[simulation]]></kw>
			<kw><![CDATA[texture]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39030376</person_id>
				<author_profile_id><![CDATA[81332515728]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gavin]]></first_name>
				<middle_name><![CDATA[S. P.]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Alias Research Inc., 110 Richmond St. East, Toronto, Canada, M5C 1P1]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F. "Simulation of Wrinkled Surfaces." Computer Graphics, Vol. 12, No. 3, August 1978.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Coquillart, Sabine, "A Control-Point-Based Sweeping Technique", IEEE Computer Graphics and Applications, November 1987 pp 36-45.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Culhane, John, "Special Effects in the Movies", Hilltown Press, Inc., ISBN 0-345-34536-3, November 1981.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Girard, Michael and Anthony A. Maciejewski, "Computational Modelling for the Computer Animation of Legged Figures", Computer Graphics, Vol. 19, No.3, July 1985 pp 263-270.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Isaaes, Paul M. and Michael F. Cohen, "Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics", Computer Graphics, Vol. 21, No. 4, July 1987 pp 215-224.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Johnson, Lee W., R. Dean Riess, "Numerical Analysis", Addison-Welsey Publishing Company Inc. 1982. ISBN 0-201-10392- 3.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Klauber, Lawrence M., "Rattlesnakes", University of California Press, 1982. ISBN 0-520-04039-2.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Mehrtens, John M., "Living Snakes of the World", Sterling Publishing Co. Inc., New York. Blandford Press Dorset, England. 1987. ISBN 0-8069-6460-X.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Miller, Gavin S. P., "Computer Display and Manufacture of 3-D Models", Ph.D. thesis, June 1987, Cambridge University Engineering Department, Cambridge, England.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[O'Neill, Eileen, personal communication Nov. 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Reynolds, Craig W., "Hocks, Herds and Schools : A Distributed Behavioral Model", Computer Graphics, Vol. 21, No. 4, July 1987 pp 25-34.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., J. Platt, A. Barr, K. Fleischer, "Elastically Deformable Models", Computer Graphics, Vol. 21, No. 4, July 1987 pp 205-214.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Waters, Keith, "A Muscle Model for Animating Three- Dimensional Facial Expression", Computer Graphics, Vol. 21, No. 4, July 1987 pp 17-24.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Willhelms, Jane and Matthew Moore, "Dynamics for Everyone", Appendix 1, SIGGRAPH '87 Course 10, Computer Animation : 3-D Motion Specification and Control pp 145-146.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Motion Dynamics of Snakes and Worms Gavin S. P. Miller Alias Research Inc. 110 Richmond St. East, 
Toronto, Canada. M5C 1P1. Abstract Legless figures such as snakes and worms are modelled as mass-spring 
systems. Muscle contractions are simulated by animating the spring tensions. Directional friction due 
to the surface structure is included in the dynamic model and legless figure locomotion results. Various 
modes of locomotion are described. Keywords: Modeling, Deformation, Elasticity, Dynamics, Ani- mation, 
Simulation, Locomotion, Rendering, Texture. CR categories: 1.3.5 -Computational Geometry and Object Modeling 
(Surface and object representations); 1.3.7 -Three-Dimensional Graphics and Realism (Color, shading, 
texture and animation). 1. Introduction Modelling biological forms using computer graphics poses several 
difficult problems. The models must look con- vincing both in their static appearance and in the way 
they move. Legged figures, based on hierarchies of transformations, have received considerable attention 
in recent years. Both kinematic and dynamic models have been presented in the literature [5]. Whilst 
they are successful at animating skeletal structures, the problems of modelling skin and muscle remain. 
Waters presented a facial animation technique which modelled the effects of muscle tensions over a region 
of skin [13], Whilst successful in that application, the model was purely geometrical rather than dynamic. 
It did not respond in a physi- cally realistic fashion to external forces. For animations to be flexible 
and realistic, biological forms should not only work in isolation but they should be able to interact 
with each other and with their environment. Elastically deformable models simulate the interaction of 
objects with external constraints by modelling the physical properties of the materials [12]. By modelling 
biological struc- tures in this way, it should be possible to create life-like anima- tions. The models 
will be made to look "alive" by animating the elastic properties of the muscles as a function of time. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 
ACM-0-89791-275-6/88/008/0169 $00.75 Unfortunately, of course, real plants and animals have highly complex 
structures, leading to complicated and extremely expensive models. However, certain classes of creature 
are elegant in their simplicity, namely snakes, caterpil- lars and worms. 2. Motivation Animals have 
been a favourite topic of animation from its earliest days. Being either loveable or frightening, they 
have a strong emotive effect on an audience. At the same time, the real-life counterparts are notoriously 
difficult to train as well as being potentially dangerous. Puppets have been used to good effect although 
they either require direct physical controls or tedious alteration for every frame [3]. Exceptions to 
this include models which have one actuator for each degree of freedom of the creature. Computer animation 
holds the prom- ise of creating subde motions automatically and synthesising large numbers of creatures 
without additional work on the part of the animator. Reynolds modelled the interaction of schools of 
fish and flocks of birds [11]. The individual creatures were comparatively simple, but collision avoidance 
strategies led to complex and beautiful motions. Individual snakes and worms, on the other hand, change 
shape with every frame. They slither over the ground in a way which depends on how well they grip it. 
They deform elasti- cally when external forces are applied. A simple model with these characteristics 
is described in the next section. 3. Modelling Elastically Deformable Strands Snakes and worms have complex 
internal structures. For the purposes of this paper, a gready simplified model was used. Each segment 
of the creature was modelled as a cube of masses with springs along each edge and across the diagonal 
of each face. For each time interval, the spring lengths and spring length velocities were used to compute 
the forces exerted on the masses at the end of each spring. f =, (£ -t)-D at 7E where f is the force 
along the spring direction, k is the spring constant, D is the damping, l is the current length of the 
spring and L is the minimum energy spring length. (L is animated as a function of time to simulate muscle 
contractions.) In addi- tion, external forces such as gravity were computed, and the total force was 
divided by the mass to give the acceleration. The new position was then computed by integrating the acceleration 
twice with respect to time. / SIGGRAPH '88, Atlanta, August 1-5, 1988 = .~-J'f:,a, at where ~ is the 
position of point p, m e is the mass of the point and f~ is the total force acting on the point. This 
simple mass spring model is adequate to describe many physical objects such as pieces of rope and strands 
of hair. (Unfortunately a head of such hair would be extremely expensive to compute). The edge and diagonal 
springs together control the Young's modulus of the strand, whilst the diagonal springs affect the shear 
and twisting moduli. The method of integration appropriate to compute the position of each point mass 
depends in part on how external constraints are implemented. Impulse-based collisions detect whether 
the motion of a point intersects a surface. If it does, the new position and velocity are computed analytically 
(see Figure 1). P. J Y=y~ y e j÷l Figure 1. Point-plane constraint intersection. For a point mass travelling 
from Pj to Pj+i, the intersection position (xl, yD will be given by: yi = ys x~ = xj+t + (3,, - Yj*O 
~.~ For an inelastic collision, the new position (xi+t ,Yj~t ) is given by: ' yj+t = Yi + rn(yl --yj+l) 
xf+l = Xi + rt(xl --Xj+I) where r, is the coefficient of normal reflection, and r, is the coefficient 
of tangent reflection. The advantage of such a scheme is that the collision detection calculation is 
simple to compute. It is equivalent to intersecting a ray with a surface. Note that the collision calcu- 
lation is done in the static coordinate frame of the constraint, so that Pj and Pj,i take account of 
the motion of the constraint relative to the world coordinate system between successive time steps. Another 
advantage is that the points are guaranteed not to penetrate the constraint. Impulse based constraints 
are most easily implemented when used in combination with Euler integration. vi+l = v i +a i At xj+t 
= xj + vj At + ~a i At 2 This is slower to converge than higher order methods such as the Runge-Kutta 
[14] or predictor-corrector methods [6], which assume that the forces vary smoothly as a function of 
time. These higher order methods have to be restarted when impulse based techniques are used. For such 
methods the con- straints are usually expressed as a force of repulsion as the par- ticle approaches 
the surface. The more localised the force, the smaller the time-step needed for correct integration. 
As explained later, forces such as directional friction can occur very suddenly, so this paper was illustrated 
using Euler integra- tion, although the physical principles would apply equally well to other techniques. 
Unfortunately, applying constraints to the point masses is not a general solution to collision detection. 
Sharp discontinui- ties in the constraints, such as at a cliff edge, should be tested against the edges 
of the cubes as well as the vertices. So there should really be both particle-surface and edge-surface 
colli- sion detection. This will be especially important when creatures interact with each other and 
with themselves. However, for this paper the actual locomotion of snakes and worms was of primary interest, 
so the constraints were kept simple: a horizontal floor and a rounded cliff edge. 4. Muscle Contractions 
and Directional Friction In order to make the mass-spring systems move it is necessary to exert forces 
on the masses. This may be done globally using gravity and viscous drag [12] and directly, using force 
vectors applied to individual masses. This is equivalent to having a rubber puppet with strings and rods 
pulling and pushing it. However, to make the model look really alive it is necessary to generate the 
motive power internally. The mass- spring system must use frictional forces with constraints and changes 
of shape to achieve locomotion. Walking is one exam- pie of using friction to move the centre of mass. 
One foot stays in place on the ground as the other is moved through the air. In this way the frictional 
force with the ground is exploited whilst the geometry is reconfigured. Lifting feet is necessary because 
the frictional forces are isotropic i.e. they are independent of the direction in which the foot is slid. 
Sliding one foot forward causes the other foot to slide back equally far if the pressure on each foot 
is the same, hence the nee d to change pressure from one foot to the other. Snakes and v~orms, on the 
other hand, remain in contact with the ground at~all times (sidewinding is an exception to this). So, 
in order to get along, they must have frictional forces which vary with the direction of sliding. This 
is achieved by the scales which cover the skin. Just as the microstructure of a surface affects its macroscopic 
optical pro- perties, the small scale features of an object determine the fric- tional forces generated 
when it interacts with its environment. If the body segment moves forwards, the scales slide rela- tively 
easily over the ground exerting little friction. When the body segment slides backwards, however, the 
scales dig in and the frictional force suddenly becomes very great. Worm locomotion is a simple application 
of this idea. Figure 2 illus- trates a two mass, one spring worm. A B  < I > J Direction of Movement 
Figure 2. A two mass, one spring worm. If the spring is expanded (1 increased) scale B will slide over 
the ground and scale A will grip. If the spring is con- tracted (1 decreased) scale B will dig in and 
scale A will slide, Both these motions lead to the system travelling in the same direction, so oscillating 
the spring length as a function of time will lead to forward motion. A real worm, of course, consists 
of a number of such see- tions. If all of the spring lengths were varied in phase, only the front and 
back most scales would ever grip the floor. All of the intermediate scales would be constantly sliding. 
So, to prevent undue stresses at either end, a worm sends waves of compres- sion from its head to its 
tall. The familiar worm-like motion results. In a real worm the travelling compression wave seems to 
be approximately a square-wave, Unfortunately, because of the coarse nature of the mass-spring approximation, 
square-waves lead to peculiar distortions of the shape of the worm. However, a travelling sine-wave gives 
well-behaved and acceptably realistic results for the worm. In the computer simulation, the directional 
friction was implemented as follows. The local forward spine unit vector was computed from the centre 
of the next and last segments. ~= I~+t-~-i I The velocity was then modified as follows : if (~. ~ < 0.0) 
~= ~-~(~. ~) This stops any backwards sliding of the worm. The fric- tional effect was only applied 
if the point mass was less than a certain distance from the floor so that is could be said to be in contact. 
Because the model is a dynamic one, it was possible to apply gravity as well. Image la shows a worm in 
free-fall colliding with the constraint, in this case a book. The nose slides forwards on impact. Image 
lb shows the body mostly in contact, the tail exhibits a little "bounce". Image lc shows the worm wriggling 
towards a vertical edge. The front begins to bend downwards under the weight. Image ld shows the worm 
sliding off the edge. The tail flops over with the momentum from the sliding. In a real worm, as the 
muscles contract they bulge out. This may be included in the model by making the circumferen- tial spring 
lengths increase as a function of the axial compres- sion. The model used for this animation was to keep 
the total volume of the worm constant, Ill/1 along the worm was used to scale the value of L for the 
springs around the circumference of the worm. This then helps to conserve volume. The anatomy of a snake 
is very different from a worm, both in its internal structure and in the formation of its scales (squamation). 
Snakes have a skeleton with a flexible spine and ribs. The scales on a snake are diamond shaped on tlie 
upper part, but on the bottom they are a linear array of slanted blades. Snakes come in a wide variety 
of shapes and sizes ]8] but move in only four basic ways, just as there are various "gaits" for four-legged 
figures [4]. The worm motion described above is called "rectilinear progression" and is achieved by the 
snake sliding its skin over its ribs [7]. The more familiar sinusoidal motion is called "hor- izontal 
undulatory progression". To model this, compression waves are again sent down the mass-spring system, 
but the springs on the left hand side of the snake are 180 degrees out of phase with those on the right 
hand side. This has the effect of bending the snake into the familiar waves. The directional friction 
with the floor leads to the snake being propelled along. When a snake has a good grip on the ground and 
has highly curved coils and is moving slowly, the body segments all follow along the same curve. It is 
as if the cross-sections of the snake follow along the same spline curve at constant distances. Indeed 
this technique has been used to model and animate snakes [2] and [10]. How-ever, if the snake only has 
a poor grip on the surface, or if it is acted on by external forces, or if it is changing the amplitude 
of its coiling, then the segments will slide sideways as well. Image 2a shows the mass spring system 
"at rest" with no muscle tensions. Image 2b shows the effects of undulations deforming the snake. The 
head-end has stayed virtually fixed while the tall is dragged forwards as the coils form. Image 2c shows 
the snake with the coils fully formed. Little forward motion of the head-end has been achieved. Image 
2d shows the snake at a later stage. The segments are now all very nearly following each other along 
the same path. The dynamic snake model is interesting in the way that it deviates from the spline following 
paradigm. The tail, because it is not laterally constrained, swishes slightly from side to side. (It 
looks like a happy snake). In addition, the mass spring sys- tem has secondary reactions to the spring 
contractions and the friction. This leads to a slightly irregular motion of the snake which looks both 
convincing and realistic. Finally, of course, the snake can fall under gravity and collide with constraints 
in the same way that the worm did. A third form of snake locomotion is called "sidewinding". When grip 
on the ground is poor such as in open areas of sand, some snakes adopt a method of reducing their contact 
area with the sand so that the effective pressure increases. This also prevents undue heat exchange with 
the hot sand. This motion may be achieved using a vertical sinusoidal flexing of the snake which is 90 
degrees out of phase with respect to the hor- izontal undulations. The vertical flexing has the effect 
of lifting all but a small portion of the snake off the ground. The wavelength used for the simulation 
in this paper was the length of the snake divided by 1.4. Image 3a shows the sidewihder as the coils 
are forming. The back arches and the contact with the ground is localised. Image 3b shows the snake reaching 
its fully coiled state. Image 3c shows the snake as progression begins to take effect prop- erly and 
Image 3d shows the snake at a later time. The ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 I diagonal nature 
of the locomotion is apparent. The fourth form of snake locomotion is called "concertina progression" 
and involves successive flexing and straightening of the snake. It is only very rarely used and has not 
been simu- lated by the author. Whilst most snakes are not adept at flexing their backs vertically in 
a sinusoidal fashion through large amplitudes, creatures such as caterpillars are. Since the underside 
of the caterpillar is lifted and thrust forward and then placed down again, there is no need for directional 
friction. Instead it is better to eliminate all tangential movement for any segments in contact with 
the surface. This gives the caterpillar the ability to scale steep gradients both up the slope and down. 
Image 4a shows the caterpillar at rest. The fanciful creature shown, called the Arctic caterpillar, is 
covered in fur to highlight the changes in orientation of the surface. Image 4b shows the caterpillar 
arching its back. 5. Timings for the Dynamics The dynamics calculations for the snake animations took 
30 seconds per frame on a Silicon Graphics 4DF/0 workstation. In part this was due to the implementation 
in a convenient but interpreted procedural modelling language (Alias SDL) and in part it was due to the 
comparatively unstable nature of Euler integration. 25 subintervals per frame were used to ensure accuracy 
in the animation of the snakes. For the less rigid worms this was reduced to 10 subintervals. The different 
creatures were animated using different values for the spring constants and the damping. The worm had 
a k spring strength of 1.5 and a damping D value of 0.9. The worm tends to bounce on contact with the 
floor and as it dangles over the edge of the book it takes on interesting chain- like oscillations. The 
snake, on the other hand, used a k of 0.5 and a D of 3.5, The difference is that the snake swishes its 
tail as it moves. Too httle damping leads to standing waves in its body wtiich interfere with locomotion 
and mean that the snake is in danger of shaking itself to pieces. The caterpillar had a k of 0.3 and 
aD of 0.6. 6. Rendering Worms, Snakes and Caterpillars In order to render the snakes and worms, the 
lattice of masses was used to create control points for cardinal bicubic parametric patches. They were 
generated so that the cross-sections of the snakes and worms just touched the edges of the lattice. This 
prevented any possible intersections with the ground plane. The worms for this paper were rendered using 
a colour map and a bump map [1]. The colour map gave the pink underside and the grey top. The bump map 
gave the wrinkles in the skin. The snake in Image 5 was rendered using a bump map and a colour map for 
the scales. The depth value for the scales was also used to blend between the texture mapped "markings" 
and the underlying skin eolour. The hairs on the caterpillar were modelled as separate pieces of geometry. 
The roots of the hairs were generated as a dithered lattice in param- eter space for each patch. The 
other end of the hairs were com- puted using linear combinations of the tangent vectors and the surface 
normal at the root to offset from the root position. This technique is discussed in more detail in [9]. 
The individual hairs in Images 4a to 4d als0 had collision detection with the floor. In the event of 
penetration of the ground plane, the hairs were individually rotated upwards about their roots until 
the ends were just in contact with the ground. This approach is trivial for an extended planar surface 
but would be more difficult for arbitrary obstructions. The hairs for these images were composed of three 
forward-facing triangles arranged in the form of a cone. The results were raycast with supersarn- piing 
everywhere to avoid aliasing. Each hair was colour mapped along it length. The tips of each hair were 
black whilst the roots were white. The caterpillar images at 500 lines reso- lution each took 0.5 hours 
to render on a Silicon Graphics 4D170 workstation. 7. Areas for Future Work Now that the basic principles 
of legless figure locomotion have been implemented it is necessary to improve the collision detection 
computations. This will allow several snakes or worms to interact with each other and will enable the 
snakes to coil up without penetrating themselves. The task of directing the snakes to specific action 
needs to be investigated, giving the creatures goals and path planning skills. On a different tack, the 
dynamic models for legless creatures may be com- bined with legs to extend the models to such creatures 
as cro- codiles and Chinese dragons which use their tails for locomo- tion extensively. 8. Acknowledgements 
This research took place at Alias Research Inc. in Toronto as part of the Natural Phenomena Project. 
Thanks to Alias for encouraging this work. A big thank you to Patrieia Anderson at Alias for modelling 
the snake head, to Freddi Gitelman for modelling the background to the worm sequence, and to Jim Craighead 
and Bob Leblanc for additional help with the snake rendering, and to Andrew Pearce, Steve Williams and 
Gary Mundell for help with the background to Image 6. A special thank you to David Ross for revealing 
to me the joys and com- plexities of procedural motion. Finally, thanks to Eileen O'Neill for introducing 
me to the beauty of snakes, and for leading the worm hunt without which the images in this paper would 
have been much less realistic. 9. References 1. Blinn, James F. "Simulation of Wrinkled Surfaces." Com- 
puter Graphics, Vol. 12, No. 3, August 1978. 2. Coquillart, Sabine, "A Control-Point-Based Sweeping 
Tech- nique", IEEE Computer Graphics and Applications, November 1987 pp 36-45. 3. Culhane, John, "Special 
Effects in the Movies", Hilltown Press, Inc., ISBN 0-345-34536-3, November 1981. 4. Gira-d, Michael 
and Anthony A. Maciejewski, "Computa- tional Modelling for the Computer Animation of Legged Figures", 
Computer Graphics, Vol. 19, No.3, July 1985 pp 263-270. 5. Isaaes, Paul M. and Michael F. Cohen, "Controlling 
Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics", Computer Graphics, 
Vol. 21, No. 4, July 1987 pp 215-224.  6. Johnson, Lee W., R. Dean Riess, "Numerical Analysis", Addison-Welsey 
Publishing Company Inc. 1982. ISBN 0-201-10392- 3. 7. Klauber, Lawrence M., "Rattlesnakes", University 
of Cali- fornia Press, 1982. ISBN 0-520-04039-2. 8. Mehrtens, John M., "Living Snakes of the World", 
Sterling Publishing Co. Inc., New York. Blandford Press Dorset, England. 1987. ISBN 0-8069-6460-X. 9. 
Miller, Gavin S. P., "Computer Display and Manufacture of 3-D Models", Ph.D. thesis, June 1987, Cambridge 
University Engineering Department, Cambridge, Eng- land. 10. O'Neill, Eileen, personal communication 
Nov. 1987.  11. Reynolds, Craig W., "Hocks, Herds and Schools : A Distri- buted Behavioral Model", Computer 
Graphics, Vol. 21, No. 4, July 1987 pp 25-34. 12. Terzopoulos, D., J. Platt, A. Barr, K. Fleischer, 
"Elastically Deformable Models", Computer Graphics, Vol. 21, No. 4, July 1987 pp 205-214. 13. Waters, 
Keith, "A Muscle Model for Animating Three- Dimensional Facial Expression", Computer Graphics, Vol. 21, 
No. 4, July 1987 pp 17-24. 14. Willhelms, Jane and Matthew Moore, "Dynamics for Everyone", Appendix 
1, SIGGRAPH '87 Course 10, Computer Animation : 3-D Motion Specification and Control pp 145-146.   
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378509</article_id>
		<sort_key>179</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[A modeling system based on dynamic constraints]]></title>
		<page_from>179</page_from>
		<page_to>188</page_to>
		<doi_number>10.1145/54852.378509</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378509</url>
		<abstract>
			<par><![CDATA[We present "dynamic constraints," a physically-based technique for constraint-based control of computer graphics models. Using dynamic constraints, we build objects by specifying geometric constraints; the models assemble themselves as the elements move to satisfy the constraints. The individual elements are rigid bodies which act in accordance with the rules of physics, and can thus exhibit physically realistic behavior. To implement the constraints, a set of "constraint forces" is found, which causes the bodies to act in accordance with the constraints; finding these "constraint forces" is an <i>inverse dynamics</i> problem.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[contraints]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39036514</person_id>
				<author_profile_id><![CDATA[81100296840]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ronen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barzel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034821</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, William W., and Mark W. Green, The dynamics of articulated rigid bodies for purposes of animation, in Visual Computer, Springer-Voting, 1985, pp. 231-240.]]></ref_text>
				<ref_id>Armstrong and Green 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H., Geometric Modeling and Fluid Dynamic Analysis of Swimming Spermatozoa, Ph.D. Dissertation, Rensselasr Polytechnic Institute, 1983]]></ref_text>
				<ref_id>Barr 83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H., Topics in Physically Based Modeling, to appear, Addison Wesley]]></ref_text>
				<ref_id>Barr 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan H., Brian Von Herren, Rouen Barrel, and John Snyder, Computational Techniques for the Self Assembly of Large Space Structures Proceedings of the 8th Princeton/SSI Conference on Space Manufacturing, Princeton New Jersey, May 6-9 1987, to be published by the American Institute of Aeronautics and Astronautics.]]></ref_text>
				<ref_id>Barr, Von Herzen, Barzel, and Snyder 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Boycu, William E., and DiPrima, Richard C., Elementary Differential Equations and Boundary Value Problems, John Wiley &amp; Sons, New York, 1977.]]></ref_text>
				<ref_id>Boyce and Deprima 77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Caltech studies in modeling and motion (videotape), in SIGGRAPH video Review #28, Visualization in Scientific Computing Computer Graphics, volume 21 number 6. ACM SIG- GRAPH, 1987]]></ref_text>
				<ref_id>Caltech '87 Demo Reel</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fox, E.A., Mechanies, Harper and Row, New York, 1967]]></ref_text>
				<ref_id>Fox 67</ref_id>
			</ref>
			<ref>
				<ref_obj_id>540426</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gear, C. William, Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-Hall, Englewood Cliffs, NJ, 1971]]></ref_text>
				<ref_id>Gear 71</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Goldstein, Herbert, Classical Mechanics, 2nd edition, Addison-Wesley, Reading, Massachusetts, 1983.]]></ref_text>
				<ref_id>Goldstein 83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Golub, G., and Van Loan, C., Matrix Computatlons, Johns Hopkins University Press, Baltimore, 1983.]]></ref_text>
				<ref_id>Golub and Van Loan 83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Isaacs, Paul M. and Michael F. Cohen, Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions, and Inverse Dynamics, Proc. SIGGRAPH 1987, pp. 215-224]]></ref_text>
				<ref_id>Isaacs and Cohen 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lengyel, Jed, Dynamic Assembly and Behavioral Simulation of the Flagellar Axoneme, in Caltech SURF Reports, 1987]]></ref_text>
				<ref_id>Lengyel 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lien, Sheue-ling, and James T. Kajiya, A symbolic method for calculating the integral properties of arbitrary nonconvex polyhedra, IEEE Computer Graphics and Applications, Vol. 4 No. 10, Oct. 1984, pp. 35-41.]]></ref_text>
				<ref_id>Lien and Kajiya 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Misner, Charles W., Kip S. Thorae, and John Archibald Wheeler, Gravitation, W.H. Freeman and Co., San Francisco, 1973.]]></ref_text>
				<ref_id>Misner, Thorne and Wheeler 73</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42249</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Press, William II., Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling, Numerical Recipes in C/The Art of Scientific Computing, Cambridge University Press, Cambridge, 1988.]]></ref_text>
				<ref_id>Press et. al. 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Platt, John, and Alan Barfs Constraints on Flexible Objects, Submitted to SIGGRAPH 1988.]]></ref_text>
				<ref_id>Platt and Barr 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Ralston, Anthony, and Philip Rabinowitz, A First Course in Numerical Analysis, McGraw-Hill, New York, 1978.]]></ref_text>
				<ref_id>Ralston and Rabinowitz 78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325242</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Shoemake, Ken, Animating Rotation with Quaternion Curves, Computer Graphics, Vol. 19 No, 3, July 1985. pp. 245-254.]]></ref_text>
				<ref_id>Shoemake 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Terzoponlos, Demetri, John Platt, Alan Barr, and Kurt Fleischer Elastically Deformable Models, Proc. SIGGRAPH, 1987, pp. 205-214.]]></ref_text>
				<ref_id>Terzopoulos, Platt, Fleischer, and Barr 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Witkin, Andrew, Kurt Fleiascher, and Alan Barr, Energy Constraints on Parametrized Models, Proc. SIGGRAPH 1987, pp. 225-232]]></ref_text>
				<ref_id>Witkin, Fleisher, and Barr 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, Jane, and Brian Barsky Using Dynamic Analysis To Animate Articulated Bodies Such As Humans and Robots, Graphics Interface, 1985.]]></ref_text>
				<ref_id>Wilhelms and Barsky 85</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Modeling System Based On Dynamic Constraints Rouen Barzel Alan H. Barr California Institute of Technology 
Pasadena, Abstract We present "dynamic constraints," a physically-based technique for constraint-based 
control of computer graphics models. Using dynamic constraints, we build objects by specifying geometric 
constraints; the models assemble themselves as the elements move to satisfy the con-straints. The individual 
elements are rigid bodies which act in ac-cordance with the rules of physics, and can thus exhibit physically 
realistic behavior. To implement the constraints, a set of "constraint forces" is found, which causes 
the bodies to act in accordance with the constraints; finding these "constraint forces" is an inverse 
dynamics problem. KEYWORDS: Modeling, Dynamics, Constraints, Simulation CR categories: 1.3.5--Computationai 
Geometry and Object Modeling; 1.3.7--Three-Dimensional Graphics and l~ealism 1 Introduction Some of 
the most natural and graceful motion in computer anima- tion has been achieved recently by simulating 
the physical behavior of objects. But physical simulation has not yet become the standard technique for 
modeling and animation, because of several limitations: Simulations are hard to implement: Typically, 
a special-purpose program is written to simulate the behavior of a given computer graphics model; the 
overhead for making new models is large.  Simulations are hard to control: If "innate" behavior is pro- 
grammed into models, it becomes hard to make the models do exactly what we want; the behavior is often 
determined indirectly by non-intuitive or non-orthogonal parameters.  i Simulations are slow: Physical 
simulation can be computationally intensive. The goal of this work is to develop a modeling system in 
which it is easy to build and animate physically-based computer graphics models. To this end, our modeling 
approach is based on four features: Generality: A model is built from a collection of primitive physically-based 
elements.  Geometric Constraints: A model is constructed by applying con- straints to the objects, starting 
from an initial configuration of the primitive elements. A model is also positioned and animated through 
constraints.  Newtonian Mechanics: Each primitive element is a rigid body whose motion is due to the 
effects of inertia and forces and torques acting on the body. Many of the forces and torques are externally 
applied; other forces and torques, however, are derived from the geometric constraints.  Equivalence 
of Modeling and Animation: The temporal behavior of physically based objects is bound up in the model 
itself.  To implement the constraints, we solve an inverse dynamics prob-lem: given constraints on the 
behavior of the model, the problem is to determine the forces which result in an example of the constrained 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. @1988 AC M-0-89791-275-6/88/008/0179 
$00.75 CA 91125 ~gravlty ~gravity i i i i V b. Figure 1: All primitive bodies obey Newton's laws. e.g. 
(a) A ball released in gravity falls; (b) A ball thrown in gravity moves in an arc. behavior we desire. 
Thus, we convert each constraint into a "constraint force"; as the model animates, the constr~.int forces 
are continuously computed, to continuously maintain the constraints. Sec. 2 of this paper presents the 
modeling system, and provides implementation notes. Sec. 3 discusses the inverse dynamics problem. See. 
4 presents the technique for setting up and solving a "constraint-force" equation. The simulation of 
Newtonian mechanics, derivations for various examples of constraints, and miscellaneous mathematical 
details are found in the Appendices. Related Work [Witkin, Fleischer, and Barr 87] uses "energy" constraints 
to assem-ble 3D models, for changing the shape of parametricaily-defined primitive objects. This work 
is not concerned with dynamic me-chanical simulation of models. [Platt and Barr 88] uses augmented lagrangian 
constraints in the physical simulation of flexible ob-jects. [Isaacs and Cohen 87] does physical simulation 
of rigid bod- ies, for the special ease of linked systems without closed kinematic loops. They share 
our emphasis on ease of modeling, and also use an inverse-dynamics formulation to control the models' 
behavior. [Wilhelms and Barsky 85] utilizes physically based modeling, but has a reduced emphasis on 
control. 2 The Modeling System Modeling with the "Dynamic Constraints" system consists of instan- tiating 
primitive bodies, connecting and controlling them with con-straints, and influencing their behavior by 
explicitly applying external forces. The modeling system thus has three libraries: Primitive bodies: 
A collection of rigid .bodies, such as spheres, rods, torii, and more complex shapes, that are the component 
elements of models. The modeler specifies the body density, as well as specific parameters such as the 
length and radius of a rod. Each body type defines the quantities needed for physical simulation, such 
as the rotational inertia tensor for that body type.  Exlernal applied forces: Forces that the modeler 
can introduce into the model, including gravity, springs, and damping forces. Each force has parameters 
specific to the force, such as damping coefficients or spring constants.  Constraints: Various types 
of geometric constraints, such as :'point-t~nail" or "orientation" are described below.  To build a 
model, we make instances of objects, calculate the forces, and run the simulation. We also specify "timelines" 
of events to take place, such as creating or removing instances, turning constraints or explicit forces 
on or off, or otherwise adjusting parameters. 2.1 Newtonian Mechanics Fig. 1 illustrates one of the simplest 
examples of a body obeying New- ton's laws. This behavior is easy to simulate: Appendix A describes the 
general newtonian simulation procedure.  i' ? 179 J: .. f SIGGRAPH '88, Atlanta, August 1-5, 1988 
a. A rod floating in . , ~ Sp&#38;C~: S\ b. User constrains end of rod to a '%nil" : J aR c. End of 
rod flies to nail: / stays ~naiI  d. Introduce grav- ity; Pendulum swings: ///~ ........ ~  Figure 
2: "Point-to-nail" constraint. A user creates a pendulum by fix- ing an endpoint of a rod at some location 
in space. The constraint causes the rod to "fly" into place, assembling the pendulum. See videotape [Caltech 
'87 Demo Reel]. All primitive bodies in our system exhibit physically realistic her havior, in the sense 
that they respond correctly to forces and torques. 2.2 Constraints We show some examples of constraints 
supported by our modeling sys- tem. "Point-to-Nail" constraint (see Fig, 2): This fixes a point on a 
body to a user-specified location in space. The body may swivel and swing about the constrained point, 
but the constrained point may not move.  "Point-to-Point" constraint (see Fig. 3): This forms a joint 
be- tween two bodies. The bodies may move about freely, as long as the two constrained points stay in 
contact.  "Point-to-Path" constraint (see Fig. 4a): We can require a point on an object to follow an 
arbitrary user-specified path; this al- lows us to animate models by using standard kinematic keyframe 
techniques.  "Orientation" constraint (see Fig. 4b): A constraint to align ob- jects by rotating them. 
 Other constraints (not illustrated): Other constraints include "point-on-line," which restricts a point 
to lie on a given line, and "sphere-to-sphere, 'j which requires two spheres to touch, but lets them 
slide along each other.  We can easily add new types of geometric constraints to our con- straint library, 
by defining the constraint "deviation" function and de- riving various required quantities, as described 
in Appendix C. The only restriction is that the "deviation" function be twice-differentiable (as is discussed 
in the appendix). 2.3 Constraint Forces When we have built a model using dynamic constraints, the model 
is held together by constraint forces, as illustrated in Fig. 5. Thus the constraint forces are analogs 
of the internal forces which hold the parts of compound objects together. Constraint forces also assemble 
the models, pulling the com-ponents into the proper configurations. Thus constraint forces represent 
forces which could be used to assemble real-world ob-jects. For example, figures in the appendices show 
frames from animations demonstrating the self-assembly of space structures [Burr, Von Herren, Barrel, 
and Snyder 87]. 180 a. Pendulum of /n/nil Fig. 2d, and a sec- ond rod: f b. User constrains ends of rods: 
stays ~natl  c. Ends of rods fly f..xe/d~{ together: ////.~f ~nail stays ~ I[ fixed~ d. Introduce gray- 
gravity  ity; Compound pendulum swings: ~---~ fj" Figure 3: A "point-to-point ~ constraint. A users 
adds a second rod to the pendulum of Fig. 2, to create a compound pendulum. See videotape [Caltech '87 
Demo Reel]. Figure 4: Other constraint examples. (a) "Point-tc-path ~ constraint. This constraint pulls 
objects along user-specified paths. (b) "Orientation" con-straint. We rotate the rod to make its axis 
parallel to the slot axis. 2.4 Implementation We describe here the high-level program structure; details 
of simulat- ing Newtonian mechanics are given in Appendix A, the procedure to calculate the constraint 
forces is given in Sec. 4.4. Our modeling system is implemented in Common Lisp on Symbolics Lisp Machines, 
using Symbolics' object-oriented "Flavors" mechanism. The fundamental object classes we have defined 
are: rigid-body: a primitive body in the model. This class defines the functions and state variables 
needed for the dynamics calculation (see Appendix A), including a list of forces and torques acting on 
the body. There are subclasses for each type of body in our library; each subclass provides type-specific 
information, such as the rotational inertia tensor.  control-point: a point on a body, or in space. 
A point on a body contains a reference to the body, as well as the position of the point in body-coordinates. 
A point in space defines its position, which can be constant, or a function of time. Forces and con-straints 
are typically created by specifying the control-points at which they act.  force: a force being applied 
to a body. Each force contains a reference to a control point at which it is applied. There are subclasses 
for each type of force in our library; each subclass provides a function that computes the force.  constraint: 
any type of dynamic constraint. There are subclasses for each type of constraint in our library. Each 
subclass provides  H ,sail '\\, ",, ", F2 /" 122 a. Forces on upper rod b. Forces on lower rod Figure 
5: Constraint forces holding together compound pendulum of Fig. 3d. The constraint forces model the internai 
forces of a real-world pendulum. (a) shows forces on the upper rod, (b) shows forces on the lower rod: 
.Fg is gravity pulling down on rods. F1 is the "point-to-nail ~ constraint force on the upper rod, holding 
it at the nail. F2 is the "point-to-point" constraint force on the lower rod, holding it to the upper 
rod; -F2 is the reaction force on the upper rod. the quantities needed to determine the constraint force 
(described in Appendix C). Each constraint also keeps references to the bodies being constrained, and 
associates the appropriate forces with the bodies. All objects handle a "draw" message, which displays 
the object in its current state. For debugging a model, we send the "draw" mes-sage to all objects, including 
forces, control points, and constraints; for producing an animation, we send the "draw" message only 
to bodies. Some examples of subclasses are:  rod: a subclass of rigid-body. This class provides the 
values spe- cific to rods, e.g. the rotational inertia tensor (see Appendix A). The cl~ also associates 
two control points with each rod, named "endl" and "end2", at the ends of the rod, and provides functions 
to access them.  nail: a control point fixed at a location in space.  point-to-nail: a subclass of 
constraint. Provides the functions which calculate the terms needed for a "point-to-nail" constraint 
(see Sec. 4, Example 1).  The addition of new types of bodies, forces, or constraints to the system 
merely requires the creation of an appropriate new subclass. Currently, the user-interface is via the 
lisp environment; for exam- ple, the pendulum of Fig. 3 could be built via the series of commands: ; 
create bodies and control points (make rod "upper-rod") (make rod "lower-rod") (make nail "nail" 0 
0 100) ; specify consfraints (connect (endl "upper-rod" ) "nail")  (connect (end2 "upper-rod") (end1 
"lower-rod"))  ; add e~teraalforces (gravity-on) ; apply gravity to each body To animate a model once 
the instances are made, we simply iterate these steps: Simulate until end of frame (Appendix A).  Send 
"draw" message to objects.  The implementation makes heavy use of a home-grown pack- age of numerical 
routines, which include linear-system solvers, dif-ferential equation solvers, and the like; some useful 
references are [Press et. al. 88,Golub and Van Loan 83,Ralston and Kabinowitz 78, Boyce and Deprima 77]. 
We also have embedded into lisp an exten-sion to "Einstein Summation Notation" for mathematical expressions 
[Barr 83,Misner, Thorne and Wheeler 73]; this makes it quite simple to create lisp functions by merely 
typing in the mathematical formulae using the same notation with which we derive them.  Inverse Dynamics 
 If we are given the forces which act on a collection of objects, we can easily solve the forward dynamics 
problem--that of determining the objects' behavior---as described in Appendix A. However, to meet constraints, 
we must solve the reverse problem: Given a partial de- scription of the desired behavior, we must determine 
forces which will yield an appropriate behavior. This inverse dynamics problem, sum-marized in Fig. 
6, consists of two pa~ts: (a) finding forces to meet a constraint, and (b) finding forces to maintain 
a constraint. InverseDynamics Problem: Given: A constraint /    / ~?~ Find: A force: /j~ ?:......... 
 (~) Such that body moves to meet constraint, and Such that constraint stays (b) gravity~ / ~'x~it~l~ 
met, despite motion and other forces. ........ .. Figure 6: The inverse dynami¢~ problem for dynamic 
constraints. Assembling a model: a. Given 8 constraint to be met: b. Introduce force:  constraint to.nail 
~> '¢'-- force c. Force pulls object: d. Force slows object: e. Constraint is met:  nil Figure 7: 
Meeting a Constraint. The constraint force pulls the ball towards the nail, then brings the ball to rest 
at the nail. Meeting A Constraint Fig. 7 shows a constraint force being used satisfy to part (a) of the 
in- verse dynamics problem, that of moving the objects to meet an initially unmet constraint. Notice 
that this part of the problem is actually very loosely specified: How quickly should the constraint be 
met? Along what path should the object move? For our solution, as we shall see in Sec. 4.2, the "deviation" 
of the constrained point decays exponentially, with a user-specified time constant. Maintaining A Dynamic 
Constraint Fig. 8 shows a dynamic constraint force adapting to satisfy part (b) of the inverse dynamics 
problem, that of keeping a constraint met de- spite motion and other forces. There is typically a unique 
solution, in which the dynamic constraint forces provide the internal forces that hold together an object. 
 @ ~ Computer Graphics, Volume 22, Number 4, August 1988 o. /'-;-_ . = -~ "2o "g0 "g0 "~0 * ~o ~o= 
~(..2-~o) eo b. c. d. e. f. g. t= to t=to +0.3¢ t = to +0.6~- t = t0 +0.9~- t =to+2.0~ t > to + 6.o.r 
Figure 10: Constralut-force calculation for a "point-to-nail" constraint (details in Sec. 4.2): Constraint 
force has components opposing gravity (-Fs), opposing motion (-ff~), and pulling towards hall (--ffD)- 
(a) User specifies constraint at center of mass. (b) Constraint force initially pulls towards nail. (c-e) 
Once ball is moving towards nail, constraint force turns around. (f) Constraint force slows ball. (g) 
Steady-state: ffD = Z~v = O, fie = --ff#. Net force on ball is 0; by Newton's first law, the bail remains 
at rest. Example 1: "Point-to-Nail" Constraint. We choose D to be the! vector from the constrained point, 
at J~p, to the "nail", at ~0 (see Fig. 9). i We thus have: d =3 ~(Y) =2p-20 The differentiation in Appendix 
B.2 immediately gives us the quantities: ~o)(y) ~p(y) = A = ~*TI-a = b'Tl -x (L x 5) + ~ x (~ x b') 
We apply an arbitrary force to the constrained point. The ~constraint force" ff¢ is used directly as 
a force on the body, and it contributes ~'x ff¢ = b*ff¢ to the torque. Thus we define: f =3 G = i SeeAppendix 
Cforotherexamplea. H = b* initially, constraint ff isu't met. ~gD0 #0 Do lmcon-%. D decreases strained 
% /~ov~ time. later~ motion %,/ constraint % is met; (o,0) 4 to -~ 27" to -~ 4~" to -~ 6~r time Graph 
of solution to: ~D.D+ 2 ~D+ l~D=O,t>to Figure 12: D evolving over time. We have picked a second-order 
differential equation to describe D as a function of time. The solution yields the behav- ior required 
by the inverse dynamics problem--the constraint "deviation" decays down to 0, assembling the model, then 
remains at 0, maintaining the constraint. The-rate of assembly is controlled by the time constant r. 
See [Boyce and Deprima 77] for a discussion of second-order differential equa- tions. Substituting Eqn. 
2 into Eqn. 4, we get the constraint-force equation for a single constraint: Example 2: "Polnt-to-Nail" 
Constraint. In Fig. 10, we illustrate a simple case: A single body, with a ~point-to-nail" constraint 
acting at its center-of-mass, and with gravity. Since both the constraint force and gravity act on the 
balrs center-of-mass, there are no rotational terms. Thus the quantities in Example 1 reduce to: b=b" 
=4= ~=H =2~E =0 L5 = X-Xo .3(2) = ~-# r "v i~ = ~ Substituting into Eqn. 5 gives: . We easily solve for 
the constraint force: Thus we see the constraint force has three components: One opposing the force of 
gravity, one opposing the ball's velocity, and one pulling the bail towards the nail. Fig. 10 illustrates 
the constraint force adapting to pull the ball to the nail, and bring it to rest. Once the ball is at 
rest at the nail, we have )~ -- J~0 = 0 and ~ = 0; so the constraint force becomes ffc = -fig, yielding 
a net force on the bali of ff = ~c + ~g = 0 coastraimt* j bodies i + ~ ,r'~'s + A'~) = o (5) bod|.$ 6 
+/~+ _2r l~(r) + ~/~1 Notice that, to meet this one constraint, we must take into account the effect 
of all the constraint forces. See Example 2 for a sample derivation of the constraint forces. 4.3 Multiple 
Constraints Each constraint results in a version of Eqn. 5; with several constraints, we have a set of 
simultaneous equations which must be solved. We duplicate Eqn. 5, for each constraint in the model: coas~r&#38;ints 
j bodies , + ~ (r~+A~) bo diel i =o,{ forail constraints k (6) 'r~ k " ~"k: where we label terms for 
the kth constraint with subscript k's. Writ- ing this system of equations more compactly, as a multidimensional 
vector equation, we have the constraint force equation for the model:   SIGGRAPH '88, Atlanta, August 
1-5, 1988 i! where A4~ = ~ (rkG;- + AsH i) b2,d; e, i 7oj = F¢j (7) bodies i Fig. 13 illustrates collecting 
individual constr~nt equations into the multidimensional vector equation. Notice that each element of 
A4 is a matrix, and each element of Yc and of B is a vector. 4.4 Solving the Constraint-Force Equation 
Fig. 15 outlines the procedure to set up Eqn. 7, as well as solve it and compute the net force and torque 
on each body. In step 3 of Fig. 15, we call a standard linear-system solver to solve Eqn. 7. There are 
many well-known methods for solving linear sys- tems (see [Press et. aI. 88,Ralston and Rabinowitz 78]). 
We note some characteristics of .h4 that should be taken into account when choosing a solution method: 
 A4 is typically sparse. The [k,j]th entry in .M is non-0 only if some body is influenced by both constraint 
k and constraint j. Typically, most of the elements are zero.  .h4 is not necessarily square. A constraint 
may have d ~ f; for example, the "orientation" constraint (Appendix C.3) has d = 1 and f -- 3, yielding 
a matrix which is "wider" than it is "tall."  A4 may be singular, implying that Eqn. 7 is overconstrained 
or underconstrained.2  We most often use singular-value decomposition (SVD) to solve Eqn. 7, because 
it robustly handles singularity and near-singularity, as well as non-square systems. However, SVD does 
not take advantage of sparseness, and is a relatively slow technique. Underconstralned Equations Constraint-force 
equation Eqn. 7 will sometimes be underconstrained, thus having many solutions. This can occur, for example, 
when there are several constraints acting on a single body; it may be possible to vary some of the individual 
constraint forces without affecting the net torque or force on the object. An example is shown in Fig. 
14a, in which the pair of forces labeled "V" yield the same net force (= 21Yv) and torque (= 0) as the 
pair labeled "W". There is no difficulty caused by having many solutions to Eqn. 7; we could use any 
solution, since they will all yield satisfactory behavior. We might wish to use the solution which is 
smallest in magnitude, to avoid numerical difficulties; SVD yields this solution. Overeonstrained Equations 
eats In Fig. 14b, the user has specified constraints which can not be met; there is no "correct" constraint 
force to be applied. In Fig. 14c, the specified constraints can be met, but not by moving the constrained 
point in a straight line; however, Eqn. 3 requires that the point move in straight line if the constrained 
point is initially at rest. s For overconstrained systems, using the least-squares solution for the constraint 
forces typically yields "reasonable" behavior -the ob- ject typically assumes some intermediate configuration, 
for the case of Fig. 14b, or moves along the feasible path, for the case of Fig. 14e. SVD computes the 
least-squares solution for overconstrained systems. 5 Summary We have developed a modeling system featuring 
constraint-based con- trol of rigid bodies. The bodies' behavior is determined by simulation of Newtonian 
mechanics. We compute dynamic "constraint forces" to apply to the bodies such that they behave in accordance 
with user- specified geometric constraints; the computation of these forces is an inverse dynamics problem. 
The modeling system supports various types of geometric con-straints, such as "point-to-nail" and "point-to-point." 
The modeler builds objects by using constraints to connect primitive components; the constraint forces 
cause the components to assemble themselves into the model, and ensure that the model stays assembled 
as it animates. 2Unfortu_r~tely, we have some overloading of the word "constrairt': "overcon- strained" 
and "underconstrained" refer to the linear system of equations Eqn. 7", rather than to the constraints 
themselves. 3A solution to the problcxn of unrealizable paths is to use scalar constraint men- mares 
(d m 1}. For example, the "point-tc-nall" constraint could be redefined so that D is the distance from 
the point to the nail, rather thart the vector separating the point and the nail. nail / 0  LM , M,.j 
LF oj -r L ,j _ A4.~ + B = 0 Figure 13: Multiple constraints: Each constraint contributes one line to 
the equation. The collection of constraints together yields a set of simultaneous linear equations, expressible 
a~ a linear matrix equation. °%. u.d .... ,. tr~od ~11" b. hall Overcoxmtrai:~ <]::::=?= physically 
'~"x realizable ,k~ ath ¢. Overco~strained  / p.t~_y: ",,\. Figure 14: Under- and Overconstralned systems. 
(a) Underconstrained: Forces "V" and "W" yield the same net force. (b) Overconstrained: There is no way 
to meet both constraints. (c) Overconsttained: Both constraints could be met, but not via the path we 
have chosen. We have developed a technique to compute the constraint forces by setting up and solving 
a "constraint-force equation." The constraint- force equation is a multidimensional linear equation of 
the form .A4.T'¢ +/3 --0, where .~c is the collection of unknown constraint forces. Each constraint is 
described by a "deviation" measure Jg, such that /) = 0 when the constraint is met. D must be a twice 
differentiable function of the positions and orientations of the constrained bodies. Appendix C derives/~ 
for several types of constraints. 6 Future Work Further work we are interested in pursuing includes: 
* Expanding the constraint library. Deriving new constraint "devi- ation" functions, as described in 
Appendix C. Interactive graphical modeler. Object Intersection. Development of non-interpenetration 
con-straints  Flexible bodies. Incorporation of flexible-body simula-tion with dynamic constraint eontrol 
[Platt and Burr 88, Terzopoulos, Platt, Fleischer, and Burr 87].  Special-case models Direct implementation 
of the equations of motion for common objects, such as the linked systems of [Issues and Cohen 87,Arrr~strong 
and Green 85]. Decreeing the number of constraints in the model speeds up the constralnt-force calculation. 
 Constraints on velocity or acceleration. We are also looking forward to using the dynamic constraints 
mod- eling system as a tool in other research areas, such as molecular biology [Lengyel 87] and robotics. 
PROCEDURE TO COMPUTE FORCE AND TORQUE ON EACH BODY: ; 1. Compute net explicit forces and torques for 
each body i :for each explicit ~orce j on body i compute force ~si F~ ÷=FEj . T~ += bi x FEj end "for 
each explicit torque j on body i compute torque TEi T~ +=TE~ end end ; 2. Set up constraint.force equation 
initialize 2¢~ to 0 for each constraint k compute ~k, D; 1), and D~  S[k] = ~ + 2 130) + L/3~ ~ r k 
¢or each body i in constraint k compute r% ~td A~ .. B[k] += F'kF'E + A~T'E for each constraint j ac~in$ 
on i .A~ [k, j] + i i = ]2~Gj + A~H~ end end end ; $. Solve constraint-force equation (Eqn. 7) .To = 
solve(.M,B) ;linear-system solver ; ~. Compute net forces and torques. for each body i :for each constraint 
j acting on i end end Figure 15: The procedure to compute the coustralnt forces and the net force and 
torque on each body. See discussion in Sec. 4.4. Note that the [k,j]th clement of ~ is a dk × fj matrix, 
and the [kith element of B is a dk-dimensional vector. Rather than implementing 2¢1 as a "nested" array, 
it can be flattened into a (~ d) × (~ f) array; similarly, B is formed by concatenating the individual 
vectors into one (~ d)-dimensional vector. References [Armstrong and Green 85] Armstrong, William W., 
and Mark W. Green, The dynamics of articulated rigid bodies for purposes of animation, in Visual Computer, 
Springer-Voting, 1985, pp. 231-240. [BaH 83] Barr, Alan It., Geometric Modeling and Fluid Dynamic Analysis 
of Swimming Spermatozoa, Ph.D. Dissertation, Rensselasr Polytechnic Institute, 1983 [BaH 88] Barr, Alan 
H., Topics in Physically Based Modeling, to appear, Addison Wesley [Barr, Von Herzen, Barrel, ~nd Snyder 
87] Barr, Alan H., Brian Von Herren, Rouen Barrel, and John Snyder, Computational Techniques .for the 
Self Assembly of Large Space Structures Proceedings of the 8th Princeton/SSI Conference on Space Manufacturing, 
Princeton New Jersey, May 6-9 1987, to be published by the Ametica~ Institute of Aeronautics and Astronautics. 
[Boyce and Deprima 77] Boycu, William E., and DiPrima, Richard C., El- ementary Differential Equations 
and Boundary Value Prob-lems, John Wiley 8z Sons, New York, 1977. [Caltech '87 Demo Reel/ Caltech studies 
in .modeling and motion (video-tape), in SIGGRAPH video Review #28, Visualization in Scientific Computing 
Computer Graphics, volume 21 number 6. ACM SIC-GRAPH, 1987 [Fox 67] Fox, E.A., Mechanies~ Harper and 
Row, New York, 1967 [Gear 71] Gear, C. William, Numerical Initial Value Problems in Or- dinary Differential 
Equations, Prentice-Hall, Englewood Cliffs, NJ, 1971 [Goldstein 83] Goldstein, Herbert, Classical Mechanics, 
2rid edition, Addison-Wesley, Reading, Massachusetts, 1983. [Golub and Van Loan 83] Golub, G., and Van 
Loan, C., Matrix Compu- tatlons, Johns Hopkins University Press, Baltimore, 1983. State variables of 
a body: m -Mass of the body I -Rotational inertia tensor of the body -Position of the body R -Orientation 
of the body !~ -Momentum of the body -Angular Momentum of the body, a u x_//Jary variables: = 1_ t7 
-Velocity of the body = I~-1~ -Angular velocity of the body, THE EQUATIONS OF MOTION: ~/7= ff R = w'R 
where: ff = net force on the body, and 2 g = net torque of the body. Note: w" is the dual of ~ (see Appendix 
B.1). Figure 16: Summary of the equations of motion of a rigid body. [Isaacs and Cohen 87] Isaacs, Paul 
M. and Michael F. Cohen, Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions, 
and Inverse Dynamics, Proc. SIGGRAPH 1987, pp. 215-224 [Lengyel 87] Lengyel, Jed, Dynamic Assembly and 
Behavioral Simulation of the Flagellar Axoneme, in Calteth SUItF Reports, 1987 [Lien and Kajiya 84] Lien, 
Sheue-ling, and James T. Kajiya, A symbolic method for calculating the integral properties of arbitrary 
nonconvex polyhedra, IEEE Computer Graphics and Applications, Vol. 4 No. 10, Oct. 1984, pp. 35-41. [Misae~, 
Thorne and Wheder 73] Misner, Charles W., Kip S. Thorae, and John Archibald Wheeler, Gravitation, W.H. 
Freeman and Co., San Francisco, 1973. [Press et. al. 88] Press, William II., Brian P. Flannery, Saul 
A. Teukolsky, and Wil]iam T. Vetterllng, Numerical Recipes in C/The .Art of Scientific Computing, Cambridge 
University Press, Cambridge, 1988. [Platt and Burr 88] Platt, John, and Alan Barfs Constraints on Flexible 
Ob- jects, Submitted to SIGGRAPtt 1988. [Ralston and Rabinowitz 78] Ralston, Anthony, and Philip Rabinowitz, 
A First Course in Numerical Analysis, McGraw-Hill, New York, 1978. [Shoemake 85] Shoemake, Ken, Animating 
Rotation with Quaternion Gurves, Computer Graphics, Vol. 19 No, 3, July 1985. pp. 245-254. [Terzopoulos, 
Platt, Fleischer, and BaH 87] Terzoponlos, Demetri, John Platt, Alan BaH, and Kurt Fleischer Elastically 
Deformable Models, Proc. SIGGKAPtt, 1987, pp. 205-214. [Witkin, Fie;sober, and Burr 87] Witkin, Andrew, 
Kurt Pie;sober, and Alan Burr, Energy Constraints on Parametrized Models, Proc. SIGGRAPtt 1987, pp. 225-232 
~Wilhelms and Bazsky 85] Wilbelms, Jane, and BxSan Barsky Usin9 Dy- namic Analysis To Animate Articulated 
Bodies Such As Humans and Robots, Graphics Interface, 1985.  Appendices: A Simulating Newton;an Mechanics 
Fig. 16 summarizes the equations of motion of a rigid body. A full discussion of rigid-body dynamics 
can be found in [Fox 67,Goldstein 83]. A.1 Notes On The Equations Of Motion The Orientation Matrix R: 
It transforms tensors from body-coordinates to world coordinates (see Fig. 17). As we numerically integrate 
R, numerical noise tends to cause It to drift away from a pure rotation, yielding noticeable skewing. 
This can be alleviated by using a feedback technique, aa in [Burr 83]. Alternatively, we can rep- resent 
the orientation as a quaternion Q (see [Shoemake 85] for an introduction to quaternions). The equation 
of motion for Q is (see [Misner, Thorne aald Wheeler 73]): d 1. ~Q = ~wq We then define R to be an auxiliary 
variable, which is computed from Q as discussed in [Shoemake 85]. Rotational Inertia Tensor I: I determines 
the rotational behavior of a. body. 4 For rigid body, Ibody is constant. Note also that in Fig. 16 4A 
discussion of the dmwacterstics of I is beyond the scope of this paper; see [Fox 67,Goldsteln 83]. [Lien 
and Kailya 84] tires an algorithm to compute I for arbitrary aonconvex polyhed.ra.  SIGGRAPH '88, Atlanta, 
August 1-5, 1988 Poin~ "P" (0 o,l~ x y (o,o,o) x Body coordinates World coordinates Figure 17: A rigid 
body. Orientation matrix R transforms vectors from body coordinates to world coordinates. we use I -a 
rather than I. IEo~ can be precomputed for each body; we convert to world coordinates using R: i-~ = 
RI~o~a~R T The Net Force ff and Torque ~: Euler's principle of superposition allows us to combine the 
force applied to a body into an equivalent net force applied at the center of mass. Each force applied 
at a radius from the center of mass contributes b x -f to the net torque on the body; we can also have 
"pure torques" acting on the body. The net force and torque are thus:   :=E:, forces i = ~ (~,×:,)+ 
~ ~, forces i torques j A.2 Canonical O.D.E. Notation For brevity, we express the collection of equations 
in Fig. 16 as an ordinary differential equation (O.D.E.), in canonical form. For a single body, which 
we label A, we have: ~tYA = .f(yA, -fA, :A) (8) where we define yA = {~A RA~A,~A} --State of body A -fA 
--Net force on A ~A --Net torque on A For a model consisting of a collection of bodies, we have: d ~Y 
= I(Y,~, ~) (9) where we define y = {yA, yB,...} --State of the model ~c = {ffA,_fiB,...} --Forces in 
the model T = {~A, :B .... } --Torques in the model Numerical methods for solving first-order O.D.E.'s 
are well known (see [Press et. al. 88,Boyce and Deprima 77,Ralston and Rabinowitz 78]). When the equations 
are not stiff (stiff differential equations occur when there are multiple widely varying time constants 
for the solutions), an adaptive Adams predictor corrector is suitable; otherwise we recommend a method 
such as Gear's Method ([Gear 71]). B Mathematical Details B.1 Dual of a vector The dual of a vector 
b is the antisymmetric matrix b°: b~ , define b* = -ha 0 b~ ba b~ -ha 0 For any vectors b and g, we 
have the following identities: b'~ ~bx~ b*TE _~xg b'Tb ~ 0  B.2 Behavior of a Point Consider a point 
up, which is fixed relative to a rigid body (Fig. 17). We define bbod~ to be the vector from the center-of-mass 
of the body to F, ex-pressed in the body's home coordinates; since the point is fixed, gbod~ is constant. 
We would like to derive expressions for the position, velocity, and acceleration of P. We will need to 
know the derivative of 1-1 . Remember that since the body is rigid, 1-1 body is constant: 1-1 = RI~o~ 
1L T a -a T -1 a T ~tI-1 = (~/R')I~avIt + RIt'av(~TR~ ' ) (10) = ,~*RI~o~R T + RI~o~RTw */ = ov*1-1 + 
I-lw *T We have substituted w*Pt. for ~R, according to the equations of motion (Appendix A). We will 
also need the derivative of ~: = (~I-I).., + l-aN ' = w.i_~ + i_lw,T ~ + i_a~ (11)  = ,o'zz + I -~('T/, 
+ C') = I-a(~ x ~+ Cff) We have substituted ~ for ~-tL according to the equations of motion. We can 
now differentiate b: = Rbb~2, and = w*Itb~ =~xg ~ = (lz) (~) × ~+~ × (~ × g) = (i-~(~ × ~+P)) x g+~ 
× (~ × ~) (b*TI-:t)Cff + (b*TI -a (..g x ~) + ~ x (~ x b))  =H:+3 where we define H = b*TI -~ =b'Tl-~(Lx~)+~x(~xb 
") We have again substituted ~a*R for ~II. Finally, we can express the positio~, velocity, and acceleration 
of point P terms of the state of the body and the net force and torque on the body: Xp = X+E % = ~gg. 
=  ~.¢+ ~ = ~7+o~ x b d (is) = -~+H:+3 where we define G =-~ C Constraint Derivations For each type 
of constraint, we must derive expressions for the various quan- tities defined in Fig. 11. The steps 
we follow are: 1. Choose a simple "devlation" measure /~. ~ is a function of the po- sitions (~) and 
orientations (R) of the constrained bodies, and may optionally depend on t.  2. Differentiate D, to 
derive ~(x)(~, t); Substitute ~ and w*R for the a~X and ~/.R terms which win arise (see Fig. 11). 3. 
Differentiate again, to derive /~(2/(y, if, ~, t). Replace ~¢ff and ~/L terms with -f and T, thus giving 
rise to the linear dependence of/~(2) on the forces and torques. Define the d × 3 matrices r, A, and 
the d-vector ff  4. Choose where to apply the constraint forces needed to meet the con- straint. Most 
often, we apply a vector force to a fixed location of the constrained body; in this case, we have f = 
3 degrees of freedom.  5. Use steps 2 and 3 to derive G and H for each body. These convert the f values 
in the ~constralnt force" fie into the actual forces and torques on the bodies. Often, some of the quantities 
r, A, G, and H, which are nominally matri- ces, turn out to be scalar. Scalars can be handled as a special 
case in the implementation, or scaled identity matrices can be used. We give examples of the constraint 
derivations for the constraints illus- trated in Sec. 2.2.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378510</article_id>
		<sort_key>189</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Rendering trimmed NURBS with adaptive forward differencing]]></title>
		<page_from>189</page_from>
		<page_to>198</page_to>
		<doi_number>10.1145/54852.378510</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378510</url>
		<abstract>
			<par><![CDATA[Trimmed non-uniform rational B-splines have become a very useful surface representation form in the mechanical CAD industry. Previous rendering methods use the de Boor algorithm to evaluate the surface at equal increments in parameter space. This yields polygons which are then rendered. Alternatively the Oslo algorithm and Boehm's knot insertion algorithms are used in a subdivision approach. In this paper a new method is presented for rendering trimmed NURB surfaces of arbitrary order using the adaptive forward differencing (AFD) technique. This method extends the AFD technique to higher order, efficiently computes the basis matrix for each span, calculates the shading approximation functions for rational surfaces, and trims and image maps NURB surfaces. Trimming is accomplished by using AFD to scan convert the trimming curves in parameter space, thus producing the intersection points between the trim curves and an isoparametric curve across the surface. A winding rule is used to determine the regions bounded by the curve which are then rendered with AFD. The method is suitable for both hardware and software implementations, however, higher order surfaces require very high precision due to the forward difference nature of the algorithm.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[B-splines]]></kw>
			<kw><![CDATA[NURBS]]></kw>
			<kw><![CDATA[adaptive forward differencing]]></kw>
			<kw><![CDATA[graphics VLSI]]></kw>
			<kw><![CDATA[image synthesis]]></kw>
			<kw><![CDATA[parametric surfaces]]></kw>
			<kw><![CDATA[shading]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Splines</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010633</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010633.10010659</concept_id>
				<concept_desc>CCS->Hardware->Very large scale integration design->VLSI system specification and constraints</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334986</person_id>
				<author_profile_id><![CDATA[81332526795]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Micheal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shantz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., 2500 Garcia Avenue, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14095494</person_id>
				<author_profile_id><![CDATA[81408601942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sheue-Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc., 2500 Garcia Avenue, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>35072</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Richard Barrels, John Beatty, and Brian Barsky, An Introduction to Splines for use in Computer Graphics and Geometric Modeling, Morgan Kaufmann Publishers, 1987.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Wolfgang Boehm, Inserting New Knots into B-Spline Curves, 12, pp. 199-201, Computer Aided Design, 1980.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Wolfgang Boehm, Efficient Evaluation of Splines, 33 , pp. 171-177, Computing, 1984.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carl de Boor, On calculating with B-splines, 6, pp. 50- 62, Journal of Approximation Theory, 1972.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Edwin Catmull, A Subdivision Algorithm for Computer Display of Curved Surfaces, UTEC-CSe-74-133, University of Utah, Computer Science, 1974.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Elaine Cohen, Tom Lyche, and Richard Riesenfeld, Discrete B-Splines and Subdivision Techniques in Computer-Aided Geometric Design and Computer Graphics, 14, Computer Graphics and Image Processing, October 1980.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Robert Cook, Patch Work, Tech. Memo 118, Computer Div., Lucasfilm Ltd., June 1985.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37414</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Robert Cook, Loren Carpenter, and Edwin Catmull, The Reyes Image Rendering Architecture, SIG- GRAPH'87 Proceedings, July 1987.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[James Foley and Andries Van Dam, Fundamentals of Interactive Computer Graphics, p. 533, Addison- Wesley Publishers, 1982.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E.T.Y. Lee, Efficient Evaluation of Splines, 329, pp. 365-371, Computing, 1982.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37416</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Sheue-Ling Lien, Michael Shantz, and Vaughan Pratt, Adaptive Forward Differencing for Rendering Curves and Surfaces, SIGGRAPH'87 Proceedings, July 1987.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13164</ref_obj_id>
				<ref_obj_pid>13152</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Tom Lyche and Knut Morken, Making the Oslo Algorithm More Efficient, 23, pp. 663-675, SIAM J. Numer. Anal, 1986.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hartmut Prautzsch, A Short Proof of the Oslo Algorithm, 1, Computer Aided Geometric Design, 1984.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30665</ref_obj_id>
				<ref_obj_pid>30663</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Alyn Rockwood, A Generalized Scanning Technique for Display of Parametrically Defined Surfaces, 7, IEEE CG&amp;A, August 1987.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37425</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Michael Shantz and Sheue-Ling Lien, Shading Bicubic Patches, SIGGRAPH'87 proceedings, July 1987.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Rendering Trimmed NURBS with Adaptive Forward Differencing Michael Shanrz and Sheue-Ling Chang Sun Microsystems, 
Inc. 2500 Garcia Avenue Mountain View, CA 94043 Abstract Trimmed non-uniform rational B-splines have 
become a very useful surface representation form in the mechanical CAD industry. Previous rendering methods 
use the de Boor algorithm to evaluate the surface at equal increments in parameter space. This yields 
polygons which are then ren- dered. Alternatively the Oslo algorithm and Boehm's knot insertion algorithms 
are used in a subdivision approach. In this paper a new method is presented for rendering trimmed NURB 
surfaces of arbitrary order using the adaptive forward differencing (AFD) technique. This method extends 
the AFD technique to higher order, efficiently computes the basis matrix for each span, calculates the 
shading approxi- mation functions for rational surfaces, and trims and image maps NURB surfaces. Trimming 
is accomplished by using AFD to scan convert the trimming curves in parameter space, thus producing the 
intersection points between the trim curves and an isoparametric curve across the surface. A winding 
rule is used to determine the regions bounded by the curve which are then rendered with AFD. The method 
is suitable for both hardware and software implementations, however, higher order surfaces require very 
high precision due to the forward difference nature of the algorithm. CR Categories and Subject Descriptors: 
1.3,3 [Computer Graphics]: Picture/Image Generation - Display algorithms; 1.3.7 [Computer Graphics]: 
Three-dimensional Graphics and Realism - Color, shading, shadowing, and texture. Additional Key Words 
and Phrases: image synthesis, shad- ing, adaptive forward differencing, graphics VLSI, parametric surfaces, 
B-splines, NURBS. Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. Introduction Several methods have been used previously for rendering tr/mmed NURB surfaces. 
The de Boor Cox algorithm [4] is frequently used for evaluating a B-spline curve or surface at a particular 
point in parameter space. Also, subdivision techniques using knot insertion have been described by Boehm 
[2] and Cohen and others (the Oslo algorithrn)[6]. The Oslo algorithm is capable of simultaneously inserting 
multiple knots in an efficient manner. A simple proof of the Oslo Algorithm is given by Prautzsch[13], 
and a more efficient way of using the Oslo algorithm is given by Lyehe and Morken[12]. Lee [10] gives 
an algorithm for evaluating the derivatives of a NURB at a point in parameter space by using knot insertion. 
Boehm [3] later derived a more efficient scheme for the simultaneous evaluation of all sur- face derivatives 
at a point in parameter space. Nonuniform B-spline curves and surfaces can be rendered by tesselation 
to piecewise linear vectors or planar polygons by evaluating at intervals in parameter space. They may 
also be subdivided to produce vector or polygon vertices or subdi- vided to individual pixels. Each of 
these methods has cer- tain drawbacks. Subdividing using knot insertion down to the pixel level is very 
expensive. Piecewise planar methods, while fast, yield lower quality renderings if done coarsely and 
make image mapping and trimming more difficult. The approach presented in this paper involves obtaining 
the functional description of each span by computing the basis function of the span, then rendering the 
span using the adap- tive forward difference technique together with a Hermite shading function approximation. 
In this paper the AFD technique is extended to higher orders and used to evaluate the NURB surfaces and 
their associated trimming curves incrementally. A recursive relation is derived for obtaining the coefficients 
of the basis functions for a given knot vector, and a method is given for computing shading function 
approximations for a rational surface. AFD is also used to evaluate the NURB trimming curves in parameter 
space "scanline" order to provide the parameter bounds for rendering curves across the surface. Figure 
3 shows a result produced with these techniques, an image of trimmed NURB surfaces with image mapping 
and shading. &#38;#169;1988 ACM-0- 89791-275-6/88/008/0189 $00.75 Summaryof the AFD Technique A previous 
paper[3] describes an adaptive forward differenc- ing technique for rendering trimmed, image mapped, 
parametric surfaces. A similar technique for rendering parametric surfaces was also proposed by Rockwood[4], 
which computes the minimum possible steps for each sur- face and then renders the surface with ordinary 
forward dif- ferencing. A brief comparison between the two techniques and the error accumulation problem 
were mentioned in the discussion section. The AFD method unifies the processes of reeursive subdivi- 
sion [1] and forward differencing [2] for curves and surfaces in the R 4 space (homogeneous coordinates 
x,y,z,w). A linear substitution transforms a parametric function f(t) into f(at+b) or f(s,t) into f(as+b,ct+d). 
The geometric effect of linear substitution is to translate and scale a segment or patch within the curve 
or surface containing it. Any segment of a curve can be mapped to any other segment of the same curve 
by some linear substitution, and likewise for patches. Let L be a linear substitution it2 and R be (t+l)/2. 
L and R are the operators associated with recursive subdivision; they act on a segment C to yield the 
"left" and "right" halves LC and RC of C, see Figure 1. g is a linear substitution t+l, which acts on 
a segment C to yield its "right neighbor" EC. The pro- cess of applying a sequence of E operators to 
render a curve segment is known as forward differencing. LC ~ RC LLC RLC E~ LRC___~. RRC Figure 1. Relationship 
of linear substitutions L, R and E. A disadvantage of forward differencing is that it may not traverse 
C with uniform velocity. Recarsive subdivision avoids this difficulty by stopping at different depths 
in dif- ferent parts of the recursion tree. The adaptive forward dif- ferencing technique transfers this 
advantage of recursive subdivision to forward differencing by inserting an occa- sional L or L -~ (the 
substitution 20 into the stream of E's whenever the velocity is too great or too small respectively. 
This has the effect of changing the level in the recursion tree while forward-differencing across it. 
While any basis will do for the AFD technique, the forward difference basis Bo= 1, B 1 = t, Bz= tt~ ..B, 
= t(t'71)(t-2) "'" (t-n+l) 2 n! is best suited. The forward step E, the adjust-down L, and the adjust-up 
L -1 operators of this basis of order 4 are: ,/2 -1,'8 1/| L-1 = o 1/4 -l~j The above linear operators 
can be applied to a cubic function f (t) = aB 3(t )+bB z(t )+c.B l(t)+dB o(t ) tO transform f (t ) into 
f "(t ) = a "B 3+b "B z+c "B t+d'B o. The E transformation performs a forward step operation f'(t)=f(t+l) 
: The L operator can reduce the step size by f'(t)=f (t/2) : _ 0 1/2-1,'8 1 [a :J -"~igjO o° 1/4 and 
the L -~operator can double the step size by   [! !i i ! 1 Extending AFD to Higher Order The AFD technique 
can be generalized to arbitrary order by extending these matrices. The forward difference matrix for 
one span of a NURB sur- face of arbitrary order is given by A = [FD] [DU] [CU] [P] [CV] r [DV] r [FD] 
r where P is the matrix of control points for the given span of the NURB, CU and CV are the basis matrices 
in the u, v directions defined by the u and v knot vectors, DU and DV are the initial scaling matrices, 
FD is a matrix which con- verts polynomial basis (i.e. polynomial power series) into forward difference 
basis, and A is the resulting forward difference matrix. The matrix A has v columns and u rows when the 
NURB surface has order u and v in the u and v directions. 1. Computing NURB polynomial basis coefficients 
The next major section will discuss a recursive method for obtaining the polynomial basis matrices CU 
and CV. 2. Initial scaling matrix The DU and DV matrices are used to scale polynomial coefficients in 
the u and v direction to the appropriate initial forward step size. For nth order this matrix is simply 
 [!ooo du 0 0 DUff 0 du 2 0 0 0 du~ ..  The scaling matrix can be trivially extended to higher order 
by filling in the jth diagonal elements with duJ, where du is the amount of scaling. 3. Converting polynomial 
to forward difference The FD matrix converts from polynomial to forward differ- ence basis. For a cubic 
this is the well known matrix ° We note here that the FD matrix for higher order can be computed from 
an expression ao+alu ,-I- a2u2+ ... +ad ud = u... (u-d+l) b°+blu +b2 + "'" +bd d! which relates a set 
of forward difference basis coefficients <b~> to the corresponding polynomial basis coefficients <aj>: 
b 0 = a 0 b~ = Ig Ig(-lI~-~Cl k~ a~ 'I' 1 j=ll *=O J where C~ i----L--arid d = degree k !(i-k)t Thus 
the elements in matrix FD can be defined as i FO~j= E(-1)~-~c~k j k=0 For example the FD matrix for order 
5 is 11000i] llt FD= 0 2 6 ,4 00636 0002 The resulting forward difference matrix A can then be calcu- 
lated by concatenating all the matrices appropriately. A =[FD] [DUI [CU] [P] [CV] r [DV] r [FD] r 4. 
The forward step operation The forward step operation [E] is mathematically a linear substitution of 
v+l for the parameter v. Practically it is used to advance from the current curve to the next or from 
the current pixel to the next. This operation can be extended trivially to higher order. In the forward 
difference basis a forward step is performed for all coefficients by adding the i+l coefficient to the 
ith coefficient Thus the [E] matrix can be generalized as Eij= 1 if i=j or j=i+l, otherwise 0 The forward 
step matrix for nth order is I, 10 il °° 1 .., o .... 0 5. The adjust down operation To decrease the 
distance between two consecutive curves, an adjust down operation is performed on [A ]. Let W be the 
matrix which adjusts down the polynomial basis coefficients by half, i.e. w is a scaling matrix with 
a scaling factor of 0.5. ~1/2 0 0 W= 0 0 0 o 1/8 The adjust-down operation is extended to higher order 
by L = [FD ] [W] [FD-~]. where the [FD -I] matrix converts the forward difference coefficients into polynomial 
basis, the [W] matrix scales the polynomial coefficients by 0.5, and [FD] converts the scaled result 
back into forward difference basis again. For order 5 the adjust down matrix is 0 0 118 -3/32| 0 0 0 
1/16 ]  Ii °°° 6. The adjust up operation The adjust-up matrix can be similarly extended by  [ 00000!j 
L-1= [FD I [UI [FD-1], where U = 00 To increase the distance between two curves the matrix A is transformed 
by L -t. For order 5 the adjust up matrix is  [!ooo 210 L-I= 0 4 4 008 000163 Notice that above order 
4 the adjust down matrix contains values which are not powers of two. Up to order nine, the elements 
can all be represented as the sum of two powers of two. Obtaining NURB basis functions Trimmed NURBS 
have become a useful surface representa- tion form in the MCAD industry[l]. Uniform splines have constant 
basis functions throughout the spans, i.e. the basis matrix is the same for all spans. Non-uniform splines 
instead have a different basis function for each span defined recursively by a knot vector. A B-spline 
curve is a piece- wise polynomial curve f(~)= E p~M(") i where the coefficients P i of the B-spline functions 
Nik(u) are called control points or de Boor points. The functions N~(u) are piecewise polynomial of 
order k defined over a knot vec- tor  < u 0 < u 1 < u 2 < - - by a recursive relation Nil(u)=0 if 
ue [ul,u~÷ l] Nil(u)--1 if ue [ul,ui+l] N~(u) "-ul N~_lfu) + u.~-. N~l(u ) Ui +k-l--I~ i Ui +k--Ui + 
1 Boehm's triangular scheme operates on the knot vectors and control points to give the values and the 
derivatives of the coordinate functions xyzw. This scheme can then be used to obtain the polynomial coefficients 
for each span of the sur- face and to calculate the normal vectors and the bicubic Her- mite approximations 
of the shading function for a surface. An alternative method is presented here which operates on the 
knot vectors to give the basis matrices of each span which then convert the control points for the span 
to polyno- mial or forward difference basis. To render the surface with the AFD technique, the parameter 
u for a current span (ut,um) is redefined to range between 0.0 and 1.0 by a linear substitution u' = 
ut+lu + (1-u)ul so that N~(u) (ut-ui)+(ut+l-ut)u N~_i(u) ui+k-l-ui + (Ui÷k--ut~(Ut+l--Ut)UNik~l (u) 
(l) Igi+k--lAi+l Given the basis functions represented in polynomial power series, let C~j denote the 
jth coefficient of the ith basis func- tion N~(u) of order k: k-I Nik( u ) = ~E~ Cikd u~ (2) j=O The 
coefficients C. ~. ,j can be defined recursively in terms of the lower order ones as c:j = ~ c::_ ~, 
+ b C:~ l + ~ C:Z~_i + d C:Z~ (3) Ut+l--U I Ui--U i where a = --b = --ui +k-l--lg i I~i +k_l--Ui Ul+l--tl 
I Ui+k--U l C= d I~i÷k--Mi+l I~i+k--Ui+ 1 This equation is used to obtain the NURB basis matrix CU and 
CV in the u, v directions from the u, v knot vectors. The derivation in (3) can be proved by observing 
that N~(a) is a product of a linear function times a polynomial. Substituting equation (2) into equation 
(1) gives the following equation (ut--ui)+(ul+l--ul)u +-2 k 1 N~(u)= ZCi~ .J Ui +k-l --lg i j ~o ( ui 
+~-u~ )-( ut + ~-ut )u ~2 _~_~ + ~i+Id u~ (4) Ui+k--l/i+t j~ from which the derivation follows trivially. 
In Appendix A a recurrence formula is given for efficiently computing the forward difference basis matrix 
for a NURB span. This recursive equation is similar to the previous one. The above two methods allow 
the basis matrices CU and CV to he derived independently of the control point mesh. These matrices are 
concatenated with the control point arrays to give the forward difference matrices of the coordi- nate 
functions and the shading functions for the span. Rational Shading Approximation A shading function 
approximation method for non-rational surfaces was presented in a previous paper by the authors [15]. 
This method uses Hermite approximation to approxi- mate the normalized shading functions N'L and N'H 
with two bicubic functions. The shading approximation algorithm for rational surfaces is very similar 
to that described previously. The derivation of the shading function approximation for rational surfaces 
is included in Appendix B. The calculation of derivatives of rational functions are gen- erally more 
complex. The implementations of the two algo- rithms are the same except at the low level routines where 
the derivatives are computed. Here only the differences between the two are outlined. For a non-rational 
surface x(u,v ) = UXV, y (u,v ) = UYV, z(u,v )= UZV the low level derivatives are ax ~x °2x = u"xv, 
~u -u'xv, Tv = uxv', ~u.---~ 32x = uxv', °3x -u"xv" ~3x -u'xv-Ov a Ou20v-, Ou3v2 For a rational patch, 
UXV UYV UZV x(u,v)= ~, y(u,v)= ~,z(u,v)= Uwv the derivatives are more complicated as follows: OX x u 
w--.~'u ~u w 2 O:X 1 2 --0u2 -~T(w x~,-wxw.-2ww.x.+2xw.w.) O2X 1 2 av 2 -~-(w x~ -wxw~ -2ww~x, + 2xw, 
w. ) a2X | ~T(w 2x.,-wx, w,-wx, w.-wxw., + 2xw. w, ) O u ~v ~3X H l(u ,v) _ 3X~'(u'v)w'w Ou~av w 3 ~3X 
H 2(u ,v) = ~u~v 2 w 3 w.-3X~(u,v)--w where 2 H 1 (u ,v ) = ~v(W x~-wxw~,-2ww.x.+2xw, w.) 0 H 2( u,v 
) = ~-(w 2x~,-wxw~-2ww,~ +2xw, w~) The two spherical surfaces shown in figure 4 are rational biquadratic 
surfaces. The shading functions are computed using the method described in this section. Trimming NURB 
Surfaces Once the forward difference coefficients of the current span are obtained, the trimming curves 
are scan converted in u,v space using AFD to increment the curves to find their inter- sections with 
the curve S(uo,v). This curve is then rendered between intersections v~o and v~ using AFD in the v direc- 
tion. Then we step to the next curve with a forward step in the u direction. The AFD method allows polynomial 
parametric surfaces to be rendered in parameter space order rather than in scanline order. This greatly 
reduces the difficulty of trimming since the trim curves can be scan converted in parameter space order 
using the same techniques that are well known for scan converting polygons. The trimming curves are nth 
order, closed, NURB curves. Our trimming algorithm operates in 4 steps. 1) The NURB trim curves are converted 
to piecewise Bez- ier by knot insertion. 2) The Bezier sections are subdivided so they are all monotonically 
decreasing in the u parameter direction. 3) The Bezier sections are converted to forward difference basis. 
4) They are sorted in u parameter order by their minimum u value. 5) For each AFD forward step in the 
u direction (from curve to curve) the active trim curve sections are forward-stepped down to find intersections 
with the new curve (vmin, vmax). The appropriate portions of the surface curve are drawn based on the 
trim curve winding rule. Figure 5 shows a nut composed of NURB surfaces trimmed using the above technique. 
The rim portion of the nut is formed by a cone trimmed with two sets of trimming curves Figure 2 uses 
the rim example to illustrate the trimming algorithm. NURB surface s(u, v) ,, vlrrl.ln max 7)7 u=uo 
"~-vmax knot j Figure 2. A NURB surface trimmed by a NURB curve.  Discussion 1. Reducing Adjustment 
Overhead While rendering a surface, the decision to adjust up, adjust down, or forward step from the 
current curve to the next curve is made based on an estimate of the maximum distance between the two 
curves, d(v)=f(u+Su,v)-f(u,v). This dis- tance is an isopararnetric function of v. By converting the 
distance function into Bezier basis and using the convex hull property, the maximum distance between 
two curves can be calculated. Cook catalogs the conversion matrices between several different basis in[7]. 
The overhead per curve for converting between the two bases can be reduced by keeping a dual matrix B 
of the forward difference matrix A : A =[FD ] [DUI [CU] [PI [CV] r [DV] r [FD ]r B = [FD] [DU] [CU] [PI 
[CV] r [DV] r [BZ] r where [BZ] converts from polynomial basis into Bezier basis. Matrix A is converted 
to forward difference basis in both u and v directions and B is in forward difference basis in u and 
Bezier basis in v. The first row of A contains the coordinates of the current curve in forward difference 
basis for used in AFD to render the curve. The second row of B contains the difference function d(v) 
in Bezier basis for used in the adjustment decision making. A and B matrices are syn-chronized in the 
u direction, i.e. adjusted up or down or for- ward stepped at the same time, so that AFD can step from 
one curve to the next while keeping the distance function available in Bezier basis. 2. Degenerate Surfaces 
Shown in Figure 4 are two spherical surfaces both defined as non-uniform rational B-spline surfaces. 
The shading approx- imation method discussed in this paper was applied directly to the non-degenerate 
surface on the left. The one on the right contains a degenerate edge with three coincident con- trol 
points. A degenerate surface may have vanishing derivatives, which complicates the computation of the 
Her- mite approximation to the normalized normal vector func- tion. In this case, the vanishing derivatives 
were replaced using special case approximation before the shading method was applied. 3. Computation 
Complexity The de Boor algorithm is popular for evaluating points on a NURB surface, or inserting knots 
in a subdivision technique for surface rendering. A full version of the de Boor algo- rithm for evaluating 
a point on a surface of order k requires (k-1)k(k+l)/2 multiplies and twice as many adds. This makes 
it expensive to evaluate many points on a surface or to subdi- vide the surface down to pixel size in 
order to render a high quality image. Boehm's triangular scheme gives the values and derivatives of a 
B-spline function. This scheme can be used to obtain the polynomial coefficients for each span of the 
surface. Each triangular operation requires k(k-1)/2 mul-tiplies and k(k-l)/22 adds for an order k function, 
assuming the knot differences have been precomputed. A full version of Boehm's triangular scheme requires 
two triangle opera- tions to compute all the derivatives of a single variable B- SIGGRAPH '88, Atlanta, 
August 1-5, 1988 spline function, which is k(k-l) multiplies and adds. For a bi-variate function, it 
would require 4k triangle operations to compute all the derivatives, which is 4k2(k-l) multiplies and 
adds. Given the derivatives, k z multiplies are required to compute the polynomial coefficient matrix. 
The method presented here takes approximately 4k + 4(k-1)(k-2) + (k-1)(k-2)(21c-3)/6 multiplies and adds 
to compute a basis function of order k, assuming the knot differences have been precomputed. This method 
requires the computation of all the basis functions in the u, v direction. Given the basis functions, 
it takes two kxk matrix multiplies to produce a polynomial coefficient matrix, which is 2k 3 multiplies 
and ~z(k-1) adds per span. The computational complexity of the two methods is similar. Boehm's method 
operates on the control points directly instead of computing the basis func- tions for each span, and 
thus has more memory requirement. 4. Error Analysis Although forward differencing is the fastest possible 
way to sample a large numbers of points on a surface, it tends to be more vulnerable to errors than other 
evaluation methods. After performing k forward step operations on a cubic func- tion f(t)--aBa(t)-bbBz(t)+cBt(t)-bdBo(t), 
the four coefficients . k(k-1)(k-2) _k(k-1) ... c,=ak(~+bk+c, become a' = a ~ "+O----~---+CX+a, b'=ak+b, 
and a'=a. The error accumulation in each coefficient is formulated as k (k- 1)(k -2) +eb ~+ec k -be d 
Ea'=e~-6 E c" = e a ~-~-be b k -be e Eb = eak+el~ Ean --~a where e,,e b,e c and e d are the initial 
errors in the coefficients and E,,E~,Ec and Ed are the errors accumulated after k steps. In fixed point 
arithmetic with all the coefficients having equal number of fractional bits, the term eak(k-l)(k-2)16 
con-tributes the most to the error, which can be as much as 30 bits for k=21°. For higher order functions 
the error can accu- mulate even more rapidly. Both OFD and AFD techniques suffer error propagation problems, 
however, the AFD error is always bounded by the OFD error. The number of steps required by OFD to forward 
across a curve is always greater than or equal to that of AFD, because OFD uses the minimum step size 
while AFD can adjust up step size whenever needed and thus reducing the number of steps. An adjust-up 
operation cuts the number of forward steps in half, and at the same time requires an n-bit left-shift 
in the ease of a degree-n function. It is clear from the dominating error term in the following relation 
that the AFD error with k for- ward steps following an adjust-up is always smaller than the OFD error 
with 2k forward steps. e, 2k(2k-l)(2k-2) >2ae ° k (k-1)(k-2) 6 6 A section of error analysis on the 
OFD technique can also be found in Rockwood's paper. 5. Transparency and Anti-aliasing Redundant pixel 
painting in AFD constitutes the major obs- tacle in rendering transparent objects. Quick solutions to 
get around the redundant pixel problem would be either to tesselate a transparent object into polygons 
or to keep a buffer for object identification at each pixel to eliminate redundancy. However, the object-id 
buffer still can not han- dle a folded surface. A new twin-curve buffer algorithm is under development 
by the author to tackle this problem. Still more work and testing are required. One very successful anti-aliasing 
technique is based on dic-ing to produce micropolygona [1] followed by skittered sub- sampling and averaging. 
Previous methods for dicing used screen space derivatives to determine how finely to dice, and ordinary 
forward differencing to do the actual dicing. The AFD technique may have potential as a method for dicing 
since screen space step size is the condition which controls adjust up, adjust down, or forward step. 
Further investiga- tion in this area is needed. Conclusion In this paper a technique for rendering nonuniform 
rational B-spline surfaces is described. The AFD technique is gen- eralized to higher order, and a recursive 
relation is derived for efficiently computing the basis function coefficients of a NURB surface. An approximation 
method for computing the shading functions of a rational surface is developed and AFD is applied to the 
problem of trimming NURB surfaces with NURB trim curves using a method similar to polygon scanline algorithms. 
AFD based rendering methods for NURBS give the quality of subdivision methods with the efficiency of 
forward difference techniques. Image mapping and NURB trimming are also facilitated. Figure 6 shows a 
clevice rendered using these techniques. The shading approximations and the re.cursive relation for computing 
basis functions are equally applicable to other rendering techniques such as polygon tesselation, ordinary 
forward differencing, or recursive subdivision. Further work should be done on evaluating the accuracy 
of the Herrnite approximation functions for shading and possi- bly extending these methods to higher 
order. Acknowledgement The authors would like to thank Lewis Knapp and David Elrod for aquiring the 
NURBS data bases and writing the database reader software. Thanks to Tony Wyant for provid- ing the digitized 
images for mapping, and to Sue Carrie for helpful discussions on error analysis. We are grateful to Lewis 
Knapp for reviewing early drafts of this paper and for many helpful discussions. Special thanks to Automation 
Technology Products for providing trimmed NURB data. Appendix A This appendix derives the NURB forward 
difference basis function for a single span from the knot vectors. We can redefine the B-splint function 
N~ in forward differ- ence basis as + .-- + B~_~ u (u - 1 )(u -2)...(u --(k -2)) (k-Dr and B:, [1 
ui~u<u~+t and j=0 J,I = 0 otherwise The jth coefficient B:j of the NURB basis function N~ in the forward 
difference basis for the ith span of a curve of order k is given by +t./_,,)n~21 k-i ~-t j Bi+l,i_1 + 
(.j-ui+~)Bi+lj . k-1 BEd = J Bi d-I U i +k-l--t~i gi-+.k--Ui+l  Derivation: From the B-spline basis 
definition we notice that N~(u) is the sum of two products of a linear equation times a polynomial. N~(u 
)=(au+b )Ni ~-t + (a" u +b')N~.i t We proceed by first obtaining a recurrence relation for one product 
and then combine the relations for the two products. Taking au+b times each term of N: -~gives Bo(au+b 
) = aBou + bB o B u(u-1) [.3_q..~.u__~_+ 3(b+2a)] 3aBz u (u-1)(u-2) + (b+2a)B z u (u-l) 3! 2t Bj u 
(u-l)...(u-(j-l)) (au+b) = j! (j+l)aBj u(u-1)...(u-j) + (b+ja )Bj u(u-1)...(u-q-1)) (j+l)! jt Grouping 
common terms and repeating similarly for the second product gives Substituting for a and b gives the 
equation of the recursive ~lation. Appendix B: This appendix describes how to compute the derivitaves 
for the Hermite shading function approximations for the rational case. A rational bicubic patch is defined 
by UXV x (u ,v ) X(u,v)= -w(u,v) UYV y(u,v) YCu,v) = UWV-w(u,v) UZV z (u,v ) zcu,v) = = -- UWV w(u,v) 
 where x(u,v), y(u,v), z(u,v) and w(u,v) are the nonrational polynomial functions describing the coordinates 
of a patch. The normal vector N = <n+,%,n, > is given by .~=Y.Z.-Y,Z., %=z.x,-z,x., n,=x. Y,-X. Y. 
The derivatives of the unnorrnalized normal vector function are given by 3n~ au = r.z. + Y.ZZ~ - r~z. 
-r.z., 3n. ~, =r.z, +Y.Z. -r.z. -rvz+ a2n~ ~uOv -Y.~,Z. + Y.Z. + Y.Z~  where the low level rational 
terms x.,x~,,x., x~,,x.. , etc. can be derived separately in terms of the derivatives of the nonrational 
functions x (u,v),y (u ,v ),z (u ,v ) and w (u ,v). X u W--XW u X~ ~. w2 1 X~, = -~-(w x~,-wxw~,-2ww.x. 
+2xw. w.) 1 2 X~ = ~ (w x~,-wxw~-2ww, x~ +2xw~ w, ) 1 2 X., = -~ ( w x., -wx. w.-wx, w .-wx~ + 2x~ . 
w, ) X~, H l(u ,v ) w, = ---3X~ (u,v)-- W 3 W X.,, H2(u,v) w. --3X.(u,v)-- w 3 W where 2 H l(u,v 
) ffi "~(w x~-wxwu.u-2wwux.+2XWuWu) z H2(u,v) = -~-(w x~,~-wxwv,-2w%x,,+2xw, wv)  The normalized normal 
vector function, its derivatives and the cross derivatives in the u and v directions are derived exactly 
the same as for a nonrational patch. The normalized normal vector function is z(u,v)=nzG, dy(u,v)=nyG, 
dz(u,v)=nsG , where G(u,v)=(n2~ + n~ +n2,) -t]~ III I The derivatives and the cross derivatives in 
the u and v directions are given by O~(u,v) anx ~ aG = ~j +'~U fix au au av = av G+'~ "n" aua~ = a~ 
a + -E~" + ~.x + au a, aG =_.Gs an= any an. ~-E (n= -E + n' -E +'"~-) aG = ._G3 an= a% an. (n=-5;:+~,--E+n,-~;-) 
a,,,~; GLa, J -L. [n.-~+~ a~v +n. auav j  : an, an= a% a% an, an, ] To approximate the unit normal 
vector function we need ale, ~t,(o,o) ,f,(o,D -~-(o,o) .-~-(0,1) ~t=(Lo) ~,(LD -~-(LO) --~-O,D :== -~-(o,o) 
-E(O,l) .~.(o,o) ~.~.(o,1~ apt.,, a~ a% a2,t, ~-(1,0) --~-(|,1) -~-(t,O) a~v(l,ll References 1. Richard 
Barrels, John Beatty, and Brian Barsky, An Introduction to Splines for use in Computer Graphics and Geometric 
Modeling, Morgan Kaufmann Publish- ers, 1987. 2. Wolfgang Boehm, Inserting New Knots into B-Spline Curves, 
12, pp. 199-201, Computer Aided Design, 1980. 3. Wolfgang Boehm, E3ficient Evaluation of @lines, 33 
, pp. 171-177, Computing, 1984. 4. Carl de Boor, On calculating with B-splines, 6, pp. 50- 62, Journal 
of Approximation Theory, 1972. 5. Edwin Catmull, A Subdivision Algorithm for Computer Display of Curved 
Surfaces, UTEC-CSe-74-133, University of Utah, Computer Science, 1974.  . Elaine Cohen, Tom Lyche, and 
Richard Riesenfeld, Discrete B-Splines and Subdivision Techniques in Computer-Aided Geometric Design 
and Computer Graphics, 14, Computer Graphics and Image Process- ing, October 1980. 7° Robert Cook, Patch 
Work, Tech. Memo 118, Computer Div., Lucasfilm Ltd., June 1985. 8. Robert Cook, Loren Carpenter, and 
Edwin Catmull, The Reyes Image Rendering Architecture, SIG-GRAPH'87 Proceedings, July 1987. . James Foley 
and Andries Van Dam, Fundamentals of Interactive Computer Graphics, p. 533, Addison-Wesley Publishers, 
1982. 10. E.T.Y. Lee, Ej~cient Evaluation of Splines, 329, pp. 365-371, Computing, 1982. 11. Sheue-Ling 
Lien, Michael Shantz, and Vaughan Pratt,  Adaptive Forward Differencing for Rendering Curves and Surfaces, 
SIGGRAPH'87 Proceedings, July 1987. 12. Tom Lyche and Knut Morken, Making the OsIo Algo- rithm More 
Ef~cient, 23, pp. 663-675, SIAM J. Numer. Anal, 1986. 13. Hartmut Prautzsch, A Short Proof of the Oslo 
Algo- rithm, 1, Computer Aided Geometric Design, 1984.  14. Alyn Rockwood, A Generalized Scanning Technique 
for Display of Parametrically Defined Surfaces, 7, IEEE CG&#38;A, August 1987. 15. Michael Shantz and 
Sheue-Ling Lien, Shading Bicubic Patches, SIGGRAPH'87 proceedings, July 1987.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378511</article_id>
		<sort_key>199</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[A recursive evaluation algorithm for a class of Catmull-Rom splines]]></title>
		<page_from>199</page_from>
		<page_to>204</page_to>
		<doi_number>10.1145/54852.378511</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378511</url>
		<abstract>
			<par><![CDATA[It is known that certain Catmull-Rom splines [7] interpolate their control vertices and share many properties such as affine invariance, global smoothness, and local control with B-spline curves; they are therefore of possible interest to computer aided design. It is shown here that another property a class of Catmull-Rom splines shares with B-spline curves is that both schemes possess a simple recursive evaluation algorithm. The Catmull-Rom evaluation algorithm is constructed by combining the de Boor algorithm for evaluating B-spline curves with Neville's algorithm for evaluating Lagrange polynomials. The recursive evaluation algorithm for Catmull-Rom curves allows rapid evaluation of these curves by pipelining with specially designed hardware. Furthermore it facilitates the development of new, related curve schemes which may have useful shape parameters for altering the shape of the curve without moving the control vertices. It may also be used for constructing transformations to B&amp;eacute;zier and B-spline form.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[B-spline]]></kw>
			<kw><![CDATA[Catmull-Rom spline]]></kw>
			<kw><![CDATA[Lagrange polynomial]]></kw>
			<kw><![CDATA[Neville's algorithm]]></kw>
			<kw><![CDATA[de Boor algorithm]]></kw>
			<kw><![CDATA[recursive evaluation algorithm]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.1</cat_node>
				<descriptor>Spline and piecewise polynomial interpolation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor>Spline and piecewise polynomial approximation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Splines</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003722</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Interpolation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P226872</person_id>
				<author_profile_id><![CDATA[81409596342]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Phillip]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Barry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Laboratory, Computer Science Dept., Univ. of Waterloo, Waterloo, Ontario, Canada N2L 3G1]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14022247</person_id>
				<author_profile_id><![CDATA[81100027175]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ronald]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Goldman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Laboratory, Computer Science Dept., Univ. of Waterloo, Waterloo, Ontario, Canada N2L 3G1]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>913388</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barry, Phillip J., Urn models, recursive curve schemes, and computer aided geometric design, Ph.D. dissertation, Dept. of Mathematics, University of Utah, Salt Lake City, 1987.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barry, Phillip J. and Goldman, Ronald N,, Piecewise polynomial recursive curve schemes and computer aided geometric design, in prepexation.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>910231</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barsky, Brian A., The beta-spline: a local representation based on shape parameters and fundamental geometric measures, Ph.D. dissertation, Computer Science Dept., University of Utah, Salt Lake City, 1981.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[de Boor, Carl, On calculating with B-splines, Journal of Approzimation Theory 6, (1972), 50-62.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[de Boor, Carl, A Pyaetical Guide to Splines, Springer-Verlag, New York, 1978.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Burden, Richard L., Faires, J.Douglas, and Reynolds, Albert C., Numerical Analysis, Prrindle, Weber, and Schmidt, Boston, 1978.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin and Rom, Raphael, A class of local interpolating splines, in R.E. Barnhill and R.F. Riesenfe}d (eds.) Computer Aided Geometric Design, Academic Press, New York, 1974, 317-326.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cox, M.G., The numerical evaluation of B-splines, J. Inst. Maths. Applies. 10, (1972), 134-149.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[DeRose, Anthony D. and Barsky, Brian A., Geometric continuity and shape parameters for Catmull-Rom splines, submitted for publication.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[DeRose, Anthony D. and Holman, Thomas J., The triangle: a multiprocessor architecture for fast curve and surface generation, submitted for publication.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Overhauser, A.H., Analytic definition of curves and surfaces by parabolic blending, Scientific Research Staff Publication, Ford Motor Co., Detroit, Michigan, 1968.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Ramshaw, Lyle, Blossoming: A Connect-the-Dots Approach to Splines, Digital Systems Research Center, Palo Alto, California, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>906872</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Riesenfeld, Richard F., Applications of B-epline approximation to geometric problems of computer-aided design, Ph.D. dissertation, Dept. of Systems and Information Science, Syracuse University, Syracuse, New York, 1973.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~ Computer Graphics, Volume 22, Number 4, August 1988 A Recursive Evaluation Algorithm for a Class 
of Catmull-Rom Splines Phillip J. Barry and Ronald N. Goldman Computer Graphics Laboratory Computer Science 
Dept., Univ. of Waterloo Waterloo, Ontario, Canada N2L 3G1 Abstract: It is known that certain CatmulbRom 
splines[7] inter-polate their control vertices and share many properties such as affine invariance, global 
smoothness, and local control with B-spline curves; they are therefore of possible interest to computer 
aided design. It is shown here that another property a class of Catmull-Rom splines shares with B-spline 
curves is that both schemes possess a simple recursive evaluation algorithm. The CatmulbRom evaluation 
algo- rithm is constructed by combining the de Boor algorithm for evaluat- ing B-spline curves with Neville's 
algorithm for evaluating Lagrange polynomials. The recursive evaluation algorithm for Catmull-Rom curves 
allows rapid evaluation of these curves by pipellning with spe- cially designed hardware. Furthermore 
it facilitates the development of new, related curve schemes which may have useful shape param- eters 
for altering the shape of the curve without moving the control vertices. It may also be used for constructing 
transformations to B~sier and B-spline form. Categories and Subject Descriptors: G.I.1 [Numerical Anal= 
ysis]: Interpolation --Spline and piecewise polynomial interpola- tion; G.1.2 [Numerical Analysis]: Approximation 
--Spline and piecewise polynomial approzima~ion; 1.3.5 ]Computer Graphics]: Computational Geometry and 
Object Modeling -- Curve and surface representation Additional ]Key Words and Phrases: B-spline, Catmull-Rom 
spline, de Boor algorithm, Lagrange polynomial, Neville's algorithm, recursive evaluation algorithm Introduction 
In computer aided design designers often use B-spline curves: S(t) = ~ iVt(t)~ (i) where the Vi are 
points called con(rol vertices and the N~(t) are de- gree n (order n + 1} piecewise polynomial blending 
functions called B-splines or B-spline basis functions. These blending functions de- pend on a set of 
knots {tl}. By altering the control vertices, and perhaps the knots, the designer is able to manipulate 
the shape of t,he curve I13]. B-spline curves are useful for many reasons, among them Permission to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM -0-89791-275-6/88/008/0199 
$00.75 --piecewise polynomials: B-spline curves are piecewise polyno- mial. They are therefore easy to 
store and manipulate, while often being faster to compute and analyze than single polynomials because 
usually one can use lower degree piecewise polynomials. differentiability: B-spline curves have a high 
degree of smooth- ness. Usually the curve will be n-1 times continuously differentiable, although by 
introducing multiple knots it can be designed to be less smooth. local control: altering a single control 
vertex affects only a lim- ited portion of the curve rather than the entire curve. This is because the 
blending function N~(t) is 0 outside of the interval Its, t~+~+l}. a~ne invaxiance: the B-spline basis 
functions are normalised to sum to 1. This implies that B-spline curves are invariant under afflne transformations. 
Thus these curves depend only on the relative geometry of their control vertices, and not on any absolute 
coordinate system. recursive evaluation algorithm: There is a simple, numerically stable, recursive evaluation 
algorithm for B-spline curves called the de Boor algorithm [4], which computes points along S(t} without 
explicitly evaluating N~(t). While B-spline curves do have many desirable properties, there are some 
desirable features they lack. For example, B-spline curves are approximating curves; that is, they approximate 
the shape and position of the control polygon (the polygon obtained by connect- ing the control vertices 
in order with line segments), bat in general they do not interpolate the control vertices. For some applications 
in computer aided geometric design it is desirable for the control vertices to actually lie on the curve. 
Many known curve schemes in- terpolate their control vertices, however these curve schemes usually have 
other drawbacks. Natural cubic spllnes (see, e.g., [5] or [6]), for example, do not have local control 
or a known recursive evaluation algorithm. Certain curve schemes have been developed which retain many 
B-spline carve properties while incorporating additional features. Catmull-Rom splines are one such scheme. 
Catmull and Rom noted that, in any curve scheme, one can replace control vertices with func- tions, and 
thus get a more general scheme [7]. Various choices of these functions impart different desirable properties 
to the curve. In particular, they observed that certain choices led to interpolatory curves. Although 
Catmull and Rom discussed a more general case, we will restrict our attention to an important class of 
Catmull-Rom splines obtained by combining B-spline basis functions and Lagrange interpolating polynomials. 
These Catmull-Rom splines, which we shall define more precisely below, have many nice features. They 
are plecewise polynomial, have local support, are invariant under affine transformations, and have certain 
differentiability and interpolatory properties. The purpose of this paper is to show that they also have 
a recursive evaluation algorithm similar to the de Boor algorithm for B-splines. This new result is interesting 
for many reasons. First, by em-ploying this algorithm and specially designed hardware one can eval- uate 
and render such curves very rapidly [10]. Second, the fact that CatmulbRom splines possess such an evaluation 
algorithm places them in a class of curves called =piecewise recursive curve schemes ~ [2]. These schemes 
generate new curves which may not only retain certain properties of Catmull-Rom splines but also possess 
shape parameters, scalars which affect the shape of a curve without mov-ing the control vertices. Third, 
general results for recursive curve f SIGGRAPH '88, Atlanta, August 1-5, 1988 schemes provide ways of 
transforming Catmull-Rom splines to Bdzier or B-spline form. Finally, the fact that Catmull-Rom splines 
have a rectursive evaluation algorithm of this sort makes them notewor- thy because very few welLknown 
piecewise polynomial schemes have such an evaluation algorithm. This paper is structured as follows: 
in Section 2 we will give more details concerning Catmull-Rom splines and then introduce the recursive 
evaluation algorithm and make some observations about it. In Section 3 we give some concrete examples 
by looking at a few cubic Catmull-Rom splines. Section 4 contains concluding remarks. 2 Cntmull-Rom splinea 
and their rec~aive evaluation al- gorithm This section is divided into three parts. In Subsection 2.1 
we define the class of Catmull-Rom splines with which we are concerned and discuss the properties of 
the splines in this class. In Subsection 2.2 we introduce the recursive evaluation algorithm for this 
class of curves. Subsection 2.3 contains a discussion of some aspects of the algorithm. 2.1 Catmnll-Rom 
splines Catmull and Rom noted that if one began with a curve scheme D(t) = ~ F, (t)V, (2) one could 
replace the control vertices V/by functions V~ (~) which may depend on new control vertices. The resulting 
curve scheme will be more general than the original schem% since V~(t) can be thought of as a generalization 
of V/. This generality can be exploited to endow the new curve with special properties; in particular 
Catmull and Rom observed that special choices of Vi(t) will result in .D(t} interpolating certain points. 
 We will now center our attention on an important subclass of this class of curves. We will employ a 
notation more suitable for our needs than that used in [7]. Suppose one wishes to generalize B-spline 
curves. Let the blend- ing functions F/(t) in (2) be the B-spline basis functions N~(t) with knot set 
{ti}. One can choose the V/(t) to be the Lagrange interpo- lating polynomials of degree m which interpolate 
the control vertices Pi-m, ..., P~ at any distinct nodes Sl--m,..., st, respectively. Unlike the knots, 
we do not require the nodes to be increasing. Although Catmull and Rom equated the nodes s] with the 
knots ti, we will allow the nodes to be arbitrary, as long as they are distinct. Anal- ogous to the interpolation 
result in [7], if *j E [ty+n, ti+~+t ), then D{s#} --Pi {the spline is interpolatory). Note this requires 
rn > n. (If tj+~+1 is not a knot of multiplicity n + 1, then D(s#) = Pi if tj E [ty+n,ti+m+l]. ) Regardless 
of whether or not the spline is in- terpolatory, it will always be a degree n + m piecewise polynomial, 
 -1 times continuously differentlable, affine invariant, and have local control. All these properties 
are inherited from properties of the B-spllne basis functions N~(t) and the Lagrange interpolating polynomials 
V/{t). The Catmull-Rom splines in this class can be written either as D(t) = ~ N~(t)V~(t) (3) i or, 
collecting coefficients of P~, as D(t) = ~ C,~(t)~ (4) for some functions olct}. The G~(t) are called 
the Catmull-Rom blending functions and are sums of products of certain B-spline and Lagrange basis functions. 
More specifically if we let L~ (t) denote the Lagrange cardinal function which has nodes sy_,~,..., sj 
and which is 1 at sl, j -- rn < i < j, then i v~Ct)= ~ L~,.{t)P. (5) and it is then not difficult to 
see that i+m G,:(t) = ~ N$Ct)L.~jCt). (6) When s i E [ti+.,ti+m+l } for all j, then these blending functions 
satisfy the cardinal conditions Gi(si) = 5~y since if j # i then either LT.~(s#) = 0 or N~(s;) = 0 while 
if ~ = ~ then LT, As;) = ~ for t# =i ..... i+rn and E~+__~ N~(sj) = 1. For Catmull-Rom splines we have 
a set of knots {t~} and a set of nodes {sy}. To simplify the number of parameters, we can express the 
s's in terms of the Ps. For example, we can equate the nodes with the knots. If for all j we set %. = 
ty+k for any integer k such that n < k < m (n < k < m+ 1 ff all the knots have multiplicity 1), we will 
not destroy any interpolation present. Another possibility is to equate the Lagrange nodes to the B-spline 
nodes (cf. [5, p.214]). If the B-spline has multiple knots, equating knots and nodes will create a singularity 
in the Lagrange curve. The usual method of overcoming this difficulty is to use a scheme which also interpolates 
certain derivative values; however, such a scheme will not have a recursive evaluation algorithm of the 
type developed below. Thus, when the B-spline has multiple knots, one cannot totally equate the Lagrange 
nodes to the B-spline knots. One can do so partially as long as no assignments are made resulting in 
singularities. Some examples of Catmull-Rom splines and their blending func- tions will be shown in Section 
3. 2.2 The recursive evaluation algorithm We now introduce a recursive evaluation algorithm for this 
class of Catmull-Rom curves. To do this, we call to mind two other recur- sire evaluation algorithms 
-- the above mentioned de Boor algorithm [4] for B-spline curves, and Neville's algorithm (cf. [6]) for 
Lagrange polynomials. To evaluate a B-spline curve S(t) for t C [t,, tq+l) , set P~(t) = v, i = q -,~ 
..... q P[{t) --t.+z+i-r -t pr_Zft~ t -ti ----,_,,, + P:-l(t) ttt+l+i--r --ti tn+l+i--r --ti r = 1,...,rt; 
i=q--rt+r,...,q. (7) Then S(t) = P~(t). The de Boor algorithm can be represented in a triangular array 
as shown in Figure 1. An example using this algorithm to evaluate a B-spllne curve is given in Section 
3. pq3(t) tq÷l-t / Xt-t q tq+l-/ Xl-tq Pq2_l(t) P~(t) tq+ 1 --tq-l/ tq+ l --tq_ 1 tq+ 2 --tq X+2 --tq 
  / \/ Pql_2(t) Pql_l(t) pql (t) tq+l-- t t --tq-2 tq+ --t -- tq-1 +3--t t --tq tq+l --tq-2 tq+l --tq-2 
tq.2 --tq_ 1 3 tq 3 tq / \/ Vq_3 Vq_2 Vq_ I Vq l¢ignre 1: A diagram of the de Boor algorithm for evalu- 
ating a B-spline curve S(t). The cubic case (n = 3) is shown where t E [tq, tq+l I. The control vertices 
V~ are placed at the bottom of the triangle and blended together until the point P~(t) = S(~) is obtained. 
Neville's algorithm is a recnrsive algorithm for evaluating the Lagrange polynomial L(t) which interpolates 
points P0,.-.,P~ at nodes so,..., s~. It can be written as P?(O= e, i=O ..... m P{{t) = sl -t p;__zz(t 
) + t-s,_, p~_Z(t) Si --Si--r Si --Sl--r r= 1,...,rn; i=r,...,rn. (8) Then L(t) = P2(t). Figure 2 shows 
a diagram of Neville's algo- ~ Computer Graphics, Volume 22, Number 4, August 1988 rithm as a triangular 
array. An example using Neville's algorithm to evaluate a Lagrange polynomial is given in Section 3. 
P33(t) t3~.~/ ~ t--tO t3 ~-to t2-t / ~-tto t, St, ~ 3"V"7"t, \/ \ PI(t) P~(t) P3(0 t~ t-t o t z- __t~ 
t~-t t~t~ X /t2-tl t2--tl~ /t3--t 2 ~ t2 tl ~ -to Pc P, P~ P, Figure 2: A diagram of Neville's algorithm 
for evaluat- ing a Lagrange polynomial L(t). The cubic ease (m = 3) is shown. The control points P~ are 
placed at the bottom of the triangle and blended together until the point P~(t) ~ L(t) is obtained. To 
evaluate a Catmull-Rom spline we could naively first use Neville's algorithm to calculate the functions 
I,~(Q and then apply the de Boor algorithm to obtain a point on the curve D(t). See Figure 3 for a diagram 
of this procedure. Note that although Fig- ure 8 does present a recursive evaluation algorithm for Catmull-Rom 
curves, this Mgorithm is neither as efficient nor as elegant as, e.g., the de Boor algorithm for B-spline 
curves since the de Boor algorithm can be represented in a more compact triangular form (Figure I). 
What is remaxkable about Catmull-Rom splines is that this naive recursive evaluation algorithm can be 
simplified extensively because there is substantial overlap in evaluating succesive V/(t)'s. Let P~(t) 
be the point P~(t) computed in evaluating V~(t) by Neville's algo- rithm. Then, since I.~(t) and V~+l(t)share 
the nodes st-m+,,..., s~ and the control vertices Pi_,~+,, ..., Pi, the parameters used in cal- culating 
P~+,,i(t} are identical to the corresponding parameters used in computing e~i+i (t) when 2" < m. Therefore 
P;+,,, (t) = P~,+i (t) for 2' < m. In particular the points P~_1,1+1(t) are found in eval- uating ~{t) 
and therefore do not need to be recomputed in evalu- ating l'~+l(t). If we store these points, then (see 
Figure 2} we need only compute the m new values P~,i+t(t) r = 1,..., m to evaluate v~+~(O. This redundancy 
leads to a simpler and less costly evaluation al- gorithm for Catmull-Rom splines. This algorithm can 
be represented by a triangular diagram, an example of which is shown in Figure 4, similar to the diagrams 
in Figures 1 and 2. We now write down explicitly the recursive evaluation algorithm for Catmull-Rom 
splines. To evaluate the Catmull-Rom curve D(Q for t E [tq,tq+l) J set Pp(t) = P, ~=q-.-m ..... q ~'(t) 
-s~ - t e:.::(t) + : -s,_. P:-qO 8i --Si--r 8i --$i--r r = 1,...,m; i=q--n--rn+r,...,q. t.+~+,_,z~p:z:(O 
+ t-t, e:(t) r=m+l~...,m+n; i=q--n--m+r,...,q. {9) Then D(t) = W+"(t}-To verify that P~n+n(t) does indeed 
equal D(t), merely note that the first stage of the algorithm produces the Lagrange curves P~(t) = P~[t) 
i = q --n ..... q and the second stage applies the de Boor algorithm to these curves. /\ D(t)   /\/\ 
Vq_ 2 (t) Vq_ 1 (t) Vq(t) ,/\ / \ ./\ /N/X/X/X/N/", Pq--4 Pq-3 Pq-2 Pq-3 Pq-2 Pq-, Pq-2 Pq-I Pq Figure 
3: One possible means of evaluating Catmull-ltom splines is to evaluate each of the Vi (t) separately 
by Neville's algorithm, and then blend these curves together by the de Boor algorithm to get D(t). Such 
a technique can be repre- sented as shown (for the case n = m = 2). D(t) /\  /\/\ Vq_2(t ) Vq_ I 
(t) Vq(t) / \/\/\ / \/\/\/\ Pq--4 Pq-3 Pq-2 Pq-I Pq  Figure 4: A diagram of the recursive evaluation 
algo- rithm for Catmull-Rom curves. The case shown is ~ = m = 2. The lower levels in Figure 3 can be 
combined to yield the algorithm shown here. This algorithm is theoretically less complicated and computationally 
less expensive than the one in Figure $. 2.3 A discussion of the algorithm In this subsection we will 
discuss a few important aspects of the recursive evaluation algorithm for Catmull-Rom splines. As with 
B-splines, it is possible to use the standard tensor prod- uct construction to obtain rectangular tensor 
product CatmuII-Rom surfaces. Such surfaces will possess geometric properties similar to those possessed 
by Catmull-Rom curves, and will also possess an analogous recursive evaluation algorithm. Whether one 
can con- struct similar surfaces for triangular domains is still an open ques- tion. We mentioned 
above that one of the reasons the recursive evalua- tion algorithm for Catmull-Rom curves is important 
is that it allows fast evaluation of the curve. If one used a processor to compute each new point P~(t) 
and ran the processors in parallel, one could cal- culate points on the curve extremely rapidly [10]. 
A slightly more complicated multlprocessor architecture would allow rapid evalua- tion of Catmull-Rom 
tensor product surfaces. Such architectures would permit real-time interactive design using Catmull-Rom 
tensor product surfaces and/or large numbers of Catmull-Rom splines. Shape parameters axe scalars which 
affect the shape of the curve without moving the control vertices (cf. [3]). They are useful for in- 
troducing features such as tension into a curve. By altering a single  / SIGGRAPH '88, Atlanta, August 
1-5, 1988 shape parameter one can often obtain a curve which would other- wise have required simultaneously 
changing the positions of many control vertices. CatmuU-Rom splines do not have shape parame- ters as 
such, although it may be possible to develop useful shape parameters based on the knots and/or the nodes. 
(Another possibil- ity --visually continuous Catmull=Rom splines -- has been studied in [9].) We can, 
however, use the recursive evaluation algorithm to construct curve schemes which have shape parameters 
and which axe related to Catmull-Rom splines. One can modify the recursive evalu- ation algorithm so 
that for some choices of r, i and shape parameters ar,i ~ br,i ~ -a::~a,,, -,- i at=bE,,, P;-'(t) (10) 
t _  v:(O P~_, (0 r,i while the remainder of the algorithm stays the same. The resulting curves will 
still have a recursive evaluation algorithm, be piecewise polynomial, have local support, and be afllne 
invaxiant. Depending on how the shape parameters axe introduced, the curves may retain differentiability 
and interpolatory properties. Again, the effects of such shape parameters need further study. Another 
reason that a recursive evaluation algorithm is impor- tant is that it can be applied to develop transformation 
formulas. By using the recursive evaluation algorithm and techniques such as degree raising and duality 
[1] or a method called "blossoming" [12], it is possible to transform Catmuil-Rom curves to B-spline 
or B~zier form. Further research is needed to investigate the efficiency of these transformation techniques 
and to determine whether these methods can be generalized to yield other transformations algorithms. 
As with B-spiines (cf. [12]), the triangular arrays representing the recursive evaluation algorithm for 
contiguous segments of a Catmull- Rom spline mesh together. H we overlay the triangular arrays for two 
adjacent segments of the spllne so that the shared control points lie directly on top of one another, 
then the functions on overlapping edges of the diagram will be identical [2]. This makes Catmull-Rom 
splines especially noteworthy since very few piecewise polynomial schemes have a simple evaluation algorithm, 
let alone one of this special form. There axe certain properties possessed by the de Boor algorithm 
which axe not possessed by the Catmull-Rom evaluation algorithm. Since the de Boor algorithm calculates 
new points by taking convex combinations of old points, it is numerically stable. However, any reasonably 
smooth interpolatory curve will not lie in the convex hull of its control vertices; therefore the evaluation 
algorithm for Catmull- Rom splines may be unstable. In particulax instability can occur when there is 
a large variation in the spacing between the knots or the nodes. This instability is a consequence of 
a similar problem in Neville's algorithm. Another difference is that there is a closer connection between 
the de Boor algorithm and the B-spline basis functions than between the evaluation algorithm for Catmull-Rom 
splines and the Catmull-Rom basis functions. For example, one can derive the Cox-Mansfield-de Boor recur- 
rence relationship [4,8] for the B-spline basis functions from the de Boor algorithm. Similarly one can 
derive a recursion formula for the CatmuU-Rom blending functions from the recursive evaluation algo- 
rithm for Catmull-Rom curves. However, in the recursion formula for B-splines, B-splines are computed 
directly from lower degree ]3- splines, while the Catmull-Rom blendlng functions are not computed directly 
from lower degree Catmun-Rom blending functions. Again this happens because Neville's algorithm does 
not compute the La- grange basis functions from a Lagrange basis of lower degree. Examples In this section 
we will examine a few cubic Catmull-Rom splines and their recursive evaluation algorithms. We take the 
B-spline knots to be uniformly spaced with tl = £, define the Lagrange nodes by sy = ~y+~, and consider 
the evaluation algorithm for the interval [0,1]. For each example we will provide a set of four graphs: 
a diagram of the recursive evaluation algorithm, a spline curve, an example using the recurslve evaluation 
algorithm to evaluate a point on the curve, and a graph of one of the blending functions. In the graphs 
showing evaluation, the only point P~'(t) which lies on the curve is F~(t). That some of the other points 
appear to lie on the curve is merely coincidental. Also, since the knot spacing in the examples is uniform, 
all other blending functions are translates of the one shown in the blending function graphs. For cubics 
we have four possibilities for n and r~. If we choose n = 3, rn = 0 we will obtain the usual cubic B-spline 
which is twice continuously differentiable. The graphs for this case are shown in Figure 5. The case 
n = 2, rn = 1produces a spline which is C 1. Figure 6 shows the illustrations for this case. The case 
n = 1, m = 2 illustrates some elegant properties of Catmull-Rom splines. The figures for this case axe 
presented in Fig- ure 7. The resulting spline is guaranteed to be C ° and interpolating. It is, however, 
actually C 1. Indeed, for any Catmull-Rom spline if for all 3" we let sy = t¢+~ for any integer k such 
that n < k ~ m, Po3(t) P l2 (t) Po2(t) t+ 1 2-t -'2--2 \ / 1-t t+2 2-t t+ 1 3-t .-3---~-.-7 -3- \/ \/ 
P-3 P-2 P-I PO Figure 5a "..° ...... ..'" Figure 5b P-3 P0 P~ p,'(.4) 0 z~ P~(A) = 0(.4) &#38;#169; 
 P:(.4) P-~ P-~ Figure 5c Figure 5d Figure 5: Various figures for cubic Catmull-Rom splines with n = 
3, m = 0, ti = i. Since m = 0 this is a C s B-spline curve. Figure 5a shows a diagram of the evaluation 
algorithm for t E [0, 1], Figure 5b shows an example of such a spline along with its control polygon, 
Figure 5c shows evaluation of the spllne at t = .4, and Figure ~d shows a blending function G~(t). ~ 
 P~(t) /' 1.._~_ t + 1 2-t  2/ -r--r- / \ /  \ t\ I t+2 -t t+l 1-t \/ \/ Y I~3 P-2 P-1 P0 F 
igu.re 6a  / ./ Figure 6b P~3 P--I .~PO. 'i ~o(.4) = o(.4) 0 .......... 'yJ Figure 6c Figure 6d Figure 
6: "Various figures for cubic Catmull-Rom splines with n = 2, m = I, ti = i,~ = i+ 1. The spline consists 
of quadratic B-splines blended with linear Lagrange curves. Figure 6a shows a diagram of the evaluation 
algorithm for t E [0, 11, Figure 6b shows an example of such a spline along with its eontrol polygon, 
Figure 6e shows evaluation of the spline at t = .4~ and Figure 6d shows a blending function Gi(t). Note 
that this spline is C 1. Computer Graphics, Volume 22, Number 4, August 1988 then the curve is C n t2l. 
Note too from Figure 7 that the case n = 1, m = 2, ~j ~- ty+2 is identical to the case n = 2, rn ~ 1 
with sy = ty÷z. In generalj if rt+m = 2d+ 1 for any nonnegative integer d, then by comparing recursive 
evaluation algorithms it can be shown that the cases n = na + 1, sy = ty+m+l and n = m -1, sy = ti+m 
are identical. Finally, the particular case here is also an Overhauser spline [11]. The final cascj shown 
in Figure 8, is n = 0, m = 3, which pro- duces a continuous interpolatory spline. P~(t) P_Zl (t) Po2(t) 
1 -t t + 1 2-t -~" ~ 2   / \/ P_~ (t) P~(t) Plo(t )  7\ I t+ 1 1-t t 2-t \/ \/ P-3 P-2 P-1 Figure 
7a " i " " Figure Tb S P, p/(.4) ¢ r?(,4) ,~ poe(.4) = o(.4) &#38;#169; l P-I P-2 Figure 7e t I I 
I Figure ?d Figure T: "Various figures for cubic Catmull-Rom splines with n = 1, m = 2, t~ = i, s~ = 
i+2. This spiine consists of lin- ear B-spllnes "blended with quadratic Lagrange polynomials. Figure 
Ta shows a diagram of the evaluation algorithm for t E [0, 1], Figure 7b shows an example of such a spline 
along with its control polygon, Figure Tc shows eva]uatlon of the spline at t = .4, and Figure 7d shows 
a blending function Gi(t). This spline is C 1 and interpolatory. 203 SIGGRAPH '88, Atlanta, August 1-5, 
1988 PoS(t) t 3-t "2-2 \ / P-2~ (t) pl(t) e~(t) _ X 7\ I 1 t 2-t t-1 3---t y 2 \/ \/ P-3 m-2 P-1 P0 
Figure 8a Figure 8b P~I(.4) P~(.4) m~(.4) = D(.4) O "",. P- l P~2 Figure 8d Figure 8: Various figures 
for cubic Catmull-Rom splines with n = 0, m---- 3, t~ = i,s~ =i+ 3. Since n = 0 each segment of this 
curve is a cubic Lagrange polynomial. Figure 8a shows a diagram of the evaluation algorithm for t E [0, 
1], Figure 8b shows an example of such a spline along with its control polygon, Figure 8c shows evaluation 
of the spline at t = .4, and Figure 8d shows a blending function G/(t). This spline is C ° and interpolatory. 
4 Concluding remarks In this paper we have shown that a special class of Catmull- Rom splines possess 
a recursive evaluation algorithm similar to the de Boor algorithm for B-splines. This algorithm for Catm~U-Rom 
splines is obtained by combining the deBoor algorithm for the eval- uation of B-splines with Neville's 
algorithm for the evaluation of L~ grange curves. The recursive evaluation algorithm for Catmull-Rom 
splines gives us a possible means of fast evaluation. It also allows the construction of new curve schemes 
which retain some properties of Catmull-Rom curves and which may have useful shape parameters. Another 
benefit is that [t facilitates derivation of some transforma- tion techniques. Further it makes Catmull-Rom 
splines noteworthy since very few known piecewise polynomial schemes have a simple evaluation algorithm. 
Although we have derived one new property of Catmnll-Rom splines, other properties still need to be investigated. 
For exam-ple, what shape preservation properties do Catmull-Rom splines pos- sess? What geometric effects 
can be produced by the introduction of shape parameters? And finally, are there simple algorithms for 
such processes as subdivision, degree elevation, or differentiation of Catmull-Rom splines? .Acknowledgments: 
The research reported here was partially supported by the Natural Sciences and Engineering Research Council 
of Canada, the University of Waterloo, and Control Data Corpora- tion. The authors would also like to 
thank Dr. John Beatty of the University of Waterloo for his helpful remarks. References 1. Barry, Phillip 
J., Urn models, recursive curve schemes, and computer aided geometric design, Ph.D. dissertation, Dept. 
of Mathematics, University of Utah, Salt Lake City, 1987. 2. Barry, Phillip J. and Goldman, Ronald N,, 
Piecewise polyno- mial recursive curve schemes and computer aided geometric design, in prepexation. 
3. Barsky, Brian A., The beta-spline: a local representation based on shape parameters and fundamental 
geometric me~surees, Ph.D. dissertation, Computer Science Dept., University of Utah, Salt Lake City, 
1981. 4. de Boor, Carl, On calculating with B-splines, Journal of Ap- prozimation Theory 6, (1972), 
50-62. 5. de Boor, Carl, A Pyaetical Guide to Splines, Springer-Verlag, New York, 1978. 6. Burden, 
Richard L., Faires, J.Dougla~, and Reynolds, Albert C., Numerical Analysis, Prrindle, Weber, and Schmidt, 
Boston, 1978. 7. Catmull, Edwin and Rom, Raphael, A class of local interpolat- ing splines, in R.E. 
Barnhill and R.F. Riesenfe]d (eds.) Com-pnler Aided Geometric Design, Academic Press, New York, 1974, 
317-326. 8. Cox, M.G., The numerical evaluation of B-splines I J. Inst. Maths. Applies. I0, (1972), 
134-149. 9. DeRose, Anthony D. and Barsky~ Brian A., Geometric continu- ity and shape parameters for 
Catmull-Rom splines, submitted for publication. 10. DeRose, Anthony D. and Holman, Thomas J., The triangle: 
a multiprocessor architecture for fast curve and surface gener&#38;- tion, submitted for publication. 
 11. Overhauser, A.H., Analytic definition of curves and surfaces by parabolic blending, Scientific Research 
Staff Publication, Ford Motor Co., Detroit, Michigan, 1968. 12. Ramshaw, Lyle, Blo*~omlng: A Connec~-~hs-Dots 
Approach to Splines, Digital Systems Research Center, Palo Alto, Califor- nia, 1987. 13. Riesenfeld, 
Richard F., Applications of B-epline approximation to geometric problems of computer-aided design, Ph.D. 
disser- tation, Dept. of Systems and Information Science, Syracuse University, Syracuse, New York, 1973. 
   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378512</article_id>
		<sort_key>205</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Hierarchical B-spline refinement]]></title>
		<page_from>205</page_from>
		<page_to>212</page_to>
		<doi_number>10.1145/54852.378512</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378512</url>
		<abstract>
			<par><![CDATA[<i>Refinement</i> is usually advocated as a means of gaining finer control over a spline curve or surface during editing. For curves, refinement is a local process. It permits the change of control vertices and subsequent editing of the detail in one region of the curve while leaving control vertices in other regions unaffected. For tensor-product surfaces, however, refinement is not local in the sense that it causes control vertices far from a region of interest to change as well as changing the control vertices that influence the region. However, with some care and understanding it is possible to restrict the influence of refinement to the locality at which an editing effect is desired. We present a method of localizing the effect of refinement through the use of <i>overlays</i>, which are hierarchically controlled subdivisions. We also introduce two editing techniques that are effective when using overlays: one is direct surface manipulation through the use of <i>edit points</i> and the other is <i>offset referencing</i> of control vertices.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[free-form surface editing]]></kw>
			<kw><![CDATA[refinement]]></kw>
			<kw><![CDATA[splines]]></kw>
			<kw><![CDATA[subdivision]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Modeling packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Splines</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011070</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Application specific development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003657.10003659</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Nonparametric representations->Spline models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P61545</person_id>
				<author_profile_id><![CDATA[81100153208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Forsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Laboratory, Department of Computer Science, University of Waterloo, Waterloo, Ontario, Canada N2L 3G1]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14177180</person_id>
				<author_profile_id><![CDATA[81100508844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Bartels]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Laboratory, Department of Computer Science, University of Waterloo, Waterloo, Ontario, Canada N2L 3G1]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barr, Alan, "Global and Local Deformations of Solid Primitives", Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics. 18,3 (July, 1984) 21-30.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35072</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bartels, Richard, Beatty, John, and Barsky, Brian, An Introduction to Splines for Use in Computer Graphics and Geometric Modeling, Morgan Kaufmann Publishers, Palo Alto, California (1987).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>911441</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cobb, Elizabeth, Design of Sculptured Sulfaces Using the B-Spline Representation, University of Utah PhD Thesis, Salt Lake City, Utah (1984).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Elaine, Lyche, Tom, and Riesenfeld, Richard, "Discrete B-spfines and Subdivision Techniques in Computer-Aided Geometric Design and Computer Graphics," Computer Graphics and Image Processing, 14,2 (October, 1980) 87-111.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578513</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Faux, Ivor and Pratt, Michael, Computational Geometry for Design and Manufacture, John Wiley &amp; Sons (1979).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Foley, James and van Dam, Andries, Fundamentals of Interactive Computer Graphics, Addison Wesley (1982).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102315</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Forsey, David and Wilhelrns, Jane, "Techniques for Interactive Manipulation of Articulated Bodies Using Dynamic Analysis," Proceedings of Graphics Interface '88 to appear} (1988).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37419</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Joe, Barry, "Discrete Beta-Splines," Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics, 21,4 (July, 1987) 137-144.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4159</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mortenson, Michael, Geometric Modeling, Wiley, New York (1985).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sederberg, Tom and Parry, Scott, "Free-Form Deformation of Solid Geometric Models," Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics, 20,4 (August, 1986) 151-160.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Hierarchical B-Spline Refinement David R. Forsey 
and Richard H. Barrels Computer Graphics Laboratory, Department of Computer Science University of Waterloo, 
Waterloo, Ontario, Canada N2L 3G1 ABSTRACT Refinement is usually advocated as a means of gaining finer 
control over a spline curve or surface during editing. For curves, refinement is a local process. It 
permits the change of control vertices and subsequent editing of fine detail in one reg.'on of the curve 
while leaving control vertices in other reports unaffected. For tensor-product surfaces, however, refinement 
is not local in the sense that it causes control vertices far from a region of interest to change as 
well as changing the control vertices that influence the region. However, with some care and understanding 
it is possible to restrict the influence of refinement to the locality at which an editing effect is 
desired. We present a method of localizing the effect of refinement through the use of overlays, which 
are hierarchically controlled subdivisions. We also introduce two editing techniques that are effective 
when using overlays: one is direct surface manipulation through the use of edit points and the other 
is offset referencing of control vertices. CR Categories and Subject Descriptors: 1.3.5 [Computer Graphics]: 
Computational Geometry and Object Modeling- Curve, surface, solid, and object representations; Geometric 
algorithms, languages, and systems; Hierarchy and geometric transformations; Modeling packages. Key Words 
and Phrases: Splines, free-form surface editing, refinement, subdivision. 1. Introduction The material 
in this paper derives from experience gained during the design of a prototype B-spline surface editor 
intended for the construction of jointed tx>dies to be used in a realistic animation system [7] with 
which one of the authors has become involved. The two issues that influenced the design of the editor 
in this context were: the need to mix broad-scale surface manipulations with manipulations of a finer 
nature and the need to superimpose fine-scale details upon broad-scale surface movements and distortions. 
This has led to a hierarchy of surface refinements, which we refer to as overlays, to a representation 
of control vertices in terms of offsets relative to a hierarchy of local reference frames, and to the 
investigation of mechanisms for the direct manipulation of points on surfaces Permission to copy without 
fee all or part of this material is granted provided that the copies are not made or distributed for 
direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM-0-89791-275 
$00.75 -6/88/008/0205 rather than manipulation indirectly through the movement of control vertices. The 
techniques we employ are suitable for any tensor-product, parametric surface, defined in terms of control 
vertices and basis functions, provided that the surface supports a refinement algorithm; i.e. a re-representation 
process that replaces each basis function by an equivalent linear combination of one or more new basis 
functions. This includes, but is not restricted to, surfaces constructed from B-splines, Beta-splines, 
Bezier patches, and NURBS. This paper will develop the underlying ideas in the notation of B-splines, 
and assume that refinement is provided by the Oslo Algorithm [4]. Occasional discussions will be specific 
to the uniform, bicubic B-spline case, to streamline the presentation. The ideas have been implemented 
and tested using uniform cubic B-splines on a Silicon Graphics 4-D workstation. This simplification was 
made for reasons of the ease and speed with which such surfaces are supported on the hardware and in 
the graphics library of this workstation, not out of a limitation of the approach. In Section 2 we will 
give a brief background for spline refinement. Section 3 follows with a description of overlays and their 
construction through the use of refinement. The representation of an overlay through the use of a local 
reference frame and offsets is covered in Section 4. Mechanisms for achieving direct manipulation of 
surface features are mentioned in Section 5. In Section 6 we touch upon some obvious ways to join our 
proposals with techniques introduced by Barr, Cobb, and Sederberg and Parry. Section 7 closes with some 
examples taken from our prototype editor. 2. Terminology and Notation The material that we will be presenting, 
in its broadest formulation, relates to surfaces S(u,v) which are defined by control vertices Vl,j and 
basis functions B i.t ( u ) , B j ,t ( v ) of some polynomial order k and e, respectively, s(..v) = ~ 
~ V,.jB,.t(.)Bj.~(v) . 1 The basis functions, furthermore, should be refinable in the sense that each 
one can be re-expressed as a linear combination of one or more "smaller" basis functions B,.k(u) = ~ 
o~t.,(r)N..,(.) r Bj:(v) = ~ ~j.,(s)N,,,(v) . $ Reflected in this property is a corresponding re-representation 
of the surface in terms of the smaller basis functions and a larger number of control vertices f SIGGRAPH 
'88, Atlanta, August 1-5, 1988 s(.,v) = ~ ~ W..,A',.k(,)S,.~(v) , r where w... = E ~ ~,,,(O~j.,(~)v,j 
. i s Refinement is nonlocal in the sense that, if V~,./ is one control vertex that influences a (large) 
region, to which some fine detail is to be added, it is not possible merely to replace V~,/ by one or 
more control vertices W,,,. The conversion of V's to W's proceeds by way of the conversion of B's to 
N's, and this results in a large-scale replacement of V's by W's. V's that have no influence on the region 
to be edited may be changed along with V's that do have an influence. The foregoing material is often 
presented in matrix terminology; e.g. as in [5,6,9], and we will follow this convention. The matrix notation 
derives from the fact that each of the functions B and N is nonzero in only a small region, where it 
is a piecewise composite of polynomials. For example, taking each polynomial piece of Bt,~(u) and combining 
it with each polynomial piece of Bl,t(v), a surface patch is produced that can be represented as [u][Bu 
][V]IB,]r[v] r , (2 1) where the superscript T stands for the transpose of a matrix or vector. On each 
patch the parameters u and v vary over the unix interval, and  [u]= [luu2 ...u'-t] , [v]= [lvv2 . . 
. v t-' ] The 6,7 ~ patch is given by the control vertices V6...4t+l,,~_t+ 1 . V~_k+l,~ . [ V ] --(2 
2) [ [V~,7_t+ 1 . . V/~,7 Finally lB.] and [B~] are the matrices formed from the polynomial coefficients 
appropriate for the basis pieces in the 6 th and ,7 th parametric intervals rew~eetively. With an array 
of (re+l)× (n+l) control vertices Vo, 0 .,. V0," (2.3) Vm, 0 0 Vm, n and basis functions of order k 
and e respectively, a tensor-product surface consisting of (m-k+2)× (n-t+2) patches is defined. The common 
example is the uniform, bicubic, B-spline case, for which k = e = 4 and both matrices [ B ] are equal 
to , 10 1 0 3 0 (2 4) "~" -630 3-3 1 for all polynomial segments. The refinement process that produces 
basis functions N from basis functions B is derived, in the B-spline, Bcta-spline, Bezler, and NURB case 
by breaking up one or more polynomial segments into a succession of smaller segments. The re-expression 
of the surface defined by the m+l)×(n+l) control vertices [ V ] as a surface of m+M+l)×(n+N+l) new control 
vertices |W] is accomplished by two matrices composed of the a coefficients, [a#,p ] and  [ a,lth, ]: 
[W] = [at¢][V][a,~s~] r , (2.5) where I W#.....k . . W#._k+i, +I,X--£ -t-1 ~ |W] = [W.,x-t.t . . . 
Wp, x .. at,~(g-k+l ) [ ~, ] =  """ ~.kO') Ot~_t +l, ! (X--l + i) - a~,t(X-t +1) [ a,ls~ ] = ~-t +l,t 
(x) "" ~7,t (x) and [V] is as is given in (2.2) This matrix formulation is to be understood in the context 
of the # ,-r th patch and the /~ ,X th subpatch that result from breaking the parametric ranges O<u,v<l 
into a number of subranges O< "'' _<%_<u <%+1_< "'" <1 and 0_< ... _< vx _< v < vx+1_< " " " _< l . 
The simplest example derives from the uniform cubic case where each parametric range in u and v is broken 
at its midpoint. This converts each patch determined by the control vertices t V ] into four equal patches 
according to the diagram  I ! II III I IV 1 0 .4---.U ---I~. 1 Formula (2.1), in turn, is converted 
into [u][B. ][W][B~ ]r[v]r , (2.6)  ,i~ Computer Graphics, Volume 22, Number 4, August 1988 where [B.] 
and [B~] are given by (2.4), [W] is given by (2.5), and f l At ] for regions I and llI [ "le3~] = [[ 
A2 ] for regions II and IV , tAll for regions I and II ['~,~gh, ] = [[ A2] for regions III and IV . The 
matrices [ A ] are given by 1 1 0 0 2 2 1 8 3 4 1 --8 0 [A1] = 0 ! 1_ 0 2 2 1 3 1 0 ~ 4 s and 1 3 1 
-- 0 8 4 8 1 1 0 ~-T 0 [A2] = 1 3 1 0 - 8 4 8 0 0 1 1 2 2 A more thorough treatment of this material, 
and computational algorithms for determining the matrices [ B ] and [. ] in the case of B-spline/Bezier 
surfaces (and by extension, NURBS) can be found in [2]. The computational algorithms presented there 
have their origin in the Oslo Algorithm first presented in [4]. For the case of Beta-splines the material 
in [8] is applicable. 3. Overlays The refinement process described in Section 2 is the standard mechanism 
for reproducing an existing, V-defined surface using a W definition. The major complaint to be made about 
the process is that it frequently generates more W control vertices than we have any intention of moving. 
We would like to retain only those W's that interest us for editing purposes and discard the rest, retaining 
the unedited portion of the surface in its V definition. It is important to remind ourselves that the 
refinement process produces an exact re-representation. The W-defined surface is the same as its V-defined 
parent. Figure 1 shows a small portion of a uniform, bicubic, V-defined surface in cross section (with 
circles indicating the V's), and Figure 2 shows a view of the same surface in a W definition (with black 
dots indicating the W's and with the V's included as circles for comparison). Refinement has been applied 
to the middle portion of the surface (centered about the topmost V). The fight and left margins of the 
surface have not been included in the refinement. If one of the W control vertices is moved, then the 
W surface departs from its V parent, but only in the area influenced by the W control vertex that has 
been changed. Outside of this area, parent and child are identical. Figure 3 shows the V surface superimposed 
on the W surface after one W has been moved. Because of this correspondence, we may continue to use the 
V definition as our basic description of the surface, save for the replacement of a small piece of the 
W definition. Generally more than just one W control vertex must be retained to define this small piece, 
but the number is small relative to the total number of W control vertices that the refinement produces. 
In the bicubic case, for example, 49 W control vertices must be retained in a 7×7 pattern centered around 
the control vertex that has been moved. In the general B-spline case, [1+2(k-1)]×[1+2(£-1)] W's must 
be retained centered about the control vertex that has been moved. 0 0 Figure I. V surface in cross section. 
0 0 0 v Figure 2. W surface in cross sccl~on. 0 0 0 0 0 Figure 3. V surface and altered W surface. 
 SIGGRAPH '88, AtMnta, August 1-5, 1988 We can regard the retained portion of the W definition as a separate 
surface to be manipulated. If we are careful to manipulate only the central W vertex and keep the peripheral 
W vertices static, we can localize editing/refinement processes to restricted patches of the surface. 
Each such localized patch subjected to such restricted editing and used as a replacement for a portion 
of the parent-level substrate constitutes an overlay. We can repeat this approach on the interior of 
an overlay, regarding it, in its turn, to be the parent surface to be subjected to refinement for the 
creation of further overlays. The basic operation of creating an overlay consists of designating a patch 
on the surface at any level of refinement and executing a new refinement step to re-represent this patch. 
Also, we refine a surrounding number of patches sufficient to include the area influenced by any refined 
control vertex that we will manipulate. If this causes overlays to cross each other at some level of 
refinement, the overlays concerned are made into a composite overlay by combining their respective control 
vertices into a single collection. In order to get a feel for the creation of an overlay, it is instructive 
to look at the simplest refinement step that could be carried out on a uniform, bicubic surface. Figure 
4 shows a schematic plan of 7x7 control vertices, along with the 16 patches making up the surface they 
define. This constitutes the minimal surface portion that would change due to any movement of the central 
control vertex, V,,,. If all vertices save V,, , are held fixed, the depicted region can be regarded 
as an independent surface, yet its boundary will always coincide with the larger surface from which it 
was derived. If this area of surface is too large for the scale of detail we wish to introduce, the simplest 
thing we might do is refine each of the central four patches by halving, as was presented at the end 
of Section 2, Figure 5 diagrams the overlay that would result. The black dots represent the W control 
vertices, and the dashed boxes outline the smaller patches that the central W will influence. If only 
this central vertex is moved, and all the others are held fixed, the patches given by the dashed boxes 
can be considered an integral unit of surface whose boundary will always coincide with the 12 surrounding 
patches defined by the circles. This is the style in which overlays are to be created. For editing involving 
the movement of several control vertices, modifying a larger area of surface, the overlay to be created 
must enclose the union of the separate single-vertex overlays. For editing that is to influence a smaller 
region, the refinement must break each patch into a greater number of subpatches. The creation of an 
overlay in the general B-spline case will involve other numbers of patches and V and W control vertices. 
The net effect of refining and subdividing the surface, over time, will be that the surface will be broken 
into a collection of overlays at different levels of refinement. The obvious storage mechanism for managing 
overlays is a tree-structure with each level of depth in the tree corresponding to a level of refinement. 
The root node of the tree defines the basic V-defined surface, and every other node in the tree stores 
information that defines an overlay surface. Every node in the tree points to overlays that are derived 
entirely within the portion. Sibling pointers are used to access information in adjoining patches for 
ease in processing portions of the surface at a common level of refinement. Successive application of 
refinement defines a composite surface reeursively. The composite surface is given by the totality of 
information contained at the root and leaves of the data structure. 4. Offset Referencing Up to this 
point, the formulas have been presented assuming that a single coordinate frame has provided the description 
of each portion of the surface at each level of refinement. This is not suitable in the context of hierarchical 
refinements. When editing takes place at one level of surface definition, any 0 0 0 0 0 0 0 0 0 0 
0 (, () ! Vr,~ O 0 i O 0 0 0 0 0 0 0 0 Figure 4. A 16-patch surface described by 49 control vertices. 
0 0 0 0 0 0 0 O 0 O  0 O -'--+ ++ 4- 0 O 0 O v v v 0 0 0 0 0 0 0 0 Figure S, A 16-patch surface 
with refinement and overlay control vertices. overlays resting within the edited area are expected to 
remain embedded in that area. They will follow editing changes only if the.y can be dynamically tied 
to that area, which amounts to saying that their control vertices must move in accord with the movement 
of the section of surface undergoing edit. One method of achieving this is to represent the control vertices 
of any overlay relative to a frame of reference fixed upon the surface being edited rather than relative 
to the fixed frame of reference defined by some external coordinate system. This brings into consideration 
a "reference~plus-offset" notation for the control vertices. By this we mean that we write each control 
vertex Wi,j of any part of the surface, whether root-level parent surface or overlay at any level of 
refinement, in the form  SIGGRAPH '88, Atlanta, August 1-5, 1988 $. Direct Surface Manipulation and 
Edit Points A composite surface of the nature indicated has a highly complicated structure of control 
vertices. It becomes more sensible to allow direct picking and manipulation of points on the surface 
than to hope that the user can make any sense of the maze of the control graph. The most fundamental 
relationship between surface and control vertices that can be provided is the one that relates each control 
vertex to the point on the surface over which it has maximal influence. A movement of that surface point 
can be converted, transparently to the user, to a corresponding change in that one control vertex. This 
generalizes to areas on the surface influenced by multiple control vertices. The complete implementation 
of the pick operation to achieve these ideas would require a root-finding algorithm to convert a point 
P on the surface to u,v values on some patch. However, it is easy to determine the u,v associated with 
the point P maximally influenced by any given control vertex Vl. j. For example, in the uniform cubic 
case, the point maximally influenced by any control vertex Va,! is given by the formula: 1~1V 4., 1 P 
= ~K i-t,j-1 + ~-vi,j_l + ~-Vt+la-t ) (5.1) 4 1 4 1 + ~(~Vt_t,j + ~Vjj + ~V~+lj ) 1 1 4 1 + "~-( ~Vt-l,j+l 
.-1-~Vi,j+ 1 + "~-Vi+lJ+l ) , We have carried out our preliminary studies by offering only these points 
of maximal influence on the surface for picking and manipulation. The displacement of the above surface 
point P to a new position Q is carried out by adjusting the control vertex of maximal influence. For 
example, in the uniform cubic case, the control vertex V~,j is to be replaced by the new control vertex 
V~,j according to the formula = 36 Vt,j i~'[Q-PI+Vij Of course, Vi.j is to be represented as the fixed 
reference Rid suitable for the V's and an offset Ol, 1 = Vi, j -R~.]. Further, as we have pointed out, 
all overlays depending on the surface just changed must have their reference information updated. In 
the Section 7 we present some examples taken from our prototype surface editor. This editor was written 
in C to run on a Silicon Graphics 4-D workstation. The software uses the Silicon Graphics library for 
its spline computations; consequently all example pictures represent uniform bicubic B-spline surfaces. 
6. Other Manipulation Techniques Each overlay, together with the originally defined surface on which 
the overlays were constructed, may be viewed as an individual spline surface, independently defined by 
control vertices and basis functions. The only conditions required for the integrity of the hierarchical 
composite is that marapulations carried out on any overlay be restncted to the interior of the overlay, 
and that the control-vertex information be stored in reference-plus-offset format. Within this context, 
however, manipulations that are traditionally performed on control vertices may be performed on offset 
information instead. We have presented manipulations that concentrated on the use of edit points, but 
many things are possible. In particular, the composite forms of manipulation suggested by Cobb [3] may 
be used in this context. The result of any hierarchical editing session is a composite surface, whose 
individual components are simply ten.or-product spline surfaces occupying known locations m space. Transformational 
techniques that build new surfaces from existing ones can use the composites produced by our suggestions. 
In particular, Barr [1] and Sederberg and Parry [10] have proposed methods of transforming existing surfaces 
Into deformed surfaces. Barr shows how space curves can be continuously deformed, and then shows how 
such deformations can be applied, approximately, to bivariate, parametric surfaces, by a process of point 
sampling. Scderberg and Parry embed surfaces in a trivariate spline volume, distort the volume by control-vertex 
manipulation, and then compute, approximately, the corresponding deformation of the embedded surface, 
also by a process of point sampling. Either of these techniques would work on the surfaces we have produced. 
7. Examples The surface in Figure 9 was constructed through repeated local refinement around the center 
of the 16-patch surface illustrated in Figure 5. The dark orange portion spans the region created in 
the first step of refinement as illustrated in Figure 6. The light orange portion spans a region created 
by a second step of refinement around the same edit point. Parts b, c, and d of Fi.~ure 9 illustrate 
the effect of moving the central edit point at different levels of refinement. If the central edit point 
is moved at the finest level of refinement, the entire surface is affected (Figure 9b). In Figures 9c 
and 9d, by moving the edit point at coarser levels of refinement, more restricted regions of the surface 
are modified without affecting the integrity of the entire surface. Figure 10a-c illustrates how the 
modifications of the surface at a fine level of refinement affects edits performed at coarser levels 
of refinement. Edits performed at the coarsest level (Figure 10a), are retained when larger regions of 
the surface are modified (Figure 10b-c). After editing at a fine level, the surface can be still be modified 
at the coarsest level of refinement without affecting finer levels (Figure 10d). In Figure 11 lighter 
colored patches denote regions of the surface that have undergone greater refinement. 8. Conclusions 
Tensor product B-splines are quite flexible, but they possess a deficiency when it comes to refinement. 
Refinement may change more control vertices than we wish to manipulate. We present a solution to this 
problem that uses a hierarchical data structure to localize the refinement operations. This data structure 
also supports, by means of offset referencing, a means of allowing a designer to manipulate a surface 
conveniently at various levels of detail. Local refinement and offset referencing provide a flexible 
and powerful new editing tool. Local refinement controls the extent of any modification to the surface, 
and offset referencing allows localized edits to be retained over global changes to the surface. 9. Acknowledgements 
This research was supported in part by the Natural Sciences and Engineering Research Council of Canada 
and in part by the Studio d'Animation Franeais of the National Film Board of Canada. We wish to thank 
Robert Forget for arranging the latter funding. Thanks are also due to Silicon Graphics for the donation 
of the 4-D workstation on which the system was implemented, to Alan Paeth for his IM imaging tools, Victor 
Klassen for his sky and image resizing software, and Stewart Kingdon for his solid texturing software. 
Robert Dickinson of Visual Edge Software participated in many of our formative discussions on this material. 
Comments by the reviewers were most helpful, and we appreciate the care with which they read the manuscript. 
   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378513</article_id>
		<sort_key>213</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Intensity fluctuations and natural texturing]]></title>
		<page_from>213</page_from>
		<page_to>220</page_to>
		<doi_number>10.1145/54852.378513</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378513</url>
		<abstract>
			<par><![CDATA[A model for texturing of surfaces is introduced based on the concept of light intensity fluctuations. During the evaluation of the reflected intensity in the rendering process a non-Gaussian stochastic component is added which is governed by electromagnetic scattering theory. This component simulates the appearence of macroscopic surface irregularities in the image plane by considering not only the mean value of the intensity, given by the usual specular contribution, but also its variance and autocorrelation function. The variance generates the strength and distribution of the intensity fluctuations and the spatiotemporal auto-correlation function can be used to model the form and temporal development of the texture patterns. With an appropriate choice of a few parameters, soft intensity perturbations and bumpy speckle patterns as well as glint effects can be created.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39032389</person_id>
				<author_profile_id><![CDATA[81332510462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wolfgang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Krueger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Art + Com Projekt, HdK Berlin, Hardenbergstr. 27a, D 1000 Berlin 12, West Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abramovitz,M., Stegun,I.A. (eds.), Handbook of Mathematical Functions, Dover, New York, 1964]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Amanatides,J., Realism in Computer Graphics: A Survey, IEEE CC&amp;A, (Jan. 1987), pp. 44-56]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Beckmann,P., Spizzichino,A., The Scattering of Electromagnetic Waves from Rough Surfaces, MacMillan, New York, 1963]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Berry,M.V., Twinkling Exponents in the Catastrophe Theory of Random Short Waves, in "Wave Propagation and Scattering", Uscinski,B.J. (ed.), Clarendon Press, Oxford, 1986, pp. 11-35]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn,J.F., Models of Light Reflection for Computer Synthesized Pictures, Proceedings of SIGGRAPH'77, (San Jose, California, July 20-23, 1977), In Computer Graphics, Vol. II, 2 (1977), pp. 192-198]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blinn,J.F., Simulation of Wrinkled Surfaces, Proceeding of SIGGRAPH'78, (Atlanta, Georgia, August 23-25, 1978), In Computer Graphics, Vol. 12, 3 (1978), pp. 286-292]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37434</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cabral,B., Max,N., Springmeyer,R., Bidirectional Reflection Functions from Surface Bump Maps, Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987), In Computer Graphics, Vol. 19, 4 (1987), pp. 273-281]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Carey,R.J., Greenberg,D.P., Texture for Realistic Image Synthesis, Comput. &amp; Graphics, Vol. 9, 2 (1985), pp. 125-138]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806819</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cook,R.L., Torrance,K.E., A Reflectance Model for Computer Graphics, Proceedings of SIGGRAPH'81 (Dallas, Texas, August 3-7, 1981), In Computer Graphics, Vol. 13, 3 (1981), pp. 307-316]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Haruyama,S., Barsky,B.A., Using Stochastic Modeling for Texture Generation, IEEE CGA, (March 1984), pp. 7-19]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Heckbert,P.S., Survey of Texture Mapping, IEEE CCG&amp;A, (Nov. 1986), pp. 56-57]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hoenders,B.J., Jakeman,E., Baltes,H.P., Steinle, B., K - Correlations and Facet Models in Diffuse Scattering, Optica Acta, Vol. 26, (1979), pp. 1307-1319]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jakeman, E., Pusey,P.N., Non-Gaussian Fluctuations in Electromagnetic Radiation Scattered by a Random Phase Screen, J. Phys. A, Vol. 8, 3 (1975), pp. 369-391]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jakeman, E., Pusey,P.N., Photon Counting Statistics of Optical Scintillations, in "Inverse Scattering Problems in Optics", Baltes,H.P. (ed.), Springer Verlag, Berlin, 1980, pp. 73-116]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jakeman,E., Speckle Statistics with a Small Number of Scatterers, Opt. Engineering, Vol. 23, 4 (Ig84), pp. 453-461]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325167</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kajiya,J.T., Anisotropic Reflection Models, Proceedings of SIGGRAPH'86 (San Francisco, California, July 22-26, 1985), In Computer Graphics, Vol. 19, 3 (1985), pp. 15-21]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lewis,J.P., Generalized Stochastic Subdivision, ACM Trans. on Graphics, Vol. 6, (July 1987), pp. 167-190]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Pusey,P.N., Statistical Properties of Scattered Radiation, in "Photon Correlation Spectroscopy and Velocimetry", Cummins,H.Z., Pike,E.R. (ads.), Plenum Press, New York, 1977, pp. 45-141]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sancer,M.I., Shadow-Corrected Electromagnetic Scattering from a Randomly Rough Surface, IEEE Trans. AP, Vol. 17, (1969), pp. 577-585]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Zardecki,A., Statistical Features of Phase Screens from Scattering Data, in "Inverse Source Problems in Optics", Baltes,H.P. (ed.), Springer Verlag, Berlin, 1978, pp. 155-189]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ Computer Graphics, Volume 22, Number 4, August 1988 I I IIII INTENSITY FLUCTUATIONS AND NATURAL TEXTURING 
Wolfgang Krueger Hochschule der Kuenate, Berlin Art + ComProjekt A model for texturing of surfaces is 
introduced based on the concept of light intensity fluctua- tions. During the evaluation of the reflected 
intensity in the rendering process a non-Gaussian stochastic component is added which is governed by 
electromagnetic scittering theory. This component simulates the appearance of macroscopic surface irregularities 
in the image plane by considering not only the mean value of the intensity, given by the usual specular 
contribution, but also its variance and autocorrelation function. The variance generates the strength 
and distribution of the intensity fluctuations and the spatiotempcral auto- correlation function can 
be used to model the form and temporal develoment of the texture patterns. With an appropriate choice 
of a few parameters, soft intensity perturbations and bumpy speckle patterns as well as glint effects 
can be created. Categories and Subject Descriptors: 1.3.7 (Computer Graphics): Three-Dimensional Graphics 
and Realism- Color, shading, shadowing and texture Autor's address: Art + Com Projekt, HdK Berlin, Hardenbergstr. 
27a, D I000 Berlin 12, West Germany Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed :for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is lay 
permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a 
fee and/or specific permission. 01988 ACM-0-89791-275-6/88/008/0213 $00.75 I. Introduction One of the 
goals of modern computer animation is the simulation of complex natural environments 121. Texture mapping 
is one of the most common tech-niques used to model macroscopic surface patterns 18,10,Iii. These procedures 
usually work with artificial patterns computed with stochastic and/or analytic models. The patterns are 
mapped onto the object surface or are modeled on the surface patch itself. Approaches especially suitable 
for rendering via ray tracing incorporate the texture generating process into the reflection calculations 
16,7,8,161 directly. A wide range of naturally occurring phenomena that are visible to the naked eye 
are characterized by fluctuation effects. Examples are the glittering of a sunlit sea surface or of a 
snow-covered object, the beautiful caustic patterns produced by sunlight on the floor and the surface 
of a pool, the appearance of a glass window on a rainy day or a bathroom window, and the twinkling of 
light sources caused by atmospheric fluctuations. In the following, a natural texturing model is introduced 
which is implemented in a physical ray tracing program. The optical appearance of realistic non-smooth 
surfaces is described by the statistical properties of the intensity of the scattered light. The model 
considered is especially concerned with the following aspects of simulating natural (stochastic) texture 
patterns:   ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 - The model should reproduce the appearance of 
a texture with consideration given to the under- lying natural properties of the object. - The texture 
generation process should be contained in the reflection or transmission calculations, because ray 
tracing methods are better equipped to treat complicated shading models than to render large and/or 
complicated databases.  - The model should take into account the distance dependence of the texture 
appearance. In computer animation, one is only interested in the appearance of the texture in the image 
plane (display screen or other reflecting surfaces in the scenery). Modeling the texture on the surface 
itself often causes serious aliasing problems. - The model should also govern the time development 
 of the pattern. As a first attempt to introduce intensity fluctua- tions of the scattered light into 
computer graphics a simple version of the random phase screen (RPS) method 112-15,18,201 in electromagnetic 
scattering theory is exploited. Section 2 briefly explains this method from a physicist's point of view. 
The first two moments of the probability density function (PDF) and the autoeorrelation function of the 
intensity of the scattered light are given. Section 3 gives the statistical description of the scattered 
light based on the intensity moments. Section 4 shows how this statistical description can be applied 
in computer graphics to generate stochastic texture patterns. Several interesting limiting cases are 
discussed and some test pictures are presented to illustrate the implementation procedure. All textures 
on the pictures are modeled on a single polygon. 2. Reflection from macroscopic rough surfaces In 
general, naturally occurring, that is "non- sanitized" in appearance, scattering surfaces and objects 
with high transparency (glass, dust, clouds, ocean water) can be divided into two basic categories: 
- The fractal type, e.g. surfaces with self-similar roughness properties over many scales, which only 
generates diffraction and interference effects but never caustic effects (glints).  - The smoothly varying 
type with Gaussian-like  correlation properties, which also generates geometrical optics effects associated 
with rays (caustic patterns). For both types the scattered intensity can be described by the RPS model 
113,15,181 which intro- duces spatial and temporal distortions into an incident plane electromagnetic 
wavefront. This distortions are assumed to have scales very large compared to the wavelength. This approach 
is based on the evaluation of the Huygens-Fresnel integral which approximately solves the wave equations 
for electromagnetic scattering theory. The RPS model can extend the results of scattering theory for 
randomly rough surfaces 13[. It permits evaluation of the mean intensity and also predicts higher statistical 
moments such as the variance and the spatiotemporal autocorrelation function of the scattered intensity 
in the observation plane. Those higher moments strongly depend on the surface parameters (mean height 
and correlation length of the surface distortions~, on the relation of the sizes of the distortion elements 
to the size of the illuminated area, and on the distance of the observer from the scattering surface. 
For several classes of random irregularities, e.g. having one- or two-dimensional Gaussian-like or fractal 
cor- relation functions, analytic expressions for the intensity moments can be approximated I13,15,201, 
provided assumptions such as small angle scattering and near or far field only are made. The connection 
of this model to catastrophe optics 141 treating caustic effects in the near field of the scattering 
object, e.g. rippled water surface or drops, should also be mentioned. In the event that we are not 
interested in the "full blown" models of stochastic scattering theory a more tractable approximation 
should be used. This is the discrete scattering model which describes a limited number of uncorrelated 
scattering centers (macro-facets) I13,181 giving randomly phased con- tributions to the scattered electromagnetic 
field.  @ Computer Graphics, Volume 22, Number 4, August 1988 The phase variations are converted into 
non- Gaussian intensity fluctuations by a distance dependent focusing of the light rays (s. Fig. I). 
 observation plane  surface Fig. 1 Focusing of reflected rays  Generally, the reflection model used 
in computer graphics has the additive form Is =Iamb + Idiff + Ispec 15,91, where lamb, Idiff and Ispec 
represent the ambient, diffuse and specular part, respec- tively. Stochastic texture patterns can be 
gene- rated by geometric and/or spectral perturbations of the specular component 16,81. In the following, 
perturbations will be achieved by calculating the specular part via a probabilistic description. The 
scattered electromagnetic field E at space S  point r=(x,y,z) and time t is assumed to be a superposition 
of independent contributions from N facets I13,181  N(r,t) Es(r,t ) = ~ Ai(r,t)'exp(-i¢i(r,t)-00t)) 
. (I) i=1 where the A i(r,t) are the individual scattering amplitudes, ¢i(r,t) are statistically independent 
random phases end ~ is the light frequency. For natural (incoherent) light no interference effects will 
appear such that the specular reflected intensity yields  N(r,t) Is(r,t ) = IEs(r,t) I 2 = Z IAi(r,t) 
l = (2) i=I Neglecting diffraction effects, the statistical mean of the specular reflected intensity 
(2) for very rough surfaces has the general form  (3) < I > = I = D S F s spec  as already been 
used in various reflection models 15,91. The brackets denote averaging over an ensemble of undulating 
surfaces. The decisive quantity to calculate <I > is the probability S  density function D of the local 
slope. For a two- dimensional Gaussian distribution it is given by 13,5,91 1 D = "exp (- tan2y / 2 
" m 2) 2 * IT * m 2- COS ~  (4) where y is the tilt angle of the facet normal and m denotes the mean 
slope. The factor S (~I) depending on the incident and scattering directions accounts for the self-shadowing 
of the facets 19,191. F(n, %) denotes the Fresnel reflection coefficient 15,91 depending on the light 
frequency via the refractive index n and on the scattering angle 8 . s The angles y and 8 can be determined 
from the s incident and scattering directions and the mean surface normal 15,91. The variance 0 1 
of the scattered intensity is given by the effectively contributing number Nef f of facets 113,181 <i2 
> O I < i-s>2 -I -1 (5) i _ = Neff s  where the macro-facet model considered Nef f is given by Nef 
f = N - D - S (6) N is the number of facets covering the visible part of the surface, D is given, for 
example, by (4) end S is the self-shadowing factor. Even for large N the variance may be very large because 
the slope distribution (4) is sharply peaked around the specular direction ~=0). SIGGRAPH '88, Atlanta, 
August 1-5, 1988 The variance (5) describes the interesting non- Gaussian fluctuations representing 
geometrical optics effects, arising from the focusing or lens- like behaviour of the individual scattering 
elements (s. Fig. I). The texture pattern generated by the irregularities of the scatterer in such a 
non-Gaussian configur- ation may have a highly complex spatial and temporal structure. For random distortions 
this structure can be defined by the correlation func- tion of the essential statistical parameter describing 
the irregularities, e.g. local height deviation, refractive index, density of scattering particles. For 
the macro-facet model a convenient description of the spatiotemporal correlation function of the height 
deviation H can be given by Cfacet(R1,tl;Rg,tg) = <H(RI,tl)-H(Rg,tg)>  = Cr(IRi-Rgl).Ct(It2-tiI) (7) 
 where RI,R 2 are points in the surface patch. For example, for smoothly varying facets appearing on 
rippled water surfaces the spatial part C can be r modeled with 2 IRi-R2[ O~ ° (1 - ") for I Ri-R21 
~= T2 r ' r Cr(IR1-R2 t) = 0 for IRI-RgI>T r  (8) where 0 H is the mean height deviation and the 
correlation length T r represents the mean diameter of the facets such that the mean slope is given by 
m = 21/~H/~. For crystalline or random struc- tures C should be modeled by tiny polygons or r random 
two-dimensional shapes, respectively. The temporal part C t of Cface t in (7) can be taken as a constant 
for static glints or as a sinusoidal-like function to simulate the temporal development of a glint 
on a water surface.  The concept of using the spatial and/or temporal autocorrelation function to generate 
the texture appearance is equivalent to the usual spectral modeling 18,10,11,171 due to the Wiener theorem. 
 The spatial autocorrelation function C describes r the shape of the simulated texture pattern and the 
 parameters OH and T provide a suitable measure of r the coarseness or granularity. The rapidity or 
conversely, the persistence, of the patterns is governed by the temporal part C t. In addition, a movement 
of the whole pattern structure can be simulated (see e.g. 118,201). The RPS model describes the appearance 
of the surface texture at the observation plane. By evalu- ating the Huygens-Fresnel integral it maps 
the correlation function Cface t (7) onto the auto- correlation function of the scattered intensity 
 <Is(rl,tl)'Is(rg,tg)> -I (9) Cs(rl'tl;rg'tg) = <I (rl,tl)>'<Is(rz,tz)> s where rl,r 2 are points 
in the observation plane such that one obtains Cs=~ I for rl=r 2 and t2=t I. Approximated analytic results 
for a variety of surface or volume structures can be found in 112-1s,18,2ol. The macro-facet model will 
be applied in the following sections to simulate natural texturing in computer graphics. It neglects 
all diffraction and interference effects such that the intensity auto- correlation function (9) can simply 
be calculated by a perspective projection of Cfacet/O ~ onto the observation plane. 3. Statistical description 
of the specular scattered light In "classical" reflection models (see e.g. 15,91) the specular part 
of the reflected intensity in the image plane is given by expressions equivalent to the mean value <I 
> (3). For non-zero intensity s variances (5) the scattered specular intensity Ifluc , fluctuating around 
the mean specular part <I >, has to be described by a probability density s function (PDF). The functional 
form of this PDF strongly depends on the scattering environment and  @ Computer Graphics, Volume 22, 
Number 4, August 1988 i | i on the illumination considered. An appropriate form of the PDF for the scattering 
of natural (incoherent) light from a random configuration of macro-facets has been suggested to be the 
gamma distribution If41 ~--~a'Ifluc e-1 .exp(- e'Ifluc) PF(Ifluc ) = <I >,F(~) "~ <I > " <I > S S S 
 (lO) whereF (~) is the gamma function and the parameter is given by = ~/o i (ii) Obviously, for 0 
~=i this distribution degenerates to the form for a totally random Gaussian process Ifluc  i .exp(- 
~i-V-" (12) Prand(Ifluc ) - <I > s s  which generates "perfectly" noisy pictures (speckle). For very 
large ~ (small variances) P F(Ifluc) degenerates into a Gaussian distribution for Ifluc. For very large 
N in (6) this is expected by virtue of the central limit theorem.  The gamma distribution (I0) is appropriate 
for describing fluctuations of the "effective" facet number Nef f . Texture models simulating more complex 
patterns with composite scales, appearing e.g. in remote sensing models, should be constructed with K-distributions 
(K is the modified Bessel function)  I12,1~I 4. Modeling of natural texture patterns  The simple macro-facet 
scattering model was chosen such that the requirements of computational trac- tability are fulfilled. 
To apply this model in computer graphics the generation of natural texture patterns is divided into two 
steps. In line with the general input form used in computer graphics the scattered intensity in the 
image plane can be written I = Iamb + Idiff + Ifluc (13) where Ifluc represents the fluctuating specular 
part. In the first step the additional fluctuation term Ifluc in (13) will be locally evaluated with 
(S), (9) and (ll) via the probability that Ifluc exceeds a given pseudo-random number RN uniformly 
distri- buted in (0,1). Then one obtains Ifluc by inverting KIfluc~ / PF(I') dI' = F(~, <I > " =RN 
(14) Ifluc s where F (e,B) is the incomplete gamma fT/nction tabulated in llI. Using the leading expansion 
terms of the error function and of F (a,B) Ill, equation (14) can be approximately inverted in two inter- 
esting limits <is>.(1 + (2~-0~) i/z .(RN-0.5)) for O~<<I, Iflu c % 2 ° I <Is>'U~'RN for o~>>I.  (15) 
 From (15) it follows that for very large intensity variances (5) Ifluc will almost everywhere be equal 
 to zero and only a few centers of caustic effects will appear for RN =I. Glint effects on water, snow, 
or mineral surfaces can be modeled within this range of (~I'2 On the other hand, for small (YI the 
fluctuation term will almost everywhere be equal to < Is> , and the intensity (15) will appear to fluctuate 
only softly. This case simulates "diffuse" reflection from objects with very rough surfaces or those 
consisting of inhomogeneous material such as building materials, ceramics, textiles, paper and biological 
substances. In the special case e = 1 (noise-to-signal ratio equal to one) equation (14) can be exactly 
inverted to   SIGGRAPH '88, Atlanta, August 1-5, 1988 5. Conclusions  In this work a preliminary 
simple model for natural texturing is introduced which exploits the physical concept of light intensity 
fluctuations. For describing the complex random appearance of naturally occurring surfaces it seems to 
be important to study not only the mean specular reflected intensity hut also its variance and auto- 
correlation moment. The intensity variance generates the amount and the distribution of the facet-like 
scattering elements whereas the auto- correlation function determines the spatial appearance and temporal 
development. The model can be implemented in the reflection coefficient routine of rendering programs, 
e.g. ray tracing. The model is not very time consuming and no mapping problems arise. The set of parameters 
given allows a simulation of a wide class of surface structures occurring in nature, but textures which 
carry a large amount of information cannot be modeled by this construction. Acknowledgements  I am 
grateful to the reviewers, H.-J. Andree and John A. Berton for helpful discussions and suggestions, and 
to ARRI TV, Munich, for technical support. A part of this work was performed at mental images, Berlin. 
 References  I. Abramovitz,M., Stegun,I.A. (eds.), Handbook of Mathematical Functions, Dover, New York, 
1964 2. Amanatides,J., Realism in Computer Graphics: A Survey, IEEE CC~A, (Jan. 1987), pp. 44-56  3. 
Beckmann,P., Spizzichino,A., The Scattering of Electromagnetic Waves from Rough Surfaces, MacMillan, 
New York, 1963  4. Berry,M.V., Twinkling Exponents in the Catastrophe Theory of Random Short Waves, 
in "Wave Propagation and Scattering", Uscinski,B.J. (ed.), Clarendon Press, Oxford,  1986, pp. 11-35 
 5. Blinn,J.F., Models of Light Reflection for Computer Synthesized Pictures, Proceedings of SIGGRAPH'77, 
(San Jose, California, July 20-23, 1977), In Computer Graphics, Vol. ii, 2 (1977), pp. 192-198  6. Blinn,J.F., 
Simulation of Wrinkled Surfaces, Proceeding of SIGGRAPH'78, (Atlanta, Georgia, August 23-25, 1978), In 
Computer Graphics, Vol. 12, 3 (1978), pp. 286-292  7. Cabral,B., Max,N., Springmeyer,R., Bidirectional 
Reflection Functions from Surface Bump Maps, Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 
1987), In Computer Graphics, Vol. 19, 4 (1987), pp. 273-281  8. Carey,R.J., Greenberg,D.P., Texture 
for Realistic Image Synthesis, Comput. &#38; Graphics, Vol. 9, 2 (1985), pp. 125-138  9. Cook,R.L., 
Torrance,K.E., A Reflectance Model for Computer Graphics, Proceedings of SIGGRAPH'81 (Dallas, Texas, 
August 3-7, 1981),  In Computer Graphics, Vol. 13, 3 (1981), pp. 307-316 i0. Haruyama,S., Barsky,B.A., 
Using Stochastic Modeling for Texture Generation, IEEE CG~A, (March 1984), pp. 7-19 iI. Heckbert,P.S., 
Survey of Texture Mapping, IEEE CCG~A, (Nov. 1986), pp. 56-57 12. Hoenders,B.J., Jakeman,E., Baltes,H.P., 
Steinle, B., K -Correlations and Facet Models in Diffuse Scattering, Optica Acta, Vol. 26, (1979), pp. 
1307-1319  13. Jakeman,E., Pusey,P.N., Non-Gaussian Fluctuations in Electromagnetic Radiation Scattered 
by a Random Phase Screen, J. Phys. A, Vol. 8, 3 (1975), pp. 369-391  14. Jakeman,E., Pusey,P.N., Photon 
Counting Statistics of Optical Scintillations, in "Inverse Scattering Problems in Optics", Baltes,H.P. 
(ed.), Springer Verlag, Berlin, 1980, pp. 73-116  15. Jakeman,E., Speckle Statistics with a Small Number 
of Scatterers, Opt. Engineering, Vol. 23, 4 (Ig84), pp. 453-461  16. Kajiya,J.T., Anisotropic Reflection 
Models, Proceedings of SIGGRAPH'86 (San Francisco, California, July 22-26, 1985), In Computer Graphics, 
Vol. 19, 3 (1985), pp. 15-21  17. Lewis,J.P., Generalized Stochastic Subdivision, ACM Trans. on Graphics, 
Vol. 6, (July 1987), pp. 167-190  18. Pusey,P.N., Statistical Properties of Scattered Radiation, in 
"Photon Correlation Spectroscopy and Velocimetry", Cummins,H.Z., Pike,E.R. (ads.), Plenum Press, New 
York, 1977, pp. 45-141  19. Sancer,M.I., Shadow-Corrected Electromagnetic Scattering from a Randomly 
Rough Surface, IEEE Trans. AP, Vol. 17, (1969), pp. 577-585  20. Zardecki,A., Statistical Features of 
Phase Screens from Scattering Data, in "Inverse Source Problems in Optics", Baltes,H.P. (ed.), Springer 
Verlag, Berlin, 1978, pp. 155-189    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378514</article_id>
		<sort_key>221</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Reconstruction filters in computer-graphics]]></title>
		<page_from>221</page_from>
		<page_to>228</page_to>
		<doi_number>10.1145/54852.378514</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378514</url>
		<abstract>
			<par><![CDATA[Problems of signal processing arise in image synthesis because of transformations between continuous and discrete representations of 2D images. Aliasing introduced by sampling has received much attention in graphics, but reconstruction of samples into a continuous representation can also cause aliasing as well as other defects in image quality. The problem of designing a filter for use on images is discussed, and a new family of piecewise cubic filters are investigated as a practical demonstration. Two interesting cubic filters are found, one having good antialiasing properties and the other having good image-quality properties. It is also shown that reconstruction using derivative as well as amplitude values can greatly reduce aliasing.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[antialiasing]]></kw>
			<kw><![CDATA[cubic filters]]></kw>
			<kw><![CDATA[derivative reconstruction]]></kw>
			<kw><![CDATA[filters]]></kw>
			<kw><![CDATA[reconstruction]]></kw>
			<kw><![CDATA[sampling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010254</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Reconstruction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14128889</person_id>
				<author_profile_id><![CDATA[81100360165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Mitchell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14091692</person_id>
				<author_profile_id><![CDATA[81100235596]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arun]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Netravali]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Brown, Earl F., "Television: The Subjective Effects of Filter Ringing Transients", Journal of the SMPTE, Vol. 78, No. 4, April 1969, pp. 249-255.]]></ref_text>
				<ref_id>BRO69</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807505</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Catmnll, Edwin, Alvy Ray Smith, "3-D Transformations of Images in Scardine Order", Computer Graphics, Vol. 14, No. 3, pp. 279-285.]]></ref_text>
				<ref_id>CAT80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., "Stochastic Sampling in Computer Graphics", ACM Trans. Graphics, VoL 5, No. 1, January 1986.]]></ref_text>
				<ref_id>COO86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., personal communication, August, 1987.]]></ref_text>
				<ref_id>COO87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Crow, Franklin C., "The Aliasing Problem in Computer- Generated Shaded Images", Comm. ACM, Vol. 20, No. 11, November 1977, pp. 799-805.]]></ref_text>
				<ref_id>CRO77</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dippe, Mark A. Z. and Erling Henry Wold, "Antialiasing Through Stochastic Sampling", Computer Graphics, Vol. 19, No. 3, July 1985, pp. 69-78.]]></ref_text>
				<ref_id>DIP85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Duff, Tom, "Splines in Animation and Modeling", State of the Art in Image Synthesis, SIGGRAPH 86 Course Notes.]]></ref_text>
				<ref_id>DUF86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hou, Hsich S., Harry C. Andrews, "Cubic Splines for Image Interpolation and Digital Filtering", IEEE Trans. Acoustics, Speech, and Signal Processing, Vol. ASSP-26, No. 6, December 1978, pp. 508-517.]]></ref_text>
				<ref_id>HOU78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Keys, Robert, G, "Cubic Convolution Interpolation for Digital Image Processing", IEEE Trans. Acoustics, Speech, and Signal Processing, Vol. ASSP-29, No. 6, December 1981, pp. 1153-1160.]]></ref_text>
				<ref_id>KEY81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Mettz, Pierre, and Frank Grey, "A Theory of Scanning and its Relation to the Characteristics of the Transmitted Signal in Telephotography and Television," Bell System Tech. J., Vol. 13, pp. 464-515, July 1934.]]></ref_text>
				<ref_id>MER84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Mitchell, Don P., "Generating Antialiased Images at Low Sampling Densities", Computer Graphics, Vol. 21, No. 4, July 1987, pp. 65-72.]]></ref_text>
				<ref_id>MIT87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>576199</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Netravali, Arun N., Barry G. Haskell, Digital Pictures: Representation and Compression, New York, Plenum, 1988.]]></ref_text>
				<ref_id>NET88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Park, Stephen K., Robert A. Schowengerdt, "Image Reconstruction by Parametric Cubic Convolution", Computer Vision, Graphics, and Image Processing, Vol. 23, No. 3, September 1983, pp. 258-272.]]></ref_text>
				<ref_id>PAR83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Petersen, Daniel P., David Middleton, "Reconstruction of Multidimensional Stochastic Fields from Discrete Measurements of Amplitude and Gradient", Information and Control, Vol. 7, pp. 445-476.]]></ref_text>
				<ref_id>PET64</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Schreiber, William F., Donald E. Troxel, "Transformation Between Continuous and Discrete Representations of Images: A Perceptual Approach", IEEE Trans. Pattern Analysis and Machine Intelligence, Vol. PAMI-7, No. 2, March 1985, pp. 178-186.]]></ref_text>
				<ref_id>SCH85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Shannon, Claude E., "Communication in the Presence of Noise.", Proc. IRE Vol. 37, 19,49, pp. 10-21.]]></ref_text>
				<ref_id>SHA49</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner, "An Improved Illumination Model for Shaded Display", Comm. ACM, Vol. 23, No. 6, June 1980, pp. 343-349.]]></ref_text>
				<ref_id>WHI80</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Reconstruction Filters in Computer Graphics Don 
P. Mitchell Arun N. Netravali AT&#38;T Bell Laboratories Murray Hill, New Jersey 07974 ABSTRACT Problems 
of signal processing arise in image synthesis because of tlansformations between continuous and discrete 
representations of 2D images. Aliasing introduced by sampling has received much attention in graphics, 
but recon-struction of samples into a continuous representation can also cause aliasing as well as other 
defects in image quality. The prob- lem of designing a filter for use on images is discussed, and a new 
family of piecewise cubic filters are investigated as a practical demonstration. Two interesting cubic 
filters are found, one having good antialiasing pro- perties and the other having good image-quality 
properties. It is also shown that recon- struction using derivative as well as amplitude values can greatly 
reduce aliasing. CR Categories and Subject Descriptions: 1.3.3 [ Computer Graphics ]: Picture]Image 
Generation; 1.4.1 [ Image Processing ]: Digitization General Terms: Algorithms Additional Keywords and 
Phrases: Antialiasing, Cubic Filters, Filters, Derivative Reconstruction, Reconstruction, Sampling 1. 
Introduction The issues of signal processing arise in image synthesis because of transformation between 
continuous and discrete representations of images. A continuous signal is converted to a discrete one 
by sampling, and according to the sampling theorem [SHA49], all the information in the continuous signal 
is preserved in the samples if they are evenly spaced and the frequency of sampling is twice that of 
the highest fre- quency contained in the signal. A discrete signal can be converted to a continuous one 
by interpolating between samples, a process referred to in the signal-processing literature as reconstruction. 
Many conversions between continuous and discrete representations may occur in the course of generating 
an image. For example when ray trac- ing a texture-mapped surface, a photograph may be sampled by a digi- 
tizer to define the texture, then the texture samples are inteqxilated and resampled when a ray strikes 
the textured surface, the ray samples are interpolated and resampled to generate pixel values, and the 
pixels are interpolated by a display and finally resampled by retinal cells when the image is viewed. 
Resampling may be more explicit, as in enlarging or reducing a digital image or warping an image (e.g., 
with Catmull and Smith's algorithm [CAT80]). Each of these conversions can introduce conspicuous errors 
into an image. Errors introduced by sampling (e.g., aliasing) have received considerable attention in 
the graphics community since Crow identified this as the cause of certain unwanted artifacts in synthetic 
images [CRO77]. Alias-ing in images was discussed in the classic 1934 paper by Mertz and Gray [MER34]. 
Their discussion contains a description of artifacts well-known to graphics researchers today and shows 
that the condition for preventing aliasing was known, as a rule of thumb, long before Shannon's proof 
of the sampling theorem: The interference usually manifests itself in the form of serra- tions on diagonal 
lines and occasional moir6 effects in the received picture. Confusion in the signal may be practically 
eliminated by using an aperture of such a nature that it cuts off all [Fourier] components with n numbers 
greater than N/2 [half the scanning rate] .... By comparison, the problems introduced by reconstruction 
have been somewhat neglected in the graphics literature. Reconstruction can be responsible for aliasing 
and other types of distortion that mar the subjec- tive quality of an image. This paper will focus on 
the effects of recon- struction and how to design filters for graphics applications. 2. Aliasing Caused 
by Reconstruction Aliasing in synthetic images is a serious problem and still not completely solved. 
In other digital-signal-processing applications, aliasing is elim- inated by prefiltering signals before 
sampling, as illustrated in Figure l. Note that it is the prefiltered signal that is reconstructed in 
this ease. Permission to copy without fee all or part of this material is granted provided that the 
copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the 
title of the publication and its date appear, and notice is given that copying is by permission of the 
Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. &#38;#169;1988 ACM-O-89791-275-6/88/O08/0221 $00.75  ,screte reconstructed sig° s,gnal- 
I filter I signal sampling pulses Figure I. Sampling and Reconstruction While prefi/lering is the classic 
solution to a/iasing problems, there is a special problem encountered in computer graphics. Many synthetic 
images originate from what we will call procedural signals, in which the ¢SIGGRAPH '88, Atlanta, August 
1-5, 1988 signal is only implicitly defined by an algorithm for computing point samples. Operations that 
require an explicit representation of the signal cannot be performed, and in particular, prefiltering 
is impractical. This difficulty is unique to computer graphics, and ray tracing is the clearest example 
of it [wHIgo}. To explain the role that reconstruction plays in aliasing, it will be helpful to review 
briefly the theory of sampling and define the operations of sampling and reconstruction more precisely, 
tn one dimension, a signal can be represented by a continuous function f(x). Producing a discrete signal 
by sampling is equivalent to multiplying by an infinite train of impulses known as a comb function: £(x) 
= f (x)" comb(x) (1) where comb(x) = ~ ~(x-n) (lb) Unit spacing between samples is assumed in equation 
(lb), and ~x) is the Dirac delta function. In this case, the sampling theorem states that f(x) can be 
reconstructed exacdy from its samples if it contains no fre- quencies greater than 0.5 cycles per sample. 
This critical frequency is called the Nyquist frequency. Reconstruction is accomplished by convolving 
(indicated by *) the discrete signal with a reconstruction filter kernel, k(x): f,(x) = ./~(x)* k(x) 
(2) = ~f,(u )" k (x - u)du (2b) = ~ f(n)'k(x-n) (2c) Except in the mathematically ideal case, some error 
is introduced in the process of sampling and reconstruction, and f(x) will be somewhat dif- ferent from 
fr(X). To analyze this error, it is useful to view the problem in the frequency domain. The Fourier transform 
of the signal is its spec- trum F(v), and the Fourier transform of the filter is its frequency response 
K(v). Since multiplication in the spatial domain is equivalent to convolution in the ffrequency domain 
(and vice versa), sampling can be described by: F~(v) = F(v)* Comb(v) (3) and reconstruction by: F,(v) 
= F,(V) .K(v) (4) The Fourier transform of a comb function is also a comb function (with reciprocal 
spacing between impulses). K(v) Figure 2. Sampling and Reconstruction in Frequency Domain Figure 2 illustrates 
the consequences of the convolution in equation (3). The spectrum of a sampled signal F,(V) is the sum 
of an infinite sequence of shifted replicas of the original signal's spectrum, each centered at the location 
of an impulse in the comb. Equation (,4) states that, in the frequency domain, reconstruction can be 
interpreted as the multiplication by K (v) which is intended to eliminate all the extraneous replicas 
of the signal's spectrum and keep the original base-band cen-tered at the origin. K(v) is indicated by 
the dashed curve in Figure 2. However, Figure 2 also demonstrates a problem. The replicas of the sig- 
nal spectrum overlap, aad the reconstruction filter can not isolate a pure version of the base-band signal. 
When part of the energy in a replica of the spectrum leaks into the reconstructed signal, aliasing results. 
If the bandwidth of the signal were narrower or the sampling rate higher, the copies would not overlap, 
and exact reconstruction would be possible. Even if the replicated spectra do not overlap, alining can 
result from poor reconstruction, as illustrated in Figure 3. When aliasing is a conse- quence of undersampling 
(or lack of prefiltering), it is referred to as prealiasing, and when it results from poor reconstruction, 
it is called postaliasing. K(v) r--........... -~ F~(V) V VN Figure 3. Postaliasing Resulting from Poor 
Reconstruction Filter Figure 4 shows an extreme example of aliasing in an image. In this fig- ure, the 
two-dimensional signal, f(x,y) = sin(x 2 +y2), was sampled on a 128 x 128 pixel grid. Then, these samples 
were reconstructed with a cubic filter (to be described later in the paper) and resampled to 512 x 512 
pixels. The rings on the left side of the image are part of the actual signal, but the rings on the right 
side are Moit~ patterns due to prealiasing. In the center of the image is a fainter set of concentric 
rings resulting from pos- taliasing. Postaliasing occurred when the discrete image of 128 x 128 pixels 
was enlarged to 512 x 5t2 pixels by resampling. Note that this conspicuous postaliasing pattern results 
from "treating" between the sig- nal and its alias. This can also be understood from Figure 3, where 
it can be seen that at the Nyquist frequency (indicated by VN) the signal's spectrum and its nearest 
replica come close together. Power in the spec- trum very near the Nyquist frequency is thus the cause 
of the most diffi- cdt type of aliasing to remove from an image. This problem has been noted by other 
graphics researchers [COO87] and by Mertz et al. [MER34]. Using the same set of samples as in Figure 
4, a much better reconstruc- tion filter can be applied (a 30-unit-wide windowed sine filter). Figure 
5 demonstrates a dramatic reduction of the postaliasing pattern, but the prealiasing is unaffected. The 
spectrum of this reconstruction filter is very close to the ideal step shape shown in Figures 2 and 3. 
3. Other Image Defects Caused by Reconstruction Notice in Figure 2, that a reconstruction filter K(v) 
has two tasks. First it must remove the extraneous replicas of the signal spectrum (to prevent aliasing). 
Second, it should pass the original signal base band, but the signal can be distorted if this is not 
done perfectly. This second type of reconstruction error will be referred to as base-band attenuation. 
From the previous section, one might assume that the literature of signal processing provides a complete 
solution to the reconstruction problem in graphics; however, there is a serious difficulty with the ideal 
sine filter that is not obvious from studying its frequency response. Figure 6 shows a simple figure 
reconstructed with the same filter used in Figure 5. The rippling pattern radiating from the edges is 
called ringing. Ring-ing is strongly suggested by the form of the impulse response of the sinc  @ * 
Computer Graphics, Volume 22, Number 4, August 1988 fiher, as shown in Figure 7: 1 - 0.5- 0- I I I -5 
0 5 Figure 7. [mpulse Response of Ideal Sinc Filter Classical digital filter design places a heavy emphasis 
on the frequency response of a filter. That works well in the audio domain, but when con- sidering the 
appearance of images, it is important to also pay attention to the shape of the impulse response. The 
response of human viewers to various spatial effects of filters is not yet a well-understoed science 
and is largely subjective in nature. Filters that have some aliasing problems or certain types of base-band 
attenua- tion may turn out to give visually-pleasing results. Schreiber and Troxel have discussed the 
spatial effects of reconstruction filters [SCH85], and they mention some of the important defects that 
can occur when judging the quality of an image subjectively: sample-frequency ripple, anisotro- pic effects, 
ringing, blurring, and aliasing. Each of these effects will be considered in detail in the following 
section. Unfortunately, it is often necessary to trade off one type of distortion for another, and the 
design of a single filter perfect for all applications is almost certainly impossible. As Figure 6 illustrated, 
perfect antialiasing resulted in the serious defect of ringing. However, Brown realized that a moderate 
amount of ringing can improve the subjective quality of an image by enhancing the appearance of shaqmess 
[BRO69]. He found that a single transient lobe of ringing was effective at sharpening, but multiple transients 
(as in Figure 6) always degrade image quality. Many of the concepts presented so far have been illustrated 
in one dimension for simplicity. However, image reconstruction takes place in two dimensions and involves 
the convolution of a 2D lattice of samples with a filter k(x,y). In this paper, we will consider only 
separable filters, where the samples are convolved with the product k(x)kty). Separable filters are compurationally 
more efficient than nonseparable because the filtering operation can be performed in separate passes 
verti- cally and horizontally. If the filter kernel is N samples wide, the recon- struction can be performed 
with O(N 2) multiplications for the general filter k(x,y) but with O(N) if the filter is separable. 4. 
Piecewise Cubic Reconstruction Filters Rather than discuss the issues of filter design abstractly, this 
paper will apply them to the study of a family of filters defined by piecewise cubic polynomials. Cubic 
filters ate sufficiently complex to have a broad range of behaviors, but they are simple enough to be 
compntationally attractive. Hou and Andrews have studied the fikering properties of the cubic B-spline 
[HOU78], and two studies have been made of the one-parameter family of cardinal cubic splines [KEYSI,PAR83]. 
The general form for a symmetric cubic filter is: [Plxl3+Qlxl2+RIxI+S if Ixl<l k(x)= ~Tlxl3+UIxIZ+VIxI+W 
ifl_<lxl<2 (6) otherwise to Several obvious constraints can be placed on this function to reduce the 
number of free parameters. First, the filter should be smooth in the sense that its value and first derivative 
are continuous everywhere. Discontinuities in k(x) will lead to high-frequency leakage in the fre- quency 
response of the filter which can allow aliasing. In addition, the problem of sample-frequency ripple 
can be designed out of the filter by requiring (for all x): k(x-n) = 1 (7) This means that if all the 
samples are a constant value, the reconstruction will be a fiat constant signal. Figure 8 demonstrates 
this defect by using an unnormalized Gaussian filter to reconstruct a 512 x 512 image from 64 x 64 samples. 
In the frequency domain, sample ripple can be viewed as an alias of the image's DC component. It can 
be shown that the con- dition given by equation (7) means that the frequency response of these cubic 
filters will be zero at all integer multiples of the sampling fre- quency except zero, eliminating all 
extraneous replicas of the DC com-ponent. With these constraints, the number of free parameters are reduced 
from eight to two, resulting in the following family of cubic filters; (12-9B -6C) Ixl 3 + if Ixl<l I 
(_18+i2B+6C)Ix12+(6_2B) 1 J(-B-6C)Ixl 3 +(6B +30C)IxI 2 + if 1<_ Ixl <2 (8) k(x) = 6 [/0(-12B-48C)1xl 
+(8B+24C) otherwise Some values of (B, C) correspond to well-known cubic splines. (1,0) is the cubic 
B-spliue, (0, C) is the one-parameter family of cardinal cubits with (0, 0.5) being the Catmull-Rom spline, 
and (B, 0) are Duff's ten- sinned B-splines [DLrF86]. In two or more dimensions, visible artifacts can 
be caused by angle- dependent behavior or anisotropic effects. Figure 9 illustrates this prob- lem by 
reconstructing with the separable filter k(x)k(y) using parameter values of (0,0). Even though sample-frequency 
ripple has been designed out of k(x), in two dimensions the pixel structure is highly conspicuous because 
the impulse response and the sampling lattice are not radially symmetric, The phenomenon of ringing has 
already been seen in Figure 6. Filters in the cubic filter family can also exhibit this problem as seen 
in Figure 10, where parameter values of (0,1) were used. Ringing results when k(x) has negative side 
lobes, and although some ringing can enhance shaqaness, a filter that becomes negative is problematic. 
In Figure 10, a typical problem is seen where portions of the image near an edge have become negative 
and have been damped to zero. This results in pro- nounced black spots (e.g., at the top of the statue's 
head). Similar clamping occurs to white, but is less noticeable because of the eye's non- linear response 
to contrast. Schreiber and Troxel have suggested that subjectively even sharpening can only be produced 
by introducing ting- ing transients in a suitably nonlinear fashion [SCH85]. These conspicu- ous clamping 
effects could also be eliminated by reducing the dynamic range of the image or raising the DC level of 
the image. Parameter values of (3/2, -1/4) result in an image that is unnecessarily blurry, as seen in 
Figure 11. The cubic B-spline also suffers from this problem. In viewing many reconstructions with filters 
in this family, ringing, anisotropy, and blurring are the dominant behaviors, and in a small region of 
the parameter space, a satisfactory compromise seems to exist which is seen in Figure 12, using parameter 
values of (1/3, 1/3). This is quite good, considering that the image is being magnified from x 64 pixels. 
There is some degree 0f sharpening, and almost no visi- ble evidence of the sampling lattice. To get 
a better idea of which regions of the parameter space yield which type of behavior, a simple subjective 
test was designed. On a neutral background, four images were displayed typifying the effects of ringing, 
  SIGGRAPH '88, Atlanta, August 1-5, 1988 blurring,anisotropy, and an example of die most satisfactory 
behavior. In the center of the display, images reconsuucted fxom filters with ran- dom values of (B, 
C) were displayed, and the test subject was asked to choose which of the four behaviors it exemplified. 
Nine expert observers (researchers working in graphics or image processing) took part and over 500 samples 
were taken. It would not be credible to sug- gest that a single ideal parameter pair can be deduced from 
subjective testing. The motivation for this experiment was simply to draw approxi- mate boundaries between 
regions of differing behavior as shown in Fig- ure 13. The test subjects were quite consistent with one 
another in their judgements. '""'........ 0.8- 0.6- B parameter 0.4- 0.2-  0 x \ \ I I I 0 0.2 0.4 
0.6 0.8 C parameter Figure 13. Regions of Dominant Subjective Behavior To help choose a good filter [rom 
the two-parameter space, some quanti- tative analysis can be done to remove one more degree of freedom. 
Keys and Park et al. studied the cardinal cubic splines because these cubics exactly interpolate at the 
sample positions [KEYSI,PAR83]. Using standard numerical analysis, Keys concluded that the Catmull-Rom 
spline was best. Park et al. reached the same conclusion using an equivalent analysis in the frequency 
domain. Figure 14 illustrates this technique; f (x) 2J" X ~---h --.-~. Figure 14. f(x) andf~(x) As the 
sample spacing h diminishes, the function and its reconstruction become closer. The difference f (x) 
-f,(x) can be expanded into a power series in h to study how parameters affect various orders of behavior. 
Details of this type of analysis can be found in Keys' paper, and when applied to the two-parameter family, 
the following is obtained: f (x)-f,(x) = (2C+B-1)hfr(x) + O(h 2) (9) r(x) is a polynomial factor. When 
2C +B = I (indicated by dotted line in Figure 13), quadratic convergence of fit is achieved. This line 
con-tains the cubic B-spline and the Catmull-Rom spline (which actually has cubic convergence). Within 
the interval of B = 5,33 to B = 0, good sub- jective behavior is found with a simple trade-off between 
blurring and tinging. Outside this interval, k(x) becomes bimodal or exhibits extreme ringing. The filter 
(1/3, 1/3) used to generate Figure 12 is recommended by the authors, but other observers may prefer more 
or less ringing. 5. Postaliasing Revisited A systematic consideration of subjective appearance along 
with quantita- tive analysis has yielded an excellent piecewise cubic filter. However, the issue of postaliasing, 
defined in section 2, has been ignored. In fact the (1/3, 1/3) filter has only fair antialiasing properties 
and was used to generate Figure 4. Postaliasing is usually not strong enough to cause visible "jaggies" 
on edges unless a very poor filter is used (e.g., a box filter); however, an image with periodic patterns 
can have conspicuous postalias Moire effects unless careful precautions are taken. Synthetic images that 
contain brick walls, ocean waves, or the ubiquitous checker- board pattern are examples of images that 
might have this difficulty. There are several approaches to fixing this problem. If the signal is bandlimited 
and samples carry information about the derivative as well as about signal amplitude, a better job of 
reconstruc- tion can be done [PET64]. Given samples (at unit spacing) of a signal and of its derivative, 
a reconstruction can be done in the following form: f(x)= ~ If~g(x-n)+f,h(x-n)] (1o)  n =~ In an extension 
of the sampling theorem, if the signal contains no energy above the sampling frequency (twice the allowed 
bandwidth of sampling without derivatives), then it can be perfectly reconstructed by the filter kernels: 
sinZ~ g(x)= n2x2 (ll) h(x) = sin 2 ~x (llb) This is analogous to the ideal sine reconstruction formula 
in the standard case where no derivative information is present. A common approxima- tion to these ideal 
reconstruction formulae is Hermite cubic interpolation: / lxl3-31xl2+l if Ixl_<l g (x) = otherwise (12) 
{ 3-2x Ixl +x if Ixl~l h (x) = otherwise (12b) Figure 15 shows the aliasing test pattern (stir starting 
with 128 x 128 samples) reconstructed with the Hermite cubic postfilter. The effect is dramatic when 
compared to Figure 4, The postaliasing artifact in the middle of the image is nearly gone, and the prealiasing 
paltern on the right is less intense. The theory of derivative reconstruction may have some practical 
value in computer graphics. For example, it may be possible to extend Whitted's ray-tracing shading model 
[WHI80] to generate derivatives with respect to the screen coordinates. This is not an easy problem, 
but we have demonstrated the feasibility of this extension by deriving the formulae for Lambert and Phong 
shading on quadric surfaces. It is possible that the density of rays used to reconstruct an image could 
be reduced in this manner by gathering more useful information from each visible surface calculation. 
A second approach to improving postaliasing properties is suggested by the success of stochastic sampling 
on the prealiasing problem '~' [COO86,DIPg5,MIT87]. However, preliminary experiments conducted by the 
authors with stochastic-phase reconstructfon have yielded very poor results. The amount of noise needed 
to obscure postaliasing seri- ously degraded image q?ality. Finally, it was observed in section 2 that 
signal energy very near the Nyquist frequency is most responsible for conspicuous Moire patterns. It 
is possible to cut out this component by notch-filter reconstruction. The frequency response of the two-parameter 
cubic filter in equation (8) is: x(v) = -~-3-3B Isinc2(v)_sinc(2v) ] (13) 2C [_3sinc2(2v)+ 2sinc(2v)+sinc(4v)] 
+ B sinca(v) This function goes to zero at v = 1/22 when B = 3/2. In fact, the fre- quency response 
is zero at all integer and half-integer multiples of the sampling rate except zero. The filter (3/2, 
-1/4) is quadratically conver- gent, and the result of reconstruction with it can be seen in Figure 16, 
in which the postaliasing artifact is almost completely eliminated. Unfor-tunately, this filter is quite 
blurry as was seen in Figure 11. The behavior of this notch filter can be seen in its frequency response 
in Fig- ure 17 compared with the cubic B-spline filter (1, 0) in Figure 18. The log magnitudes of the 
frequency responses are plotted below: 0.1 0.01 0.001 0,0001 [I i 0 1 2 Figure 17. Frequency Response 
of Cubic Notch Filter OH m 0.01 - 0.~1 - 0.0~1 I I 1 2 Figure 18. Frequency Response of Cubic B-Spline 
Filter 6. Conclusions Designing reconstruction filters for computer graphics applications requires a 
balanced analysis of formal quantitative properties and subjec- tive image quality. There are many trade-offs, 
arid it may be impossible to find a filter that yields good image quality and has good antialiasing properties. 
  Computer Graphics, Volume 22, Number 4, August 1988 A new family of cubic filters has been analyzed, 
and two interesting filters have been found. The (113, 1/3) filter yields excellent image qual- ity, 
and the notch filter (3/2, -1/4) strongly suppresses postaliasing pat- terns. If derivative values can 
be generated by a procedural signal, an image with less aliasing is possible by reconstruction with Hermite 
intelpolation or some other suitable filter. More work remains to be done. While the authors do not believe 
simple filters will be found that improve much on the cubic filters derived here, there aae other avenues 
for progress. Adaptive filters might allow good image quality with strong antialiasing only where it 
is needed in problem areas. The effects of the reconstruction in the display and eye might be allowed 
for given models of the visual system [NET88]. Finally, the problem of reconstruction from nonuniform 
sampling is not entirely solved. Reasonable filters have been proposed [MIT87], but more analysis could 
be done: "Ideal" nonuniform reconstruction filters am known which are analogous to the sinc filter used 
witli uniform sam- pies. A greater challenge will be to understand the subjective issues involved in 
designing filters that are well suited to computer graphics. 7. Acknowledgements We would like to thank 
our colleagues who volunteered to help with subjective testing. We would also like to thank Jim Bergen 
from the David Sarnoff Laboratory, Jim Johnston from Bell Labs Signal Process- ing Research Department., 
and William Schreiber from MIT's Advanced Television Research Program for their views on filter design. 
We would also like to thank Larry O'Gorman, Brace Naylor, Rob Pike, David Tho- mas and Pamela Zave and 
the SIGGRAPH reviewers for their helpful comments. 8. References [BRO69] Brown, Earl F., "Television: 
The Subjective Effects of Filter Ringing Transients", Journal of the SMPTE, Vol. 78, No. 4, April 1969, 
pp. 249-255. [CAT80] Catmnll, Edwin, Alvy Ray Smith, "3-D Transformations of Images in Scardine Order", 
Computer Graphics, Vol. 14, No. 3, pp. 279-285. [COO86] Cook, Robert L., "Stochastic Sampling in Computer 
Graphics", ACM Trans. Graphics, VoL 5, No. t, January 1986. [COO87] Cook, Robert L., personal communication, 
August, 1987. [CRO77] Crow, Franklin C., "The Aliasing Problem in Computer- Generated Shaded Images", 
Comm. ACM, Vol. 20, No. 1 l, November 1977, pp. 799-805. [DIP85] Dippe, Mark A. Z. and Erling Henry Wold, 
"Antialiasing Through Stochastic Sampling", Computer Graphics, Vol. 19, No. 3, July 1985, pp. 69-78. 
[DIJF861 Duff, Tom, "Splines in Animation and Modeling", State of the Art in Image Synthesis, SIGGRAPH 
g6 Course Notes. [HOU78] Hou, Hsieh S., HaJ'ry C. Andrews, "Cubic Splines for Image Interpolation and 
Digital Filtering", IEEE Trans. Acoustics, Speech, and Signal Processing, Vol. ASSP-26, No. 6, December 
1978, pp. 508-517. [KEY81] Keys, Robert, G, "Cubic Convolution Interpolation for Digital Image Processing", 
1EEE Trans. Acoustics, Speech, and Signal Processing, Vol. ASSP-29, No. 6, December 1981, pp. 1153-1160. 
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378515</article_id>
		<sort_key>229</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Constant-time filtering with space-variant kernels]]></title>
		<page_from>229</page_from>
		<page_to>238</page_to>
		<doi_number>10.1145/54852.378515</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378515</url>
		<abstract>
			<par><![CDATA[Filtering is an essential but costly step in many computer graphics applications, most notably in texture mapping. Several techniques have been previously developed which allow prefiltering of a texture (or in general an image) in time that is independent of the number of texture elements under the filter kernel. These are limited, however, to space-invariant kernels whose shape in texture space is the same independently of their positions, and usually are also limited to a small range of filters.We present here a technique that permits constant-time filtering for space-variant kernels. The essential step is to approximate a filter surface in texture space by a sum of suitably-chosen basis functions. The convolution of a filter with a texture is replaced by the weighted sum of the convolution of the basis functions with the texture, which can be precomputed. To achieve constant time, convolutions with the basis functions are computed and stored in a pyramidal fashion, and the right level of the pyramid is selected so that only a constant number of points on the filter kernel need be evaluated.The technique allows the use of arbitrary filters, and as such is useful to explore interesting mappings and special filtering techniques. We give examples of applications to perspective and conformal mappings, and to the use of filters such as gaussians and sinc functions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Filtering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.3</cat_node>
				<descriptor>Smoothing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP42051322</person_id>
				<author_profile_id><![CDATA[81100345881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alain]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fournier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Sandford Fleming Building, University of Toronto, Toronto, Ontario, M5S 1A4]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136075</person_id>
				<author_profile_id><![CDATA[81100188679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eugene]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fiume]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Sandford Fleming Building, University of Toronto, Toronto, Ontario, M5S 1A4]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F.C. Crow, "Summed-Area Tables for Texture Mapping," Computer Graphics, vol, 18(3), pp. 207-212, July 1984.]]></ref_text>
				<ref_id>Crow81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Flume, A. Foumier, and V. Canale, "Conformal Texture Mapping," Proceedings of Eurographics '87, pp. 53-64, August 1987. Elsevier Science Publishers (North Holland) (August 24-28, 1987, Amsterdam, The Netherlands).]]></ref_text>
				<ref_id>FiFC87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6023</ref_obj_id>
				<ref_obj_pid>6020</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N. Greene and P. S. Heckbert, "Creating Raster Omnimax Images from Multiple Perspective Views Using the Elliptical Weighted Average Filter," IEEE Computer Graphics and Applications, vol. 6, no. 6, pp. 21-27, June 1986.]]></ref_text>
				<ref_id>GrHe86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13023</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Greene, "Environment Mapping and Other Applications of World Projections," IEEE Computer Graphics and Applications, vol. 6(11), pp. 21-29, November 1986.]]></ref_text>
				<ref_id>Gree86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15921</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P.S. Heckbert, "Filtering By Repeated Integration," Computer Graphics, vol. 20(4), pp. 315-321, August 1986.]]></ref_text>
				<ref_id>Heck86a</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P.S. Heckbert, "Survey of Texture Mapping," IEEE Computer Graphics and Applications, vol. 6(11), pp. 56-67, November 1986.]]></ref_text>
				<ref_id>Heck86b</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806784</ref_obj_id>
				<ref_obj_pid>800224</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Kajiya and M. Ullner, "Filtering High Quality Text for Display on Raster Scan Devices," Computer Graphics, vol. 15, no. 3, pp. 7-15, 1981. (ACM SIG- GRAPH'81 Conference Proceedings, July 1981, Dallas, Texas)]]></ref_text>
				<ref_id>KaUl81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>28000</ref_obj_id>
				<ref_obj_pid>27993</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Kishimoto, K. Onaga, and E. Nakamae, "Theoretical Assessments of Mean Square Errors of Antialiasing Filters," Computer Vision, Graphics and Image Processing, vol. 37, pp. 428-437, 1987.]]></ref_text>
				<ref_id>KiON87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37430</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Naiman and A. Fournier, "Rectangular Convolution for Fast Filtering of Characters," Computer Graphics, vol. 21, no. 4, pp. 233-242, 1987. (ACM SIG- GRAPH'87 Conference Proceedings, July 27-31, 1987, Anaheim, California).]]></ref_text>
				<ref_id>NaFo87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>108781</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W.K. Pratt, Digital linage Processing, Wiley- Interscience, 1978.]]></ref_text>
				<ref_id>Prat78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[L. Williams, "Pyramidal Parametrics," Computer Graphics, vol. 17(3), pp. 1-11, July 1983.]]></ref_text>
				<ref_id>Will83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807383</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[W. Dungan, A. Stenger, and G. Sutty, "Texture Tiles Consideration for Raster Graphics," Computer Graphics, vol. 12, no. 3, pp. 130-134, 1978. (ACM SIG- GRAPH'78 Conference Proceedings, July 1978, Atlanta, Georgia)]]></ref_text>
				<ref_id>DuSS78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Catmull and R. Rom, "A Class of Local Interpolating Splines," in Computer-Aided Geometric Design, ed. R. F. Riesenfeld, pp. 317-326, Academic Press, 1974.]]></ref_text>
				<ref_id>CaRo74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578095</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Rosenfeld and A. C. Kak, Digital Picture Processing, Academic Press, 1976.]]></ref_text>
				<ref_id>RoKa76</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~' Computer Graphics, Volume 22, Number 4, August 1988 Constant-Time Filtering with Space-Variant Kernels 
Alain Fournier Eugene Fiume Department of Computer Science Sandford Fleming Building University of Toronto 
Toronto, Ontario M5S IA4 BITNET: { elf I alain }@dgp.utoronto CSNET]UUCP: { elf I alain }@dgp.toronto.edu 
 Abstract Filtering is an essential but costly step in many computer graphics applications, most notably 
in texture mapping. Several techniques have been previously developed which allow prefiltering of a texture 
(or in general an image) in time that is independent of the number of texture elements under the filter 
kernel. These are limited, however, to space-invariant kernels whose shape in texture space is the same 
independently of their positions, and usually are also limited to a small range of filters. We present 
here a technique that permits constant-time filter- ing for space-variant kernels. The essential step 
is to approximate a filter surface in texture space by a sum of suitably-chosen basis functions. The 
convolution of a filter with a texture is replaced by the weighted sum of the convo- lution of the basis 
functions with the texture, which can be precomputed. To achieve constant time, convolutions with the 
basis functions are computed and stored in a pyramidal fashion, and the right level of the pyramid is 
selected so that only a constant number of points on the filter kernel need be evaluated. The technique 
allows the use of arbitrary filters, and as such is useful to explore interesting mappings and special 
filtering techniques. We give examples of applications to perspective and conformal mappings, and to 
the use of filters such as gaussians and sine functions. CR Categories: 1.3.3 [Computer Graphics]: Picture/Image 
Generation --display algorithms; 1.3.5 [Computer Graph- ics]: Computational Geometry and Object Modeling 
--Sur-face representation; 1.4.3 [Image Processing]: Enhancement --filtering, smoothing. 1. Introduction 
In many applications of computer graphics such as raster image transformations, environment mapping and 
texture mapping,filtering is a basic operation. To use consistent and Permission to copy without fee 
all or part of this material is granted provided that the copies are not made or distributed for direct 
commercial advantage, the ACM copyright notice and the title of the publication and its date appear, 
and notice is given that copying is by permission of the Association for Computing Machinery. To copy 
otherwise, or to republish, requires a fee and/or specific permission. &#38;#169; 1988 ACM-O-89791-275-6188/O08/0229 
$00.75 familiar terminology (see glossary at end of paper), we will call the image on which the filtering 
is applied the texture and the coordinates for the texture space (u,v). The central operation of filtering 
is to compute for a filter function F(u,v), a texture T(u,v), and a position in texture space (uc, v,,), 
the convolution s,. =[.~ r(.,v) F(.,-.,~,,-v)du d~,. (1) Usually an entire array of such sample values 
is needed, and the positions of these values are determined from a mapping from another space. Again 
by convention we will call that space the screen and denote screen coordinates by (x,y). The kernel of 
the filter is the domain of F centered at a par- ticular sample pair (u,.,Vc). The texture to screen 
mapping is x(u,v) = (x,y), and the inverse mapping (if defined) is ~-1 (x,y) = (u,v). By the same token, 
the filter kernel in texture space is nor- mally obtained by mapping a given kernel from screen space: 
F(u,v) = F(~-l(x,y)). The main concerns in applications are the quality and pro- perties of the filters 
used, the accuracy of the computation of the convolution, and the efficiency of the computation. The 
latter is especially important, since convolution can be a costly proposition, in the simple case of 
a discrete texture, and a kernel with a finite width of support (that is non-zero only over a finite 
area), the cost is proportional to the number of texels (texture elements) under the kernel. Since that 
can be most or all of the texture if the kernel is large with respect to the texture, the cost per sample 
can be very high. A further distinction is important. In applications where the mappings are affine, 
° each filter is a translation of the same function. In this case more efficient methods are applicable, 
and we will survey some in the next section. The kernel of the filter is then said to be space-invariant. 
The majority of applications, however, involve non-affine mappings, which cause a filter kernel to vary 
from sample point to sample In an affine mapping parallelism is preserved, but not neces- sarily distances 
and angles. Perspective projection is not affine. point. Such kernels are thus space-variant, and dealing 
with them is more difficult, but unfortunately unavoidable. 2. Previous Techniques A series of papers 
by Greene and Heckbert [GrHe86], Greene [Gree86], and Heckbert [Heck86a, Heck86b] have surveyed the recent 
results, especially as they relate to tex- ture mapping, and the reader is referred to them. Table 1 
is directly derived from a table in [Heck86b]. The additional references are to [DuSS78, Crow81, Wi1183]. 
Method Filter Shape Time Storage Reference Direct Convolulion Any Any # of texels I Any Point Sampling 
Delta Point 1 1 Any Point sampled Pyramid Box Square I 4]3 Dungan MIP map Box Square 8 4/3 Williams EWA 
on Pyramid Any Ellipse # of lexel~ 4/3 Greene Summed Area Table Box Rectangte 4 or 16 2 to 4 Crow Repeated 
Integration Spline Rectangle "Order-" "Order Heckbert EWA stands for Elliptical Weighted Average, and 
was developed for space-variant filtering for Omnimax images. There are variations on these basic techniques. 
MIP maps have been modified to allow for rectangular areas. In the other direction, Naiman and Fournier 
[NaFo87] used a summed-area filter in the special case where the picture is decomposed into single-valued 
rectangles. There is no need to reproduce here the excellent discussions found in Greene and Heckbert 
about the pluses and minuses of these various methods. An important fact is that the tech- niques achieving 
constant time are severely limited in the type of filters they can use (with the exception of repeated 
integration) or in the shape of the area considered. The most flexible methods in this respect (direct 
convolution and EWA on a pyramid) can take an arbitrarily large amount of time for kernels that are large 
in texture space. Our original motivation was to find a suitable filtering tech- nique when using conformal 
texture mapping [FiFC87]. In this type of mapping the kernel in texture space is space- variant, and 
can often be severely distorted. Figure 1 shows how circles of equal size in screen space map to texture 
space under a conformal mapping which maps a square to a non-convex pentagon. .....'..~:" \, / "-~Z_./ 
Figure l. Distortion of kernels under conformal mapping The number of texels under the kernel can also 
vary greatly. This is especially true in animation. Moreover, in animation the same texture can be used 
in hundreds of frames. Even a small gain in cost per frame can therefore more than offset even a large 
precomputing cost. It is clear from the preceding table that a technique which could accommodate any 
type and shape of filter but whose cost would be largely independent of the number of texels under the 
filter would be useful. 3. The Technique 3.1. Filter Surface Approximation If we look at F(uc-U, Vc-v) 
as a surface in texture space, it can be approximated piece-wise in the traditional manner by the union 
of patches, each being a weighted sum of the cartesian product of M basis functions over some knots: 
M M F(ttc-u'vc-I') = U ~, ]~ Bi(u ) Bi(v) bij. (2) all patches i=O j=0 Patches are normally selected 
from an array, and will be indexed by (k,1). The parameters u and v for patch (k,l) vary from uk to uk+t 
and v / to vt+ I. In general the values of the parameters at knot k will be k, and the basis functions 
will be translates of each other so that in effect u and v range from 0 to 1. The b o are coefficients 
determined from the values of F(uc-u,v,.-v) at the knots. The convolution over the patches can then be 
approximated by ll~+l UI+I m m  s. : Z S ~ T(.,v) Z Z 8i(.)sj(v)biiaudv. all patches tt =u~ v = D i=0 
j--O Since the bij are independent of u and v over a patch, and since summation distributes over integration 
for well-behaved T(u,v) and B i and Bj, M M lt~+l Vl+l Sa : X X ~, bij I ~ T(u,v) Bi(u ) Bj(v)dudv. all 
patches i=0 j--O tt=lt~ v=t" t The M 2 double integrals of the form t¢~+ I I'1+ I Cij = ~ I T(u'v)Bi(u)Bj 
(v)dudv (3) l¢ : I¢ L I" = I' I can therefore be precomputed and stored for a given texture. For each 
position of the filter, the filter surface is approxi- mated by a collection of patches for which the 
b 0 are deter- mined, then multiplied by the stored C U and summed to give the approximation Sa to the 
convolution So: M M S,. = S, = E E Z bij Cq. (4) all patches i=O j=O For each patch contributing to 
the piece-wise approximation to the filter surface in texture space, the cost of computation and storage 
is therefore a function of the number of basis functions (the order of the polynomials in the case of 
poly- nomial basis functions) and the number of primaries used for the image values. 3.2. NIL Maps To 
keep the total cost for each application of the filter independent of the number of texels under the 
filter, we have to make sure that the number of patches used is independent of the number of texels. 
The number of patches needed is a function of how well the filter surface is approximated by the  4~ 
Computer Graphics, Volume 22, Number 4, August 1988 basis functions, and of how much approximation error 
we are willing to tolerate. Once this is established, however, to effectively guarantee this number of 
patches we must have an approximately-equal number of knots under the filter width of response. This 
suggests immediately a pyramidal approach, in which we build up precomputed Cij for increas- ingly closer 
knots, until we reach the spacing of the texels if we have a discrete texture, or some other practical 
limit for an analytic texture. The hierarchical construction thus obtained closely resembles MIP maps 
described in [Wi1183] and we call them NIL maps, where NIL stands for nodus in largo, which can be loosely 
translated as "knot large". When using the pyramid, the goal is then to select the level (or levels) 
of the pyramid which will give the fewest knots, and therefore patches under the filter, while guaranteeing 
a good approximation of the filter surface for the purpose of convolution. 3.3. Computing the Answer 
Once the Cij have been computed and stored for each level (i.e. knot spacing) of the NIL maps, the result 
of the convo- lution for a given filter position is computed according to the following steps: map the 
filter position from screen to texture space  find the level in the NIL maps so that the number of patches 
used is sufficient for a good approximation of the surface while making sure that the number of patches 
is bounded by a small constant. Note that the level does not have to be the same for all patches.  for 
each patch selected to contribute, compute the relevant bTj from the filter values at the knots, and 
compute the S a according to Eq. 4 summing all the contributions to obtain the final result.  3.4. Cost 
in Time and Space The storage cost can be determined as follows. At the highest level (where there are 
as many patches as there are texels), the number of Cij is M 2 times the number of texels. The precision 
needed is dependent of the type of basis func- tions used, but most reasonable choices are functions 
whose values do not go far beyond [0,1], and therefore each Cij will have values of the order of the 
texel values. Thus the same precision is required to store the C d as to store the texel values. To avoid 
too large an error accumulated in round-offs when adding M 2 terms, it is prudent to add log2(MZp) bits 
per value for storage. The number of levels needed is p+l, if the size of the original texture is S = 
2P×2 p. Each level requires one-fourth of the size of the preceding one, and therefore the total storage 
needed is 0 M2×S×i_Z 7 = O M2×S× The cost per patch after pre-processing is easily obtained. It is proportional 
to the number of bij coefficients to be evaluated, and to the number of Cij to be retrieved. In both 
cases this number is M 2 if M is the number of basis func- tions used. For polynomial bases, M is the 
order of approxi- mation. The theoretical goal of constant-time space-variant filtering is reached if 
the number of patches used is effectively bounded by a number independent of the number of texels under 
the filter. A variety of algorithms can guarantee this, and we will describe in the next section a rather 
simple one. The additional cost of the search through the NIL maps can only be determined for a specific 
algorithm, but will be most likely directly related to the number of levels in the pyramid. 4. Modalities 
4.1. Choosing the Basis Functions and the Order The main criterion governing the choice of the basis 
func- tions is how well and how easily the filter surface is approxi- mated. The ways to determine the 
quality of approximation, however, are not the usual criteria of smoothness, visual fidelity or ease 
of control. If we view the filter as a recon- struction waveform, the approximated surface should be 
such that the various characteristics of the filter, both good and bad (amplitude of side lobe, stopband 
attenuation, reso- lution and interpolation errors), should be respected as much as possible. Most of 
these characteristics are computed in the frequency domain, and some include the power spectrum of the 
signal to which the filter is applied, which is not known in general. It is more useful and convenient 
to use a metric in the spatial domain for the approximation error. We use the mean square metric, namely 
the expression: uk+l vt+' I I 2 ER= ~2 I S F(uc-u'v"-v)-F(u'v) dudv, all patckes u=u~ v= D where M M 
2Z(u, v) = ~_2 Y', Bi(u) Bj(v) bij. i--O j--O ER is normalized by dividing by Mk+l P/+[   SQ= ~-~ 
I I [F(uc-#d'Vc-V)] 2du dr" aU patches u = u~ v = v s Such a metric is commonly used when computing 
sampling errors [RoKa76] or evaluating filtering methods [KaU181, KiON87]. In those cases the difference 
involved is between the image function (making some assumptions when it is unknown) and its sampled/approximated 
version. Here our metric is to indicate how well the filter is approxi- mated, independently of the filtered 
image (i.e. texture). Such a metric is especially useful in this case because as the integral of the 
square of the difference between the filter and its approximation, it is directly related by Parseval's 
theorem to the energy difference due to the approximation error. This energy plays the main role in the 
various formulas for the characterization of the quality of filters[Prat78]. Since the method involves 
a piecewise approximation, we cannot seek a global least-square solution, but a formulation which gives 
a local least-square approximation is good as long as the computation of the bij is not too costly. The 
cost of the computations of the basis functions themselves is not as important an issue since it only 
intervenes in the prepro- cessing step. Polynomial bases are an obvious choice since they are well behaved 
and familiar. They have the added advantage that many of the popular filter formulations are polynomial, 
and therefore the approximation can be expected to be good (it is not necessarily exact, even if the 
degree of the polynomial describing the filter is less than or equal to the degree of the basis, since 
the screen-texture mapping itself can be arbitrary). It is also important for storage pur- poses that 
the values of the basis functions are not far from a [0,1] range since this influences the amount of 
storage needed for the NIL maps. For our examples we have chosen an interpolating formulation. The advantage 
is that in this case the bij of equation 2 are simply the values of the filter at the knots and this 
simplifies the use of the NIL maps. In the choice of the order for the basis functions, there is an obvious 
trade-off between the storage and computation cost, which are proportional the the square of the order 
(we will assume it is the same in the u and v direction) and the number of patches required for a given 
quality of interpola- tion. It is interesting to examine the characteristics of the first few orders. 
M Patch Terms/ Patches Terms % Error Type Patch Required Required i Box t NR --31.5 2 Bilinear 4 27 
108 13.1 3 Biquadratic 9 22 198 11.2 4 Bicubic 16 13 208 8.8 The entry in the "Patches Required" column 
is the number of patches required to approximate a bivariate Gaussian filter in the -2c to 2~ range with 
a mean square error less than 5% of the mean square value of the filter. The 5% error thres- hold was 
not reached for the order I approximation because the necessary level of subdivision was more than the 
resolu- tion of the original texture used. The entry in the "% Error" column is the percentage error 
when 9 patches of equal size are used to approximate the same filter. These errors should be compared 
to a resolution error of 54.6% and an interpo-lation error of 2.0% (relative to the ideal filter) for 
a Gaus- sian of~=l pixel [Prat78]. The latter are mean square errors in frequency space, but the order 
of magnitude is useful and indicates that it is easy to achieve approximation errors that are much smaller 
than the one due to the filter itself. Figures 2, 3, 4 and 5 illustrate how the surface is approximated 
by the patches of order 1, 2, 3 and 4 respectively. It should be noted that these surfaces are not explicitly 
computed in the normal process. Figure 2. Gaussian approximated by 9 order I patches (boxes) Figure 3. 
Gaussian approximated by 9 order 2 (bilinear) patches Figure 4. Gaussian approximated by 9 order 3 (biquadratic) 
patches X X Figure 5. Gaussian approximated by 9 order 4 (bicubic) patches It is clear from the table 
than in practice order 2, a bilinear patch approximation, is sufficient, since after that the gain in 
precision is probably not sufficient to compensate for the increased cost in computation and storage. 
Most of the examples we give were computed with a Catmull-Rom inter- ~ Computer Graphics, Volume 22, 
Number 4, August 1988 polating bicubic spline formulation[CaRo74] mainly for illustration purposes. It 
would be serious overkill for a pro- duction system. 4.2. Choosing the right level As indicated before, 
it is crucial for the efficiency of the method that, when applying a filter, the number of patches used 
to approximate the surface is bounded by a small con- stant, independently of the kernel size in texture 
space. We use the following algorithm, but we stress that there are many ways to meet the same goal. 
For a given type of filter in screen space, a set of Ng representative points on the filter surface, 
called filter grid points, and a number N n is chosen. They are chosen so that if the filter surface 
is approximated by Np patches of equal size including all the filter grid points, then the square error 
is less than a given threshold. For most filters the grid points will be equally spaced and form a square 
grid in screen space (whence their names), but it is not required. There should be at least four grid 
points defining a quadrilateral enclosing the kernel in screen space. In the simplest case the grid points 
reduce to these four boundary points. In the case of a kernel with an infinite width of support, these 
points define the boundary at which the filter can be safely truncated. We will see that there is not 
much penalty involved in making this boundary very loose. We will call s the level within the NIL map 
pyramid, s ranging from O, which contains only one patch, to p, with 2Px2 p patches. In the case of discrete 
tex- tures p is the level of the original image. The steps of the algorithm are as follows: (1 ) Determine 
the global level. map the four corner grid points to texture space.  determine in texture space the 
smallest enclosing rec- tangle and compute its area A in texel square units.  determine the level s 
such that the rectangle is covered by Np patches. To do this, observe that at level s each patch has 
area 2e-~x2 p-s. Thus s = p- log2 . (5)  compute the indices of the patches to be selected at that 
level. At level s they are the coordinates of the corners of the minimum enclosing rectangle taken from 
p bits to the top s bits.  We now have found the levels such that the filter kernel is covered by at 
least Nt, patches. The screen to texture map- ping, however, might have distorted the kernel in such 
a way that the filter would be poorly approximated, especially in the case of low order bases. The role 
of the filter grid points is to allow a refinement of the selected patches. (2) Refine the selected patches 
 for each of the selected patches Refine(patch)  Reline(patch) is a recursive procedure: if the patch 
contains more than 2 of the filter grid points and if it is not at level p then split it in 4 by selecting 
the 4 corresponding patches at the next s+l level. For each of these new patches Refine(patch).  Figure 
6 illustrates the determination of the global level, and Figure 7 the refinement of the patches. In this 
example Ng =9, Ne =4, p =5, A = 195 ands =2. ÷-H-¢-H.+H+!"  t!t!!t!!t!!t ;.i.i.;.i.H.i.i.l.i. -H-H.i.~-t-1.+-1.~4- 
lll!l Ill; ][iJ~i]l!ll! }:H-:hi:~--U.+:H:~: -r -~ T": -V ~TO:C= " TZZST%TW~TT f ,t :, ::~< + x;= .; ~: 
,&#38;, . .$. -~--.4-i.. :: : ~ OO! 000 9414~ 6 - -i-*-..*-. -*.  J .M=l.i.,.l:t.,-l.l.,. :i; : :i:; 
--*. ,$ ; ;~-- -.~- : : :i; -.i.  -tMt-rf-!-i- Texture Screen DMinimum enclosing rectangle .............,.,,, 
:;i i Four level 2 patches selected Figure 6. Determining the global level W iJ ~ ililiiiiiii!ii!iiiiiiiiiil 
 iiJiiiiiiiii i!i iiiiii iiii!iiiiiiiiii~:~j:i: ii~:iiiilili~i:i:ili~/:' :::::::::::::::::::::: ! Patches 
selected iiiiiiiii~iiiiiiiiiiiiii~i~i;i;i~i~i~'iiiiiiiiiiiii :::::::::::::::::::::::::::::::: Patch to 
be split Figure 7. Refining the patches We can establish the range of the number of patches actually 
selected. The smallest number is obtained when none of the initial patches are actually split. In this 
case about N n patches are then used. The exact number depends on the effect of rounding the log in equation 
5, but cannot be more than 4Np. The worst case arises when patches have been split from level 0 down 
to level p. In this case, the last split occurred because there were at least 3 grid points in the patch. 
If there were more than 3 grid points involved at any level, then we would not have maximal splitting 
for all grid points, because the extra points are not credited for the creation of new patches. Therefore 
the worst case occurs when there are SIGGRAPH '88, Atlanta, August 1-5, 1988 only 3 grid points present 
in the patch from level 0. They would then create 3p new patches from level 0 to level p. No other triple 
can create that many patches, since the first splitting, from leve| 0 to level 1, is already credited 
to the first triple. To simplify the analysis, we will then use the upper bound, which is obtained assuming 
that all the triples cause the maximum number of new patches. Figure 8 shows the situation for a patch 
at level 0 split down to level p = 5 by 3 filter grid points. 4 7 12 9 8 Figure g. Maximum splitting 
of a patch Ng Therefore a maximum of 3p new patches are created, 3 and the maximum total number of patches 
is 4 Np+p Ng. We are therefore guaranteed a constant upper bound for a given resolution. The term p is 
proportional to the log of the reso- lution, and will not be very high (10 or 11 at most). 4,3. Discrete 
Textures In most computer graphics applications (but not all) the tex- ture is discrete and finite. A 
convenient formulation is to represent it by a finite array of delta pulses[Prat78] : 2/,_1 2r,_l  
y, ~ T(mAu,nAv) ~)(u-rnAu,v-nAv). m =0 n =0 Each discrete value can be written as T1(m,n ). The double 
integral of the convolution then reduces to the sum 2P-| 2/'-| Sc = ~ ~2 Tl(m,n)F(uc-mAu,vc-nAv). m=0 
tt =0 It is generally assumed that the texel value represents a sam- ple in the middle of the texel, 
that is Tl(m,n) has effective coordinates ((m +0.5)Au, (n +0.5)Av). The C 6 for patch (k,l) at level 
s are then computed as 111.+1 I'/+ t Cij = ~ ~ Tl(rn,n) Bi(u) Bi(v). II ~ l¢~ I' = I' / To normalize 
the Cij, the sum of the coefficients multiplying the Tl(k,1), that is products of the form Bi(u)Bj(v), 
has to be computed and used to divide the entries in the corresponding NIL maps. The entries are thus 
of the same order of magni- tude and require a precision similar to the one required by the texel values. 
In this respect they are similar to MIP map entries, and are less demanding than entries in a summed- 
area table or a table using repeated integration, which require a higher precision. 4.4. Analytic Textures 
In the case of textures given as continuous T(u,v) functions, a double integral must be performed for 
the computation of the Cij (Eq. 3). Since the double integral is taken over a square region in texture 
space, it is advantageous to use Green's theorem. It states that given functions P(u,v) and Q(u,v) which 
are continuously differentiable on R 2, and given a closed path y f Pdu + Qdv = !! ~Q ~v 1 du dv. "i 
2 ~u The partial derivatives also must be continuous on R 2. It is simpler at this point to use a [0, 
1] range for u and v within a patch. The Cij for patch (k,l) at level s are written as: 1 1 Cij = S I 
T((kt-U)l"(l-bv)l')gi(ll)Bj(v)du dv u:0 v-=0 where r is the ratio between the size of patches at level 
p and the size at level s. Hence r = 2 n-s. If we can find a function P(u,v) such that OP(u,v) _ T((k 
+u) r, (l+v) r) By(v), 3v which means that P(u,v) = S T ((k +u) r, (/+v) r) Bj(v) dr, then by Green's 
theorem, Cij = --J Bi(u ) P(u,v) du, 7 where 'y is the path around the square (0,0),(I,0),(1,1),(0,1). 
This reduces to the two terms: 1 I Cij = -~ Bi(ll)e(u'O)du+ I Bi(u) P(u'l)du" u =0 u =0 There are many 
commonly-used texture functions for which these integrals have closed-form solutions, and which there- 
fore can be computed analytically at little cost. It is important to note that with analytical textures 
the C q do not have to be precomputed, but can be computed "on the fly". There is also no ultimate resolution. 
A "bottom" level still has to be kept in the algorithm used to find the right level in the NIL maps (which 
are now "virtual" NIL maps) to limit the number of patches created. In the case where no closed-form 
solution for the integrals is available, or if the functions involved are expensive to compute, or if 
the map- ping will be done often enough so that most of the levels and most of the patches will be used, 
precomputing the real NIL maps can still be the most efficient solution. 4.5. Interpolation of Textures 
A situation intermediate between discrete textures and pro- cedural textures arises when a continuous 
T(u,v) is com-puted from a set of discrete Ti(m,n). This is of course what is produced by a reconstruction 
filter, but in this case we still want the convolution of our filter with the reconstructed sur- face. 
 '~' Computer Graphics, Volume 22, Number 4, August 1988 We will examine briefly the common case where 
the interpo- lation is done with a piece-wise polynomial intewolant. In this case the only difference 
from the preceding section is that Green's theorem has to applied piece-wise (since the functions involved 
have to be continuous over the region), and we have now two different situations: when the patches of 
the NIL maps are larger than the patches of the interpo- lant, which correspond to the case s<p, or r= 
2P-S>l, and when the patches of the interpolant are larger than the patches of the NIL maps, that is 
when s>p and 1" = 2p-s< I. In the s<p case the computation of the Cij proceeds as in the discrete case, 
except that there is an effective integration over each interpolant patch within the NIL map patch. To 
give a specific example, assume that we have a discrete tex- ture Tl(m,n), which is bilinearly interpolated. 
To simplify the formula we will assume, as opposed to what we have done for discrete textures, that the 
T/(m,n) values are at the lower left corner of texel (re,n). The interpolated value is Ti(m +ut, n +v 
t) = Tl(m,n )( 1 -ut )( l-vt ) + Tl(m,n +1 )( 1 -ut)v t + Tl(m +l,n)ut(l-vt) + Tl(m +l,n +1)utv t. It 
is important to distinguish the parameters of the interpo- lant within the texel (ut,vt) from the parameters 
of the NIL map patches (u/~,vp). The relationship between them is: kr + upr = m + u t h + ~),r = n + 
v t for patch (k,l) at level s, r = 2p-s, and texel (m,n). If r>l, it is best to let (ut,vt) range from 
0 to I, and express (ul,,v p) as functions of them. If s<l, then it is best to use (up,Vp) and express 
(ut, vt) as functions of them. One can then compute P (u,v). For example, for the term Coo it is (to 
simplify (ut,vD are written as (u,v)): P (u,v) = Tl(m,n) (l-u) (av+bv2+cv 3) + Tl(m,n +1) (l-u) (dv2+ev 
3) + Tl(m+l,n) u (av+bv2+cv 3) + Tl(m+l ,n+l) (dv2+ev 3) where a,b,c,d,e are expressions of r,k,l,m,n. 
The line integrals for Coo are: 1 1 - S (1 +k -m +u ) p (u, O) du + S ( 1 +k -m +u ) p (u, 1 ) du. 0 
/" 0 /" In the case where s>p, the NIL maps are not actually precomputed but computed as needed. For 
the example above, the functions are the same but the variables used are now (up,vp), which range from 
0 to 1. The substitutions are ut = k r + upr -m, v t = I v + vpr -n. This allows an arbitrary magnification 
of the texture with correct filtering of the interpolated surface. 5. Examples of Applications 5.1. Approximating 
Filters _ A2+, V2 A Gaussian kernel, 1 2~2 F (x,y) = 2rt-------Te has many qualities for filtering, but 
its main drawback is its infinite width of support. Using the NIL maps it is not such a problem, since 
a wide support can be used at little increased cost in number of patches. Figures 2 to 5 depict approxima- 
tions of a Gaussian with polynomial bases of order 1 to 4. The top row of Figure 9 shows 128 x 128 pictures 
produced by filtering the original mandrill texture, using NIL maps with Catmull-Rom bicubic bases and 
an identity mapping between screen and texture. The Gs are 1.0 and 0.3; the width of support is 4 x 4 
pixels. It is easy to see the blurring of the image caused by the widening of the kernel. The second 
row of Figure 9 shows an approximation of a separ- able sinc filter: m 2 sin(rex) sin(my) F (x,y) -rt 
2 ma my This is the ideal reconstruction filter for textures that have had rectangular band-limiting, 
but is not used in practice because of its infinite width of support and negative lobes. The method used 
here is not affected by negative lobes, and the sinc filter can be used almost as easily as the Gaussian. 
The main difference is that the approximation errors are greater with low order bases. The examples given 
are for 03 3= equal to re/2 and --. The first zero is then at 2 and ~ 2 3 pixel respectively. The other 
parameters are the same as for the Gaussian filter. It is easy to see how much sharper and more detailed 
the pictures are compared to the Gaussian filter. A diff,,fence of Gaussians or DOG has been used in 
image processing (mostly as an approximation of the Laplacian of a Gaussian) and to model some properties 
of the human visual system. Figure 10 shows pictures obtained by approxima- tions of a Gaussian of ~ 
= 0.5, another Gaussian of ~ = 1.0, and the difference of the preceding two suitably normalized. Figure 
l I shows the approximated surface. Figure 11. Approximation of a DOG The last example is of a "rotated 
Gaussian". The kernel of a Gaussian filter has been rotated and stretched to simulate the effect of the 
texture rotating around a centre. The resulting image shown in Figure 12 simulates convincingly the motion 
blur which would be created by the texture rotating while a camera shutter is open. The kernel under 
the rotation takes 235 SIGGRAPH '88, Atlanta, August 1-5, 1988 the shape of a sickle shown in Figure 
13, and this example for a pixel in the lower left region of the picture. illustrates how well a non-convex 
kernel is handled by the method. / ( I i //-Y i_ L / t Figure 13. Kernel transformed by rotation It 
is interesting to note that paradoxically a box filter is not well approximated by this method because 
of the discon- tinuities. Figure 14 shows a box filter approximated by Catmull-Rom bicubic. The error 
in the approximation is clearly visible, Of course one would not want to use this method for box filters 
anyway. Figure 14. Approximation of a box filter by Catmull-Rom bicubic 5.2. Space-Variant Mappings The 
perspective mapping is the most common and the most important space-variant mapping in computer graphics. 
Fig- ure 15 shows the same old monkey in perspective (the plane of the texture is inclined 60 degrees 
from the vertical), and filtered by a sinc and a Gaussian filters with the same param- eters as used 
in the preceding section. The picture in the middle was produced by a display system using MIP maps. 
It is easy to note how sharp are the pictures produced with the sinc filter with a small ~. Most techniques 
would consid- erably blur the top of the picture in these cases. Figure 16 depicts a slice through the 
top of the surface approximated for the Gaussian filter, illustrating the deformation of the kernel under 
the perspective transformation. This is a filter I I t [ I | IIIllllLI klllll I I t I I [ I I I lllllll,, 
m \llt I I I | I i i | i I I I l ll_~-l-.l-l~ ~J I I | i I I I I I I I I l l ~-./..J-/-~NL_LI ~ ! i i 
i i i ; I I l~l_~LJ-J~r Figure 16. Distortion of a Gaussian kernel under perspective Another challenging 
example is conformal mapping. The mapping in this example takes a rectangle (again the original mandrill) 
to a dodecagon while conserving all angles and continuity. For more details on the mapping see [FiFC87]. 
In this case the mapped kernels vary in shape and size from point to point. Figure 17 shows the results, 
again with the same two filters. It is easy to follow the lines of the long hairs around the mouth and 
to see the compression of the texture around the eyebrows, as well as the expansions near some of the 
vertices of the dodecagon. 6. Conclusions The basic goal of achieving constant-time filtering with arbi- 
trary space-variant kernels has been met. The most notable aspects of the technique are that it does 
not involve approxi- mations of the convolution, but only approximations of the filters' surfaces, that 
it can be applied to discrete as well as analytic textures, and that it allows the use of sophisticated 
filters without having to pay too high a price. While the examples we give are relatively simple, it 
is important to remember that the mappings can be composed, and a mixture of conformal, perspective and/or 
environment mappings Would be handled in the same way. Since the method is at first glance rather complex, 
and A involves the computation and storage of --~M 2 terms per texel, a legitimate question is whether 
it is practical in simple cases, First, the technique can be simple. The error results show clearly that 
bilinear approximation is probably sufficient for most cases, and in this case an approximation with 
16 patches requires 64 terms. There is therefore a gain over a direct convolution if the filter covers 
more than 64 texels on average. This is met, for example, if we filter a 256 × 256 texture down to a 
128 x 128 image with a 4 x 4 pixel width of support. If we compare to MIP maps, the computation and storage 
costs are multiplied by M ~. The gain is in the additional flexibility and filtering quality. Even in 
the case where M = 1, where the storage is the same as in straight M1P maps, the adaptive subdivision 
inherent in the methods improves the result. @ '~' Computer Graphics, Volume 22, Number 4, August 1988 
As mentioned before, in animation a small gain per frame quickly recoups even a large preprocessing cost, 
and for any texture whose on-screen size varies by a few binary orders of magnitude during a sequence 
there will be a net saving no matter which order is used. Glossary Symbol Meaning Relations u,v Texture 
coordinates O_<u,v < 2/~ .v,y Screen Coordinates p Texture Resolution s Level in NIL map r Linear ratio 
between levels p and s r=2 v ~ (i,j) Indices for basis functions (k,I) Indices for patches (m,n) Indices 
for texels  (u, v~) Coordinates at level p O --< It t, I' t < 2 p ut, Coordinate in patch {k,1) at level 
s ]O'+ltp r = m +ll t vp Coordinate in patch (k,l) at level s h'+vpr = n+v r T (u, v ) Texture function 
Tl(m,n ) Discrete texturesamples F(u,v) Filter in texture space (u,,v,) Center of filter in texture space 
z Texture to screen mapping (_r,y) = z(u,v) "U~ Screen to texture mapping (u,v) = z -I (.r,y) M Order 
of polynomial basis Degree = M-1 Bi(u) Basis function O<_i <M bii Coefficients of B,(u)Bi(v) for given 
filter C U Precomputed convolution terms S,. Convolution of texture with filter Eq. (l) S, Approximation 
to S, Eq. (4) Acknowledgements We acknowledge the support of NSERC through operating grants, a University 
Research Fellowship and an equipment grant which considerably facilitated this research. The first author 
was visiting at Xerox PARC and the second author was visiting at CUI, University of Geneva, when this 
work began, and they are grateful for the support these institu- tions provided. References Crow81. 
F.C. Crow, "Summed-Area Tables for Texture Map-ping," Computer Graphics, vol, 18(3), pp. 207-212, .July 
1984. FiFC87. E. Flume, A. Foumier, and V. Canale, "Conformal Texture Mapping," Proceedings of Eurographics 
'87, pp. 53-64, August 1987. Elsevier Science Publishers (North Holland) (August 24-28, 1987, Amsterdam, 
The Netherlands). GrHe86. N. Greene and P. S. Heckbert, "Creating Raster Omnimax Images from Multiple 
Perspective Views Using the Elliptical Weighted Average Filter," IEEE Computer Graphics and Applications, 
vol. 6, no. 6, pp. 21-27, June 1986. Gree86. N, Greene, "Environment Mapping and Otber Applica- tions 
of World Projections," IEEE Computer Graphics and Applications, vol. 6(11), pp. 21-29, November 1986. 
Heck86a. P.S. Heckbert, "Filtering By Repeated Integration," Computer Graphics, vol. 20(4), pp. 315-321, 
August 1986. Heck86b. P.S, Heckbert, "Survey of Texture Mapping," 1EEE Computer Graphics and Applications, 
vol. 6(11), pp. 56-67, November 1986. KaUl81. J. Kajiya and M. Ullner, "Filtering High Quality Text for 
Display on Raster Scan Devices," Computer Graphics, vol. 15, no. 3, pp. 7-15, 1981. (ACM SIG- GRAPH'S1 
Conference Proceedings, July 1981, Dallas, Texas) KiON87. K. Kishimoto, K. Onaga, and E. Nakamae, "Theoretical 
Assessments of Mean Square Errors of Antialiasing Filters," Computer Vision, Graphics and Image Pro- 
cessing, vol. 37, pp. 428-437, 1987. NaFo87. A. Naiman and A. Fournier, "Rectangular Convolution for 
Fast Filtering of Characters," Computer Graphics, vol. 21, no. 4, pp. 233-242, 1987. (ACM SIG-GRAPH'87 
Conference Proceedings, July 27-31, 1987, Anaheim, California). Prat78. W.K. Pratt, Digital linage Processing, 
Wiley- Interscience, 1978. Will83. L. Williams, "Pyramidal Parametrics," Computer Graphics, vol. 17(3), 
pp. 1-11, July 1983. DuSS78. W. Dungan, A. Stenger, and G. Sutty, "Texture Tiles Consideration for Raster 
Graphics," Computer Graph- ics, vol. 12, no. 3, pp. 130-134, 1978. (ACM S1G-GRAPH'78 Conference Proceedings, 
July 1978, Atlanta, Georgia) CaRp74. E. Catmull and R. Rom, "A Class of Local Interpolat- ing Splines," 
in Computer-Aided Geometric Design, ed. R. F. Riesenfeld, pp. 317-326, Academic Press, 1974. RoKa76. 
A. Rosenfeld and A. C. Kak, Digital Picture Process- ins, Academic Press, 1976.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378516</article_id>
		<sort_key>239</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[High-performance polygon rendering]]></title>
		<page_from>239</page_from>
		<page_to>246</page_to>
		<doi_number>10.1145/54852.378516</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378516</url>
		<abstract>
			<par><![CDATA[This paper describes a system architecture for realtime display of shaded polygons. Performance of 100,000 lighted, 4-sided polygons per second is achieved. Vectors and points draw at the rate of 400,000 per second. High-speed pan and zoom, alpha blending, realtime video input, and antialiased lines are supported. The architecture heavily leverages parallelism in several forms: pipeline, vector, and array processing. It is unique in providing efficient and balanced graphics that support interactive design and manipulation of solid models. After an overview of algorithms and computational requirements, we describe the details of the implementation. Finally, the unique features enabled by the architecture are highlighted.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphics systems]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>B.2.1</cat_node>
				<descriptor>Parallel</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.3</cat_node>
				<descriptor>Pipeline processors</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>B.2.1</cat_node>
				<descriptor>Pipeline</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.1.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600.10010615</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits->Logic circuits</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010522.10010526</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Serial architectures->Pipeline computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010600.10010615</concept_id>
				<concept_desc>CCS->Hardware->Integrated circuits->Logic circuits</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39048699</person_id>
				<author_profile_id><![CDATA[81100563035]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akeley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics, Inc., 2011 North Shoreline Boulevard, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335170</person_id>
				<author_profile_id><![CDATA[81365597127]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jermoluk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics, Inc., 2011 North Shoreline Boulevard, Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bresenham, J. Algorithm for Computer Control of a Digital Plotter. IBM Systems Journal 4, 1 (1965), 25-30.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Clark, Jim and Hannah, Marc. Distributed Processing in a High- Performance Smart Image Memory. Lambda 1, 3 (4th Quarter 1980), 40-45.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Clark, Jim. The Geometry Engine, A VLSI Geometry System for Graphics. Computer Graphics (ACM) 16, 3 (1982), 127.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Crow, Frank. The Aliasing Problem in Computer-Generated Shaded Images. Communications of the ACM 20, November 1977, 799-805.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>802893</ref_obj_id>
				<ref_obj_pid>800090</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry and Johnson, B. An Expandable Multiproeessor Architecture for Video Graphics. Proceedings of the 6th ACM-IEEE Symposium on Computer Architecture (April 1979), 58-67.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. Continuous Shading of Curved Surfaces. IEEE Transactions on Computers C-20, 6 (June, 1971), 623-629.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gupta, Safish and Sproull, Robert. Filtering Edges for Gray-Scale Displays. Technical Report, Carnegie-Mellon University, Computer Science Department, 1981.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Porter, Thomas and Duff, Tom. Compositing Digital Images. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18, 3 (July 1984), 253-259.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Silicon Graphics. IRIS 4D/70 Superworkstation Technical Report. Silicon Graphics, Mountain View, CA 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360802</ref_obj_id>
				<ref_obj_pid>360767</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sutherland, Ivan and Hodgman, Gary. Reentrant Polygon Clipping. Communications oftheACM 17, 1 (January 1974), 32.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger and Thayer, Larry. A Fast Shaded-Polygon Renderer. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20, 4 (August 1986), 95-101.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37426</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Torborg, John. A Parallel Processor Architecture for Graphics Arithmetic Operations. Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987). In Computer Graphics 21, 4 (July 1987), 197-204.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 High-Performance Polygon Rendering Kurt Akeley 
Tom Jermoluk Silicon Graphics, Inc. 2011 North Shoreline Boulevard Mountain View, CA 94039-7311 ABSTRACT 
 This paper describes a system architecture for realtime display of shaded polygons. Performance of 100,(300 
lighted, 4-sided polygons per second is achieved. Vectors and points draw at the rate of 400,000 per 
second. High-speed pan and zoom, alpha blending, realtime video input, and antialiased lines are supported. 
The architecture heavily leverages parallelism in several forms: pipeline, vector, and array processing. 
It is unique in providing efficient and balanced graphics that support interactive design and manipulation 
of solid models. After an overview of algorithms and computational requirements, we describe the details 
of the implementation. Finally, the unique features enabled by the architecture are highlighted. CR Categories 
and Subject Descriptors: B.2.1 [Arithmetic and Logic Structures]: Design Styles Parallel, Pipeline; C.1.2 
[Processor Architectures]: Multiprocessorrs - Parallel processors, Pipeline processors; 1.3.1 [Computer 
Graphics]: Hardware Architecture -Raster Display Devices. Additional Key Words and Phrases: Graphics 
Systems. Permission to copy without fee all or part of this material is granted provided that the copies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publication and its date appear, and notice is given that copying is by permission of the Association 
for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
&#38;#169;1988 ACM-O-89791-275-6/88/O08/0239 $00.75 1. Introduction Traditional 3D graphics workstations 
have concentrated on the hardware that transforms points and lines from object-space to screen-space. 
As users" needs for display of realistic solid objects have increased, demands on graphics architectures 
have changed significantly. New challenges include increases in transformation rate, incorporation of 
realtime illumination calculations, and dramatic increases in pixel fill rates. Contemporary workstations 
have attempted to satisfy these new demands using a variety of architectures. Swanson and Thayer [11] 
describe a system which incorporates parallel pixel processors in its raster subsystem. A parallel geometry 
system is described by Torborg [12]. The lineage of these and other contemporary graphics systems can 
be traced to works by Clark [3], Clark and Hannah [2], and eventually to Fuchs and Johnson [5]. Our specific 
goals for the performance and capability of the new architecture were: 100,000 polygons per second. 
The polygons are RGB, 4-sided, 10xl0 pixels, lighted, Gouraud shaded [6], arbitrarily rotated, Z-buffered, 
clip tested, projected, and rendered into one of multiple, possibly overlapping, windows at an instantaneous 
rate of 100,000 per second.  10 frames per second. Realtime systems must be able to draw and display 
at rates exceeding 10 Hz.  Window support. User productivity is optimized by a system that supports 
multiple fully independent windows.  First we describe our view of the general algorithmic problem of 
rendering 100,000 polygons per second, paying particular attention to the computational requirements 
of each step of the process. Then we describe a novel architecture to achieve the goals. Finally we present 
several unique features that were realized from the implementation. 2. Problem Description The floating-point 
performance and pixel fill rates required for interactive display of solids are both exceptional. By 
examining each component of the problem we show that at least 40 million floating-point operations per 
second, and fill rates exceeding 10 million pixels per second, are required to render 100,000 polygons 
per second. The problem components are: 1. Transfer vertex data from memory to the graphics subsystem. 
 2. Transform vertex coordinates. 3. Transform vertex normals. 4. Light each vertex. 5. Clip each 
vertex. 6. Project each vertex. 7. Map vertex coordinates to the screen. 8. Fill the resulting screen-space 
polygons, interpolating color and depth.  SIGGRAPH '88, Atlanta, August 1-5, 1988 9. Clip all drawing 
against the visible window boundaries. 10. Be prepared to quickly swap drawing contexts at any time. 
 11. Continually scan the frame buffer at screen refresh rates, interpreting each pixel appropriately 
as a function of the process to which it belongs.  2.1 Transfer Data Achieving our goal of 100,000 4-vertex 
polygons per second requires that 400,000 vertex specifications per second be transferred to the graphics 
subsystem. A lighted vertex specification includes 6 floating-point values: 3 (x,y,z) specify the vertex 
position, and 3 (nx, ny,nz) specify the vertex normal direction. The required data rate is therefore: 
400,000 (xform/sec) x 6 (words/xform) x 4 (bytes~word) ~ 10 Mbytes/sec 2.2 Transform Vertexes Homogeneous 
3D vertexes include 4 components, and are transformed by multiplication by a 4x4 matrix. This vector 
operation requires 16 floating- point multiplications and 12 floating-point additions. The computation 
rate is therefore: 400,000 (xform/sec) x (16 + 12) (flop/~form) = 11 Mflops If it is known that the w 
component of the vertex to be transformed is 1.0 (a common case with 3D homogeneous data) then 4 multiplications 
can be eliminated, resulting in a computation rate of: 400,000 × (12 + 12) .~ 9.5 Mflops 2.3 Transform 
Normals Plane equations are properly transformed by the inverse-transpose of the vertex matrix. This 
transformation has the same expense as the full vertex transformation. It is unnecessary, however, for 
lighting calculations. Vertex normals are plane equations stripped of distance information. Because normals 
are not position sensitive, translation information in the vertex matrix need not be included in a normal 
matrix. Also, because vertex normals are normalized to unit length before they are used, uniform scale 
information need not be applied to a normal matrix. Thus only rotations and non-uniform scales of the 
vertex matrix are applied, by inverse-transpose, to the normal matrix. A 3 by 3 normal matrix supports 
all the required information, and is used to transform the 3-component lighting normals. This transformation 
requires 9 floating-point multiplications and 6 floating-point additions, for a total computation rate 
of: 400,000 x (9 + 6) = 6 Mflops As was indicated above, normals must be unit length before they are 
used in lighting calculations. Although it will in some cases be possible to avoid explicit normalization, 
1 we compute the expense of this operation. Sum of squares requires 3 floating-point multiplications 
and 2 floating-point additions. We conservatively estimate the cost of reciprocal square root calculation 
to be twice that of simple reciprocal calculation: 8 floating- point operations. Finally, each of the 
three components is multiplied by the newly computed factor. The approximate required computation rate 
for normalization is: 400,000 × (3 + 2 + 16 + 3) = 9.5 Mflops 2.4 Light Vertexes Because the target 
polygons are Gouraud shaded, lighting calculations are required only at the vertexes of polygons, never 
in their interiors. Transformed vertex and normal information, current light positions and colors, surface 
properties, and specific lighting-model properties for each vertex are resolved to a single RGB triple. 
These triples will be interpolated across the interiors of projected polygons. 1. Normals spec~ed witk 
unit tength, no non-uniforrn scales. The fighting model that we chose for our performance requirement 
estimates is: A single light - infinitely distant  A viewer - infinitely distant  Ambient, diffuse, 
and specular reflection components The equation  Cob jeer = C,ma~i,nt + C~ffus, Cugh,(N.L ) + C,p,cularCtlght(N'H)" 
is executed 3 times, once each for red, green, and blue (all C's are RGB vectors). Dot products are evaluated 
only once. Including tests for overflow, each optimized lighting computation requires 12 floating-point 
multiplications, 10 floating-point additions, 5 floating-point comparisons, and a table lookup. The total 
compute power required is: 400,000 x (12 + 10 + 5 + 1) ~ 11 Mflops 2.5 Clip Polygons are correctly clipped 
in all cases using the Sutherland-Hodgman Algorithm [10]. This algorithm requires one floating-point 
compare per clipping plane, 6 compares per vertex in a 3D system. Additional floating- point operations 
are required only in the event of actual clipping, i.e. infrequently. In either case the algorithm execution 
time is dominated by data movement and branching, not by floating-point operations. Using proper optimization 
to avoid unnecessary clipping, the floating-point demands for clipping are: 400,000 x 6 = 2.5 Mflops 
 2.6 Project Each vertex is projected in homogeneous space by division of its x, y, and z components 
by its w component. This is accomplished most efficiently by first computing l/w, then multiplying each 
of x, y, and z by this factor. We asserted previously that computing a reciprocal requires 8 floating-point 
operations. Thus perspective division requires a total of 11 floating-point operations, at an aggregate 
rate of: 400,000 x (8 + 3) = 4.5 Mflops 2.7 Viewport and Fix Projected vertexes are mapped to screen 
coordinates with a simple affine calculation. Each of the three vertex components is scaled by an independent 
scale factor, offset by an independent offset, and convened to integer screen coordinates. The total 
floating-point calculation rate is: 400,000 × (3 + 3 + 3) = 3.5 Mflops The total floating-point performance 
required to convert object-space coordinate vertexes and normals to screen-space coordinates and colors 
is: Operation Mflops Vertex Transformation 9.5 Normal Transformation 6 Normal Normalization 9.5 Lighting 
11 Clipping 2.5 Projection 4.5 Viewport 3.5 Total 46.5  2.8 Fill and Smooth Shade Screen Space Polygons 
Screen-space vertexes, now interpreted as polygon vertexes, are used to specify the boundaries of frame 
buffer regions to be smooth shaded. Although the details of this shade/fill operation are implementation 
dependen4 we can safely describe some of the problems that will be encountered. They are: Test for convexity. 
A substantially more complex algorithm is required to fill concave polygons.  Decompose to trapezoids. 
It will almost always be desirable to reduce the full polygons to collections of screen-aligned trapezoids, 
whose   ~ Computer Graphics, Volume 22, Number 4, August 1988 parallel edges are in the direction 
of preferred fill in the frame buffer.  Calculate slopes. Slopes for all parameters to be interpolated 
must be computed. Substantial integer precision must be maintained if interpolation errors are to be 
avoided.  Write to the frame buffer. A huge memory bandwidth is required to till polygons at the rate 
of 100,000 per second. Our benchmark t0 pixel by l0 pixel polygons fill at 10 Million pixels per second. 
A substantially higher fill rate is desirable for larger polygons. Screen clear, really just filling 
a large, screen-aligned polygon, demands the highest fill rate.  2.9 Clip all Drawing Against Visible 
Window Boundaries The clipping and viewport operations described above will limit polygon tilling to 
a screen-aligned r~tangular region, or window. They are not sufficient, however, if the window is non-rectangular, 
either because it is obscured by another window, or because it wasn't rectangular to begin with. In some 
systems the problem of obscured windows is deferred by always rendering into rectangular regions, then 
assembling the final screen image on the fly. While attractive in many respects, this solution does nothing 
to solve the fundamental problem of non-rectangular windows, and is expensive in terms of memory consumption. 
 2.10 Change Contexts The entire graphics system must be prepared, at any moment, to save the drawing 
state of the current context and restore the state of a previously interrupted context. This operation 
must happen quickly in most cases, but must also be able to support a huge number, perhaps hundreds, 
of independent contexts. Support for a working set of processes is therefore desirable. 2.11 Scan Frame 
Buffer Although the bandwidth required to scan a high-resolution frame buffer at 60 Hertz is enormous 
(pixel rates of 110 to 125 MHz are standard today) the availability of inexpensive Video RAMs allows 
this bandwidth to be supported with little engineering effort. We don't emphasize this problem here. 
Rather, we concentrate on the issue of multiple windows as it pertains to frame buffer output. It is 
desirable that imaging to separate windows be as independent as possible. Most important, perhaps, is 
that windows be able to select and alter their buffer modes independently. Single and double buffer images 
must coexist, and double buffer images must swap buffers independently. Further, if pixels can be interpreted 
in different ways, it is important that the interpretation in each window also be independent. An important 
exception is color mapping, the process of interpreting pixel values as indexes into a table of RGB triples. 
While it would seem that each process should have its own table, it is sometimes desirable to share table 
entries between processes. Thus a single table, large enough to supply separate areas to processes that 
desire independence, yet shared by all processes, is an appropriate solution. 3. Architectural Solution 
 Our graphics subsystem is a part of a complete workstation whose host processor comprises multiple RISC-based 
CPUs. The CPUs and the graphics interface share a high-speed 64-bit synchronous bus of proprietary design. 
While the primary design goal of the bus was multiproeessor support, it includes special support for 
data transfer to the graphics subsystem. The graphics system itseff is partitioned into four pipelined 
subsystems. In order of data flow these are: 1. Geometry subsystem. Supports all floating-point operations. 
Transforms data from object-space coordinates to screen-space coordinates. 2. Scan conversion subsystem. 
Interprets screen-space coordinate vertexes as points, lines, and polygons, and generates appropriate 
fill instructions. Interpolates color and depth data across lines and polygons. 3. Raster subsystem. 
Maintains a 1280 by 1024 frame buffer of 96-bit pixels. Executes pixel algorithms such as replace, depth 
conditional replace (Z-buffer), and blend.  4. Display subsystem. Continually scans the frame buffer 
to supply video data to the monitor. Each pixel is interpreted individually as a function of the window 
to which it belongs. Each of these four subsystems, as well as the host interface, is described in detail 
below. 3.1 Data Transfer As we have seen, the graphics subsystem consumes data at roughly 10 Mbytes per 
second. The 64 Mbyte per second synchronous bus that connects the host processors to the graphics subsystem 
is able to handle this load. Thus large blocks of geometric data can be transferred across this bus to 
the graphics subsystem. Such transfers, however, are not consistent with the programming model desired 
for the machine. The target graphics library includes commands such as vertex(x,y,z) and normat(nx,ny,nz). 
Each command is implemented as a subroutine in the language of the calling application program. Each 
specifies data from an arbitrary structure. Graphics programs using commands such as these can operate 
directly from application data bases. Programs need not be 'compiled' into display lists, and therefore 
can traverse data under complete application control. Finally, because all traversal code and data reside 
in main memory, there is essentially no limit to the size of either. We seek a solution that retains 
the desired properties of immediate-mode graphics, and supports extremely high-performance graphics. 
Our answer is to create new commands that operate on 2, 3, and 4-component vectors, rather than on scalar 
values. Thus vertex(x,y,z) becomes vertex(xyz), where xyz is the address of three adjacent floating-point 
values. Hardware support allows each host processor to make a single memory reference when dealing with 
such a vector. The memory and synchronous bus deliver the data to the graphics subsystem in a single 
burst, making optimum use of the available bus bandwidth. Vectors that straddle page boundaries are detected 
and handled automatically. By providing support for program controlled data transfer to the graphics 
subsystem at rates far in excess of 10 Mbytes per second, we allow for both future increases in graphics 
performance, and for desirable inefficiencies in program execution. One such inefficiency is shared graphics 
libraries. While such libraries exact a performance penalty at each call, they greatly reduce code size, 
both on disk and in memory, and also support object code compatibility between machines with different 
graphics subsystems.  3.2 Geometry Subsystem The geometry subsystem comprises a single conversion and 
FIFO module, followed by 5 identical floating-point processors (Geometry Engines®). These 6 processors 
are organized as a single pipeline. Each executes a specific subset of the rendering algorithm, minimizing 
microcode space requirements. 3.2.1 Conversion and FIFO Module This module accepts coordinate data in 
4 formats: 16-bit integer, 24-bit integer, 32-bit IEEE floating-point, and 64-bit IEEE double precision 
floating-peint. Color data are accepted as packed integers as well as in the coordinate formats. All 
data are converted to 32-bit IEEE floating-point format for consumption by the Geometry Engines. Hardware 
format conversion supports direct transfer of data from user structures to the graphics subsystem without 
performance penalty. A 512-word FIFO precedes the conversion module. The hardware interrupts when a high 
water mark is passed, allowing user programs to transfer data to the graphics subsystem without concern 
for flow control. On interrupt, the operating system blocks the user program until the FIFO empties past 
a low water mark. Thus transfer rate is adversely affected by flow control protocol only when it has 
already exceeded the ability of the graphics system to accept data. 3.2.2 Geometry Engine Each of the 
five Geometry Engines is an identical module capable of 20 million single-precision floating-point operations 
per second (Mflops). Each includes separate high-speed microcode and data memories. The engines accept 
and output commands accompanied by up to 4 data words. Command interpretation is accomplished by program 
jump, followed by normal program counter operations. Hardware support in each engine includes:  ~  
 Flow control. Microcode ignores the issues of command availability, and of the subsequent engine's ability 
to accept commands. Hardware blocking is provided for both cases. FIFO input buffer. Each engine includes 
4 command buffers at its input. Buffers store up to 4 data words and a command address.  Pipeline support. 
Although the Geometry Engine has 6 internal pipeline stages, individual microcode instructions specify 
complete operations, including data sources, operations to be performed, and data destinations.  Concurrent 
command execution. The flow control and branch hardware support concurrent command (as well as insu'uction) 
execution.  The above, taken together, allow each engine to operate efficiently. The pipeline sustains 
the required 40-50 Mflops floating-point rate with 5 modules whose aggregate peak rate is 100 Mflops, 
an efficiency approaching 50 percent. This efficiency is not achieved in more general purpose vector 
processors, especially when the vectors are of 3 to 4 element length. Graphics tasks are distributed 
among the 5 Geometry Engines as follows: 1. Matrix and normal transformation. Matrix and normal stacks. 
Normal normalization. 2. Lighting calculations. 3. Clip testing. 4. Perspective division. Clipping 
(when required).  5. Viewport transformation. Color clamping to a maximum value. Depthcue calculations. 
 3.3 Scan Conversion Subsystem Screen coordinates sent from the geometry subsystem to the Scan Conversion 
Subsystem specify the vertexes of points, lines, and polygons. The Scan Conversion Subsystem performs 
the calculations required to reduce vertex data to individual pixels. Each pixel is assigned an x, y, 
and z coordinate and an r, g. b, and ¢xcolor value. Color and z data are always interpolated linearly 
between vertexes and between the edges of polygons. The task of scan-converting polygons is partitioned 
into three separate processors within the Scan Conversion Subsystem. The first two of these processors, 
the Polygon and Edge processors, use a pseudo floating-point representation to maintain coordinate integrity 
when calculating slopes. In addition, the y coordinates of polygon edges are computed to 1/8 pixel tolerance. 
All depth and color component iterations are first corrected to the nearest pixel center, then iterated 
in full-pixel steps. As a result, iterated color and depth values remain planar across polygonal surfaces, 
and subsequent Z-buffer calculations result in clean intersections. Vertex data are not passed directly 
from the geometry subsystem to the Scan Conversion Subsystem, but rather are accumulated in one of two 
256-vertex buffers. Vertex representations in this buffer are always the same, regardless of the operating 
mode of the system. Hardware on both the Geometry and Scan sides of the buffer is optimized to operate 
on these vertexes. Thus, the Polygon Processor receives entire polygons, rather than individual vertexes. 
It operates on vertexes directly from this buffer, avoiding unnecessary copying and interpretation. The 
Polygon Processor both sorts vertexes from left to right and checks for convexity in one simple, pipelined 
operation. The sorted vertexes are decomposed into trapezoids. Slopes of y, z, r, g, b, and ct are computed 
relative to delta x. Coordinates and slopes for each edge are passed to the Edge Processor. Trapezoid 
edges are handles at the rate of 1 per microsecond. The Edge Processor iterates along the top and bottom 
edges of the trapezoid, generating at each iteration the top and bottom coordinates of a single span.~ 
Spans are always iterated bottom to top. Therefore hardware 2. We refer to vertical lines of pixels as 
spans, horizontal lines as scans.   ComputerGraphics,Volume22, Number4, August1988 SCAN CONVERSION 
SUBSYSTEM :ii:i:::::::::::::::::::::::::::::::::::::::::::::::::::::::: :ii::i :16::::i::::::i:~?:~i~!i:~::i:ili 
!iG':::::i:::::: :::::::::::::::::::::::::::::::::::::::::::::::::::::::..... :::~:,Polyg on :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: 
::::::::::::::::::::::::::::::::::::;~;::::;::::::i~:::~:~!,F:::::::::i ~::~i::::::i ;::i::.i~;::::::::i~i: 
i::i:!:: ::~ i!::::~!::::::::: :::: ::::::~:.:::!:: i:.i::iisi~i~ i:i:::i:~!::i:~!:!i i: : :::~:is~opo 
::::i::i::i::iiii iii~,~,tW~:il;il :::::::::::::::::::::::::ii~:i:,iiiiii!t ~2~:~Ii)))iiii:::~:::::i~::::~:,i::i 
)::iiii::::i::::i:,iii~i~::ii~;: l::,::!::calculators :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::i~:~!~::`~.~:i::iii~!!:!iii!::il 
~::::-:~ [:::(Y Z,R G,B A) :::~::::~h:ii:ii::~iiii:iiiiiiiii[i~!!!ij!i~;~E~:i~iiii£iiiiiiiiiiiii~iiiiiiiiiiiiiiii 
!!!!ii1 ii~i~:!!!i!!!i!!!i!!E!~iE~ ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: 
  FIGURE2 is provided to swap span ends as necessary, both avoiding a complex test at trapezoid decomposition 
time, and correctly handling bow-tie polygons, which occur frequently at surface silhouettes. The color, 
y, and z edge components comprise 2 vectors which are iterated in parallel by multiple, proprietary engines. 
Spans are generated at the rate of 2 per microsecond. The y components of span endpoints are computed 
to 1/8 pixel accuracy. Color and depth slopes are computed using delta y to this accuracy. This slope 
is then used to iterate to the nearest pixel center. The final span definition comprises the corrected 
initial color and depth values, the color and depth slopes, the integer x and y values of the bottom 
pixel, and the span length. The Edge Processor delivers each span to one of five Span Processors. Each 
Span Processor manages every fifth column of pixels in the frame buffer. Since spans generated from a 
single polygon are always adjacent, the span processing load is evenly distributed across the five Span 
Processors. Each Span Processor iterates through its span using the initial and slope values provided, 
treating color and z span components as a vector. Pixel specifications are generated at the rate of 8 
per microsecond. Thus the aggregate fill rate of the 5 Span Processors is 40 million pixels per second 
(Z-buffered). 3.4 Raster Subsystem The Raster Subsystem contains 20 Image Engines TM, each of which 
is an independent state machine that controls 1,r20th of the frame buffer memory. Groups of 4 Image Engines 
are driven by each Span Processor. The array of Image Engines tiles the frame buffer in a 5-wide, 4-high, 
pattern. Bitplane memory is organized into 5 banks, comprising a total of 96 bits per pixel. The banks 
are arranged as follows: Image banks. Two banks of 32 bits each, organized as 8 bits each of red, green, 
blue, and alpha data.   ~)~ Computer Graphics, Volume 22, Number 4, August 1988 | milliseconds. Thus 
full screen animations running at 10 Hz lose only 8% of their draw time to screen clear. Even 30 Hz animations 
lose only 25% of their draw time. Pixel access. An important ancillary function of 3D graphics is high- 
speed host access to the frame buffer. This is useful for image display and storage, image convolution, 
paint programs, and many other applications. The new raster architecture supports host read and write 
rates of 5 million pixels per second. 5. Special Features Our design goal achieved, let us now consider 
some other features of the new graphics architecture. 5.1 Pan and Zoom Typical raster systems handle 
pan and zoom as a display process by altering the fetching of data for the monitor. Frame buffer scan 
lines are output multiple times to achieve vertical zoom, and are output at reduced rates to achieve 
horizontal zoom. Initial pixel addresses are altered to achieve horizontal and vertical pan. In all eases 
the video data rate is either reduced or unaffected. Thus, while the implementation is complex, it makes 
no performance demands on the hardware. This typical pan and zoom implementation, however, has some undesirable 
properties: It either operates on the entire screen, which is unacceptable in a window environment, 
or it becomes unmanageably complex.  The effort and cost expended solving pan and zoom in this manner 
do not contribute to the machine in any other way.  The second point is of particular interest. We prefer 
solutions that have a synergistic effect on the performance of the entire machine. Recall the bus that 
connects the Edge Processor to the five Span Processors. This pixeibus transmits span definitions during 
polygon fill, but is also designed to support pixel transfers during line fill. (The Edge Processor fills 
lines as though each was a single trapezoid edge, generating pixels at the rate of 8 (Z-buffered) or 
16 million per second.) The addition of a small pixel cache on the pixelbus allows pixels to be read 
and written in blocks large enough to achieve performance roughly equal to the peak pixelbus rates: Operation 
Mpixel/sec read 5.3 write 16.0 Because write cycles greatly outnumber read cycles when the zoom factor 
is large, fill rates approach the higher write rate as the zoom factor is increased. The fill rates for 
a variety of zoom factors are: Zoom Factor Mpixel/sec 1 4.0 2 9.1 3 12.0 4 13.5 8 15.3  With this 
performance it is possible to zoom 1/4 of the screen by a factor of 2 at the rate of 7 frames per second. 
Smaller areas, common in window- capable systems, easily zoom at 30 frames per second. Because the effects 
of pan and zoom are limited to a single window, or to multiple windows with independent factors if desired, 
the full screen with all its windows remains a useful resource. High-speed pixel copy leverages pixelbus 
th.oughput, which was also required for line drawing. By emphasizing high-speed pixel read and write, 
we improve the performance of transfers between host memory and the frame buffer, and also support real-time 
video input. 5.2 Window ID Masking Each pixel in the frame buffer includes a 4-bit ID field that is 
unique to the process that controls that pixel. Previous architectures [9] have used this per-pixel window 
ID field to control interpretation of pixel contents at display time. 4 Such an ID, read out and interpreted 
as a part of the display process, easily supports independent buffer mode specification on a per- pixel 
basis. Windows can independently select single or double buffer operation, and double buffer windows 
can swap buffers independently. Colorindex or RGB operation is also selected independently on a per-window 
basis. Thus, while the notion of a pixel ID is not new, its use as a drawing mask is. The new graphics 
hardware includes pipelined hardware that tests the ID of each pixel against the ID of the current drawing 
process. If the test fails, the draw operation is aborted with no change to the frame buffer contents. 
Otherwise, the drawing operation is completed in the currently specified manner. Because the compare 
operation is truly pipelined, there are no drawing order requirements imposed by the test. All drawing 
operations to the frame buffer, including lines, are ID masked with no performance penalty. 5 ID masking 
supports both partially obscured windows and non-rectangular windows (such as round clocks or templates) 
in a simple and consistent manner. It imposes no constrainm on window size or shape, and never results 
in loss of performance.  5.3 Realtime Video The new graphics architecture is capable of capturing both 
NTSC and PAL images in real time. These images are transferred to an arbitrary window on the screen via 
the pixelbus at the rate of 16 million pixels per second. Once in the frame buffer, they can be operated 
on just like images from any other source. Frame grab rate is controlled by the drawing program, allowing 
the simple program loop: while (TRUE) grab a frame modify the image swap buffers to operate as expected. 
Multiple buffers within the grabbing hardware insure that no frames are missed as long as the sum of 
the grab a frame period and the modify the image period does not exceed 1/30 of a second. The resulting 
NTSC or PAL image can be output in the same video format, allowing the hardware to act as a realtime 
video filter. Genlock and the alpha channel output allow additional video sources to be merged in a useful 
manner. 5.4 Alpha Blending Each of the twenty Image Engines includes both ALU and microeode support 
for an alpha blending algorithm. This blending algorithm, used while operating in RGB mode, causes the 
destination pixel values to be a linear combination of the previous destination values and the new source 
values. Cun = F,z, Ca, t + F~C,,~ F ~ O, 1, alpha, 1-alpha, C~rc, 1-Csrc, fdn, 1-Gun The algorithm operates 
identically on red, green, blue, and alpha color components, each of which is stored as an 8-bit value 
in the frame buffer. Algorithm options are specified in table format. All of the operations described 
by Porter and Duff [8], as well as others, are available. The frame buffer provides complete support 
for image eompositing, including output of the alpha channel for external image merging. In addition, 
such a blending function at the tail end of a geometric graphics system provides capabilities well beyond 
traditional image compositing. Specifically, because blending is supported in conjunction with Z-buffer 
operation, geometrically specified solids can be blended to simulate the effects of transparency. With 
some attention to the order in which image components are specified, useful engineering images earl be 
created.  5.5 Antialiased Lines While the problem of realtime antialiasing of geometric images (us discussed 
by Crow [41) has yet to be solved by a workstation, it has become possible to solve limited subsets of 
this problem. Our specific 4. Silicon Graphics has applied for patent protection for this technology. 
 5. SiliconGraphicsha.rappliedforpatentprotectionforthistechnology.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378517</article_id>
		<sort_key>247</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Virtual graphics]]></title>
		<page_from>247</page_from>
		<page_to>253</page_to>
		<doi_number>10.1145/54852.378517</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378517</url>
		<abstract>
			<par><![CDATA[Graphics can be implemented as a virtual system resource. This abstraction appears to each application on a multiprocessing workstation as a dedicated rendering and display pipeline. A variety of simple mechanisms support the simultaneous display of different types of images and eliminate the need for low-level device driver software. They permit applications to embed graphics instructions directly in their code. The abstraction allows for cleaner software design, higher performance, and effective concurrent use of the display by several applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P70030</person_id>
				<author_profile_id><![CDATA[81100490984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Douglas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Voorhies]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Computer Inc., 330 Billerica Road, Chelmsford, Mass.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14068580</person_id>
				<author_profile_id><![CDATA[81100166914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kirk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Computer Inc., 330 Billerica Road, Chelmsford, Mass.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P211774</person_id>
				<author_profile_id><![CDATA[81100270194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Olin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lathrop]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Apollo Computer Inc., 330 Billerica Road, Chelmsford, Mass.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>16306</ref_obj_id>
				<ref_obj_pid>16304</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Asal, M., Short, G., Preston, T., Simpson, R., Roskell, D., and Guttag, K., "The Texas Instruments 34010 Graphics System Processor", IEEE Computer Graphics and Applications, Vol. 6, No. 10, October 1986, pp. 24-39]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barton, R. S., "A New Approach to Functional Design of a Digital Computer", Proc. AFIPS Western Joint Comp. Conf., 1961, Vol. 19, pp. 393-396.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Buzen, J. P. and Gagliardi, U. O., "The Evolution of Virtual Machine Architecture", Proc. of AFIPS, NCC 1973]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13039</ref_obj_id>
				<ref_obj_pid>13036</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, E. S., Smith, E. T., and Iverson, L. A., "Constraint-based Tiled Windows", IEEE Computer Graphics and Applications, Vol. 6, No. 5, May 1986, pp. 35-45.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13055</ref_obj_id>
				<ref_obj_pid>13050</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[England, N., "A Graphics System Architecture for Interactive Application-Specific Display Functions", IEEE Computer Graphics and Applications, Vol. 6, No. 1, January 1986, pp. 60-70.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6684</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Foley, J. and van Dam, A., Fundamentals of Interactive Computer Graphics, Addison-Wesley, Reading, Mass., 1982]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13053</ref_obj_id>
				<ref_obj_pid>13050</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Guttag, K., Van Aken, J., and Asal, M., "Requirements for a VLSI Graphics Processor", IEEE Computer Graphics and Applications, Vol. 6, No. 1, January 1986, pp. 32-47.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30310</ref_obj_id>
				<ref_obj_pid>30300</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ilgen, S. and Scherson, I. D., "Real Time Virtual Window Management for Bit Mapped Raster Graphics", Proc. 5th International Conf. on Computer Graphics in Japan, Springer-Verlag, Tokyo, 1987, pp. 145-158.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kiiburn, T., Edwards, D. B. G., Lanigan, M. J., and Sumner, F. H., "One-level Storage System", IRE Trans. on Electronic Computers, Vol EC-11, No. 2, pp. 223-235.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>24922</ref_obj_id>
				<ref_obj_pid>24919</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lantz, K. A., Tanner, P. P., Binding, C., Huang, K., and Dwelly, A., "Reference Models, Window Systems, and Concurrency", Computer Graphics, Vol. 21, No. 2, April 1987, pp. 87-97.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Meyer, R. A. and Seawright, L. H., "A Virtual Machine Timesharing System", IBM Sys. Journal, Vol. 9, No. 3, 1970]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Newman, W. M. and Sproull, R. F., Principles of Interactive Computer Graphics, 2nd ed., McGraw-Hill, New York, 1979, pp. 262-265.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pinkham, R., Novak, M., and Guttag, K., "Video RAM Excels at Fast Graphics", Electronic Design, Vol. 31, No. 17, Aug. 18, 1983, pp. 161-182]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>24053</ref_obj_id>
				<ref_obj_pid>22949</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Scheifler, R. W. and Gettys, J., "The X-Window System", ACM Trans. on Graphics, Vol. 5, No. 2, April 1986, pp. 79-109]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16308</ref_obj_id>
				<ref_obj_pid>16304</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Shires, G., "A New VLSI Graphics Coprocessor - The Intel 82786", IEEE Computer Graphics and Applications, Vol. 6, No. 10, October 1986, pp. 49-55.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sproull, R. F. and Sutherland, I. E., "A Clipping Divider", Fall Joint Computer Conf. 1968, Thompson Books, Wash. D.C., pp. 765-775.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Virtual Graphics Douglas Voorhies, David Kirk, 
Olin Lathrop Apollo Computer Inc. 330 Billerica Road Chelmsford, Mass. 01824 ABSTRACT Graphics can 
be implemented as a virtual system resource. This abstraction appears to each application on a multiproeessing 
workstation as a dedicated rendering and display pipeline. A variety of simple mechanisms support the 
simultaneous display of different types of images and eliminate the need for low-level device driver 
software. They permit applications to embed graphics instructions directly in their code. The abstraction 
allows for cleaner software design, higher performance, and effective concurrent use of the display by 
several applications. INTRODUCTION There is a conflict between the multiple-process orientation of workstations 
and the single-task orientation of graphics hardware. Timeslieed CPUs with virtual memory support many 
concurrent processes [2,9], and increasingly, those processes demand fast, sophisticated graphics for 
high interactivity and for complex data visualization. Moreover, windowing systems are raising the users' 
expectations for concurrency [10]. Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. 01988 ACM-0-89791-275-6/88/008/0247 $00.75 Previously, graphics hardware has not 
been structured to match this environment. (See Figure 1). Usually it is coupled to the CPU by an ad-hoc 
protocol. Although current graphics hardware connects to a high-bandwidth internal bus, its interface 
still presents the old paradigm of a dedicated graphics display serving one application from the far 
end of a communications line [5]. Despite the graphics hardware holding considerable per-process drawing 
state information, there is rarely any state management design discipline or effective swapping mechanism 
present [7]. Consequently, layers of graphics systems software are needed to manage access and context. 
Additional low-level software complexity arises from the need to throttle the CPU's request rate so as 
not to exceed the graphics hardware's input capacity. Finally, a single screen-wide display mode such 
as a color lookup table or pixel format satisfies only one class of applications at a time. Thus, the 
single-task orientation of graphics hardware has left the recta-rendering problem of updating and displaying 
multiple images unaddressed. CPU/graphics interfaces are ad-hoc because they fall between two cultures. 
To the CPU and OS, graphics is a peripheral, and to graphics, the CPU and memory are a command source. 
Ad-hoc I/O interfaces are usually "dressed up" by intervening software for elegance and for device independence. 
While device independence is a requirement in many cases, applications are increasingly seeking the maximum 
performance from expensive hardware. For them, the intervening software is an obstacle. As we have learned, 
with more careful integration, this software can be eliminated. In this paper we develop an approach 
which makes current user-interface and graphics rendering technology (both hardware and software) more 
effective on a workstation. f SIGGRAPH '88, Atlanta, August 1-5, 1988 Typical Hardware Drawing Pipeline 
~___~ Drawing I Drawing ~ ,:::Buffering ::: engine I Bitmap I commands ~ " ~ I ~:~::~::~< I:: B  I/O 
status I i :ii...................... ~ii:ii = serving one class = single-threaded ii::;istate :::::~: 
 ~?,,;,i?:,,;,ii~.,;; of image at a time context Figuce 1 We offer an effective abstraction, "virtual 
graphics", which cleans up the ad-hoe hardware/software interface and tackles the problems of both time-slicing 
drawing hardware and simultaneously displaying varied images. "VIRTUAL GRAPHICS" By "virtual graphics" 
we mean every application has the illusion of owning a dedicated rendering co-processor. Each screen 
window is independently displayed. Applications need not deal with sharing access, switching contexts, 
modulating eomrnand flows, I/O status checking, screen-wide pixel formats, or sharing color lookup tables. 
 "Virtual" means that implementation details are hidden beneath an abstract interface, allowing higher 
levels to be simpler [3]. Virtual graphics hides the single-threaded nature of the rendering and display 
hardware. Because the interface is simplified, multiple threads of graphics rendering can be handled 
efficiently. Since each applications' windows are updated more smoothly, the benefits extend to the user 
as well. Although windowing systems, such as X-windows [14] or Apollo's Display Manager, have already 
begun to address the screen allocation problem, they do so by making window shape and size variable at 
display time. This, in turn, places demands on the drawing and display hardware to support window-oriented 
update and display. To create the appearance of a dedicated resource to multiple requestors, the hardware 
must either have sufficient parallelism to actually perform all work simultaneously, or be able to rapidly 
switch between tasks. The success of both CPU timesharing and the virtual  memory page sharing have 
proven rapid switching of an expensive resource to be effective [11]. Since CPUs and high-end graphics 
hardware cost roughly the same, concurrency through rapid switching is the most practical solution. The 
key to managing state is to switch low-level contexts rapidly. It is very difficult to emulate fast task 
switching at a high abstraction level if lower levels cannot exchange their state quickly. Useful techniques 
include the simple switching of the context (by moving a pointer) or the complete swapping of the context 
(by a saving and restoring copy). IMPLEMENTATION At Apollo we have implemented a high-end graphics system 
for the DN10000. It offers virtual graphics by combining six simple mechanisms (see Figure 2): 1. The 
integration of graphics via a co-processor interface 2. The exception-based detection of graphics ownership 
violations 3. The efficient swapping of drawing context 4. The exception-based management of command 
flow rate 5. The clipping of drawing to window boundaries 6. The switching of pixel formats and lookup 
tables per pixel  These mechanisms are not very powerful separately, but together they remove the barriers 
between the applications and the graphics hardware. Applications become unaware Virtual mem .ory mapping 
  Application f ~ software-~.~,]instructions ~ ~ ~ Computer Graphics, Volume 22, Number 4, August 
1988 I  "Virtual Graphics" Drawing Pipeline Drawing format Multiple engine multi-Color Buffering with 
Bitmap plexing Lookup window per Tables < I clipping Blocking | interrupts T tObuffer Rapidly avoid 
 ova,,ow swappable I I drawing Per-window display attributes state Figure 2 that they are sharing the 
hardware device, or its drawing context, or the screen. Co-processor Interface The graphics hardware 
is mapped into the application's memory space. Memory-mapping allows control to be cleanly presented 
in higher-level languages. It permits the application to use Store instructions to set all drawing parameters 
and initiate all drawing operations. Drawing is simply done by initializing all relevant parameters and 
then requesting an operation. Graphics is a co-processor since the Store subsumes both an 8-bit graphics 
opcode and 32-bit data operand in its address and data. The parameters and operations are selected by 
8 low address bits, and the data is the 32-bit operand. By packing all the commands into one page, the 
cost of setting up the mapping is minimized. Exception-based detection of graphics ownership vio- lations 
State ownership and graphics access are built upon virtual memory access management mechanisms. Both 
the graphics drawing commands and the bitmap itself are mapped into the physical memory space. By allowing 
only one requesting process at a time to map the graphics com- mandpage, access to the graphics becomes 
single-threaded. Even in a shared-memory and multiple CPU system, access remains exclusive. Whenever 
the graphics command page is mapped, that process's context is pre- sumed to be active in the drawing 
hardware. The fault handler grants access to processes following a "fairness" policy. A graphics access 
fault differs from page faults in that the requesting process does not necessarily get access as soon 
as possible. The access policy software permits only one requesting process to "own" the graphics; the 
others wait their turn. In this respect it resembles the "fair" allocation of CPU timeslices to processes. 
The bitmap may also be mapped into the process's virtual address space. In order to insure a consistent 
view of the bitmap by both direct reads and writes as well as by the drawing hardware, an interlock is 
needed. Here again, virtual memory mapping can detect both direct bitmap access as well as command page 
access. Only one or the other is mapped at a time. Execution of a direct bitmap read/write is delayed 
until all drawing has completed, and a request for drawing is assumed to signal the end of direct bitmap 
access. Fast drawing context swapping In hardware Drawing context can be swapped quickly by a VLSI state 
machine within the graphics hardware. In our implemen- tation, the state is large because this rendering 
hardware is highly parallel and strives for unusually high image qual- ity. The per-process drawing state 
is kept in 144 hardware registers (576 bytes) during use. When swapping, the live state (524 bytes) is 
exchanged with a copy in a local f, SIGGRAPH '88, Atlanta, August 1-5, 1988 graphics context RAM. The 
remaining per-process state (52 bytes) stays in that RAM while in use, and so may be switched by updating 
a reference pointer. This local RAM has space for six graphics contexts, including the active one; these 
copies function as a cache over additional ones in main memory. The state machine can perform a swap 
to and from the local RAM in 16 ~sec., which is less time than a CPU process swap takes. Those occasional 
swaps involving a context not in the local RAM are handled by CPU copying to and from the main memory 
contexts, and take under 200 ILtsec.. Since all drawing commands atomically update the drawing engine 
state, swaps are legal between any commands, Drawing commands are never interrupted or aborted, since 
some (such as RASTER-OP [12]) may not be idempotent or may use temporary storage in mid-execution. Swaps 
are initiated by issuing SAVE and RESTORE commands between the drawing commands of one process and the 
next. The fault handler inserts these commands between the commands of the old and new owning processes. 
Exception-based command flow control Flow control can best be handled by an exception mecha- nism. Usually, 
graphics hardware handles requests faster than a CPU can generate them, but whenever this is un- true, 
the CPU must wait until the graphics hardware has caught up. In our implementation, a command FIFO with 
512 entries buffers between the bursty request and execu- tion traffic. It permits a requesting CPU and 
the drawing hardware to proceed asynchronously. When a FIFO is nearly full, all further requests trigger 
interrupts [1], which force the requesting process to wait until the FIFO signals it has reached half 
full. (An interrupt is issued upon each request to insure the nearly-full condition is communicated successfully, 
since processes may migrate between CPUs at any time.) This throttling of the request- ing process is 
separate from the access mechanism, al-though it may be factored into the access policy decisions. Since 
the CPU is increasingly the bottleneck in graphics-based applications, it is advantageous to slow it 
down only in the exceptional ease of being limited by the graphics hardware. CPU busy-flag tests, "done" 
interrupts, and other hardware/software locks are eliminated by handling flow control transparently, 
streamlining and simplifying the co-processor interface. Window-boundary clipping during drawing Drawing 
into a window usually requires 2-D clipping to the window boundaries. This can be cumbersome, especially 
if the window is partially occluded [6,16]. The burden of screen clipping makes it more difficult for 
applications to fully participate in a shared screen, and slows down their rendering if they do;~ Since 
we added rectangle clip logic in hardware, drawing can simply ignore window bounda- ries, or only trivially 
reject primitives prior to drawing. In our implementation, every potential pixel write is compared with 
up to seven rectangles using 28 parallel X or Y comparators. These 28 rectangle coordinates are part 
of the per-process state swapped when changing drawing contexts. Two clipping tactics are supported. 
Simple windows are handled by one "clip outside" rectangle occluded by up to six "clip inside" rectangles. 
More complex windows are drawn in multiple passes, with each pass clipped to the union of seven "draw 
inside" rectangles. In both modes, the clip decision is made in parallel with address synthesis, and 
imposes no speed penalty. Pixel format switching per plxel Even if multiple windows can be drawn rapidly, 
having only a single pixel format or single color lookup table for the whole screen thwarts their concurrent 
display. For example, a page-layout system may wish to mix full-color photographs with false-color text. 
Another application may wish to alter the color lookup table to highlight part of its image. And a third 
may want to double.buffer a false-color CAD image. If they are to effectively share the screen, the video 
display mode must change on-the-fly at each window boundary. Switching the display hardware mode at pixei 
rates satisfies the requirement of most window managers to arbitrary window position, size, and complexity 
[15]. By appending each bitmap pixel with a 4-bit tag, the video logic obtains control information synchronously 
with the raw bitmap pixel data. Using this tag as an index into a 16-entry display attributes table expands 
the tag into its current display mode [17]. See Figure 3. This table ~ Computer Graphics, Volume 22, 
Number 4, August 1988 :iKii: ...... : "::::." ..... : : : Per-pixel Display Mode Implementation Bed 
 :: ::: :Video:RAM. .% _Green ::I536 x 1024 x:#8 -I ::i~16!:i#athS!ii:: [ "a Blue :ii . i ~:~,.::~:~::~:~ 
...... :~,::: .... ;:~ ~.i;ii::Dis lay!::::: ~i Mode i: :-:vlaeo:Ham ~ ..... : T ............ i  Upper 
LUT address bits ] ...... ~ able:: " :::: T I .-::.~:: 536:X~;!024;X4 ....... ~16:.x:::~::~: :::~:.:J 
 .............. :i:: ..... ii. ii :::): .... :i~i  Figure 3 lookup is analogous to the color lookup 
table for pixel data. Per-pixel display attributes in our implementation include: Color Lookup Table 
(LUT) selection (1 of 8)  Plane multiplexing mode: 8-bit false color . 10-bit false color 12-bit real 
color 24-bit real color Mixed false and real color Substitute a cursor color  Overlays on/off  Double 
buffer select  Typically, all pixels in a particular window are displayed in the same mode. The actual 
number of windows is not limited by the 16 display attributes table size, since several windows will 
often share the same attributes (e.g. text windows). Further, the limitation of 8 x 256 LUT entries is 
ameliorated by allocating color blocks smaller than 256 on demand, and by sharing LUT blocks (e.g. a 
shared real color Gamma function). BENEFITS Together, these six mechanisms and the regular graphics hardware 
appear to each application as a fast dedicated rendering and display pipeline. Applications are unaware 
of sharing the screen area, drawing context timeslicing, screen display mode cooperation, or flow control. 
Consequently, graphics is presented to applications as a clean and useful abstraction. The abstraction 
allows instructions embedded within an application to request drawing directly. Neither active coordination 
with other applications nor intervening layers of graphics system software are required. Moreover, this 
memory-mapped interface is easily used by high level languages. The most challenging part of virtual 
graphics is access management. We chose to base our implementation on virtual memory management, thus 
reducing it to an already-solved problem. Performance is improved by the reduction in both software layering 
and context management overhead. Indeed, there is no state-management overhead when there is only one 
active drawing process, and minimal overhead when there are six or less active processes. A more subtle 
performance gain is achieved through the asynchrony of the CPU and graphics executions allowed by the 
FIFO. Inserting swap requests in the drawing instruction sequence inherently synchronizes drawing context 
and operations. When a process gains access to the FIFO, it does not need to wait for its state to be 
swapped in. Drawing instructions can be issued immediately, even though they presume post-swap context, 
because they are preceeded in the FIFO by the swap request. Since the FIFO preserves the sequence, the 
swap will emerge from the FIFO and occur before these instructions emerge. This is possible because the 
graphics context is swapped synchronous with drawing and asynchronous from the CPU by a post-FIFO mechanism. 
SIGGRAPH '88, Atlanta, August 1-5, 1988 HARDER PROBLEMS Our six mechanisms do not address several more 
difficult graphics resource management limitations. Any sharing abstraction breaks down when its underlying 
resources have insufficient capacity or are too slow to multiplex their context. For example, thrashing 
occurs in a virtual memory system if there is insufficient physical memory. Also, software locks are 
needed for single-threaded peripherals such as tape drives. Similarly, virtual graphics, while effective 
for common rendering, cannot hide finite resources and cannot transparently share what it cannot swap. 
Screen space is the most visible finite resource. There is an obvious extension of virtual memory to 
virtual windows [8], which allows drawing to proceed oblivious to window occlusion, and allows a potentially 
larger bitmap. However, crossing discontiguous page boundaries is awkward, and gathering the scattered 
windows at video rates is either very expensive or requires a massive copy. Such copying cuts into drawing 
bandwidth, and may in turn cause jerky screen update. Moreover, a fixed-size video-RAM array offers much 
lower cost; and, because it can be tightly interconnected to a dedicated drawing engine, it can achieve 
higher potential performance. Off-screen images, such as image preparation areas, down-loaded fonts, 
texture maps, or tile patterns, represent a huge context which defies rapid swapping. Many bitmaps have 
some off-screen area where the drawing hardware can work at full speed, but it is expensive and must 
be allocated very carefully. Moreover, high-level software locks are often needed to single-thread access 
to large blocks of the limited space. Virtual graphics can do little to manage these large images. Similarly, 
color and display attribute lookup tables sizes are finite, and the number of entries needed for all 
the windows may ocassionally exceed what the hardware can support. In time, however, technology will 
push the limit beyond common user needs. Other features, such as per-window pan and zoom, remain particularly 
difficult to implement without copying pixels. High display rates and the horizontal shifting efficiency 
of video RAMs [13] limit flexibility in video back-end hardware. Fortunately, with improving redraw speeds, 
video panning and pixei-repli-eating zoom are becoming obsolete. Finally, with increasingly asynchronous 
CPU and drawing execution and with more automatic state management, software has less control. These 
features optimize output-only rendering while penalizing operations which require the CPU to know the 
state of the bitmap or drawing operation. For example, if an application wishes to read the bitmap, or 
be signaled at the end of a drawing operation, or ascertain the current interpolated colors, then the 
long pipeline must be drained and synchroniza-tion reestablished. Since most of such "upstream" communication 
is to support human input, the frequency is quite low. Response time, however, must remain adequate, 
and any forced re-synchronization conflicts with concurrent update. CONCLUSIONS The abstraction of virtual 
graphics elevates graphics to a first-class system resource. Its implementation pushes the multiplexing 
of control and .context from the device driver level down into the hardware. Hardware accelerates context 
swaps, FIFO full detection, and window clipping. By moving these mechanisms into the hardware, we eliminate 
a layer of software and achieve a significant reduction in multiplexing overhead. Faster multiplexing 
can quantitatively improve performance as well as qualitatively smooth the drawing of multiple windows. 
The software sees a dedicated graphics co-processor. Because the ad-hoc jumble of low-level driver software 
has been replaced, applications can simply access the hardware by embedding graphics instructions directly 
in their code. Additionally, several applications each retain a clean view despite simultaneously running 
on multiple processors. The user sees a screen supporting multiple images, each displayed properly and 
updated smoothly. Thus virtual graphics enhances the concurrency and effectiveness of modern workstations 
by addressing the meta-rendering problem of multiple image update. ~ Computer Graphics, Volume 22, Number 
4, August 1988 ACKNOWLEDGEMENTS We wish to thank Inwhan Choi, Robert Feidstein, Thomas Fincher, Jeffery 
Kurtze, Eliot Polk, and Robert Taylor for their insightful contributions and refinements during the implemention 
of this architecture. We also appreciate Dr. Terence Lindgren for his helpful observations in the presentation 
of these ideas. REFERENCES [1] Asal, M., Short, G., Preston, T., Simpson, R., Roskell, D., and Guttag, 
K., "The Texas Instruments 34010 Graphics System Processor", IEEE Computer Graph- ics and Applications, 
Vol. 6, No. 10, October 1986, pp. 24-39 [2] Barton, R. S., "A New Approach to Functional Design of a 
Digital Computer", Proc. AFIPS Western Joint Comp. Conf., 1961, Vol. 19, pp. 393-396. [3] Buzen, J. 
P. and Gagliardi, U. O., "The Evolution of Virtual Machine Architecture", Proc. of AFIPS, NCC 1973 [4] 
Cohen, E. S., Smith, E. T., and Iverson, L. A., "Con- straint-based Tiled Windows", IEEE Computer Graph- 
ics and Applications, Vol. 6, No. 5, May 1986, pp. 35-45. [5] England, N., "A Graphics System Architecture 
for In- teractive Application-Specific Display Functions", IEEE Computer Graphics and Applications, Vol. 
6, No. 1, January 1986, pp. 60-70. [6] Foley, J. and van Dam, A., Fundamentals of Interactive Computer 
Graphics, Addison-Wesley, Reading, Mass., 1982 [7] Guttag, K., Van Aken, J., and Asal, M., "Require-ments 
for a VLSI Graphics Processor", IEEE Com- puter Graphics and Applications, Vol. 6, No. 1, Janu- ary 1986, 
pp. 32-47. [8] Ilgen, S. and Scherson, I. D., "Real Time Virtual Win- dow Management for Bit Mapped Raster 
Graphics", Proc. 5th International Conf. on Computer Graphics in Japan, Springer-Verlag, Tokyo, 1987, 
pp. 145-158. [9] Kiiburn, T., Edwards, D. B. G., Lanigan, M. J., and Sumner, F. H., "One-level Storage 
System", IRE Trans. on Electronic Computers, Vol EC-11, No. 2, pp. 223-235. [10] Lantz, K. A., Tanner, 
P. P., Binding, C., Huang, K., and Dwelly, A., "Reference Models, Window Sys-tems, and Concurrency", 
Computer Graphics, Vol. 21, No. 2, April 1987, pp. 87-97. [11] Meyer, R. A. and Seawright, L. H., "A 
Virtual Ma- chine Timesharing System", IBM Sys. Journal, Vol. 9, No. 3, 1970 [12] Newman, W. M. and Sproull, 
R. F., Principles of Inter- active Computer Graphics, 2nd ed., McGraw-Hill, New York, 1979, pp. 262-265. 
[13] Pinkham, R., Novak, M., and Guttag, K., "Video RAM Excels at Fast Graphics", Electronic Design, 
Vol. 31, No. 17, Aug. 18, 1983, pp. 161-182 [1.4] Scheifler, R. W. and Gettys, J., "The X-Window Sys- 
tem", ACM Trans. on Graphics, Vol. 5, No. 2, April 1986, pp. 79-109 [15] Shires, G., "A New VLSI Graphics 
Coprocessor --The Intel 82786", IEEE Computer Graphics and Appli- cations, Vol. 6, No. 10, October 1986, 
pp. 49-55. [16] Sproull, R. F. and Sutherland, I. E., "A Clipping Di- vider", Fall Joint Computer Conf. 
1968, Thompson Books, Wash. D.C., pp. 765-775.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378518</article_id>
		<sort_key>255</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[A display system for the Stellar graphics supercomputer model GS1000]]></title>
		<page_from>255</page_from>
		<page_to>262</page_to>
		<doi_number>10.1145/54852.378518</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378518</url>
		<abstract>
			<par><![CDATA[This paper describes a high performance display system that has been incorporated into the overall architecture of the Stellar Graphics Supercomputer Model GS1000. The display system is tightly coupled to the CPU, memory system and vector processing unit of this supercomputer, and is capable of rendering 150,000 shaded triangles/sec, and 600,000 short vectors/sec. The goal of the architecture is to share hardware resources between the CPU and display system and achieve a high bandwidth connection between them. This coupling of the display system and the processor, the architecture of the rendering processor, and the two ASICs that are used to implement the rendering processor are described.In addition, the display system architecture is contrasted to other approaches to high performance graphics, and design trade-offs and possible extensions are described. The implementation of popular display algorithms on the architecture is discussed, and their performance specified. The reader is advised that Stellar Computer Inc. is seeking patent protection for work described in this paper.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>C.5.1</cat_node>
				<descriptor>Super (very large) computers</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10010940.10010971.10011120.10010541</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Software system structures->Distributed systems organizing principles->Grid computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010528.10010536</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Parallel architectures->Multicore architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010362</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Massively parallel and high-performance simulations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010522.10010525</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Serial architectures->Superscalar architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010537.10010541</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Distributed architectures->Grid computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334631</person_id>
				<author_profile_id><![CDATA[81100205988]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Apgar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stellar Computer Inc., 85 Wells Ave., Newton, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334630</person_id>
				<author_profile_id><![CDATA[81100066481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bret]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bersack]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stellar Computer Inc., 85 Wells Ave., Newton, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334573</person_id>
				<author_profile_id><![CDATA[81100414799]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Abraham]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mammen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stellar Computer Inc., 85 Wells Ave., Newton, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baskett, Forest, Tom Jermoluk, Doug Solomon. The 4D-MP Graphics Superworkstation: Computing + Graphics = 40 MIPS + 40 MFLOPS and 100,000 Lighted Polygons per Second. Digest of papers COMPCOM '88 (San Francisco, California, February 29 - March 4 1988) pp. 468-471]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15897</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bishop, Gary and David Weimer, Fast Phong Shading. Proceedings of SIGGRAPH'86 ( Dallas, Texas, August 18-22). In Computer Graphics 20, 4 (August 1986) pp. 103-106]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bresenham, Jack. Algorithm for Computer Control of Digital Plotter. IBM System Journal 4, 1 (1965)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carpenter, Loren. The A-buffer, an Antialiased Hidden Surface Method. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27). In Computer Graphics 18, 3 (July 1984) pp. 103-108]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801272</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Clark, Jim. The Geometry Engine: A VLSI Geometry System for Graphics. Proceedings of SIGGRAPH'82 (Boston, Massachusetts, July 26-30). In Computer Graphics 16, 3 (July 1982) pp. 127-133]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Clark, Jim. and M. Hannah. Distributed Processing in a High Performance Smart Image Memory. LAMBDA 4th Quarter, 1980. pp. 40-45]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13055</ref_obj_id>
				<ref_obj_pid>13050</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[England, Nick. A Graphics System Architecture for Interactive Application Specific Display Functions. IEEE Computer Graphics and Applications 6, 1 (January 1986)pp. 60-70]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry and John Poulton. Pixel-planes: A VLSI-Oriented Design for a Raster Graphics Engine. VLSI Design 2, 3 3rd quarter 1981, pp. 20-28.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fuchs, Henry, Jack Gotdfeather, Jeff Hulquist, Susan Spach, John Austin, Frederick Brooks, John Eyles, and John Poulton. Fast Spheres, Shadows, Textures , Transparencies, and Image Enhancements in Pixel-planes. Proceedings of SIGGRAPH'85 (San Francisco, California July 22-26). In Computer Graphics 19, 3 (July 1985)pp. 111-120]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15898</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goldfeather, Jack, Jeff Hulquist, and Henry Fuchs. Past Constructive Solid Geometry Display in the Pixel-Powers Graphics System. Proceedings of SIGGRAPH'86 (Dallas, Texas, August 18- 22). In Computer Graphics 20,4 (August 1986) pp. 107-116]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>30659</ref_obj_id>
				<ref_obj_pid>30657</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Goris, Andy, B. Fredrickson, H. Baeverstad Jr., "A Configurable Pixel Cache for Fast Image Generation", Computer Graphics and Applications, Vol. 7, No. 3]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gouraud, H. "Computer Display of Carved Surfaces" Dept. of Computer Seience, U. of Utah, UTEC-CSc-71-113, June 1971]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA["GRAPHICON 700 Specifications", A marketing specification sheet from General Electric Company, Silicon Systems Technology Department, P.O. Box 13049 Research Triangle Park, NC 27709]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808581</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Levinthal, Adam and Thomas Porter. Chap - A SIMD Graphics Processor. Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27). In Computer Graphics 18, 3 (July 1984) pp. 77-82]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[McCormick, Bruce,Thomas DeFanti, Maxine Brown editors. Visualization in Scientific Computing. Siggraph Computer Graphics newsletter 21, 5 (October 1987)]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Phong, Bui Tuong. Illumination for Computer Generated Pictures. Communications of the ACM18, 6 (June 1975) pp. 311- 317]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sporer Michael, Franklin Moss, and Craig Mathias. An Introduction to the Architecture of the Stellar Graphics Supercomputer. Digest of papers COMPCOM '88 (San Francisco, California, February 29 - March 4 1988) pp. 464-467]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15896</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Swanson, Roger and Larry Thayer. A Fast Shaded-Polygon Renderer. Proceedings of SIGGRAPH'86 ( Dallas, Texas, August 18- 22). In Computer Graphics 20, 4 (August 1986) pp. 95-101]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37426</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Torborg, John. A Parallel Processor Architecture for Graphics Arithmetic Operations. Proceedings Of SIGGRAPH'87 (Anaheim, California, July 27-31). In Computer Graphics 21, 4 (July 1987) pp. 197-204]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807402</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance. Casting Curved Shadows on Curved Surfaces. In Computer Graphics 12, 2 (1978) pp.270-274]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 A Display System for the StellarTM Graphics Supercomputer 
Model GS1000 "ru Brian Apgar, Bret Bersack, Abraham Mammen Stellar Computer Inc. 85 Wells Ave. Newton, 
MA 02159 Abstract This paper describes a high performance display system that has been incorporated into 
the overall architecture of the Stellar Graphics Supercomputer Model GS1000. The display system is tightly 
 coupled to the CPU, memory system and vector processing unit of this supercomputer, and is capable of 
rendering 150,000 shaded triangles/sec, and 600,000 short vectors/sec. The goal of the architecture is 
to share hardware resources between the CPU and display system and achieve a high bandwidth connection 
between them. This coupling of the display system and the processor, the architecture of the rendering 
processor, and the two ASIC~ that are used to implement the rendering processor are described. In addition, 
the display system architecture is contrasted to other approaches to high perfomaance graphics, and design 
trade-offs and possible extensions are described. The implementation of popular display algorithms on 
the architecture is discussed, and their performance specified. The reader is advised that Stellar Computer 
Inc. is seeking patent protection for work described in this paper. Introduction In the past decade, 
the use of supercomputers for the solution of large, complex scientific and engineering problems has 
become increasingly important. As the performance of supercomputers and the size of the problems studied 
on them has grown, the need for aids to human comprehension of the results and ways to 'steer' the solution 
process has increased. At the same time, computer graphics has become an important part of a wide range 
of technical applications including mechanical CAD, medicine, molecular modelling, and computational 
fluid dynamics. As the complexity of the problems under study in both supercomputing and graphics increases, 
it is clear that much can be gained by the integration of supercomputing and computer graphics technologies. 
This is the focus of the NSF initiative on Visualization in Scientific Computing (vise). [15] For use 
in such applications, a display system must be able to render a large number of objects at speeds that 
allow animations of time- varying phenomena. We believe this requires tens of thousands of polygons and 
hundreds of thousands of vectors rendered at interactive speeds: To maximize the information content 
of the created images, high quality rendering techniques are necessary. These include anti- aliasing, 
shading, light modeling, transparency, and texture mapping. Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM-0-89791-275~6/88/008/0255 
$00.75 Current Approaches to High Performance Graphics There are four areas that are important for the 
performance of a display system: the display interface, geometry computations, pixel computations, and 
the pixel memory system. Disnlav Interface In many current systems the display system is a specialized 
processor that is connected to a general purpose host computer over a network, parallel interface, or 
memory bus [13,14,18]. An application running on a host precessor is the souree for all the graphics 
commands; it sends them through the interface to the display processor. If this interface does not have 
sufficient bandwidth, it can limit the performance of the system. Some systems use a display list memory 
local in the display processor. This approach works well if the object description is not frequently 
modified. The object may be tumbled at high rates but cannot be extensively modified for each new frame. 
Geometry Comoutations The geometry computations include object coordinate transformation, clipping, lighting, 
and device coordinate scaling. Since the different steps of the geometry computations for a single primitive 
are largely independent and different primitives are commonly independent of one another, parallel techniques 
can be used to achieve the geometry processing speeds needed for high performance graphics. Two approaches 
are a pipeline structure and parallel processing of primitives [539]. The pipeline performs each of the 
steps if the geometry computation in different stages of a hardware structure; this causes the different 
steps of several primitives to be executed in parallel. To process entire primitives in parallel, the 
primitives are distributed to multiple independent geometry processors. As a result objects are not necessarily 
rendered in the same order that the commands for them were issued. In most cases this is of no concern, 
but some operations (such as changing the draw colors or light sources) require execution order to be 
maintained. This is done by tagging graphics commands with order dependence information. A1/of the processors 
must keep track of any commands requiring sequential execution. Pixel Cornputation Pixel computations 
consist of the scan conversion of the primitives and the computation of the color values and Z coordinates. 
Lines are efficiently scan converted using the Bresenham algorithm [3]. Tl{is algorithm is easily implemented 
in hardware that can produce a new pixel address every clock cycle. Variations of the algorithm can handle 
the shading of polygons. [18] The polygon setup, scan conversion of the polygon edges, and interpolation 
of color and Z values can be pipelined to achieve high performance. The algorithm can be implemented 
using a digital differential analyzer (DDA) that uses iterative addition, which works well if the object 
to be scan converted and the pixel computations are relatively simple. This is the case for linear color 
interpolation over a polygon. SIGGRAPH '88, Atlanta, August 1-5, 1988 Since the computations for a given 
pixel are independent of the computations for all other pixels (for most rendering algorithms) pixel 
parallelism may be used. This can easily be extended to a processor for each pixel, as in the Pixel-planes 
system.J8, 9] Objects are scan converted by evaluating functions for their boundaries, and only those 
pixels that are inside the boundaries are written. For simple polygons, the edges are defined by linear 
equations. For Gouraud shading of a flat polygon with Z-buffering, both the color values and Z coordinate 
are computed from linear functions. The power of this technique is that any bounding function can be 
used, limited only by the numeric capabilities of the pixel processors. Second order functions can be 
used to render conic sections, and this can be used for direct rendering of constructive solid geometry 
operations. [10] The system is controlled in a single instruction stream, multiple data s~eam (SIMD) 
fashion i.e., a single control word is supplied to all of the processors. Pixel Memory To supply the 
pixel memory bandwidth that is needed in high performance display systems, several approaches have been 
used. To get high pixel rates, frame buffers have been designed to access multiple pixels at a time. 
A frame buffer memory location that holds 16 pixels can be organized as 4x4 or 16xl tiles.[ 11] The scan 
conversion hardware can generate a single pixel at a time, as long as all the pixels are completed in 
the memory cycle time of the frame buffer. A pixel cache can be used to match the different speeds of 
the frame buffer memory and the scan converter. A frame buffer can be divided into separate banks that 
allow multiple accesses to occur simultaneously. Scan conversion hardware can be incorporated into each 
of the frame buffer memory banks so that scan conversion can also be done in parallel. One implementation 
organizes the frame buffer memory horizontally and vertically as a 5x4 array of banks.[ 1,6] Each bank 
holds every fifth horizontal pixel and every fourth vertical pixel and has its own dedicated scan conversion 
chip. This allows 20 pixels each in a different bank to be accessed and processed at the same time. If 
a processor is dedicated to each screen pixel, it is possible to incorporate the frame buffer memory 
storage in the processors. This is the approach used in the Pixel-planes system; it allows all of the 
pixels on the screen to be accessed and processed in parallel. Since the pixels are stored in the chips, 
the chips can also support the reading out of the pixels for video generation. Limitations In the systems 
discussed, specialized hardware was used in the display processor to achieve high performance for some 
applications. However, this specialized hardware may have fundamental limitations that make it less effective 
for a broad range of graphics functions. A pipelined geometry processor works well when the computations 
to be performed are simple and can be broken into a fixed set of stages. It is not well suited for computations 
that vary greatly in their complexity or involve many cases such as lighting computations. For the simple 
ease of Gouraud shading [t2] (diffuse lighting with a single directional ligh0 approximately 6 floating 
point operations per vertex are needed. In Stellar's implementation of Bishop Weimer Fast Phong Shading 
[2,16], a light local to the object with specular lighting requires more than 500 floating point operations 
per vertex. If a pipeline is optimized for the most common simple cases, the performance will drop suddenly 
for an occasional complex case, or worse: it cannot be supported at all. Pixel computation based on hardware 
implementations of DDA techniques are good for lines and smooth shading of polygons. The Pixel-planes 
technique of general purpose function evaluation is better suited for more complex objects such as spheres 
and CSG primitives. Operations requiring non-linear functions or multiplication at the pixel level, such 
as specular lighting models and texture mapping, cannot be easily implemented with DDA scan conversion 
methods. The use of dedicated frame buffer memory in a display processor can present several difficulties. 
For simple rendering operations, each pixel only needs storage for color values. To support pixel space 
functions, such as double buffering and Z-buffering, additional dedicated storage is needed at each pixel. 
Functions such as anti- aliasing, transparency, shadows, and depth sorting can be implemented by using 
additional storage at each pixel. If frame buffer memory is added to a system to support these functions, 
a significant cost is added to the system for a feature that may only be used occasionally. Further, 
hardware restrictions imposed by the display processor may prevent additional per-pixel storage for new 
algorithms and functions. Dedicated frame buffer memories are also designed to optimize accesses by the 
rendering hardware; host processor access to the plxels can be poor. Specialized application operations 
on pixels that are not supported by the display processor are inconvenient or impossible. Other researchers 
have recognized the restrictions of special purpose graphics architectures and have built machines using 
general purpose programmable processors. One approach connects frame buffer memory, display processors 
and graphics I/O devices to a shared high speed bus.[ 7] System Hardware and Functions The Stellar design 
goal was to tightly integrate a high performance display system with the CPU and vector processor of 
a supercomputer. We recognized that high memory bandwidth and floating point performance were both critical 
needs of vector processing and graphics. We designed a system that shared a single memory system and 
vector processor between the CPU, vector processor, and display system. This reduced the need for specialized 
hardware, and achieved a high bandwidth connection between the display system and the CPU and vector 
processor. The GS1000 system consists of several major sections that are shown in Figure 1. [17] Multi-Stream 
Processor and DataPath TM Architecture The Multi-Stream Processor is single uniform 25 MIPS processor 
that simultaneously executes instructions from 4 independent instruction "streams". The core of the machine 
is the DataPath. The DataPath acts as an interconnect path between all of the functional units, and supplies 
the register storage for the processor. Independent sets of registers for each stream are held within 
the Data Path. These include 32 integer registers, 8 scalar floating point registers, and 6 vector registers 
of 32 elements each. Both the memory system and the cache are connected to the Data Path by dedicated 
512-bit wide busses, and the Vector Floating point Processor (VFP) is connected by a 384-bit wide path. 
The Data Path also contains a pixel buffer, which consists of 8 pixef registers. Each pixel register 
holds 16 32-bit pixels. Associated with the pixet buffer is logic for horizontal alignment of pixels, 
raster ops, and a register for controlling these functions called the drawing state register. The CPU 
supports pixel load/store instructions that transfer pixels between the pixel registers and memory. They 
are used to support a wide variety of pixel graphics functions to arrays of pixels stored in virtual 
memory or the video memory. This includes 2D line drawing, polygon filling, and pixel block transfers 
(pix- BLTs) with raster operations. Pixels can be written at 160 Million pixels/second or copied at 60 
Million pixels/second. Memory System The memory system consists of a cache, Translation Look-aside Buffer 
(TLB), main memory, and video memory. It is designed to support the high memory bandwidth needs of the 
Multi-Stream Processor, the Vector Floating-point Processor and the Rendering Processor. The TLB holds 
16K entries mapping virtual to physical page addresses. The cache holds 1Mbyte and is shared between 
the four streams of the Multi-Stream Processor. Memory consists of two parts, Main memory and Video memory 
which share a 512-bit connection to the DataPath. Each main memory location holds 16 32-bit words that 
can be used for program and data storage, or can hold 16 pixels organized either as  ~' ~ Computer 
Graphics, Volume 22, Number 4, August 1988 Multi-Stream Processor Vector Floating Point Processor Rendering 
Processor IIII Main Data Path General-purpose registers Floating point registers Vector registers I Pixel 
registers I/0 registers Instruction buffers m[ I I/O Processors I (4) Peripheral busses I TLB 16K entries 
Cache 1Mbyte _ I Main Memory 16 -128 Mbytes Display Screen 1280x1024 ~#~iii~iiiii~iiii~ii~iii~i~i~i~i~i~.... 
Video Memory 16132 planes 1280x1024 System Block Diagram Figure 1 Setup Engine Isetup processor J Scratch 
Pad I 16Kx32 To Vector Floating Point Processor f 32  ',ii writeable DL~J J (1) SA ASIC control store 
t6Kx64  To Main Data Path Rendering Processor Figure 2  Address Engine , , .- _ J Address _erocessor 
I Address .rocessor ~"~A writeable = . ~ L control storei~ll-.iplO 16Kx64 J iI (1) SA ASIC i / I ~ Memory 
Address to CPU  A Foot Print Engine Foot Print WCS 16Kx64 D Foot Print Processor (16) 'TOE' ASICs D 
A Foot Print Processor Scratch Pad (4) 16Kx32  SIGGRAPH '88, Atlanta, August 1-5, 1988 4x4 blocks or 
16xl strokes. The video memory is organized as a 1280x1024 array of 32-bit pixels with each video memory 
location holding a 16xl stroke. Video memory is identical to main memory except that it is implemented 
with video rams, holds the screen image that is used for video ger~eration, and allows write enabling 
down to groups of 4 planes within a pixel. Both Main memory and Video memory support two types of memory 
cycles. The standard cycle reads or writes a single 512-bit memory location every 200ns. Pixel transfers 
to/from the pixel buffer may use an overlapped memory cycle that moves 1024-bits in 200ns. Virtual Pixel 
Maps TM Rendering Technique Pixels are stored as rectangular arrays in virtual memory called Virtual 
Pixel Maps (VPM), which are identified by a pixel map bit in the TLB. The CPU may access the pixels in 
a VPM with any general purpose load/store instruction or with the special pixel load/store instructions. 
The Rendering Processor performs all of its operations on VPMs. A VPM may be up to 216 x 216 pixels in 
size. Up to the 4Gbyte virtual address limit, any number of pixel maps may be defined and used. Multiple 
VPMs are used to support rendering operations that require more than 32 bits per pixel. For rendering 
operations the 4x4 format is used because it yields higher pixel efficiency for small graphics objects 
(more useful pixels per memory access). The Rendering Processor supports rendering with 12 plane pseudo- 
color and 24 plane true color. A single VPM is used for rendering in pseudo-color. The Z-buffer occupies 
16 bits of each pixel; the color value uses 12 bits, and 4 bits are unused. Two VPMs are used for true-color. 
The 24-bit color value and 8 unused bits occupy the first pixel map, and a 32-bit Z-buffer is held in 
the second. We are presently implementing rendering functions that use several VPMs to support anti-aliasing 
of solids, texture mapping, and transparency. Vector Floating Point Processor The Vector/Floating Point 
Processor (VFP) performs scalar and vector floating point operations for the entire machine. Operands 
are loaded from cache/memory to vector registers using VLOAD instructions, and results are stored with 
VSTORES. Vector registers are 'broad-side loaded' in 2 or 4 memory accesses, depending on the precision 
of the operand. They can hold single or double precision floating point values or 32-bit signed integers. 
Vectors are processed with register-to-register vector instructions. The VFP supports a general set of 
vector multiply, add, subtract, multiply-add, compress, mask, merge functions. In addition it supports 
vector instructions specialized to graphics geometry computations. These include instructions for coordinate 
transformation, clip checking, matrix concatenation, lighting dot products, square root approximation, 
and device coordinate conversion. Loads and stores of vector registers are overlapped with vector operations 
as long as there are no register conflicts. The VFP is pipelined to produce one floating add, multiply 
or multiply-add result every clock cycle for a peak throughput of 40 MFLOPS. Granhics Geometrvprocessin~ 
All the geometry computations are implemented by a software package written in C and assembly code that 
provides the graphics device interface for the machine. It is a high level device interface that is exported 
through the Xll Window System TM on our system. It is called the X Floating Point Device Interface (XFDI), 
and it supports a large number of graphics primitives, and controls their attributes. The primitives 
are: points, lines, line meshes, line polyhedral meshes, triangles, triangle meshes, triangle polyhedral 
meshes, and spheres. The XFDI performs coordinate transformation, clipping, lighting computations, and 
device coordinate conversion for all the primi.tives that it supports. All of the geometry computations 
are done in single precision floating point using the VFP. The XFDI can transform a 3D point in approximately 
800ns with the VFP operating at over 35 MFLOPS during the computations. In addition to the standard attributes 
for these primitives, the XFDI supports flat, Gouraud and Phong shading with diffuse and specular lighting. 
Up to 16 colored light sources are allowed, and they may be point or directional lights. For specular 
lighting, the viewer may either be at infinity or local to the object. Clipping can be done to the standard 
six clipping planes and to 16 arbitrary clipping planes (used to create cut-away views of complex objects. 
) Connection to the Renderin~ Processor The VFP supports three vector instructions for communicating 
with the Rendering processor. The send-to-renderer instruction transfers data (at a rate of 32 bits per 
clock cycle) from a vector register to the Setup Engine scratch pad memory. The XFDI uses this instruction 
to send argument and atttribute information for a group of primitives to the renderer. The arguments 
can include the X, Y, and Z coordinates of the vertices, the vertex color values computed from the light 
sources, and the coefficient values needed to compute the linear equations for the color and Z coordinates. 
The attributes can include the draw color, the definitions of the current pixel maps, and the light source 
intensities. The receive-from-renderer instruction, which is used primarily for diagnostics, transfers 
clam in the reverse direction. The execute-renderer instruction causes the Setup Engine to begin execution 
of the micro-code for the desired primitives. All three instructions are hardware interlocked so the 
VFP is prevented from proceeding if the Setup Engine is busy. Rendering Processor The Rendering Processor 
(RP) performs all of the per-pixel rendering computations in the system. It receives rendering commands 
and parameters from the vector unit, calculates individual pixel values, and writes the new values into 
pixel maps stored in virtual memory. The RP is shown in Figure 2. It consists of three independent engines 
that operate as a rendering pipeline: the Setup Engine, the Address Engine, and the Foot Print Engine. 
The Setup Engine performs initialization and preliminary computations on the primitives to be rendered 
and sends commands and data to the other engines. The Address Engine determines which 4x4 blocks of pixels 
are covered by a primitive, and sequentially "walks" the Foot Print Engine over those blocks while coordinating 
the virtual memory accesses. The blocks of pixels are transferred between memory and the pixel buffer, 
where they can be read or written by the Foot Print Engine. The Foot Print Engine evaluates the bounding 
functions for the primitive, computes the pixel values and Z coordinates, and performs the depth buffering 
comparison. Core Processor Functions The RP is implemented using two specially designed application- 
specific integrated circuits (ASICs). The Setup-Address (SA) ASIC is used once in the Setup Engine and 
once in the Address Engine. It contains over 40,000 used gates in a 299-pin package. The Toe ASIC is 
used 16 times to implement the footprint engine. It contains over 25,000 used gates in a 155-pin package. 
Both ASICs use scan-path techniques for testing and fault isolation. The SA and Toe ASICs each contain 
a micro-coded 32-bit integer processor whose core arithmetic features are shown in Figure 3. The processor 
ALU performs integer arithmetic, logical, and shifting operations on two 32-bit operands, generating 
a 32-bit result. The multiplier performs signed, unsigned, and mixed mode 16x16 integer multiplies to 
produce a 32-bit product. With the accumulator register, the multiplier and ALU can implement 16x32 and 
32x32 multiplication. The general register file is a 32-word by 32-bit triple-port memory. It provides 
operands to the other functional units and receives their results. The memory address register is used 
to access external scratch memories, and the input/output data registers are used to transfer data to 
these memories or the pixel buffer. Setup Processor Hardware In addition to the core functions, the SA 
ASIC has hardware for functions specific to the Setup Processor. This includes a micro- sequencer, the 
interface to the VFP, and an interface to the Address and Foot Print Engines.  ~ Computer Graphics, 
Volume 22, Number 4, August 1988 The instruction sequencer generates the micro-code execution address 
for the Setup Engine control store. A standard set of micro-code branch and subroutine call/return functions 
are provided. The interface to the VFP supports the renderer communication instructions. The Address/Foot 
Print interface consists of a transfer RAM and handshaking logic. The transfer RAM buffers data to be 
sent from the Setup Engine to the Address and Foot Print processors. Setuo Engine Operation After the 
XFDI performs an execute-renderer instruction, the Setup Engine starts working on the first primitive 
in the argument buffer. The setup computation involves determining the orientation of the primitive and 
calculating the coefficients and starting values for the eqgations used for rendering the primitive. 
After the setup results for a single primitive are written into the transfer RAM, the Address and Foot 
Print Engines will start working on that primitive, and the Setup Engine can go on to the next primitive 
in the argument buffer. When the argument buffer is exhausted, the Setup Engine returns to its idle loop 
to wait for new commands. Address Processor Hardware The SA ASIC also has hardware for functions that 
are specific to the Address Processor. This includes the same micro-sequencer used by the Setup Processor, 
an interface to the Setup Engine, a CPU/memory interface, and logic for controlling the Foot Print Engine. 
The Setup Engine interface controls the burst transfer of data from the transfer RAM in the Setup Processor. 
The CPU/memory interface controls the accesses to virtual memory during rendering. The interface consists 
of a memory access controller and a queue for holding active memory requests. The memory controller manages 
the queue and requests the necessary memory accesses specified by the queue entries. It also synchronizes 
Foot Print Engine execution with the completion of the requested memory cycles. The Foot Print Engine 
interface controls the micro-cede execution of the Foot Print Engine and consists of a jump address queue 
and a micro-sequencer. The queue holds the starting micro-addresses of code sequences to be executed 
by the Foot Print Engine. current footprint ~ position J  0000 O01DO o,=,o, oo o&#38;Si0  =. oOOOOO 
0 &#38;#169;0001 ooc: 0000  oooo o D&#38;#169;O&#38;#169; 000000001 DO00 16-pixel footprints Pixel 
Blocks Covering a Triangle Figure 4 Address Emzine Ooemtion The Address Engine begins a primitive by 
fetching the relevant data from the transfer RAM in the Setup Engine. The Address Engine evaluates the 
bounding function(s) of the primitive, sequentially determining the virtual address of each 4x4 block 
that the primitive hits (See Figure 4.) For triangles and lines, the bounding functions are the linear 
equations defining the sides or ends of the primitive. For spheres the equation of a circle defines the 
boundary. Each block is associated with a Foot Print Engine micro-code sequence. The virtual addresses, 
along with commands for the appropriate memory operations, are inseded into the memory request queue. 
The starting addresses of the Foot Print sequences are written into the jump queue. Foot Print En ~ine 
Hardware In addition to the core functions, the Toe ASIC contains an interface to the Setup Engine and 
pixel write enable logic. The Setup Engine interface controls the burst transfer of data from the transfer 
RAM. The 16 Toes share an input bus that is used to broadcast the transfer data. The write enable logic 
generates pixel write enables based on the computed values of the bounding equations and Z comparison. 
The write enables determine which new color and Z values will be written to the pixel map. The Foot Print 
Engine is a 4x4 array of Toe ASICs (See Figure 5), alranged so each Toe handles one pixel per memory 
block. The array is a single-instruction multiple-data (SIMD) machine with all the Toes executing instructions 
in lockstep from a single control store. The Toe ASIC supports conditional execution of instructions 
so that data-dependent operations can be individually controlled at the pixel level without using micro-code 
branches. Pixel data is transferred between the Foot Print Engine and the pixel registers in the DataPath 
over a 128-bit wide bus. It takes four 50ns cycles to completely transfer a pixel register; each cycle 
involves only one Toe in each column. Each column of Toes also shares a 16K x 32-bit scratch RAM. Only 
one Toe in a column may address it or write data to it at a time, but all four may receive data that 
is accessed by one of the four. This makes the scratch RAM very useful for constant values that are independent 
of the pixel position. Foot Print Engine Ooeration Under the control of the Address Engine, the Foot 
Print Engine begins a primitive by fetching the initial values and coefficients for all the rendering 
equations from the transfer RAM. These initial values were computed for the pixel at position (1,1) ip 
the first block of the primitive. Each Toe adjusts the values (by adding or subtracting the appropriate 
coefficients, as shown in Figure 6) to obtain the correct values for its position in the array. 3,0 1,0 
12,0 3,0 C-A-B C-B ] C+A-B C+2A-B 0,1 1,1 12,1 3,1 C-A C I C+A C+2A ),2 !1,2 2,2 3,2 C-A+B I C÷B C+A+B 
C+2A+B 3,3 ,1,3 2,3 3,3 C-A+2B C+2B C+A+2B 3+2A+2B L F(X,Y) = AX ÷ BY ÷ C Foot Print Function Adjustment 
Figure 6 After the first block is done, the Address Engine walks the Foot Print Engine to the other blocks 
in horizontal or vertical steps, at each step moving 4 pixels in either X or Y. For a horizontal step, 
each Toe updates each function by 4A, while for vertical steps the functions are updated by 4B. The functions 
are evaluated by finite differences taldng advantage of the coherence of the objects being rendered. 
Performance and System Operation We will illustrate the performance of the system by presenting overall 
measured performance of a test application running through the X11 Window System, and the performance 
of the rendering processor for a variety of functions. This will show how well we have matched the geometry 
computation speed of the XFDI to the pixel rendering performance of the rendering processor. The performance 
measured through the Xll Window System was done with a simple animation application that we have written 
for XFDI testing purposes. It uses X and XFDI calls to perform all of its graphics operations; all the 
functions that are used are available to user applications. It is important to note that the XFDI performance 
measurements were done in a multi-user UNIX® environment. In ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 
Ill I |11 I addidon to X 11, all the typical UNIX processes were active including those for network 
services. We feel that meaningful performance measurements must be made in the same environment in which 
the system will be used. Standalone measurements using specialized 'demo' programs yield results that 
are almost never possible for real applications to achieve. The rendering processor performance was measured 
using an exact functional simulation model. This model was used during the hardware design process to 
validate the chip designs for the rendering processor, and to debug renderer micro-code. It is a register 
transfer level (RTL) model written in C that functionally models all register state internal to the renderer 
and all signals that cross chip boundaries and internal blocks within chips. In the performance charts 
below, numbers are specified at a 50ns machine cycle. At the time the measurements were made, we had 
20 running systems based on our first pass of our ASICs. These first pass machines have several minor 
design errors that have been fixed with external logic. This external logic prevents us from running 
these machines at their design speed of 50as. As this paper is completed, second pass ASICs which will 
run at 50ns are returning from our silicon vendor. We have already received second pass Toe and SA ASICs 
and they have passed their chip level tests. The actual measurements were made on a first pass system 
running at 80ns. Since our system is synchronous, we can confidently extrapolate the performance to second 
pass systems running at 50ns. XFDI Performance The XFDI performance was measured using a data base for 
a toms and a test program that could render it in a variety of ways. The toms was rendered between 200 
and 1000 times, and the elapsed time was measured using system time calls. When rendered as a shaded 
surface the torus contains 1624 triangles, or as lines, 1638 lines. As the paper is being completed, 
we are actively tuning the geometry computation code in the XFDI. The cases for which we can quote performance 
are shown in figure 7. We are still tuning some of these cases and expect further improvements. Rendering 
Processor Performance Triangles For Gouraud or Flat shading without Z-buffering, the RP needs only to 
write the color values of the triangle. For large triangles, the RP is able to sustain 80 million pixels 
per second for either shading cases with both true-color and pseudo-color. When Z-buffering is in effect, 
the Z coordinates are read, and the color and Z coordinates are written. 40 million pixels per second 
are sustained for large pseudo- color triangles, and 25 million pixels per second for true-color. When 
triangles are small, the rendering efficiency determines the performance. When the Foot Print processor 
walks over a small triangle, the 4x4 foot print often overlaps the triangle edges. This reduces the useful 
pixels produced with each Foot Print step and reduces the effective pixel throughput. We define the triangle 
rendering efficiency to be the ratio of the triangle area in pixels to the total number or pixels that 
are accessed in rendering it. On average, this is independent of the triangle orientation and depends 
on the ratio of the area to the perimeter of the triangle. For 100 pixel area triangles, we see rendering 
efficiencies ranging from 15% to 60%. We have found 45% rendering efficiency to be average and quote 
the triangle rendering performance for this case. For a 100 pixel triangle, this means that 14 Foot Print 
steps are required. Ling$ We quote our line rendering performance for 10 pixel long vectors. At this 
length, we see an average of 2.5 pixels written for each Foot Print step, for a total of 5 steps required. 
In figure 8 the Rendering Processor performance for a few cases are shown. XFDI Performance Case Performance 
 True and pseudo-color solid lines 551.194 lines/sec 10 pixels long Pseudo-color Gouraud shaded 163,710 
triangles/see Z-buffered 100 pixel triangles Pseudo-color Gouraud shaded Z-buffered 100 pixel triangles 
1 directional light 143,616 triangles/sec 2 directional lights 134,123 triangles/sec 4 directional lights 
119,053 triangles/sec 39,203 triangleslsec Z-buffered 100 pixel triangles 1 directional light, diffuse 
lighting Pseudo-color Phong shaded Pseudo-color Phong shaded 25.144 triangleslsec Z-buffered 100 pixel 
triangles 1 directional light, specular lighting Figure 7 Rendering Processor Performance Case Clock 
Cycles Rate 10 pixel Lines, pseudo-color 33 600,000/sec Gouraud shaded, Z-buffered, 129 155,000/sec 
pseudo-color100 pixel triangles ! Gouraud shaded, Z-buffered, 195 100,000/sec true-color100 pixel triangles 
 Phong shaded, Z-buffered. 491 40,700/sec pseudo-color100 pixel triangles 1 directional light Figure 
8 Discussion Geometry We feel that the implementation of the geometry computations with a general purpose 
vector processor is very effectivo in this system. It is much easier to implement complex functions such 
as arbitrary clipping planes and general lighting models for the vector processor than foi~ a specialized 
micro-coded engine. All the tools of a general purpose programming environment, such as high level languages, 
compilers and debuggers, are available. As more light sources and clipping planes are added, performance 
degrades predictably with the increased complexity of the geometry computations. There are improvements 
that can be made. When the measured performance is compared to the rendering processor performance, it 
is clear that additional vector processing throughput would be useful. We are confident that our architecture 
will allow this to be easily improved in future systems. There are new floating point parts already available 
that could allow us to double the vector processing performance. Pixel Memory Rendering to pixel maps 
stored in virtual memory works very well, and provided several advantages over rendering to specialized 
frame buffer memory. It allows fast and flexible application access to pixcls, and it allows us to support 
pixel space rendering algorithms that require very deep pixels.[ 4,20] ~i~ Computer Graphics, Volume 
22, Number 4,August 1988 There are aspects that we feel can be improved. If we could eliminate the video 
memory, and generate video directly from main memory, we could avoid copying pixels from VPMs to the 
video memory. At the present time it is not possible to get sufficient main memory bandwidth to generate 
video directly from main memory. This requires us to copy pixels from VPMs to the video memory so they 
can be displayed, while systems with specialized frame buffers do not require this copy. In the present 
system, we are able to copy at over 60 million pixels per second, yet there are easy changes that can 
at least double this rate. A main memory location holds pixels in a 4x4 block, while video memory organizes 
them as a 16xl stroke. Video memory is organized to simplify video generation, but this requires pixels 
to be reorganized through the pixel buffer during the copy. If pixels in the video memory could be organized 
as 4x4 blocks, the reorganization would not be needed and the copy rate could double. Pixel Processing 
 The pixel processing capabilities of the Rendering Processor are very flexible and powerful. The presence 
of a multiplier at each Toe allows functions such as transparency and texture mapping to be easily supported. 
We feel that in the future, the trend will be to increase the numeric capability at the pixel level. 
Simulations have shown that the Foot Print processor architecture can be scaled to approximately 3 times 
the present performance by using an 8x8 array of Toes. Four times the memory bandwidth would be needed 
to support this, but such bandwidth seems possible. Toe arrays larger than 8x8 would suffer from poor 
efficiency and could not be cost-justified. A MIMD architecture may then be needed to go faster. During 
rendering, the present system transfers data over the 512-bit wide memory path every 200ns, using non-interleaved 
memory cycles. We do use a simple form of interleaving for transferring data every lOOns during pixel 
copies. We feel that it will be possible in future systems to transfer memory data every 50ns using both 
interleaving and page mode DRAMs. Although we were successful at eliminating specialized hardware for 
geometry computations and frame buffer memory, the Rendering Processor is still used only for graphics. 
It is implemented with general purpose computational elements that can evaluate any functions limited 
only by its fixed numeric precision. Since it is micro-programmed for graphics rendering functions, it 
remains a specialized processor. It is not clear that it will be possible in future systems to design 
a processor that can be used both for pixel rendering computations and other application specific computations. 
Conclusion We have presented a display system architecture intimately coupled with the CPU of our graphics 
supercomputer. The architectural principle of sharing resources between a display system and CPU is discussed, 
and a particular implementation is described. The performance of the system is shown to be competitive 
with specialized architectures. Limitations of the implementation are described, and possible extensions 
and areas for further study are put forth. Acknowledgements The authors would like to thank Professors 
Andries van Dam and Henry Fuchs for their suggestion to write this paper, for their review and comments 
while it was written, and most of all for their support and ideas during the architectare and design 
of the graphics system described here. We want to thank Bill Poduska and Mike Sporer for the key ideas 
behind the architecture, and Paul Jones and Mike Sporer for technical leadership during the project. 
Finally, the work described here is the creation of a large group of exceptional individuals working 
in Stellar's CPU hardware, Hardware Tools, Graphics hardware, and Software groups. Special thanks to 
Clare Campbell for assistance in manuscript preparation. STELLAR, GSloo0, DATAPATH, VIRTUAL PIXEL MAPS 
are trademarks of Stellar Computer Inc. UNIX is a registered wademark of AT&#38;T. X Window Systerm is 
a trademark of MIT. References [1] Baskett, Forest, Tom Jermoluk, Doug Solomon. The 4D-MP Graphics Superworkstation: 
Computing + Graphics = 40 MIPS + 40 MFLOPS and 100,000 Lighted Polygons per Second. Digest of papers 
COMPCOM '88 (San Francisco, California, February 29 -March 4 1988) pp. 468-471 [2] Bishop, Gary and David 
Weimer, Fast Phong Shading. Proceedings of SIGGRAPH'86 ( Dallas, Texas, August 18-22). In Computer Graphics 
20, 4 (August 1986) pp. 103-106 [3] Bresenham, Jack. Algorithm for Computer Control of Digital Plotter. 
IBM System Journal 4, 1 (1965) [4] Carpenter, Loren. The A-buffer, an Antialiased Hidden Surface Method. 
Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27). In Computer Graphics 18, 3 (July 1984) 
pp. 103-108 [5] Clark, Jim. The Geometry Engine: A VLSI Geometry System for Graphics. Proceedings of 
SIGGRAPH'82 (Boston, Massachusetts, July 26-30). In Computer Graphics 16, 3 (July 1982) pp. 127-133 [6] 
Clark, Jim. and M. Hannah. Distributed Processing in a High Performance Smart Image Memory. LAMBDA 4th 
Quarter, 1980. pp. 40-45 [7] England, Nick. A Graphics System Architecture for Interactive Application 
Specific Display Functions. IEEE Computer Graphics and Applications 6, 1 (January 1986)pp. 60-70 [8] 
Fuchs, Henry and John Poulton. Pixel-planes: A VLSI-Oriented Design for a Raster Graphics Engine. VLSI 
Design 2, 3 3rd quarter 1981, pp. 20-28. [9] Fuchs, Henry, Jack Gotdfeather, Jeff Hulquist, Susan Spach, 
John Austin, Frederick Brooks, John Eyles, and John Poulton. Fast Spheres, Shadows, Textures , Transparencies, 
and Image Enhancements in Pixel-planes. Proceedings of SIGGRAPH'85 (San Francisco, California July 22-26). 
In Computer Graphics 19, 3 (July 1985)pp. 111-120 [10] Goldfeather, Jack, Jeff Hulquist, and Henry Fuchs. 
Past Constructive Solid Geometry Display in the Pixel-Powers Graphics System. Proceedings of SIGGRAPH'86 
(Dallas, Texas, August 18- 22). In Computer Graphics 20,4 (August 1986) pp. 107-116 [11] Goris, Andy, 
B. Fredrickson, H. Baeverstad Jr., "A Configurable Pixel Cache for Fast Image Generation", Computer Graphics 
and Applications, Vol. 7, No. 3 [12] Gouraud, H. "Computer Display of Carved Surfaces" Dept. of Computer 
Seience, U. of Utah, UTEC-CSc-71-113, June 1971 [13] "GRAPHICON 700 Specifications", A marketing specification 
sheet from General Electric Company, Silicon Systems Technology Department, P.O. Box 13049 Research Triangle 
Park, NC 27709 [14] Levinthal, Adam and Thomas Porter. Chap - A SIMD Graphics Processor. Proceedings 
of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27). In Computer Graphics 18, 3 (July 1984) pp. 77-82 
[15] McCormick, Bruce,Thomas DeFanti, Maxine Brown editors. Visualization in Scientific Computing. Siggraph 
Computer Graphics newsletter 21, 5 (October 1987) f SIGGRAPH '88, Atlanta, August 1-5, 1988 [16] Phong, 
Bui Tuong. Illumination for Computer Generated [lg] Swanson, Roger and Larry Thayer. A Fast Shaded-Polygon 
Pictures. Communications of the ACM18, 6 (June 1975) pp. 311- Renderer. Proceedings of SIGGRAPH'86 ( 
Dallas, Texas, August 18- 22). In Computer Graphics 20, 4 (August 1986) pp. 95-101 [17] Sporer Michael, 
Franklin Moss, and Craig Mathias. An [191 Torborg, John. A Parallel Processor Architecture for Graphics 
Introduction to the Architecture of the Stellar Graphics Arithmetic Operations. Proceedings Of SIGGRAPH'87 
(Anaheim, Supercomputer. Digest of papers COMPCOM '88 (San Francisco, California, July 27-31). In Computer 
Graphics 21, 4 (July 1987) pp. California, February 29 - March 4 1988) pp. 464-467 197-204 [201 Williams, 
Lance. Casting Curved Shadows on Curved Surfaces. In Computer Graphics 12, 2 (1978) pp.270-274 Literal 
~lnput port JlI[' I 32x32 Register File I I I I r.~o.o.o,t i rAccum°'a'°rir Ad,,o.. I rou,~ul Po. I 
Core Functions of SA and Toe ASICs Figure 3 " v I I File RegisterALU IL MuFtiplier Foot Print Engine 
Figure 5   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378519</article_id>
		<sort_key>263</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Terrain simulation using a model of stream erosion]]></title>
		<page_from>263</page_from>
		<page_to>268</page_to>
		<doi_number>10.1145/54852.378519</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378519</url>
		<abstract>
			<par><![CDATA[The major process affecting the configuration and evolution of terrain is erosion by flowing water. Landscapes thus reflect the branching patterns of river and stream networks. The network patterns contain information that is characteristic of the landscape's topographic features. It is therefore possible to create an approximation to natural terrain by simulating the erosion of stream networks on an initially uneroded surface. Empirical models of stream erosion were used as a basis for the model presented here. Stream networks of various sizes and shapes are created by the model from a small number of initial parameters. The eroded surface is represented as a surface under tension, using the tension parameter to shape the profiles of valleys created by the stream networks. The model can be used to generate terrain databases for flight simulation and computer animation applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[database amplification]]></kw>
			<kw><![CDATA[drainage network simulation]]></kw>
			<kw><![CDATA[erosion models]]></kw>
			<kw><![CDATA[structural models]]></kw>
			<kw><![CDATA[surfaces under tension]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334583</person_id>
				<author_profile_id><![CDATA[81100317485]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alex]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Kelley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334978</person_id>
				<author_profile_id><![CDATA[81100445696]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Malin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Geology, Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14115464</person_id>
				<author_profile_id><![CDATA[81100316506]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Nielson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abrahams, A. "Channel Networks: A Geomorphological Perspective", Water Resour. Res., 20, 2 (February 1984), 161-168.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Abrahams, A. "Divide Angles and Their Relation to Interior Link Lengths in Natural Channel Networks", Geographical Analysis, 12, 2 (April 1980), 161-168.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325249</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. "Modeling the Mighty Maple", Computer Graphics 19, 3 (July 1985), 305-311.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[de Boor, C., A Practical Guide to Splines, Springer- Verlag, 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dunkerly, D. "Frequency Distributions of Stream Link Lengths and the Development of Channel Networks", J. Geol. 85, (1977), 459-470.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Flint, J. "Stream Gradient as a Function of Order, Magnitude, and Discharge", Water Resour. Res., 10, 5 (October 1974), 969-973.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Flint, J. "Tributary Arrangements in Fluvial Systems", Am. J. Sci. 280, (January 1980), 26-45.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Fussell, D., and Carpenter, L. "Computer Rendering of Stochastic Models", Commun. ACM ,25, 6 (June 1982), 371-384.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fournier, A. "Prolegomenon", Siggraph '87 Course Notes: The Modeling of Natural Phenomena", July 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Franke, R., "Scattered Data Interpolation: tests of some methods, Math. Comp. 38 (1982), 181-200.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Howard, A. "Simulation of Stream Networks by Headward Growth and Branching", Geogr. Anal., 3, (1971), 29-50.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Howard, A. "Optimal Angles of Stream Junction: Geometric, Stability to Capture, and Minimum Power Criteria", Water Resour. Res., 7, 4 (August 1971), 863- 873.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kelley, A., Malin, M. "Three-Dimensional Digital Simulation of Drainage Basin Development: Modeling the Martian Valley Networks", Reports of Planetary Geology and Geophysics Program - 1987, NASA Tech Mere. (in press).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kirkby, M. "A Two-Dimensional Simulation Model of Slope and Stream Evolution", In Hillslope Processes, edited by A. D. Abrahams, Alien and Unwin, Boston, 1986, 203-222.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Leopold, L. and Langbein, W. "The Concept of Entropy in Landscape Evolution", Geol. Surv. Prof. Pap. 500-A, 1962.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lewis, J. "Generalized Stochastic Subdivision", ACM Trans. Graphics, 6, 2 (July 1987), 167-190.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Morisawa, M., Streams: Their Dynamics and Morphology, McGraw-Hill Inc. 1968.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>569954</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Newell, M. E., Newell, R. G.and Sancha, T. L. "A Solution to the Hidden Surface Problem", Proc. ACM Nat. Conf., (1972), 236-243.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Nielson, G. and Franke, R. "A Method for Construction of Surfaces Under Tension", Rocky Mountain Journal of Mathematics 14, 1 (Winter 1984), 203-221.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Richards, K. "A Note on Changes in Channel Geometry at Tributary Junctions", Water Resour. Res., 16, 1 (February 1980), 241-244.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Ritter, D., Process Geomorphology, Win. C. Brown, Dubuque, Iowa, 1978.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Schenck H. "Simulation of the Evolution of Drainage- Basin Networks with a Digital Computer", J. Geophys. Res., 68, 20 (October 1963), 5739-5745.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Shreve, R., "Statistical Law of Stream Numbers", J. Geol., 74, (1966), 17-37.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Smith, A. "Plants, Fractal, and Formal Languages", Computer Graphics 18, 3, (July 1984), 1-10.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Terrain Simulation Using a Model of Stream Erosion 
Alex D. Kelley 1 Michael C. Malin 2 Gregory M. Nielson ] t Department of Computer Science 2 Department 
of Geology Arizona State University Tempe, Arizona 85287 Abstract The major process affecting the configuration 
and evolution of terrain is erosion by flowing water. Landscapes thus reflect the branching patterns 
of river and stream networks. The network patterns contain information that is characteristic of the 
landscape's topographic features. It is therefore possible to create an approximation to natural terrain 
by simulating the erosion of stream networks on an initially uneroded surface. Empirical models of stream 
erosion were used us a basis for the model presented here. Stream networks of various sizes and shapes 
are created by the model from a small number of initial parameters. The eroded surface is represented 
as a surface under tension, using the tension parameter to shape the profiles of valleys created by the 
stream networks. The model can be used to generate terrain databases for flight simulation and computer 
animation applications. CR Categories and Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image 
Generation - Display Algorithms; 1.3.5 [Computer Graphics]: Computational Geometry and Object Modeling 
- curve, surface and object representations; geometric algorithms; modeling packages; 1.3.7 [Computer 
Graphics]: Three-dimensional Graphics and Realism -animation; color, shading, texture. Additional Keywords 
and Phrases: Drainage Network Simulation, Erosion Models, Surfaces Under Tension, Database Amplification, 
Structural Models. 1. Introduction During the past decade, considerable progress has been made toward 
developing efficient models for generating approximations to natural terrain. However, models that are 
both realistic and efficient have not been perfected. Models used in real-time applications (e.g., flight 
simulation) often sacrifice realism for efficiency, and the most realistic models may take many hours 
to compute a single scene. Fractal techniques [8] are considered by many to be the most efficient method 
for creating realistic-appearing terrain. Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publicationand its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. Their efficiency stems from their ability to generate complex detail 
by "amplifying" a small database of structural or statistical primitives. In the case of terrain, this 
information may be derived direcdy from digital elevation maps of actual topography. In such cases, however, 
care must be taken to insure proper sampling of the geographic data: too litde "seed" information will 
result in a conspicuous self-similarity, characterized by unrealistically complex and irregular terrain. 
In natural landscapes, different erosional and weathering processes shape the surface at different scales, 
thereby restricting self-similarity to a finite range in scale. This paper describes an alternative approach 
from which images of realistic-looking terrain may be produced while retaining a degree of database amplification 
as present in fractal models. Its basic tenet is that greater realism can be achieved from somewhat more 
deterministic approximations of the relief of natural landscapes. As relief is primarily created through 
water erosion, the model developed here creates topographic structure by tracking the "negative space" 
formed by a drainage system comprised of a stream and its tributaries. Such systems are sometimes called 
stream networks, channel networks or drainage networks. The model shares an "amplifying" quality with 
fractals, in that tributaries may be added to a stream at a variety of scales. By increasing or decreasing 
the number of tributaries, terrain may be modeled at variable degrees of detail. The primary sources 
of information for this work are empirical erosion models used in geomorphology. These models provide 
simple equations for simulating the features of drainage systems. The stream networks thus created then 
provide a coarse framework for surface fitting, which is accomplished by triangulation and interpolation 
using a bivariate analog of the spline under tension [19]. The tension parameters, useful for controlling 
the shape of the modeled terrain, are selected based upon the values of certain features of the stream 
network. An additional goal of this model is to create a numerical system that can be used as a test 
bed for examining the physics by which erosion occurs on the earth and other planets [13]. Given the 
complexity of such problems, the amount of data produced by numerical simulations are nearly uninterpretable 
using conventional methods of analysis. By employing computer graphics, it is possible to synthesize 
these data into visual form, thus taking advantage of the visual bandwidth into the human brain. &#38;#169; 
1988 ACM-0-89791-275 $00.75 -6/88/008/0263 ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 2. Background 
2.1. Basic Terminology The following is a glossary of mostly geological terms, used throughout the remainder 
of the paper: baselevel --the level below which a land surface eannot be reduced by running water. constant 
of channel maintenance --the minimum area necessary to support the development of a stream. divide angle 
--the angle (measured in the horizontal plane) between a drainage divide and an adjacent stream. drainage 
area --the amount of surface area draining into an individual section of channel. drainage basin --the 
area occupied by a stream network defined by the ridge crests that surround the network. drainage density 
--the total length of channel per unit area. This parameter is the reciprocal of the constant of channel 
maintenance. drainage divide --a boundary between streams, separating the area drained by these streams; 
this is usually a ridge. drainage polygon --a polygon representing a portion of the surface area drained 
by one side of a section of channel. exterior link --a section of tributary channel that extends from 
a source of water to a junction with another stream. interior link --a section of channel between two 
tributaries. junction --the point of confluence of two streams. junction angle --the angle (measured 
in the horizontal plane) Several of these terms are illustrated in Figure 1. The links are numbered 
according to Shreve Ordering [23]. These numbers reflect the cumulative increase in the amount of water 
as links come together. Exterior links are assigned a magnitude of 1. When links of magnitude n and m 
come together the resulting link has magnitude (n + m). Research in geomorphology has shown that there 
are relationships between stream order and many of the properties of drainage systems [20]. Several empirical 
models of planimetric features employed in the present simulation are derived from these relationships. 
 2.2. Previous work Stream network simulations have been developed by researchers in geomorpholgy over 
the last two decades. The majority are two dimensional, falling into two broad categories herein termed 
the stream convergence and headward growth models. A survey published by Abrahams [ 1 ] is an excellent 
starting point for the reader interested in learning more about drainage network research. In stream 
convergence models [15,22], a stream is initiated by randomly choosing a source location within a grid. 
Its growth and direction is controlled by successive random moves into adjacent grid areas. It continues 
to grow until it joins another stream or goes outside the grid. Stream convergence models produce various 
statistics that are similar to those of natural networks, but they do not simulate their physical appearance. 
Streams often wander excessively and drainage basins exhibit highly irregular geometries. formed by the 
confluence of two streams. link --a section of channel extending between two tributaries or between a 
source and its first junction with a stream. link gradient --the change in elevation between two junctions, 
divided by the horizontal distance between them. longitudinal profile --the change in elevation as a 
function of position along a stream. main trunk stream --the stream to which all water collected by the 
tributaries is funnelled. outlet link --a link through which all water is discharged from the network. 
This link is the lowest end of the network. sources --the farthest points upstream in a drainage system. 
valley sidewall slope --the slope measured from the edge of a channel to a brink where the slope begins 
to taper off. Figure 1. Schematic Diagram Illustrating Terminology Introduced in Section 2.10 1  Headward 
growth models [11,5] better simulate the physical appearance of natural networks and often produce statistics 
closer to reality than stream convergence models. The growth of a stream is initiated through headward 
random walks on a grid representing uneroded area. Branching of an original stream occurs upon reaching 
a pre-defined length. If a stream threatens to cross an existing stream, its growth is terminated. An 
alternate type of model simulates erosion of the entire landscape using transport equations for the removal 
of solid material [14]. These models show greater promise in understanding the geomorphic processes and 
mechanisms that control the evolution of natural drainage systems. The principal difficulty with this 
approach is the selection of appropriate transport equations for the channel and hillslope subsystems. 
 3. Modeling the Drainage Network Caution must be exercised in comparing the model presented here with 
the simulation models described above, as an approach directly analogous to these other works has not 
employed. Rather, the model presented below is structural [9] in the sense that a three-dimensional skeleton 
of terrain is developed. Aside from fitting points representing the stream network, parameters controlling 
the appearance of the surface (e.g., texture, tension, etc.) may be freely adjusted. Structural models 
have been previously used as a basis for modeling plants and trees [3,24]. The model presented herein 
incorporates empirical methods for determining tributary arrangement along principal streams, interior 
and exterior link lengths, drainage density, stream junction angles, drainage divides, longitudinal profile, 
and valley sidewall slope. 3.1. Drainage Network Initialization The data structure used to describe the 
drainage network is a tree, where each node represents an individual channel link and the surface area 
that contributes water to it. The   ~ Computer Graphics, Volume 22, Number 4, August 1988 components 
of each node are used to store the link's endpoints, length, Shreve order, drainage polygons, and drainage 
area. The tree is constructed by recursively adding sub-branches, hereinafter referred to as tributary 
links. To initialize the root of the tree, points projected onto the horizontal plane that describe the 
initial outline of the drainage basin and position of the main trunk stream are specified by the user. 
An example of an initial drainage system is shown in Figure 2. The procedure for computing the elevations 
at these data points is described at the end of Section 3.2. To initialize the left and right drainage 
polygons, the drainage basin is partitioned along the line segment representing the maintrunk stream. 
Since the maintrunk stream is initially represented by a single link, the Shreve order assigned to this 
root node is 1. Figure 2. An Initial Drainage System. 3.2. The Addition of Tributaries A recursive 
algorithm is used to generate additional links within the drainage network. The addition of a tributary 
link occurs when the channel maintenance of a candidate link is greater than the mean value specified 
for the entire drainage basin. The constant of channel maintenance is defined by the quantity: C=A/L 
(1) where A is the total drainage area and L is the total length of channel. On a regional scale, surface 
material is the main factor controlling this parameter [1]. For example, in humid- temperate climates, 
typical values range between 0.33 and 0.25 for resistant materials (e.g., sandstone). In contrast, if 
the surface material is weak (e.g., clay), the same climate produces values that range from 0.00077 - 
0.00091 [21]. Adding a new tributary link results in the insertion of two additional nodes into the tree. 
The second node, herein termed the upstream link, is created by subdividing the the original, or parent 
link, into two sublinks at the point of junction (the shortened parent link is then called the downstream 
link). Initializing the branch nodes as well as modifying the parameters within the parent node involves 
the computation of Shreve orders, junction position, tributary arrangement, junction angle and drainage 
divides. The Shreve order at each of the three links is computed in the following manner. As all tributaries 
are initially exterior | links, their magnitudes are 1. The upstream link inherits the original Shreve 
order of the parent link. The downstream link receives water from both the upstream link and the magnitude 
1 tributary. Thus its magnitude is the original (ancestral) Shreve order plus 1. Stream orders throughout 
the network increment with the contribution of each new tributary, as appropriate. The following equation 
determines the junction position where the tributary link enters the parent link: Junction = Mean Junction 
+ Rand( ) * Delta Junction (2) where Rand( ) is a procedure returning a pseudorandom number uniformly 
distributed between -1.0 and +1.0. Each link in the network has "parametric length" 1. Therefore, the 
values of MeanJunction and Delta Junction are set to insure that Junction is greater than 0.0 and less 
than or equal to 1.0. For example, if MeanJunction is 0.5 and DeltaJunction is 0.0, the junction position 
will subdivide the parent link into two sublinks of equal length. The placement of junctions has a direct 
effect on the resulting length of interior and exterior links. A small MeanJunction is likely to result 
in smaller interior links than exterior links. Conversely, if Mean Junction is large, exterior links 
are likely to be smaller than interior links. DeltaJunction and the pseudorandom number are used to provide 
a stochastic perturbation on the resulting link lengths. Investigation into the ratios of exterior link 
lengths to interior link lengths have found them to vary considerably between regions, although the ratio 
is usually greater than 1 [1]. The decision on which side of the parent link to place the tributary link 
is based on field observations of tributary arrangements in natural networks [7]. These observations 
show that in the lower reaches of a stream, the initial tributaries have a greater probability of occurring 
on the obtuse or outer side of the stream. Along the middle reaches of the stream, a tributary is more 
likely to develop on the side opposite the next tributary encountered downstream. Both of these observations 
are attributed to space filling constraints imposed on tributary development. In order to model these 
empirical relationships, a stream is partitioned into three reaches (lower, middle, and upper) of equal 
length. Each junction's position is evaluated with respect to this partitioning and the tributary arrangement 
in the lower and middle reaches are biased accordingly. In the upper reaches of the stream, the model 
assigns both sides an equal probability, although some evidence has shown that the shape of the basin 
at the upstream end will tend to promote tributary development on one side over the other [1]. The tributary 
and upstream links are next assigned a junction angle, which is estimated using the Howard geometric 
model [12]: Junction Angle = E1 + E2 (3) where cos E1 = $3/S1 (4) cos E 2 = S3/S2 i5) The entrance angles 
E1 and E2 (Figure 3) are projected onto the horizontal plane. S1, $2 and $3 are the stream gradients 
(slope tangents) of the tributary, upstream and downstream links, respectively. The magnitude of each 
of the  SIGGRAPH '88, Atlanta, August 1-5, 1988 surface evaluation. Computation time for the stream 
network shown in Figure 6 was 8 minutes, about 90% of which was consumed by the surface evaluation and 
minimum norm network computations. The surface was evaluated at 26,671 locations and transformed into 
41,339 triangles. This series of computations need be performed only once. Rendering the 512 x 512 x 
24-bit image took 4 minutes. 7. Conclusion &#38; Future Work A method for modeling terrain at the scale 
in which fluvial processes shape its surface has been demonstrated. Terrain is modeled by simulating 
the erosion caused by stream networks on an initially uneroded surface. The model has an "amplifying" 
quality because an initial stream network evolves into a much larger network. Furthermore, very little 
information is required to represent the initial drainage system. Empirical models from geomorphology 
are used as a basis for the modeling. Planimetric attributes are parameterized and therefore do not require 
explicit modeling. The model may be amplified in many ways. Although the tension parameter appears to 
be useful in controlling the transverse profiles of valleys, the model currently does not incorporate 
an explicit or physically based model of changes in hilislope profiles. Thus, the hillslopes are too 
simplistic. A deficiency of the model is that it addresses only one, albeit major, mechanism for shaping 
landscapes. Several others contribute to the total picture. At smaller scales, various weathering processes 
are important factors controlling the shape and texture of rock surfaces. Stochastic subdivision methods 
[16] are a possible source for modeling these smaller features. The model can probably be animated to 
show the evolution of a landscape once these suggested areas of future work have been addressed.  Acknowledgments 
ADK and MCM were supported by NASA Grant NAGW-1 and NSF Grant EAR-8313091. GMN was supported by the U.S. 
Department of Energy under contract DE-FG02-87ER25041 to Arizona State University and by a NATO Research 
Grant RG.0097/88. We wish to thank Mike Caplinger for his help in defining and implementing the rendering 
software used to produce Figure 6. Richard Franke wrote the original code which performed the minimum 
norm network computations.  References 1. Abrahams, A. "Channel Networks: A Geomorphological Perspective", 
Water Resour. Res., 20, 2 (February 1984), 161-168. 2. Abrahams, A. "Divide Angles and Their Relation 
to Interior Link Lengths in Natural Channel Networks", GeographicalAnalysis, 12, 2 (April 1980), 161-168. 
 3. Bloomenthal, J. "Modeling the Mighty Maple", Computer Graphics 19, 3 (July 1985), 305-311. 4. de 
Boor, C., A Practical Guide to Splines, Springer-Verlag, 1978. 5. Dunkerly, D. "Frequency Distributions 
of Stream Link Lengths and the Development of Channel Networks", J. Geol. 85, (1977), 459-470.  . Flint, 
J. "Stream Gradient as a Function of Order, Magnitude, and Discharge", Water Resour. Res., 10, 5 (October 
1974), 969-973. 7. Flint, J. "Tributary Arrangements in Fluvial Systems", Am. J. Sci. 280, (January 
1980), 26-45. 8. Fournier, A., Fussell, D., and Carpenter, L. "Computer Rendering of Stochastic Models", 
Commun. ACM ,25, 6 (June 1982), 371-384. 9. Fournier, A. "Prolegomenon", Siggraph '87 Course Notes: 
The Modeling of Natural Phenomena", July 1987. 10. Franke, R., "Scattered Data Interpolation: tests 
of some methods, Math. Comp. 38 (1982), 181-200. 11. Howard, A. "Simulation of Stream Networks by Headward 
Growth and Branching", Geogr. Anal., 3, (1971), 29-50. 12. Howard, A. "Optimal Angles of Stream Junction: 
Geometric, Stability to Capture, and Minimum Power Criteria", Water Resour. Res., 7, 4 (August 1971), 
863- 873.  13. Kelley, A., Malin, M. "Three-Dimensional Digital Simulation of Drainage Basin Development: 
Modeling the Martian Valley Networks", Reports of Planetary Geology and Geophysics Program - 1987, NASA 
Tech Mere. (in press).  14. Kirkby, M. "A Two-Dimensional Simulation Model of Slope and Stream Evolution", 
In Hillslope Processes, edited by A. D. Abrahams, Alien and Unwin, Boston, 1986, 203-222. 15. Leopold, 
L. and Langbein, W. "The Concept of Entropy in Landscape Evolution", Geol. Surv. Prof. Pap. 500-A, 1962. 
 16. Lewis, J. "Generalized Stochastic Subdivision", ACM Trans. Graphics, 6, 2 (July 1987), 167-190. 
 17. Morisawa, M., Streams: Their Dynamics and Morphology, McGraw-Hill Inc. 1968. 18. Newell, M. E., 
Newell, R. G.and Sancha, T. L. "A  Solution to the Hidden Surface Problem", Proc. ACM Nat. Conf., (1972), 
236-243. 19. Nielson, G. and Franke, R. "A Method for Construction of Surfaces Under Tension", Rocky 
Mountain Journal of Mathematics 14, 1 (Winter 1984), 203-221. 20. Richards, K. "A Note on Changes in 
Channel Geometry at Tributary Junctions", Water Resour. Res., 16, 1 (February 1980), 241-244. 21. Ritter, 
D., Process Geomorphology, Win. C. Brown, Dubuque, Iowa, 1978. 22. Schenck H. "Simulation of the Evolution 
of Drainage- Basin Networks with a Digital Computer", J. Geophys. Res., 68, 20 (October 1963), 5739-5745. 
 23. Shreve, R., "Statistical Law of Stream Numbers", J. Geol., 74, (1966), 17-37. 24. Smith, A. "Plants, 
Fractal, and Formal Languages", Computer Graphics 18, 3, (July 1984), 1-10.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378522</article_id>
		<sort_key>269</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Modeling inelastic deformation]]></title>
		<subtitle><![CDATA[viscolelasticity, plasticity, fracture]]></subtitle>
		<page_from>269</page_from>
		<page_to>278</page_to>
		<doi_number>10.1145/54852.378522</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378522</url>
		<abstract>
			<par><![CDATA[We continue our development of physically-based models for animating nonrigid objects in simulated physical environments. Our prior work treats the special case of objects that undergo perfectly elastic deformations. Real materials, however, exhibit a rich variety of inelastic phenomena. For instance, objects may restore themselves to their natural shapes slowly, or perhaps only partially upon removal of forces that cause deformation. Moreover, the deformation may depend on the history of applied forces. The present paper proposes inelastically deformable models for use in computer graphics animation. These dynamic models tractably simulate three canonical inelastic behaviors---viscoelasticity, plasticity, and fracture. Viscous and plastic processes within the models evolve a reference component, which describes the natural shape, according to yield and creep relationships that depend on applied force and/or instantaneous deformation. Simple fracture mechanics result from internal processes that introduce local discontinuities as a function of the instantaneous deformations measured through the model. We apply our inelastically deformable models to achieve novel computer graphics effects.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[deformation]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[elasticity]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor>Modeling and recovery of physical attributes</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010254</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Reconstruction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14109166</person_id>
				<author_profile_id><![CDATA[81100294834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Demetri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Terzopoulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051176</person_id>
				<author_profile_id><![CDATA[81332499016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fleischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Palo Alto Research, 3340 Hillview Avenue, Palo Alto, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barr, A., Barrel, R., Haumann, D., Kass, M., Plait, J., Terzopoulos, D., and Witkin, A., Topics in physically-based modeling, ACM SIGGRAPH '87 Course Notes, Vol. 17, Anaheim, CA, 1987.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Bloomenthal, J., Oppenheimer, P., Reeves) W.T., and Smith, A.R., The modeling of natural phenomena, ACM SIGGRAPH '87 Course Notes, Vol. 16, Anaheim, CA, 1987.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W.W., and Green, M., "The dynamics of articulated rigid bodies for purposes of animation," The Visual Computer, 1, 1985, 231-240.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J., and Barsky) B.A., "Using dynamic analysis to animate articulated bodies such as humans and robots," Proc. Graphics Interface '85, Montreal, Canada, 1985, 97-104.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Girard, M., and Maciejewski, A.A., "Computational modeling for the computer animation of legged figures," Computer Graphics, 19, 3, 1985, (Proc. SIGGRAPH), 263- 270.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Barrel, R., and Barr, A., Dynamic Constraints, 1987,]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hoffmann, C.M., and Hopcroft, J.E., "Simulation of physical systems from geometric models," IEEE Journ. Robotics and Automation, RK-3, 3, 1987, 194-206.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Issacs, P.M., and Cohen, M.F., "Controlling dynamic simulation with kinematic constraints, behavior functions, and inverse dynamics," Computer Graphics, 21, 4, 1987, (Proc. SIGGRAPH) 215-224.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Weil, J., "The synthesis of cloth objects," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 49-54.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Feynman, C.R., Modeling the Appearance of Cloth, MSc thesis, Department of Electrical Engineering and Computer Science, MIT, Caxnhridge, MA, 1986.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Platt, J., Barr, A., and Fleischer, K., "Elastically deformable models," Computer Graphics, 21, 4, 1987, (Proc. SIGGRAPH) 205-214.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Haumann, D., Modeling the physical behavior of flexible objects, 1987, in {1}.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Well, J., "Animating cloth objects," unpublished manuscript, 1987.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102333</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., and Witkin, A., "Physically-based models with rigid and deformable components," Proc. Graphics Interface '88, Edmonton, Canada, June, 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Alfrey, T., Mechanical Behavior of High Polymers, Interscience, New York, NY, 1947.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>22977</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kardestuncer, H., and Norrle, D.H., (ed.), Finite Element Handbook, McGraw-Hill, New York, NY, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H.N., "Computer generated displays of structures in vibration," The Shock and Vibration Bulletin, 44, 2, 1974, 185-192.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Christiansen, H.N., and Benzley, S.E., "Computer graphics displays of nonlinear calculations," Computer Methods in Applied Mechanics and Engineering, 34, 1982, 1037- 1050.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Shephard, M.S., and Abel, J. F., Interactive computer graphics for CAD/CAM, 1987, in {16}, Section 4.4.3.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Christensen, R.M., Theory of viscoelasticity, 2nd ed., Academic Press, New York, NY, 1982.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Mendelson, A., Plasticity-Theory and Application, Macmillan, New York, NY, 1968.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sih, G.C., Mechanics of Fracture, Martinus Nijhoff, The Hague, 1981.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Goldstein, H., Classical Mechanics, Addison-Wesley, Reading, MA, 1950.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Courant, R., and Hilbert, D., Methods of Mathematical Physics, Vol. I, Interscience, London, 1953.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5994</ref_obj_id>
				<ref_obj_pid>5979</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., "Regularization of inverse visual problems involving discontinuities," IEEE Trans. Pattern Analysis and Machine Intelligence, PAMI-8, 1986, 413-424.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Lapidus, L., and Pinder, G.F., Numerical Solution of Partial Differential Equations in Science and Engineering, Wiley, New York, NY, 1982.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6771</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Press, W.H., Flannery, B.P., Teukolsky, S.A., and Vetterling, W.T., Numerical Recipes: The Art of Scientific Computing, Cambridge University Press, Cambridge, UK) 1986.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz, O.C., The Finite Element Method; Third edition, McGraw-Hill, London, 1977.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Hackbusch, W., Multigrid Methods and Applications, Springer-Verlag, Berlin, 1985.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Hansen, C., and Henderson, T., UTAH Range Database, Dept. of Computer Science, University of Utah, Salt Lake City, Utah, TR No. UUCS-86-113, 1986.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., "Multilevel computational processes for visual surface reconstruction," Computer Vision, Graphics, and Image Processing, 24, 1983, 52-96.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>102331</ref_obj_id>
				<ref_obj_pid>102313</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Fleischer, K., and Witkin, A., "A modeling testbed," Proc. Graphics Interface '88, Edmonton, Canada, June, 1988.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Modeling Inelastic Deformation: Viscoelasticity, 
Plasticity, Fracture Demetri Terzopoulos Kurrt Fleiseher Schlumberger Palo Alto Research 3340 Hillview 
Avenue, Palo Alto, CA 94304 Abstract We continue our development of physically-based models for animating 
nonrigid objects in simulated physical envi- ronments. Our prior work treats the special case of objects 
that undergo perfectly elastic deformations. Real materi- als, however, exhibit a rich variety of inelastic 
phenomena. For instance, objects may restore themselves to their nat- ural shapes slowly, or perhaps 
only partially upon removal of forces that cause deformation. Moreover, the deforma- tion may depend 
on the history of applied forces. The present paper proposes inelastically deformable models for use 
in computer graphics animation. These dynamic mod- els tractably simulate three canonical inelastic behaviors-- 
viscoelasticity, plasticity, and fracture. Viscous and plastic processes within the models evolve a reference 
component, which describes the natural shape, according to yield and creep relationships that depend 
on applied force and/or in- stantaneous deformation. Simple fracture mechanics result from internal processes 
that introduce local discontinuities as a function of the instantaneous deformations measured through 
the model. We apply our inelastically deformable modds to achieve novel computer graphics effects. Keywords: 
Modeling, Animation, Deformation, Elastic- ity, Dynamics, Simulation C/t Categories and Subject Descriptors: 
G.1.8--Partial Differential Equations; 1.3.5--Computational Ge- ometry and Object Modeling (Curve, Surface, 
Solid, and Object Representations); 1.3.7--Three-DimensionM Graph- ics and Realism (Animation); 1.6.3 
Simulation and Model- ing (Applications) Permission to copy without fee all or part of this material 
is granted provided that the copies are not made or distributed for direct commercial advantage, the 
ACM copyright notice and the title of the publication and its date appear, and notice is given that copying 
is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires 
a fee and/or specific permission. &#38;#169; 1988 ACM-0-89791-275 $00.75 -6/88/008/0269 1. Introduction 
Modeling and animation based on physical principles is establishing itself as a computer graphics technique 
offer- ing unsurpassed realism [1, 2]. Physically-based models of natural phenomena are making exciting 
contributions to image synthesis. A popular theme is the use of Newtonian dynamics to animate articulated 
or arbitrarily constrained assemblies of rigid objects in simulated physical environ- ments [3-8]. The 
animation of continuously stretchable and flexible objects in such environments is also attracting increasing 
attention. It is extremely difficult to animate nonrigid objects with any degree of realism using conven- 
tional, kinematic methods. A better approach to synthe- sizing physically plausible nonrigid motions 
is to model the continuum-mechanical principles governing the dynamics of nonrigid bodies. Initial models 
of flexible objects were concerned with static shape [9, 10]. Subsequent work produced models for animating 
nonrigid objects in simulated physical worlds [11-14]. In [11] we employ elasticity theory to model the 
shapes and motions of deformable curves, surfaces, and solids. TechnicaUy as well as computationally, 
this ap-proach is more demanding than conventional methods for modeling free-form shape, but the results 
are weU worth the extra effort. Our simulation algorithms have proven capable of synthesizing realistic 
motions arising from the complex interaction of elastically deforraable models with diverse forces, ambient 
media, and impenetrable obstacles. Prior work on deformable models in computer graph- ics treats only 
the case of objects undergoing perfectly elas- tic deformation. A deformation is termed elastic if the 
undeformed or reference shape restores itself completely, upon removal of all external forces. A basic 
assumption underlying the constitutive laws of classical elasticity the- ory is that the restoring force 
(stress) in a body is a single- valued function of the deformation (strain) of the body and, moreover, 
that it is independent of the history of the deformation. It is possible to quantify elastic restor- 
ing forces in terms of potential energies of deformation, a characterization that we employ in the formulation 
of our models. Like an ideal spring, an elastic model stores po- tential energy during deformation mad 
releases the energy entirely as it recovers the reference shape. By contrast, a perfect (Newtonian) fluid 
stores no deformation energy, SIGGRAPH '88, Atlanta, August 1-5, 1988 hence it exhibits no resilience. 
In the present paper, we develop computer graphics models which make inroads into the broad spectrum 
of in- elaJtic deformation phenomena intermediate between per- fectly elastic solids, on the one hand, 
and viscous fluids, on the other. Generally, a deformation is inelastic if it does not obey the idealized 
(Hookean) constitutive laws of clas- sical elasticity. Inelastic deformations occur in real materi- als 
for temperatures and forces exceeding certain limiting values above which irreversible dislocations at 
the atomic level can no longer be neglected. Why model inelastic behavior? Aside from an artistic motivation 
to achieve a rich variety of novel graphics ef- fects, we wish to incorporate into our deformable models 
the mechanical behaviors commonly associated with high polymer solids--organic compounds containing a 
large num- ber of recurring chemical structures--such as modeling clay, thermoplastic compound, or silicone 
putty [15]. These behaviors are responsible for the universal utility of these sorts of modeling materials 
in molding complex shapes (e.g, in the design of automobile bodies). We are inter-ested in assimilating 
some of the natural conveniences of this traditional art into the computer-aided design envi- ronment 
of the future. We envision users, aided by stereo- scopic and haptic input-output devices, carving "computer 
plasticine" and applying simulated forces to it in order to create free-form shapes interactively. Our 
physically-based models incorporate three canon- ieal genres of inelastic behavior--viJeo ela~tieity, 
p la~tieity, and ]raeture. Viscoelastic material behavior includes the characteristics of a viscous fluid 
together with elasticity. Silicone ("Silly") putty exhibits unmistakable viscoelastic behavior; it flows 
under sustained force, but bounces like a rubber ball when subjected to quickly transient forces. Inelastic 
materials for which permanent deformations re-sult from the mechanism of slip or atomic dislocation are 
known as plastic. Most metals, for instance, behave elas- tically only when the applied forces are small, 
after which they yield plastically, resulting in permanent dimensional changes. Our models can also simulate 
the behavior of thermoplastics, which may be formed easily into desired shapes by pressure at relatively 
moderate temperatures, then made elastic or rigid around these shapes by cool- ing. As materials are 
deformed beyond certain limits, they eventually fracture. Cracks develop according to internal force 
or deformation distributions and their propagation is affected by local variations in material properties. 
Fig. 1 illustrates some of the capabilities of our inelas- tic models in Flatland, a restricted physical 
world. Flat-land models are deformable planar curves capable of rigid- body dynamics or general "elastoviscoplastodynarnics" 
(!) with possible fractures. An efficient numerical algorithm provides real-time response (on Symbolics 
3600 series Lisp Machines), enabling us to interact with the models by sub- jecting them to user-controlled 
forces, aerodynamic drag, gravity, collisions, etc. (see [11] for more details on for-mnlating forces). 
Fig. la-c shows the strobed motion of an indastic flatland model that has zero, medium, and high viscodasticity 
as it collides into friction less walls. The strobe frames in Fig. ld ilhistrate the interactive molding 
D C Figure 1. Simulations in Flatland. Models are strobed while undergoing motion subject to gravity, 
drag, collisions, and user- controlled forces. Velocity vector of the center of mass (dot) is indicated. 
(a) Elastic model. (b) Viscoelastic model. (c) Highly viscoelastic model. (d) A viscoelastic model is 
deformed. (e) B.esulting shape is made elastic and bounced. (f) Same shape made viscoelastic and bounced. 
 ~ Computer Graphics, Volume 22, Number 4, August 1988 of inelastic models through the application of 
simple forces. The user starts with a circular viscoelastic model fixed at its center. The model simulates 
thermoplastic material. The user applies a sustained spring force from point A. The spring (under position 
control from a "mouse") is shown in the figure as a llne between two points. The spring force de- forms 
the modal, stretching it to the left (an effect known as stress relaxation). Next, the user releases 
the spring from A, then reactivates it at B and sweeps through C, D, and E, pulling the material along. 
The final shape is set by "cooling" the thermoplastic. The model is then made per- fectly elastic and 
it can be bounced (Fig. le). Finally the model is made inelastic and bounced again (Fig. lf). Later we 
present further details and examples of more complex three-dimensional inelastic models. The inelastic 
models described in this paper gener- alize our prior elastic models and inherit their animate characteristics, 
thereby unifying the description of shape and motion. We show how to model inelastic deforma- tion in 
the context of two varieties of deformable models which we have developed in prior papers [11, 14]. Both 
formulations allow elastic deformation away from a refer- ence shape represented within the model. In 
our inelastic generalizations, internal viscous and plastic processes dy- namically feed part of the 
instantaneous deformation back into the reference shape component. Simplified fracture mechanics result 
from internal processes which introduce local discontinuities dynamically as a function of the in- stantaneous 
deformations measured through the model. We conclude the introduction with a perspective on our work 
as it relates to the engineering analysis of mate- rials and structures. First, here is a caveat: We 
make no particular attempt to model specific materials accurately. Usually the general behavior of a 
material will defy ac-curate mathematical description, and engineering modds tend to be complicated. 
Sophisticated finite element codes are available for analyzing the mechanics of nonrigid struc- tures 
constructed from specific materials such as steal and concrete [16]. Computer graphics has become indispens- 
able for visualizing the overwhelming amount of data that can be produced during the preprocessing and 
postprocess- ing stages of finite dement analysis [17-19]. Although we adopt certain numerical techniques 
from finite element analysis, our computer graphics modeling work has a distinctly different emphasis. 
We have sought to develop physically-based models with associated numer- ical procedures that can be 
utilized to create realistic ani- mations. Hence, our deformable models are convenient for computer graphics 
applications, where a keen concern with tractability motivates mathematical abstraction and com- putational 
expediency. This paper develops inelastic mod- els that idealize regimes of material response under certain 
types of environmental conditions, whose parameters de- scribe qualitatively familiar behaviors, such 
as stretchabil- ity, bendability, resilience, fragility, etc. The organization of the remainder of the 
paper is as follows: Section 2 describes inelastic deformation phenom- ena in more detail using idealized 
mechanical units. Sec-tions 3 and 4 review our basic dastic models and explain how we incorporate inelastic 
behaviors into the partial dif- ferential equations that govern their motions. Section 5 summarizes our 
implementation. Section 6 presents more simulation results and Section 7 draws conclusions. 2. Inelastic 
Deformation A formal treatment of inelastic deformation is beyond the scope of this paper. For theory 
on viscoelasticity, plastic- ity, and fracture, refer to, e.g., [20-22]. The basic inelastic behaviors 
may be understood readily, however, in terms of assemblies of idealized uniaxial (one-dimensional) me-chanical 
units. The ideal finear elastic unit is the spring (Fig. 2a). The spring satisfies Hooke's law---elongation 
or contraction e (strain) is proportional to applied tension or compression force f (stress): ke = f, 
where k is the spring constant. The elastic unit is supplemented by two other uniaxiaI units, the viscous 
and plastic units (Fig. 2b,c). By assembling these units in specific configurations, we can simulate 
simple, uniaxial viscoelasticity and plasticity. Our indasticaUy deformable models incorporate the laws 
governing these units, suitably generalized and extended over a multidimensional continuum. / Elastic 
unit / Viscous unit i---i--. i   I--e~ J Plastic unit br ---p -I e Figure 2. Uniaxial deformation 
units and their response to applied forces. (a) Elastic spring. (b) Viscous dashpot. (c) Plastic slip 
unit. 2.1. Viscoelasticity Viscoelasticity is a generalization of elasticity and viscosity. It is characterized 
by the phenomenon of creep which mani- fests itself as a time dependent deformation under constant applied 
force. In addition to instantaneous deformation, creep deformations develop which generally increase 
with the duration of the force. Whereas an elastic model, by definition, is one which has the memory 
only of its refer- ence shape, the instantaneous deformation of a viscoelastic model is a function of 
the entire history of applied force. Conversely, the instantaneous restoring force is a function of the 
entire history of deformation. The ideal linear viscous unit is the dashpot (Fig. 2b). The rate of increase 
in elongation or contraction e is pro- portional to applied force f: Wd = f, where i/is the viscos- ity 
constant (the overstruck dot denotes a time derivative). The elastic and viscous units are combined to 
model lin- ear viscoelasticity, so that the internal forces depend not just on the magnitude of deformation, 
but also on the rate of deformation. Fig. 3a illustrates a four-unit viscoelastic model, a series assembly 
of the so called Maxwell and Voigt viscoelastic models. The stress-strain relationship for this assembly 
has the general form ~z2E+a,~+aoe=b~]+b,j +bof, (1) where the coefficients depend on the spring and viscosity 
constants. The response of the models to an applied force (Fig. 3b) is shown graphically in Fig. 3c. 
 Four-unit viscoelastic model [ I I r , I V-~---q I - Maxwe. emmen~ I .-.J Voigt element I- / OT~ > 
t Maxwell ~ Four-unit Elastic / ~. tVisc°us  0 Voigt Figure 3. Uniaxial viscoelastic model. (a) The 
four-element model is a series connection of a Maxwell viscoelastic unit and a Voigt viscoelastic unit. 
(b) Force applied to the model. (c) Response of various components. 2.2. Plasticity In plasticity, unique 
relationships between displacement and applied force do not generally exist. The ideal plastic unit is 
the slip unit (Fig. 2c). It is capable of arbitrary elon- gation or contraction as soon as the applied 
force exceeds a yield force. During plastic yield, the apparent instan- taneous elastic constar~ts of 
the material arc smaller than those in the elastic state. Removal of applied force causes the material 
to unload elastically with its initial elastic constants. This behavior may be termed elastoplastic. 
 Viscoplasticity, a generalization of plasticity and vis- cosity, can be modeled by assembling dashpots 
with plastic units. Analogously, elastoplasticity generalizes elasticity and plasticity and is modeled 
by assembling springs with plastic units. Fig. 4b presents graphically the response of a simple elastoplastic 
model (Fig. 4a). The model is lin- early elastic from O to A. After reaching the yield point A, the 
model exhibits linear work hardening. Upon un-loading from B, the elastic region is defined by force 
am- plitude fB -fc = 2fA. Subsequent loads now move the model along BC. Loading past point B causes further 
plas- tic deformation along BE. The reverse plastic deformation occurs, along CD. After a closed cycle 
in force and displace- ment OABCDO, the model returns to its initial state and subsequent behavior is 
not affected by the cycle. Elastoplastic model / FeN B ......X E O Figure 4. Uniaxial elastoplastic 
model. (a) The three-unit model. (b) Response to applied force (see text). 2.3. Fracture Solid materials 
cannot sustain arbitrarily large stresses with- out failure, as is represented at point E in the elastoplas- 
tic model of Fig. 4. Beyond this limiting elongation, the elastoplastic model fractures. Fractures are 
localized posi- tion discontinuities that arise due to the breaking of atomic bonds in materials. They 
usually initiate from stress sin- gularities that arise at corners of irregularities or cavities present 
in solids. Solids exhibit three modes of fracture opening: a tensile mode and two shear modes, one planar 
and one normal to a plane. @ Computer Graphics, Volume 22, Number 4, August 1988 As fractures develop 
they release internal potential energy of deformation (strain energy). For fractures to propagate through 
the material, the energy release rate as the fracture lengthens must be greater than a critical value. 
For brittle materials such as glass, fractures will de- velop unstably if the energy released is equal 
to the energy needed to createthe free surface associated with the frac- ture. In this case, minor variations 
in material properties in the continuum can greatly influence the propagation. For materials like steel, 
however, the effects of plasticity at fracture tips must be taken into account. We do not consider this 
effect; its mathematical treatment is under development in the large body of literatureon fracture mechanics 
(see [22]). 3. Basic Deformable Models This section briefly reviews two formulations of deformable models, 
a primary formulation and a hybrid formulation, each of which can serve as a foundation for modding inelas- 
tic behavior. In both formulations u denotes the intrinsic or material coordinates of points in a body 
fL For a solid body u = (ul,uz,u3) has three coordinates. For a surface u = (Ul,U2) and for a curve u 
= (ul). In these three cases, respectively, and without loss of generality, 12 will be the unit interval 
[0, 1], the unit square [0,1] 2, and the unit cube [0,1] s. The primary formulation of deformable models 
[11] describes deformations using the positions x(u, t) of points in the body relative to an inertial 
frame of reference 6 in Euclidean 3-space (Fig. 5). Position is a 3-component vector-valued function 
of the material coordinates and time. Deformations are measured away from a reference shape which is 
represented in differential geometric form. For elastic deformations, this representation gives rise 
to in- ternal deformation energies £(x) which produce restoring forces that are invariant with respect 
to rigid motions in 6. Y Reference  ponent X   ~ame Z Figure 5. Geometric representation of deformable 
models. The hybrid formulation [14] represents the same de-formable body as the sum of a reference component 
r(u, t) and a deformation component e(u,t). Both components are expressed relative to a reference frame 
~b whose origin coincides with the body's center of mass e(t) and which translates and rotates along 
with the deformable body (Fig. 5). Wc denote the positions of mass elements in the body relative to q~ 
by q(u,t) = r(n,t) + e(u,t). (2) We measure deformations with respect to the reference shape r represented 
in parametric form. Elastic defor-mations are again representable by an energy ~(e), but this energy 
depends on the position of ¢. Hence, for the deformable model to have a rigid-body motion mode in ad- 
dition to an elastic mode, the reference component must be evolved over time according to the laws of 
rigid-body dynamics [23]. We obtain a model with explicit deformable and rigid characteristics; hence 
the name "hybrid." Appendix A gives the equations of motion for both formulations. The primary and hybrid 
formulations offer different practical benefits at extreme limits of deformable behavior. The primary 
formulation handles free motions implicitly, but at the expense of a nonquadratic energy functional £(x) 
(nonlinear restoring forces). The equation of motion (9) with such a functional is numerically solvable 
without much difi/iculty for extremely nonrigid models such as rubber sheets, but the numerical conditioning 
deterio- rates with increasing rigidity due to exacerbated nonlinear- ity. The hybrid formulation permits 
the use of a quadratic energy functional £(e) (linear restoring forces). Despite their greater complexity, 
the equations of motion (13) of- fer a significant practical advantage for fairly rigid mod- els with 
complex reference shapes. Conditioning improves as the model becomes more rigid, tending in the limit 
to wall-conditioned, rigid-body dynamics. See [14] for more details. 4. Incorporating Inelastic Behavior 
 This section describes how we incorporate inelastic behav- ior using the hybrid formulation of deformable 
modds and also briefly indicates how we obtain similar effects using the primary formulation. First we 
will specify the internal restoring forces that govern deformation. Recall that the hybrid formulation 
expresses this deformation e(u, t) with respect to a reference component r(u, t). We obtain vis- coelastic, 
plasti% and fracture behavior by designing inter- no1 processes that lawfully update r and modify material 
properties according to applied force and instantaneous de- formation. In the hybrid equations of motion 
(13), the restoring force due to deformational displacement e(u,t) is repre- sented in (13c) by /feE, 
a variational derivative [24] with respect to e of an rustic potential energy functional ~. The general 
form of ~ is £(e) L E(n, e, e,, e~u,...) du, (3) an integral over material coordinates of art elastic 
energy density E, which depends on e and its partial derivatives with respect to material coordinates. 
A convenient choice for E is the controlled-continuity generalized spline kernels [25]. These splines 
are of the form (3) with the integrand defined by = i. = jl!...J, fwJlO~ e I , (4) where j = (ja,... 
,jd) is a multi-index with IJl = J, +.. + jd, where d is the material dimensionality of the model (d 
= 1 for curves, d = 2 for surfaces, and d = 3 for solids), and where the partial derivative operator 
0m a? = (5) . . . Thus, E is a weighted combination of partial derivatives of e of all orders up to 
p, with the weighting functions wj(u) in (4) controlling the elastic properties of the de-formable model 
over u. The allowable deformation be-comes smoother for increasing p. The variational derivative in ~ 
of E with the spline density (4) is P ~eE = E (--1)mA'~"~ e' (6) rrl.~ 0 where _~ .0.m Ijl=,~ is a spatially-weighted 
iterated Laplacian operator of order m. For convenience, we use cyclic boundary conditions on N and we 
introduce predetermined fractures to create free boundaries as necessary. To create a free surface, for 
example, we start with a torus and section it around the large and small circumference to obtain a single 
sheet. For a surface with p = 2 (the highest order of p that we have used to date), the variational derivative 
of (18) is 0e 0 w01  ( ) (°°) geE(e) =w00e- ~1 02 ( 02e~ 0 z f 02e O~lO~a ~, O~lO~z] + 02( 02e~ (8) 
where u = (ul,u2) are the surface's material coordinates. The function woo penalizes the total magnitude 
of the de- formation; wl0 and w01 penalize the magnitude of its first partial derivatives; w20, wax, 
and w02 penalize the magni- tude of its second partial derivatives; etc. The controlled-continuity spline 
kernel (4) allows our models to simulate the piecewise continuous deformations characteristic of fractures, 
creases, curvature discontinu-ities, etc. The distributed parameter functions wj offer local continuity 
control throughout the material domain fL Discontinuities in the deformation of order 0 < k < p will 
occur freely at a material point u0 when wj(u0) is set to 0 for IJl > k [25]. When the stresses or deformations 
exceed preset frac- ture limits, we locally nullify the wj to introduce disconti- nuities. We have experimented 
with several simple schemes for propagating fractures in our models; for instance, at each time step 
we can insert a position discontinuity (order k = 0) at the material point u. at which there occurs the 
greatest elastic displacement beyond the limiting elonga- tion over ~. The yield limit may vary greatly 
over material coordinates in real materials, especially if there happen to be localized weaknesses, say, 
from imperfections. We have experimented successfully with yield functions that vary stochastically around 
some mean yield limit. Promising variations on this theme abound. As a simple ease of viscoelasticity, 
consider the Maxwell unit depicted in Fig. 3. We allow e(u, t)~ as governed by (6), to play the role 
of a multidimensional elastic spring in the continuum generalization of this unit, while r(u, t) plays 
the role of the dashpot. The viscous behavior of the dashpot is simulated by an internal process which 
evolves the reference component as follows: /~(u,t) = (1/~(u))e(u,t). We extend this to simulate the 
four-element viscoelastic model shown in the figure, according to (1). Thus, the vis- coelastic process 
establishes a feedback path from e into r. During each time interval, a portion of the instantaneous 
elastic displacement is transferred into the reference com- ponent, thereby maintaining a deformation 
history. This is analogous to the incremental strain theory or flow the- ory of elasticity. More complex 
viscoelastic behaviors are produced readily by introducing nonlinear functions into the feedback loop. 
Bizarre yet interesting behavior--such as negative viscosity--is possible by choosing physically unrealizable 
parameters. We have incorporated a multidimensional extension of the uniaxial elastoplastic model of 
Fig. 4. Here, the refer- ence component e absorbs the extension of the plastic unit as soon as the applied 
force exceeds the yield limit. In the multidimensional case, we can incorporate a yield condi- tion which 
can either be dependent on the stresses internal to the model (such as the Tresca or yon Mises yield 
con- ditions [21]) or on the internal deformation e. The model behaves elastically until the yield condition 
is exceeded lo- cally. Then the material parameters wj are reduced locally to simulate linear strain 
hardening. The primary formulation of elastically deformable mod- els involves deformation energy functionals 
that contain fundamental tensors of curves, surfaces, and solids (see [11]). For example, the elastic 
functional for a solid model was of the form E(x) = fn I G- GO I Zw du, a squared normed difference between 
the first-order or metric tensors (ma-trices) G(x) of the deformed body and G O of the undo- formed body. 
The weighted norm I" Iw provides functions wi(u) that determine material properties. The approach for 
introducing inelastic behavior is essentially the same as for the hybrid model: We evolve the metric 
tensor G O (and other tensors in E(x) associated with the undeformed body) according to the model's internal 
stresses or defor- mations. For plasticity and fracture, this includes dynamic adjustments to the material 
property functions. 5. Implementation Overview Our implementation of inelastic models is built on a sub- 
strafe of numerical algorithms that we have developed for simulating elastically deformable models [11, 
14]. This sec-   SIGGRAPH '88, Atlanta, August 1-5, 1988 by d d-~(mv) + ~ L p6du+ /ftT:kdu =fV, (13a) 
(Iw)+~ #q×6du+ ,7q×idu=f w, (13b) L ~(~) + ,+ + ~ × × q) +2pz~xA+p&#38;xq+Tx+geE=fe. (13c) Here m = fn 
pdu is the total mass of the body, and the time-varying, 3 x 3 symmetric matrix I with entries Iij = 
ffl/.t(6ijq 2- qiqj)du, where q = [qt)qa,qs] and ~ij is the Kronecker delta, is known as the inertia 
tensor. The applied force transforms to a deformational term fe (u, t) = if(u, t), as well as net translational 
fv(t) = fa f(u, t) du and net torque l~(t) = f~ q(u, t) x f(u, t) du terms on the center of mass. The 
ordinary differential equations (13a) and (13b) describe v and W, the translational and rotational motion 
of the body's center of mass. The terms on the left hand sides of these equations pertain to the total 
moving mass of the body as if concentrated at c, the total (vibrational) motion of the mass elements 
about the reference compo- nent r, and the total damping of the moving mass elements. The partial differential 
equation (13c) describes (relative to ¢) the deformation e of the model away from r. Each term is a dynamic 
per-mass-element force: (i) the basic in- ertial force, (it) the inertial force due to linear acceleration 
of ~b, (iii) the centrifugal force due to the rotation of ~b, (iv) the Coriolis force due the velocity 
of the mass elements in ¢, (v) the transverse force due to the angular acceleration of ¢, (vi) the damping 
force, and (vii) the restoring force due to deformation away from r. References i. Barr, A., Barrel, 
R., Haumann, D., Kass, M., Plait, J., Terzopoulos, D., and Witkin, A., Topics in phys- ically-based modeling, 
ACM SIGGRAPH '87Course Notes, Vol. 17, Anaheim, CA, 1987. 2. Fournier, A., Bloomenthal, J., Oppenheimer, 
P.)Reeves) W.T., and Smith, A.R., The modeling of nat- ural phenomena, ACM SIGGRAPH '87 Course Notes, 
Vol. 16, Anaheim, CA, 1987.  3. Armstrong, W.W., and Green, M., "The dynamics of articulated rigid 
bodies for purposes of animation," The Visual Computer, I, 1985, 231-240. 4. Wilhelms) J~) and Barsky) 
B.A.) "Using dynamic anal- ysis to animate articulated bodies such as humans and robots," Proc. Graphics 
Interface '85, Montreal, Canada, 1985, 97-104.  5. Girard, M., and Maciejewski, A.A., uComputational 
modeling for the computer animation of legged figures," Computer Graphics, 19, 3, 1985, (Proc. SIGGRAPH), 
263- 270. 6. Barrel, R.., and Barr, A., Dynamic Constraints, 1987, in [11 . 7. Hoffmann, C.M.) and 
Hopcroft, J.E., "Simulation of physical systems from geometric models," IEEE Yourn. Robotics and Automation, 
RK-3, 3, 1987, 194-206. 8. Issacs, P.M., and Cohen, M.F., "Controlling dynamic simulation with kinematic 
constraints, behavior functions, and inverse dynamics," Computer Graphics, 21, 4, 1987, (Proc. SIGGRAPH) 
215-224. 9. Well) J., "The synthesis of cloth objects," Computer Graphics, 20, 4, 1986, (Proc. SIGGRAPH), 
49-54.  10. Feynman, C.R., Modeling the Appearance of Cloth, MSc thesis, Department of Electrical Engineering 
and Com- puter Science, MIT, Caxnhridge, MA, 1986. 11. Terzopoulos, D.) Platt, J., Barr, A.) and Fleischer) 
K.) "Elastically deformable models," Computer Graphics, 21, 4, 1987, (Proc. SIGGRAPH) 205-214. 12. Haumann, 
D., Modeling the physical behavior of flexible  objects, 1987, in [I]. 13. Well) J., "Animating cloth 
objects," unpublished manu-script, 1987. 14. Terzopoulos, D., and Witkln, A., "Physically-based models 
with rigid and deformable components," Proc. Graph- ics Inlet[ace '88, Edmonton, Canada, June, 1988. 
 15. Alfrey, T., Mechanical Behavior of High Polymers, In- terscience, New York, NY, 1947. 16. Kardestuncer, 
H., and Norrle, D.H., (ed.), Finite Element Handbook, McGraw-Hill, New York, NY, 1987. 17. Christiansen, 
H.N.) "Computer generated displays of structures in vibration," The Shock and Vibration Bul-letin, 44, 
2, 1974, 185-192. 18. Chrlstlansen, H.N., and Benzley) S.E., "Computer graphics displays of nonlinear 
cMculations," Computer Meth- ods in Applied Mechanics and Engineering, 34, 1982, 1037-  1050. 19. Shephard, 
M.S., and Abel) JoF., Interactive computer graphics for CAD/CAM, 1987, in [16], Section 4.4.3. 20. Christensen, 
R.M., Theory of viscoelasticity, 2nd ed., Academic Press, New York, NY, 1982. 21. Mendelson) A.) Plasticity--Theory 
and Application, Mac- millan, New York, NY, 1968. 22. Sih, G.C.) Mechanics of Fracture, MartLnus Nijhoff, 
The Hague, 1981. 23. Goldsteln, H.) Classical Mechanics, Addison-Wesley, Read- ing, MA, 1950. 24. Courant) 
R., and Hilbert) D.) Methods of Mathemat- ical Physics, Vol. I, Interscience, London, 1953.  25. Terzopoulos, 
D.) "Regulaxizatlon of inverse visual prob- lems involving discontinuities," IEEE Trans. Pattern Anal- 
ysis and Machine Intelligence, PAMI-8, 1986, 413-424. 26. Lapidus, L., and Pinder, G.F., Numerical Solution 
of Partial Differential Equations in Science and Engineering, Wiley, New York, NY, 1982. 27. Press) W.It.) 
Flannery) B.P., Teukolsky, S.A.) and Vetterling, W,']:.) Numerical Recipes: The Art of Scien- tific Computing, 
Cambridge University Press, Cambridge, UK) 1986. 28. Zienkiewlcz) O.C., The Finite Element Method; Third 
edition, McGraw-Hill, London, 1977. 29. Hackbusch, W., Multigrid Methods and Applications, Springer-Verlag, 
Berlin, 1985.  30. Hansen, C., and Henderson) T., UTAH Range Data- base, Dept. of Computer Science, 
University of Utah, Salt Lake City, Utah, TR No. UUCS-86-113, 1986. 31. Terzopoulos, D., "Multilevel 
computational processes for visual surface reconstruction," Computer Vision, Graph- ics, and Image Processing, 
24, 1983, 52-96. 32. Fleischer) K., and Witkin, A.) "A modeling testbed," Proc. Graphics Interface '88, 
Edmonton, Canada, June, 1988.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378524</article_id>
		<sort_key>279</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Constraints methods for flexible models]]></title>
		<page_from>279</page_from>
		<page_to>288</page_to>
		<doi_number>10.1145/54852.378524</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378524</url>
		<abstract>
			<par><![CDATA[Simulating flexible models can create aesthetic motion for computer animation. Animators can control these motions through the use of <i>constraints</i> on the physical behavior of the models. This paper shows how to use mathematical constraint methods based on physics and on optimization theory to create controlled, realistic animation of physically-based flexible models. Two types of constraints are presented in this <i>paper: reaction constraints (RCs)</i> and <i>augrmented Lagrangian constraints</i> (ALCs). RCs allow the fast computation of collisions of flexible models with polygonal models. In addition, RCs allow flexible models to be pushed and pulled under the control of an animator. ALCs create animation effects such as volume-preserving squashing and the molding of taffy-like substances. ALCs are compatible with RCs. In this paper, we describe how to apply these constraint methods to a flexible model that uses finite elements.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[constraints]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[elasticity]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Constrained optimization</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14042181</person_id>
				<author_profile_id><![CDATA[81100090687]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Platt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14034821</person_id>
				<author_profile_id><![CDATA[81100070192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Barr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arrow, K., Hurwicz, L., Uzawa H., Studies in Linear and Nonlinear Programming, (Stanford University Press, Stanford, CA, 1958).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319132</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Badler, N., "Multi-Dimensional Input Techniques and Articulated Figure Positioning By Multiple Constraints," 1986 Workshop on Interactive 3D Graphics (Chapel Hill, NC, 1986).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barzel, R., Barr, A., "Modeling with Dynamic Constraints," in Topics in Physically Based Modeling, SIGGRAPH Tutorial 17 Notes, (1987).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bertsekas, D., "Multiplier Methods: a Survey," Automatica, 12, 133-145, (1976).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[de Boor, C., A Practical Guide to Splines, (Springer-Verlag, NY, 1978).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[do Carmo, M., Differential Geometry of Curves and Surfaces, (Prentice-Hall, Englewood Cliffs, N J, 1974).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Feynman, C., Modeling the Appearance of Cloth, MSc Thesis, EECS Dept. , (MIT, Cambridge, MA, 1986).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fung, Y., Foundations of Solid Mechanics, (Prentice-Hall, Eaglewood Cliffs, NJ, 1965).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Girard, M., Maciejcwski, A. "Computational Modelling for the Computer Animation of Legged Figures," Proc. SIGGRAPH 1985 263-270, (1985).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goldstein, H, Classical Mechanics, (Addison-Wesley, Reading, MA, 1950).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Haumann, D., "Modeling the Physical Behavior of Flexible Objects", in Topics in Physically-Based Modeling, SIGGRAPH Tutorial 17 Notes, 1987.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hestenes, M., Optimization Theory, (Wiley &amp; Sons, NY, 1975).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Issues, P., Cohen, M., "Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics," Proc. SIGGRAPH 1987, 215-224, (1987).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Press, W., Flannery, B., Teukolsky, S., Vetterling W., Numerical Recipes, (Cambridge University Press, Cambridge, 1986).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, D., Platt, J., Burr, A., Fleischer, K., "Elastically Deformable Models," Proc. SIGGRAPH 1987, 205-214, (1987).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Truesdell, C., "The Non-Linear Field Theory of Mechanics," in Encyclopedia of Physics, S. Fl~gge, ed., III/3 (Springer-Verlag, Berlin, 1965).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15922</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Well, J., "The Synthesis of Cloth Objects," Proc. SIGGRAPH 1986, 49-54 (1986),]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J., Barsky, B., "Using Dynamic Analysis to Animate Articulated Bodies such as Humans and Robots," Proc. Graphics Interface '85, 97-104 (Montreal, 1985)]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[White, R., An Introduction to the Finite Element Method with Applications to Non-linear Problems, (John Wiley &amp; Sons, NY, 1985),]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Witkin, A., Fleiseher, K., Barr, A., "Energy Constraints on Parametrized Models," Proe. SIGGRAPH 1987, 225-232, (1987).]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz, O., The Finite Element Method, Third Edition, (McGraw-Hill, London, 1977).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Constraint Methods for Flexible Models John C. 
Platt Alan H. Barr California Institute of Technology Pasadena, CA 91125 Abstract Simulating flexible 
models can create aesthetic motion for computer an- imation. Animators can control these motions through 
the use of con- straints on the physical behavior of the models. This paper shows how to use mathematical 
constraint methods based on physics and on opti- mization theory to create controlled, realistic animation 
of physically- based flexible models. Two types of constraints are presented in this pa- per: reaction 
constraints (RCs) and augmented Lagrangian constraints (ALCs). RCs allow the fast computation of collisions 
of flexible models with polygonal models. In addition, RCs allow flexible models to be pushed and pulled 
under the control of an animator. ALCs create ani- mation effects such as volume-preserving squashing 
and the molding of taffy-like substances. ALCs are compatible with RCs. In this paper, we describe how 
to apply these constraint methods to a flexible model that uses finite elements. KEYWOKDS: Elasticity, 
Modeling, Dynamics, Constraints, Simula- tion CK categories: G.1.6 --Constrained Optimization; 1.3.7--Three- 
Dimensional Graphics and Realism (Animation)  1 Introduction A primary goal of simulating flexible models 
is to animate physically realistic motions. Examples include simulating the musculature of a human body 
to create realistic walking; simulating the flow of viscous liquids, such as lava over volcanic rocks; 
or simulating a sculptor mold- ing clay. This paper takes a step towards these goals, by adding constraint 
properties to flexible models; and other properties, such as moldability and incompressibility. Using 
these properties, we can now simulate materials, such as clay, taffy, or putty, that have been very difficult 
to simulate using previous computer graphics models. 1.1 Desirable Properties of Flexible Models In order 
to create pleasing and supple motions discussed above, we incorporate many of the following properties 
for our flexible models: Physical Realism --Flexible models should be able to move in natural, intuitive 
ways. Using the theory of elasticity to animate flexible models is very helpful in creating natural motion. 
Permission to copy without fcc all or part of this material is granted provided that the copies arc not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication 
and its date appear, and notice is given that copying is by permission of the Association for Computing 
Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 
ACM-0-89791-275-6/881008/0279 $00.75 Controllability --Flexible models should be able to follow an animation 
script. Models should be able to follow pre-defined paths exactly, while still wriggling in an interesting 
manner and interacting with other models.  Non-interpenetration --Flexible models should be able to 
bounce off other models while using a small amount of computer time.  Limited Compressibility-- Flexible 
models should be able to have constant volume, even while being squashed. Models that squash without 
retaining their volume look as if they are made of sponge: they do not bulge out enough at the sides. 
 Moidabili~y ~ Flexible models should be moldable: external forces should mold the rest shape of the 
model. Models should follow the theory of plasticity, which describes materials that do not return to 
their rest shape after large deformation.   1.2 Force-Based Constraint Methods Constraint methods that 
add external forces to physical systems yield physically realistic motion and allow simulation with simple, 
commer- cially available, differential equation solvers. I constraints I constraints I (RCs) Figure 1: 
A hierarchy of constraint methods There are at least three force-based constraint methods that allow 
the creation of flexible models with the properties listed in the last section. Dynamic constraints [3] 
use inverse dynamics to create critically damped forces which fulfill the constraints. Dynamic constraints 
are easy to use on systems which have simple dynamics. Elastic models have many state variables, however; 
this makes the dy- namics hard to invert. We do not apply dynamic constraints to elastic models in this 
paper.  Reaction constraints, presented in this paper, use a modified pro- jection method for simple 
constraints, such as guiding flexible models along a path and preventing flexible models from pene- trating 
a polygon, l~eaction constraints supply reaction forces that cancel other forces that would violate the 
constraint. Reac- tion constraints require no extra differential equations, but they are limited in scope. 
 Optimization constraints use ideas from optimization theory to constrain physical systems. Physical 
systems perform optimiza- tion, because the total energy of any physical system with dissi- pation decreases. 
  There are two types of optimization constraints. The simplest kind of optimization constraint is the 
well-known penalty method, where an extra energy that penalizes incorrect behavior is added to the physical 
system. The penalty method is analogous to adding rubber bands that attract the physical system to the 
constraints One large disadvantage of the penalty method is that the constraints are enforced in the 
pres- ence of external forces only as the ratios of the strengths of the rubber band to the external 
forces increases to infinity The ALC method is a constrained optimization method that adds differential 
equations that compute Lagrange multipliers of the physical system. These additional differential equations 
cause the system to eventually fulfill multiple constraints, even in the presence of external forces 
 1.3 Previous Work As discussed in the last section, this paper combines physically-based modeling techniques 
with constrained optimization methods There has been a growing interest in physical models in the field 
of computer graphics. Elastic models have been proposed previously [7] [11] [15] [17] that simulate deformable 
models quite well. Of these, [7] and [15] were based directly on variational principles, which are easily 
modified by constrained optimization techniques. The physically-based elastic models are based on classical 
elastic- ity theory A recommended explanation of elasticity may be found in Truesdell [16]; Fung [8] 
is another useful reference for both elasticity and plasticity. In order to make controllable modeling 
and animation, researchers in computer graphics have previously studied constraint methods [2] [9] [18]. 
Witkin, et al. [20] applied the penalty method to parametrized constraints. Barzel and Burr [3] and Isaacs 
and Cohen [13] developed dynamic constraints. We extend their work to flexible models RCs are related 
to techniques that enforce boundary conditions of partial differential equations [21]. ALCs are based 
on the method of multipliers first developed by Ar- row, et al. [1]. A comprehensive review paper was 
written by Bertsekas [4]. 1.4 Preview Sections 1- 5 of this paper discusses optimization and various 
constraint methods. Section 2 explains why optimization theory is applicable to flexible models Section 
3 discusses the penalty method. Section 4 presents ~Cs and section 5 presents ALCs. Section 6 shows the 
appli- cation of the general constraint methods in the first part of the paper to flexible models Section 
7 shows various animation effects made by the constraints. The appendices of this paper contain the mathematical 
details of how to apply RCs and ALCs to flexible models. The appendices de- scribe the finite element 
flexible model, the equations necessary for an- imation control and collision, the equations for incompressibility 
and plasticity, and an explanation of why ALCs work.  2 Flexible Models Minimize Functions This section 
illustrates that simulating physically-based flexible models is an optimization procedure. An optimization 
procedure finds a vector .T. to locally minimize f(x) (1) where z_ is a position in a high-dimensional 
space; and f(~_) is a scalar function, which can be imagined as the height of a landscape as a function 
of position ~ (see figure 2). In figure 2, the arrows represent the action of an optimization procedure, 
where ~_0 is the state of the system before the optimization procedure and .~min is the state of the 
system afterwards. ~0 Xmln Figure 2: An optimization landscape Physically-based flexible models minimize 
a particular function f. Consider the simplest flexible model, a spring. The energy of the spring comes 
in two forms: kinetic energy (the energy of motion) and potential energy (the energy stored in the tension 
of a spring). As a spring oscillates, the kinetic energy turns into potential energy, and back into kinetic 
energy. Because of friction, however, a spring eventually slows down and stops, with all of the energy 
having been converted into heat. The total energy of the spring always decreases. In general, any physical 
system with dissipation always loses energy, yet the total energy is always bounded below Hence, physically-based 
flexible models will minimize their total energy as time increases. Even non-dissipative physical systems 
extremize energy over all paths in space-time. ~ince simulating a flexible model is an optimization procedure, 
we can use optimization concepts to modify the flexible model. A useful concept is that optimization 
procedures, like computer graphics models, can be constrained. A constrained optimizalion procedure finds 
a minimum of a function on a specified subspace. The prototypical constrained optimization problem can 
be stated as locally minimize f(~_), subject to g(~) = 0, (2) where g(z) = 0 is a scalar equation describing 
a subspace of the state space. During constrained optimization, the state vector z should be attracted 
to the subspace g(z) = 0, then slide along the subspaee until it reaches the locally smallest value of 
f(~) on a(~_) = 0 (see figure 9). Solutions to a constrained optimization problem are restricted to a 
subset of the solutions of the corresponding unconstrained optimization problem. Since physically-based 
flexible models minimize a function, we use constrained optimization algorithms as physical constraint 
methods. Applying constrained optimization algorithms to a physical system still decreases the total 
energy of the system, while enforcing external con- straints; thus, optimization constraints do not destabilize 
physical sys- tems. There are other optimization procedures than simply simulating a physical system. 
The simplest optimization algorithm is gradient descent, where the values of ~ ski downhill, in the opposite 
direction of the gradient Uff (see figure 3). ~Yf points in the direction of the maximum increase in 
f. 0.f 5:i --0zi (3)   ~ Computer Graphics, Volume 22, Number 4, August 1988 Inexact Constraints --Forofinite 
constraint strengths ca, the penalty method does not fulfill the constraints precisely. Un-der many circumstances, 
however, constraints should be fulfilled energy contour gradient i) energy "valley" flexible model energy 
"hill" Figure 3: Both Gradient Descent and Flexible Models Minimize a Func- tion The Penalty Method 
This section discusses a traditional constrained optimization technique called the penalty method; the 
method has previously been used in constraining computer graphics models [15][20]. The physical interpretation 
of the penalty method is a rubber band that attracts the physical state to the subspace g(~) = 0. The 
penalty method adds a quadratic energy term that penalizes violations of con- straints [12]. Thus, the 
constrained minimization problem (2) is con- verted to the following unconstrained minimization problem: 
minimize ~penalty(.~) = f(.ff~_) q- e(g(~)) 2. (4) Figure 4: The penalty method makes a trough in state 
space The penalty method can be extended to fulfill multiple constraints by using more than one rubber 
band. Namely, the constrained optl- mization problem minimize f(z), subject to ga(.~.) = 0; a = 1,2,..., 
n; (5) is converted into unconstrained optimization problem (see figuTe 4) minimize Ep~lty(x) = f(~) 
+ fi c~(g~(~)) ~. (6) ce~i The penalty method has a few convenient features. Inerac~ Constraints --There 
are situations in which it is not necesssary to exactly fulfill constraints; sometimes it is desirable 
to compromise between constraints.  Ease of Use --.Adding a rubber band to a physical system is simple 
and requires no extra differential equations.  However, the penalty method has number of disadvantages. 
exactly. Using multiple rubber band constraints is like building a machine out of rubber bands; the machine 
would not hold to- gether perfectly. Sliffness of Equations --Second, as the constraint strengths i~- 
crease, the differential equations become sti1~, that is, there are widely separated time constants. 
Most numerical methods must take time steps on the order of the fastest time constant, while most modelers 
are interested in the behavior at the slowest time constant. As a result of stiffness, the numerical 
differential equa- tion solver takes very small time steps, using a large amount of computing time without 
getting much done. 4 Reaction Constraints When flexible models are constrained to be on the outside of 
another model, or when they are constrained by an animator, they should fulfill these constraints quickly 
and exactly. As discussed in the last section, the penalty method has difficulties with swiftly fulfilling 
precise con- strMnts. RCs are a constraint method that retains the advantages of the penalty method while 
avoiding many of the disadvantages. RCs can force a point to follow a path, or to lie on the outside 
of a polygonal model. RCs are fast and simple to use, and do not require additional differential equations 
to be added to the physical system. However, only one RC can be applied to a mass point at any time. 
RCs cancel forces that violate constraints and add forces that would critically damp the distance from 
the state to the constraint surface. RCs are a combination of the projection method [12] and dynamic 
constrainta. RCs work on individual mass points. Since elastic models are fre- quently discretized into 
mass points, RCs are applicable to constraining elastic models on a polnt-by-point basis.  _F_un~onstr~in~ 
> _P_ \/ / F constrained _~output Figure 5: The reaction constraint cancels undesirable force components. 
A reaction constraint is a procedure that processes the net force at a point, .K-input created by physics 
or other constraint techniques, in order to yield a constrained force at a point F output, needed to 
fulfill a particular constraint. The RC first projects out undesirable compo- nents of.if_input to yield 
_~unc~nstralned (see figure 5). Next, _~_constrainedis computed to yield critically damped motion that 
fulfills the constraint. Finally, the control force routput is the sum of the constrained and unconstrained 
forces: ~o~tput = Eeon~tr~nea + Eunconstr~i~d (7) To fulfill Newton's second law, the reaction force 
_~_inptt~--~Fouepueshould be applied to the object that is interacting with the flexible model. Let 
the vector D be the deviation in the position of the mass point. That is, the vector D points from the 
mass point towards where the mass point should be. The constrained force that eventually sets ._~ to 
Zero is d  where k is the strength of the constraint and c is the damping. If c = x/2k, then the mass 
point fulfills the constraint with critically damped motion. If the damping is too low, then the constraint 
force overshoots. For critically damped motion, if k is increased, then the time needed to fulfill the 
constraint is decreased. In the appendices, we describe the equations necessary for imple- menting two 
useful reaction constraints (see figure 6): Path Following --In constraining flexible models, we frequently 
want to constrain a mass point to follow a specified spatial path parameterized by time, without speeding 
up or slowing down. The pre-defined path is a useful constraint in animation, where flexible models need 
to be picked up and moved around. If only a few mass points of the flexible models are constrained, then 
the rest of the model is free to wriggle in a physically realistic manner. The equations for the path-following 
reaction constraint are contained in Appendix A. Attraction ~o a Plane --Another useful constraint is 
to force a mass point to lie on a plane. A mass point inside of a polygonal model can be forced outside 
of the polygonal model by using a planar reaction constraint. The equations for the planar reaction constraint 
are contained in Appendix B. S path following plane repulsion Figure 6: Examples of Reaction Constraints 
 Using reaction constraints is an easy way to implement simple con- straints. Similar to the penalty 
method, no extra differential equations are required. Unlike the penalty method, the constraint is fulfilled 
in the presence of outside forces. If a flexible model is being lifted by a reaction force against gravity, 
then the lifting path is followed, even if gravity increases by a factor of ten. The reaction constraint 
thus re-duces the amount of parameter adjustment needed in modeling elastic objects. Reaction constraints 
are an extension of the projection method of constrained optimization, where any motion outside an allowed 
region is projected back into the region. Keaction constraints are more ap-propriate for physical models 
than the projection method, because the projection method needs to manipulate the physical state variables 
directly. Reaction constraints manipulate only forces, hence are com- patible with both dynamic constraints 
[3] and with ALCs. In addition, reaction constraints do not need special numerical routines. Reaction 
constraints are much faster than the penalty method for collisions. The penalty method tries to cancel 
a large penetration force by adding a force that is a rapidly changing function of position. Small numerical 
step sizes are needed for the penalty method in order to pre- vent unstable oscillation. However, reaction 
constraints cancel a pen- etration force, independent of the depth of the penetration. Reaction constraints, 
therefore, can take much larger step sizes.  5 Augmented Lagrangian Constraints In the animation of 
flexible models, more than one constraint per mass point is needed. Constraints may be more complex than 
simple path following or repulsion from a plane. In addition, we wish to enforce real properties of flexible 
models, such as incompressibility and moldability. This section presents a type of constraint, called 
an augmented Lagragian constraint, that enforces the complex, multiple constraints needed for flexible 
models. The differential equations used in ALCs were first developed by Arrow in 1958 [1]. 5.1 Lagrange 
Multipliers Lagrange multiplier methods, like the penalty method, convert con-strained optimization problems 
into unconstrained extremization prob- lems. Namely, a solution to the equation (2) is also a critical 
point of the energy 6L~rnn~e(g) = f(~_) + Ag(z). (9) A is called the Lagrange multiplier for the constraint 
g(x) = 0 [12]. A direct consequence of equation (9) is that the gradient of f is coltinear to the gradient 
of 9 at the constrained extrema (see Figure 7). The constant of prgportionality between Vf and Vg is 
-A : V£La~r~ge = 0 = V/+ AVg. (I0)  We use the collinearity of Vf and Vg in the design of the ALC. 
/ contours off/ / )= 0 Figure 7: At the constrained minimum, Vf = -AVg ]  A simple example shows that 
Lagrange multipliers provide the extra degrees 'of freedom necessary to solve constrained optimization 
prob- lems. Consider the problem of finding a point (x, y) on the line x--by = 1 that is closest to the 
origin. Using Lagrange multipliers, gLa~range= Z 2 + y2 + A(z ÷ y --I) (Ii) Now, take the derivative 
with respect to all variables, z, y, and A. 3gLa~r~n~e = 2x + A = 0 (12) 0= ~gLagr~nge  = 2V+A=0 03) 
0y 0~La~ran~e = Z + y --1 = 0 (14) 0A With the extra variable A, there are now three equations in three 
un- knowns. In addition, the last equation is precisely the constraint equa- tion.   '~ ~ Computer 
Graphics, Volume 22, Number 4, August 1988 5.2 Gradient Descent Does Not Work with La-grange Multipliers 
Applying gradient descent in equation (3) to the energy in equation (9) yields coSLagrange Of COg (15) 
co~Lagrange = -0A = --g(:e_). (16) Note that there is an auxiliary differential equation for X, which 
is necessary to apply the constraint g(x) = O. Also, recall that when the system is at a constrained 
extremum, XTf _-- --A~Tg, hence, dei = 0. Solutions to the constrained optimization problem (2) are saddle 
points of the energy in equation (9), which has no lower bound [1]. If the vector x_ is held fixed where 
g(x) -~ 0, the energy can be decreased to -oo by sending A to +oo or -oo. Gradient descent does not work 
with Lagrange multipliers, because a critical point of the energy in equation (9) need not be an attractor 
for equations (15) and (16). A stationary point must be a local minimum in order for gradient descent 
to converge. 5.3 The Basic Lagrange Constraint , . , Figure 8: The sign flip from equation (16) to equation 
(18) makes Lagrange multipliers stable We present an alternative to differential gradient descent that 
estimates the Lagrange multipliers, so that the constrained minima are attractors of the differential 
equations, instead of "repulsors." The differential equations that solve (2) are Of (9g (17) = +g(~_). 
(18) Equations (17) and (18) are similar to equations (15) and (16). As in equations (15) and (16), solutions 
to problem 2 are stationary points of equations (17) and (18). Notice, however, the sign inversion in 
the equation (18), as compared to equation (16). The equation (18) is performing gradient ascent on X. 
The sign flip makes the method stable, as shown in Appendix G (see figure 8) The system of differential 
equations (17) and (18) gradually fulfills the constraints. Notice that the function g(x) can be replaced 
by kg(x_), without changing the location of the constrained minimum. As k is increased, the state begins 
to undergo damped oscillation about the constraint subspace g(x) = 0. As k is increased further, the 
frequency of the oscillations increase, and the time to convergence increases. 5.4 Extensions to the 
Algorithm One extension to equations (17) and (18) is an algorithm for constrained minimization with 
multiple constraints. Adding an extra differential constraint subspace N o ~ o f algorithm initial state 
%finalstate'~ Figure 9: The state is attracted to the constraint subspace equation for every equality 
constraint and summing all of the constraint forces creates the energy ~multiple : f(~_) + E ~aga(_X_), 
(19) which yields differential equations a f ~ Og. _ ao~-, (20) L~ = +go(z_). (21) Another extension 
is constrained minimization with inequality con- straints. As in traditional optimization theory [12], 
one uses addi-tional slack variables to convert inequality constraints into equality constraints. Namely, 
a constraint of the form h(z) _> 0 can be ex- pressed as g(~_) = h(~_) -?. (22) Since z 2 must always 
be positive, then h(_z) is constrained to be posi- tive. The slack variable z is treated like a component 
ofz in equation (17). An inequality constraint requires two extra differential equations, one for the 
slack variable z and one for the Lagrange multiplier ~. Alternatively, the inequality constraint can 
be represented as an equality constraint. For example, if h(x_) is constrained to be greater than zero, 
then the optimization can be constrained with {[h(x)] 2, if h>0  (23) g(~) = 0, otherwise. Combining 
the basic Lagrangian constraints with the penalty method yields augmented Lagrangiart constraints (ALCs). 
ALCs have better convergence properties than basic Lagrangian constraints, as shown in Appendix G. The 
basic Lagrangian constraints are com-pletely compatible with the penalty method. If one adds a penalty 
force to equation (17) that corresponds to an quadratic energy e 2 Epenalty : ~(g(.x)) , (24) then the 
set of differential equations for an ALC is o~°/ (25)  --.°g eg~,Og x ~ -a b~ S - The extra force 
from the penalty does nat change the position of the stationary points of the differential equations, 
because the penalty force is zero when g(x) = 0, independent of the value of c. There is a minimum necessary 
penalty strength c required in some cases for the ALC to converge (see appendix G). The minimum penalty 
strength in the ALC is usually much less than the strength needed by the penalty method for an accurate 
solution [4]. ALCs are applicable to more general constraints than RCs, especially when more than one 
non-linear constraint is associated with each mass point. Constraining Flexible Models with The complete 
differential equation for an incompressible element is given in Appendix E. Augmented Lagrangian Constraints 
Es _r7 Es r l Figure 10: An element of flexible material ALCs are ideal for the non-linear constraints 
that arise from adding new properties to flexible models. The augmented Lagrangian constraints are applied 
to the differential equations that govern an element of ma- terial. Flexible models are created by aggregating 
these elements in a grid, which may be difficult in the case of complex rest shapes [19]. The internal 
forces on a element are fully derived in Appendix C. The forces depend on the average metric tensor, 
Gq(r_l,r~,...rs), which describes the current shape of an element, and is computed for each element of 
material using the finite element method (see figure 10) [19]. Each element of material also has a rest 
state, which is described by Rq. For a Hookean elastic material, the internal force encourages the metric 
tensor of each element to be close to the metric tensor of the rest state [15]. ~ force motion motion 
rest state I force Figure 11: Incompressibility preserves the volume of an element Hookean elasticity, 
however, does not fully describe the range of materials that are desirable to animate. For example, a 
Hookean elastic model can be easily compressed. If an elastic model undergoes violent deformation, as 
is common in computer graphics, then it will behave more like ~. sponge than like gelatin. If an incompressible 
material is desired (see figure 11), then ALCs are added to the equations for an elastic element. The 
volume squared of one element is the determinant of the metric tensor G~j of that element [6]. To constrain 
the volume of an element to be a constant Vo, we apply the augmented Lagrangian method, using the constraint 
g = det Gij --V02 = 0. (27) deformations of elastic object deformations of a moldable object do not 
change rest state change the rest state Figure 12: The rest shape of plastic materials changes after 
strong deformation. Many materials, such as taffy and putty, are moldable. Moldable materials do not 
return to their rest shape after being strongly deformed (see figure 12). Augmented Lagrangian constraints 
can be applied to each element's rest state so that it roughly approximates the theory of strongly deformed 
materials. A moldable element has a rest metric .R/j that is constrained to be close to the metric Gij 
[8]. Mathematically, there is an inequality constraint, based on the von Mises ~ yield criterion from 
the theory of plasticity [8], P = (c,~ -P~)(a,j -R~) -P0 < 0. (2S) Using the method described in equation 
(23), we use the constraint function [ 1/2P2; if P > O, (29) 7/= L0; if P_< 0. For plasticity, there 
are differential equations for R/i derived from ap- plying equations (20) and (21) to the constraint 
in equation (29). The general differential equations for ~ moldable element are given in Ap- pend/x F. 
The general equations for applying an ALC to a flexible model are given in appendix D. To apply an ALC 
to a flexible model, forget that the position and velocity are related, and simply apply equations (25) 
and (26) directly. In general, using ALCs on flexible models.results in equations of the form - :~ = 
vl ud=_,v_) (30)  6i = Fi - ~, -~,~(~,~_) (31) where ui and vi are functions determined by applying 
various ALCs. Equations (30) and (31) do not appear to be in the form of a standard physical system. 
However, we can change the differential equations in (30) and (31) into one second-order differential 
equation: d ~i "4- ¢~i ---- Fi -eui -w(z, ~. + U) -~ui(z, v). (32) The left-hand side of equation (32) 
is a standard form for a physical system; therefore, ALCs add only forces to flexible models. 7 Results 
We have simulated all of the constraints discussed in this paper using standard differential equations 
solvers [14]. Since differential equations are simulated over a time interval, the results are in the 
form of anima- tion. The figures in this section are individual frames from a sequence. Figures 13 and 
14 show frames from an animation of a compressible elastic cube of gelatin which is lifte d up and then 
bounced off a table. The lifting of the cube is done with a path-following reaction constraint, and the 
table is implemented with a reaction constraint that keeps the cube above a plane. Notice that since 
the cube in compressible, its volume can vary through the course of the simulation. Figure 15 shows a 
compressible seat cushion being squashed with a sphere. The sphere is a physical model with mass. An 
RC prevents the sphere from penetrating the cushion. Figure 16 shows an incompressible moldable cube 
striking a surface. Instead of bouncing off the surface, the moldable cube sticks to the  ~ Computer 
Graphics, Volume 22, Number 4, August 1988 surface, with its sides near the surface bulging out. Incompressiblity 
forces the sides to bulge, and the moldability updates the rest shape so that the shape is no longer 
a cube. Both the incompressibility and the moldability are enforced with augmented Lagrangian constraints. 
Figures 17-20 illustrate the moldability of the models. A sphere squashes the model in figure 17; but 
the elastic models bounces back to its rest shape in figure 18. In figure 19, a moldable model starts 
with the same rest shape, and is squashed by the sphere; but in figure 20, the moldable model has a dented 
edge. Conclusions In the past, researchers have made models that simulate the behavior of flexible materials. 
These models automatically move in a physically realistic way, without specifying the exact positions 
and velocities of the model at all times. The "hands-off" nature of the physically-based models, however, 
makes them hard for an animator to control. By adding physical modeling constraints to the elastic models, 
a compromise can be reached between completely specifying the motion of a model and allowing a simulation 
package to run freely. Constraint methods are useful for controlling the flexible models, while retaining 
the physically realistic motion created by the physics. This paper presents two constraint techniques, 
based physics and optimization theory, for constraining the physical simulation of flexi- ble models: 
reaction constraints and augmented Lagrange constraints. Both reaction constraints and augmented Lagrange 
constraints even- tually fulfill specified constraints exactly, unlike the penalty method. Reaction constraints, 
based on the projection method, are a simple way of enforcing path following or repulsion from a polygon. 
Reaction constraints require no extra differential equations, because they project away undesirable components 
of the force. Only one reaction constraint can be applied to a mass point at a time. Reaction constraints 
are useful for guiding flexible models along a path and for reducing the amount of computation time needed 
for collisions. ALCs are a differential version of the method of multipliers from optimization theory. 
ALCs are a general technique for constrained op- timization. In this paper, we use ALCs for constraining 
flexible models to be incompressible and moldable. Compressible elastic models look as if they are made 
out of sponge. To simulate other materials, such as rubber, an augmented Lagrange incompressibility constraint 
should be added to the elastic model. Many natural substances, such has clay and taffy, do not return 
to their rest shape after strong deformations. Purely elastic models are in- adequate for these substances. 
Using ALCs to keep the rest shape near the current shape is an effective model for these moldable substances. 
In addition, by applying forces to these plastic substances, we can mold interesting shapes without numerically 
specifying the rest shape. Acknowledgements We wish to thank Jed Lengyel for rest state models and 
John Snyder for rendering software. This paper was supported by grants from Apple Computer, Hewlett-Packard 
Company, Symbolics Inc., and an AT&#38;T Bell Labs Fellowship. References [1] Arrow, K., IIurwicz, 
L., Uzawa H., Studies in Linear and Non- linear Programming, (Stanford University Press, Stanford, CA, 
1958). [2] Badler, N., "Multi-Dimensional Input Techniques and Articulated Figure Positioning By Multiple 
Constraints," 1986 Workshop on Interactive 3D Graphics (Chapel Hill, NC, 1986). [3] Barzel, R.., Barr, 
A., "Modeling with Dynamic Constraints," in Topics in Physically Based Modeling, SIGGR.APtI Tutorial 
17 Notes, (1987). [4] Bertsekas, D., "Multiplier Methods: a Survey," Automatica, 12, 133-145, (1976). 
[5] de Boor, C., A Practical Guide to Splines, (Springer-Verlag, NY, 1978). [6] do Carmo, M., Differential 
Geometry of Curves and Surfaces, (Prentice-Hall, Englewood Cliffs, N J, 1974). [7] Feynman, C., Modeling 
the Appearance of Cloth, MSc Thesis, EECS Dept. , (MIT, Cambridge, MA, 1986). [8] Fung, Y., Foundations 
of Solid Mechanics, (Prentice-Hall, Eagle- wood Cliffs, NJ, 1965). [9] Girard, M., Maciejcwski, A. "Computational 
Modelling for the Computer Animation of Legged Figures," Proc. SIGGRAPH 1985 263-270, (1985). [10] Goldstein, 
H, Classical Mechanics, (Addison-Wesley, Reading, MA, 1950). [11] Haumann, D., "Modeling the Physical 
Behavior of Flexible Ob- jects", in Topics in Physically-Based Modeling, SIGGRAPH Tuto- rial 17 Notes, 
1987. (12] Hestenes, M., Optimization Theory, (Wiley &#38; Sons, NY, 1975). [13] Issues, P., Cohen, M., 
"Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynam- ics," 
Proc. SIGGRAPH 1987, 215-224, (1987). [14] Press, W., Flannery, B., Teukolsky, S., Vetterling W., Numerical 
Recipes, (Cambridge University Press, Cambridge, 1986). [15] Terzopoulos, D., Platt, J., Burr, A., Fleischer, 
K., "Elastically Deformable Models," Proc. SIGGRAPH 1987, 205-214, (1987). [16] Truesdell, C., "The Non-Linear 
Field Theory of Mechanics," in Encyclopedia of Physics, S. Fliigge, ed., III/3 (Springer-Verlag, Berlin, 
1965). [17] Well, 3., "The Synthesis of Cloth Objects," Proc. SIGGRAPH 1986, 49-54 (1986), [18] Wilhelms, 
J., Baxsky, B., "Using Dynamic Analysis to Animate Articulated Bodies such as Humans and Robots," Proc. 
Graphics Interface '85, 97-104 (Montreal, 1985) [19] White, R., An Introduction to the Finite Element 
Method with Applications to Non-linear Problems, (John Wiley &#38; Sons, NY, 1985), [20] Witkin, A., 
Fleiseher, K., Barr, A., "Energy Constraints on Parametrized Models," Proe. SIGGRAPH 1987, 225-232, (1987). 
[21] Zienkiewicz, O., The .Finite Element Method, Third Edition, (McGraw-Hill, London, 1977). Appendices 
 A Equations for a Path Following Re The deviation vector D to a path is the difference between where 
the mass point is and where it should be on the path at that time. Let (_x(t), v_(t)) be the current 
position and velocity of the mass point, and (x*(t),v_*(t)) be the desired position and velocity of the 
mass point. Then, __D = ~_*(t) - r(t) (33) d ~._O_ = v*(t) -v(t) (34) Since we want to control the velocity 
along the path, we do not allow any unconstrained force: F ...... trained = O (35) The final control 
force is: F o.tput = e(~*(t) -~_(t)) + k(~_'(l) -~_(t)), (36) Notice how the control force in this case 
is independent of the input force, F input. SIGGRAPH '88, Atlanta, August 1-5, 1988 B Equations for 
a Planar R C Consider the plane with normalized plane equation P(x(t)) = Ax(t) + By(t) + Cz(t) + D = 
0 . Let the homogeneous operator be Q(x(t)) _ Ax(t) + By(t) + Cz(t). The normal, n, to the plane is (A 
B C)T . We want the distance of the mass point to the plane to be zero : D = nP(x) , (37 ) Q(v) (38 
) dtD n where the vector x is the position of the mass point and the vector v_ is the velocity. The components 
of the input force normal to the plane need to b e controlled . The force tangent to the plane should 
be unconstrained . Funconstrained = Finput ( Finput ' ?O n-(39) Using equation (8) yields Fconstrained 
= (kP (x) + cQ(v))n . (40 ) The output of a planar RC is F' output = Fnput (kP(x) +cQ(v) + Fiaput . 
n) n . (41 ) To constrain a point to lie on one side of the plane, P(x) < 0, we apply the reaction constraint 
only if the mass point is on the wrong side of the plane and if the input force is not lifting the point 
away from the plane : P(x) < 0 and F_''input . n > F'' constrained (42 ) The one-sided planar RC can 
be extended to prevent any mas s points from entering a solid polygonal model. From inside of the model 
, choose the closest polygon, then apply the one-sided planar RC to forc e the mass point to the surface 
of that polygon .  C Finite Elements for Elasticity Following [15], there is a potential energy for 
each flexible element that encourages the metric tensor to be near the rest metric : i] P+j) z , (43) 
where s is the stiffness of the material . The energy in equation (43 ) describes an isotropic material 
with a Poisson ratio of zero . The forc e on the the points that make up the element is the derivative 
of th e potential energy [10] : F+k antic = s > (Gt.i. _ Ri7) aGij (44) a rk id where rk is the position 
of the kth corner . In addition, there is a viscous damping force that , resists changes in the metric 
tensor : SCOUe _ aG ij _ aGij aG ij Fk' ij -1 v,n ark , (45) 1E Gark ar,, i,j where vv ,,, is the velocity 
of the mth corner, and 1 is the viscous damping of the element. If s >> 1, then the material acts like 
a solid. If 1 >> s, then the material acts like a fluid [16] . Using Newton's Second Law , the differential 
equations for an unconstrained viscoelastic element i s d = vi (46) dtri F elastic +(viscous (47) = dt 
v' The viscoelastic forces and the constraint force depend on Gij . Fol­lowing the finite element method, 
the G ij in each element is assume d to be the integrated average of Gij over the entire element . Leta 
be the material coordinates of a point in the element and let r(a) be th e position of the points a . 
Then, from the definition of metric tensor , ar ar dV (48) Gij faai aaj Assuming a position in the 
element is a linear interpolation of the positions of the corners of the element (see figure 11), the 
average Gij can be analytically computed from the positions of the corners . To compute Gij , estimates 
of the spatial derivatives are required : ai = r2i r2i-1, i = 1,2,3,4 (49 ) Q1 = r3 T'I,N2 = r4 N3 
= r7 -725,114 = rs, (50 ) 7i=ri+4 ri, i=1,2,3,4 (51 ) Averages of the spatial derivatives are also 
required : 4 44 a=Eai, b =E3i, c=E7i. (52) i.1 i =1 i.1 Finally, the various components of Gij can be 
computed, assuming the element has unit length, width, and height in material coordinates . Goo a mil 
-a4 -12 13) (53 ) 18 (2a Gil 26 .6 -/9 1/34-Qz . $3 ) (54 ) 18 ( G22 (2c c 7i 74 72 .73) (55) 18 Gol 
= G1a 24[1'6 (crl +02) (/j1+ ) Rq +(Cr3 + a4) (Y3 + Q4)] (56 ) G 02 = G2o (al+a3) (Yi+72 ) 24 ~ +022 
+ (14) ' ( ')'3 + 74)] (57 ) R G12 = G21 C (N1+13)(7'1+)3 ) Z4 ~ (58 ) +(i32 +/24) (72 + P4)] As in 
the continuous case, the diagonal terms of the metric tensor Gij in equations (53) (58) depend on various 
distances in the cube, while the off-diagonal terms depend on angles. Also, the Gij are quadratic functions 
of the ri. Thus, aGij/ari are complicated, although linear , functions of ri . The finite element is 
equivalent to a set of mass points with non ­linear springs between them . D Equations for a Flexible 
Model ALC This appendix illustrates how to apply ALCs to physical systems . A s stated in section 2, 
physical systems perform optimization, but no t gradient descent . ALCs, however, are easily added to 
physical systems . Consider a typical flexible model, with forces Fi (x) and damping e . The differential 
equation for this system is xi = vi, (59 ) Vi = F,1 ev i . (60) Let us constrain the flexible model 
in equations (59) and (60) to lie on the subspace g(x) = O. There are 2N optimizing state variables : 
x i and We can apply an augmented Lagrangian A to the equatio n for x to fulfill g(x) = O. We can also 
add a penalty term (dg/dt) 2 to the v equation to provide extra damping in the direction of violation 
of the constraint . (Notice that this extra damping force is zero when the constraint is fulfilled.) 
The final form of an ALC applied to a physical model is xi = vi -(A+kg)-x , (61) -2 8g v Vi = F, evi 
 c (62) axi axj " a = g(x) . (63 )   '~' Computer Graphics, Volume 22, Number 4, August 1988 As section 
in 4, multiple constraints are performed by creating an auxiliary differential equation for each constraint 
and summing all of the constraint forces. E Equations for Incompressibility The constraint for an incompressible 
element is g = det(aff) -Vg = 0. (64) The derivative of the constraint g with respect to the spatial 
variables r i is needed for an ALC. Let Cij be the matrix of cofaetors of Gij. Then, the derivative is 
  Og = c,~ °o--~ (65) Then, the differential equations for an incompressible element with other forces 
Ft are d = v_~ - (~ + ~g)~,Og (66) ~_~, d ~ 03g Og ~v_~ = ~_,-~b~,, (67) i = ~. (68) F Equations for 
a Moldability The constraint for a moldable element is: P = (Gij -Rij)(Gij -Rij) -P0 < 0 (69) 1/2P2; 
if P > 0, (70) r/= /0; if P_< 0. Again, the derivative of the constraint function with respect to the 
state variables is needed by an ALC. For stretchable models, however, the rest metric is also a function 
of time. We thus need the derivative of o with respect to Rij. Let Q =PifP > 0 and Q=0, otherwise. Then, 
Or/ OGij Or--'~ = Q(Vi~ -Ri~) ~r I (71) Or/ --Q(Gij -RO). (72) Using these derivatives yield the differential 
equations for a mold- able element with other forces Et: d ¢9r/ (73) ~_~z = _~_t-(~+er/)b-~ d Or/ O~ 
 &#38;~ _ or/ (75) = ~, (76) G Why ALCs Work The damped oscillations of equations (20) and (21) can 
be explained by differentiating equation (20) and then substituting (21): Og~ Equation (77) is the equation 
for a damped mass system, with an inertia term, xi; a damping matrix, 02f 02g~ ---~, (7s) Aij --OxiOgxj 
q- and an internal force, ~a gaOge,/Oxi, which is the derivative of the internal energy, __ I70) If the 
system is damped and the state remains bounded, the state falls into a constrained minima. As in physics, 
we can construct a total energy of the system, which is the sum of the kinetic and potential energies. 
If the total energy is decreasing with time, and the state remains bounded, then the system will dissipate 
any extra energy, and will settle down into the state where go(x) = 0, (81) , ~ ~ = o, (82) which is 
a constrained extremum of the original problem in equation (2). The time derivative of the total energy 
in equation (80) is Oga ~. = /~= ~ x,x,+ ~g~(x_)~zi , --~ xiA,,.~,. (83) If damping matrix Aij is positive 
definite, the system converges to fulfill the constraints [1]. ALC always converges for quadratic programming, 
a special case of constrained optimization. A quadratic programming problem has a quadratic function 
f(x) and pieeewise linear continuous functions ga(z), such that __ b2g~ d2f is positive definite and 
~ = 0. (84) 0xi0~j Under these circumstances, the damping matrix Aij is positive definite for all z_ 
and A, so that the system converges to the constraints. It is possible, however, to pose a problem that 
has contradictory constraints. For example, gx(z) = x = 0 and g2(x) = x-1 = 0. (85) In the case of conflicting 
constraints, the ALC compromises, trying to make each constraint g~ as small as possible However, the 
Lagrange multipliers Aa go to ±o~ as the constraints oppose each other. It is possible, however, to arbitrarily 
limit the A~ at some large absolute value. For a given constrained optimization problem, it is frequently 
nec- essary to alter the ALC to have a region of positive damping surround- ing the constrained minima. 
Arrow [1] combines the multiplier method with the penalty method to yield a modified multiplier method 
that is locally convergent around constrained minima [1]. The damping matrix is modified by the penalty 
force to be ~gga Og,~ 02ga (86) dxiOzj Ox~ Ozj + cg oz~.Ozj " Arrow [1] proves a theorem that states 
that there exists a c* > 0, such that if c > c*, the damping matrix in equation (86) is positive definite 
at constrained minima. Using continuity, the damping matrix is positive definite in a region/:/surrounding 
each constrained minimum. Ifthe system starts in the region R and remains bounded and in R, then the 
convergence theorem is applicable, and the augmented Lagrangian method converges to a constrained minimum. 
   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378528</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Collision Detection and Response for Computer Animation]]></title>
		<page_from>289</page_from>
		<page_to>298</page_to>
		<doi_number>10.1145/54852.378528</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378528</url>
		<abstract>
			<par><![CDATA[When several objects are moved about by computer animation, there is the chance that they will interpenetrate. This is often an undesired state, particularly if the animation is seeking to model a realistic world. Two issues are involved: <i>detecting</i> that a collision has occurred, and <i>responding</i> to it. The former is fundamentally a kinematic problem, involving the positional relationship of objects in the world. The latter is a dynamic problem, in that it involves predicting behavior according to physical laws. This paper discusses collision detection and response in general, presents two collision detection algorithms, describes modeling collisions of arbitrary bodies using springs, and presents an analytical collision response algorithm for articulated rigid bodies that conserves linear and angular momentum.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[analytical solution]]></kw>
			<kw><![CDATA[collision detection]]></kw>
			<kw><![CDATA[collision response]]></kw>
			<kw><![CDATA[computer animation]]></kw>
			<kw><![CDATA[dynamical simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43131787</person_id>
				<author_profile_id><![CDATA[81542898156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics & Imaging Laboratory, Computer & Information Sciences Board, University of California at Santa Cruz, Santa Cruz, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135087</person_id>
				<author_profile_id><![CDATA[81341498533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wilhelms]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics & Imaging Laboratory, Computer & Information Sciences Board, University of California at Santa Cruz, Santa Cruz, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[William W. Armstrong and Mark W. Green, "The Dynamics of Articulated Rigid Bodies for Purposes of Animation," Proceedings of Graphics Interface '85, pp. 407-415, Canadian Information Processing Society, Toronto, Ontario, Canada, May 1985.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359048</ref_obj_id>
				<ref_obj_pid>359046</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[John W. Boyse, "Interference Detection Among Solids and Surfaces," Communications of the ACM, vol. 22:1, pp. 3-9, January, 1979.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889291</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[John Canny, "Collision Detection for Moving Polyhedra," MIT Aar. Lab Memo 806, October, 1984.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31472</ref_obj_id>
				<ref_obj_pid>31468</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ingrid Carlbom, "An Algorithm for Geometric Set Operations Using Cellular Subdivision Techniques," IEEE Computer Graphics and Applications, vol. 7, pp. 44-55, Computer Society of the IEEE, Los Alamitos, CA, May 1987.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brice Carnahan and James O. Wilkes, Digital Computing and Numerical Methods, John Wiley and Sons, Inc., New York, 1973.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Scott E. Fahlman, "A Planning System for Robot Construction Tasks," Artificial Intelligence, vol. 5, pp. 1-49, 1974.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Wm. Randolph Franklin, "Efficient Polyhedron Intersection and Union," Proceedings of Graphics Interface 1982, pp. 73-80, 1982.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>540426</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. William Gear, Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-Hall, Englewood Cliffs, NJ, 1971.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31469</ref_obj_id>
				<ref_obj_pid>31468</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Jeffrey Goldsmith and John Salmon, "Automatic Creation of Object Hierarchies for Ray Tracing," IEEE Computer Graphics and Applications, vol. 7, pp. 14-20, Computer Society of the IEEE, Los Alamitos, CA, May 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[I.N. Herstein, Topics in Algebra, Xerox College Publishing, Lexington, MA, 1964.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J.E. Hopcroft, J.T. Schwartz, and M. Sharir, "Efficient Detection of Intersections among Spheres," The International Journal of Robotics Research, vol. 2:4, pp. 77-80, Winter 1983.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Paul M. Isaacs and Michael F. Cohen, "Controlling Dynamie Simulation with Kinematic Constraints," Computer Graphics, vol. 21, no. 4. Proceedings of SIG- GRAPH'87 (Anaheim, CA, July 27-31, 1987)]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Donald Knuth, Fundamental Algorithms, Addison- Wesley Publishing Co., Reading, MA, 1975.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Donald Knuth, Searching and Sorting, Addison-Wesley Publishing Co., Reading, MA, 1975.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359164</ref_obj_id>
				<ref_obj_pid>359156</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Tomas Lozano-Perez and Michael A. Wesley, "An Algorithm for Planning CoUision-Free Paths Among Polyhedral Obstacles," Communications of ACM, vol. 22, no. 10, pp. 560-570, October, 1979.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Richard V. Lundin, "Motion Simulation," Proceedings of Nicograph 1984, pp. 2-10, November, 1984.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[William D. MacMillan, Dynamics of Rigid Bodies, Dover Publications, Inc, New York, 1936.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[W.G. McLean and E. W. Nelson, Engineering Mechanics: Statics and Dynamics, Shaum's Outline Series, McGraw-Hill Book Co., New York, 1978.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Matthew Moore, "A Flexible Object Animation System," Masters Thesis, University of California, Santa Cruz, Computer &amp; Information Sciences, Santa Cruz, California, March, 1988.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ole Osterby and Zahari Zlatev, Direct Methods for Sparse Matrices, Springer-Verlag, Berlin, 1983.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Sergio Pissanetsky, Sparse Matrix Technology, Academic Press, London, 1984.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling, Numerical Recipes, Cambridge University Press, Cambridge, England, 1986.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801293</ref_obj_id>
				<ref_obj_pid>800064</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Craig W. Reynolds, "Computer Animation with Scripts and Actors," Computer Graphics, vol. 16, no. 4, pp. 289-296, Association for Computing Machinery, July, 1982. Proceedings of SIGGRAPH'82]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Craig W. Reynolds, "Flocks, Herds, and Schools: A Distributed Behavioral Model," Computer Graphics, vol. 21, no. 4, pp. 25-34, Association for Computing Machinery. Proceedings of SIGGRAPH'87 (Anaheim, CA, July 27-31, 1987)]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[David F. Rogers, Procedural Elements for Computer Graphics, McGraw-HiU Book Company, New York, 1985.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Robert Skinner, U Cal. Santa Cruz, CIS Dept. personal communication.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325243</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Scott N. Steketee and Norman I. Badler, "Parametric Keyframe Interpolation Incorporating Kinetic Adjustment and Phrasing Control," Proceedings of SIGGRAPH '85, vol. 19, no. 4, pp. 255-262, July, 1985.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[David Sturman, A Discussion on the Development of Motion Control Systems, Association for Computing Machinery, July 1987. SIGgraph '87 Course 10 Notes: Computer Animation: 3-D Motion Specification and Control.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Demetri Terzopoulous, John Platt, Alan H. Barr, and Kurt Fleischer, "Elastically Deformable Models," Computer Graphics, vol. 21, no. 4. Proceedings of SIG- GRAPH'87 (Anaheim, CA, July 27-31, 1987)]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Tetsuya Uchild, Toshiaki Ohashi, and Mario Tokoro, "Collision Detection in Motion Simulation," Computers &amp; Graphics, vol. 7:3-4, pp. 285-293, 1983.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms, "'Towards Automatic Motion Control," IEEE Computer Graphics and Animation April, 1987, vol. 7, no. 4, pp. 11-22, April, 1987.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms, "Using Dynamic Analysis for Animation of Articulated Bodies," IEEE Computer Graphics and Applications, vol. 7, no. 6, June, 1987.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Collision Detection and Response for Computer Animation Matthew Moore and Jane Wilhelms Computer Graphics 
&#38; Imaging Laboratory Computer &#38; Information Sciences Board University of California at Santa 
Cruz Santa Cruz, California 95064 Abstract When several objects are moved about by computer ani- marion, 
there is the chance that they will interpenetrate. This is often an undesired state, particularly if 
the animation is seeking to model a realistic world. Two issues are involved: detecting that a collision 
has occurred, and responding to it. The former is fundamentally a kinematic problem, involving the positional 
relationship of objects in the world. The latter is a dynamic problem, in that it involves predicting 
behavior according to physical laws. This paper discusses collision detection and response in general, 
presents two collision detection algorithms, describes modeling collisions of arbi- trary bodies using 
springs, and presents an analytical collision response algorithm for articulated rigid bodies that conserves 
linear and angular momentum. CR Categories and Subject Descriptors: 1.3.5: [Computer Graphics]: Computational 
Geometry and Object Modeling -Geometric algorithms; 1.3.7: [Computer Graphics]: Three Di- mensional Graphics 
and Realism - Animation. Key Words and Phrases: computer animation, collision detection, collision response, 
analytical solution, dynamical simulation. 1. OVERVIEW Computer animation provides a number of methods 
for controlling object motion.[28] The object's positions and orientations as functions of time may be 
interpolated from keyframes or parameter specification,[27] or may be the out- put of special computer 
programs written by the user,[23] or may be produced by physical simulation of the effect of inter- nal, 
model-derived, and user-specified forces and torques.J1, 12, 16,29, 32] In any such scheme, the main 
ques- tions when animating a single object are how to achieve real- istic motion and how to economize 
on the human animator's time. When several objects are animated at once, the addi- Permission to copy 
without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. tional problem of detecting 
and controlling object interactions is encountered. When no special attention is paid to object in- teractions, 
the objects will sail majestically through each oth- er, which is usually not physically reasonable and 
produces a disconcerting visual effect. Whenever two objects attempt to interpenetrate each other, we 
call it a collision. The most general requirement that arises from this is an ability to detect collisions. 
Most animation systems at present do not provide even minimal collision detection, but require the animator 
to visually inspect the scene for object interac- tion and respond accordingly. This is time-consuming 
and difficult even for keyframe or parameter systems where the user explicitly defines the motion; it 
is even worse for pro- cedural or dynamical animation systems where the motion is generated by subroutines 
and laws defining their behavior. Though automatic collision detection is somewhat expensive both to 
code and to run, it is a considerable convenience for animators, particularly when more automated methods 
of mo- tion control, such as dynamics or behavioral control, are used.[24, 31] This paper describes two 
collision detection al- gorithms. One algorithm deals with triangulated surface representations of objects, 
and is appropriate for flexible or ri- gid surfaces. The other algorithm applies to objects modeled as 
rigid polyhedra. Both algorithms are simple, robust, and not dreadfully expensive. The related issue 
is response to collisions once they are detected. Even keyframe systems could benefit from automat- ic 
suggestions about the motion of objects immediately fol- lowing a collision; animation systems using 
dynamical simu- lation inherently must respond to collisions automatically and realistically. Linear 
and angular momentum must be preserved, and surface friction and elasticity must be reason- able. This 
article presents two methods that satisfy these cri- teria. One is the obvious method, based on temporary 
springs introduced at collision points. The other method is an analyti- cal linear system solution. The 
former method is more gen-eral, working equally well for flexible, rigid, and articulated bodies. The 
latter, limited to rigid and articulated objects, is typically faster. Furthermore, while the spring 
solution as-sumes the ability to use the dynamics equations of motion to predict the motion immediately 
after impact, the analytical solution could be used within a kinematic animation system. @1988 AC M-0-89791-275 
-6/88/008/0289 $00.75 2. COLLISION DETECTION Collision detection involves determining when one ob-ject 
penetrates another. It is clearly an expensive proposition, particularly when large numbers of objects 
are involved and the objects have complex shapes. Collision detection has been extensively pursued in 
the fields of CAD/CAM and robot- ies,[2, 3, 6,7, 11, 30] and it is with some diffidence that we offer 
any more algorithms. Some published algorithms[2, 3] solve the problem in more generality (and at higher 
cost) than we have found to be necessary for computer animation. Oth-ers[6] do not easily produce the 
collision points and normal directions necessary if collision response is to be calculated. VoxeI-based 
methods have also been used,J30] but would not be appropriate for all applications. Finally, many collision 
detection algorithms are quite intricate and must deal with many special cases, which we wished to avoid 
for software engineering reasons. Two collision algorithms are discussed here: the first is designed 
to test the interpenetration of sur- faces modeling flexible objects; the latter is designed to test 
for interpenetration of convex polyhedra. 2.1. Collision Detection for Flexible Surfaces Surfaces are 
modeled as a grid of points connected to form triangles.[19] Collisions between surfaces axe detected 
by testing for penetration of each vertex point through the planes of any triangle not including that 
vertex (thus, self- intersection of surfaces is detected). The surfaces are assumed to be initially separate. 
For each time step of animation, the positions of points at the beginning and the end of the time step 
must be compared to see if any point went through a tri- angle during that time step. If so, a collision 
has occurred. The algorithm is O (nm) for n triangles and m points. A correct test must consider edges 
and triangles, as po- lyhedral objects can collide edge-on without any vertices be- ing directly involved. 
However, in many cases merely testing points versus triangles produces acceptable results. This algo- 
rithm only tests points versus triangles. It is worth noting that the mathematics for testing intersection 
of a moving point with a fixed triangle is the same as for testing a fixed edge versus a fixed triangle. 
Thus the fully general edge versus tri- angle tests could be done at fixed instants in time, with the 
same advantages and disadvantages that will be discussed for the second collision detection algorithm. 
The question of whether a moving point has intersected a surface can be divided into two cases. The easy 
ease requires the surface to be fixed in space, whereas the hard case allows the surface to be moving 
also. When the surface triangle is fixed, the parametric vector equation P + (P" -P) t = Po + (Pi-Po) 
u + (P2---Po) v where P and U a.re the beginning and ending positions of the point and the Pi's define 
the triangle, is set up and solved for the variables u,v,t, u and v are parametric variables for the 
plane defined by the triangle, whereas t is a time variable which is 0 at the beginning of the simulation 
step in question, and 1 at the end. The left hand side is the parametric equation for the path of the 
point, and the right hand side is the parametric equation for any point on the plane. This vector equation 
represents three scalar equations in three unknowns and is solved by matrix inversion. If 0,St_<l and 
u:20 and v:20 and u+v_<l, then the point has intersected the triangle during the time step. The hard 
case is solved by setting up the parametric vec- tor equation P +V t =Po+Vo t +((PI-Po)+(VI-Vo) t )u 
+ ((P2-Po) + (V2-V0) t ) v where P is the point (with velocity V per time step), the Pi s define the 
triangle vertices (with velocity V i per time step), and t,u,v are the parametric variables. Rearranging, 
we can write this as three linear equations in three unknowns. a u +b v +c t=d eu+fv+gt=h iu+jv+kt=l 
 where a =(P1,-Pax)+t(Vlx-Vax) b =(Pz~- Pax) + t(Vz~- Vax) C ~--V x d =Px -(Pax + tVox) e =(Ply-Poy)+t(Vty-Voy) 
f = (P2y- Coy) + t(V2y- roy) g =-Vy h =ey -(eoy +tVoy) i = (P l,-Pax) + t(Vl,- Vo,) J = (P~- Po,) + t(V~- 
Vo,) k =-V z t =P, -(P0= +tVoD The Pw s and Vws are the position and velocity components of the point, 
and the Piw S and Viw s are the position and velocity components of the triangle vertices. The velocities 
are per time step. The linear system above can be solved for t and expand- edto 0 = a Ua-/b )(ha-ca) 
-a (da-ib)(ga --cc ) t + (fa -eb )(ka-ic ) t - (la-id)ffa--eb) Substitution of the actual expressions 
for a through l gives a 5'th order polynomial in t. If further substitutions were made, the equations 
could be written in the form C 5t5 .l- c 4t4 -1-c 3 t3 -I-c2t2-I-Cl tl -I- Co= O Polynomials of order 
5 and above cannot be solved analytically,[10] so a binary search technique is used to find approximate 
values for t.[5] Binary search is used because it is guaranteed to converge, and because, using economizing 
techniques described below, this algorithm is not used often enough to warrant large efforts at optimization. 
The interval from t=0 to t=l is subdivided into a number of sub-intervals, and the left-hand side is 
evaluated at each dividing point. If the sign of that value is different for the two endpoints of some 
subinterval, then some t for which the equation is true must lie within that interval. A binary search 
of values of t within that interval brings the brackets around that value of t closer together, until 
a limit is reached (after 10 iterations, in our system) and an approximate value of t is found. Each 
value of t thus arrived at is used to get values for u and v by back substitution, and then the standard 
0<_t<_l and u~0 and v~0 and u+v~l test is used to determine whether a collision has occurred. To minimize 
the cost of executing the above calcula- tions, a preliminary step is used. Every point is compared to 
every triangle. The perpendicular distance of the point from the plane defined by the triangle is first 
derived, by substitut- ing into the plane equation,[25] for the beginning and the end of the time step. 
If the sign of the perpendicular distance has not changed intersection is assumed not to have occurred. 
If the sign has changed, then the more expensive tests outlined above must be done, but in practice this 
test eliminates most point-triangle pairs. A special kind of bounding box can also be used to minimize 
computation. This bounding box includes the be- ginning and ending position of the triangle. This box 
is then grown by the distance between the beginning and ending posi- tions of the point being tested. 
(This is necessary to avoid the point passing unnoticed completely through the box during the time step. 
A similar growth technique is used in the Lozano- Perez path planning algorithm.)[15] The basic algorithm 
is O (nm), for n triangles and m points. Use of an octree[19] and bounding boxes can reduce the time 
to O (mlogm) to construct the octree, and O (n logm) to search it (assuming that the tree is almost balanced 
and that the bounding boxes are small compared to the space covered by the tree). The search finds all 
point - bounding box pairs that must be examined more closely for possible intersection. All of the points 
in the model are inserted into an octree, which is creat- ed anew for each round of collision detection. 
This octree is based on the points themselves, with each point P having up to 8 subtrees containing points 
in each of the octants of space defined by the P's position. This is an obvious generalization of the 
well known binary search tree.[13, 14] A pseudo-random number generator is used to scramble the order 
of insertion; in this way, Knuth assures us, J13] the tree will be al- most balanced, i.e. the height 
of the octree will be O (logm) al- most always. Each triangle's bounding box is grown by the distance 
between the starting and ending positions of the fastest point being tested. Each bounding box is then 
recursively compared against the octree to find the points inside it. If a point is in- side the box, 
all of its subtrees must be searched recursively. If a point is outside the box, at least half of its 
subtrees do not need to be searched. If a point is found to be inside a box, then the algorithm above 
must be run to determine if the point in- tersected the associated triangle during the time step. r ................. 
D ' Figure 1 Searching a Quadtree Figure 1 illustrates a two-dimensional version of this pro- cedure. 
The points A through 1 were inserted into an initially empty quadtree in alphabetical order, so that 
A is the root ele- ment of the tree. The tree is to be searched for all points inside the dotted box. 
A is inside, so all of it's subtrees must be searched. B is above and to the right of the dotted box, 
so only its lower left subtree must be searched. This finds C, which is inside the box. If C had subtrees, 
they would all have to be searched. The next subtree of A starts with F. F is above the bounding box, 
so both of its lower subtrees must be searched. One is empty, and the other contains only I, which is 
also out- side the box. A's third subtree contains only E, which is below the box. If E had subtrees, 
only the upper ones would need to be searched. A's fourth and last subtree contains only G, which is 
outside the box. If G had subtrees, only the two fight hand ones would be searched. A large, bushy quadtree 
would be very fast to search (if the dotted box were small relative to the area covered by the tree) 
because the unsearched subtrees would often contain large numbers of points. 2.2. Collision Detection 
for Convex Polyhedra The detection of collisions between solids (or closed sur- faces) can be treated 
somewhat differently, for the objects have a distinguishable inside and outside. The problem is somewhat 
more complex than might be initially thought. Edges as well as vertex points may be involved in collisions. 
This method for detecting collisions is based on the Cyrus -Beck clipping algorithm.[25] Collisions of 
articulated objects can be detected by applying this algorithm to all pairs of the polyhedra making up 
the two objects. The two polyhe- dra are assumed to be convex; concave polyhedra can be decomposed into 
collections of convex ones. The basic algo- rithm is O(n2m 2) for n polyhedra and m vertices per po- 
lyhedron. Methods for reducing these exponents are discussed below. The two-dimensional Cyrus -Beck algorithm[25] 
tells whether a point is inside a convex polygon. It takes the dot product of each side's outward normal 
vector (n) with a vector from some point (v) on the side to the point in question (p). If that dot product 
is negative for all edges of the polygon, then the point is inside; if not, it is outside (see Figure 
2). dot pro.duct negative, ~ p n l V Figure 2 Cyrus - Beck Clipping ¢SIGGRAPH '88, Atlanta, August 
1-5, 1988 The collision detection algorithm is developed as a three-dimensional analogy to Cyrus - Beck 
clipping. The al- gorithm works by testing whether representative points of one polyhedron are inside 
the other polyhedron. First points from polyhedron B are tested against polyhedron A, and then the process 
is reversed and points from A are tested for inclusion in B. These two steps combine to cover all special 
cases and give a reliable answer. The algorithm given below terminates when a single point of interpenetration 
is found, which is sufficient for collision detection. If collision response is also required, the algorithm 
below should be modified to find all points of interpenetration. The rest of this section describes the 
test of points from B against A. Let A consist of a set of planar polygonal faces (Pi). Each polygon 
contains a set of vertices (uii) and an outward point- ing normal vector ni. Let B consist of a set of 
vertices (vD, a set of edges (el), and a set of planar polygonal faces ffi). All coordinates of B have 
been transformed into the reference frame of A. The first step tests for the presence of vertices of 
B inside of A. Each vertex of B is compared to every face of A ; if any vertex is on the inward side 
of all such faces, it is inside A and the algorithm terminates having detected a collision. For each 
vertex i of B and for each face j of A, form the dot product (vi-ujl) nj. If this dot product is negative 
the vertex is on the inward side of the face. The second step tests for penetration of the edges of B 
through the faces of A. Each edge of B is divided into a number of smaller line segments by intersecting 
it with the infinite planes corresponding to every face ofA. See Figure 3. This subdivision is done as 
follows. Let some edge of B con-nect the vertices vi and vy, and let us compare it against some face 
of A that has an outward pointing normal n, and a vertex point u~l. First the perpendicular distance 
of each vertex from the plane defining the face is calculated, by substitution into the plane equation.[25] 
If the perpendicular distances differ in sign, then the edge intersects the plane, and the intersection 
point P can be calculated. di = (vi -Ukl)" nk aj = (vj -ak~)' n,  td~t t-- mail + IdyE P =v~ +t (vy 
-v~) V2 planes seen edge-on Figure 3 Edge Subdivision This will result in a collection of intersection 
points P ly- ing along the edge. Intersection points with t < 0 or t > 1 do not lie on the actual edge 
and are discarded. The remaining in- tersections are sorted into order according to their t values, forming 
a sequence of points from one vertex to the other along the edge. Each adjacent pair of points in this 
sequence, including those made by the vertices and the first and last sub- division points, defines a 
sub-segment of the edge. The mid- point of each resulting line segment is checked for being in- side 
A by the same method that was used for vertices, above. Again, if any of these midpoints is inside A 
the algorithm ter- minates with a detected collision. The third step tests for the infrequent case where 
two identical polyhedra are moving through each other with faces perfectly aligned. Here, the centroid 
point of each face of B is tested against A by the method used for vertices, above. If any of these centroids 
is inside A the algorithm terminates with a detected collision. If the algorithm survives the above three 
steps without detecting a collision, and also does not detect one when rev- ersing and comparing A against 
B, then the two polyhedra do not interpenetrate. The above algorithm can be speeded up by a variety of 
tricks. A bounding box or bounding sphere test can be applied to every pair of polyhedraa, yielding an 
immediate "no colli- sion" result in most cases. Many of these bounding box tests can even be eliminated 
by octree or voxel methods. [4,9] When a point is to be tested against a polyhedron, it chn first be 
compared to the polyhedron's bounding box, which will probably eliminate the need to compare it against 
all of the faces. The bounding box can be aligned with the coordinate axes of the polyhedron's local 
frame to make this point elimi- nation test particularly fast. It should be noted that this algorithm, 
or indeed any algo-rithm which point samples the positions of objects over time, could fail if one object 
moved entirely through another during a single time step. This is a rather unusual occurence in pro- 
cedural or dynamic animation because simulation time steps are normally small relative to the velocities 
of the objects. The correct solution to this problem is to generalize to four dimen- sions;J3] the starting 
and ending positions of the polyhedra define 4-D hyper-polyhedra which are checked for interpene- tration 
by higher-dimensional analogues to the algorithm given above. The more practical approach is either to 
ignore the problem (as we do) or to restrict the animation step size so that the change in any object's 
position in any step is small re- lative to the object's size. 3. COLLISION RESPONSE In keyframed and 
procedural animation systems, colli- sion detection is the main requirement; collision response usu- 
ally consists of informing the animator or the motion control program that a collision has occurred, 
and trusting them to handle it. In animation systems using dynamics to generate motion, the system itself 
must respond to a collision by deter- mining new linear and angular velocities for the colliding ob- 
jects. These new velocities must conserve linear and angular momentum, or else the resulting "funny bounce" 
will be very obvious to viewers of the animation. The elasticity of the sur- faces must also be taken 
into account, as this determines how much kinetic energy is lost in the collision; no-one will be-  
@ * Computer Graphics, Volume 22, Number 4, August 1988 lieve that a bean bag should bounce off of a 
hard surface as if it were a golf ball. 3.1. Collision Response Using Springs The most intuitive way 
to handle collisions is with springs. Dynamic simulation systems must already have a method for applying 
external forces to objects. Thus, when a collision is detected, a very stiff spring is temporarily inserted 
between the points of closest approach (or deepest interpene- tration) of the two objects. The spring 
law is usually K/d, or some other functional form that goes to infinity as the separa- tion d of the 
two objects approaches 0 (or the interpenetration depth approaches some small value). K is a spring constant 
controlling the stiffness of the spring. The spring force is ap- plied equally and in opposite directions 
to the two colliding objects. The direction of the force is such as to push the two objects apart (or 
to reduce their depth of interpenetration). Our particular implementation handles variable elasticity 
by making a distinction between collisions where the objects are approaching each other and collisions 
where the objects are receding from each other. For e = 1, i.e. perfectly elastic (hard) collisions, 
the spring constant K will be the same whether the objects are approaching or receding. For e = 0, i.e. 
totally inelastic (soft) collisions, the spring will act as noted above as long as the objects are approaching 
each other, but as soon as they start to move apart the spring force will decrease to 0. For elasticities 
between 0 and 1, the two spring constants will be related by K,e,,d~ = e Kot, pr~h. The spring method 
is easy to understand and easy to pro- gram. It applies equally well to rigid bodies (articulated or 
not) and to flexible bodies, whether modeled as point masses connected by springs, or by energy of deformation 
tech-niques.[29] The main problem with this method is that it is computationally expensive; stiffer springs 
mean stiffer equa- tions, which require smaller time steps for accurate numerical integration. [8] The 
numerical effort required goes up with the violence of the collision; as the springs are compressed more 
and more, the equations become stiffer and stiffer, and smaller and smaller time steps are needed. This 
was the motivation for seeking a better method of collision response. 3.2. Collision Response Using an 
Analytical Solution An analytical solution for the collision of two arbitrary articulated rigid objects 
is available. The analytical solution depends upon the conservation of momentum during a colli- sion, 
and results in a new angular and linear velocity for each body. Thus, the solution bypasses the question 
of collision forces and can be used independent of dynamic simulation, as- surning information concerning 
the bodies mass and mass dis- tribution can be provided. Some combination of spring and analytical collision 
response may be desirable for a dynamic animation system. Analytical solutions are typically faster for 
strong collisions, because the solution need only be found once. However, for gentle collisions, such 
as a body resting quietly atop another body, springs may be desirable.[26] In such a case, gravity may 
eonsistently cause the two objects to interpenetrate and, thus, the analytical solution would have to 
be applied time and time again. A simple spring that counteracts gravity will be faster and more stable 
in this case. This section develops the solution in stages. First, an analytical solution for the collision 
of two rigid bodies is presented; this result is due to MacMillan.[17] MacMillan's solution is extended 
to tree-like articulated rigid objects with revolute joints. Then, the restriction to wee-like objects 
is re- moved, and finally the method is extended to encompass joints with one or two sliding degrees 
of freedom. 3.2.1. Single Rigid Bodies MacMillan gives a general solution for the collision of two arbitrary 
rigid objects. Each object has a linear velocity vector v i, an angular velocity vector toi, a mass m 
i, a center of mass vector cl, and an inertial tensor matrix Ii which is rela- tive to the center of 
mass. All of these quantities, for both ob- jects, are expressed in the same inertial reference frame. 
In addition, each object has a vector Pi which points from its center of mass to the collision point~ 
The solution also re- quires three orthogonal unit vectors i ,j,k that define the "colli- sion frame", 
k will be perpendicular to the plane of collision and i and j will be in that plane. The definition of 
the plane of collision is somewhat arbitrary; for convenience we will define it as follows. If a vertex 
of one object is colliding with a face of the other, then that face defines the plane of collision. If 
an edge of one object is colliding with an edge of the other, these two'edges define the plane of collision. 
If two vertices are colliding, k is directed along the line joining them. See Figure 4. "q ot C2 Figure 
4. Collision Problem - Two Rigid Objects It is desirable to assume that there is only one collision 
point in any given collision; this restriction is not totally necessary, but it simplifies the formulations 
given below. It is reasonable to say that whenever two objects collide in the real world, there is one 
point at which they collide first (other col- lisions may follow within microseconds). Thus, the collision 
detection algorithm must furnish a single collision point between two objects. Because of the time-stepped 
nature of dynamics simulations, this will only be an approximate colli- sion point; a good heuristic 
is to take the point of greatest in- terpenetration of any two objects in the simulation, provided that 
the relative velocities of the two objects at that common point are such that the interpenetration depth 
is increasing. If adaptive step size control is available, this heuristic can be refined by stating that 
interpenetration to greater than some threshold depth iz unacceptable, and causes backtracking and reduction 
of the step size. This allows the simulation to close in on a collision point very close to the surfaces 
of the objects by a process similar to binary search. Multiple collision points can be handled by a straightforward 
extension to the al- gorithms given below, by inventing multiple collision im- pulses and incorporating 
them into the matrix. The solution involves solving a set of 15 linear equations in 15 unknowns. The 
fifteen unknowns are: the new linear velocity vector for each object (~1, V2); the new angular velo- 
city vector for each object (c01, o2); and the impulse vector R. An impulse has units of momentum and 
can be thought of as a huge force applied for a tiny time. Because the collision is as- sumed to occur 
in a negligible time (approximately instan- taneous), only the collision impulse itself matters; any 
other forces being applied to the objects will be too small to have an effect. By convention, the impulse 
is directed from object 2 to object 1. Twelve linear equations can be written down immediate- ly, expressing 
the change in linear and angular momentum that each object experiences as a result of the collision im- 
pulse R. rnlv- 1 =rnlv 1 +R ra2V2 = rnxvz - R I101 =ll001 + Pl ×R 12~2 = 12002 - Pa × R The last three 
linear equations come from some assump- tions about the collision conditions; the assumptions that we 
will use are that the elasticity, e, is zero (so that the two collid- ing objects come to rest relative 
to each other, at least at the collision point) and that the surfaces are frictionless (so that the impulse 
must be perpendicular to the collision plane). Oth- er assumptions are possible and are discussed below. 
Our as- sumptions require the dot products of R with the collision frame unit vectors i and j to be zero, 
and the difference in the velocity of the collision point, as seen from each of the two objects, to be 
zero in the k direction. We can write: R.i=O R "j=0 (V2 + 02 x p2-Vl-~l x pl)"k =0 These equations can 
be solved by standard Gauss-Jordan elimination with maximal pivoting,[5] LU-decomposition,[22] or by 
more advanced sparse matrix methods.[20, 21] It is pos- sible at this point in the algorithm to find 
the solution for an elastic collision. The actual elasticity of the collision can be taken as the lower 
of the elasticities of the two colliding sur- faces. A new collision impulse Rae~l Can then be calculated 
as Ractual =(l+eaauat)R. This new collision impulse is then plugged back into the defining equations 
above, to solve for the ~ and ~i vectors that are required. The ~ vectors come out easily; the oi vectors 
require inverting the I i inertial tensor matrices. Next consider including friction. If the objects 
axe infinitely rough and e = 0, the collision condition requires that the objects come to rest (relative 
to each other) at the collision point. This corresponds to the vector equation: V2+~xp2-~l-~ lxpl=0 
In between perfectly smooth and perfectly rough colli- sions lies the great middle ground of partially 
rough friction. Modeling partial (i.e. realistic) friction can become quite com- plex; the simple treatment 
given here is from MacMillan[17] and McLean[18] and is sufficient to produce visually reason- able results. 
The coefficient of friction, 7, is the maximum allowed ra- tio of force parallel to the collision plane 
versus force perpen- dicular to that plane. Although properly speaking, y is a pro- perty of pairs of 
surfaces, we assign a y value to each surface, and then use the larger of the 77 values of the colliding 
objects. When the two objects have finite 77 and e = 0, the collision can be solved in two steps. First 
the collision is solved as if it were infinitely rough. Then the resulting collision impulse, R, is examined. 
If the allowed ratio, 77, of the components of R parallel and perpendicular to the collision plane is 
not exceed- ed (i.e. if77R, k ~ I R -k(R -k) I), all is well and the solution stands, because the objects 
should stick. Otherwise, the objects should slide. The system of equa- tions must be set up and solved 
again with different collision conditions. These new conditions will give a smaller restrain- ing parallel 
force, because only a limited amount of friction earl act against sliding motion. Two constants ct and 
13 are cal- culated, such that the collision impulse will exactly fulfill 77R - k = I R -k (R k) I, 
or in other words such that the ratio of the parallel and perpendicular components of R is exactly y, 
and the direction of the parallel component of R is the same as before. This gives the maximum parallel 
force allowed by the necessary perpendicular force and the coefficient of friction. The collision conditions 
axe then: R -i =txR -k g -j =~R -k (V2 + ~2 x p2 - Vl - ~l x pl) " k = O ct and ~ are calculated as 
follows, with Q the component of R perpendicular to the collision plane, and P the unit direc- tion vector 
of the component of R parallel to the collision plane: Q=k(R .k) R-Q P tR-Qt ct = 77(P .i) ~=77 (P -j) 
 To reiterate, the full algorithm for solving a general colli- sion of two rigid objects is to transform 
the required quantities (incoming velocities, tensor matrices, Pi, etc) from the ob- jects' local coordinate 
frames to a common inertial frame, define the collision frame's orthogonal unit vectors i, j, and k, 
choose appropriate collision conditions, set up and solve the system of equations as outlined above, 
and transform the new linear and angular velocities back to the objects' local frames. This may seem 
like a drastic amount of work when compared with inserting a simple spring between the two objects, and 
it does require more lines of computer code, but this method is usually applied only once for each collision, 
whereas springs generally must be applied over a large number of very small time steps. This analytical 
method is cheaper computationally unless the collision is very gentle indeed, and the cost of this collision 
solution does not depend upon the violence of the collision, certainly a desirable property. 3.2.2. Articulated 
Rigid Bodies -Tree-Structured, Revo-lute Joints Now we extend MacMillan's solution to tree-like articu- 
lated rigid objects with revolute joints. The various rigid ob- jects that make up the tree-like linkages 
will be numbered from 1 to n. Objects 1 and 2 will be the colliding objects, and the rest will be linked 
to one or both of them, either directly or through some number of intermediaries. Note that this solu- 
tion allows the links of an articulated object to collide with other links of the same object or with 
another object entirely. Each rigid object will again have a linear velocity vector v i , an angular 
velocity vector toi, an inertial tensor mawix li, a mass mi, and a center of mass ci, all expressed in 
a common inertial reference frame. The revolute joints connecting the various rigid objects will be assumed 
to be ideal, that is, perfectly elastic and with no mechanical tolerance. The single joint that connects 
object i to object j will be described by the vector Pij that points from c i to the joint, and the vector 
Pji that points from cj to the joint. As well as the collision impulse R, this solution will calculate 
an attachment impulse Rij for each joint. Unlike the collision impulse, the attachment impulses Rij are 
uncon-strained as to direction. By convention, the attachment im- pulse Rij points from object j to object 
i, and Rij =-Rji. Rij will be (0,0,0) if objects i and j are not connected by a joint. See Figure 5. 
.... collision ~',,,,. point Figure 5. Articulated Collision Problem For a collision involving n rigid 
objects there are 6n unknowns corresponding to the resulting linear and angular velocities of the objects, 
3 unknowns for the collision impulse, and either 3(n-l) unknowns corresponding to the attachment impulses 
if the objects are all part of one articulated linkage, or 3(n-2) unknowns if two different articulated 
objects are colliding. Thus, the total size of the linear system to be solved is approximately 9n for 
n rigid objects involved in the coUi- sion. The sparsity of the matrix increases as n increases, so that 
if sparse matrix methods are used the solution should be around O (n).[20, 21] Once again, the unknowns 
to be solved for are g. and ~i for i = 1...n, R, and Rq for all pairs of objects i and j connect-ed by 
a joint. The equations for objects 1 and 2, and for the collision impulse, still look familiar. The extra 
summation terms reflect the change in linear and angular momentum resulting from any attachment impulses 
felt by those objects. n ml~t=mlvl +R + ~Rli iffil n m2V2 =m2v 2 -R + ~R~ i=1 n 11~1 =I1091 +pl xR + 
~Pli ×Rli i=1 n 12~2 =12(.022 -- P2 × R + ~ 92i ~R2i i=1 The conditions on the collision impulse R are 
still the same. R "i =0 R 'j=0 (V2+~xp2-VI-~I x Pl)" k =0 For the objects that are not directly colliding 
(for object i = 3..n ), the momentum conservation equations are n rrti~. =miv i + ~Rij j=l n lif-Oi =liOOi 
+ ~Pij ×Rij j=t Each joint requires three more linear equations to make the system of equations complete 
and solvable. These are derived from the basic requirement of a revolute joint: the velocity of the joining 
point, when seen as part of either of the rigid objects which it connects, must be the same. Otherwise, 
the joint would tend to pull apart. For each joint connecting objects i and j, three more equations can 
be written. ~ +~ xpu =~ +~j xp~ Once again, the algorithm requires that the necessary in- formation about 
all of the objects be transformed from their local reference frames to a common inertial reference frame. 
The collision frame orthogonal unit vectors i, j, and k must be determined. The (potentially rather large) 
linear system is set up and solved for the variables V/, 0~ i, R, and Rij, by stan- dard methods.[5, 
22, 20, 21] The actual elasticity of the colli- sion is determined as above, and actual impulses are 
deter- mined by multiplying R and the Rq's by (1 + I~aa.al). The ac-tual impulses are then put back into 
the equations above to get the final solution for linear and angular velocities. The last step is to 
transform the solution back to the object's local frames. 3.2.3. Articulated Rigid Bodies -Revolute 
Joints The above solution for tree-like articulated rigid objects can be extended by removing the requirement 
for tree-like linkage. Since the two articulated objects that are colliding are defined to be connected 
objects, some subset of the attachment points will define tree-like linkages. The first step is to set 
up the problem as above for the objects and for those joints. Then the extra joints are added; each contributes 
another attachment impulse Rij, and thus adds three variables to the problem. Each joint also allows 
three more linear equations to be writ- ten down, the familiar velocity matching condition. This larger 
system once again contains as many variables as equations, and so can be solved by standard techniques. 
The actual collision and attachment impulses are calculated and applied in the same way as above, and 
the solution values are transformed back to the objects' local coordinate systems. It is even possible 
to have more than one joint connecting two objects i and j, although in that case the notation used above 
would have to be expanded slightly. If two joints connect ob- jects i and j, the objects will have only 
one degree of freedom of motion relative to each other; they will be able to twist around the line connecting 
the two joints. If a third joint is ad- ded connecting i and j, which is not colinear with the other 
two, the two objects will be locked in position relative to each other, and will form in effect a single 
rigid object. This is probably not a desirable state of affairs, but the solution algo- rithm does permit 
it.  3.2.4. Articulated Bodies - Sliding Joints A sliding joint is one in which the joining points on 
the two objects are allowed to move freely with respect to each other in one or two dimensions, but are 
at the same time con- strained to a fixed relationship in the other dimensions. A linear sliding joint 
allows sliding motion in one degree of free- dom, while controlling two others; a planar sliding joint 
con- trois one degree of freedom, allowing sliding motion in the other two. For now, assume that these 
joints allow three revo- lute degrees of freedom as well. For a linear sliding joint, assume that objects 
i and j are connected, and that a joint coordinate system is defined by three orthogonal unit vectors 
di, dj, and dk. These vectors are stated in the local coordinate system of object i and rotate with it. 
Further assume that the attachment point on object j is allowed to move freely in the d; direction, but 
must maintain some particular value for its position along dj and d k as seen from object i. Note that 
the "attachment point" on object i is in fact a line; this requires us to calculate P0, the actual attach- 
ment point on object i, separately for each collision. Note also that the joint coordinate system orthogonal 
unit vectors must be rotated into the common inertial frame. Notice that the attachment impulse R V is 
required to lie in the dj, dk plane. As it is possible to write down three linear constraining equations 
about this joint, such a joint can be treated within the linear systems described above. One equa- tion 
expresses the constraint that Rij must lie in a plane; the other two equations constrain the attachment 
point velocities to match in two of the three joint coordinate system directions. R U "d i =0 (vj +~j 
X Pji -v'i -~j X pij)'dj =0 (~ +~j xpj~-~ -~j xpv)-ak =o The argument for a planar sliding joint is 
similar. In this case the attachment point on object j is allowed to move free- ly in the d~ and dj directions, 
constraining the collision im- pulse to exactly the dk direction, but leaving its magnitude unknown. 
The attachment point velocities must still match in the d k direction, but are allowed to vary in the 
other two direc- tions. The equations are as follows. n~ i .d~ =o eli .dj =o (~j + ~ xpji-~ -~j ×P0)' 
dk =0 The sliding joints described above allow the two objects that they connect either 4 (linear) or 
5 (planar) degrees of free- dom of movement relative to each other. Sliding joints that provide fewer 
degrees of freedom can be constructed by ad- ding one or more extra joints of the above types. For instance, 
suppose that a planar sliding joint is desired such that one ob- ject can slide relative to the other, 
but the objects cannot rotate relative to each other. This can be accomplished by defining three planar 
sliding joints (all using the same plane) with the sliding points not colinear. A piston type joint (one 
degree of translational freedom and one degree of rotational freedom) can be described by two linear 
sliding joints of the above type, with the connection points constrained to slide along the same line. 
3.3. Collisions of Dynamic Objects with Non-Dynamic Objects A complication seems to arise when dynamically 
con- trolled objects collide with objects that are controlled in other ways (such as keyframe interpolation). 
In these cases the velo- cities of the non-dynamic objects involved in the collision cannot change. Thus, 
~ =vi andtoi =o)i for the objects that are not under dynamic control, and V/ and o01 are not variables 
in the linear system formulations above. The systems can be reformulated with fewer rows and columns, 
and the solution proceeds just as before. The result is collisions that do not conserve linear or angular 
momentum. The keyframe or pro- cedurally controlled objects move along their assigned paths with lordly 
disdain, brushing aside the dynamically controlled objects as if they had negligible mass. More complex 
responses from the non-dynamic objects are possible. Programs that control objects could be written to 
take the results of dynamic collisions into account. In effect, the procedural object could become dynamic 
for the duration of the collision, and its velocity could change. The program would have to be alert 
to this possibility. This would be fairly simple to implement using the analytic solution, which does 
not require setting up and solving the complete dynamics equations of motion. Altematively, collisions 
between dynamic and keyframed objects could be defined as excep- tional events that require that the 
human animator be notified. 4. CONCLUSIONS Collision detection is important for any animation sys- tem. 
The coding requirements are not excessive, and, while a naive approach to collision detection can consume 
large amounts of computer time, several tricks are available to keep the cost reasonable. Dynamical simulation 
systems must resolve collisions after detecting them. The obvious method of inserting tem- porary springs 
is general and easy to program, but exacts a severe execution time penalty, particularly for violent 
colli- sions. This makes an analytical collision resolution algorithm attractive. On the other hand, 
for objects resting against each other but encouraged by forces to interpenetrate, the spring solution 
is more appropriate. A dynamical simulation system should have a combination of both methods available. 
ACKNOWLEDGEMENTS This work was supported by National Science Founda- tion grant number CCR-8606519. We 
wish to thank Robert Skinner, David Forsey, and Peter Valtin for contributing to the dynamical animation 
software that we used to implement these algorithms. We would also like to thank our reviewers for their 
incisive and helpful comments and references. References 1. William W. Armstrong and Mark W. Green, "The 
Dynamics of Articulated Rigid Bodies for Purposes of Animation," Proceedings of Graphics Interface '85, 
pp. 407-415, Canadian Information Processing Society, Toronto, Ontario, Canada, May 1985. 2. John W. 
Boyse, "Interference Detection Among Solids and Surfaces," Communications of the ACM, vol. 22:1, pp. 
3-9, January, 1979. 3. John Canny, "Collision Detection for Moving Polyhe- dra," MIT Aar. Lab Memo 806, 
October, 1984. 4. Ingrid Carlbom, "An Algorithm for Geometric Set Operations Using Cellular Subdivision 
Techniques," IEEE Computer Graphics and Applications, vol. 7, pp. 44-55, Computer Society of the IEEE, 
Los Alamitos, CA, May 1987. 5. Brice Carnahan and James O. Wilkes, Digital Computing and Numerical Methods, 
John Wiley and Sons, Inc., New York, 1973. 6. Scott E. Fahlman, "A Planning System for Robot Con- struetion 
Tasks," Artificial Intelligence, vol. 5, pp. 1-49, 1974. 7. Wm. Randolph Franklin, "Efficient Polyhedron 
Intersec- tion and Union," Proceedings of Graphics Interface 1982, pp. 73-80, 1982.  8. C. William Gear, 
Numerical Initial Value Problems in Ordinary Differential Equations, Prentice-Hall, Engle- wood Cliffs, 
NJ, 1971. 9. Jeffrey Goldsmith and John Salmon, "Automatic Crea- tion of Object Hierarchies for Ray Tracing," 
IEEE Com- puter Graphics and Applications, vol. 7, pp. 14-20, Com- puter Society of the IEEE, Los Alamitos, 
CA, May 1987. 10. I.N. Herstein, Topics in Algebra, Xerox College Publish- ing, Lexington, MA, 1964. 
 11. J.E. Hopcroft, J.T. Schwartz, and M. Sharir, "Efficient Detection of Intersections among Spheres," 
The Interna- tional Journal of Robotics Research, vol. 2:4, pp. 77-80, Winter 1983. 12. Paul M. Isaacs 
and Michael F. Cohen, "Controlling Dynamie Simulation with Kinematic Constraints," Com-puter Graphics, 
vol. 21, no. 4. Proceedings of SIG- GRAPH'87 (Anaheim, CA, July 27-31, 1987) 13. Donald Knuth, Fundamental 
Algorithms, Addison-Wesley Publishing Co., Reading, MA, 1975. 14. Donald Knuth, Searching and Sorting, 
Addison-Wesley Publishing Co., Reading, MA, 1975. 15. Tomas Lozano-Perez and Michael A. Wesley, "An 
Algorithm for Planning CoUision-Free Paths Among Polyhedral Obstacles," Communications of ACM, vol. 22, 
no. 10, pp. 560-570, October, 1979. 16. Richard V. Lundin, "Motion Simulation," Proceedings of Nicograph 
1984, pp. 2-10, November, 1984. 17. William D. MacMillan, Dynamics of Rigid Bodies, Dover Publications, 
Inc, New York, 1936. 18. W.G. McLean and E. W. Nelson, Engineering Mechan- ics: Statics and Dynamics, 
Shaum's Outline Series, McGraw-Hill Book Co., New York, 1978. 19. Matthew Moore, "A Flexible Object 
Animation Sys-tem," Masters Thesis, University of California, Santa Cruz, Computer &#38; Information 
Sciences, Santa Cruz, California, March, 1988. 20. Ole Osterby and Zahari Zlatev, Direct Methods for 
Sparse Matrices, Springer-Verlag, Berlin, 1983. 21. Sergio Pissanetsky, Sparse Matrix Technology, Academic 
Press, London, 1984. 22. William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling, 
Numerical Recipes, Cam- bridge University Press, Cambridge, England, 1986. 23. Craig W. Reynolds, "Computer 
Animation with Scripts and Actors," Computer Graphics, vol. 16, no. 4, pp. 289-296, Association for Computing 
Machinery, July, 1982. Proceedings of SIGGRAPH'82 24. Craig W. Reynolds, "Flocks, Herds, and Schools: 
A Dis- tributed Behavioral Model," Computer Graphics, vol. 21, no. 4, pp. 25-34, Association for Computing 
Machinery. Proceedings of SIGGRAPH'87 (Anaheim, CA, July 27-31, 1987) 25. David F. Rogers, Procedural 
Elements for Computer Graphics, McGraw-HiU Book Company, New York, 1985. 26. Robert Skinner, U Cal. 
Santa Cruz, CIS Dept. personal communication. 27. Scott N. Steketee and Norman I. Badler, "Parametric 
Keyframe Interpolation Incorporating Kinetic Adjust-ment and Phrasing Control," Proceedings of SIGGRAPH 
'85, vol. 19, no. 4, pp. 255-262, July, 1985. 28. David Sturman, A Discussion on the Development of 
Motion Control Systems, Association for Computing Machinery, July 1987. SIGgraph '87 Course 10 Notes: 
Computer Animation: 3-D Motion Specification and Control.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378530</article_id>
		<sort_key>299</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Realistic animation of rigid bodies]]></title>
		<page_from>299</page_from>
		<page_to>308</page_to>
		<doi_number>10.1145/54852.378530</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378530</url>
		<abstract>
			<par><![CDATA[The theoretical background and implementation for a computer animation system to model a general class of three dimensional dynamic processes for arbitrary rigid bodies is presented. The simulation of the dynamic interaction among rigid bodies takes into account various physical characteristics such as elasticity, friction, mass, and moment of inertia to produce rolling and sliding contacts. If a set of bodies is statically unstable, the system dynamically drives it toward a stable configuration while obeying the geometric constraints of the system including general <i>non-holonomic</i> constraints. The system also provides a physical environment with which objects animated using more traditional techniques can interact. The degree of interaction is easily controlled by the animator. A computationally efficient method to merge kinematics and dynamics for articulated rigid bodies to produce realistic motion is presented.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[modeling]]></kw>
			<kw><![CDATA[rigid bodies]]></kw>
			<kw><![CDATA[simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P132395</person_id>
				<author_profile_id><![CDATA[81100617606]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Hahn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio Supercomputer Center and Department of Computer and Information Science, The Ohio State University, 1224 Kinnear Road, Columbus, OH]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, William W. and Green, Mark W. "The Dynamics of Articulated Rigid Bodies for Purposes of Animation". Proc. Graphics lnterfafe 85 (1985), pp. 407-415.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barzel, Ronen and Barr, Alan H. "Modeling With Dynamic Constraints". ACM SIGGRAPH "87 Course Notes (1987).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359048</ref_obj_id>
				<ref_obj_pid>359046</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Boyse, John W. "Interference Detection Among Solids and Surfaces". Communications of the ACM 22, (January 1979), pp. 3-9.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Flash, Tamar and Hogan, Neville. "The Coordination of Arm Movements An Experimentally Confirmed Mathematical Model". MIT AJ. Memo 786 (November 1984).]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Girard, Michael and Maciejewski, A. A. "Computational Modeling for the Computer Animation of Legged Figures". Computer Graphics 19, 3 (July 1985), pp. 263-270.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Goldsmith, Wemer. Impact: The Theory and Physical Behavior of Colliding Solids. Edward Arnold Pub. Ltd., London, 1960.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Goldstein, Herbert. Classical Mechanics. Addison- Wesley Publishing Company, Reading, MA, 1950.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hahn, James. "Rigid Body Dynamics Simulations". ACM SIGGRAPH "87 Film and Video Show (1987).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Haumann, David. "Modeling the Physical Behavior of Flexible Objects". ACM SIGGRAPH" 87 Course Notes (1987).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hombeck, Robert W. Numerical Methods. Quantum Publishers, Inc., New York, NY, 1975.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hughes, Peter C. Spacecraft Attitude Dynamics. John Wiley &amp; Sons, Inc., 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Isaacs, Paul M. and Cohen, Michael F. "Controlling Dynamic Simulation With Kinematic Constraints, Behavior Functions and Inverse Dynamics". Computer Graphics 21, 4 (July 1987), pp. 215-224.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kane, Thomas and Levinson, David. Dynamics: Theory and Applications. McGraw-Hill, New York, N.Y., 1985.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Press, William H. Numerical Recipes. Cambridge University Press, 1986.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Routh, E. J. Dynamics of a System of Rigid Bodies. Macmillan and Company, Ltd., London, 1905.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Symon, Keith R. Mechanics. Addison-Wesley Publishing Company, Reading, MA, 1971.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, Demetri, Platt, John, Barr, Alan, and Fleischer, Kurt. "Elastically Deformable Models". Computer Graphics 21, 4 (July 1987), pp. 205-214.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15891</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Weil, J. "The Synthesis of Cloth Objects". Computer Graphics 20, 4 (August 1986), pp. 49-54.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J. and Barsky, B.A. "Using Dynamic Analysis for the Animation of Articulated Bodies Such as Humans and Robots". Proc. Graphics Interface 85 (May 1985), pp. 97-104.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Witkin, Andrew, Fleischer, Kurt, and Barr, Alan. "Energy Constraints On Pararneterized Models". Computer Graphics 21, 4 (July 1987), pp. 225-229.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Realistic Animation of Rigid Bodies James K. Hahn Ohio Supercomputer Center and Department of Computer 
and Information Science The Ohio State University 1224 Kinnear Road, Columbus, OH 43212 Abstract The 
theoretical background and implementation for a computer animation system to model a general class of 
three dimensional dynamic processes for arbitrary rigid bodies is presented. The simulation of the dynamic 
interaction among rigid bodies takes into account various physical characteris- tics such as elasticity, 
friction, mass, and moment of inertia to produce rolling and sliding contacts. If a set of bodies is 
statically unstable, the system dynamically drives it toward a stable configuration while obeying the 
geometric con-straints of the system including general non-holonomic con-stralnts. The system also provides 
a physical environment with which objects animated using more traditional tech-niques can interact. The 
degree of interaction is easily con- trolled by the animator. A cornputationally efficient method to 
merge kinematics and dynamics for articulated rigid bod- ies to produce realistic motion is presented. 
CR Categories and Subject Descriptors: 1.3.7 [Three-Dimensional Graphics and Realism]: Animation Additional 
Key Words and Phrases: Modeling, Simula-tion, Rigid bodies, Dynamics 1. Introduction In traditional computer 
graphics, objects in a scene are looked upon as geometric shapes devoid of dynarnieal prop- erties. The 
result is that the animator is forced to use his intuition about the physical world in planning the motion 
of objects in the scene. Since we are so sensitive to detecting anomalies in everyday physics and real 
motions tend to be complex, such techniques have generally proven unsatisfac- tory. Many animators have 
relied on specialized software Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. @1988 ACM-O-89791-275-6/88/O08/0299 $00.75 (usually ad hoe) to model specific types 
of motion. Analo- gous to the development of physically based illumination models in computer graphics 
display algorithms, we need to think of objects in a scene as real objects having mass, moment of inertia, 
elasticity, fi'iction, etc. We present a simulation system for computer anima-tion capable of realistically 
modeling the dynamics of a gen- eral class of three dimensional motions of arbitrary rigid bod- ies. 
The system introduces the following concepts absent in previous dynamics simulation systems: Using collision 
analysis, the interaction among objects can be realistically simulated in a completely general way. This 
includes continuous contact and complex contact geometry, allowing the solution of general constraint 
problems including non-holonomic constraints. Collision analysis makes it possible to solve the constraint 
problems using only the absolute minimum quantities needed to describe motion, the first derivatives 
of position and orientation (velocity and angular velocity).  The motion of articulated figures, whose 
limbs are under kinematic control of the animator, can be solved by simple conservation of momentum arguments. 
The algorithm is linear in the number of links moved and does not involve numerical solutions of differential 
equations involving joint forces or torques.  The system provides a physically realistic environment 
with which objects animated using more traditional techniques, such as key-framing and forward and inverse 
kinematics, can interact.   2. Other Works in Dynamics Simulations Recently there has been a rising 
interest in dynamics simulations in computer animation. Weil [18] has simulated the motion of cloth. 
Terzapoulos et al. [17] and Haumann [9] have investigated the dynamics of flexible objects in modeling 
their deformations. In rigid body motion, the emphasis has been in simulat- ing articulated figures. 
Armstrong and Green [1] and Wil- SIGGRAPH '88, Atlanta, August 1-5, 1988 helms and Barsky [19] have 
used dynamics to simulate INPUT / OUTPUT human figures. Isaacs and Cohen [12] have used similar strategies 
but have also incorporated kinematic control of some of the joints. Two serious drawbacks of the dynamics 
approaches are the large computation time and the problem of control. Our method for articulated figure 
motion solves a slightly different problem of internal kinematic control of the limbs and external dynamic 
analysis. We feel that this is simpler and more effective in generating realistic motion in many cases. 
The dynamics of contact between bodies that result in jointed mechanisms have been solved by researchers 
in studying articulated figures using simple constraints. This involves formulating a different solution 
for each configura- tion of constraints. Recently, Witkin et al. [20] have investi- gated purely geometric 
constraints to deal with several classes of constraint problems. Barzel and Barr [2] have used a similar 
strategy but in the context of dynamics simu- lations. This works well for animating the process of satisfy- 
ing the constraints and is more general in the sense that dif- ferent configurations of constraint do 
not need different solu- tions. However it is still specialized in the sense that for each different 
class of constraint one must be able to define the constraint in the form of an equation relating the 
coordi- nates and formulate a different solution. Other systems have modeled contacts between objects 
directly using repulsive forces [17, 20] and by using imaginary springs and dampers [19]. Our model takes 
a more rigorous and completely gen- eral approach that is able to realistically simulate friction (especially 
the transition between sliding and sticking con-tact) and elastic properties (especially the transition 
between impact and continuous contact) of any contact between arbitrary rigid bodies.  3. Overview of 
the System The system was implemented on the Symbolics 3600 family of machines using Common LISP with 
Flavors. The general flowchart is given in Figure 1. Each object in the scene to be simulated is given 
physi- cal characteristics such as shape, density, coefficient of restitution, coefficient of friction, 
and link hierarchy if any. From these, other properties such as total mass, center of mass, moment of 
inertia tensor, and principal axes are calcu-lated, The dynamic state of each object include the linear 
and angu- lar velocities, the position, and the orientation. The current dynamic state is used to solve 
for the dynamic state at an infinitesimal time increment dt later. Usually no oversam-pling (more than 
30 per second video and 24 per second film) is necessary and dt represents the time increment between 
frames of the animation. The update is done in two steps. First, the objects are moved using the current 
dynamic state. This involves solving for the positions and orienta-tions of the objects using self-starting 
numerical solutions of sets of coupled first order differential equations (such as CALCULATED [ PHYSICAL 
ATTRIBUTE PHYSICAL ATTRIBUTE Center of mass Shape  Principal axes i Density  Principal moment of 
 Frictional coefficient inertia Coefficient of restitution  Mass Link hierarchy  I t, .-1 OUTPUT 
SCRIPT SCENE SCRIPT Object transform t Camera attributes UPDATE  Linear velocity, position  l INITIAL 
STATE  Angular velocity (Euler equations), orientation Linear velocity, position Angular velocity, 
¢ orientation COLLISION DETECTION Collision point t SCRIPT  "Back up" vector  Position  Orientation 
 Ioint angles  External Forced   TRAVERSEGRAPHCONTACT ! External Torques' Order of collision analysis 
SCRIPT ] ¢ Physical attributes  New velocity  New angular velocity  I t=t+dt Figure 1. Flowchart 
of the system Runge-Kutta [10]). If the motion of the object is ,scripted" then the state is read in. 
Second, the objects are checked for intersections. If contact occurred, the new dynamic state for the 
objects that were effected are calculated using impact dynamics in an order given by traversing the "contact 
graph". 4. Motion of Rigid Bodies Under External Forces and Torques The general motion of a rigid body 
can be decomposed into a linear motion of a point mass equal to that of the body located at the center 
of mass of the body under an external force and a rotational motion about the center of mass under an 
external torque. The linear motion under a force F can be calculated by solving the set of coupled differential 
equations ~r=V/m X=V (1) where m is the mass of the object, X is the position vector, and V is the linear 
velocity. 4.1 Euler Equations If we choose to solve the rotational dynamics in a body fixed coordinate 
system given by a set of axes known as the principal axes, a set of simplified coupled first order differen- 
tial equations for the angular velocity W, known as the Euler equations, results (Appendix B). These 
along with Tx = Wx "~ y = Wy (2)  Tz = Wz where T's are the orientations in the principal axes coordi-nate, 
form a set which can be solved by a numerical tech- nique such as Runge-Kutta [10]. Analytic solutions 
also exist for the equations in which Jacobian elliptic trigonomet- ric functions are used [11]. These 
solutions may have an advantage when efficient packages are available for elliptic functions [14]. The 
analytic solutions could also make motion planning easier. 4.2 Moment of Inertia Tensor and the Principal 
Axes The moment of inertia tensor for a rigid body, which is the rotational analogue of mass, is given 
by [16] I = f p (R 2 U- R R) dv (3) where p is the density of the object, R is the location vector of 
the volume element dr, U is the unity dyadic, and R R is a dyad product. This is a Hermitean or a symmetric 
tensor of the second rank. The 3 x 3 matrix form of I is given in Appendix A. The inertia tensor can 
be transformed under rotation and translation to any coordinate system (Appendix A). The numerical integrations 
for the inertia tensor are per- formed in a coordinate frame where the origin coincides with the center 
of mass of the object to facilitate the separation of linear and rotational motion. We can rotationally 
transform the inertia tensor to a coordinate frame in which the tensor is diagonalized. The existence 
of such a coordinate frame for any inertia tensor is guaranteed by the fact that it is a Hermitean [7]. 
This is just the problem of finding the eigenvectors E and its associated eigenvalues i for the matrix 
I. I. Ej = ij. Ej (1 _<j _< 3) (4) A numerical solution such as the power method [10] can be used to 
find the largest and the smallest eigenvalues and the associated eigenvectors. The E's which are the 
axes of the coordinate system in which I is diagonalized are known as the principal axes and the i's 
which are the diago- nal elements of the tensor in the principal axes coordinate are known as the principal 
moments of inertia. Intuitively the principal axes correspond to the "axes of symmetry" of an object 
and the principal moments of inertia corresponds to the associated moments of inertia. It is important 
to realize that for any arbitrary shaped object, one can find the principal axes and the principal moments 
of inertia. They axe invariant geometrical descrip- tions of the object in the body fixed coordinate 
system and need to be calculated only once for each object. 4.3 Dynamics of Articulated Figures In most 
interesting human or animal motion, all the joints are under some autonomous control. Cases where limbs 
react to other limb motion or external forces and torques with absolutely no internal muscle control 
are rare. Also, empirical studies have shown that the unrestrained human limb motion are determined by 
intelligent trajectory planning in purely kinematic terms [4]. Even constrained systems in which all 
the parts cannot be defined as a mechanical system (e.g. where joints are controlled by feed- back systems 
consisting of muscles and sensors) cannot be modeled using pure dynamics. Therefore the computationally 
intensive solution for the internal dynamics of articulated fig- ures may be unjustified except for modeling 
inanimate joint- ed objects. We use kinematics to control joint trajectories [5] and dynamics to model 
the effects of limb motion and external forces and torques on the body as a whole. The articulated body 
is defined in the form of an arbi-trary tree of links. The tree structure makes the kinematic control 
easier but is not necessary for the dynamics analy- sis. In fact any system in which quanta of masses 
axe moved within the body by the animator, such as an object changing shape, can use approaches similar 
to the following. The dynamics of the figure as a whole proceeds as in the treatment of a single rigid 
body. The total moment of inertia tensor is calculated by summing the inertia tensors of individual links 
in the world coordinate and then transform- ing to the body fixed coordinate system with its origin at 
the center of mass of the articulated body. The principal axes are calculated from the total inertia 
tensor. When the joints are being driven kinematically, there are additional motions of the whole object 
in the body fixed reference frame due to the conservation of linear and angular momentum of the system. 
When a joint j is moved with angular velocity dWj in the joint fixed coordinate system, (Figure 2) the 
whole body must rotate by dW' =-fit [(E i Ii) dWj + (Rj X (dWj X C j)) (Ei mi)] (5) in the body fixed 
coordinate system to conserve angular momentum. ITt is the transpose of the total inertia tensor of the 
whole body, the first sum is the moment of inertia tensor associated with the joint (i.e. the inertia 
tensors of all the descendants of j) in the joint coordinate system, Rj is the location of the joint 
with respect to the body fixed coordinate system, Cj is the location of the center of mass of the descendants 
of the joint in the body fixed coordinate system, and the last sum is the total mass of the descendants. 
 ............... -\ body fixed coordinate  : forsu J .................... . ., ..'" ,.-"'f "": Figure 
2. Moving joint j by dWj in the body fixed coordinate The linear momentum is conserved by finding the 
new center of mass of the whole body after the change and mov- ing the body so that the center of mass 
coincides with the origin of the body fixed frame. The above analysis is done at each time step for the 
joints that are being driven. The order in which the joints are treated is given by traversing the tree 
from the leaves toward the root. Then /he inertia tensor of a subtree can be used to calculate the inertia 
tensor of its ancestor joint. There is a new angular velocity of the entire body due to the change in 
the inertia tensor  W[ = ~t" Lt (6) where ~t' is the matrix transpose of the new total inertia tensor 
and L t is the invariant total angular momentum of the body. 5. Interaction Among Objects Dynamics simulations 
(and disciplines involved in solving mechanical problems in general) have used the con-cept of holonomic 
constraints to solve/he dynamics of con- tinuous contact between objects. Hotonomic constraints are a 
class of constraints in which one can define the constraints in the form of an equation of coordinates 
[7, 16]. They are abstractions of a small subset of the general constraint intro- duced to facilitate 
an analytic solution. The majority of con- straints do not have such simple abstractions. As an cxarn- 
ple, the constraints of the links in a chain cannot be abstract- ed as, for example, a 3-degrees of freedom 
ball and socket joint. In fact each link has 6 degrees of freedom until they are in contact with other 
links and then the interaction is very complex (Figure 13). The most general constraint should therefore 
not be expressed in terms of what the objects must do (remain on a point, a line, etc.) but in terms 
of what the objects must not do (penetrate each other). In the system, interactions among objects are 
simulat- ed using collision detection to model the general constraints and impact analysis to solve the 
dynamics. Impact analysis has been extended to include continuous contacts and simul- taneous contact 
of many bodies. This makes it possible to solve the dynamics of arbitrary interactions without solving 
differential equations involving finite forces and torques. It also makes possible the realistic simulation 
of the transition between instantaneous and continuous contacts and between sticking and sliding contacts. 
5.1 Impact Dynamics An analysis of the impact process of two rigid bodies was proposed by Routh in the 
late nineteenth century [15]. Routh included the effect of the Coulomb model of friction and partially 
elastic materials employing graphical solution meth- ods. His work remains essentially unchanged in modem 
expositions [6]. The following uses analytic and numerical solution techniques involving only the states 
before and after the collision. When two bodies collide and the contact area of one of the bodies is 
locally planar, one can define the normal N to the tangent surface of contact between the two bodies 
(Figure 3). If a surface of contact cannot be defined for the impact (for example when a point of one 
object strikes the point of another) the outcome is theoretically indeterminate. In the system, we average 
the normals of neighboring poly- gons. In the following, "normal" refers to N and "tangential" refers 
to the direction along the tangent surface of contact. Figure 3. Modes and normals of local contact In 
an impact process, the bodies act on each other with impulse P P = fat F dt (7) where F is the large 
force between the objects that act through an infinitesimally short time interval At. Since the integral 
is over time as At approaches 0, any finite forces such as gravity does not contribute to P. The conservation 
of linear and angular momenta gives (Figure 4) ml(Vl'Vl)='Pl m 2 (V~- V 2) = + P2 (8a)  I 1 (W l-wl) 
=R 1 X (- P1) 12 (W~ - W2) = R 2 X (+ P2) (8b) The subscripts stand for each of the bodies and the primes 
denote the quantities after the impact. The moment of inertia tensors and the angular velocities are 
transformed from the body fixed frames to the world coordinate frame before they are used in these equations. 
Figure 4. Collision between two objects Here we introduce an empirical result known as the generalized 
Newton's rule [6]. (Vi+W ~ X R1)" N- (V~ + W~ X R2)" N =-e (9) (V 1 + W 1XR1)- N- (V2 +W2X R2) .N The 
constant of proportionality, e, known as the coefficient of restitution depends to a large extent on 
the elasticity of the materials of the two constituent objects, e has a value ranging from 0, corresponding 
to a perfectly inelastic colli- sion to a value of 1, corresponding to a perfectly elastic colli- sion 
where no kinetic energy is lost. Now we consider friction between the two bodies at the moment of impact. 
Coulomb's law states [13] I F t I _< IX F n (10) where t is the tangential component and n is the normal 
com- ponent of the force F between the objects. The positive num- ber Ix is the coefficient of friction 
and depends solely on the materials of the two bodies. When /.t = 0 the interaction is frietionless. 
If the two objects are moving tangentially rela- five to each other at the point of contact then the 
equality holds in (10). We first assume that the two bodies do not slip on impact at the point of impact. 
Then [(V i + W i X R1)- (V~ + W~ X R2)]t = 0 [(V i + W I X R1) '- (V~ + W~ X R2)]r = 0 (ii) where t 
and r are the orthogonal components of the velocity vector perpendicular to N. Equations (8), (9), and 
(11) give us 15 independent equations in 15 unknowns (P and for both objects V' and W'). If the solution 
for P satisfies IN × (P × N)I _> I x IP. NI (12) then by (10) the no slip assumption that leads to (11) 
is not valid and the two bodies are sliding at the point of contact. In this case Pt = 0 Pr = 11 IP. 
NI (13) where t is the direction given by (P X N) and r is the direc- tion given by N × (P × N) , can 
be substituted for (11). The new set of 15 equations can be solved for the unknowns. V' and W' for both 
objects constitute the new state after the collision. For the collision of a rigid body with an object 
of infinite mass (e. g. floor or other objects that effect the environment but are not in turn effected 
by it) the devel- opment is similar except only the conservation of momentum and energy of the one body 
is considered resulting in 9 equa- tions in 9 unknowns (P, V', and W' for the body). 5.2 Continuous Contact 
 After a collision analysis is performed between two objects, if the relative velocity of the objects 
at the coUision point in the direction of the normal of local contact is less than a small threshold 
then the objects can be considered to be in continuous contact. If the objects are applying a force on 
each other, for example when one of the objects is the floor, the dynamics can still be simulated using 
the impact equations (8), (9), (11) and (13). Although the forces and torques do not appear explicitly, 
their contribution is seen as the gain in momenta of the object during dt which are the impulses that 
the support applies to the object in the impact process. Even though we are approximating continuous 
con-tact with a series of instantaneous contacts, oversampling is usually not necessary. 5.3 Collision 
Detection In order to minimize the number of polygon to polygon intersection tests, a hierarchical method 
involving bounding boxes is used. At the bottom of the hierarchy, each edge of object 2 is tested against 
each polygon of object 1 and vice versa. Since the collision detection is performed at discrete intervals 
of time, two types of penetrations are possible [3]. In Figure 5, the collision point is given by the 
"inside" vertices of the edges that intersect polygons. Assuming that object 1 is stationary in world 
coordinate one can define a ray originating from the collision point in a direction given by the relative 
velocity of the two objects at the collision point. If we assume that the velocity of the two objects 
at the colli- sion point remains constant during the time step, the ray represents the path that the 
collision point of object 2 took when it penetrated object 1. The intersection between the ray and the 
polygons of object 1 represents the actual pene- SIGGRAPH '88, Atlanta, August 1-5, 1988 ~ relative velocity 
(inside vertex) penetration point collision point Figure 5. Point collision detection tration point 
at which the two objects collided. In order to determine the actual positions and orientations of the 
objects at time t, both objects must be backed up to the time of the collision and collision dynamics 
used to generate the new velocities and thus the positions and the orientations at t. In our implementation, 
assuming sufficiently small dt, object 2 is "backed up" at time t so that the two objects touch but do 
not penetrate. Figure 6 represents an edge collision where an edge penetrates more than one polygon. 
The penetration point is calculated by intersecting the polygon swept by the edge during the time step 
with the edges of the pierced polygons. The collision point is calculated by finding the intersection 
between the penetrating edge and a ray originating from the penetration point in a direction given by 
the negative of the relative velocity. relative vel .... ~ point collision point pierced polygons Figure 
6. Edge collision detection The above "algorithm assumes that the time step dt and/or the velocity of 
the polygons of the objects are small enough such that the distance covered during dt is much smaller 
than the dimensions of the polygons. If this were not the case then one must consider the volume swept 
by the bounding boxes and the polygons during dt in the collision detection algorithm not to miss the 
collision.   5.4 Complex Contact Geometry For a scene consisting of a number of bodies in simul- taneous 
contact, the impact analysis is applied to each pair of objects. If an object belongs to more than one 
such pair, then the contributions from each of the impacts are summed. An arbitrary order in handling 
the contact pairs could result in penetration between objects even after the collision analy- sis because 
of the necessity to "back up" after an impact is discovered. In general, the contact geometry of a scene 
can be rep- resented as a graph (Figure 7). The nodes represent the Figure 7. Contact geometry and associated 
graph objects and the edges represent contacts. The special immovable node represents the set of all 
immovable objects in the scene. In order to prevent objects from being "backed up" into immovable objects, 
the contact pairs are handled in an order given by a breadth first search of the graph starting from 
the immovable node. If there are no immovable nodes, then the breadth first search can start from any 
node. In graphs involving cycles the last contact pair to be considered in the cycle must be checked 
so that the objects are not "backed up" into each other. 6. Control Issues In any simulation system, 
there is a trade-off between automation and control by the animator. In our system the animator has a 
great deal of flexibility in determining how much of a control be has on the motions of objects in the 
scene. He can take full advantage of automation by specify- ing the initial state of the system and letting 
the system generate the subsequent motions. Through a series of exper- imentation, the desired overall 
motion can be achieved in a relatively short period of time. Our experiences have shown that most sequences 
(averaging approximately 10 seconds of animation) can be generated after only a few trials. By controlling 
the physical characteristics of the object (possibly as a function of time) the animator can manipulate 
the physics to his liking. Some of the objects can be under the direct control of the animator allowing 
the integration of traditional animation techniques with simulation. The trajectories of these objects 
are usually scripted by specifying the position and orienta- tion of the objects as a function of the 
frame number. In order to apply impact dynamics, the script is numerically differenti- ated to get the 
velocities as a function of time. A weighted average of the scripted velocities and the velocities given 
by the impact dynamics (if any) can be used to move the object. The amount of effect that the other objects 
have on the object being moved is controlled by scaling the mass and the moment of inertia of the object 
being moved. With a high scaling factor, the object effects the environment more and follow closely the 
scripted trajectory. Some of the objects can be moved by applying forces and torques directly. Control 
is harder since the effect on an object is not clear. Inverse dynamics [12] can be used to cal- culate 
in advance the forces and torques needed to move an object in a desired trajectory.   7. Examples of 
Animation Figures 9-16 illustrates a few of the wide range of real- istic animation sequences generated 
with the system [8]. The collision detection algorithm, which is of order n 2 in the number of polygons 
when the objects are close enough, takes most of the calculation time in most sequences. Figure 8 gives 
approximate calculation times per frame with and without collision detection. Animation Withoutcollision 
detection With collision detection Figure 9 .05 1.33 Figure 10 .05 6.97 Figure l 1 .50 0.54 Figure 12 
.60 3.41 Figure 13 .15 6.31 Figure 14 .07 8.60 Figure 15 .15 0.59 Figure 16 .04 1.52 Figure 8. Calculation 
time per frame in seconds Figure 9 illustrates how the animator can direct the overall motion (even 
fairly complex motion). We wanted the car to come off the ramp, bounce off of a second car, and then 
crash into a third car. The low level details of the motion were generated by the system. Figure 10 (showing 
proces- sion and nutation of the tops) illustrates how the laws of physics can be manipulated to get 
a desired effect. We want- ed the tops to spin slowly to prevent temporal aliasing. In order to keep 
the tops from falling over because of a small angular velocity, the moments of inertia were increased 
arti- ficially. In the articulated figure animation (Figure 11), the joint trajectories were kinematically 
specified and the sys-tem generated the external motion. In Figure 12, the motion of the rocket was scripted 
by the animator. The plate pieces realistically react to being pushed by the rocket. In the colli- sion 
analysis, the mass and the moment of inertia of the rocket were set essentially to infinity compared 
to those of the plate pieces. In Figure 13, the top link is fixed. The other links in the chain are free 
to move without artificially imposed constraints. The chain was released from an initial state. The motion 
reflects the fact that the links are faeeted and have some friction. Figures 14, 15, and 16 give exam-ples 
of continuous and complex configuration of contacts among arbitrary shaped objects. 8. Conclusion We 
are currently studying the possibility of using vari- ous strategies to search the space spanned by the 
dynamic state of an object to maximize or minimize certain quantities such as the closeness to a desired 
trajectory for an object. This type of motion planning would make it possible to pre- cisely control 
the animation using our system. We are also in the process of implementing a near linear order collision 
detection algorithms employing neighborhood or spatial information. In the system, the dynamics simulation 
proceeds from an initial state by a time series analysis of the linear and rotational motion. The rotational 
dynamics is simplified by solving the Euler equations in the principal axis reference frame. The external 
dynamics of kinematically driven articu- lated figures are solved principally by using conservation of 
momenta. The complex interactions between objects (including continuous contacts) are modeled in a completely 
general and novel way using collision detection and impact dynamics. The use of conservation of momenta 
in the dynam- ics analysis allows the solution for the motion involving only the velocities and not the 
accelerations. Scripts can be speci- fied to integrate simulation and traditional animation tech-niques 
and to influence the dynamics. The variety of realistic animations generated with the system show promise 
in systems based on physical simula- tions becoming an integral part of animation of rigid bodies.  
 Acknowledgments I would like to thank Rick Parent, Brian Guenter, Michael Girard, and everyone in the 
"Symbolics Group" at ACCAD for many helpful discussions and software support. I would also like to thank 
Chuck Csuri and Tom Linehan for providing a free and supportive research atmosphere without which this 
work would not have been possible. This research was supported in part by a National Science Foun- dation 
grant DCR-8304185. SIGGRAPH '88, Atlanta, August 1-5, 1988 Figure 9. Figure 10. Figure 11. Figure. 12 
O Figure. 13 Figure. 14 Figure. 15 ii J Li i Figure. 16 @  Appendix A In the 3 x 3 matrix form of 
the moment of inertia tensor of an object, the diagonal elements or the moment of inertia coefficients 
are given by [7, 16] ix x = f p (y2 + Z 2) dv Iyy = f p (x 2 + z 2) dv (AI) I~= fp (x2 +y2)dv and the 
off-diagonal clcmcnts or the product of inertia are given by Ixy = f p (x y) dv Ixz = f p (x z) dv (A2) 
Iyz= f P (Y z) dv where the subscripts stand for the matrix indices, p is the density of the object, 
and the integral is over the volume of the object. The inertia tensor can be transformed to any coor- 
dinate frame. The matrix of the tensor transforms under a 3 x 3 orthogonal matrix A as a similarity transform 
[7] I'= A I A T (A3) where the superscript T stands for the matrix transpose. For our purposes of rotational 
transform the matrix A is the direction cosine matrix of the two coordinates. For the trans- lational 
transform, by the matrix form of the tensor (A1) and (A2) l~tx= Ixx + m (y2 + Z 2) I~y = Iyy + m (x 2 
+ z 2) I~z = Izz + m (x 2 + y2) (A4) I~y = lxy + m (x y) I~z = Ixz + m (x z) I~z = Iy z + m (y z) where 
x, y, and z gives the translation of the coordinate frame and m is the mass of the object. Appendix 
B The rotational dynamics is given by dL/dt = N (B 1) L = I. W (B2) where L is the angular momentum of 
the body, N is the external torque being applied to the body, I is the moment of inertia tensor of the 
body, and W is the angular velocity of the body that we want to solve for. The major obstacle for a simple 
solution is that the rotational equivalent of mass, the Computer Graphics, Volume 22, Number 4, August 
1988 moment of inertia tensor, is not constant with respect to an inertial reference frame but changes 
as the body rotates. This can be avoided by solving the rotational dynamics in a frame that is fixed 
in the body. Taking the time derivative of (B1) with reference to a coordinate frame fixed in the body 
dL/dt + W × L = N (B3) Substituting (B2) into (B3) I. dW/dt + W × (I- W) = N (B4) If we choose the principal 
axes as the body fixed axes and transform (B4) to the body fixed coordinate we get a set of simplified 
differential equations   @x+(Iz-iy)WzWy_-N Iy Wy + (Ix - Iz) Wx Wz = Ny 035) Iz ~/z + (Iy - Ix) Wy 
Wx = Nz where the products of inertia do not appear. These are known as the Euler equations [7]. The 
x, y, and z are the directions of the principal axes. i: References i- 1. Armstrong, William W. and Green, 
Mark W.. "The Dynamics of Articulated Rigid Bodies for Purposes of Animation". Proc. Graphics lnterfafe 
85 (1985), pp. 407-415. 2. Barzel, Ronen and Barr, Alan H.. "Modeling With Dynamic Constraints". ACM 
SIGGRAPH "87 Course Notes (1987).  . Boyse, John W.. "Interference Detection Among Solids and Surfaces". 
Communications of the ACM 22, (January 1979), pp. 3-9. 4. Flash, Tamar and Hogan, Neville. "The Coordination 
of Arm Movements An Experimentally Confirmed Mathe- matical Model". MITAJ. Memo 786 (November 1984). 
 5. Girard, Michael and Maciejewski, A. A.. "Computational Modeling for the Computer Animation of Legged 
Figures". Computer Graphics 19, 3 (July 1985), pp. 263-270.  6. Goldsmith, Wemer. Impact: The Theory 
and Physical Behavior of Colliding Solids. Edward Arnold Pub. Ltd., London, 1960. 7. Goldstein, Herbert. 
Classical Mechanics. Addison-Wesley Publishing Company, Reading, MA, 1950. 8. Hahn, James. "Rigid Body 
Dynamics Simulations". ACM SIGGRAPH "87 Film and Video Show (1987). 9. Haumann, David. "Modeling the 
Physical Behavior of  307 Flexible Objects". ACM SIGGRAPH" 87 Course Notes (1987). 10. Hombeck, Robert 
W.. Numerical Methods. Quantum Publishers, Inc., New York, NY, 1975. 11. Hughes, Peter C.. Spacecraft 
AtEtude Dynamics. John Wiley &#38; Sons, Inc., 1986. 12. Isaacs, Paul M. and Cohen, Michael F.. "Controlling 
Dynamic Simulation With Kinematic Constraints, Behavior Functions and Inverse Dynamics". Computer Graphics 
21, 4 (July 1987), pp. 215-224. 13. Kane, Thomas and Levinson, David. Dynamics: Theory and Applications. 
McGraw-Hill, New York, N.Y., 1985. 14. Press, William H.. Numerical Recipes. Cambridge Uni- versity 
Press, 1986. 15. Routh, E. J.. Dynamics of a System of Rigid Bodies. Macmillan and Company, Ltd., London, 
1905. 16. Symon, Keith R.. Mechanics. Addison-Wesley Pub-lishing Company, Reading, MA, 1971. 17. Terzopoulos, 
Demetri, Platt, John, Barr, Alan, and Fleischer, Kurt. "Elastically Deformable Models". Com-puter Graphics 
21, 4 (July 1987), pp. 205-214. 18. Weil, J.. "The Synthesis of Cloth Objects". Computer Graphics 20, 
4 (August 1986), pp. 49-54. 19. Wilhelms, J. and Barsky, B.A.. "Using Dynamic Analy- sis for the Animation 
of Articulated Bodies Such as Humans and Robots". Proc. Graphics Interface 85 (May 1985), pp. 97-104. 
 20. Witkin, Andrew, Fleischer, Kurt, and Barr, Alan. "Energy Constraints On Pararneterized Models". 
Com-puter Graphics 21, 4 Quly 1987), pp. 225-229.  308 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378531</article_id>
		<sort_key>309</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Motion interpolation by optimal control]]></title>
		<page_from>309</page_from>
		<page_to>315</page_to>
		<doi_number>10.1145/54852.378531</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378531</url>
		<abstract>
			<par><![CDATA[Motion Interpolation, which arises in many situations such as <i>Keyframe Animation</i>, is the synthesis of a sequence of images portraying continuous motion by interpolating between a set of <i>keyframes</i>. If the keyframes are specified by parameters of moving objects at several instants of time, (e.g., position, orientation, velocity) then the goal is to find their values at the intermediate instants of time. Previous approaches to this problem have been to construct these intermediate, or <i>in-between</i>, frames by interpolating each of the motion parameters independently. This often produces unnatural motion since the physics of the problem is not considered and each parameter is obtained independently. Our approach models the motion of objects and their environment by differential equations obtained from classical mechanics. In order to satisfy the constraints imposed by the keyframes we apply external control. We show how smooth and natural looking interpolations can be obtained by minimizing a combination of the control energy and the roughness of the trajectory of the objects in 3D-space. A general formulation is presented which allows several trade-offs between various parameters that control motion. Although optimal parameter values resulting in the best subjectively looking motion are not yet known, our simulations have produced smooth and natural motion that is subjectively better than that produced by other interpolation methods, such as the cubic splines.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[interpolation and control theory]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor>Motion</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Control theory</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010213</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010213.10010214</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods->Computational control theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010238</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Motion capture</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010380</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Motion processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010238</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->Motion capture</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309783600</person_id>
				<author_profile_id><![CDATA[81542296156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lynne]]></first_name>
				<middle_name><![CDATA[Shapiro]]></middle_name>
				<last_name><![CDATA[Brotman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14091692</person_id>
				<author_profile_id><![CDATA[81100235596]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arun]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Netravali]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>5446</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Magnenat-Thalmann, N. and Thalmann, D., "Computer Animation: Theory and Practice", Springer-Verlag,. 1985.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Stern, Garland, "Bbob - a System for 3-D Key-Frame Figures Animation", S1GGRAPH'83, Tutorial Notes on Introduction to Computer Animation, pp. 240-243.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Sturman, David, "Interactive Keyframe Animation of 3-D Articulated Models", Graphics Interface, '84, pp. 35-40.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kochanek, Doris H. U. and Barrels, Richard H., "Interpolating Splines for Keyframe Animation", Graphics Interface '84, pp. 41-42.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325242</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Shoemake, Ken., "Animating Rotation with Quaternion Curves", SIGGRAPH'85, Computer Graphics 19 (3), pp. 245-254.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W. W. and Green, Mark, "The Dynamics of Articulated Rigid Bodies for the Purposes of Animation", Graphics Interface, '85, Montreal, pp. 407-416.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>20331</ref_obj_id>
				<ref_obj_pid>20313</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, Jane and Barsky, Brian A., "'Using Dynamics for the Animation of Articulated Bodies Such As Humans and Robots", Graphics Interface '85, Montreal, pp. 407-416.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Raibert, Marc H., et. al., "Experiments in Balance with a 3-D One-Legged Hopping Machine", The International Journal of Robotics Research, Vol. 3, No. 2, 1984, pp. 75-92.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Isaacs Paul M. and Cohen, Michael F., "Controlling Dynamics Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics", SIGGRAPH'87, Computer Graphics 21 (4), pp. 215-224.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Bryson, A. E. and Ho, Y., "Applied Optimal Control: Optimization, Estimation, and Control", Hemisphere Publishing Corp., 1975.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Goldstein, H., "Classical Mechanics", Addison-Wesley, Inc. 1951.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Halfman, R. L., "Dynamics", Addison-Wesley, Inc. 1962.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 MOTION INTERPOLATION by OPTIMAL CONTROL by Lynne 
Shapiro Brotman Arun N. Netravali AT&#38;T Bell Laboratories Murray Hill, NJ 07974 ABSTRACT Motion 
Interpolation, which arises in many situations such as Keyframe Animation, is the synthesis of a sequence 
of images portraying continuous motion by interpolating between a set of keyframes. If the keyframes 
are specified by parameters of moving objects at several instants of time, (e.g., position, orientation, 
velocity) then the goal is to find their values at the intermediate instants of time. Previous approaches 
to this problem have been to construct these intermediate, or in-between, frames by interpolating each 
of the motion parameters independently. This often produces unnatural motion since the physics of the 
problem is not considered and each parameter is obtained independently. Our approach models the motion 
of objects and their environment by differential equations obtained from classical mechanics. In order 
to satisfy the constraints imposed by the k¢yframes we apply external control. We show how smooth and 
natural looking interpolations can be obtained by minimizing a combination of the control energy and 
the roughness of the trajectory of the objects in 3D-space. A general formulation is presented which 
allows several trade-offs between various parameters that control motion. Although optimal parameter 
values resulting in the best subjectively looking motion are not yet known, our simulations have produced 
smooth and natural motion that is subjectively better than that produced by other interpolation methods, 
such as the cubic splines. CR Categories and Subject Descriptions: 1.3.6 Computer Graphics: Methodology 
and Techniques -Interaction Techniques, 1.3.7 Computer Graphics: Three Dimensional Graphics and Realism 
-Animation, 1.6.3 Simulation and Modelling: Applications Additional Keywords: Animation, Dynamics, Interpolation 
and Control Theory. Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. &#38;#169; 1988. ACM-0-89791-275-6/g8J008/0309 $00.75 1. Introduction Specification of motion 
in computer synthesis of image sequences has been done traditionally by an animator. Ideally, as in other 
human-machine interactions, the animator would like to minimize the amount and the complexity of information 
that he specifies and maximize the amount of information that the machine synthesizes. In keyframe animation, 
for example, a frame sequence portraying motion is created by interpolating between a set of keyframes 
specified by the animator. If the keyframes are specified by parameters of motion (e.g. position, orientation, 
velocity) then the goal is to find their values at intermediate instances of time. I~J Early keyframe 
systems used linear interpolation to produce these in-betweens. This often resulted in motion that appeared 
unnatural and jerky. More recently, work aimed at increasing realism has used splines for separately 
interpolating parameters of motion, resulting in increased smoothness of motion. ~2-41 Also, use of quaternions 
has been suggested for handling rigid-body orientation in order to eliminate the artifacts which occur 
in systems that use ordinary splines. [5~ While such geometric interpolation methods guarantee smoothness 
of motion and give sufficient control to the animator to tailor it, they do not necessarily produce motion 
that is natural. Motion in our environment is due to forces and torques acting on bodies with physical 
properties such as mass, shape, moments of inertia, and is constrained by several factors such as obstacles, 
joints, etc. Clearly, to achieve authentic motion, laws of dynamics must be adhered to. Unfortunately, 
incorporation of dynamics requires formulation and numerical integration of a complex set of connected 
differential equations. Moreover, since motion is completely determined once the differential equations 
and their initial conditions are known, control that the animator needs to tailor motion is lost. Also, 
the complexity of these differential equations denies the animator a simple relationship between the 
parameters that control the dynamics and the resulting motion. Thus we have the familiar dilemma: on 
one hand, an animator wishes to tailor motion to portray drama, expression, etc., and can do so by specification 
of keyframes followed by interactive, geometric but not necessarily natural looking interpolation; on 
the other hand, to make the motion look natural, complexity of simulation of natural processes has to 
be dealt with along with a simple method of control. Ideally, if the animator specifies only the keyframes 
and computer minds the physics, we have the best of both worlds. This has been recognized recently by 
several people. [6-91 Use of principles of dynamics to simulate motion of physical bodies including linked 
figures, although new in computer graphics, [6-sl has been practiced in other fields such as mechanics 
and robotics for a number of years. Unfortunately, such simulation does not allow the animator to shape 
the motion explicitly. One way to shape the trajectories is to add external forces and torques in the 
differential equations representing the dynamical model. However, the animator should not be burdened 
with the determination of the appropriate amount, place and duration of these external forces. This view 
is similar to the one put forth by Isaccs and Cohen [91 in the context of dynamic simulation of linked 
figures. They advocate use of behavior functions and inverse dynamics to compute the desired external 
forces. Given the keyframes and differential equations that model dynamics, the amount and the duration 
of these forces is not unique and since improper design of forces can  / SIGGRAPH '88, Atlanta, August 
1-5, 1988 III lead to jerky and unnatural motion, (although obeying physics) we propose to find the 
best set of forces. We hypothesize that the smoothest and most natural motion is obtained when the applied 
external force has the least energy and is continuous. Thus, we construct interpolated motion as a solution 
of the differential equation obtained by modelling dynamics which is constrained to pass through keyframes 
by applying the least amount of external force. In addition to the usual keyframe specification, the 
animator is now required to specify the dynamics, but the computer does the rest. 2. The Approach We 
present a new approach for solving the motion interpolation problems in the context of keyframe animation. 
We model motion of objects and their environment by differential equations obtained from classical mechanics 
and use external control to force the motion to satisfy constraints imposed by keyframes. Currently, 
objects are modelled as rigid bodies. The model can be extended to handle articulated and deformed bodies 
at a cost of increased complexity. In addition to characteristics of objects and the environment traditionally 
modelled in graphics, such as shape, shading and illumination, our model requires specification of mass 
and for problems involving rotation, inertial parameters. The model of the environment may require knowledge 
of factors such as gravity, friction, and wind pressure. We start with a differential equation which 
models each objeet's motion. Since the solution of this differential equation, starting with some initial 
condition, will not, in general, pass through the keyfram~, "external control" is necessary. In many 
cases, there is a natural place for application of control (or force) and it is included in the model. 
Otherwise, the place and form of the control (i.e., how it affects the differential equation) is chosen 
somewhat arbitrarily. The next step is to obtain a trajectory of the object such that it requires the 
least amount of control and simultaneously maximizes some measure of smoothness of the trajectory while 
passing through the keyframes. We choose "least amount of control" to mean the least amount of control 
energy which is defined by the integral of the square of the control value over time. This optimization 
is performed using algorithms of control theory, tt°l Our hypothesi s, which is supported by simulations, 
is that the most natural motion results when the least amount of smooth control is applied to an object. 
The principal drawback of our approach is a significant increase in the computational burden over that 
required for other interpolation methods such as cubic splines. 2.1 Mathematical Formulation  Ix(t)l 
Let r(t) -/y(t)/, be a column vector at time t in 3D-space with [z(t) J respect to a coordinate system 
fixed in time. The equations of motion for a general rigid body can then be written as: d2r(t) (1) ~Fo-m 
dt 2 dH(t) (2) ~M°" dt where ~Fo is the vector sum of all forces acting on the body (i.e., natural forces 
such as gravity and friction as well as externally applied control forces), m is the mass, and ~Mo and 
H represent the moment of the forces and the angular momentum of the body about dH(t) the center of 
mass, respectively. In many eases, ~ can be " dZ#(t) [#,(t) / and written as 1-~---, where #(t) -Ox(t), 
0y(t), #z(t) are L0,(t)] the angles of rotation about the x,y,z axes, respectively. I is the moment 
of inertia about the same axes. In other cases, depending on the type of rotation, equivalent forms relating 
angular aoceleration to the moment of external forces can be used from classical mechanics, lnl We state 
the problem as follows: Given differential equations of motion (1.) and (2) over a time interval [0, 
tN], and the key-frame constraints r(ti) -ri (3) O(t i) --#i (4) dr(q) dt vi (5) dO(ti) dt ~i (6) where 
ti, 0 ~ i ~< N, are instants of time (0 --to <h <...< tN), and vi and ~i are linear and angular velocities, 
respectively; find the trajectories r(t) and 0(t) such that they satisfy equations (1-6), and are natural 
and smooth. In general, some external forces and torques are necessary to satisfy the constraints of 
equations (3-6). In most cases, there are an infinite number of possible forces and torques that can 
force the trajectory to satisfy the above constraints. Our goal is to minimize the energy expended by 
these forces and torques since we believe that the most natural motion will occur when the least amount 
of force is applied. Smoothness of such a trajectory is dependent upon the eharaeteristics of differential 
equations (1) and (2). In most problems, these differential equations are at least see#rid order and 
if the forces are not discontinuous, the solution is at least twice differentiable. This suggests that 
the external forces should b~ continuous as well. To formalize our approach, we use state-space notation 
which is convenient for the application of control theory. This is done by converting differential equations 
(1) and (2) into a first order vector differential equation. As an example, if ~F0 and ~Mo in equations 
(1) and (2) do not contain any r-or #-dependent qu~ntiti#s, then |r(t) /  /0 (t) / this conversion 
is achieved by defining the state, s(t) - / dr [ dO Equations (1) and (2) can now he expressed as ds(t) 
0 0 dt -0 0 s(t) + ~Fo/m o o Ll-,2;Mo j where 0 and 1 are 3 x 3 zero and identity matrices, respectively. 
The quantity s(t) is called the state since it encapsulates all the information necessary for further 
evolution of the trajectory based on the differential equation. ~F0 and ~Mo contain control forces and 
torques, and can be written as G(t) u(t), where u(t) is the control vector and G(t) determines how control 
is related to the differential equation. Thus the above differential equation can be written in general 
? as: ds(t) , F(t) s(t) + G(t) u(t) (7)dt dr Since constraints of equations (3-6) are linear in r(t), 
#(t), -~-and d0 -~-, they can be expressed by proper choice of matrices M i and vectors 1If i where, 
'4'i -Mis(ti), i -- 1 ..... N (8) * r(t) It(t) drtO d0(t) , ~ -~-may be specified at different instants 
of time and they may be specified p~rtiatly. t If '~Foand ~Mocontuin r(t) and 0(t) dependent terms, then 
F(t) would have a diff~ent form.If this dependency is nonlinear, then equation (7) w l be nonlinear. 
Example of section 2.2 illustrates this conversion to the first order vector differential equation in 
detail.  @) ~ ComputerGraphics,Volume22, Number4, August1988 We have thus converted a higher order differential 
equation into a Thus, in this case, first order vector differential equation and the set of constraints 
defined by the keyframes into a set of linear constraints on the state vector. We wish to determine the 
control that minimizes a weighted sum of control energy and a measure of the smoothness of the trajectory 
s(t). That is, we want to minimize: IN J -f[(sr(t)A s(t)) + (uX(t)B u(t))]dt (9) o where A and B are 
appropriately chosen positive semidefinite matrices and the superscript T denotes the transpose. The 
above expression for J has sufficient generality to incorporate a variety of situations. For example, 
if we define the "smoothest" to mean the minimum of tN (d0x)x (_~_)2 + (_~)2]dt, then f[(-~-)2+ (dd~t)2+ 
(-~-)2+ dt +  0 i:0o:10 0 A -0 1 . On the other hand, to minimize control energy, g 0 0 would be set 
to identity matrix, and A to zero. As shown in the example below, by properly choosing A and B, different 
combinations of control energy and roughness of the trajectory can be minimized. Thus, the problem is: 
Given the differential equation in state variable form (7) and constraints as in equation (8), obtain 
a control function u(t) such that J of equation (9) is minimized. 2.2 An Example Consider a truck of 
mass m moving along the x-axis. The frictional force on the truck is inversely proportional to the speed 
of the truck (proportionality constant: u) and control is the force along x-axis applied by either the 
truck's gas peddle or the brakes. The differential equation is: d2x(t_._____) dx(t) u(t), 0 < t < tN 
(10) m dt2 ~-'~---- Suppose we want to specify the truck's position and velocity at three instants of 
time as: x(0) -0 dx(t~) x(h) -xl; dt l --~V x(tN) -xN (11) In accord with the previous discussion, we 
seek a control function u(t) that minimizes tN f dx(t) ] 2 J--o at + u2(t) ldt (12) f[[ J ~ dx(t) 12dt 
Minimization of [ dt J results in the smoothest trajectory x(t), since larger variations in x(t) will 
result in larger values of I dx(t) 12 .tN Similarly, minimization of j u2(t)dt minimizes the j. dt t/ 
magnitude of the total control, which tends to make the trajectory dominated by the solution of the unforeeed 
differential equation (10) (i.e., with u(t) -0). We employ a weighted combination of these two. Now, 
to convert this problem to state-space notation, we define the state s(t) as st (t) -x(t) s2(t)-dx(t___.~ 
(13) dt then u(t) (14)dt --s(t) + F -, and G --.  I:+1 I;l The constraints given by (11) are written 
as: l10ls(0) -x(O) [1 0]s(tt) -x(tt), [0 1]s(h) -vl [1 0]$(tN) -X(tN) (15) which define M and ~. The 
performance index J of Equation (12) can be written in the form of Equation (9) as follows: tN J -J [(s2(t)) 
~ + u2(t)]dt 0 --0f[(sT(t) s(t)) + (uT(t)u(t))ldt (16) tN Ill] Thus, in this case, A-[: 7]andB-[1]. Within 
this formulation several other meaningful quantities can be minimized by the proper choice of A and B. 
For exa~pl~,] if we want only a minimum energy control we set A-| I and B -[1]. If we want the trajectory 
t,o be very smooth, then we can100j to 0 increase the value of A, e.g., A-while keeping B the 0 1000 
same.  2.3 Solving the Control Problem While control theory can be applied to nonlinear differential 
equations, we have chosen for simplicity to solve only the linear problem.* For this case, as before, 
the differential equation is written in state-space notation as: ds(t) . F(t)s(t) + G(t)u(t) 0 ~< t <~ 
tN (17) dt Solving a control problem with several interior point constraints such as those of equation 
(8) is computationally complex since it leads to a multi-point boundary value problem FlOl . We can reduce 
the complexity of the problem by viewing it as a series of terminal constraint problems. That is, we 
solve the problem one interval at a time starting with interval [0, hi and ending with interval [tN-l, 
tN]. For the first interval, we have the following problem: Given ds(t) , F(t)s(t) + G(t)u(t), 0 ~< t 
~< t 1 dt and the key conditions s(0) -so  ils(tl) --~ , (18) find the control u(t), 0 ~< t ~< tl such 
that it minimizes tl J1 --f[(sr(t)A s(t)) + (uT(t)B u(t))]dt (19) 0 * The nonlinear problem may be solved 
by linear expansion of the differential equation about an initial guess of the trajectory_ and then solving 
the linear problem. The resulting solution is then taken as the new guess of the trajectory and this 
iterative process is continued.  ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 The solution to this problem 
is not optimal in the sense of minimizing N-1 J, but since J = ~ Ji the solution is not far from being 
optimal, Using '=0 control theory,[tdi it can be written as: u(t) = -B -t GT[K(0 -R(t)Q-1(t)Rr(t)]s(t) 
-B-1 GTR(t)Q-I(t)"Ft(20) where dK(t) = _K(t)F_F T K(t) -A + K(0GB-1GT K(0, K(tt) = 0(21)dt dR(0 = _(FT 
_ K(0GB-'GT)R(0, ROt) = M? (22)dt dQ(O = R(t)TGB-iGTR(t), Q(h) = 0 (23)dt Equations (21), (22) and (23) 
are solved backwards in time (i.e., from tt to zero) and their solutions are used to compute the control 
function function n(t). Equation (20) indicates that control is obtained as a combination of a time varying 
matrix multiplying the state s(t) and another time varying matrix multiplying the keyframe condition 
at time t, i.e., ~t+ These matrices are defined in terms of three other time varying matrices K(t), R(t) 
and Q(t); and their evolution in time is governed by the differential equations (21-23). Thus the principal 
cost of our approach is the numerical integration of equations (21-23). Although due to the generality 
of presentation, these equations may appear formidable, in practice matrices F,G,A, and B are sparse 
and in such cases, a large number of components of matrices K(t), R(t) and Q(t) are identically zero. 
In the control theory literature, equation (21) is commonly referred to as the Ricatti equation and since 
it is nonlinear, care is required in its numerical integration. Equations (22) and (23) are linear and 
can be integrated easily. It is worth noting that if we want to minimize only the control energy (i.e., 
A -0 and B -1), then K(t) is identically zero and considerable simplification results. After solving 
first the control u(t) and then the trajectory s(t) for subinterval [0, h], we solve the identical problem 
for subinterval [q, t2]. The state at tt, S(tl), which is known by solving the problem for the first 
subinterval, now becomes the initial keypoint for the next subinterval, [tl, t2]. Thus, S(tl) --Sl M2s(t2) 
-@2 (24) We have imposed continuity of state at h and because the state includes the trajectory and its 
first derivative (for a second order differential equation), we have constrained the trajectory and its 
first derivative to be continuous across the subintervals [0, tl] and [h, t2]. This process is continued 
to the last subinterval, [ts-x, tN]. 3. The Truck Example The truck problem presented in section 2.2 
was expanded to include ad~intio~l keypoints and was then solved using our approach with A-Iv[ and B-[I]. 
The graph in Figure 1 shows the [0 lJ path of the truck computed using the optimal control approach. 
This path is smoother than that shown in Figure 2 which was computed using an interpolating cubic spline. 
To bring out the differences in smoothness, both these figures also show the rate of change of x(t), 
or the velocity. As expected, the spline interpolation shows velocity as a number of quadratic functions 
pieced together. The amount of variation in the velocity is large compared to that produced by the optimal 
control method. Although it is difficult to illustrate, difference in the naturalness of motion is quite 
evident on the screen. This may be due to our approach requiring nearly thirty times less control energy 
than the spline method. To force the solution of the differential equation to be an interpolating cubic 
spline, a large control or force is necessary, making the trajectory appear unnatural. Plots of control 
used by both methods are shown in Figures 3 and 4. These plots also illustrate discontinuity of control 
at the boundaries of subintervals. Discontinuity is particularly severe for the spline method, which 
further reduces its naturalness. 80O 10O g0  600- ion .60 Posidon as Velocity(Plotted as .)  (Ploned 
as u} 400 - ~ 40 -20 200- 0 5 10 15 Time Figure 1: Positionand Velocity of Truck Computed Using Optimal 
Control 800 100 -80  600- / Posi6on -60 (Plotted as ') Velocity plotted as ~) 400-.] -40 -20  200- 
I l 5 10 15 Time Figure 2: Position and Velocity of Truck Computed Using Cubic Spline Solution of the 
control problem as posed in equations (17-19) has some undesirable properties. The continuity constraints 
we have imposed ensure that the solution is smooth across subintervals (i.e., the position and velocity 
are continuous) and that the trajectory is smooth within a subinterval. However, most of the control 
is applied at the beginning of each subinterval." (See Figure 3). Although the resulting motion is relatively 
smooth, it can be improved, particularly at the boundary of subintervals. One method of doing this, while 
still solving one subinterval at a time, is to impose the additional constraint that control be a continuous 
function of time throughout [to, t s] and then minimize the energy in control as well as its first derivative. 
This would result in a smoother control function which in turn would increase the smoothness of the trajectory 
at the boundary of two subintervals. This revised approach is described below. 4. A Continuous Control 
Approach First we augment the state by including the control. We define the derivative of control as: 
w(t) du(t) (25)dt * Intuitively speaking this may be due to the fact that early application of control 
within a subinterval allows the control to have the largest impact in shaping the trajectory. Later application 
of control rnav require larger control and therefore larger control energy to satisfy the terminal keyfrarne 
constraints.  ~:~ ~ Computer Graphics, Volume 22, Number 4, August 1988 20O O-f Amount of Control -2.00- 
-400- I I 0 5 Time 10 15 Figure 3: Amount of Control Applied to Truck Using Optimal Control 0 5 Time 
10 15 Figure 4: Amount of Control Applied to Truck Using Cubic Spline and construct a new state equation: 
 -~(t) + (26) dt 0 w(t)  = 1 [° l where Is(t) 1 ~(t) - (27) [u (t) ] As before, we solve the problem 
one subinterval at a time, starting with the subinterval [0, t~]. The initial value of the control, u(0), 
is simply set to zero." For this subinterval, the key conditions become: " .0,10 [s ,l (28) ~(o) tu(O)] 
u - Mls(h) -~'1 becomes  [S(tl) l [MiO] [u(tt)] -~1 A Ml~(ti ) (29) * Any otter value can be chosen, 
but we choose zero in the spirit of keeping control as small as possible. Optimum value can aim be found, 
but this leads to a more complex two-point boaffdary value problem, t~°J The new control, w(t), is derived 
to minimize: t] J1 -f[ (~T (t)A~(t)) + (w T (t)Bw(t))]dt (30) 0 where matrices A and B are chosen as 
before. Now the problem is in the same symbolic form as the previous problem with barred quantities replacing 
unbarred quantities. By ensuring that the new state, ~(t), remains continuous across the subintervals 
[0, tt] and it l, t2], we ensure that the state and the control remain continuous. Because components 
of s(t) are trajectory, its first derivative, and control, we have ensured their continuity throughout 
the interval [to, tN]. Additionally, our new performance index minimizes the energy in w(t), and therefore 
control fluctuations are minimized. The overall effect of this is that the resulting motion is smooth 
and natural. The following example illustrates this revised approach.  4.1 Revised Approach for the 
Truck Example To solve the truck example described in section 2.2 by this revised approach, we first 
augment the state equation (14) to include the derivative of control: d [s2(t) _..~_ --.-.L [s2(t) + 
w(t) (31) [ u(t) m m [u(t ) 0 0   Ii °1 IH At t -0, key conditions are: At t -h, only s~(h) is known, 
therefore: Is,(t,)] [sl(tl) ] ~, /s:(t,)[-tl o / -s,(t,) (33) [u(t,)] [u(t,)] The matrices -b and B-[el 
(34) 0 will minimize " 2 - 0 bIdX(t) / 2 eldU(t) / ]dt 31 ftax2(t) + [--~---j + cu2(t) + (---~---j (35) 
 The nevi results are shown in Figures 5 and 6. It can be seen that the new path is smoother than that 
generated by the original approach, and there are no discontinuities in u(t). However, in order to achieve 
this increased smoothness, the amount of control has increased. For this example, the control energy 
used by the revised approach is fifteen times that of the original approach, but it is still only half 
that required by the interpolating cubic spline. 5. The Aircraft Example To demonstrate the ability 
of this algorithm to handle more complex problems, we chose to simulate the problem of perturbation of 
an aircraft from a straight-line flight, ll2l Consider an aircraft of mass m moving along its equilibrium 
flight direction, X, which is in the aircraft's plane of symmetry, Y is out the right wing and Z is down. 
The velocity of the perturbed motion is not allowed to deviate far from tbe x-direction so we can describe 
its orientation by the sideslip angle /~ and the angle of attack change Aa as shown in Figure 7. ¢SIGGRAPH 
'88, Atlanta, August 1-5, 1988 lo08O0 -g0 600--60 Position (l, lottea as -) Velocity (Plotted as 1:3) 
400- -40 -20 200- I [ 0 5 10 15 Time Figure 5: Position and Velocity of Truck Computed Using Revised 
Optimal Control 200 Amount of Control -200- -400- I I 5 Time 10 15 Figure 6: Amount of Control Applied 
to Truck Using Revised Optimal Control X V + v~ ¥ Z Figure 7: Coordinate System for aircraft example. 
 With V the equilibrium velocity, the components of instantaneous velocity are given by: v-V+v~, vy-VB, 
vz-VA~ (36) The force and moment equations are: dvx dtox d~oz Fx " m'~ -' M~ " Is"~ --Jzx dt dB , My 
-Iy Fy --mV ~ + OOz dt  I 1 d,0, [ d (Ac~) / d~z dwx Fz -mV [---~---- -~y , Mz --Iz-~---J~--~-(37) 
where, the components of t~ are the time derivatives of the Euler angles. The matrices for the state 
equation of this problem using the notation in equation (26) are: 0 0 0 0 0 010 0 0 0 0 00000 0 0 0 0 
0 0 0 1 0 0 0 0 00000 0 0 0 0 0 0 0 010 0 0 000000 0 0 0 0 0 0 0 0 0 1 0 0 0o0ooo i 0 0 0 0 0 0 0 0 0 
0 1 0 000000 I 0 0 0 0 0 0 0 0 0 0 0 1 000000 F(t) - G(t) - 0 0 0 0 0 0 0 0 0 0 0 0 aO0000 0 0 0 0 0 
0 0 0 0 0 0 -V 0b0000 0 0 0 0 0 0 0 0 0 0 V 0 OOcO00 0 0 0 0 0 0 0 0 0 0 0 0 000d0c 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 o 0 f 0 0 0 0 0 0 0 0 0 0 0 0 0 000g0h where 1 lz a-b--c----, d m Ixlz-(J~x) 2 Jzx 1 Ix e-h 
Ixlz (j=)2, f---g --Iy' Izlx - (Jzx) 2 The control used in the spline method is several times higher 
than that used by our method. Figures (8-9) show, as examples, the control applied in both approaches 
for translational motion. This example also illustrates one of the major advantages of this approach 
--the ability to handle dependencies between the parameters of motion. The dynamic equations given in 
(37) show that linear and angular motion are coupled. For example, the translational motion along the 
y-axis is affected by the rotational motion about the z-axis. Since our algorithm uses the dynamics, 
it produces interpolations which incorporate these dependencies. The resulting animation looks more natural 
than that generated by interpolating cubic spline. 0.05 - Amount of Control 0- i I I I I 0 0.5 1 1.5 
2 Time Figure 8: Control Applied to Translational Motion Along X-axis (Revised Optimal Control) ~ Computer 
Graphics, Volume 22, Number 4, August 1988 REFERENCES 40- Amount / of Control  20 / // 0- /// -20 
- / -40 - ! I I I I 0 0.5 1 1.5 2 Time Figure 9: Control Applied to Translational Motion Along X-axis 
(Spline) 6. Summary The algorithm presented in this paper provides a systematic method for obtaining 
smooth natural looking motion from keyframes. It also provides a large amount of flexibility in specifying 
the keypoints, since any portion of the state can be specified at any time. Thus any combination of position, 
orientation, translational and angular velocities can be specified at any key point. We have demonstrated 
that control theory formulation is appropriate and results in desirable characteristics in animation. 
Although within this formulation various measures of smoothness of the trajectory and control energy 
are possible, we have found that the appropriate measure is a weighted combination of integrals of the 
square of the first derivatives of trajectory and control. Weights determine the relative importance 
given to the trajectory derivative and the control energy and can be used as an additional tool by the 
animator for the particular application at hand. We have also shown that for additional visual smoothness, 
control should be a continuous function of time. Since most differential equations resulting from modelling 
dynamics are at least second order, our animation results in trajectories that are at least twice continuously 
differentiable. Compared to the traditional approach to animation, our approach requires more computations 
and additional information such as: models of the dynamic behavior of the objects in the environment 
and proper choice of the performance index. Much of the computational burden comes from the need to solve 
several differential equations. Some of these differential equations arise from the dynamic modelling 
and are therefore common to any other approach that models dynamic behavior. Additional equations due 
to control-theory formulation depend upon the precise choice of the smoothness criteria used. Although 
our animation looks natural and smooth, we have not yet performed any subjective tests to correlate quality 
of motion (e.g., natural, smooth and visually pleasing) with the choice of the performance index or whether 
computationally cheaper approximations will suffice. Our test models have been restricted to that of 
simple rigid bodies with three or six degrees of freedom. We also restricted ourselves to linear differential 
equations and linear constraints. However, the method can be extended to non-rigid bodies and nonlinear 
situations. 7. Acknowledgements We thank Dave Hagelbarger, Roger Faulkner, Debasis Mitra and Jerry Well 
for help in various phases of this project. In addition, Don Mitchell, Bruce Naylor and David Thomas 
helped sharpen many of our wet ideas. 1. Magnenat-Thalmann, N. and Thalmann, D., "Computer Animation: 
Theory and Practice", Springer-Verlag,. 1985. 2. Stern, Garland, "Bbob -a System for 3-D Key-Frame Figures 
Animation", S1GGRAPH'83, Tutorial Notes on Introduction to Computer Animation, pp. 240-243. 3. Sturman, 
David, "Interactive Keyframe Animation of 3-D Articulated Models", Graphics Interface, '84, pp. 35-40. 
 4. Kochanek, Doris H. U. and Barrels, Richard H., "Interpolating Splines for Keyframe Animation", Graphics 
Interface '84, pp. 41-42. 5. Shoemake, Ken., "Animating Rotation with Quaternion Curves", SIGGRAPH'85, 
Computer Graphics 19 (3), pp. 245-254. 6. Armstrong, W. W. and Green, Mark, "The Dynamics of Articulated 
Rigid Bodies for the Purposes of Animation", Graphics Interface, '85, Montreal, pp. 407-416. 7. Wilhelms, 
Jane and Barsky, Brian A., "'Using Dynamics for the Animation of Articulated Bodies Such As Humans and 
Robots", Graphics Interface '85, Montreal, pp. 407-416. 8. Raibert, Marc H., et. al., "Experiments in 
Balance with a 3-D One-Legged Hopping Machine", The International Journal of Robotics Research, Vol. 
3, No. 2, 1984, pp. 75-92. 9. Isaacs Paul M. and Cohen, Michael F., "Controlling Dynamics Simulation 
with Kinematic Constraints, Behavior Functions and Inverse Dynamics", SIGGRAPH'87, Computer Graphics 
21 (4), pp. 215-224. 10. Bryson, A. E. and Ho, Y., "Applied Optimal Control: Optimization, Estimation, 
and Control", Hemisphere Publishing Corp., 1975. 11. Goldstein, H., "Classical Mechanics", Addison-Wesley, 
Inc. 1951. 12. Halfman, R. L., "Dynamics", Addison-Wesley, Inc. 1962.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378535</article_id>
		<sort_key>317</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Getting graphics in gear]]></title>
		<subtitle><![CDATA[graphics and dynamics in driving simulation]]></subtitle>
		<page_from>317</page_from>
		<page_to>326</page_to>
		<doi_number>10.1145/54852.378535</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378535</url>
		<abstract>
			<par><![CDATA[Man-in-the-loop simulation uses a person in the control loop to provide feedback to the system operations. Proper operator cueing must be provided to ensure a realistic response. Real-time computer graphics and dynamics both play dominant roles in providing these necessary cues. Dynamics simulation of modern vehicles requires a multi-body non-linear approach for acceptable fidelity of motion. A vehicle can be modeled as a set of linked rigid bodies, whose connections are described by a graph. Real-time constraints on the computation of non-linear dynamics equations require the development of naturally parallel recursive algorithms, whose organization closely follows the system graph. Significant speed-up can be accomplished using these parallel algorithms.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[engineering simulation]]></kw>
			<kw><![CDATA[parallel algorithms]]></kw>
			<kw><![CDATA[real-time dynamics]]></kw>
			<kw><![CDATA[real-time graphics]]></kw>
			<kw><![CDATA[vehicle simulation]]></kw>
			<kw><![CDATA[visual systems]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Parallelism and concurrency</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Parallel algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Real time</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761.10003762</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency->Parallel computing models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169.10010170</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010170</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P335097</person_id>
				<author_profile_id><![CDATA[81100255569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rod]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Deyo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Evans & Sutherland, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334874</person_id>
				<author_profile_id><![CDATA[81100277520]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Briggs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Evans & Sutherland, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335040</person_id>
				<author_profile_id><![CDATA[81100131399]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pete]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Doenges]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Evans & Sutherland, Salt Lake City, UT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Armstrong, W. Recursive Solution to the Equations of Motion of An N-Link Manipulator. In Proc. 5th World Congress on Theory of Machines and Mechanism, Vol. 2, (Montreal, 1979), 1343-1346.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bae, D. and ttaug, E. A Recursive Formulation for Constrainted Mechanical System Dynamics. Technical Report 86-14, Center for Computer Aided Design, College of Engineering, University of Iowa, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baumgarte, J. Stabilization of Constraints and Integrals of Motion in Dynamic Systems. Computer Methotis in Applied Mechanics in Engineering, 1 (1972), 1- 16.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Casali, J. and Wierwille, W. The Effects of Various Design Alternatives on Moving-Base Driving Simulator Discomfort. Human Factors, 22, 6 (1980), 741-756.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chace, M. Methods and Experience in Computer Aided Design of Large-Displacement Mechanical Systems. In Computer Aided Analysis and Optimization of Mechanical System Dynamics, E. Haug. (ed.). Springer-Verlag, Heidelberg, 1984.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dennis, J. and More, J. Quasi-Newton Methods, Motivation and Theory. SIAM Review 19, 1 (1977), 46-89. September 1967, pp. 250-253.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dickmanns, E.D., and Zapp, A. Guiding Land Vehicles Along Roadways by Computer Vision. Presented at AFCET Conference "Automatique 85 - the tools for tomorrow", Toulouse, October 1985.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Doenges, Peter K. Overview of Computer Image Generation in Visual Simulation, Presented at ACM Siggraph Technical Courses, July, 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Duncan, J.R., and Wegscheid, E.L. Off-Road Vehicle Simulation for Human Factors Research. Paper 82- 1610, 1982 Winter Meeting, American Society of Agricultural Engineers (Chicago, Dec. 14-17, 1982.)]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Drosdol, J. and Panik, F. The Daimler-Benz Driving Simulator: a Tool for Vehicle Development. SAE Technical Paper Series, 850334, (Feb. 1985).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gear, W. Differential-Algebraic Equations. In Computer Aided Analysis and Optimization of Mechanical System Dynamics, E. Haug (ed.) Springer-Verlag, Heidelberg, 1984.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Goldstein, H. Classical Mechanics. Addison- Wesley, Reading, Mass., 1980.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hahn, S., and Kalb, E. The Daimler-Benz Driving Simulator Set-Up and Results of First Experiments. In Summer Computer Simulation Conference Proceedings Simulation Councils, Inc., San Diego, 1987, pp. 993 - 998.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>600920</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Haug, E. (ed.) Computer Aided Analysis and Optimization of Mechanical System Dynamics. Springer- Verlag, Heidelberg, 1984.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Haug, E. Elements and Methods of Computational Dynamics. In Computer Aided Analysis and Optimization of Mechanical System Dynamics, E. Haug (ed.).]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hooker, W. and Margulies, G. The Dynamical Attitude Equations for an n - Body Satellite. J. Astronaut. Sci. 12 (1965), 123-128.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Issacs, P. and Cohen, M. Controlling Dynamic Simulation with Kinematic Constraints, Behavior Functions and Inverse Dynamics. Computer Graphics 21, 4 (July 1987), 215-224.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kempf, D., Bonderson, L., and Slater, L. Real Time Simulation for Application to ABS Development. SAE Technical Paper 870336, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Lambert, J. Computational Methods in Ordinary Differential Equations. John Wiley, New York, 1973.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Luh, J., Walker, M., and Paul, R. On-line Computational Scheme for Mechanical Manipulator. J. Dyn. Syst. Measurement Control 102 (1980), 69-76.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Nordmark, S. VTI Driving Simulator - Mathematical Model of a Four-wheeled Vehicle for Simulation in Real-Time. VTI Rapport Nr 267A 1984. Statens vagoch trafikinstitut, Link~ping, Sweden, 1984.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Orlandea, N., Chute, M., and Calahan, D. A Sparsity- Oriented Approach to the Dynamic Analysis and Design of Mechanical Systems- Parts 1 and 2. J. of Engineering for Industry (1977), 773-784.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Richter, Bernd. Driving Simulator Studies - the Influence of Vehicle Parameters on Safety in Critical Situations. SAE Technical Paper Series, 741105, (Feb. 1974).]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Sheridan, T.B., Paynter, H.M., and Coons, S.A. Some Novel Display Techniques for Driving Simulation. In IEEE Transactions on Human Factors in Electronics, Vol. HFE-5, September 1964, pp. 29-32.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Wehage, R. and Haug, E. Generalized Coordinate Partitioning for Dimension Reduction in Analysis of Constrained Mechanical Systems. J. of Mechanical Design, 104 (1982), 247-255.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Weirwille, W. W., Gagne, G.A., and Knight, J. R. A Laboratory Display System Suitable for Man-Machine Interface. In EEE Transactions on Human Factors in Electronics, Vol. HFE-8, No. 3.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Wittenburg, J. Dynamics of Systems of Rigid Bodies. B. G. Teubner, Stuttgart, 1977.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Getting Graphics in Gear: Graphics and Dynamics 
in Driving Simulation Rod Deyo John A. Briggs Pete Doenges Evans &#38; Sutherland Salt Lake City, 
UT 84108 Abstract Man-in-the-loop simulation uses a person in the con-trol loop to provide feedback 
to the system operations. Proper operator cueing must be provided to ensure a re-alistic response. Real-time 
computer graphics and dynam- ics both play dominant roles in providing these necessary cues. Dynamics 
simulation of modern vehicles requires a multi-body non-linear approach for acceptable fidelity of motion. 
A vehicle can be modeled as a set of linked rigid bodies, whose connections are described by a graph. 
Real-time constraints on the computation of non-linear dynamics equations require the development of 
naturally parallel re- cursive algorithms, whose organization closely follows the system graph. Significant 
speed-up can be accomplished using these parallel algorithms. CR Categories and Subject Descriptors: 
J.6 [Computer-Aided Engineering]: Computer-aided de-sign; G.1.0 ]Numerical Analysis[: General -Parallel 
al- gorithms; J.7 [Computers in Other Systems]: Real time; 1.6.3 [Simulation and Modeling]: Applications; 
1.3.7 [Computer Graphics]: Three-dimensional Objects and Realism -Animation; Color, shading, shadowing, 
and texture. General Terms: Algorithms, Performance, tiuman Factors Additional Key Words and Phrases: 
Vehicle simu- lation, Real-time dynamics, Parallel algorithms, Real-time graphics, Engineering simulation, 
Visual systems Permission to copy without fee all or part of this material is granted provided that 
the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and 
the title of the publication and its date appear, and notice is given that copying is by permission of 
the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific 
permission. 01988 ACM-0-89791-275 $00.75 -6/88/008/0317 Introduction In the last fifteen or so years, 
man-in-theqoop simulation using computer-generated, real-time graphics has assumed a major role not only 
in pilot training, but also in engineer- ing applications for land, sea, air, and space vehicles. Man- 
in-the-loop simulation uses a person in the control loop of a simulation to provide feedback to the system 
operations. The operator experiences a synthetic environment, manip- ulates his controls in response 
to the situation, and experi- ences the results of his actions. In a real-time simulator, the dynamics 
model is continually evaluated to give feedback to the operator. On the basis of this data, the simulator 
provides realistic environmental cues to allow him to con- trol the simulated vehicle in the same way 
that he would in the real World. The goal of human interaction with a design is to tune raw performance, 
stability, ride quality, and safety mar-gins, to suit human tolerances in control, task loading, and 
comfort. Through the use of simulation, training or design testing can often be achieved at lower cost, 
experiments can be conducted under controlled, repeatable circumstances, and --important for engineering 
--vehicle designs can be evaluated while minimizing the number of prototypes. An important engineering 
use of simulation with a per- son in the loop is to determine vehicle response and to study the man-machine 
interface before the start of a vehicle test program. For example, a new aircraft can be modeled and 
test flown even before it leaves the drawing board. The pilots can give valuable feedback to the designers 
about the plane's characteristics at an early enough stage to per- mit changes in the airframe. Integration 
of the avionics systems can be achieved at an earlier time. Workload mea- surements can be made, and 
different alternatives can be tested. Computer graphics represents a large portion of the cost of man-in-the-loop 
simulation. Hence, as the capabil- ities of computer image generation have improved and the relative 
cost of simulation has dropped, there are better economic justifications for its use. In some applications, 
such as the space shuttle simulator, there has never been a good alternative to simulator training. In 
other areas, how- SIGGRAPH '88, Atlanta, August 1-5, 1988 ever, such as vehicle engineering, cost of 
man-in-the-loop simulation testing has always been an important consider- ation, and, as a result, has 
only recently been low enough to justify simulation on a large scale. Computer graphics is the critical 
element in creating a realistic operator environment in a simulator, but the graphics must work in concert 
with the rest of the sys-tem to be believable. In particular, the vehicle motion and the scenes generated 
must seem realistic in order not to seem like an arcade game. To show how real-time com-puter graphics 
and dynamics must work together in vehicle simulation, we have selected a specific application to discuss 
driving simulation. We will give a brief history of the use of synthetic imagery in simulation, identify 
the com-ponents of a modern simulator with emphasis on the role of the visual system, present a new approach 
to computing vehicle dynamics that promises significantly improved ve- hicle models for realistic motion, 
and conclude with a view of the future. Historical Perspective Department of Defense initiatives through 
the military and its contractors have done much to advance the state-of-the-art in simulation and computer 
graphics. For example, seminal work in computer graphics conducted at the Uni- versity of Utah under 
the leadership of Dr. David Evans two decades ago was largely sponsored by the Department of Defense's 
Advanced Research Projects Agency. The U. S. Air Force supported in part the first use of CRTs in driving 
simulation at MIT in 1962 124]. This work by T.B. Sheridan, H.M. Paynter, and S.A. Coons was the earliest 
use of an artificial display of a vehicle path in dy- namic perspective. A refined implementation was 
devel-oped by W.W. Wierwille, G. A. Gagne, and J. Knight at Cornell Aeronautical Laboratory in 1966 [26]. 
Use of these same techniques occurred at General Mo- tors in the late 1960's. In the early 1970's, both 
Volkswa- gen 123] and the Swedish Road and Traffic Institute (VTI) [21[ built driving simulators with 
visual and motion sub- systems. A number of simulators were built over the next decade. For example, 
simulators at the Virginia Polytech- nic Institute and State University [4] and Deere and Com- pany 19] 
were developed primarily to support human factors research. Another system, complete with motion platform, 
was constructed at Universitaet der Bundeswehr Muenchen for research into guiding land vehicles with 
computer vision a sort of robot-in-the-loop simulation [7 I. The graphics associated with these systems 
were limited. Line segments representing the road were displayed on a single CRT or projected on a flat 
screen in front of the driver. In 1984, over twenty years after the MIT project, Daimler-Benz built, 
in Berlin, the first driving simulator expressly as an aid to designing vehicles 110] [131. This sys- 
tem marked the first use of a 180-degree-wide image on a dome in a driving simulator. For the first time 
a driver was able to use his peripheral vision in a natural way. The Daimler-Benz simulator was built 
to allow test drivers to make subjective judgments about the handling qualities of new automobile designs. 
Today's Advanced Simulator Our advanced man-in-the-loop simulator (Figure 1) is made up of a few, expensive 
subsystems that combine to create a complete synthetic driving environment for the operator: * The host 
computer (Figure lg) controls all of the real- time operations of the system, including computation of 
the vehicle and motion platform dynamics. All cal- culations for the entire system are performed within 
a 10 ms time frame. An integrated data base contains visual models, geometric data on the simulated en-vironment, 
data relating to the sounds encountered, and mechanical characteristics of the vehicle. . The visual 
system calculates the correct image (Fig- ure lb) based on position information from the host computer. 
It removes hidden areas, computes the sun angle, smooth shades, textures, and anti-aliases the result. 
There is a high degree of parallelism in the foregoing operations, allowing about ten GIPS (Gigs Instructions 
Per Second) operation in a large system. Multiple CRT projectors (Figure la) display an im-age on the 
dome. Special screen material is used for maximum brightness and contrast.  The motion platform (Figure 
1-2,3,d) is a configu-ration of hydraulic actuators that can move the op- erator's cab in any direction 
or angle by combining motions about the x, y, z, yaw, pitch, and roll axes. The control signals to the 
motion platform are fil-tered ("washed out") to transform the virtual real-world motion computed by the 
dynamics software into movements achievable by the system.  The sound subsystem (Figure le) uses multiple 
speak- ers to generate appropriate sounds to simulate the engine, gear whine, wind noise, passing traffic, 
etc.  Instrumentation (Figure lh) provides data to the host computer to monitor the the entire system 
and ensure the driver's safety.  Control force loaders (Figure lc) are used to provide appropriate forces 
back to the operator through the steering wheel, brake pedal, and transmission lever to replicate the 
feedback forces found in a real car.  The operations console (Figure lf) allows a single per- son to 
oversee all of the simulation activities, allowing flexible control over vehicle tests.  Relating Graphics 
and Dynamics Under Real-Time Constraints Driving simulation for automotive engineering must pro-vide 
enough accuracy in simulating vehicle motion and in SIGGRAPH '88, Atlanta, August 1-5, 1988 Provide 
constant interfaces between different forms of the same data distributed within the simulator so that 
changes afforded by technology advances can be easily incorporated into simulator improvements.  Develop 
simulator software architectures that port easily into future computer systems.  Provide as much reserve 
capability as economically possible.  CIG Demands of High-Performance Driving Simu- lation The use 
of real-time, man-in-the-loop simulators for the evaluation of designs of hlgh-performance land vehicles 
has greatly lagged flight simulation. Major advances in dynam- ics, washout, motion, and graphics have 
recently set the stage for another leap. The current state of CIG (Computer Image Generation) evolution 
is closely approaching photographic realism with update rates, lag, and image quality that suffice for 
a broad range of operational and perceptual objectives. Recent ad- vances in computing and mechanical 
dynamics techniques have set the stage to achieve vehicle behavior in a simula- tor rivaling the quality 
of CIG real-time graphics, and to afford dynamics quality capable of unmasking subtle CIG shortcomings 
rarely encountered before now. CIG improvement is driven by operational maneuver-ing and perceptual requirements 
[8]. Driving involves very low eye heights where optical flow density must change very rapidly over the 
field of vision available in a car. The driver must be able to judge speed and proximity to obstacles 
very quickly by visualizing textural cues in and around the road as well as passing 3D features. The 
visual depiction of the road surface must be good enough for the driver to antici- pate road hazards 
like bumps and ice. When appropriate, urban, country, and highway scenes must be possible with contending 
traffic and pedestrians to saturate the driver's task loading and reaction times. The basic psychology 
of vision and kinematics of driver responses at the controls of the car also demand CIG fi- delity. The 
effective resolution of the CIG image deter- mines what the driver can detect and recognize. A driving 
simulator should ideally match the lag, from control input to visual result, at a few tens of milliseconds 
typical of re- sponsive cars. The rate of image refresh and update must satisfy eye demands for visual 
tracking, smooth motion of scenery, flicker-free viewing and discrimination of temporal events that may 
alter driver response. The current generation of top-end real-time CIG is rep- resented by such products 
as the Evans &#38; Sutherland CT-6. This system offers critical improvements in scene perfor-mance needed 
to discriminate the nuances of vehicle be- havior possible with the dynamics techniques covered in the 
following section. Synthetic and photographic texture along with high 3D feature densities now allow 
sound judg- ments to be made about speed and distance. Subpixel anti-aliasing allows road signs and road 
surfaces to be vi- sualized reliably at varied vehicle speeds. Generalized oc- cultation allows complex 
traffic movement over rolling ter- rain, around urban clutter, and among other traffic. Mul- tiple eyepoints 
can support the virtual eyepoints of mir- rors and the simultaneous observation of own-vehicle chas- 
sis and suspension behavior from external vantage points while driving the car through difficult maneuvers. 
Figure 2 shows a typical driving landscape and situa- tion achievable with CT-6 for driving simulation. 
Figure 3 represents the kind of car-external viewing of critical mo- ments in suspension deformation 
and chassis excursions. This real-time visual display can complement a designer's study of subtle car 
subsystem motion over specific road ge- ometries. Real-Time Vehicle Dynamics Overview Non-real-time computer 
simulation of compli- cated mechanical linkages has been performed for machines, robots, spacecraft, 
and ground vehicles. ]'rue real-time sim- ulation is more difficult and hitherto done only for relatively 
simple mechanical systems, complex systems with approx- imated governing equations, or by using specialized 
com-puter hardware. For example, aircraft are usually treated as relatively simple mechanical systems 
subject to compli- cated forces calculated from experimental data, while au- tomobile systems are often 
approximated by eliminating velocity coupling effects. Engineering simulation of mod- ern high performance 
vehicles demands a multi-body non- linear approach in order to provide acceptable fidelity of motion; 
software flexibility is required to deal with the var- ied nature of vehicle engineering problems. A 
solution to real-time engineering simulation requires both cost-effective computational capacity and 
the adaptability of general pur- pose computers and software. Simulator system integration and introduction 
into the real-time software of motion-base washout and vehicle subsystem models must be facilitated by 
the use of standard operating systems and programming languages. Two significant approaches to real-time 
vehicle dynam- ics modeling, albeit at very different levels, are those imple- mented by the Swedish 
Road and Traffic Research Institute (VTI) [21} and Daimler-Benz [10] [13]. The VTI model em- ploys a 
simple, planar three degree-of-freedom car, but care- fully considers tire and other forces. Daimler-Benz 
achieves real-time with a much more sophisticated, but still sim- plified, vehicle dynamics model. It 
has successfully been used to perform driver behavior and vehicle design studies. Small velocity coupling 
terms are neglected in the equations of motion to achieve real-time performance. We are primarily interested 
in the accurate prediction of vehicle dynamics, rather than kinematics or inverse dynam- ics [17]. The 
approach we use decomposes the system into a set of rigid bodies (a rigid body requires distances between 
points within the body to be fixed) that are connected by joints that allow relative motion between the 
bodies, sub- ject to various forces, moments, and additional constraints. SIGGRAPH '88, Atlanta, August 
1-5, 1988 the second class, a minimal, or at least small, set of relative coordinates is used recursively 
to identify a body's position [16[. The first method has the advantages of generality and relatively 
simple equations and the disadvantage of rarely being optimal for a given mechanism or vehicle. Commer-cial 
codes, such as DADS [25] or ADAMS [5], use general- ized Cartesian coordinates for each body and apply 
a max- imal set of constraints. This is similar to finite element methods in structural mechanics where 
a very large, but sparse, equation set is generated. In the second method, a minimal set of relative 
joint coordinates is used, and fewer constraints must be applied, but the equations are often extremely 
complex. This minimal coordinate description is very effective in describing spacecraft and robots, since 
these systems naturally form tree graphs. A complication occurs when closed loops appear in the system 
graph, since the relative joint coordinates are then subject to additional constraints from the closing 
of the loop, and so are not in-dependent. Wittenburg 127] considered the idea of cutting the closed loop 
to form a tree graph, and adding Lagrange multipliers to the equations of motion to satisfy the now missing 
constraints. Once the system graph is a tree, re-cursive methods developed by Hooker and Margulies [16 
l for spacecraft, and Armstrong [1] and Luh, et. al. [20], for robotics, can be used to recover body 
accelerations. Bae I2], using these ideas in his thesis, derived an algo-rithm combining cut joints with 
recursion. In addition, he discussed issues relating to the natural parallelization of the resulting 
algorithm. Essentially, we have implemented Bae's work, adding additional techniques for stable integra- 
tion and pipeline delay reduction to the parallel recursive algorithm. Vehicle Graph A typical modern 
high-performance sports sedan consists of a chassis, the two MacPherson front herical Joint Piston Rod 
Rack L~'--~",',--Tran slatio n all Joint Assembly t Swiss Arm Figure 4 * McPherson Strut Front Suspension 
 suspension subsystems, the steering rack, and the two rear suspension arms. The MacPherson front suspension 
sub- system is detailed in Figure 4. This suspension allows both jounce (spindle vertical motion) and 
steer (the rotation of the spindle) as independent motions. Steering is done by motion of the tie-rods 
(which act as distance constraints) connecting the rack and spindle. The corresponding vehi- cle graph 
is shown in Figure 5. There are four closed loops cut  -c°, cud ~ R4/ Figure 5 - Vehicle Graph with 
Closed Loops from the front suspension and steering linkages. If we ~:ut the links between rack and 
spindle, and lower control arm and spindle on both sides, we produce the tree graph shown in Figure 6. 
C   "2/fy/ ® Figure 6 -Graph after Cutting Closed Loops Vehicle Coordinates In Figure 6, the chassis 
is the base body vertex, whose coordinates are the three Carte- sian degrees of freedom Fi of the center-of-mass 
in the iner- tialframe and a vector ~, of four Euler parameters [141 [12] describing its orientation. 
The lower control arm Cartesian position is determined by the chassis position and specifi- cation of 
the revolute joint angle (the rear suspension arms have a similar description). The strut's position 
is given by the chassis and spherical joint orientation (again using ~ Computer Graphics, Volume 22, 
Number 4, August 1988 Euler parameters). The spindle's position can be found from the strut's position 
and the translational joint dis-tance. The position of the rack relative to its translational joint with 
the chassis is prescribed by the driver's steering input. Notice that we have not yet closed any of the 
four loops in Figure 6. The four tires are not treated as individual bodies, but are given only a single 
rotational degree of freedom and re- sulting inertia. In our model, there are 10 rigid bodies, 4 tires, 
and 26 body and relative joint coordinates (not all independent) used in the kinematic description of 
the vehi- cle tree graph. The constraints from the closed suspension and steering loops must be added 
to these 26 coordinates. Neglecting the tire as a full body is reasonable, since tire inertial forces 
can be separately calculated and added as additional external coupling torques to the equations of motion. 
Flexibility in any of the bodies is not presently considered, but can be added as additional generalized 
de- formation coordinates. Holonomic Vehicle Constraints The vehicle coor- dinates are subject to holonomic 
constraints [12] ~(~, fi~) = 0 from the closed loops in the graph and are not indepen- dent. Constraints 
of this type reduce the number of inde- pendent coordinates by the row-rank of the Jacobian of par- tial 
derivatives of each constraint component by the coordi- nates. When the constraints are independent, 
the row-rank is the number of constraint equations. The MacPherson front suspension requires the spindle 
to meet the lower con- trol arm at a spherical joint as shown in Figure 4. Count- ing both the right 
and left sides, gives 6 independent con- straints. The rack-spindle distances give 2 more indepen- dent 
constraints, while the normalization of the three sets of Euler parameters provides 3 more. The driver 
steer- ing commands produce 1 more constraint on rack motion. Since each of these constraints is holonomic, 
and they are all independent, we have 26 -(6 + 2 + 3 + 1) = 14 inde- pendent degrees of freedom in our 
vehicle (exclusive of the drivetrain and other subsystems). Non-holonomic constraints [12] (non-integrable 
rela- tions involving the coordinates) are encountered in our model only in the kinematics of tire roll-without-slip 
on a surface. The resulting tire constraint forces are treated as external forces on the spindle and 
tire. Recovery of Outboard Positions, Velocities, Ac- celerations The velocity and acceleration formulas 
in- volve joint matrices B ! and B2 which give the linear re- lation between outboard body velocity and 
inboard body and relative joint velocity. We write the Cartesian veloc- ity of outboard body i+1 as ~+1 
= Bi~ + B2~(i+l}~ where for body i, its global translational and a~ngular velocities are combined as 
Y~ = =.7" -r r . [ri wi ] The corresponding acceler- ation formula is Yi+l : BiYi + B2~(,+1}, +/9(i+1}~, 
where the velocity coupling terms D(i+l), contain the coordinate velocities and derivatives of the joint 
matrices Bi and B2. The Bi matrices and /9 vector must be individually con- structed for each specific 
joint type. These kinematic formulas are used to express the global Cartesian position, velocity, and 
acceleration of an out-board body in terms of an inboard body and relative joint position, velocity, 
and acceleration. All body global coor- dinates, velocities, and accelerations are determined recur- 
sively moving outward in the graph from the initial base body. Recovery of Coordinate Accelerations We 
gen- erate our dynamical equations using D'Alembert's prin-ciple of virtual work [12}. By using relative 
joint coor-dinates, rather than Cartesian coordinates, the unknown joint constraint forces are automatically 
eliminated from our equations. Using virtual work instead of alternative variational methods avoids the 
additional step of forming complicated Lagrangians or Hamiltonians and their Euler- Lagrange equations. 
Additional difficulties with variational formulations can occur when non-conservative forces, such as 
friction, are present. By using the virtual work principle, we can treat both conservative and non-conservative 
forces in a straightforward manner, while the remaining cut joint constraints are easily incorporated 
into the principle using Lagrange multipliers. The result of our derivation of the equations of motion, 
and choice of kinematics, is a parallel algorithm that allows the inward recursive elimination of the 
relative joint accel- erations, and accumulation of generalized mass, velocity, force, and constraint 
terms into a single matrix equation that is solved for the base body accelerations and Lagrange multipliers. 
The remaining coordinate accelerations are re- cursively recovered by moving outward in the graph from 
the base body. The organization of the algorithm closely follows the system tree graph, and so exhibits 
the inherent parallelism of each independent branch. The algorithm's recovery of the coordinate accelerations 
is fully non-linear, in that velocity coupling terms /9 are not assumed negli- gible. The assumption 
of slow rates of angular change, so that coupling from the Euler terms ~2 × d~ is small, fails during 
high speed maneuvering of vehicles. The inclusion of these non-linear terms is critical for simulating 
the effects of anti-lock braking systems (ABS) [18] and four-wheel steer- ing controls. External Forces 
We include external forces such as tire forces, gravity, wind resistance, engine and brake torques, springs, 
dampers, stabilization bars, suspensions stops, and internal reactions in the model. The most dif-ficult 
and critical forces to model are the ones generated by the tires. Because of the complexity of road-tire 
inter- action, the forces and moments are taken from measured data as a function of normal force, slip 
angle, and camber angle. Attention must be paid to how the tire forces change during conversion from 
a no-slip to a slip condition, in order to minimize longitudinal force discontinuities. Complex drivetrain 
models for both manual and auto-matic transmissions have been developed. They are based on combining 
individual drivetrain components such as en- gine: clutch, transmission, torque converter, and differential 
 ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 together with proper feedback. Each component is mod- eled 
using experimental data generated for that subsystem. Our current drivetrain models have a single degree 
of ro- tational freedom, which is independently integrated to find rotational velocity and applied wheel 
torque. Integration of Accelerations We symbolically write the result of the recursive algorithm's recovery 
of the ac-celerations as evaluating the right-hand side ](t, Y) of the first-order equation Y = f(t, 
Y) where Y is the state vec-tor of 26 chassis and joint coordinates, and their veloc- ities. Included 
in this recovery of the accelerations was the twice-differentiated acceleration form of the constraints 
in order to have sufficient equations to determine both the base body accelerations and the Lagrange 
multipliers. But the constraint equations themselves have not been in- cluded. If they are solved as 
part of the system, the re-sulting DAE's are stiff and awkward to integrate [11]. Ig- noring our constraints 
for the moment (we return to them in the next paragraph), our equation can be integrated using standard 
techniques from numerical analysis to ad-vance 17(t) to 17(t + &#38;t). Because of real-time limitations, 
methods that require only a single new evaluation of ff for each time step can currently be used. This 
limits us to conditionally-stable explicit methods such as Adams-Bashford and Adams-Moulton Predictor-Correcter 
schemes [19], without a final update. When such explicit meth- ods are used, great care must be taken 
in how the result- ing equations are partitioned to avoid instabilities resulting from high frequency 
force inputs. To improve total system bandwidth, after the system has been properly partitioned into 
slow (chassis) and fast (suspension) components, a hy- brid integration scheme where the low frequency 
slow com- ponents are integrated with an explicit method and the high frequency fast components with 
an implicit method is advantageous. The non-linear equations from the implicit integrations can be solved 
using quasi-Newton methods [61 . Constraint Stabilization The numerical solution of our differential 
equation must satisfy all cut joint con-straints. These additional algebraic equations force us to solve 
the differential equations on the curved configuration manifold (the algebraic manifold embedded in parameter 
space on which the system trajectories are forced by the constraints to move), rather than in the flat 
parameter space itself. Special techniques are needed to correct the solution produced by our standard 
"Euclidean" integration methods, in order to retain accuracy and stability. For very short times, since 
the differential form of the constraints are incorporated into our equation, the solution will approxi- 
mately satisfy the cut joint constraints. For longer times, either Baumgarte's method [3] of modifying 
the equations to make the configuration manifold a stable attractor (so that points close to the configuration 
manifold will move nearer in time along their trajectories), or a coordinate partitioning method [25] 
of updating the dependent coor-dinates can be used. Baumgarte's method essentially in- troduces a primitive 
feedback loop to control error growth, while the partitioning method uses Newton-Raphson iter- ation 
to force the dependent coordinates to satisfy all con- straint conditions. Either of these can ensure 
that accu-mulated numerical error will not cause the solution to drift too far off the configuration 
manifold. Organization of Reeursive Algorithm At the start of each time step, the global orientation, 
position, and ve-locity of each body is calculated from the relative joint positions and velocities by 
moving outward in the graph from the base body (Figure 7a). All local vectors are con- verted to global 
coordinates. The driver steering, brake, accelerator pedal position, and other inputs are obtained a) 
- Forward Sequence b) -Backward Sequence Figure 7 -Computation Paths from sensors and used to determine 
rack position and veloc- ity, brake, and drivetrain parameters. External forces and moments are then 
calculated; tire, brake, spring, damper, stabilizer bar, aerodynamic, gravitational, and drivetrain forces 
and torques are independently determined by spe- cial subsystem models. The inertia matrices are updated 
to the global coordinate system. Next, concurrently on each branch, the accelerations are recursively 
eliminated moving inward along the graph toward the base body (Figure 7b). When the base body is reached, 
and the base body equation assembled, it is solved for the chassis Cartesian accelera- tions and Lagrange 
multipliers using Gaussian elimiaation. Recovery of the outboard body Cartesian and relative joint accelerations 
is then begun, concurrently moving outward (Figure 7a) in the graph. When this is completed, all accel- 
erations have been calculated, and tile integration scheme advances the solution to the next time step. 
Computer Architectures and Software The re-quirement of imptement.ing a parallel algorithm with a small 
number (4-8) of concurrent tasks leads to a single bus archi- tecture with global memory. Care must be 
taken to avoid bus contention from simultaneous memory accesses or mes- sage passing. Modern optimizing 
FORTRAN and C com- pilers running under POSIX-type operating systems pro- vide software flexibility. 
Specialized simulation computers with non-standard languages suffer from insufficient adapt- ability, 
liinited transportability, and narrow growth poten- tial. Upgrading of a simulator computer system is 
simpli- fied by writing software in standard languages. Algorithm Timing Table 1 shows the results of 
tim- ings of the recursive algorithm taken on Alliant FX/8 (in parallel and serial mode) and VAX-series 
computers (in se- @ RELATIVE TIME TO FINISH ONE ALGORITHM STEP (ALLIANT FX/8 WITH 8 CE'S = 1 UNIT) Alliant 
FX/8 (8 CE's -parallel code) 1 Alliant FX/8 (4 CE's -parallel code) 1.25 Alliant FX/8 (2 CE's -parallel 
code) 2.0 Alliant FX/8 (1 CE -serial code) 3.2 VAX 8800 (serial code) 4.5 VAX 780 (serial code) 21.5 
Table 1 - Algorithm Timings rial mode only), using optimized FORTRAN code for each machine. The Alliant 
FX/8 was run with 1, 4, and 8 com- pute elements (CE's) available for concurrency to the al- gorithm. 
Asymptotic behavior of the algorithm speed-up beyond 4 CE's on the FX/8 is seen. The parallel algorithm 
provides a considerable improvement in speed over the se- rial version. The time obtained with 8 CE's 
allows real-time simulation. Future Directions in Real-Time Visuals for Driving Simulation There are 
some exciting developments, in both CIG tech- nology and advanced vehicle systems for safety and traffic 
control, that will usher in a wave of simulation opportuni- ties with the driver in the loop. There are 
related develop- ments in personalized parallel computing and in dynamics methods that will allow real-time 
simulation to be moved out of the simulator bay and into the office. To boot, the dy- namics methods 
summarized in the previous section along with networking can aid the ready fusion of pre-existing me- 
chanical models with various forms of both real-time and non-real-time mechanical dynamics simulation. 
This sec-tion samples some enticing opportunities now contributing to a small revolution in the way mechanical 
designers will integrate traditional finite element analysis, design sensl- tivity/optimization, and 
life-cycle analysis with mechanical dynamics and vehlcle-environment studies. Future real-tlme CIG enhancements 
will boost scene density and specificity. Lag will be further reduced to im- prove the step response 
of the simulated vehicle and to meet the demands of eye-tracking displays. Modeling systems now under 
development will allow complex road systems and environments to be generated from photos with in-creasing 
reliance on automated image processing and ex-pert system methods. The occulting generality of next- 
generation CIG will allow for arbitrary traffic encounters and for complex geometries of roads to be 
integrated eas- ily with appropriate cuts and fills into surrounding land- scapes. Photographic texture 
and feature densities will be- come commonplace. Next-generation dynamics must be capable of model- ing 
high-speed control systems and subtle mechanical res- Computer Graphics, Volume 22, Number 4, August 
1988 onances that affect driver performance. The approach to dynamics summarized in this paper has the 
flexibility and inherent modeling rigor to grow with these demands. Interactive dynamics is on the verge 
of spilling out of the expensive high-performance computers of big simula- tors into the office. Products 
will likely emerge that package the robust dynamics methods typified in this paper with specially tailored 
parallel compute engines affording real- time and enhanced slow-time, mouse-driven, interactive dy- namics 
on workstations. The emergence of high-speed net- working will also help support the linkage of very 
complex parallel dynamics algorithms running on super-minis and super-computers with interactive dynamics 
visualization at workstations and graphic terminals. If similar dynamics models and processing techniques 
can be distributed as widely, there may emerge CAD standards that allow de- sign data across the simulation 
spectrum to be moved eas- ily around the organizational environment. As a result, dynamic study can become 
a more routine element of inte- grated mechanical design systems. Conclusion This paper has shown how 
graphics and dynamics must work together in driving simulation to provide realistic op- erator environmental 
cueing. A new approach to real-time vehicle dynamics, exploiting natural parallelism in the vehi- cle 
system graph, was discussed. We have aspired to present our view of a path to the future in vehicle simulation. 
Acknowledgments This paper would not have been possible without the efforts of the Simulation Technology 
Group and the continuing support of management at Evans and Sutherland. We want to express our appreciation 
to the following individuals: D. Anderson, D-S. Bae, J. Drosdol, E. Haug, W. Kaeding, J. Kuhl, W-S. Lee, 
G. Lerner, E. Pankiewicz, B. Thomson, C. Walther. In addition, we want to thank the engineering and 
simulation groups at Daimler-Benz AG and Bayerische Motoren Werke AG for their cooperation. References 
 I1] Armstrong, W. Recursive Solution to the Equations of Motion of An N-Link Manipulator. In Proc. 5th 
World Congress on Theory of Machines and Mechanism, Vol. 2, (Montreal, 1979), 1343-1346. [2] Bae, D. 
and ttaug, E. A Recursive Formulation for Constrainted Mechanical System Dynamics. Technical Report 86-14, 
Center for Computer Aided Design, Col- lege of Engineering, University of Iowa, 1986. [s] Baumgarte, 
J. Stabilization of Constraints and Inte- grals of Motion in Dynamic Systems. Computer Meth- otis in 
Applied Mechanics in Engineering, 1 (1972), 1- 16. / SIGGRAPH '88, Atlanta, August 1-5, 1988 14] Casali, 
J. and Wierwille, W. The Effects of Various Design Alternatives on Moving-Base Driving Simula- tor Discomfort. 
Human Factors, 22, 6 (1980), 741-756. [5] Chace, M. Methods and Experience in Computer Aided Design of 
Large-Displacement Mechanical Sys- tems. In Computer Aided Analysis and Op[imiza-tion of Mechanical System 
Dynamics, E. Haug. (ed.). Sprlrtger-Verlag, Heidelberg, 1984. [61 Dennis, J. and More, J. Quasi-Newton 
Methods, Mo- tivation and Theory. SIAM Review 19, 1 (1977), 46.-89. September 1967, pp. 250-253. I7] 
Dickmanns, E.D., and Zapp, A. Guiding Land Vehicles Along Roadways by Computer Vision. Presented at AFCET 
Conference "Automatique 85 -the tools for tomorrow", Toulouse, October 1985. [8] Doenges, Peter K. Overview 
of Computer Image Gen- eration in Visual Simulation, Presented at ACM Sig- graph Technical Courses, July, 
1985. [91 Duncan, J.R., and Wegscheid, E.L. Off-Road Vehicle Simulation for Human Factors Research. Paper 
8~- 1610, 1982 Winter Meeting, American Society of Agri- cultural Engineers (Chicago, Dec. 14-17, 1982.) 
[10] Drosdol, J. and Panik, F. The Daimler-Benz Driving Simulator: a Tool for Vehicle Development. SAE 
Tech- nical Paper Series, 850334, (Feb. 1985). [11] Gear, W. Differential-Algebraic Equations. In Com-puter 
Aided Analysis and Optimization of Mechanical System Dynamics, E. Haug {ed.) Springer-Verlag, Hei- delberg, 
1984. [12] Goldstein, H. Classical Mechanics. Addison- Wesley, Reading, Mass., 1980. [13] Hahn, S., and 
Kalb, E. The Daimler-Benz Driving Simulator Set-Up and Results of First Experiments. ~n Summer Computer 
Simulation Conference Proceed- ings Simulation Councils, Inc., San Diego, 1987, pp. 993 - 998. {14] Haug, 
E. (ed.) Computer Aided Analysis and Opti-mization of Mechanical System Dynamics. Springer-Verlag, Heidelberg, 
1984. [15] Haug, E. Elements and Methods of Computational Dy- namics. In Computer Aided Analysis and 
Optimization of Mechanical System Dynamics, E. Haug (ed.). [16] Hooker, W. and Margulies, G. The Dynamical 
Atti- tude Equations for an n - Body Satellite. J. Astronaut. Sci. 12 (1965), 123-128. [17] Issacs, P. 
and Cohen, M. Controlling Dynamic Simula- tion with Kinematic Constraints, Behavior Functions and Inverse 
Dynamics. Computer Graphics 21, 4 (July 1987), 215-224. [18] Kempf, D., Bonderson, L., and Slater, L. 
Real Time Simulation for Application to ABS Development. SAE Technical Paper 870336, 1987. 1191 Lambert, 
J. Computational Methods in Ordinary Dif- fferential Equations. John Wiley, New York, 1973. I20] Luh, 
J., Walker, M., and Paul, R. On-line Compu- tational Scheme for Mechanical Manipulator. J. Dyn. Syst. 
Measurement Control 102 (1980), 69-76. I21] Nordmark, S. VTI Driving Simulator -Mathemati-cal Model of 
a Four-wheeled Vehicle for Simulation in Real-Time. VTI Rapport Nr 267A 1984. Statens vag- och trafikinstitut, 
LinkSping, Sweden, 1984. [22] Orlandea, N., Chute, M., and Calahan, D. A Sparsity- Oriented Approach 
to the Dynamic Analysis and De- sign of Mechanical Systems- Parts 1 and 2. J. of En- gineering for Industry 
(1977), 773-784. [23] Richter, Bernd. Driving Simulator Studies --the In- fluence of Vehicle Parameters 
on Safety in Critical Sit- uations. SAE Technical Paper Series, 741105, (Feb. 1974). [24] Sheridan, T.B., 
Paynter, H.M., and Coons, S.A. Some Novel Display Techniques for Driving Simulation. In IEEE Transactions 
on Human Factors in Electronics, Vol. HFE-5, September 1964, pp. 29-32. [281 Wehage, R. and Haug, E. 
Generalized Coordinate Par- titioning for Dimension Reduction in Analysis of Con- strained Mechanical 
Systems. J. of Mechanical Design, 104 (1982), 247-255. [26] Weirwille, W.W., Gagne, G.A., and Knight, 
J. R. A Laboratory Display System Suitable for Man-Machine Interface. In EEE Transactions on Human Factors 
in Electronics, Vol. HFE-8, No. 3. [271 Wittenburg, J. Dynamics of Systems of Rigid Bodies. B. G. Teubner, 
Stuttgart, 1977.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378538</article_id>
		<sort_key>327</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Applications of computer graphics to the visualization of meteorological data]]></title>
		<page_from>327</page_from>
		<page_to>334</page_to>
		<doi_number>10.1145/54852.378538</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378538</url>
		<abstract>
			<par><![CDATA[The need to visualize huge amounts of numerical data is exemplified in the field of meteorology, where measurements of many atmospheric parameters are routinely taken over large geographical areas for the purpose of monitoring and predicting weather. Computer graphics has provided and will continue to offer powerful tools to meet this visualization challenge, principally in three areas: first, efficient graphics algorithms for displaying the data; second, novel special-purpose graphics hardware; and third, interactive techniques for graphically manipulating the data at close to video rates. This paper reviews past and current uses of computer graphics for gaining insight from measured or modelled meterological data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[atmospheric phenomena]]></kw>
			<kw><![CDATA[clouds]]></kw>
			<kw><![CDATA[display techniques]]></kw>
			<kw><![CDATA[fog]]></kw>
			<kw><![CDATA[image processing]]></kw>
			<kw><![CDATA[interactive workstations]]></kw>
			<kw><![CDATA[modelling]]></kw>
			<kw><![CDATA[motion]]></kw>
			<kw><![CDATA[perception]]></kw>
			<kw><![CDATA[stereo]]></kw>
			<kw><![CDATA[weather forecasting]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human information processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P275885</person_id>
				<author_profile_id><![CDATA[81100249616]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Papathomas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P127529</person_id>
				<author_profile_id><![CDATA[81100317155]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Schiavone]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P25326</person_id>
				<author_profile_id><![CDATA[81100590058]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Julesz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hill, New Jersey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bell Telephone Laboratories, Weather Maps Transmitted by Teletypewriter System, Bell Laboratories Record, 3-4, September 1931.]]></ref_text>
				<ref_id>Bell31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. F., Light Reflection Functions for Simulation of Cloud and Dusty Surfaces, Computer Graphics, Vol. 16, No. 3, 21-29, 1982.]]></ref_text>
				<ref_id>Blin82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burr, P., and Sperling, G., Time, Distance and Feature Trade-offs in Visual Apparent Motion, Psychol. Review, Vol. 88, 171-195, 1981.]]></ref_text>
				<ref_id>Burt81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807482</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[DesJardins, M., and Haster, A. F., Stereographic Displays of Atmospheric Model Data, Computer Graphics, Vol. 14, No. 3, 134-139, 1980.]]></ref_text>
				<ref_id>DesJ80</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fournier, A., Fussell, D., and Carpenter, L., Computer Rendering of Stochastic Models, Comm. of the ACM, Vol. 25, No. 6, 371-384, 1982.]]></ref_text>
				<ref_id>Four82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42373</ref_obj_id>
				<ref_obj_pid>42372</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Frenkel, K. A., The Art and Science of Visualizing Data, Comm. of the ACM, Vol. 31, No. 2, 111-121, 1988.]]></ref_text>
				<ref_id>Fren88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fulker, D., Director's Report, UNIDATA Newsletter, 2, 2-3, Fall 1987.]]></ref_text>
				<ref_id>Fulk87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808572</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gardner, G. Y., Simulation of Natural Scenes Using Textured Quadric Surfaces, Computer Graphics, Vol. 18, No. 3, 11-20, 1984]]></ref_text>
				<ref_id>Gard84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gardner, G. Y., Visual Simulation of Clouds, Computer Graphics, Vol. 19, No. 3, 297-303, 1985.]]></ref_text>
				<ref_id>Gard85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gelberg, L. M., and Stephenson, T. P., Supercomputing and Graphics in the Earth and Planetary Sciences, IEEE Computer Graphics and Applications, 26-33, July 1987.]]></ref_text>
				<ref_id>Gelb87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Grotjahn, R., and Chervin, R. M., Animated Graphics in Meteorological Research and Presentations, Bulletin of the American Meteorological Society, 65, 11, 1201-1208, November 1984.]]></ref_text>
				<ref_id>Grtj84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hamann, D. R., Doing Physics with Computers, Physics Today, May 1983.]]></ref_text>
				<ref_id>Hama83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hasler, A. F., DesJardins, M., and Negri, A. J., Artificial Stereo Presentation of Meteorological Data Fields, Bulletin of the American Meteorological Society, 66, 970-973, 1981.]]></ref_text>
				<ref_id>Hasl81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hasler, A.F., Advances in Systems for Interactive Processing and Display of Meteorological Data, Preprints, Conference on Aerospace and Aeronautical Meteorology, Boston, American Meteorological Society, 60-62, June 1983.]]></ref_text>
				<ref_id>Hasl83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hasler, A. F., Pierce, H., Morris, K. R., and Dodge, J., Meteorological Data Fields 'In Perspective', Bulletin of the American Meteorological Society, 66, 795-801, 1985.]]></ref_text>
				<ref_id>Hasl85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hasler, A.F., Strong, J., Morris, R., and Pierce, H., Automatic Analysis of Stereoscopic Image Pairs from GOES Satellites, Proceedings Third Conference on Satellite Meteorology and Oceanography, Anaheim, CA, 1988.]]></ref_text>
				<ref_id>Hasl88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Hibbard, W.L., Krauss, R., and Young, J.T., 3-D Weather Displays Using MclDAS, Preprints, ICIIPSMOH, Los Angeles, American Meteorological Society, 153-156, 1985.]]></ref_text>
				<ref_id>Hibb85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hibbard, W. L., Computer-Generated Imagery for 4-D Meteorological Data, Bulletin of the American Meteorological Society, 67, 1362-1369, November 1986.]]></ref_text>
				<ref_id>Hibb86a</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319123</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Hibbard, W. L., 4-D Display of Meteorological Data, Proceedings of the 1986 Workshop on Interactive 3D Graphics, Chapel Hill, N.C., 23-36, 1986.]]></ref_text>
				<ref_id>Hibb86b</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Hibbard, W. L., A Next Generation MclDAS Workstation, Reprints, Fourth Int'l Conf. on Interactive Info. and Processing Systems for Meteorology, Oceanography and Hydrology (ICIIPSMOH), Anaheim, CA, American Meteorological Society, 56-61, 1988.]]></ref_text>
				<ref_id>Hibb88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Hochberg, J. E., Perception 2nd ed. Prentice-Hall, Englewood Cliffs, NJ, 1978.]]></ref_text>
				<ref_id>Hoch78</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Hussey, K. J., Hall, J. R., and Mortensen, R. A., Image Processing Methods in Two and Three Dimensions used to Animate Remotely Sensed Data, Proceedings of IGARSS Symposium, Z~rich, 771-776, 1986.]]></ref_text>
				<ref_id>Huss86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Ide, J. R., The UNIDATA PC-McIDAS Workstation: a Technical Discussion, Preprints, ICIIPSMOH, Anaheim, CA, American Meteorological Society, 332-335, 1988.]]></ref_text>
				<ref_id>Ide88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Julesz, B., Binocular Depth Perception of Computer- Generated Patterns, Bell System Tech. J., 1125-1162, 1960.]]></ref_text>
				<ref_id>Jule60</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T., and VonHerzen, B. P., Ray Tracing Volume Densities, Computer Graphics, Vol. 18, No. 3, 165-174, 1984.]]></ref_text>
				<ref_id>Kaji84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Klemp, J. B., and Rotunno, R., Taking a Good Look at Data, NCAR Annual Report for 1984, Report NCAR/AR-84, 46-49, 1985.]]></ref_text>
				<ref_id>Klem85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[MacDonald, A. E. Design Considerations of Operational Meteorological Systems: A Perspective Based upon the PROFS Experience, ICIIPSMOH, Los Angeles, American Meteorological Society, 16-23, 1985.]]></ref_text>
				<ref_id>MacD85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, B. B., and VanNess, J. W., Fractal Brownian Motions, Fractional Noises and Applications, SIAM Review, Vol. 10, No. 4, 422-437, 1968.]]></ref_text>
				<ref_id>Mand68</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15899</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Max, N. L., Atmospheric Illumination and Shadows, Computer Graphics, Vol. 20, No. 4, 117-124, 1986.]]></ref_text>
				<ref_id>Max86a</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5515</ref_obj_id>
				<ref_obj_pid>5513</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Max, N. L., Light Diffusion through Clouds and Haze, Computer Vision, Graphics and Image Processing, Vol. 33, 280-292, 1986.]]></ref_text>
				<ref_id>Max86b</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15890</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Miller, G. S. P., The Definition and Rendering of Terrain Maps, Computer Graphics, Vol. 20, No. 4, 39-48, 1986.]]></ref_text>
				<ref_id>Mill86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37437</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Nishita, T., Miyawaki, Y., and Nakamae, E., A Shading Model for Atmospheric Scattering Considering Luminous Intensity Distribution of Light Sources, Computer Graphics, Vol. 21, No. 4, 303-310, 1987.]]></ref_text>
				<ref_id>Nish87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Panel on the Physical Simulation and Visual Representation of Natural Phenomena, SIGGRAPH '87, Vol. 21, No. 4, 335-336, 1987.]]></ref_text>
				<ref_id>Pane87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Papathomas, T. V., Schiavone, J.A., and Julesz, B., Stereo Animation for Very Large Data Bases: Case Study - Meteorology, IEEE Computer Graphics and Applications, 7, 18-27, 1987.]]></ref_text>
				<ref_id>Papa87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., An Image Synthesizer, Computer Graphics, Vol. 19, No. 3, 287-296, 1985.]]></ref_text>
				<ref_id>Perl85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Petit, N. J. and Lyons, W. A., Low-cost Stand-alone Receiving and Video Facsimile Display Systems for GOES-TAP and WEFAX/APT, ICIIPSMOH, Los Angeles, American Meteorological Society, 295-299, 1985.]]></ref_text>
				<ref_id>Peti85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Pichel, W., Bristor, C. L., and Brower, R., Artificial Stereo: A Technique for Combining Multichannel Satellite Image Data, Bulletin of the American Meteorological Society, 54, 688-691, 1973.]]></ref_text>
				<ref_id>Pich73</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801169</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Potmesil, M. and Chakravarty, I., Modeling Motion Blur in Computer Generated Images, ACM SIGGRAPH "83 Proceedings, Vol. 17, No. 3, 389-399, 1983.]]></ref_text>
				<ref_id>Potm83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Ramachandran, V. S., and Gregory, R. L., Does Colour Provide an Input to Human Motion Perception? Nature, Vol. 275, 55-56, 1978.]]></ref_text>
				<ref_id>Rama78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357320</ref_obj_id>
				<ref_obj_pid>357318</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., Particle Systems - A Technique for Modeling a Class of Fuzzy Objects, ACM Trans. on Graphics, Vol. 2, No. 2, 91-108, 1983.]]></ref_text>
				<ref_id>Reev83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. T., and Blau, R., Approximate and Probabilistic Algorithms for Shading and Rendering Structured Particle Systems, Computer Graphics 19, 3, 313-322, 1985.]]></ref_text>
				<ref_id>Reev85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37436</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Rushmeier, H. E., and Torrance, K.E., The Zonal Method for Calculating Light Intensities in the Presence of a Participating Medium, Computer Graphics, Vol. 21, No. 4, 293-302, 1987.]]></ref_text>
				<ref_id>Rush87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Schiavone, J. A., Papathomas, T. V., Julesz, B., Kreitzberg, C. W., and Perkey, D. J., Anaglyphic Stereo Animation of Meteorological Fields, Preprints, Second ICIIPSMOH, Boston, American Meteorological Society, 64-71, 1986.]]></ref_text>
				<ref_id>Schi86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Smith, E. A., The MclDAS System, IEEE Transactions on Geoscience Electronics, GE- 13, 123-134, 1975.]]></ref_text>
				<ref_id>Smit75</ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Treinish, L. A., and Gough, M. L., A Software Package for the Data-Independent Management of Multi- Dimensional Data, Submitted to EOS, Transactions of the American Geophysical Union, December 1986.]]></ref_text>
				<ref_id>Trei86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[Treinish, L. A., Gough, M. L., and Wildenhain, W. D., Animated Computer Graphics Models of Space and Earth Sciences Data Generated via the Massively Parallel Processor, NASA Frontiers of Massively Parallel Scientific Computation, Report NASA/N87-26531, 217- 222, July 1987.]]></ref_text>
				<ref_id>Trei87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Upson, C., Large Scale Computer Animation in the Computational Sciences, Course No. 28 Notes for Computer Graphics and Animation in the Physical Sciences, ACM SIGGRAPH 1987, 64-65, 1987.]]></ref_text>
				<ref_id>Upso87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Vonder Haar, T., Meade, A., Brubaker, T., and Craig, R., Four-Dimensional Digital Imaging for Meteorological Applications, Preprints, ICIlPSMOH, Miami, American Meteorological Society, 1986.]]></ref_text>
				<ref_id>Vond86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Voss, R., Fractai Forgery, Course No. 10 Notes for State-of-the-Art in Image Synthesis, ACM S1GGRAPH 1983.]]></ref_text>
				<ref_id>Voss83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>50</ref_seq_no>
				<ref_text><![CDATA[Wright, T. J., Utility Plotting Programs at NCAR, Atmospheric Technology, 51-57, September 1973.]]></ref_text>
				<ref_id>Wrig73</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15895</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>51</ref_seq_no>
				<ref_text><![CDATA[Yaeger, L., and Upson, C., Combining Physical and Visual Simulation - Creation of the Planet Jupiter for the Film '2010', Computer Graphics, Vol. 20, No. 4, 85- 93, 1986.]]></ref_text>
				<ref_id>Yaeg86</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ Computer Graphics, Volume 22, Number 4, August 1988 APPLICATIONS OF COMPUTER GRAPHICS TO THE VISUALIZATION 
OF METEOROLOGICAL DATA T. V. Papathomas, J. A. Schiavone and B. Julesz AT&#38;T Bell Laboratories Murray 
Hill, New Jersey 07974 ABSTRACT The need to visualize huge amounts of numerical data is exemplified 
in the field of meteorology, where measurements of many atmospheric parameters are routinely taken over 
large geographical areas for the purpose of monitoring and predicting weather. Computer graphics has 
provided and will continue to offer powerful tools to meet this visualization challenge, principally 
in three areas: first, efficient graphics algorithms for displaying the data; second, novel special-purpose 
graphics hardware; and third, interactive techniques for graphically manipulating the data at close to 
video rates. This paper reviews past and current uses of computer graphics for gaining insight from measured 
or modelled meteorological data. CR CATEGORIES AND DESCRIPTORS: H.1.2 [Models and Principles]: User/Machine 
Systems --human information processing; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; 
J-2 [Physical Sciences and Engineering]: Earth and Atmospheric Sciences. Additional Key Words and Phrases: 
Stereo, animation, motion, perception, clouds, fog, atmospheric phenomena, weather forecasting, modelling, 
image processing, interactive workstations, display techniques. 1. Introduction Meteorology is a relatively 
young science in spite of the long history of human interest in knowledge about the weather. The weather 
affects nearly everyone on a daily basis and it occasionally affects smaller subsets of people catastrophically, 
endangering their lives and property. Nevertheless, significant barriers prevented early technological 
advancement in meteorology: the difficulty in conducting meteorological experiments on a "remote" atmospheric 
fluid as well as the difficulty in developing physical models of atmospheric dynamics. Permission to 
copy without fee all or part of this material is granted provided that the copies are not made or distributed 
for direct commercial advantage, the ACM copyright notice and the title of the publication and its date 
appear, and notice is given that copying is by permission of the Association for Computing Machinery. 
To copy otherwise, or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM-0-89791-275-6/88/008/0327 
$00.75 The difficulty in performing experiments on the atmosphere has only been alleviated in the last 
century and a half when technological advances finally permitted humans to effectively observe atmospheric 
properties. The telegraph spawned the synoptic era in the late 1800s, permitting simultaneous low-resolution 
2-dimensional measurements of ground level weather features. Radio technology initiated the radiosonde 
era in the 1930s, allowing 3-dimensional measurements to be made through the depth of the atmosphere 
via balloon-borne sensor packages. Because these data sets were relatively sparse, interpreting observations 
was hardly a problem. However, with the advent of the computer which promoted numerical weather prediction 
and the transistor which spurred the development of remote sensing technology, meteorologists were suddenly 
overwhelmed with high-resolution, 3-dimensional observational data beginning in the 1960s. Computer graphics 
found an early home in meteorology during this recent data-rich era as meteorologists strove to exploit 
their newfound enrichment of data. This paper briefly reviews the history of computer graphics adoption 
by meteorologists and then focuses on some current state- of-the-art applications. Our goal is to first 
provide a comprehensive yet cursory review of the full arena and then to highlight the work of a few 
select institutions which have had a long-term commitment to computer graphics applications in meteorology. 
Regrettably, space limitations prevent us from citing all of the many individuals and institutions who 
have made outstanding contributions to meteorological visualization. Finally, we provide a short summary 
of our expectations for the future of computer graphics applications in meteorology. 2. Historical Perspective 
2.1 History of Graphics Needs in Meteorology The types of data prevalent during each of the different 
observational eras strongly influenced the types of visualization graphics employed by meteorologists. 
During the synoptic era of low-resolution 2-D measurements, meteorologists were satisfied with simple 
graphic symbols to plot cold and warm fronts, station medal symbols to list weather observations for 
a particular location on a weather map, and contour plots to depict 2-D data fields (Figure 1). The introduction 
of routine 3-D observations during the radiosonde era placed an additional burden on meteorologists to 
perceive the 3-D structure of the atmosphere. This was accomplished by stacking sets of height-sequenced 
contour plots of atmospheric data fields on clipboards and flipping through them to develop a mental 
picture of the 3-D structure of the data fields. The advent of spa~-borne cameras at the beginning of 
the data.rich era placed 2-D image data into the hands of meteorologists for the first time. The fact 
that these images were arriving at rates of at least once an hour promoted animation as a tool to aid 
the meteorologist in mentally extrapolating cloud features into the immediate future. Finally, the current 
expanded use of supercomputing power for numerical weather prediction and the budding development of 
high-r~olution atmospheric sounders are now requiring meteorologists to work with what are effectively 
3-D images of the atmosphere.  SIGGRAPH '88, Atlanta, August 1-5, 1988 2.2 History of Capabilities 
for Visualizing Meteorological Data Facaimile technology was introduced about four decades ago for the 
transmission and display of weather data. Because of its simplicity and robustness, it has been a standard 
piece of equipment in the meteorologist's office [Peti85]. The image processing field found a new area 
for applications about a quarter century ago in response to the introduction of the meteorological satellite 
[Huss86]. Soon thereafter techniques were developed for displaying satellite images in stereo [Pieh73] 
and animation techniques and interactive workstations were introduced in meteorology in the early 1970s 
[Smit75]. Finally, the last decade has seen the application of computer generated imagery to the display 
of weather events [Hibb85], [Grtj84], [Has185], [Gelb87]. 2.3 History of Graphics Applications in Meteorology 
The earliest implementations of automated graphics (a looser interpretation of computer graphics) in 
meteorology were produced to support the weather forecasting operations of what was then known as the 
United States Weather Bureau. Teletype transmission of weather maps was introduced in the early 1930s 
[Bell31 ] which was upgraded to facsimile transmission of contoured weather maps by the 1940s. During 
the early years of numerical weather prediction in the 1950s, contoured data fields were depicted with 
line printers by filling the regions between contours with different types of print. The earliest actual 
computer graphics applications to meteorology were done at research institutions. The first dedicated 
effort to develop computer graphics tools specifically for meteorologists began at the National Center 
for Atmospheric Research (NCAR) in the late 1960s with the genesis of the NCAR Graphics Package. The 
first dedicated effort to digitally manipulate meteorological image data began at the University of Wisconsin 
in the early 1970s with the development of the Man-Computer Interactive Data Access System (MclDAS). 
Some of the first applications of stereo graphics were conducted in the late 1970s at the National Aeronautics 
and Space Administration (NASA) Goddard Space Flight Center on their Atmospheric and Oceanographic Information 
Processing System (AOIPS). Incorporation of these computer graphics research concepts into operational 
facilities began at the National Weather Service (NWS) when it initiated procurement for the Automation 
of Field Operations and Services (AFOS) system in the 1970s. AFOS provided interactive graphics capabilities 
to the Government's operational forecast offices for the first time in the early 1980s. The National 
 Oceanic and Atmospheric Administration (NOAA), in a continuing forward-looking effort to modernize weather 
forecast operations in the NWS, established the Program for Regional Observing and Forecasting Services 
(PROFS) in 1980 which has devoted a significant effort to developing interactive graphics applications. 
Also, commercial applications of computer graphics in meteorology began to appear in the 1980 time frame 
with an abundance of vendors targeting the lucrative television weather broadcast market. Research and 
development for interactive meteorological data handling continues to increase during the 1980s with 
many different government, academic, and private institutions now participating. 3. Current Applications 
3.1 Meteorological Data Visualization Issues Meteorology can be used as a typical example to illustrate 
the visualization problem for large-scale scientific data sets. To process and assimilate the huge bodies 
of measured or numerical model data, the ideal site might include high-speed supercomputers, an efficient 
interactive environment (possibly aided by a rule-based interface to the data bank), and "real-time" 
graphics capabilities. However, the fact that storage capacity increases are not keeping up with those 
of computational speed and semiconductor memory size and speed, have led Upson to conclude that "a researcher 
can compute more than he can store; he can store more than he can comprehend" [Upso87]. Computer graphics 
and visual psychophysics are two areas that provide valuable tools for confronting the major challenge 
of visualization in meteorology. We shall first examine the role of computer graphics. Recent progress 
in graphics hardware and software has made it possible to create animation sequences for weather episodes 
of ever increasing complexity. Although practically all advances in graphics algorithms can be applied 
to the display of weather phenomena, we mention concisely in this subsection a few recent display techniques 
that are highly relevant to meteorology. Fournier, Fussell and Carpenter [Four82] devised a recursive 
subdivision algorithm to apply efficiently Mandelbrot's "fractional Brownian motion" model [Mand68] for 
natural phenomena. Models for the diffuse reflection of light as it interacts with clouds of small particles 
are studied in [Blin82]. Reeves developed a method for rendering fuzzy objects, called particle systems 
[Reev83], while he and Blau implemented algorithms for shading and rendering particle systems [Reev851. 
Light scattering models were used by Kajiya and Von Herzen [Kajig4] to develop algorithms for ray tracing 
volume densities (clouds, fog, dust, etc.). Gardner sought to compromise the conflict between realistic 
images and computational time by adopting the impressionist painters' approach of "representing the essence 
of natural scenes as simply as possible." He achieved remarkable results by using textured quadric surfaces 
bounded by planes to portray clouds and trees [Gard84]. He also developed a highly efficient approach 
to render realistic cloud scenes (see Figure 2) by modulating the shading and translucence of simple 
surfaces using a texturing function [Gard85]. Perlin developed highly efficient schemes for rendering 
a wide variety of natural scenes [Per1851. In particular, his method of generating "l:f noise" for fraetal 
surfaces offers considerable computational savings over subdivision-based [Four82] or Fourier-space [Voss83] 
techniques. The clouds in Figure 3, generated by Don Mitchell and composited with other 3D graphical 
elements by Eric Hoffert on the AT&#38;T Pixel Machine, were obtained by using Perlin's approach. An 
additional advantage is that Perlin's algorithm can be performed on parallel machines. Miller's method 
[Mi1186] also enjoys this advantage. Yaeger and Upson's paper [Yaeg86] is a prime example of combining 
numerical physical simulation (fluid dynamics) with visual simulation (particle rendering). There is 
a definite need and a trend for synergies such as this to benefit both participants, in this instance 
the fields of the numerical physical sciences and computer graphics. Max approached the problem of light 
diffusion through clouds [Max86a] and atmospheric illumination [Max86b] by developing scattering models; 
similar problems are considered in [Rush87] and [Nish87]. Unfortunately, as a rule, there is a long delay 
in applying the advances in computer graphics, like the ones outlined above, to the physical sciences. 
An exception, among many, to this rule is the work of Gelberg and Stephenson [Gelb87], who applied state-of-the- 
art graphics and image processing techniques for presenting and interacting with data in the earth and 
planetary sciences. One of their meteorology-related products is SuperSeer, a cloud prediction and display 
system [Gelb87]. Figure 4, rendered on a Pixar Image Computer, is an example of their work. We next turn 
briefly to a few general remarks on results from experiments in visual psychophysies. Regarding depth 
perception (DP), Julesz was the first to devise random-dot stereograms to show that DP is possible in 
the absence of any monocular cues, as long as the appropriate binocular horizontal disparity is present 
[Jule60]. Binocularly viewed stereo pairs have been used extensively to enhance the percept of the third 
spatial dimension [Pich73], [DesJ80], [Hasl81], [Sehi86], [Papa87]. Of course, many other cues can be 
used to elicit depth perception, with or without stereo pairs. For static images, these include geometrical 
perspective [Vend86], shadows and shading, texture perspective, distance blurring, and occlusion. For 
dynamically changing scenes, the kinetic depth effect (KDE, the ability to extract the third dimension 
from an animated series of projections obtained from rotating an object), closely related to motion parallax, 
must be added to the list. As far as motion perception is concerned, it has been demonstrated that luminemce 
elicits stronger motion perception than color FRama78], and that ~ Computer Graphics, Volume 22, Number 
4, August 1988 shape is a very weak token for "carrying" motion [Burt81]. We cannot go into detail on 
the relative importance of other attributes (orientation, spatial frequency, depth etc.) in the perception 
of motion. The interested reader may consult [Hoch78] as a starting point. Motion blur has been employed 
in computer-generated images [Potm83]. Motion is important for three reasons: First, in the form of time 
animation, it reveals the atmospheric evolution; second, when generated by the user through real-time 
interactive techniques, it provides a useful tool for efficient visual data exploration and pattern detection; 
finally, it is possible for the viewer to "move about in the scenery," providing powerful KDE clues for 
discerning the 3D structure of the objects. The authors produced realistic stereo animations of complex 
meteorological phenomena [Schi86] [Papa87] paying special attention to the issues of visual perception. 
 In the special case of meteorology there are some particular issues and concerns. The small thickness 
of the atmosphere (relative to its horizontal extent) necessitates a "stretched" z-axis for visualizing 
weather phenomena. Also, the desire to view the distribution of several variables simultaneously has 
given rise to a few interesting solutions: one is to portray each variable by a different attribute (color 
for variable A, height for variable B, iso-valued contours for variable C, etc.); another is to assign 
different transparency indices to the various surfaces that represent the variables. Both of the above 
methods result in images that are highly "unrealistic," illustrating that there may be instances in scientific 
computing in which the visualization technique may have to transcend "realism." Finally, "the need to 
associate the atmospheric phenomena to the underlying map and terrain imposes additional display constraints 
that must be addressed. 3.2 Current Hardware Capabilities Most research meteorological institutions today 
use minicomputer workstations, although most have access to supercomputers. The graphical needs of remote 
operational weather sites are served by personal computers and minicomputers. The last five years have 
seen the emergence of powerful dedicated graphics and imaging machines. Typical examples are: the Silicon 
Graphics IRIS workstation with a special-purpose set of VLSI chips for graphics; the Pixar Image Computer 
with up to three parallel channel processors, each with four processors and a throughput of 120 MIPS; 
and the parallel- architecture AT&#38;T Pixel Machines with up to 82 floating-point signal processors 
and peak throughput of 820 MFLOPS.  3.3 Current State-of-the-Art Systems 3.3.1 NCAR --NCAR Graphics 
 3.3.1.1 Background. The earliest computer graphics tool tailored for meteorologists was the NCAR Graphics 
package developed at the National Center for Atmospheric Research in the late 1960s [Wrig73]. NCAR's 
Warren Washington provided early evidence of the utility of NCAR Graphics through his pioneering work 
in making 16 mm color movies depicting time varying parameters relevant to global climatology. NCAR Graphics 
has been a popular 2-D monochrome graphics package for over 15 years and it is currently undergoing a 
major upgrade (see Section 4.1). Richard Grotjahn and Robert Chervin [Grtj841, in the early 1980s, pushed 
NCAR Graphics to its limits in an effort to convey the results of a major global meteorological measurement 
program enacted in 1979. They used NCAR Graphics to generate individual frames for a number of movies 
depicting the atmospheric evolution during the field program. They experimented with anaglyphic stereo, 
mesh representations of surfaces, and drop shadows within the confines of NCAR Graphics to provide visual 
cues of the 3-D nature of the atmospheric features. They also experimented with various means to show 
atmospheric air parcels to depict the overall motion of the atmospheric fluid. NCAR Graphics' current 
restriction to wire-frame representation of 3-D surfaces inspired a number of other scientific investigators 
at NCAR to apply the 3-D solid rendering capabilities of MOVIE.BYU to their scientific results, as described 
below. 3.3.1.2 System. The new release (Version 2.00) of the NCAR Graphics software is not tailored to 
any specific computer. It consists of the following components: !) A level 0A Graphical Kernel System 
(GKS) package. 2) An intermediate-level library, the System Plot Package Simulator (SPPS). 3) A set of 
high-level graphics utilities. 4) A Computer Graphics Metafile (CGM) translator with drivers for several 
plotting devices. 5) Test drivers and miscellaneous databases, including map data. This version contains 
software to color-fill map regions defined by geopolitical and geographical boundaries. The graphics 
software, however, is essentially vector-based. Another meteorological graphics package developed at 
NCAR by J. B. Klemp and his colleagues is PolyPaint, which is also highly portable because it conforms 
to FORTRAN 77 and GKS standards. The system is interactive, allowing the user to specify transparency 
iudices, shading techniques, view-position, -angle, and -distance, direction of eyesight, and type of 
light source. In the first stage, PolyPaint transforms 3-D grid data to polygons and, in the second stage, 
it shades these polygons according to the technique selected. Contour lines, which are very useful for 
visualizing the spatio-temporal distribution of key variables, are rendered as thin shaded surfaces in 
3-D. Film recorders are used to produce animation sequences. 3.3.1.3 Example. The example picture (Figure 
5) was produced by Klemp and Rotunno [Klem85] to visualize the results of their numerical cloud model. 
The model is designed to study the structure of convective clouds, which produce most of the local severe 
weather events we experience: thunderstorms, hailstorms, and tornadoes. Such storms are difficult to 
observe directly in detail and the models are used to derive details on the active physical processes 
that may not be observable otherwise. Figure 5 shows a set of three horizontal slices through part of 
a mature, intense thunderstorm in a 3-D perspective view. The slices are at the ground and at 4 and 8 
kilometers above the ground. The white arrows depict the horizontal wind flow within each plane and the 
red and green contours show the updraft and downdraft regions, respectively. The yellow line marks the 
storm's gust front --the ground-based boundary where the cold storm downdraft meets the warm environmental 
air. The blue-shaded areas mark the precipitation fields, with the lighter blue indicating heavier precipitation. 
3.3.2 University of Wisconsin -- MclDAS 3.3.2.1 Background. The University of Wisconsin's McIDAS has 
been another pioneer for computer graphics applications to meteorology [Smit75]. Its original mission 
in the early 1970s was to provide convenient interactive viewing of weather satellite imagery. Over the 
years MelDAS has evolved into a workstation which combines data access and processing with sophisticated 
display techniques. MclDAS can generate multicolor composites of conventional, model, and satellite weather 
data in a wide variety of 2-D and 3-D displays as well as animations of these analyses. Systemsbased 
on MclDAS are in place at a number of Government forecasting facilities. Mainly through the efforts of 
William L. Hibbard and Y T. Young [Hibb85] [Hibb86a], MelDAS has become an impressive platform for animated 
3-D stereo depictions of a broad spectrum of meteorological data. A large effort was devoted to providing 
as many simultaneous visual cues as possible to afford the user a striking impression of the atmosphere 
in its truest form: that of a 3-D, time- evolving fluid. Cues such as perspective, motion parallax, stereoscopic 
perception, depth precedence, shading, and drop shadows were all explored and used to enhance the visual 
perception of depth. Several different types of stereo display techniques were tried, including anaglyphic, 
polarization, and electronic shutter techniques. 3.3.2.2 System. The MclDAS package runs on IBM 370-architectured 
computers as well as on IBM-PC/ATs and IBM PS/2s. It supports up to 50 custom-built graphics workstations, 
each with a resolution of 480× 640 pixels. Statistical encoding is used to compact the 6-bit/pixel images 
down to 3 bits/pixel, thus allowing / SIGGRAPH '88, Atlanta, August 1-5, 1988 128 frames for animation 
with an additional 64 frames ot graphics overlay. The package consists of a core of roughly 300,000 lines 
of FORTRAN cede for data acquisition, storage, analysis, management and graphical interaction and another 
300,000 lines for miscellaneous tasks. For the 3-D graphics software, an 8-bit z-buffer algorithm is 
used for hidden-surface removal, with depth scaling to utilize all 256 levels. In addition to true stereo, 
perspective, shading, and variations in texture, brightness and color, some novel graphics techniques 
are used to display information at all depths. These include the use of transparent and grid mesh surfaces, 
and groups of moving small objects to portray wind streamlines. The result is the simultaneous depiction 
of multiple variables for a given weather episode. Surface rendering is done by Gouraud shading of triangular 
patches, but a special shading function is used for clouds. Rendering progresses in two stages: first, 
for the opaque objects, characterized by brightness and depth, and then for the translucent objects, 
characterized by brightness, depth, and alpha (translucency index). Although no anti-aliasing is employed, 
the light source is placed in the same direction as the viewer, minimizing the effects of aliasing by 
causing the edges of shaded objects to be relatively dim. Wind streamlines are rendered as shaded translucent 
tubes, whose alpha depends on the velocity of the corresponding parcel, giving rise to a motion-blur 
effect (see Fig. 6). The system is highly interactive. The user can select options using a variety of 
input devices (keyboard, joystick, mouse, and graphics tablet). A 2-D cursor is drawn to help the user 
interact with the displayed information, with future plans for a 3-D cursor. The user has control over 
the contents, spatial and time extents, perspective point and information density [Hibb86b]. 3.3.2.3 
Example. The image shown in Figure 6 is derived from Robert Schlesinger's thunderstorm numerical model. 
It depicts wind trajectories and a transparent 0.5 g/m s cloud water concentration surface, the approximate 
cloud boundary. The horizontal domain of the model is about 50 kilometers square and the heights are 
labeled in kilometers. 3.3.3 NASA --AOIPS/2 3.3.3.1 Background. Another early leader in meteorology computer 
graphics technology has been the NASA Goddard Space Flight Center with its AOIPS system [Has183]. The 
initial version of AOIPS was built in 1976 as a high-performance, interactive meteorological processing 
system. Its software was designed to use state-of-the-art image processing for satellite image analysis 
functions such as cloud tracking and height determination. The software was later extended to include 
radar, aircraft, and ground-based meteorological data. The system is principally used by NASA atmospheric 
scientists in support of their research activities. From 1984 through 1987 AOIPS was upgraded to AOIPS/2 
using new hardware: 32 bit computers, a modern operating system, commercially available image terminals, 
and an upgraded, integrated software system. A.F. Hasler and his colleagues [Has185] have produced some 
outstanding animations of satellite imagery, using two separate types of images of the same cloud scene, 
as described below, to depict cloud-top features with striking realism. Interesting animated applications 
of these techniques are a number of movies depicting a viewpoint that moves over and around different 
kinds of cloud masses providing the illusion that one is actually flying over them. 3.3.3.2 System. AOIPS/2 
resides on a VAX 11/780 host with four MicroVAX II satellites and associated peripherals. The imaging 
and graphics tasks are performed by dedicated combinations of MicroVAX and International Image System 
(IIS) Model 75 image terminals with hardware features like zoom, pan, histogram computation, etc. Some 
of the graphics and image processing software (scaling, noise removal, image enhancement, perspective 
projection, etc.) is resident on the IIS75; the rest was developed at NASA/GSFC. The 1IS75 has 12 frames 
of image memory (512 x 512 × 8 bits) and two frames of overlay graphics memory. It is equipped with a 
track ball and a 3 x 5 button board; programs are accessed via a menu tree or by abbreviated commands. 
330 The meteorological data is received from a wide variety of sources (National Weather Service surface 
and upper-air data, and geostationary satellites). As the data arrives, it is formatted and placed in 
rotating (FIFO) files. The user can then control the animation parameters to display sequences of frames. 
One of the noteworthy features in AOIPS/2 is the ability to create true stereo images from two satellites 
or synthetic stereo pairs. The latter are obtained with a method which uses a visible image containing 
high resolution information on texture and shadows and an infrared image which contains cloud-top height 
information. Recently, an automated stereo analysis algorithm has been developed to obtain 3- D contours 
on the Massive Parallel Processor (MPP) [Has188]. 3.3.3.3 Example. Figure 7 shows a typical frame from 
one of the animations of the perspectively rendered visible/infrared satellite imagery combinations described 
in Section 3.3.3.1 above. The view is of Hurricane Diana as it was centered off the North Carolina coast 
on September 11, 1984. The satellite images were acquired from a NOAA TIROS-N operational weather satellite 
which provided 1-kilometer resolution images. 3.3.4 NOAA --PROFS 3.3.4.1 Background. NOAA's forward-looking 
PROFS effort yielded the PROFS workstation system in the early 1980s and it has been a leader in developing 
interactive graphics applications. Since the PROFS mission is ultimately to enhance weather forecasting 
operations of the National Weather Service, PROFS has expended a considerable effort experimenting with 
and developing a high-quality human-interface to computer graphics workstations. Special field evaluation 
exercises are enacted at least once each year when a collection of operational weather forecasters are 
gathered at the PROFS facility and placed in a highly realistic but simulated operational forecasting 
setting. After several weeks of using the PROFS prototype equipment, the participants are debriefed regarding 
their reactions and recommendations for the facilities. This drives the improvements that are incorporated 
into the following year's version of the PROFS prototype. PROFS graphics applications span the full range 
of meteorological data, including conventional point observations, satellite imagery, and radar imagery 
through a network of DEC VAX and PDP computers. Animation is used extensively and detailed, colored, 
graphical screen menus are used to control the workstation. 3.3.4.2 System. The main objective of PROFS 
graphics has been to provide the operational weather forecaster an interactive environment for viewing 
large volumes of measured meteorological data. The emphasis has been on the speed of response and "user-friendliness" 
rather than on realism of depiction [MacD85]. The latest version of the system is the DARSE workstation 
[Denver AWIPS-90 (Advanced Weather Interactive Processing System for the 1990's) Risk Reduction and Requirements 
Evaluation] which features a mouse-driven menu nesting interface. This interface allows the user to change 
color tables, to change the color and texture of graphics primitives, to control the loading of spocifie 
frames or sequenees of frames, and to request the coordinates and numerical value at selected points. 
A separate custom-built input device with dedicated buttons is also used for faster interactive control. 
The resolution is 1024x 1024 for single-image graphics, and 512x 512/256 x 256 for animation sequences 
of up to eight/thirty- two frames (RAMTEK 9400 color display system). The software package supports primarily 
2-D graphics with the ability to view any combination of up to 7 related variables simultaneously. This 
is accomplished by a technique called "family graphics," in which each variable is loaded on a separate 
bitplane in binary mode and then displayed by loading the proper color table. 3.3.4.3 Example. A recent 
PROFS effort has focused on using novel display techniques applied to ground-based weather data to enhance 
the human understanding of atmospheric data fields. A.E. MacDonald and Philip McDonald use 3-D polygon 
shading graphics (a modified version of NCAR's PolyPaint) to display the spatio- ~ Computer Graphics, 
Volume 22, Number 4, August 1988 temporal distribution of a parameter (e.g. pressure) through shading 
(to show its value), equi-pressure contour lines, and pseudo-color (to show its deviation from the mean). 
An example of this work is shown in Figure 8, one frame from an animation of 10 days of hourly observations. 
The objective is to enhance the meteorologist's perception of the pressure's geographical variation. 
Current plans are to extend this by displaying three different parameters simultaneously, e.g. pressure 
by shaded surfaces, temperature through color, and water vapor through contour lines. 4. Expectations 
for the Future 4.1 Meteorology The future holds exciting prospects for computer graphics applications 
in meteorology. We briefly explore these prospects from the three categories of interest: research systems, 
Government forecasting operational support systems, and prospects for the end-users of weather information. 
We expect that research systems will continue to pave the way in applying novel computer graphics techniques 
to meteorology. NCAR is now in a transition period with its NCAR Graphics package, as it is in the process 
of incorporating interactive, solid modeling, and color capabilities into its supported software package. 
A key driver in this effort is a newly established project to address the needs of meteorology data visualization 
at NCAR. The upgraded version is expected to be complete in 1989. Another major recent NCAR project is 
UNIDATA [Fulk87], a national program to help universities access, analyze, and display a wide range of 
atmospheric data. UNIDATA is developing graphics software and specifies standards for target workstation 
and networking hardware. The University of Wisconsin has two principal directions for the future. One 
is the interactive 4-D MclDAS workstation [Hibb8g] with plans to improve interactive performance, pixel 
depth, and frame sizes. The other is the low cost, personal computer-based PC-MclDAS workstation which 
is being used as one type of UNIDATA workstation, giving universities and others access to data broadcast 
by the University of Wisconsin [Ide88]. NASA's National Space Science Data Center (NSSDC) is developing 
an interactive discipline-independent tool box, called the NSSDC Graphics System (NGS), to support the 
visualization of data on the NSSDC Computer Facility [Trei87]. Another recent revolutionary development 
from this organization is the Common Data Format (CDF) standard, a data-independent abstraction for multidimensional 
data structures [Trci86]. The concept is evolving into a standard method for storing space and earth 
science data for a variety of applications. NOAA's PROFS organization is continuing its effort to adapt 
state-of-the-art technology for operational forecasting, with a near-term focus on solid-model visualizations 
of sparse meteorological data. Bob Wilhelmson of the University of Illinois and the National Center for 
Supercomputer Applications (NCSA) and other scientists at NCSA will be monitoring and probing simulations 
over very high-speed links from the supercomputer to powerful local workstations, looking at how the 
simulations are progressing, interactively steering the calculation, and selecting data to be saved and 
studied at later times. A number of major Government forecasting operational support systems are expected 
to be implemented from now through the mid 1990s. Among these are: NOAA's Automated Weather Interactive 
Processing System, the Air Force's Automated Weather Distribution System, the Navy's Tactical Environmental 
Support System, the FAA's Central Weather Service Unit, and the Federal Emergency Management Agency's 
Integrated Emergency Management Information System. All of these systems will greatly improve the interactive 
graphics facilities available to support the operations of the Government weather forecasters. Enhanced 
computer graphics applications will also directly affect the end-user of weather information, the general 
public, primarily in two areas: television weather broadcasting and in videotex services. The weather 
information vendors will continue to play a lead role in developing creative new ways to improve the 
communication of weather forecasts to the general public on television weather segments. We expect to 
see an increased use of 3-D image rendering and animation. Aviation weather applications are driving 
the incorporation of more and more weather graphics data into videotex services to provide users with 
on-demand access to near-real-time radar and satellite data. We expect to see greater use of color graphics 
and imagery in this arena. 4.2 Computer Graphics A recent study [Hama83] has shown that the time required 
by a computer to solve a benchmark problem (set of partial differential equations) has been decreasing 
geometrically by an annual factor of 2.15 over the past 35 years, due to a combination of hardware and 
algorithmic improvements; the contributions of the two components (hardware and software) are almost 
equal. We can safely extrapolate that similar decreases in computational time will also be occurring 
for graphics for the next several years due to improvements in both graphics hardware and algorithms. 
On the hardware front, the recent trend is to employ dedicated high-performance graphics engines and/or 
powerful multiprecessor parallel-architecture computers. Significant gains have been accomplished by 
these technologies and there is still ground to break. Although these machines are expensive for the 
average forecast office, past experience, as cited earlier, indicates that hardware prices will drop 
sharply from year to year. On the software front, there is a tendency to incorporate physical laws of 
motion in graphics algorithms (such as assigning mass and momentum to objects) for achieving higher levels 
of realism [Pane87] [FrenB8]. Indeed, the meteorology arena can contribute rgalism to the graphics arena 
through physical meteorological models and measured weather data which can be used for realistically 
portraying atmospheric phenomena such as clouds, lightning, and haze. Finally, we expect great improvements 
in the interactive capabilities of today's graphics packages for meteorologists. These range from the 
use of sophisticated window techniques to the inclusion of expert system front ends, which will enable 
forecasters to optimize their efficiency in manipulating and visualizing the vast amounts of data at 
thei~ disposal. Acknowledgements We thank William L. Hibbard, A. F. Hasler, Joseph Wakefield, Robert 
Lack_man, Thomas Stephenson, Barbara McGeehan, Philip McDonald, and Joseph B. Klemp for additional insight 
regarding their systems beyond what is published and for photographs of their work. We appreciate receiving 
photographs of computer-rendered images from G.Y. Gardner, Eric Hoffert and Don Mitchell. We also are 
grateful for the critique of our manuscript provided by the reviewers. References The references provided 
herein have been culled, because of space limitations, from a much larger bibliography. The full bibliography 
is available from the authors. [Bell31] Bell Telephone Laboratories, Weather Maps Transmitted by Teletypewriter 
System, Bell Laboratories Record, 3-4, September 1931. [Blin82] Blinn, J. F., Light Reflection Functions 
for Simulation of Cloud and Dusty Surfaces, Computer Graphics, Vol. 16, No. 3, 21-29, 1982. [Burt81] 
Burr, P., and Sperling, G., Time, Distance and Feature Trade-ells in Visual Apparent Motion, Psychol. 
Review, Vol. 88, 171-195, 1981. [DesJB0] DesJardins, M., and Haster, A. F., Stereographi¢ Displays of 
Atmospheric Model Data, Computer Graphics, Vol. 14, No. 3, 134-139, 1980. SIGGRAPH '88, Atlanta, August 
1-5, 1988 [Four82] [Fren88] [Fulk87] [Gard84] [Gard85] [Gelb87] [Grtj84] [ Hama83 ] [HaslS1] [Has183] 
[Has185] [Has1881 [Hibb85] [Hibb86a] [Hibb86b] [Hibb88] [Hoch78] [Huss86] [IdeS8] Fournier, A., Fussell, 
D., and Carpenter, L., Computer Rendering of Stochastic Models, Comm. of the ACM, Vol. 25, No. 6, 371-384, 
1982. Frenkel, K. A., The Art and Science of Visualizing Data, Comm. of the ACM, Vol. 31, No. 2, 111-121, 
1988. Fulker, D., Director's Report, UNIDATA Newsletter, 2, 2-3, Fall 1987. Gardner, G. Y., Simulation 
of Natural Scenes Using Textured Quadric Surfaces, Computer Graphics, Vol. 18, No. 3, 11-20, 1984 Gardner, 
G. Y., Visual Simulation of Clouds, Computer Graphics, Vol. 19, No. 3, 297-303, 1985. Gelberg, L. M., 
and Stephenson, T. P., Supercomputing and Graphics in the Earth and Planetary Sciences, IEEE Computer 
Graphics and Applications, 26-33, July 1987. Grotjahn, R., and Chervin, R. M., Animated Graphics in Meteorological 
Research and Presentations, Bulletin of the American Meteorological Society, 65, 11, 1201-1208, November 
1984. Hamann, D. R., Doing Physics with Computers~ Physics Today, May 1983. Hasler, A. F., DesJardins, 
M., and Negri, A. J., Artificial Stereo Presentation of Meteorological Data Fields, Bulletin of the American 
Meteorological Society, 66, 970-973, 1981. Hasler, A.F., Advances in Systems for Interactive Processing 
and Display of Meteorological Data, Preprints, Conference on Aerospace and Aeronautical Meteorology, 
Boston, American Meteorological Society, 60-62, June 1983. Hasler, A. F., Pierce, H., Morris, K. R., 
and Dodge, J., Meteorological Data Fields 'In Perspective', Bulletin of the American Meteorological Society, 
66, 795-801, 1985. Hasler, A.F., Strong, J., Morris, R., and Pierce, H., Automatic Analysis of Stereoscopic 
Image Pairs from GOES Satellites, Proceedings Third Conference on Satellite Meteorology and Oceanography, 
Anaheim, CA, 1988. Hibbard, W.L., Krauss, R., and Young, J.T., 3-D Weather Displays Using MclDAS, Preprints, 
1CIIPSMOH, Los Angeles, American Meteorological Society, 153-156, 1985. Hibbard, W. L., Computer-Generated 
Imagery for 4-D Meteorological Data, Bulletin of the American Meteorological Society, 67, 1362-1369, 
November 1986. Hibbard, W. L., 4-D Display of Meteorological Data, Proceedings of the 1986 Workshop on 
Interactive 3D Graphics, Chapel Hill, N.C., 23-36, 1986. Hibbard, W. L., A Next Generation MclDAS Workstation, 
Reprints, Fourth lnt'l Conf. on Interactive Info. and Processing Systems for Meteorology, Oceanography 
and Hydrology (ICIIPSMOH), Anaheim, CA, American Meteorological Society, 56-61, 1988. Hochberg, J. E., 
Perception 2 "a ed. Prentice-Hall, Englewood Cliffs, N J, 1978. Hussey, K. J., Hall, J. R., and Mortensen, 
R. A., Image Processing Methods in Two and Three Dimensions used to Animate Remotely Sensed Data, Proceedings 
of 1GARSS Symposium, Ziirich, 771-776, 1986. Ide, J. R., The UNIDATA PC-MclDAS Workstation: a Technical 
Discussion, Preprints, ICIlPSMOH, Anaheim, CA, American Meteorological Society, 332-335, 1988. [Jule60] 
[K~i84] [Klem85] [MacD85] [Mand68] [Max86a] [Max86b] [Mill86] [Nish871 [Pane87] [Papa87] [Peri85] [Peti85] 
[Pich731 [Potm83] [Rama78] [Reev83] [Reev851 [Rush87] Julesz, B., Binocular Depth Perception of Computer-Generated 
Patterns, Bell System Tech. J., 1125-1162, 1960. Kajiya, J. T., and VonHerzen, B. P., Ray Tracing Volume 
Densities, Computer Graphics, Vol. 18, No. 3, 165-174, 1984. Klemp, J. B., and Rotunno, R., Taking a 
Good Look at Data, NCAR Annual Report for 1984, Report NCAR/AR-84, 46-49, 1985. MacDonald, A. E. Design 
Considerations of Operational Meteorological Systems: A Perspective Based upon the PROFS Experience, 
ICIIPSMOH, Los Angeles, American Meteorological Society, 16-23, 1985. Mandelbrot, B. B., and VanNess, 
J. W., Fractal Brownian Motions, Fractional Noises and Applications, SlAM Review, Vol. 10, No. 4, 422-437, 
1968. Max, N. L., Atmospheric Illumination and Shadows, Computer Graphics, Vol. 20, No. 4, 117-124, 1986. 
Max, N. L., Light Diffusion through Clouds and Haze, Computer Vision, Graphics and Image Processing, 
Vol. 33, 280-292, 1986. Miller, G. S. P., The Definition and Rendering of Terrain Maps, Computer Graphics, 
Vol. 20, No. 4, 39-48, 1986. Nishita, T., Miyawaki, Y., and Nakamae, E., A Shading Model for Atmospheric 
Scattering Considering Luminous Intensity Distribution of Light Sources, Computer Graphics, Vol. 21, 
No. 4, 303-310, 1987. Panel on the Physical Simulation and Visual Representation of Natural Phenomena, 
SIGGRAPH '87, Vol. 21, No. 4, 335-336, 1987. Papathomas, T. V., Schiavone, J.A., and Julesz, B., Stereo 
Animation for Very Large Data Bases: Case Study --Meteorology, IEEE Computer Graphics and Applications, 
7, 18-27, 1987. Perlin, K., An Image Synthesizer, Computer Graphics, Vol. 19, No. 3, 287-296, 1985. Petit, 
N. J. and Lyons, W. A., Low-cost Stand-alone Receiving and Video Facsimile Display Systems for GOES-TAP 
and WEFAX/APT, ICI1PSMOH, Los Angeles, American Meteorological Society, 295-299, 1985. Pichel, W., Bristor, 
C. L., and Brower, R., Artificial Stereo: A Technique for Combining Multichannet Satellite Image Data, 
Bulletin of the American Meteorological Society, 54, 688-691, 1973. Potmesil, M. and Chakravarty, I., 
Modeling Motion Blur in Computer Generated Images, ACM SIGGRAPH "83 Proceedings, Vol. 17, No. 3, 389-399, 
1983. Ramachandran, V. S., and Gregory, R. L., Does Colour Provide an Input to Human Motion Perception? 
Nature, Vol. 275, 55-56, 1978. Reeves, W. T., Particle Systems --A Technique for Modeling a Class of 
Fuzzy Objects, ACM Trans. on Graphics, Vol. 2, No. 2, 91-108, 1983. Reeves, W. T., and Blau, R., Approximate 
and Probabilistie Algorithms for Shading and Rendering Structured Particle Systems, Computer Graphics 
19, 3, 313-322, 1985. Rushmeier, H. E., and Torrance, K.E., The Zonal Method for Calculating Light Intensities 
in the Presence of a Participating Medium, Computer Graphics, Vol. 21, No. 4, 293-302, 1987.     
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378540</article_id>
		<sort_key>335</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[A hand biomechanics workstation]]></title>
		<page_from>335</page_from>
		<page_to>343</page_to>
		<doi_number>10.1145/54852.378540</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378540</url>
		<abstract>
			<par><![CDATA[Interactive graphics for hand surgery was used to apply mathematical modeling and describe the kinematics of the hand and its resultant effect on hand function. Dynamic high resolution displays and three-dimensional images were tailored for use with a specific patients' hand and a new and powerful design and analysis tool produced. Methods were developed to portray kinematic information such as muscle excursion and effective moment arm and extended to yield dynamic information such as torque and work. This prototype workstation has been developed in concert with leading orthopedic surgeons and therapists.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[CT and MR imaging]]></kw>
			<kw><![CDATA[computer aided design]]></kw>
			<kw><![CDATA[computer graphics]]></kw>
			<kw><![CDATA[hand surgery]]></kw>
			<kw><![CDATA[hand therapy]]></kw>
			<kw><![CDATA[orthopedic surgery]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.4.2</cat_node>
				<descriptor>Assistive technologies for persons with disabilities</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10010927.10003616</concept_id>
				<concept_desc>CCS->Social and professional topics->User characteristics->People with disabilities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003580.10003587</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing profession->Assistive technologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334702</person_id>
				<author_profile_id><![CDATA[81544635256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Thompson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Louisiana State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335202</person_id>
				<author_profile_id><![CDATA[81100171850]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Buford]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[GWL National Hansen's Disease Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334941</person_id>
				<author_profile_id><![CDATA[81100010724]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Loyd]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Myers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[GWL National Hansen's Disease Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334695</person_id>
				<author_profile_id><![CDATA[81100441883]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Giurintano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[GWL National Hansen's Disease Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39039508</person_id>
				<author_profile_id><![CDATA[81100357473]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Brewer]]></last_name>
				<suffix><![CDATA[III]]></suffix>
				<affiliation><![CDATA[Louisiana State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agee, John M., Brand, Paul W., Thompson, David E. The Moment Arms of the Carpometacarpal Joint of the Thumb: Their Laboratory Determination and Clinical Application. Proc. o f t h e 37th Annual Mtg., Am. Soc. for Surgery of the Hand. -14, {New Orleans, LA, Jan 1982}.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[An, K.N., Chao, E.Y., Cooney III, W.P., Linscheid, R.L. Normative Model of Human Hand for Biomechanical Analysis. J. Biomechanics, 12,10 {1979}, 775-788.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[An, K.N., Ueba, Y., Chao, E.Y., Cooney III, W.P., and Linseheid, R.L. Tendon Excursion and Moment Arm of Index Finger Muscles. J. Biomeehanics 16,6 {1983}, 419- 425.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brand, Paul W. Biomechanics of Tendon Transfer. Symposium on Tendon Transfer in the Upper Extremity. Orthopedic Clinics of North America, 5,2 {April 1974}, 205- 230.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brand, Paul W., Beach, R.B., Thompson, D.E. Relative Tension and Potential Excursion of Muscles in the Forearm and Hand. J. Hand Surgery, 6, 3 {May 1981}, 209-219.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Brand, Paul W. Clinical Mechanics of the Hand. CV Mosby Pub., {St. Louis, 1985}.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Buford, Jr., William L. An Interactive Three Dimensional Simulation of the Kinematics of the Human Thumb, Ph.D. Dissertation, Dept of Engineering Science, Louisiana State University, 1984, also University Microfilms International, {Ann Arbor, MI, 1985} 85-15 133.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Buford, William, Myers, L. and Thompson, D. E. A Computer Graphics System for Musculoskeletal Modeling. Proc. 8th Annual EMBS Conference, 1, {Fort Worth, TX 1986}, 607-610.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Buford, William L. and Thompson, D. E. A System for 3D Interactive Simulation of Hand Biomechanics. IEEE Trans. Biomedical Engr., BME 32,6 {June, 19871 434- 453.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dev, Parvoti. A Simulator for the Analysis of Wrist Position Control. Proceedings of the 1082 American Control Conference, {Arlington, VA., June 14-16, 1082}, 1199-1204.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fick, R. Statische Berachtung der Muskulature des Oberschenkels. Z Ratiouelle Med, 9, {1850}, 94-106.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fick, R. Handbuch der Anatornie und Mechanik der Gelenke unter Berficksichtlgung der Bewegenden Muskein. 1904-1911, 3, Specielle Gelenk und Muskelmechanik, Gustav Fischer, {Jena, 1911}.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Fischer, C. W. A Treatise on the Topographical Anatomy of the Long Finger and a Biomechanical Investigation of its Interjoint Movement. Ph.D. thesis, Engineering Mechanics, Univ. of Iowa, Univ. Microfilms, Inc. {Ann Arbor, MI 1969}.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Flatt, Adrian E., Fischer, G.W. Biomeehanical Factors in the Replacement of Rheumatoid Joints. Ann. Rheum. Dist., 28, {1969}.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Giurintano, David J. and Thompson, D.E. A Kinematic Model for the Flexor Tendons of the Hand. Proc. IEEE/EMBS, Paper 40.330.4, {November, 1987}.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hemmy, David C., D.J. David, G.T. Herman. Three- Dimensional Reconstruction of Cranio-Facial Deformity Using Computed Tomography. Neurosurgery, 13, 5 {Nov. 1983}, 534-541.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Herman, G.T., Liu, H.K. Three - dimensional display of human organs from computed tomograms. Computer Graphics and Image Processing, 9 {1979} 1-21.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Landsmeer, J.M.F. Studies in the Anatomy of Articulation. Acta. Morphol. Neerlando-Seaudinavia, 3, {1961} 287-321.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Myers, Loyd M., W.L. Buford, and D.E. Thompson. A Graphics Editor for 3-D CT-Scan Data for Musculo- Skeletal Modeling. Proc. Computer Assisted Radiology {Berlin, July 1987}, 477-483.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Murphy, S.B., P.K. Kijewski, S.R. Simon, H.P. Chandler, P.P. Griffin, D.T. Reilly, B.L. Penenberg, and M.M. Landy. Computer-Aided Simulation, Analysis, and Design in Orthopedic Surgery. Orthopedic Clinics of North America, 17,4 {October 1986} 638-649.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Ou, C. Austin. The Biomechanies of the Carpometacarpal 3oint of the Thumb. Ph.D. Dissertation, Department of Mechanical Engineering, Louisiana State University, {Baton Rouge, LA, Dee. 1979}.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Rhodes, Michael L., Kuo, Y.M. and Rothman. S.L.G. Systems Integration for the Manufacturing of Custom Prostheses and Anatomical Models. Proc. Computer Assisted Radiology, {Berlin, July 1987}, 416-423.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Scherrer, P.K., and Hillberry, B.M. Piecewise Mathematical Representation of Articular Surfaces. J. of Biomeehanies, 12, {1979}, 301-311.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Thompson, David E. Biomechanies of the Hand Perspectives in Computing, 3, 3 {Oct. 1981}, 12-19.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Thompson, David E., Brewer, J.A. and Scott, S.R. Human-Machine Interaction: The Audio Connection, Computers in Mechanical Engineering, 1, 2, {1982}, 14- 18.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Thompson, David E., Buford, W.L., Brewer, J.A. and Myers, L.M. Simulating Hand Surgery: A Work in Progress. SOMA, 2, 2 {June, 1987}, 6-12.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Williams, R. and Seireg, A.A. Interactive Computer Modeling of the Musculo-skeletal System. IEEE Teansactions on Biomedical Engineering, 24, 3, {May 1977}, 213-218.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Rubenstein, Richard. Future Trends in Computer Technology: Computer Systems in the Year 2000. Presentatiou to the VAXstation University Consortium, {November 1987}.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801157</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Vannier, Michael W., Marsch, J.L. and Warren, J.O. Three Dimensional Computer Graphics for Cranio-facial Surgical Planning and Evaluation. Proceedings of SIGGRAPH'83, {Detroit, Michigan, July 25-29, 1983}. In Computer Graphics, 17,3 (July 1983), 263-273.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Vannier, Michael W., Marsh, J.L., Warren, J.O. Three Dimensional CT Reconstruction Images for Craniofaeial Surgical Planning and Evaluation. Radiology, 150, 1 {January 1984} 179-184.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Vogel, John C. Automated Machining of Custom Anatomical Models Using a Small-Scale Integrated Facility. Paper MS85-1098, Autofact Conference, Society of Autonmtive Engineers, {Detroit, Michigan, Nov. 1985}, 14.37-50.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[White, David N. Multidimensional Surgical Imaging: Changing the Link Between Radiologist and Surgeon. Administrative Radiology, {October 1986}, 51-54.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 A HAND BIOMECHANICS WORKSTATION David E. Thompson 
1, William L. Buford, Jr. ~, Loyd M. Myers 2, David J. Giurintano 2 and John A. Brewer lll t 1. Louisiana 
State University, 2. GWL National Hansen's Disease Center Abstract Interactive graphics for hand surgery 
was used to apply mathematical modeling and describe the kinematics of the hand and its resultant effect 
on hand function. Dynamic high resolution displays and three- dimensional images were tailored for use 
with a specific patients' hand and a new and powerful design and analysis tool produced. Meth-ods were 
developed to portray kinematic information such as muscle excursion and effective moment arm and extended 
to yield dynamic information such as torque and work. This prototype workstation has been developed in 
concert with leading orthopedic surgeons and ther- apists. CR Categories.and Subject Descriptors: 1.3.0 
(Computer Graphics): General; J.6 (Computer Aided Engineering)- Computer Aided Design (CAD); J.3 (Life 
and Medical Sciences) -Biology; Health. General Terms: Computer Aided Design, Computer Graphics, Ortho- 
pedic Surgery, Hand Surgery, Hand Therapy, CT and MR Imaging.  1 Introduction The ascension of computers 
for modeling in science and engineering is certainly a well acknowledged and accepted trend. What has 
not been made widely known, however, is the limited application of this same technology to medicine. 
While an engineer uses computers daily through Computer Aided Design (CAD) to assist him in his endeavor, 
there are no such tools for the private medical practitioner. At best, a surgeon's secretary uses a word 
processor or his accountant uses a spreadsheet or accounting package to assist him in the business aspect 
of his practice. There are no interactive computer modeling tools in use today to assist medical specialists 
such as orthopedic surgeons or physical therapists. This situation is the result of the fact that no 
conclusive evidence for the value of such modeling in the treatment of patients exists. Several years 
ago, Louisiana State University and the Rehabilitation Research Branch at the National Hansen's Disease 
Center joined efforts to initiate a basic research program on the biomechanics of the human hand. In 
this work, it became obvious that computers could do many things to assist us in this research. What 
we also discovered, however, was that the computer could be used as a bridge between mathematics and 
the clinical world of the orthopedic surgeon. Through interac- tive graphics, the surgeon could 'see' 
mathematical phenomena and thereby learn from the knowledge base which the mathematics repre- sented. 
What made this so valuable was that the surgeon could gain Permission to copy without fee all or part 
of this material is granted provided that the copies are not made or distributed for direct commercial 
advantage, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of the Association for Computing Machinery. To coRy otherwise, 
or to republish, requires a fee and/or specific permission. &#38;#169;1988 ACM-O-89791-275-6/88/O08/0335 
$00.75 from mathematical models and graphics without becoming an expert in their use. However, as the 
mathematics became better developed, it was determined that powerful workstations were a prerequisite 
if the simulations were to remain robust and interactive. Thus, we began to envision n workstation which 
would be of direct use in the practice of orthopedic surgery, in research and in education. In the following 
sections, the initial demonstration prototype for this workstation will be discussed along with suggestions 
for future enhance- ments.  Background In this work, we have designed a workstation environment which 
in- volves orthopedic surgery, physical therapy, mathematic modeling, in- teractive graphics, and kinematics. 
1.1 Biomechanies of the Hand The hand is a marvelous mechanical structure comprised of bones, llg- aments 
which serve to loosely connect structures, muscles which act as tension motors, tendons which serve as 
cables to connect muscles to bone, and a covering of protective soft tissue and skin. Muscles pro- duce 
torque and/or movement at joints only through tension, and for every muscle there are one or more muscles 
which serve to oppose it through counter-torque and/or opposing motion. The hand and the action of the 
flexor tendons have been extensively investigated and the literature on the hand has a long heritage. 
In 1850, Fick [11] initially developed experimental procedures for deter- mining the moment arms of the 
joints of the hand. Fick was a leader in studying the mechanics of muscles [12]. However, a hundred years 
lapsed before any other investigators extended his studies. Most studies were principally concerned with 
anatomy or were anecdotal in nature. In 1961, Landsmeer [18] proposed three models of a tendon crossing 
a joint, thereby demonstrating that there are important differences in the action of tendons at various 
joints. Brand [4] explained how a transfer of a tendon from a lesser func- tional location could be used 
to replace a deficiency in the hand's ability to perform the most elementary tasks. Brand proposed that 
the effects of muscle forces imposed on joints should be balanced. He stated the importance of knowing 
the proper axes of motion of joints and the ne- cessity of observing the excursions of tendons required 
to produce joint motion and torque. Transfer operations must use muscles which meet force and excursion 
requirements or the range of motion of the joint will be reduced, not just at the joint to which the 
transfer was made, but for all of the joints the transfer crosses. Flatt [14] and Fischer [13] measured 
cadaver specimens to ascertain the relationship to forces and torques for the fingers and what factors 
were important for surgical replacement of joints altered by rheumatoid arthritis. In Brand [6] and Brand, 
et al. [5], a muscle model was used to convert cadaver measurements into a table of relative tension 
and excursion po- tentials for each muscle of the forearm and hand. Brand discussed the general effects 
of edema, friction, and scarring on the ability of tendons to effect joint motion or produce torque. 
Data on the mechanical lever-  ¢SIGGRAPH '88, Atlanta, August 1-5, 1988 age of tendons, termed their 
moment arms, was presented along with joint ranges of motion and tendon excursions for most muscles in 
the hand. The human hand presents the mathematical modeler with a formidable task: representing the behavior 
of 44 separate muscle-tendon units, 27 major bones, and at least 18 joint articulations re- sulting in 
27 or more degrees of freedom. The modeler must also en- code the behavior of the tissues surrounding 
the muscles and bones and the ligamentous structures which modify their action. A great deal is known 
about hands, but little is known about how the mechanisms of the hand work together to achieve their 
function. Recently, mathematical models have been developed to describe the internal forces of hands 
(An et al. [2,3]). Such models are only ap- propriate for the static hand and have no general solution 
since most joints have more than a sufficient number of muscles to control the joint. This arrangement 
presents a mathematical closure problem, and forces the modeler to make additional assumptions about 
the distribu- tion of forces, torques, or energy expenditure between the muscles. To solve this problem, 
various optimization methods have been employed and the results, while extremely valuable, are limited 
in their scope. Most of the methods currently employed in reconstructive surgery of the hand are, however, 
subjectively based with diverse results and are not based on quantifiable analyticaLzationale. Surgical 
procedures on joints and muscle-tendon systems are performed daily without regard for fundamental biomechanical 
principles. Much of the work in our lab is directed towards understanding the mechanics of the hand. 
Results of this research [24,1,6,26], include measurements of required muscle excursions, and determinations 
of ef- fective muscle-tendon moment arms throughout each joint's angular range of motion. The moment 
arms for the muscles which cross the carpometacarpal (CMC) joint of the thumb (refer to Figure 11) form 
the basis for a model of CMC joint kinematics [24,21]. When defined in mathematical terms or even when 
using cleverly defined graphical plots [26], the analytical results for a simulated tendon transfer go 
un- used in the environment which has the greatest need: the orthopedic clinic. Through the use of a 
realistic interative graphics description of the musculo-skeletal system, the results of a proposed operation 
can be appreciated by a technically naive clinician. Ou [21] developed a single joint model to predict 
the excursions of all eight tendons which serve as motors for the CMC joint of the thumb. For the model, 
the tendon's path was assumed to be a straight line from the pulley point to the attachment point. Although 
quite simple, Ou's model showed good agreement with the experimental data for all eight muscles of a 
rigid thumb. Buford [7,9] extended Ou's work by developing a detailed interac- tive computer graphics 
simulation of the math model and adding a menu-driven program allowing clinical data to be entered and 
a tendon transfer operation to be simulated and observed. Buford defined the bones of the thumb by digitizing 
X-rays of a cadaver specimen used by Ou. The simulation was displayed on an Evans and Sutherland PS330 
color graphics system connected to a VAX host computer. A graphics control program allows the user to 
interactively rotate, flex-extend, or abduct-adduct the thumb at the CMCjoint. The metacarpal and distal 
interphalangeal joints are similarly user-controlled and were modeled as simple flex-extend joints. With 
real time interaction, one can ob- serve the tendon paths, the moment arms of the tendons at the CMC 
joint, display the results, and see the resultant excursions of proposed transfer operations. Three dimensional 
control coordinates of the CMC joint model de-  termined by Buford et al. [7,8] for the eight muscles 
of the thumb are used as parameters representing muscle tendon lines of action in this graphical simulation. 
Giuxintano [15] further improved this work by describing the paths of the flexor tendons as combinations 
of elemen- tary building blocks to represent tendons in sheaths, tendons or muscles which bowstring 
across joints, or tendons which behave according to Landsmeer's [18] model and traverse the joint space 
in a circular path. Tension fractions can be used to provide an estimate of the relative moment producing 
potential of each muscle. 1.2 The Man-Computer Interface Ideally, the interaction between man and computer 
is at an intuitive level sufficient to allow non-computer professionals to use advanced computer analysis 
tools. The need for real user-friendliness has never been so acute as in this application. The intended 
eventual user of this workstation will be a surgeon or therapist with limited or no computer knowledge 
or experience who wishes to use the system daily. The time pressures of a real clinical situation cannot 
be overemphasized and the system must therefore offer services not otherwise attainable and it must be 
fast and user-friendly. In our laboratory, surgeons and thera- pists have used the workstation and have 
commented that they know how they want the simulation to behave, but can not express themselves using 
simple menus and keyboard commands. Modern man-computer interactions are shaped more by the inade- quacies 
of the operating system or workstation tools than by what is natural and direct. Surgeons and therapists 
should not have to be ex- pert typists or fluent in FORTRAN, command languages, or database details. 
The use of the computer should be obvious, natural, and direct; man should interact on his terms and 
in his style, not forced to cryptic commands and methods based on what is readily accomplished in as- 
sembly language. Our work on man-computer interaction is therefore directed at understanding the use 
of speech, vision, and gesture and devising new workstation tools to accomplish natural interaction[25]. 
 1.3 Imaging The field of medical imaging has expanded enormously. Ordinary ra- diographic (X-ray) imaging 
is a relatively mature field. Simple X-rays, however, do not provide the information necessary to define 
three di- mensional structures. When computerized tomographic (CT) scans were introduced, the resulting 
improvement in visualizing three dimen- sional structures was so great that every major medical center 
in the world now has a CT scanner. Unfortunately, while the CT scanner proved of enormous benefit in 
resolving the details of bone structures due to the large density gradients involved, soft tissue information 
was limited. The development of magnetic resonance imaging (MRI) de- vices, however, allows a dramatic 
improvement in the details of soft tissues but poor resolution in bone since the current technology is 
prin- cipally based on hydrogen protons which are notably absent in bone structures. These developments 
in imaging have influenced the development of a workstation presented here. Indeed, without the ability 
to define the three dimensional database for every patient's hand, the concept would have little practical 
application. Although the initial scientific studies reported in the literature regarding CT and MR imaging 
were involved in clarifying and improving the visualization of each image slice, there is now an added 
emphasis on visualization of complete three dimensional structures derived from many serial sections. 
One of the earliest of these was reported by Vannier et al. [29,30] who discussed the use of the computer 
in planning facial reconstructive surgery. Earlier works which used some form of biomechanics modeling 
or 3-D visualization of tissue structures were reported by Williams and Seireg [27], Day [10], Hemmy 
et al. [16], and Herman and Liu [17]. Murphy et al. [20] and Rhodes et al. [22] describe the use of CT 
imaging, recon- struction algorithms, and CAD techniques to design custom prostheses. White [32] and 
Vogel [31] describe the application of CAD techniques to provide radiologists and surgeons detailed views 
and models to assist in radiographic therapy and prosthetic implants. Systems combining ad- vanced 
interactive three dimensional visualization techniques tailored to specific patients with a fully articulated 
kinematic model have not been described previously. This has added impetus to our research into the 
tools and knowledge required to construct the first workstation for orthopedic biomcchanics that encompasses 
the simulation of both the kinematics and dynamics of the human hand. The most recent work in our laboratory 
involves a special 3-D graph-  ics editor for segmenting image data containing multiple bones which 
 appear fused following edge detection. Myers et al. 119] use an in- teractive technique to split bone 
profiles at joint spaces. Scherrer and Hillberry [23] used mathematical descriptions to accurately represent 
 articular surfaces but assumed that the surface data existed and was not merged with the adjacent bone 
surface. 2 Methods and Materials 2.1 Image Data The algorithms we have developed use data taken from 
a cadaver hand specimen mounted in wax on a positioning fixture. This was attached    '~" Computer 
Graphics, Volume 22, Number 4, August 1988 to a Siemens Somatom DR3 CT scanner. For this work, 172 non- 
overlapping slices were taken (KV = 125, Mas = 780) at one millime- ter increments. The specimen was 
rotated 90 ° and 111 slices at one millimeter spacing were taken to improve joint reconstruction opera- 
tions. The planar scans were reconstructed as 512x512 voxel images with a mathematically pure convolution 
kernel to insure the integrity of the data in subsequent enhancement operations. All image data was transferred 
to magnetic tape for porting to the computing and display systems. 2.2 The Computing and Display Environment 
A Digital Equipment Corporation VAX 11/750 was used to store the raw and converted scan data and generate 
the 2-D edge data and the composite 3-D database. The graphics display system was an Evans and Sutherland 
PS 390 high performance raster color graphics unit which handles display transformations, data structure 
interactions, and interactive device I/O in teal time. The full hardware environment is depicted in Figure 
1. Software was developed along three major lines: 1. Scan data analysis programs were developed in FORTRAN 
on the VAX system and a database was written to disk in a format equiv- alent to a PS 390 vector list. 
 2. A display data structure language was used to define the hierarchl- cal display data structure. The 
bottom nodes of this structure are the vector lists for the data derived from the image scans. Named 
elements of the structure define transformation nodes which are required to position the elements relative 
to each other and to dy- namically alter their positions through rotations about their axes of motion. 
 3. Input devices are logically connected to the display transforma- tions at the named nodes using a 
function network. This code allows the user to interact with the image in real time.  The elements of 
the software are depicted in Figure 2. DEC  rE VANS S SUT.~RLA.0 ] VAX 11-750 CONTROL UNIT I Sio mlchonl¢| 
SeseoroS Computer MINC 11-2S Figure h The computing and display systems provide a high speed, multiprocessor, 
multitasking environment for- real time interactive graphic simulation of a kinematic model of the hand. 
PS3SO DISPLAY DATA STRUCTURES ( Z dl PS390 FUNCTION NETWORKS ASC41 Commctn , Mes~Oe Ouou4 I1 , h .......... 
....  2.3 Hand Image Generation A program to generate a vlewable hand structure from multiple serial 
CT or MR scans has been developed by our group. Although oth- ers have developed similar techniques, 
our goal has been to identify the soft tissues and bones and to segment the bones into individual datasets 
with as little human intervention as possible. If the workstation is to be used by paramedical personnel, 
this segmentation must be accom- plished as quickly as possible. These algorithms permit a database for 
each individual patient that is tied to a kinematic model permitting joint angulation. While all current 
3-D imaging techniques result in a single large data structure which moves as n single entity, our method 
derives independent data structures for each object of interest in the hand. This is a major advance 
and an essential ingredient in coupling the display to an articulated kinematic model. This procedure 
requires four steps: (1) A set of serial CT or MR scans is obtained with a scan density determined by 
the application; (2) The entire bone structure is identified as an entity; (3) This structure is segmented 
into whatever detail is necessary; and (4) Joint axes are aligned and defined. The last three steps are 
discussed in further detail in the following sections. 2.3.1 3-D Reconstruction Edge points are determined 
by a comparison of the pixel intensity data with a bone threshold value. This is typically 176 CT units 
[17,30]. The resultant edge points are then closed with n generalized curve-tracing algorithm (Figure 
3). Based on the zoom factor, reconstruction center, table position and the slice orientation, the pixel 
position data for each 2-D slice is converted into 3-D coordinates centered about the physical CT scan 
aperture center at table position zero. By utilizing such an "absolute" coordinate system, we are able 
to load and generate im- ages from multiple scans taken at varying zoom factors, reconstruction centers, 
and orientations, combining them into a single image without using intermediate transformations. This 
technique establishes a gross orientation, but precise alignment of sagittal and transverse scnus is 
accomplished interactively with the aid of a movable depth clipping plane to correctly align the images. 
We have found it necessary to use scans taken at various orientations to generate the requisite joint 
detail. The vectors resulting from the conversion of the scan data are stored in their edited, transformed 
states upon completion of the edit session to ensure that their precise alignment is retained. 2.3.2 
Segmentation The vectors representing bone outlines (Figure 4, 5) from the trans- verse and sagittal 
sets of orthogonal sections were combined into a single 3-D structure and sent to the FS 390 for display, 
segmentation, and transformation. Segmentation is accomplished by the use of an interactive 3-D graphics 
editor (Figure 6, 7) which provides the user with the following real-time operations: o Full rotation, 
translation, scaling, front and back surface clipping, and manipulation of the relative positions of 
sagittal and trans-verse scans to allow for the correction of error in the positioning of the-specimen 
at the time of the scan. o When in the hand icon block (mid left of display), the graphics tablet allows 
the user to select icons which represent bone data files into which subsequently picked individual curve 
vector lists will be stored or removed. o When in the menu block (lower left of display), the cursor 
is used 1o select editing operations which include: -storage of the next selected vector list to the 
current bone file -removal of the last selected vector list from the current bone file -interactive splitting 
of n single vector list into two sub-lists -restoration of previously split vector list  o When the 
cursor is within the 3-D viewing window, it is used to spec- ify the individual curve vector to which 
the current menu selection  Figure 2: The interrelationships of the three types of software. operation 
will apply.  SIGGRAPH '88, Atlanta, August 1-5, 1988 Color on the PS 390 is used to great advantage 
in the editor software. As shown in Figure 6, the currently active bone data file icon is high- lighted 
in red in the menu window. A change of color of the displayed curves denotes they have been picked and 
appended to the active data file. Red is used within a dialogue box to send error messages to the user 
when an abnormal condition has occurred. In curves where the division between bones is ambiguous, the 
original CT scan is searched fox a path of minimum intensity between two user- specified points (Figure 
8). The algorithm searches a progressively widening neighborhood composed of the average intensities 
of the eight adjacent rays of an expanding radius until a minimum is found. The search is restricted 
to a user definable angle about the line segment connecting the initial points. The search angle, maximum 
radius of search, and search type may be interactlvely altered by the user in order to obtain the best 
possible surface for a given structure. In the case of multiple minima about a certain point, the algorithm 
minimizes the gradient of the growing curve. Curves generated in this fashion become part of the data 
structure and can be edited reeursively. 2.$.3 IdentiFying Joint Axes Following the completion of the 
segmentation process for each bone, the sagittal and transverse vector lists are combined into a single 
3-D structure. The user then interactively defines a position and orientation for the bone and its joint 
axes of motion which are incorporated into the kinematic hand model. 2.4 Biomechanies Modeling on the 
Workstation As an example of the manner in which additional biomechanical models are integrated into 
the system, a special multi-joint model of the flexor tendons [15] will be discussed. Out kinematic model 
of the flexor tendons does not incorporate force analysis, and elastic, viscous, and inertial effects 
are ignored. The model has been designed, however, so that these features may be added to the simulation. 
This model has been used because of its realism and its accurate prediction of tendon excursion. The 
model can describe the paths of the Flexor Pollicis Longus (FPL), the Flexor Digitornm Prohndus (FDP), 
and the Flexor Digitorum Superficialis (FDS) ten- dons. It is assumed that the axes of rotations of the 
joints of the fingers are fixed with respect to the proximal bone segments. In this work, these positions 
were determined through cadaver dissection and verified by insertion of these data into the display simulation. 
The CMC joint of the thumb and metacarpophalangeal (MCP) joints of the finger were assumed to be three 
degree of freedom joints. The proximal interpha- langeal (PIP) and distal interphalangeal (DIP)joints 
of the thumb and fingers were modeled as one degree of freedom joints. This model uses elemental building 
blocks to construct the paths of the flexor tendons. These blocks are connected by control points tied 
to the data structure in a manner that permits them to move with the appropriate bones as the fingers 
articulate. I-Iomogeneous matrix transformations are used to transform the control points from a reference 
position to any new position of a finger in space. The various tendon elements are shown diagramatically 
in Figure 9. Here tendon model element A is used to simulate a tendon traveling in a straight line. The 
tendon could be traveling through a tendon sheath, bowstringing across a joint, or exiting from a sheath 
and inserting onto a bone. Element B is a simulation of a tendon traveling in a circular path as it crosses 
a joint. Landsmeer's [18] third model is the basis of this simulation. Element Cis a tendon dividing 
and then reconnecting to create a loop. The division and reconnection of the FDS is the basis for this 
building block. Tendon model element D is used to model a tendon segment dividing and inserting into 
a bone with dual attach- ment points. This building block models the most distal path of the FDS. The 
FPL crosses the web space of the thumb from the wrist in a straight line, travels through a sheath and 
inserts into the distal bone. To represent this path, one combines elements A and B in the sequence A-B-A-A'from 
proximal to distal. Figure 10 shows the construction of the FPL model from the building blocks. In a 
similar manner, the path of the FDP is also constructed by combining elements A and B. The only difference 
in the two paths is FDS ® ffi CONTROL POINT Figure 9: A diagram of the basic tendon building blocks 
used in the flexor tendon models. the use of Landsmeer's third model at the MCP joint of the finger as 
opposed to the tendon bowstringing across the CMC joint of the thumb. This results in the FDP model sequence 
B-A-B-A-A (reference tendons shown in purple in Figure 10). The path of the FDS may be anatomically described 
as following Landsmeer's third model at the metacarpal joint, traveling through a tendon sheath, dividing, 
reconnecting, and then dividing again before attaching to the middle phalanx. The path of the FDS is 
represented by the combination of elements B-A-C-A-D (reference tendons shown in gold in Figure 10). 
In the workstation, the PS 390 is continually updating the values of the viewing transformations and 
the functional rotations of the joints of the hand. On demand, these values are passed to the VAX and 
used to compute the positions of the control points and a set of splines used to represent each tendon. 
These are returned to the PS 390 for immediate display. The major limitation of the model is the speed 
of computation in the VAX. In this manner, any biomechanical model which can be related to the display 
data structure and its transformations can be added to the simulation. This extensibility is' one of 
the features essential for the continued growth of the workstation and its reportoire of models and functions. 
 ¢S[GGRAPH '88, Atlanta, August 1-5, 1988 The techniques developed and reported here are based on excessive 
radiation exposures necessary to obtain the detailed CT scans we have used. The expected improvements 
in imaging technology will, how- ever, allow the immediate application of our methods to clinical use. 
In this project we have demonstrated not only the technical feasibility of implementing a biomechanics 
workstation, but also the real neces- sity for applying the computer as a clinical, research, and educational 
tool. When combined with the continued development of the hardware and software for workstations and 
new user friendly environments, the future for this technology is indeed bright and promising.  Acknowledgement 
 The funding for this research was provided by the U.S. Public Health Service, Department of Health and 
Human Services under research con- tract 240-83-0060. Additional computing support was provided by the 
Computer Graphics Research and Applications Laboratory, Depart- ment of Mechanical Engineering, Louisiana 
State University through a joint research program with Digital Equipment Corporation. Evans and Sutherland 
has provided a PS 390 display system for use in this project. The images for this research were provided 
by Digital Diagnostics, Inc. of Baton Rouge, LA (Dr. Charles Grieson, Director). They pro- vided both 
support and scan time for this project. References [I] Agee, John M., Brand, Paul W., Thompson, David 
E. The Moment Arms of the Carpometacarpal Joint of the Thumb: Their Laboratory Determination and Clinical 
Application. Proc. of the 37th Annual Mtg., Am. Soc. for Surgery of the Hand. -14, [New Orleans, LA, 
Jan 1982]. [2] An, K.N., Chao, E.Y., Cooney III, W.P., Linscheid, R.L. Normative Model of Human Hand 
for Biomechanical Analysis. J. Biomechanics, 1~,10 [1979], 775-788. [3] An, K.N., Ueba, Y., Chao, E.Y., 
Cooney III, W.P., and Linseheid, R.L. Tendon Excursion and Moment Arm of Index Finger Muscles. J. Biomeehanics 
16,6 I1983], 419- 425. [4] Brand, Paul W. Biomechanics of Tendon Transfer. Sym- posium on Tendon Transfer 
in the Upper Extremity. Or-thopedic Clinics of North America, 5,2 [April 1974], 205- 230. [5] Brand, 
Paul W., Beach, R.B., Thompson, D.E. Rela- tive Tension and Potential Excursion of Muscles in the Forearm 
and Hand. J. Hand Surgery, 6, 3 [May 1981], 209-219. [6] Brand, Paul W. Clinical Mechanics of the Hand. 
CV Mosby Pub., [St. Louis, 1985]. [7] Buford, Jr., William L. An Interactive Three Dimen-sional Simulation 
of the Kinematics of the Human Thumb, Ph.D. Dissertation, Dept of Engineering Sci- ence, Louisiana State 
University, 1984, also University Microfilms International, [Ann Arbor, MI, 1985] 85-15 133. [8] Buford, 
William~ Myers, L. and Thompson~ D. E. A Computer Graphics System for Musculoskeletal Model- ing. Proc. 
8th Annual EMBS Conference, 1, [Fort Worth, TX 1986], 607-610. [9] Buford, William L. and Thompson, D. 
E. A System for 3D Interactive Simulation of Hand Biomechanics. IEEE Trans. Biomedical Engr., BME 3~,6 
[June, 19871 434- 453. [10] Dev, Parvoti. A Simulator for the Analysis of Wrist Position Control. Proceedings 
of the 1082 Ameri-can Control Conference, [Arlington, VA., June 14-16, 1082], 1199-1204. [II] Fick, R. 
Statische Berachtung der Muskulature des Oberschenkels. Z Ratiouelle Med, 9~ [1850], 94-106. [12] Fick, 
R. Handbuch der Anatornie und Mechanik der Gelenke unter Berficksichtlgung der Bewe-genden Muskein. 1904-1911, 
3, Specielle Gelenk und Muskelmechanik, Gustav Fischer, [Jena, 1911]. [13] Fischer, C. W. A Treatise 
on the Topographical Anatomy of the Long Finger and a Biomeehanieal In- vestigation of its Interjoint 
Movement. Ph.D. thesis, En- gineering Mechanics, Univ. of Iowa, Univ. Microfilms, Inc. [Ann Arbor, MI 
1969]. [14] Flatt, Adrian E., Fischer, G.W. Biomeehanical Factors in the Replacement of Rheumatoid Joints. 
Ann. Rheum. Dist., g8, [1969]. [15] Giurintano, David J. and Thompson, D.E. A Kine-matic Model for the 
Flexor Tendons of the Hand. Proc. IEEE/EMBS, Paper 40.330.4, [November, 1987]. [16] Hemmy, David C., 
D.J. David, G.T. Herman. Three- Dimensional Reconstruction of Cranio-Facial Deformity Using Computed 
Tomography. Neurosurgery, 13, 5 [Nov. 1983], 534-541. [17] Herman, G.T., Liu, H.K. Three -dimensional 
display of human organs from computed tomograms. Computer Graphics and Image Processing, 9 [1979] 1-21. 
[18] Landsmeer, J.M.F. Studies in the Anatomy of Articu- lation. Acta. Morphol. Neerlando-Seaudinavia, 
3, [1961] 287-321. [19] Myers, Loyd M., W.L. Buford, and D.E. Thompson. A Graphics Editor for 3-D CT-Scan 
Data for Musculo- Skeletal Modeling. Proc. Computer Assisted Radi- ology [Berlin, July 1987], 477-483. 
[20] Murphy, S.B., P.K. Kijewski, S.R. Simon, H.P. Chan- dler, P.P. Griffin, D.T. Reilly, B.L. Penenberg, 
and M.M. Landy. Computer-Aided Simulation, Analysis, and De- sign in Orthopedic Surgery. Orthopedic Clinics 
of North America, 17,4 [October 1986] 638-649. [21] Ou, C. Austin. The Biomechanies of the Car-pometacarpal 
3oint of the Thumb. Ph.D. Dissertation, Department of Mechanical Engineering, Louisiana State University, 
[Baton Rouge, LA, Dee. 1979]. [22] Rhodes, Michael L., Kuo, Y.M. and Rothman. S.L.G. Systems Integration 
for the Manufacturing of Custom Prostheses and Anatomical Models. Proc. Computer Assisted Radiology, 
[Berlin, July 1987], 416-423. [23] Scherrer, P.K., and t-Iillberry, B.M. Piecewise Mathemat- ical Representation 
of Articular Surfaces. J. of Biome- ehanies, 1~, [1979], 301-311. [24] Thompson, David E. Biomechanies 
of the Hand Perspec-tives in Computing, 3, 3 [Oct. 1981], 12-19. [25] Thompson, David E., Brewer, J.A. 
and Scott, S.R. Human-Machine Interaction: The Audio Connection, Computers in Mechanical Engineering, 
I, 2, [1982], 14- 18. [26] Thompson, David E., Buford, W.L., Brewer, J.A. and Myers, L.M. Simulating 
Hand Surgery: A Work in Progress. SOMA, 2, 2 [June, 1987], 6-12.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378543</article_id>
		<sort_key>345</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Screen PostScript (panel session)]]></title>
		<page_from>345</page_from>
		<doi_number>10.1145/54852.378543</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378543</url>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Screen design (e.g., text, graphics, color)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor>Image displays</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011666</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Touch screens</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45024080</person_id>
				<author_profile_id><![CDATA[81336487875]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Callow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P132345</person_id>
				<author_profile_id><![CDATA[81100031518]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gosling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P170492</person_id>
				<author_profile_id><![CDATA[81100046940]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Leo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hourvitz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NeXT, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P261010</person_id>
				<author_profile_id><![CDATA[81100422560]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McGregor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 '~' Computer Graphics, Volume 22, Number 4, August 1988 Panels Screen PostScript Chair: Charles Geschke 
(Adobe Systems, Inc.) Panelists: Mark Callow (Silicon Graphics) James Gosling (Sun Micrsystems, Inc.) 
Leo Hourvitz (NEXT, Inc.) Scott McGregor (Digita] Equipment Corporation) One of the most exciting and 
controversial areas in display graphics today is the use of PostScript for screen display and window 
systems. PostScript is an interpretive programming language with powerful, resolution-independent graphics 
capabilities. PostScript played a key role in bringing about the desktop publishing revolution and is 
now a de facto standard for laser printers. In the words of Arthur C. Clarke, "PostScript output is the 
future of words on paper." Recently several products have brought PostScripts to the screen. These range 
from basic PostScript output display to an entire window system based on PostScript. Printing and screen 
display can now be driven from a common format. This panel brings together pioneers and leading developers 
of PostScript screen technology from Sun Microsystems, Adobe Systems, Digital Equipment Corporation, 
Silicon Graphics and NEXT. The panelists contrast their different design approaches, discuss "real-world" 
applications and speculate on future directions. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378545</article_id>
		<sort_key>346</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Parallel processing for computer vision and display (panel session)]]></title>
		<page_from>346</page_from>
		<doi_number>10.1145/54852.378545</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378545</url>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Parallel processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Parallelism and concurrency</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Computer vision</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761.10003762</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency->Parallel computing models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P335041</person_id>
				<author_profile_id><![CDATA[81406596724]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Dew]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Leeds, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136082</person_id>
				<author_profile_id><![CDATA[81339500019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fuchs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14153096</person_id>
				<author_profile_id><![CDATA[81100435002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tosiyasu]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Kunii]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136485</person_id>
				<author_profile_id><![CDATA[81100251533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Wozny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Polytechnic Institute and NSF]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '88, Atlanta, August 1-5, 1988 User Interface Toolkits; Present and Future Chair: Brad A. Myers 
(Carnegie Mellon University) Panelists: Owen Densmore (Sun Microsystems, ]nc.) David Goldsmith (Apple 
Computer, Inc.) Andrew Schulert (Apple Computer, Inc.) Smokey Wallace (Digital Equipment Corporation) 
 The days when people implemented user interfaces from scratch are almost over. Implementers now expect 
to use some kind of users interface toolkit when constructing their systems. These toolkits may contain 
such things as moused-based menus, buttons and scroll-bars, as well as facilities for handling the keyboard. 
These low level primitives out of which user interfaces are constructed are often called interaction 
techniques. This panel discusses what interaction techniques can be found in toolkits today and what 
will be available in the future. Other topics to be covered included the internal structure of the toolkit 
(why are they mostly object-oriented?), and tools for helping the programmer use the toolkits (often 
called user interface management systems). Parallel Processing for Computer Vision and Display Chair: 
Rae A. Earnshaw (University of Leeds, UK) Panelists: Peter M. Dew (University of Leeds, UK) Henry Fuchs 
(University of North Carolina at Chapel Hill) Tosiyasu L. Kunii (University of Tokyo, Japan) Michea[ 
J. Wozny (Rensselaer Polytechnic Institute and NSF) Current developments in parallel processing are 
of increasing interest to those concerned with the creation, display and analysis of pictures. This panel 
explores the impact that developments in parallelism are having in the traditional areas of computer 
graphics and visualization. State-of-the-art topics include SIMD machines, VLSI and ULSI architectures 
for vision and image, high performance visualization of 3-D models, parallel algorithms, low-level vision, 
theoretical aspects, image segmentation, CSP arrays and transputers, real-time 3-D graphics and pattern 
recognition. The following are of great significance: Computer graphics and computer vision strategies 
are being brought together via vision and AI techniques.  Ingenious developments in parallel architectures 
are producing systems capable of exploitation in novel and revolutionary application areas.  The sum 
total of these tools is a range of powerful and innovative systems that will change the face of computer 
graphics and the traditional man/machine interface. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378544</article_id>
		<sort_key>346</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[User interface toolkits; present and future (panel session)]]></title>
		<page_from>346</page_from>
		<doi_number>10.1145/54852.378544</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378544</url>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P212607</person_id>
				<author_profile_id><![CDATA[81100510731]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Owen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Densmore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Leeds, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P61729</person_id>
				<author_profile_id><![CDATA[81100197138]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goldsmith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P18323</person_id>
				<author_profile_id><![CDATA[81100273481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schulert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335141</person_id>
				<author_profile_id><![CDATA[81365592948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Smokey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wallace]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Polytechnic Institute and NSF]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '88, Atlanta, August 1-5, 1988 User Interface Toolkits; Present and Future Chair: Brad A. Myers 
(Carnegie Mellon University) Panelists: Owen Densmore (Sun Microsystems, ]nc.) David Goldsmith (Apple 
Computer, Inc.) Andrew Schulert (Apple Computer, Inc.) Smokey Wallace (Digital Equipment Corporation) 
 The days when people implemented user interfaces from scratch are almost over. Implementers now expect 
to use some kind of users interface toolkit when constructing their systems. These toolkits may contain 
such things as moused-based menus, buttons and scroll-bars, as well as facilities for handling the keyboard. 
These low level primitives out of which user interfaces are constructed are often called interaction 
techniques. This panel discusses what interaction techniques can be found in toolkits today and what 
will be available in the future. Other topics to be covered included the internal structure of the toolkit 
(why are they mostly object-oriented?), and tools for helping the programmer use the toolkits (often 
called user interface management systems). Parallel Processing for Computer Vision and Display Chair: 
Rae A. Earnshaw (University of Leeds, UK) Panelists: Peter M. Dew (University of Leeds, UK) Henry Fuchs 
(University of North Carolina at Chapel Hill) Tosiyasu L. Kunii (University of Tokyo, Japan) Michea[ 
J. Wozny (Rensselaer Polytechnic Institute and NSF) Current developments in parallel processing are 
of increasing interest to those concerned with the creation, display and analysis of pictures. This panel 
explores the impact that developments in parallelism are having in the traditional areas of computer 
graphics and visualization. State-of-the-art topics include SIMD machines, VLSI and ULSI architectures 
for vision and image, high performance visualization of 3-D models, parallel algorithms, low-level vision, 
theoretical aspects, image segmentation, CSP arrays and transputers, real-time 3-D graphics and pattern 
recognition. The following are of great significance: Computer graphics and computer vision strategies 
are being brought together via vision and AI techniques.  Ingenious developments in parallel architectures 
are producing systems capable of exploitation in novel and revolutionary application areas.  The sum 
total of these tools is a range of powerful and innovative systems that will change the face of computer 
graphics and the traditional man/machine interface. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378547</article_id>
		<sort_key>347</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Four paths to computer animation]]></title>
		<subtitle><![CDATA[entertainment, broadcast, education and science - will their future converge? (panel session)]]></subtitle>
		<page_from>347</page_from>
		<doi_number>10.1145/54852.378547</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378547</url>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P335086</person_id>
				<author_profile_id><![CDATA[81100320391]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queens Road Film Services, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P140234</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Jet Propulsion Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P40883</person_id>
				<author_profile_id><![CDATA[81100251531]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosendahl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pacific Data Images]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39049151</person_id>
				<author_profile_id><![CDATA[81100573310]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Craig]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Upson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Steller Computer, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Four Paths to Computer Animation: Entertainment, 
Broadcast, Education and Science - Will Their Futures Converge? Chair: Nancy St. John (Pacific Data Images) 
Panelists: Robert Abe] (Queens Road Film Services, Inc.) Jim Blinn (Jet Propulsion Laboratory) Carl Rosendahl 
(Pacific Data Images) Craig Upson (Stellar Computer, Inc.) Scientific graphics gave birth to the computer 
animation field in the 1960s. In the early 1970s, broadcast and educational computer animation were offshoots 
from scientific animation, and in the early 1980s, broadcast animation gave birth to entertainment animation. 
What will the 1990s bring? Already, entertainment companies are providing computers for scientific and 
educational use while entertainment and broadcast animation are using more and more science. Will these 
four fields coverge into one field again? Or will there still be science animation as opposed to education 
animation or entertainment animation rather than broadcast animation. The panelists attempt to address 
these questions and present representative work from their respective fields. A lively discussion should 
ensue with the presentation of different perspectives of where computer animation will and should go. 
Computer Graphics and the Changing Methodology for Artists and Designers Chair: Alyce Kaprow (The New 
Studio) Panelists: Rob Haimes (Consultant) Joel Slayton (San Jose University) Paul Souza (WGBH Educational 
Foundation) As computer graphics become a standard addition in the artisit's and designer's studio, the 
notion of the process of visual communication and visual problem solving is changing. Along with this 
comes a newly defined approach to visual problem solving based on the additional capabilities of the 
designer/artist. There is also a need to understand the distinct differences between the disciplines 
of art-making and graphic design, which are often considered one and the same by developers of graphic 
systems. Because the computer is capable of synthesizing many tasks and operations, the lines often drawn 
between visual art, music, poetry, sound and environmental design will become faint, allowing us to define 
a new aesthetic. The state of the art, or more accurately, the state of the market, available to artists 
and designers has a long way to go to make this technology accessible and affordable to all. However, 
even with all the present limitations and hesitations, it is still a time to become aware of the inevitable 
changes and to be a direct participant in the development of this technology. The use of such equipment 
promises to expand our abilities beyond anything that has been previously investigated. It is essential 
that those artists and designers who embrace this technology help form it into a meaningful and useful 
toolbox. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378549</article_id>
		<sort_key>347</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Computer graphics and the changing methodology for artists and designers (panel session)]]></title>
		<page_from>347</page_from>
		<doi_number>10.1145/54852.378549</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378549</url>
		<categories>
			<primary_category>
				<cat_node>K.7.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003580.10003584</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing profession->Computing organizations</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31041071</person_id>
				<author_profile_id><![CDATA[81100410454]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haimes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31036929</person_id>
				<author_profile_id><![CDATA[81100316584]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slayton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[San Jose University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P335036</person_id>
				<author_profile_id><![CDATA[81100431703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Souza]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[WGBH Educational Foundation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 Four Paths to Computer Animation: Entertainment, 
Broadcast, Education and Science - Will Their Futures Converge? Chair: Nancy St. John (Pacific Data Images) 
Panelists: Robert Abe] (Queens Road Film Services, Inc.) Jim Blinn (Jet Propulsion Laboratory) Carl Rosendahl 
(Pacific Data Images) Craig Upson (Stellar Computer, Inc.) Scientific graphics gave birth to the computer 
animation field in the 1960s. In the early 1970s, broadcast and educational computer animation were offshoots 
from scientific animation, and in the early 1980s, broadcast animation gave birth to entertainment animation. 
What will the 1990s bring? Already, entertainment companies are providing computers for scientific and 
educational use while entertainment and broadcast animation are using more and more science. Will these 
four fields coverge into one field again? Or will there still be science animation as opposed to education 
animation or entertainment animation rather than broadcast animation. The panelists attempt to address 
these questions and present representative work from their respective fields. A lively discussion should 
ensue with the presentation of different perspectives of where computer animation will and should go. 
Computer Graphics and the Changing Methodology for Artists and Designers Chair: Alyce Kaprow (The New 
Studio) Panelists: Rob Haimes (Consultant) Joel Slayton (San Jose University) Paul Souza (WGBH Educational 
Foundation) As computer graphics become a standard addition in the artisit's and designer's studio, the 
notion of the process of visual communication and visual problem solving is changing. Along with this 
comes a newly defined approach to visual problem solving based on the additional capabilities of the 
designer/artist. There is also a need to understand the distinct differences between the disciplines 
of art-making and graphic design, which are often considered one and the same by developers of graphic 
systems. Because the computer is capable of synthesizing many tasks and operations, the lines often drawn 
between visual art, music, poetry, sound and environmental design will become faint, allowing us to define 
a new aesthetic. The state of the art, or more accurately, the state of the market, available to artists 
and designers has a long way to go to make this technology accessible and affordable to all. However, 
even with all the present limitations and hesitations, it is still a time to become aware of the inevitable 
changes and to be a direct participant in the development of this technology. The use of such equipment 
promises to expand our abilities beyond anything that has been previously investigated. It is essential 
that those artists and designers who embrace this technology help form it into a meaningful and useful 
toolbox. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378550</article_id>
		<sort_key>348</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[What can we learn by benchmarking graphics systems? (panel session)]]></title>
		<page_from>348</page_from>
		<doi_number>10.1145/54852.378550</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378550</url>
		<categories>
			<primary_category>
				<cat_node>K.6.2</cat_node>
				<descriptor>Benchmarks</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Standards</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011017</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Domain specific languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010919.10010177</concept_id>
				<concept_desc>CCS->Computing methodologies->Distributed computing methodologies->Distributed programming languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011123.10011130</concept_id>
				<concept_desc>CCS->General and reference->Cross-computing tools and techniques->Evaluation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011123.10011124</concept_id>
				<concept_desc>CCS->General and reference->Cross-computing tools and techniques->Metrics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Standardization</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334577</person_id>
				<author_profile_id><![CDATA[81100600320]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Broder]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitre Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334961</person_id>
				<author_profile_id><![CDATA[81100068445]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Charette]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electronic Data Systems Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334633</person_id>
				<author_profile_id><![CDATA[81365592385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Croll]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P285628</person_id>
				<author_profile_id><![CDATA[81100586999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Turner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitted]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Numerical Design, Ltd.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '88, Atlanta, August 1-5, 1988 What Can We Learn by Benchmarking Graphics Systems? Chair: Ricki 
Blau (University of California, Berkeley) Panelists: Alan Broder (Mitre Corporation) Mark A. Charette 
(Electronic Data Systems Corporation) Brian Croll (Sun Microsystems, Inc.) Turner Whitted (Numerical 
Design, Ltd.) As a growing user population relies on computer graphics as a tool in everyday work, there 
is increasing interest in the performance of graphics systems. Recent proposals for standard graphics 
benchmarks demonstrate this interest. This panel discusses some of these proposals and investigates general 
issues in measuring the performance of graphics systems. Can a standard set of benchmarks reveal accurate 
insights to a varied constituency? What are the right and the wrong parameters to measure? How can we 
obtain the information we want? What comparisons are useful? Panelists consider the structure, contents 
and interpretation of benchmarks and offer alternative approaches to performance measurement. The panelists 
include benchmark designers, system builders and users with wide experience in the performance analysis 
of software and hardware for graphics. The goal of the panel is to suggest ways to obtain meaningful 
performance measurements. The Reality of Computer Graphics in the Motion Picture Industry Co -Chairs: 
Richard Hollander (Video Image Associates) Micheal Wahrman (deGraf/Wahrman, Inc.) Panelists: Mike Fink 
(Peak's Island Productions) Kirk Thatcher (Henson Associates) Ralph Winter (Paramount Studios) This panel 
addresses the state of computer generated imagery in the film industry as it exists today. It is five 
years since the release of Tron and the use of computer generated effects in the motion picture industry 
is still quite limited. Many of the people in the field of computer graphics believe that Hollywood is 
moving inexorably in the direction of computer generated imagery for special effects and animation, but 
in the indusrty itself there is no such perception. In fact, one occasionally hears computer graphics 
described as "cold, expensive, over-rated and of no particular interest to the movie-going audience." 
This panel presents the attitudes of the Hollywood entertainment creative and decision-making community 
towards computer graphics, animation and special effects. Questions to be discussed include: Who uses 
computer graphics today?  Why don't they use more of it?  Why is the perception that there is no audience 
demand?  What can be done to improve the acceptance of this medium in the film industry?  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378552</article_id>
		<sort_key>348</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[The reality of computer graphics in the motion picture industry (panel session)]]></title>
		<page_from>348</page_from>
		<doi_number>10.1145/54852.378552</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378552</url>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P334993</person_id>
				<author_profile_id><![CDATA[81336489159]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fink]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Peak's Island Productions]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334910</person_id>
				<author_profile_id><![CDATA[81100523058]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kirk]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thatcher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Henson Associates]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14202406</person_id>
				<author_profile_id><![CDATA[81538508256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ralph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Winter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Paramount Studios]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 SIGGRAPH '88, Atlanta, August 1-5, 1988 What Can We Learn by Benchmarking Graphics Systems? Chair: Ricki 
Blau (University of California, Berkeley) Panelists: Alan Broder (Mitre Corporation) Mark A. Charette 
(Electronic Data Systems Corporation) Brian Croll (Sun Microsystems, Inc.) Turner Whitted (Numerical 
Design, Ltd.) As a growing user population relies on computer graphics as a tool in everyday work, there 
is increasing interest in the performance of graphics systems. Recent proposals for standard graphics 
benchmarks demonstrate this interest. This panel discusses some of these proposals and investigates general 
issues in measuring the performance of graphics systems. Can a standard set of benchmarks reveal accurate 
insights to a varied constituency? What are the right and the wrong parameters to measure? How can we 
obtain the information we want? What comparisons are useful? Panelists consider the structure, contents 
and interpretation of benchmarks and offer alternative approaches to performance measurement. The panelists 
include benchmark designers, system builders and users with wide experience in the performance analysis 
of software and hardware for graphics. The goal of the panel is to suggest ways to obtain meaningful 
performance measurements. The Reality of Computer Graphics in the Motion Picture Industry Co -Chairs: 
Richard Hollander (Video Image Associates) Micheal Wahrman (deGraf/Wahrman, Inc.) Panelists: Mike Fink 
(Peak's Island Productions) Kirk Thatcher (Henson Associates) Ralph Winter (Paramount Studios) This panel 
addresses the state of computer generated imagery in the film industry as it exists today. It is five 
years since the release of Tron and the use of computer generated effects in the motion picture industry 
is still quite limited. Many of the people in the field of computer graphics believe that Hollywood is 
moving inexorably in the direction of computer generated imagery for special effects and animation, but 
in the indusrty itself there is no such perception. In fact, one occasionally hears computer graphics 
described as "cold, expensive, over-rated and of no particular interest to the movie-going audience." 
This panel presents the attitudes of the Hollywood entertainment creative and decision-making community 
towards computer graphics, animation and special effects. Questions to be discussed include: Who uses 
computer graphics today?  Why don't they use more of it?  Why is the perception that there is no audience 
demand?  What can be done to improve the acceptance of this medium in the film industry?  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378554</article_id>
		<sort_key>349</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[X Window System (panel session)]]></title>
		<page_from>349</page_from>
		<doi_number>10.1145/54852.378554</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378554</url>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Windowing systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>X-Window</descriptor>
				<type>P</type>
			</other_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011075.10011079.10011080</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Designing software->Software implementation planning->Software design techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011081</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development process management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011053</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Window managers</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P132308</person_id>
				<author_profile_id><![CDATA[81100069208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gettys]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Equipment Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334787</person_id>
				<author_profile_id><![CDATA[81100499797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Goerges]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grinstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Lowell]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31041594</person_id>
				<author_profile_id><![CDATA[81100423056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bertram]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Herzog]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Michigan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P246348</person_id>
				<author_profile_id><![CDATA[81100077964]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheifler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 X Window System Chair: George Champine (Digital 
Equipment Corporation) Panelists: James Gettys (Digital Equipment Corporation) Goerges Grinstein (University 
of Lowell) Bertram Herzog (University of Michigan) Robert Scheifler (Massachusetts Institute of Technology) 
 The X Window System has now been endorsed by every major workstation manufacturer, and is rapidly becoming 
a de facto industry standard for application interfaces. However, the impact on graphics is far from 
clear and X is still evolving. Major issues to be addressed by the panel include: lack of world coordinate 
output (a la PostScript); relationship to NeWS and MS-Windows; support of images and live video; adequacy 
of the toolkit; 3-D extensions to X; and role of the X Consortium. X has generated considerable controversy 
because it introduces yet another drawing package whose relationship to existing graphics standards is 
unknown, as is its applicability to graphics applications. This issue is also addessed. Media Technology 
Chair: Andrew Lippman (MIT Media Laboratory) Panelists: Walter Bender (MIT Media Laboratory) Marvin Minsky 
(MIT Media Laboratory) David Zeltzer (MIT Media Laboratory) Media technology is a new research field 
that is only recently gaining legitimacy and widespread recognition as an intellectual domain. The field 
can be described as the convergence of the areas of computing, communications and information. Systems 
that result from research in this field are the synthesis of these into new forms of interaction, learning, 
creative expression and entertainment. A theme of much work is either the merger of the creative users 
of media with its developers, or the notion of building direct, intuitive interfaces to information systems, 
or the more general goal of making computer systems that enhance human creativity. Underlying technologies 
that form the basis for the field include sound and image processing in human cognitive processing. This 
panel explores current work in the field. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378555</article_id>
		<sort_key>349</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[Media technology (panel session)]]></title>
		<page_from>349</page_from>
		<doi_number>10.1145/54852.378555</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378555</url>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39043717</person_id>
				<author_profile_id><![CDATA[81100458252]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Walter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bender]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135828</person_id>
				<author_profile_id><![CDATA[81336491376]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marvin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032919</person_id>
				<author_profile_id><![CDATA[81100216523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeltzer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 22, Number 4, August 1988 X Window System Chair: George Champine (Digital 
Equipment Corporation) Panelists: James Gettys (Digital Equipment Corporation) Goerges Grinstein (University 
of Lowell) Bertram Herzog (University of Michigan) Robert Scheifler (Massachusetts Institute of Technology) 
 The X Window System has now been endorsed by every major workstation manufacturer, and is rapidly becoming 
a de facto industry standard for application interfaces. However, the impact on graphics is far from 
clear and X is still evolving. Major issues to be addressed by the panel include: lack of world coordinate 
output (a la PostScript); relationship to NeWS and MS-Windows; support of images and live video; adequacy 
of the toolkit; 3-D extensions to X; and role of the X Consortium. X has generated considerable controversy 
because it introduces yet another drawing package whose relationship to existing graphics standards is 
unknown, as is its applicability to graphics applications. This issue is also addessed. Media Technology 
Chair: Andrew Lippman (MIT Media Laboratory) Panelists: Walter Bender (MIT Media Laboratory) Marvin Minsky 
(MIT Media Laboratory) David Zeltzer (MIT Media Laboratory) Media technology is a new research field 
that is only recently gaining legitimacy and widespread recognition as an intellectual domain. The field 
can be described as the convergence of the areas of computing, communications and information. Systems 
that result from research in this field are the synthesis of these into new forms of interaction, learning, 
creative expression and entertainment. A theme of much work is either the merger of the creative users 
of media with its developers, or the notion of building direct, intuitive interfaces to information systems, 
or the more general goal of making computer systems that enhance human creativity. Underlying technologies 
that form the basis for the field include sound and image processing in human cognitive processing. This 
panel explores current work in the field. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378558</article_id>
		<sort_key>350</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Software directions for scientific visualization (panel session)]]></title>
		<page_from>350</page_from>
		<doi_number>10.1145/54852.378558</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378558</url>
		<categories>
			<primary_category>
				<cat_node>J.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39030239</person_id>
				<author_profile_id><![CDATA[81365592525]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Roy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334994</person_id>
				<author_profile_id><![CDATA[81337490396]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaplan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334575</person_id>
				<author_profile_id><![CDATA[81318490408]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Al]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lopez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P15765</person_id>
				<author_profile_id><![CDATA[81100078209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Alvy]]></first_name>
				<middle_name><![CDATA[Ray]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378556</article_id>
		<sort_key>350</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Hardware strategies for scientific visualization (panel session)]]></title>
		<subtitle><![CDATA[58]]></subtitle>
		<page_from>350</page_from>
		<doi_number>10.1145/54852.378556</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378556</url>
		<categories>
			<primary_category>
				<cat_node>D.2.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007</concept_id>
				<concept_desc>CCS->Software and its engineering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39051427</person_id>
				<author_profile_id><![CDATA[81332493735]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Clark]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15032129</person_id>
				<author_profile_id><![CDATA[81100432746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[DeFanti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334940</person_id>
				<author_profile_id><![CDATA[81100493909]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lou]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Doctor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P86049</person_id>
				<author_profile_id><![CDATA[81100028213]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Frank]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378559</article_id>
		<sort_key>351</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Designing effective pictures]]></title>
		<subtitle><![CDATA[is photographic realism the only answer? (panel session)]]></subtitle>
		<page_from>351</page_from>
		<doi_number>10.1145/54852.378559</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378559</url>
		<categories>
			<primary_category>
				<cat_node>I.3.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.4.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP60023125</person_id>
				<author_profile_id><![CDATA[81100294395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blinn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P188366</person_id>
				<author_profile_id><![CDATA[81100098812]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Margaret]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Hagen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1059314</person_id>
				<author_profile_id><![CDATA[81100427474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1059315</person_id>
				<author_profile_id><![CDATA[81452617082]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jock]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mackinlay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>378561</article_id>
		<sort_key>351</sort_key>
		<display_label></display_label>
		<article_publication_date>06-01-1988</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[Extending graphics standards to meet industry requirements (panel session)]]></title>
		<page_from>351</page_from>
		<doi_number>10.1145/54852.378561</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=378561</url>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Standards</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011017</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Domain specific languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010919.10010177</concept_id>
				<concept_desc>CCS->Computing methodologies->Distributed computing methodologies->Distributed programming languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011017</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Domain specific languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010919.10010177</concept_id>
				<concept_desc>CCS->Computing methodologies->Distributed computing methodologies->Distributed programming languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Performance</gt>
			<gt>Standardization</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P258718</person_id>
				<author_profile_id><![CDATA[81100207464]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Salim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abi-Ezzi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P334793</person_id>
				<author_profile_id><![CDATA[81365595937]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Laib]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P333306</person_id>
				<author_profile_id><![CDATA[81100117553]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Puk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1988</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

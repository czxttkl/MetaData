<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date></start_date>
		<end_date></end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>122718</proc_id>
	<acronym>SIGGRAPH '91</acronym>
	<proc_desc>Proceedings of the 18th annual conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Computer graphics and interactive techniques</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-89791-436-8</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>1991</copyright_year>
	<publication_date>07-01-1991</publication_date>
	<pages>393</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source>ACM member price $40</other_source>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node>I.3.0</cat_node>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<ccs2012>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>100</concept_significance>
		</concept>
		<concept>
			<concept_id>0.10010147.10010371</concept_id>
			<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
			<concept_significance>500</concept_significance>
		</concept>
	</ccs2012>
	<general_terms>
		<gt>Algorithms</gt>
		<gt>Design</gt>
		<gt>Languages</gt>
		<gt>Performance</gt>
		<gt>Theory</gt>
	</general_terms>
	<chair_editor>
		<ch_ed>
			<person_id>PP40041417</person_id>
			<author_profile_id><![CDATA[81100411412]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[James]]></first_name>
			<middle_name><![CDATA[J.]]></middle_name>
			<last_name><![CDATA[Thomas]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Battelle Pacific Northwest Labs., Richland, WA]]></affiliation>
			<role><![CDATA[Chairman]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>1991</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>122719</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Animation aerodynamics]]></title>
		<page_from>19</page_from>
		<page_to>22</page_to>
		<doi_number>10.1145/122718.122719</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122719</url>
		<abstract>
			<par><![CDATA[Methods based on aerodynamics are developed to simulate and control the motion of objects in fluid flows. To simplify the physics for animation, the problem is broken down into two parts: a fluid flow regime and an object boundary regime. With this simplification one can approximate the realistic behaviour of objects moving in liquids or air. It also enables a simple way of designing and controlling animation sequences: from a set of flow primitives, an animator can design the spatial arrangement of flows, create flows around obstacles and direct flow timing. The approach is fast, simple, and is easily fitted into simulators that model objects governed by classical mechanics. The methods are applied to an animation that involves hundreds of flexible leaves being blown by wind currents.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[aerodynamics]]></kw>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[control motion design]]></kw>
			<kw><![CDATA[flow primitives]]></kw>
			<kw><![CDATA[fluid mechanics]]></kw>
			<kw><![CDATA[leaves]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Physics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010441</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Physics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P131498</person_id>
				<author_profile_id><![CDATA[81100153872]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jakub]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wejchert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[European visualization Centre, IBM Scientific Centre, Winchester, Hampshire S023 9DR, England]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P61933</person_id>
				<author_profile_id><![CDATA[81100097114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haumann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research, T.J. Watson Research Center, Yorktown Heights, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson J (1985) "Fundamentals of Aerodynamics", Mc(~raw-I lill Publishers.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barzcl R, Barr A (1988) "A Modeling System based on Dynamic Constraints", Computer Graphics (SI(;(;RAPIt 88 Proceedings) 22 (4) 179.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Feynman R, Leighton R, Sands M (1965) "The Feynman Lectures on Physics', Addison Wesley.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[l:ournicr A, Reeves W (1986) "A Simple Model of Ocean Waves", Computer Graphics (SIGGRAPH "86 Proceedings) 20 (4) 75.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I laumann D, Parent R (1988) "The Behavioral Test- Bed' Obtaining Complex Behavior from simple Rules" 'l'he Visua| Computer 4 (6) 332.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97884</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kass M, Miller G (1990) *Rapid, Stable Fluid Dynamics for Computer Graphics" Computer Graphics (SI(;(; RAPI ! 90 Proceedings) 24 (4) 49.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Miller (;, Pearce A (1989) "Globular Dynamics: A Connected Particle System for Animating Viscous Fluids", Computers and Graphics, Vol 13, 305.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>115248</ref_obj_id>
				<ref_obj_pid>115244</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Norton A, 'Furk G, Bacon R (1990) "Animation and Fracture by Physical Modeling", To appear in "The Visual (?omputcr".]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[I'allrrsofl A (I 989) "A First Course in Fluid Dynamics" Can~hridge University Press.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Pilnlado X, |:uimc E (1989) "Grafields: Field-Directed l)y~~amic Splines for Interactive Motion Control" Conlpulcrs and (;raphics Vol 13, 77.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378524</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Plalt .I, Barr A (1988) "Constraint Methods for Flexible Models", Computer Graphics (S|GGRAP{! 88 Procccdir~gs) 22 (4) 279.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801167</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Recvcs W (1983) "Particle Systems - A Technique for M~dclin~ a Class of Fuzzy Objects" Computer (}rapimics (S|G()RAPll 83 Proceedings) 17 (3) 359.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97923</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Sims K (1990) "Partic|o Animation and Rendering Using l)ata Parallel Computation", Computer Graphics (SI(;(;RAPI I 90 Proceedings) 24 (4) 405.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Tcrzopoulos D, Platt J, Barr A, Fleishcer K (1987) "|:~laslically Deformanblo Models", Computer Graphics (SI(;(;RAP|! 87 Proceedings) 21 (4) 205.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 ANIMATION AEROD Y/VAMJCS JAKUi3 WEJCIIER T and 
I) AVII) IIA(JMANN European visualization Cenlre I ilM Research lilM Scientific Centre, Winchester 1 
.J, Watson Research Center Yorktown I icighls, New York 10S98, USA. IIampshire S023 9DR, England. Abstract 
Methods based on aerodynamics arc developed to simulate and controi the motion of objeck in fluid flows. 
To simplify the physics for animation, the problcm is broken down into two parts: a fluid flow regime 
and an object boundary re­gime. With this simplification one can approximate the re­alistic behaviour 
of ohjecLs moving in liquids or air. il aiso enabies a simpie way of designing and controlling animation 
sequences: from a set of flow primitives, an animator can design the spatial arrangement of flows, create 
Ilows around obstacies and direct flow timing. i he approach is fast, sim plc, and is easily fhted into 
simulators that rnodei objects governed by classical mechanics. i he rncthods arc appiied to an animatinn 
that involves hundreds of flexible Icavcs be­ing biown by wind currents. Keyw nrds: Animaliorr, Simulation, 
Acrrxiynamics, [ iuid Mechanics, i low i rimitives, Controi, Motion Design, Wind, ieaves. CR ( atcgorics 
i.3.5, i.3.7, i.6.3, J.5.  INTRODUCTION ilvery year leaves fail from trees and gather on the autumn 
ground; winds biow and scat[er them in currents, wlliripoois and eddies. i his charming motion is a corrscqucnce 
of acrodynarnics: tile description of fiuid flow and iLs rclatirm to the motion of srsiid objects. An 
Aerodynamic Modci with Controi: Wc dcscrihc a fasl aerodynamic way of rnode[ling and controlling Ihe 
motion of many ficxibic objects in fluid currents in 3i>. Physics or engineering applications would require 
numericai solutions of fluid flow with immersed soiid objcct$. ilecausc animation has less slringcnf. 
accuracy requirements, we can avoid computational expense by dividing the system into two parts: a linear 
flow regime and an object boundary rcgirnc. The first ranges over ali space and the second is used in 
the ciose vicinity of ohjccts. in the Iincat flrrw regime wc usc the an­aiytic soiulions of the equations 
insleud of soiving for the flow frumericaily. i hcse solutions define a SC{of flow Permissiontocopywithoutfeeallor 
partofthismaterialisgranted providedthat the copies are nut made or distributed for direct commercial 
advantage, rhe ACM copyrigh( notice and tbe title of the publication and its date appear. and notice 
is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, 
or to republish, requires a fee and/or specific permission. t 1991 AcM-()-x9791-436-8/91 /(N)7/(M)19 
$0075 primitives which arc given as ouid veiocily fields. Soiutions such as vorticcst sinks and uniform 
ilows, can be Iineariy mixed so ;]s 10 crcale a compiex ilow scenario. The primi­tives enahlc tbc design 
and conlroi of animalion sequences. i hc sccomi part of ti)c model is fJre interaction between the Oow 
and the ohjecLs. i his is based upon simplified boundary CITCCLS,titiit dcscrihc the forces exerted on 
object surfaces. once Ihc fbrccs acting on objccfs are known, object motion is governwi by Ncwtrmian 
mechanics. i?eievernt Modckw i)arlicie based systems have nrimickcd the visual appearance of tire [i 
2], watcrfaiis, faliing snow [13], and viscous jets [7]. Aithough these models have produced slunning 
cfrccts they can orriy account for particle-like ob­jects. Simui;Jtions of elasticity [11, 5, 8], have 
displayed the Ilcxibility or individu;d objects; related models couid exhibit the flappitlg motion nf 
flags in uniform wind fields [i4, 5]. Animation models of liquids, such as ocean foam [4] and shailow 
waler [6] bavc displayed the visual appearance of liquid surfaces, but arc not uscfui for rcprescnling 
internal Ouid currents. Usuaily, models of nalurai phenomena are too crrmplcx 10 bc applied by an animator 
using traditional lcchniqucs; a numhcr of researchers have addressed this. i intado [10] (icscribcs an 
approach that aiiows the control of ohjcct motion in non-physicai 2i) ficids, CMher mclhods ;illow anim; 
~tinns to hc crrntroiied by geometrical constrains (w op[ilrli T,;ltion [1 1, 2]. ilowcver, these techniques 
can be nurncric.nlly intensive and become unwieldiy ror controlling cwllcctions of rrbjccls with many 
degrees of freedom. in summary, II)c abo~rc rnodcis do not explicitly address the simlll;~liolt of nlany 
flcxibic ohjeck in dynamic fluid flows, cnmbinml u ill) n fiIsI control method. LINEARIZED FLUID FLOW 
I ltc mcclmnics of a fluid can be dcscribcd by the Navier S[okcs cqu;]lion [3, Y]. l his can bc simplified 
in (he case nl a iluitl tilat is A) inviscid, ii) irrotational (V x v = O) and (;) incomimrsssiblc (V.v 
= 0). i his is a reasonable modei for air at twrmal speeds when it dots not exhibit turbulence [1]. i 
icrc v, is the velocity field of the fluid, describing the magnittldc ;Jnci direction of the flow at 
every point. I hc simplified fitlid wrtisfics lhc i.aplacc cqualion V,v = V.vif = v~r$ =0. (i) i i\c 
vciocily field is given by the gradient of the scalar po­tctlliai v = V~J. Since (1) is a iincar ditTerential 
equa~ion, if wc find ;uly two analytical soiutions then lbcir linear combi ­n;llinn is alsn a solution; 
the application of boundary condi­tions ~hcn rcsuih in a physics/ srriution. i ypicaiiy, it is rcquirc~i 
tbal the flow shouid bc A) uniform at infinity and 11) have no norm;ll cornprmcni at obstacle boundaries 
[9]. i!J SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 Since solutions are analytic, we bypass the task 
of solving the fluid equations numerically and provide a fast and simple technique for creating flows 
for animation. Flow Primitives: We call a velocity field that satisfies eq (1) and the boundary condhions, 
a flow primitive. Given a set of flow primitives, an animator can conslrucl more compli­cated flows from 
these building blocks, in a manner similar to that used by Sims [13]. In fact, the primitives provide 
a physical basis for the velocity operators that he used to di­ rect particle systems. Our simplest primitive 
is um~orm flow: the velocity lines follow straighl lines. other solutions in­clude source, sink and vortex 
flows. A source is a point from which tluid moves out in all directions; a sink is a point to which fluid 
flows uniformly in all directions and disappears; and fluid moves around a vortex in concentric circles 
(fig 1). Using cylindrical coordinates, the potential and the velocity field for a line of source at 
the origin, wilh strength a, is: f$=+lnfi v,=*; VO=O; v,=(I. (2) For a sink the constant a is set negative. 
A vortex at the origin with strength b is given by: 4=*O; V,=(); b Vz= o. (3) @=G; Flow Ohstaclcs: 
We can also use flow primitives to design flows around Iargc solid obstacles, and to bound the spatial 
extent of flows. obstacles can be built out of primitives that arc strong enough to cause a main flow 
to be directed from certain regions. Similar methods are used to study the flow around obstacles such 
as airfoils [1]. Figure 3 shows the c~cct of adding together a uniform flow with a point source. I his 
can bc (akcn to represent flow around a solid object. No fluid flows across the stagnation flow line 
shown in hold, so if a solid object with the geometry of the stagnation curve were placed in Lhe fluid, 
there would be no flow across ils surface. his approach is faster than normal collision dctectirm algorithms 
and allows the smooth and natural tnotion of the objects as they interact with obstacles. The method 
was used to crcatc the motion of leaves around ob­stactcs such as slides or walls. *    ====%( U-RN 
Slmr SOURCE VomEx Figure 1. A schematic diagram of the flow primitives. Addition of Flows: Because the 
syslem is tinear (and hecausc of a uniqueness theorem) if a flow satisfies eq (1) and has the required 
properdes on object boundaries and at infinity, then it is the correct solution [1, 9]. Thus (as in aerodynamics) 
we can add the primitives to create more complicated flows: v= VW,,(XJ,2) + v,in~(xJ,z) + v,o r=(xJJ,z) 
+ .... (4) - - Figure 2. The addition of uniform and vortex flow, Figure 2 shows the flowlines that 
result from the addition of a uniform flow with a vortex. The flow detincs the whole temporal path of 
the fluid at the beginning, middle and end of the motion. Since the positions and stzengths of the primitives 
can be chosen, the approach allows for a simple, physically-motivated way of designing the paths of objects. 
Once objects are placed in the fluid, their t.rajcctorics have already been determined hy the user to 
a first approximation. Figure 3. (;rcriting solid obstacles to flow using the addition of primitives, 
1 imcdcpcndent Flows: We can also model time-dependent flows with the condition that changes to the primitives 
are dircctcd hy ~orccs that are external to the system (user spec­iticd). Although the time evolution 
of the forces may not be physically based, the resulting flow at each frame will be. I imc-varyiog fields 
enable a user to change the flow lines, by directitlg the positions of the primitives with time. This 
gives a fhrthcr degree of control, allowing obstacles to move and events to occur at specific times. 
Coupled with bounded Iiclds, it cnahlcs the control of cof/ectimrs of objects to follow sfsccificd paths, 
OBJECT BOUNDARY REGIME I)ividing the systcm into two regimes, Iincar flow and boundary Iaycr, simplifies 
our general problem. For the major parl fluids arc taken to behave as a linear inviscid systcm; however, 
in the vicinity of objects we must include boundary C(TCCLSsuch as viscous drag and pressure. In this 
way forces cxcrtcd on the objects may be calculated. Particles in Flows: A model for particles in flows 
can be based on the Stoke drag equation. Tlds gives the force ex­erted on a spherical particle with radius 
a, moving with rel­ative vclncity v in a fluid with viscosity q as: F= 67ruqv . (5) (iivcn ;I mass particle 
with velocity p, the relative velocity with respect to a fluid velocity field v is: v = v p. So from 
cq (5) wc Mine the force on the particle as  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122720</article_id>
		<sort_key>23</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Animated free-form deformation]]></title>
		<subtitle><![CDATA[an interactive animation technique]]></subtitle>
		<page_from>23</page_from>
		<page_to>26</page_to>
		<doi_number>10.1145/122718.122720</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122720</url>
		<abstract>
			<par><![CDATA[Current research efforts focus on providing interactive techniques that make 3D concepts easy to use and accessible to large numbers of people. In this paper, a new interactive technique for animating deformable objects is presented. The technique allows easy specification and control of a class of deformations that cannot be produced by existing techniques without considerable human intervention.The methodology proposed relies on the Free-Form Deformation (FFD) technique. It makes use of a deformation tool that is animated like any other object.This approach provides a representation of the deformations independent of the surface geometry, and can be easily integrated into traditional hierarchical animation systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39042187</person_id>
				<author_profile_id><![CDATA[81100424950]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sabine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coquillart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sabbatical at Thomson Digital Images, Paris and INRIA, 78153 Le Chesnay, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P227309</person_id>
				<author_profile_id><![CDATA[81100388755]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Janc&#233;ne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA, 78153 Le Chesnay, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Bart. Dynamic Constraints. Siggro, ph Course Notes, 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74358</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J.E. Chadwick, D.R. Haumann, and R.E. Parent. Layered Construction for Deformable Animated Characters. In SIGGRAPH'S9, volume 23, pages 243-252. ACM, July 1989.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97900</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Coquillart. Extended Free-Form Deformation: A Sculpturing Tool for 3D Geometric Modeling. In SIGGRAPH'90, volume 24, pages 187-193. ACM, August 1990.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T.W. $ederberg and S.R. Parry. Free-Form Deformation of Solid Geometric Models. In SIG- GRAPH'86, volume 20, pages 151-160. ACM, August 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Animated Wee-Form Deformation: An Interactive 
Animation Technique Sabine Coquillart* and Pierre Janc&#38;ze INRIA 78153 Le Chesnay, France Abstract 
 Current research efforts focus on providing interactive techniques that make 3D concepts easy to use 
and ac­cessible to large numbers of people. In this paper, a new interactive technique for animating 
deformable objects is presented. The technique allows easy specification and control of a class of deformations 
that cannot be produced by existing techniques without considerable human intervention. The methodology 
proposed relies on the Free-Form Deformation (FFD) technique. It makes use of a defor­mation tool that 
is animated like any other object. This approach provides a representation of the defor­mations independent 
of the surface geometry, and can be easily integrated into traditional hierarchical anima­tion systems. 
CR Categories and Subject Descriptors: 1.3.6 [Computer Graphics]: Methodology and Techniques -Interaction 
techniques; I. 3.7 [Computer Graphics]: Three Dimensional Graphics and Realism -Animation. Introduction 
 A great deal of work has been done towards the use of physical simulation as a means of animating deformable 
objects [1]. Considerably less attention has been given to interactively animating non physically-based 
models. Presently 011 sabbatical at Thomson Digital Imagesl Paris, PermissinrrIOcopy withmn fee all or 
part of this material is gmnted provided thal the copies are not made or distributed fnr direct commercial 
advantage. (he ACM copyright notice and the title of the publication and its dam appear, and notice is 
given that cnpying is by permission of the Asslwiatimr for Computing Machinery. To copy o(herwiw, or 
[o republish. requirm a fee andkx specific pcrmiwmrr. The predominant method in use today is metamor­phosis. 
Metamorphosis is a method used to create inter­ mediary shapes that make a smooth transition between 
two or more extreme or key-shapes. It is useful when every point of the animated model changes from one 
 position to the next at the same time and speed. If this is not the case, metamorphosis may require 
a large number of key-positions, i.e. considerable human inter­vention, resulting in an animation that 
will be, never­theless, only an approximation of the desired one. In this paper, an alternative to the 
metamorphosis technique is described. It can be used to specify the motion of a local deformation such 
as an arbitrarily shaped bump whose shape may change over time or the motion of an object inside a global 
deformation whose shape may also change over time. This technique, Animated Free-Form Deformation (AFFD), 
relies on the Free-Form Deformation (FFD) [4] technique together with the Extended Free-Fornl De­formation 
(EFFD) [3] extension. The Free-Form Defor­mation technique consists of embedding the geometric model, 
or the region of the model to be deformed, into a user-defined 3D lattice. The deformations of the 3D 
lattice are then automatically passed on to the model. The 3D lattice represents a piecewise parametric 
vol­ume. AFFD is interactive, intuitive, and independent of the geometric model of the object to be deformed. 
Furthermore, it can be integrated into most traditional animation systems. 2 Animated Free-Form Deformations 
This section concentrates on two types of animated de­formations: the motion of a local deformation and 
the motion of a surface inside a global deformation. Until now, except in Chadwick et al. [2], FFD has 
mainly been exploited as a geometric modeling technique. The animation technique described in this paper 
consists of taking advantage of the deformation tool paradigm. In FFD, the deformation tool is composed 
t! 1991 ACM-()-X979I-436-S/91/(H)7/(t023 m75      
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122721</article_id>
		<sort_key>27</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Motion without movement]]></title>
		<page_from>27</page_from>
		<page_to>30</page_to>
		<doi_number>10.1145/122718.122721</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122721</url>
		<abstract>
			<par><![CDATA[We describe a technique for displaying patterns that appear to move continuously without changing their positions. The method uses a quadrature pair of oriented filters to vary the local phase, giving the sensation of motion. We have used this technique in various computer graphic and scientific visualization applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[motion display]]></kw>
			<kw><![CDATA[oriented filters]]></kw>
			<kw><![CDATA[perception]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computation of transforms (e.g., fast Fourier transform)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003717</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computation of transforms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14104148</person_id>
				<author_profile_id><![CDATA[81452610969]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Freeman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P75009</person_id>
				<author_profile_id><![CDATA[81100466478]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Adelson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P61956</person_id>
				<author_profile_id><![CDATA[81100505719]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Heeger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NASA-Ames Research Center 262-2, Moffet Field, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S.Anstis. Luminance edges can kill motion. Investigative Opthatmology and Visual Supplement, page 426, 1989.(ARVO 1989.)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R N, Bracewell. The Fourier Transform and its Applications. Mcgraw-Hill, 1978.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W.T. Freeman and E. H. Adelson.Steerable filters for early vision, image analysis, and wavelet decomposition. In Proc. 3rd Intl.Conf.Computer Vision, Osaka, Japan,1990, IEEE.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>117688</ref_obj_id>
				<ref_obj_pid>117684</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W.T. Freeman and E. H. Adelson. The design and use of steerable filters for image analysis, enhancement, and multiscale representation.IEEE Pat. Anal Mach. Itell, 1991., Accepted for publication.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. J, Heeger. W. T. Freeman, and E. H. Adelson. Nude descending a staircase. In Physics Art at the California Museum of Science and Industry (Los Angeles, summer 1989), and in SIGGRAPH '90 Art Show (Dallas, August 1990).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>130247</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Lim. Two-Dimensional signal and Image processing. Prentice Hall, Englewood Cliffs, New Jersey, 1990.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B., D, Lucas and T. Kanade. An iterative image registration technique with an applicaion to stereo vision. In proc,Seventh IJCAI, pages 674-679, Vancouver, 1981.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Shadlen, T.Camey, and E. Switkes. Illusory rotattion, expansion, and contraction from transitions in local symmetry. Invetigative Opthamology and Visual Science Supplement, page 300, 1987. (ARVO 1987).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. G. Shoup. Color table animation. In J.C.Beatty and K.S. Booth editors, Tutorial: Computer Graphics, pages 214-219. IEEE Computer Society, Silver Spring, MD, 1982.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97923</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K.Sims. Particle animation, and rendering using data parallel computation. In SIGGRAPH-90, Dallas., 199o.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. R Smith. Paint. In J. C. Beatty and K,S. Booth, editor, Tutorial; Computer Graphics, pages 501-515. IEEE Computer Society. Silver Spring, MD, 1982.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Motion Without Movement William T. Freeman~, Edward 
H. Adelson~, and David J. Heeger~ fThe Media Laboratory Massachusetts Institute of Technology Cambridge, 
MA 02139 $NASA-Ames Research Center 262-2 Moffet Field, CA 94035 Abstract We describe a technique for 
displaying patterns that appear to move continuously without changing their positions. The method uses 
a quadrature pair of oriented filters to vary the local phase, giving the sensation of motion. We have 
used this technique in various computer graphic and scientific visualization applications. CR Catsgorles: 
1.3.3 [Computer Graphics]: Picture/Image Generation; 1.3.7 [Computer Graphics]: Graphics and Realism; 
1.4.9 [Image Processing]: Applications. Keywords: Motion Display, Oriented Filters, Perception,  1 Introduction 
Motion display is important in scientific visualization and computer graphic displays. One would often 
like to paint motion onto a scene, just as one can paint color or texture. Existing techniques for indicating 
motion have drawbacks. Superimposed arrows on a static image add clutter and give no sense of motion. 
If objects in the scene are set into actual motion in a film loop, then they must periodically snap back 
to their starting positions, giving a jerky display. Other techniques to display motion include the massively 
parallel simulation of particle systems [ 10], and pseudo­ color techniques such as color table animation 
[9; 11].  2 Creating the motion illusion We describe a method for assigning perceptual motion to objects 
that remain in fixed positions, by applying local filters and continuously varying their phase over time. 
The technique makes use of perceptual phenomena described by Shadlen et al. [8] and Anstis [I], where 
local phase changes are interpreted as global motions. Shadlen et d. produce the effect using patch-wise 
ITT s and Hilbert transforms. Our new technique is based on recently developed steerable filters [3; 
4], which provide a convenient and flexible implementation of the illusion. Consider two filters, identical 
except shifted in phase from each other by 90 degrees. The filters are called a quadrature pair, and 
are related by the Hilbert tranfonn [2]. Figure 1 shows such a pair of even and odd phase filters (chosen 
for orientation properties to be used later), (a) the second derivative of a Gaussian, Gz, and (b) its 
Hilbert transform, H2. Filters of intermediate phases, shown in Permtwmn t<]cwpy wi[hour kc all or parr 
of this material is granted provided that the cop]es an! not made or distributed for direct commcrcia] 
advantage. the ACM copyright notice and the tide of !he publiciumn and i!s date xppear. irnd notice is 
,yven that copying is by pcrm]ssmn ot the Aiwcifitimr for Computing Machinery. To cnpy otherwise, or 
to republiih, requires a fce ~nd/or sp+.?cificpermission. Fig. I(c), may be constructed as weighted sums 
of the even and odd phase filters. Note in Fig. I(c) that the filter ripples move rightward as the phase 
is shifted. This sequence of phase-shifted filters was computed using the following formula: F(t) = cos(wt)G2 
+ sin(ut)H2 (1) where F is the phase-shifted filter, u is the rate of phase shift, and t is time. when 
one views a phase-shifting stimulus, like the sequence of filters shown in Fig. l(c), an interesting 
visual illusion occurs: it appears that the entire pattern (both the ripples and the modulation envelope) 
is moving. This visual illusion of motion can be applied to any spatial pattern; an example is shown 
in Fig 2. Figs 2(a) and (b) show the results of convolving an image of Albert Einstein with a quadrature 
pair of filters (see [6] for background on image processing and convolution). Fig 2(c) shows the image 
sequence computed from combining (a) and (b) according to Eq. ( 1). when viewed as a temporal sequence, 
the result is a compelling illusion of continual (rightward) motion of a stationary image, To display 
motion in different directions, we need to apply the filters at different orientations. For that, we 
use steerable filters , which allow one to to synthesize a filter of arbitrary orientation from a linear 
combination of basis filters [3; 41. Fig. 3 shows the basis sets for tbe GZ and H2 filters. One can span 
the space of all rotations of each filter with these basis sets. Introducing the notation j@ to indicate 
rotation of the function f through an angle 8, we have, for the function Gz, G:(z, y) = k,(@) ~2a(~, 
~)+k2(~)(;2b( X,~)(@)+k3(8)~2 .(Z, ~) (2) where ki(8) are the interpolation functions, and G2~,zb,2~(z, 
y) are the basis functions for G;( x, y). There is an analogous formula for Hf (z, y) with four basis 
functions. (The number of basis filters required is related to the number of angular frequencies in the 
filter [3; 4]). Tables 1-4 give filter tap values and interpolation functions for computationally efficient 
x-y separable versions of the G2 and HZ steerable filters. The x-y separable basis filters are shown 
in Figure 6. To cause an image, 1( z, y), to appear to move in a different direction, 6 (z, g), at every 
point (z, y) in the image, we use the even and odd phase images, E(z, y) and O(r, y): E(z, y) = I(r, 
y) qG :(= rJ (3) D(z, y,t) = cos(wt)E{z, y) +sin(wt)O(z, y) (5) where D(z, y, t) is the displayed image 
sequence, w is the temporal frequency of the displayed motion, and @ represents convolution. Wkh steerable 
filters, this angularly adaptive filtering is simple to perform. The output at each pixel is simply a 
linear combination of  II 1991 AcM-1)-xv7Yl-436-x191 /(M)7/(M)27 $0075 27 2 SIGGRAPH 91 Las Vegas, 28 
July-2 August 1991 (4 @I Figure 1: l-d cross-sections of filters. (a) Even phase (Ga). (b) Odd phase 
(Hz). (c) Filters modulated in phase according to Eq. (1). Note the apparent rightward motion of the 
filter ripples. Figure 2: (a) and (b): G2 and Hzfilters were applied to an image of Einstein. (c) Images 
modulated as in Eq. (1). When viewed as a temporal sequence, this generates the perception of rightward 
motion, yet image Figure 3: (a) G2 and (b) HZquadrature pair steerable basis filters. The filter sets 
(a) and (b) span the space of all rotations of their respective filters. the corresponding pixel values 
from severalbasis images. The basis images need to be calculated only once. Motion speed variations may 
be included by changing w as a function of position (the speed is proportional to w). A potential drawback 
of this technique is that the output images are bandpass filtered along the local direction of motion, 
and low- pass filtered in the perpendicular direction (reflecting the properties of the oriented filters). 
To improve the image quality, one can restore some of the frequency components perpendicular to 0( z 
, y ) by adding -I(z, y) @ G,8( )t 2 to each frame of the processed sequence. For color images, one can 
apply the technique to the luminance component of the image, and add in the stationary chrominance components. 
In the resulting sequence, both the luminance and the chrominance components are perceived to be moving. 
However, the color gamut is limited to pastelized colors, since there needs to be a positive bias to 
the luminance, to avoid negative light values. remains stationary.  3 Applications Motion without movement 
adds a compelling motion cue, with a variety of applications in visualization and computer graphic display. 
This technique can be used to create a continuous display of instantaneous motion. Figure 4 (a) shows 
a single frame of a motion sequence of a man catching a teddy bear. From two consecutive frames of the 
video sequence, instantaneous motion vectors were derived, using the method of Lucas and Kanade [7]. 
These motion directions, Fig. 4 (b), were used for @(z, y) in Eq. 5 to create the even and odd phase 
images, Fig. 4 (c) and (d). The resulting sequence, shown in Fig. 4 (e), is a continuous display that 
corresponds to the motion at one instant. The bear is constantly falling toward the man, who is forever 
reaching out to grab it. Figure 5 shows single frames from several other applications of motion without 
movement. Fig. 5 (a) is a simulated air traffic controller s display, where the airplane velocities are 
shown by the motion illusion, yet the airplane icons maintain their positions. The sequence of Fig. 5 
(b) displays instantaneous velocities in a physical simulation of several objects colliding. Fig. 5 (c) 
is from a computer art piece entitled Nude Descending a Staircase [5], a modem interpretation of Duchamp 
s painting. In summary, we have described a flexible technique for indicating motion on graphics display 
screens. Objects or patterns appear to be continuously moving, yet stay at one position. This compelling 
motion illusion can be used to continuously display instantaneous motion. We have used this technique 
in various computer graphic and visualization applications. 4 Acknowledgement This work was supported 
in part by a contract with Goldstar Co., Ltd., and by NSF grant IRI 87 l-939-4. 63 Computer Graphics, 
Volume 25, Number 4, July 1991 (e) Figure 4: Continuous display of instantaneous motion information. 
(a) single frame of video sequence. (b) instantaneous motion, obtained from (a) and the frame following 
it. Even (c) and odd (d) filtered images are combined using Eq. 5 to give the resulting image sequence(e). 
 References [l] S. Anstis. Luminance edges can kill motion. Investigative Opthalmology and Visual Science 
Supplement, page 426, 1989. (ARVO 1989). [2] R. N. Bracewell. The Fourier Transform and its Applications. 
McGraw-Hill, 1978. [3] W. T. Freeman and E. H. Adelson. Steerable filters for early vision, image analysis, 
and wavelet decomposition. In Proc. 1 k,(o) = sin (O) 1 3rd Ml. Conf Computer Vision, Osaka, Japan, 
1990. IEEE. [4] W. T. Freeman and E. H. Adelson. The design and use of Table 1: X-Y separable basis 
set and interpolation functions for steerable filters for image analysis, enhancement, and multi- second 
derivative of Gaussian. To create a second derivative of scale representation. IEEE Pat. Anal. Mach. 
Intell., 1991. a Gaussian rotated along to an angle 0, use: Gg = L,(B) Gza + Accepted for publication. 
b(e) G2b + k(e) G2c. [5] D. J. Heeger, W. T. Freeman, and E. H. Adelson. Nude descending a staircase. 
In Physics Art at the California Museum of Science and Industry (Los Angeles, summer 1989), and in SIGGRAPH 
90 Art Show (Dallas, August 1990). [6] J. Lim. Two-Dimensional Signal and Image Processing. fl f2 f3 
 Prentice Hall, Englewood Cliffs, New Jersey, 1990. taP# 0 9213 10 00 [7] B. D. Lucas and T. Kanade. 
An iterative image registration 0.6383 0.5806 1 :0:0601 technique with an application to stereo vision. 
In Proc. Seventh IJCAI, pages 674-679, Vancouver, 198 1. i 0.1148 0.0176 0.0480 0.3964 0.1660 0.3020 
4 0.0094 0.0008 0.0028 [8] M. Shadlen, T. Camey, and E. Switkes. Illusory rotation, G2 basis filter filter 
m z filter ii I expansion, and contraction from transitions in local symmetry. 2a fl f2 Investigative 
Opthalmology and Visual Science Supplement, G2b page 300,1987. (ARVO 1987). G2c El fl 1 [9] R. G. Shoup. 
Color table animation. In J. C. Beatty and K. S. Booth, editors, Tutorial: ComputerGraphics,pages214-219. 
Table 2: 9-tap filters for z-y separable basis set for G2. Filters fl IEEE Computer Society, Silver Spring, 
MD, 1982. and i 2 have even symmetry; f3 has odd symmetry. (The filter tap indices range from -4 to 4. 
For the even symmetric filters, tap[i] = [lo] K. Sims. Particle animation and rendering using data parallel 
tap[-i]; for the odd symmetric filter, tap[i] = -tap[-i]). These filters computation. In SIGGRAPH-90, 
Dallas, 1990. were taken from Table 1, with a sample spacing of 0.67. Use the k(0) interpolation functions 
of Table 1. [l l] A. R. Smith. Paint. In J. C. Beatty and K. S. Booth, editors, Tutorial: Computer Graphics, 
pages 501-515. IEEE Computer Society, Silver Spring, MD, 1982. : SIGGRAPH 91 Las Vegas, 28 July-2 August 
1991 (4 (cl Figure 5: Single frames from several applications of motion without movement. (a) Air traffic 
controller display: the motion illusion is used to display airplane velocities, while maintaining the 
proper positions of the airplane symbols. (b) Display of instantaneous velocities of a physical simulation. 
(c) Computer art piece entitled Nude Descending a Staircase [S], after Duchamp. 1 H2n = 0.9780(-2.254z+~~)e--(~ 
+~ ) 1 Hz6 = z 20.9780(-.7515+~2)(Y)e-(z+ ) H2c = = 0.9780(-.7515+y2)(+-(52+y2) . 0.9780(-2.254y+y3)e--(z2+yz)1 
 Table 3: HZ basis set: z-y separable basis set and interpola- tion functions for fit to Hilbert transform 
of second derivative of Gaussian. To synthesize a filter oriented along direction 8, use: H, = ~a(~)&#38; 
+ kb(@)H2b + kc(e)Hzc + kd(o)Hzd. G2a Gx G2c tap # fl 00 f7! 10 f3 00 f4 0'1349 H2a &#38;b H2b H2e 1 
-0.7551 0.6383 0.4277 10: 1889 Figure 6: X-Y separable basis filters for Ga, listed in Tables 1 and 2, 
: -0.09980.0618 0.16600.0176 0.22250.0354 0.16950.0566 and Hz,listed in Tables 3 and 4. 4 0.0098 0.0008 
0.0020 0.0048 1 Hz basis filter filter m z filter m y H2a fl f2 H?h_. f4 f3 H2e f-3 f4 f&#38;i f2 fl 
Table 4: 9-tap filters for z-y separable basis set for Hz. Filters for which tap 0 is 0.0 have odd symmetry 
about tap 0; the others have even symmetry. These filters were taken from Table 3, with a sample spacing 
of 0.67. Use the interpolation functions of Table 3.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122722</article_id>
		<sort_key>31</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Coping with friction for non-penetrating rigid body simulation]]></title>
		<page_from>31</page_from>
		<page_to>41</page_to>
		<doi_number>10.1145/122718.122722</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122722</url>
		<abstract>
			<par><![CDATA[Algorithms and computational complexity measures for simulating the motion of contacting bodies with friction are presented. The bodies are restricted to be perfectly rigid bodies that contact at finitely many points. Contact forces between bodies must satisfy the Coulomb model of friction. A traditional principle of mechanics is that contact forces are impulsive if and only if non-impulsive contact forces are insufficient to maintain the non-penetration constraints between bodies. When friction is allowed, it is known that impulsive contact forces can be necessary even in the absence of collisions between bodies. This paper shows that computing contact forces according to this traditional principle is likely to require exponential time. An analysis of this result reveals that the principle for when impulses can occur is too restrictive, and a natural reformulation of the principle is proposed. Using the reformulated principle, an algorithm with expected polynomial time behaviour for computing contact forces is presented.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[NP-complete]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[friction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>F.1.3</cat_node>
				<descriptor>Reducibility and completeness</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003777.10003779</concept_id>
				<concept_desc>CCS->Theory of computation->Computational complexity and cryptography->Problems, reductions and completeness</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39038146</person_id>
				<author_profile_id><![CDATA[81100334025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baraff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., "Analytical methods for dynamic simulation of non-penetrating rigid bodies," Computer Graphics (Proc. SIGGRAPH), vol. 23, pp. 223-232, 1989.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baraff, D., "Curved surfaces and coherence for nonpenetrating rigid body simulation," Computer Graphics (Proc. SIGGRAPH), vol. 24, pp. 19-28, 1990.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barzel, R. and Barr, A.H., "A modeling system based on dynamic constraints," Computer Graphics (Proc. SIG- GRAPH), vol. 22, pp. 179- 188, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cottle, R.W., "On a problem in linear inequalities," Journal of the London Mathematical Society, vol. 43, pp. 378-384, 1968.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Erdmann, M.A., On Motion Planning with Uncertainty, M.S. Thesis, Massachusetts Institute of Technology, 1984.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>576516</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Featherstone, R., Robot Dynamics Algorithms, Kluwer, Boston, 1987.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>578533</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Garey, M.R. and Johnson, D.S., Computers and Intractability, Freeman, New York, 1979.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>866403</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Goyal, S., "Second order kinematic constraint between two bodies rolling, twisting and slipping against each other while maintaining point contact," Technical Report TR 89-1043, Department of Computer Science, Cornell University, 1989.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kilmister, W. and Reeve, J.E., Rational Mechanics, Longman's, London, 1966.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lrtstedt, P., "Coulomb friction in two-dimensional rigid body systems," Zeitschrift fiir Angewandte Mathematik un Mechanik, vol. 6 1, pp. 605-615,198 i.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[L6tstedt, P., "Numerical simulation of time-dependent contact friction problems in rigid body mechanics," SIAM Journal of Scientific Statistical Computing, vol. 5, no. 2, pp. 370- 393, 1984.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lemke, C.E., "Bimatrix equilibrium points and mathematical programming," Management Science, vol. 11, pp. 681- 689, 1965.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mason, M.T. and Wang, Y., "On the inconsistency of rigidbody frictional planar mechanics," IEEE International Conference on Robotics and Automation, 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Murty, K.G., Linear Complementarity, Linear and Nonlinear Programming, Heldermann Verlag, Berlin, 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>866487</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Vavasis, S.A., "Quadratic Programming is in NP," Technical Report TR 90-1099, Department of Computer Science, Cornell University, 1990.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Wang, Y. and Mason, M.T., "Two dimensional rigid body collisions with friction," Journal of Applied Mechanics, (to appear).]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Coping with Friction for Non-penetrating Rigid Body Simulation David Baraff Program of Computer Graphics 
 Cornell Ithaca, Abstract Algorithms and computational complexity measures for simulating the motion 
of contacting bodies with friction are presented. The bodies are restricted to be perfectly rigid bodies 
that contact at finitely many points. Contact forces between bodies must satisfy the Coulomb model of 
friction. A traditional principle of mechanics is that contact forces are impulsive if and only if non-impulsive 
contact forces are insufficient to maintain the non-penetration constraints between bodies. When friction 
is allowed, it is known that impulsive contact forces can be neces­sary even in the absence of collisions 
between bodies. This paper shows that computing contact forces according to this traditional principle 
is likely to require exponential time. An analysis of this result reveals that the principle for when 
impulses can occur is too restrictive, and a natural reformulation of the principle is pro­posed. Using 
the reformulated principle, an algorithm with expected polynomial time behavior for computing contact 
forces is presented. Categories and Subject Descriptors: 1.3.5 [Computer Graphics]: Computational Geometry 
and Object Modeling; 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Additional Key 
Words and Phrases: dynamics, friction, simula­tion, NP-complete 1. Introduction The synthesis of realistic 
motion is one of tbe goals of computer grdpbics. Recently, much attention has been given to physically 
based simulation methods, and in particular, rigid body simulation. To achieve realism, simulations must 
incorporate the effects of friction between contacting bodies, If the total number of contact points 
is small, for instance one to four, the effects of friction are easily computed. However, as the number 
of contact points grows, the problem becomes considerably more challeng­ing. Simulation algorithms with 
exponential (in the number of contact points) running times are known[5] but are impractical for problems 
involving m few as [0 to 15 contact points. In order to make rigid body simulations with friction practical 
for computer graphics, efficient, polynomial time algorithms are needed. This paper considers the problems 
of computing friction forces for configurations of perfectly rigid bodies with a finite number of contact 
points. For polyhedral bodies, only the vertices of the line segment and polygonal contact regions are 
considered m contact points. LJnless otherwise stated, it is assumed that Permission10copywithoutfeeallor 
partofthismaterialisgranted provided that the copies arc not made or distributed fnr direc( commercial 
advimtzge, the ACM copyright notice and the title of the publication and its date appear, and notice 
is given that copying is by permission of [he Associating for Computing Machinery. To copy otherwise. 
or [n republish, requires a fee and/or i~cific pcnnwsion. ~ 1991 ACM-11-X9791-436-X/91/0t)7/(M)3t $00 
7s University NY 14853 bodies are not colliding at any contact point. No restriction is placed on tbe 
allowable sliding motion between bodies at contact points. Forces at contact points are classified as 
either normal or fric[ion forces. Normal forces prevent inter-penetration by acting perpendicularly to 
the contac! surfaces. Friclion forces act tangentially to the contact surfaces and oppose slipping motion. 
The friction force at a contact point is called dynamic friction if the two bodies are slipping at the 
contact point; otherwise, the friction force is called static friction. mal and friction forces) must 
satisfy tion. The Coulomb model of friction relationship between the normal and point. The contact forces 
(the nor­the Coulomb model of fric­is a well accepted empirical friction force at a contact An important 
first step to coping with tbe problems of fric­tion is understanding the simulation behavior specified 
by the Coulomb model of friction. We need to know botb what kind of result the model specifies and the 
degree of difficulty in comput­ing that result. When computing contact forces, a principle of rational 
mechanics called the princip/e ofcorrsrrainrs [9] is usually accepted. The print iple of constraints 
states that constraints should be satisfied by non-impulsive forces if possible; otherwise, impulsive 
forces should be used to satisfy constraints. (Impulsive forces, or impulses, have the units of mass 
times velocity and discontinuously change velocities; impulses most commonly arise when bodies collide. 
Non-impulsive forces, or just forces, have the units of mass times acceleration and cannot produce velocity 
discontinuities. ) The first result of this paper is a proof that com­puting friction forces according 
to the principle of constraints is likely to require exponential time (section 5). Under the Coulomb 
friction model, even in the absence of collisions it is sometimes necessary to introduce impulses between 
contacting bodies to prevent inter-penetration. Adopting the principle of constraints requires that a 
particular behavior, non-impulsive contact forces, be searched for among possibly exponentially many 
other choices, whenever possible. In formal terms, we will prove that deciding if non-impulsive contact 
forces are sufficient to prevent inter­penetration is NP-complete. Essentially, this means that an efficient 
(that is, polynomial time) algorithm for computing con­tact forces is widely believed not to exist. (See 
Garey and John­son[7] for a discussion on F , NP, NF -complete and NP-hard problems). However, the preference 
for non-impulsive bebavior is nei­ther necessary nor justified. Using insights from the NP­completeness 
results of section 5, section 6 presents a physical model for contact that argues against the principle 
of constraints. We will use this model to reformulate the problem of computing contact forces. Using 
the reformulated problem, we present an efficient algorithmic simulation method for dealing with dynamic 
friction. The algorithm bas an expected running time that is poly­nomial in the number of contact points 
of the configuration. This is the tirst efficient algorithm we know of for computing dynamic friction 
forces. As a first step towards dealing with both static and dynamic friction, we present two preliminary 
approaches for com­puting static and dynamic friction forces (section 8). The first approach approximates 
both static and dynamic friction by using the general algorithm for dynamic friction. The second approach 
uses an iterative technique to compute static and dynamic friction forces; however, convergence is not 
guaranteed. 2. Definitions For configurations without friction, a valid set of contact forces is a set 
of normal forces satisfying three conditions. First, the normal force at each contact point must be oriented 
to push the bodies apart. Second, the normal forces must be sufficient to prevent inter-penetration between 
bodies. Third, if two bodies are separating at a contact point, the normal force at the contact point 
must be zero. For configurations without friction, a valid set of contact forces exists for any configuration 
of bodies. Although a valid set of contact forces is not necessarily unique for frictionless configurations, 
all valid contact forces yield the same accelera­tions of the bodies in the configuration[4]. Contact 
forces for fric­tionless configurations with n contact points can be found by for­mulating and solving 
a convex quadratic program (QP) of n vari­ables. Methods for formulating this QP for bodies composed 
of polyhedra and curved surfaces have been presented in [1,2,6, 11]. Convex QP s with n variables can 
be solved in time polynomial to n and in practice are solved by algorithms whose worst case behavior 
is exponential but whose expected running time is poly­nomial 14]. Configurations with friction are more 
complicated. Con­tact forces with friction are valid if they satisfy both the previous three conditions 
for normal forces and the Coulomb friction model (sections 4 and 8). Valid contact forces for configurations 
with just dynamic friction (and no static friction) can be found, as in the frictionless case, by computing 
the solution to a QP. Unlike the frictionless case though, the QP associated with a configuration involving 
dynamic friction is not necessarily con­vex. The existence of a practical solution method for non-convex 
QP s is considered unlikely, because solving non-convex QP s is NP-hard. Additionally, it is possible 
that the QP for a configuration with dynamic friction may not even have a solution. Although the Coulomb 
friction model is well accepted, it has been known for at least a century that configurations of rigid 
bedies with dynamic friction exist that have no valid set of contact forces. We call such a configuration 
inconsistent. Conversely, there are also configurations with dynamic friction where neither the set of 
valid contact forces nor the accelerations resulting from those contact forces are unique. Such a configuration 
is called indererminute. (See sections 4.1 and 4.2). 3. Previous Work Wang and Mason[ 16] present a 
detailed discussion on sin­gle contact point collisions involving friction; in particular, methods for 
computing the contact impulse resulting from the col­lision are described. (We will not consider the 
general problem of collisions involving friction in this paper). Mason and Wangi 13] discuss inconsistent 
configurations and explain how to resolve the inconsistency by applying impulsive contact forces to the 
configuration. However, it is first necessary to identify configurations as inconsistent. As we will 
show, this turns out to be a difficult problem. A paper by Lotstedt[ 11] discusses a simulation method 
that avoids inconsistence y by modification of the friction law. Lotstedt s method changes the Coulomb 
model into a relation between normal forces from the previous time step and friction forces from the 
current time step. Lotstedt s method approxi­mates both dynamic and static friction by solving a convex 
QP. It is not clear that Lotstedt s method can always be initialized so that it is numerically stable. 
It is also unclear how to perform such an initialization efficiently. 4. Contact Force Model We begin 
by considering configurations with only dynamic friction. Static friction is not considered until section 
8. This sec­tion introduces a special-case of a single contact point configuration (figure I). This configuration, 
and minor variations of it, will be used several times throughout this paper. [n figure 1, body A is 
a thin rod of length two with a sym­metric mass distribution that contacts body B at a single contact 
point. Body B (the base ) is fixed. - Variables P contact point P contact point velocity ; m a ~ unit 
surface A s mass A s angular gravitational normal ; I velocity v acceleration unit surface A s moment 
coefficient of friction tangent of inertia Relations 1.: 0= 72° 16(cos2El ~cos&#38;inO) = 2 . n P I 
~; B Pa Figure 1. A one contact point configuration with dynamic fric­tion between a thin rod A and 
a fixed base B. By choosing A s angular velocity ~ and the magnitude g of the gravity force rr?,q; acting 
on A, an indeterminate and an incon­sistent configuration can be produced. This particular example can 
be found in a number of papers; for example, Lotstedt[ 10J, Erdmann[5], or Mason and Wang[ 13]. For a 
given value of 6, the linear velocity of A is chosen such that the point p,, on A has a non-zero velocity 
tangent to B, and zero velocity normal [o B. The unit vector ; is normal to the surface of B. The unit 
vector i is tangent to the surface of B, and is directed opposite to the motion of the point p{,; ; and 
i are per­pendicular. The particular values of 1, 9 and y (p =%) given in figure I are somewhat arbitrary; 
these values are chosen to sim­plify later computations. The Coulomb model of friction states that since 
pa is slid­ing across B, a friction force in the direction i acts on A. (An equal and opposite friction 
force acts on B, but B is fixed.) If the normal force acting on A has magnitude ~, then the Coulomb fric­tion 
model states that the friction force has a magnitude of p~ (figure 2). The net contact force acting on 
A is f; +pfl =f(i +Jl;). (1) (a)f=O (b)~=m Figure 2. Normal and friction forces acting on A, What effect 
do the contact and external force -nrg~ have on A ? In appendix A, the component of acceleration of the 
point p,,, normal to B, is found to be ,, fi.~O= -+(l~l:sin~-g). (2) m This configuration has the odd 
property that as the normal force magnitude ,f is increased, the point p. is accelerated more strongly 
to~,urds B! Geometrically, the direction of the net con­tact force f(; + p;) does not change as ,f is 
increased. However, as f is increased, the torque due to friction causes pa to angularly accelerate downward. 
The normal force fln also causes the center of mass of A, and thus p<,, to accelerate upwards, but not 
fmt enough to overcome tbe downwards acceleration due to the torque. The net result is that increasing 
,f decreases the value of ~ j,,. (See appendix A for details). 4.1 An Indeterminate Configuration To 
produce an indeterminate configuration, let ~ and g satisfy I~ [ sin61 ,< = 1, Then equation (2) becomes 
f i.j<, = +l. (3) m Recall that valid contact forces satisfy three conditions. Tbe tirst condition, 
that the normal force push bodies apart is simply ,f > (). The second condition. that contact forces 
prevent inter­penetration, requires the acceleration of ~,, in the ; direction to be non-negative. This 
yields the constraint n j,, 2 f). Tbe last condi­tion is tha! if the bodies are separating, the normal 
force must be zero. Since the bodies are separating if and only if; .j. is strictly positive, this condition 
may be written as ~fi j<, = O. For [~ [~sinEl-,< = I and using equation (2). the above three condi­tions 
are ,f>(), - f +l>oandf (-~+1)= f). (4)rrl m The valid contact forces are given by the solution of equation 
(4): f= Oandf=m. For the f = O solution, ; j<, = 1. [n this solution, the cen­tripetal acceleration of 
j<, is stronger than the force of gravity pul­ling A down: thus, A merely continues its rotation and 
the point p. moves off of B (figure 3a). In the second solution. ~ = m and; j,, =0, A normal force of 
m; and a friction force of @ act on A. The torque generated by friction balances the centripetal acceleration 
of p,,; as a result, A and B do not break contact (tigure 3b). Note that the mr/y valid values of ~ are 
,f =O or ,f= m. Since the solutions produce dif­ferent accelerations for A. the configuration is indeterminate. 
P<l B 1. mn Figure 3. (a) The contact force between A and B is zero. p. ro­tates to the left and up, 
breaking contact with B. (b) The nor­mal and friction forces balance gravity and centripetal ac­celeration; 
p. moves horizontally and maintains contact with B.  4.2 An Inconsistent Configuration Now suppose that 
I~ I = O and A s linear velocity T is opposite ? (figure 4). Then the condition ~ .fi,, >0 is (5) However, 
if g> O (figure 4a), then no positive value off can prevent p. from accelerating downwards and thus inter­penetrating; 
that is, equation (5) cannot be satisfied by any ~ >0. This means that the configuration is inconsistent. 
The existence of such a configuration may seem counter-intuitive: however, we will have more to say on 
this phenomenon in section 6.1. Note that the value of g is crucial. If g = O, so that no exter­nal force 
acts on A, then f= O becomes the (unique) valid contact force (figure 4b). Any positive value off for 
this configuration causes inter-penetration. Figure 4b corresponds to p,, skimming horizontally over 
B, with neither a normal force nor a friction force exerted on A. If g becomes even slightly positive 
however, the configuration is inconsistent. Note that the requirement that B be fixed is not crucial. 
If B is massive compared to A. then incon­sistency occurs if an external force acts on A toaccelerate 
it towards B, or vice versa. (a) no solution for f (b) f =() P. B  I f; Figure 4. (a) An inconsistent 
configuration. For any f > f), p. is accelerated downwards into B. (b) The configuration has a unique 
solution of f= O when gravity is removed; A skims along the surface of B. 5. An AW-cornplete Class of 
Configurations We define the frictional consistency problem as the prob­lem of deciding if a given configuration 
is consistent. In this sec­tion, we prove that the frictional consistency problem is NP ­complete. We 
begin by showing that the frictional consistency problem lies in NP and then show that the frictional 
consistency problem is NP-hard. Although the configurations constructed in this section seem contrived 
(and arguably are), the NP-hardness result has grave implications even when inconsistency is not a concern 
during simulation. Definition. An instance of the frictional consistency problem is a configuration C 
of bodies that contact at n distinct contact points. The physical properties of each body (mass, momen~ 
of inertia, linear and angular velocity, position and orientation, and external forces) are described 
by rational numbers. The specfics of a con­tact point (position, coejjicient of friction, su~ace normal) 
are also described by rational numbers. The relative motion between bodies at contact points with friction 
is non-zero in the direction tangent to the contact sutface and zero in the direction normal to the contact 
surjace. The nota{ion ICI = k means that configuration C is describable ink bits. Cleariy k > n. Theorem 
1. The frictional consistency problem lies in NP. Proof. Given an instance of C, a QP of size n with 
the followin 3 two properties exists. ( 1) If C is consistent, then an n-vector x that is a solution 
to the QP exists. The set of contact forces such that the magnitude of the normal force at the ith contact 
point is x, is a valid set of contact forces for the configuration C. (2) Other­wise, if C is inconsistent, 
the QP has no solution. The specifics of constructing the QP can be found in [6]. The numerical quantities 
in the QP are computed from the rational entries of C in a total of O(n 3) arithmetical operations. The 
QP can therefore be con­structed in time polynomial to k. Vavasis[ 15] has recently shown that quadratic 
programming lies in NP. It follows from this that deciding frictional consistency is also in NP. In order 
to show that deciding frictional consistency is NP-hard, we reduce the NP-complete problem subset sum 
to the frictional consistency problem. Definition. An instance of the subset sum problem is a pair (A,S) 
where A= {al, .. ,~ ] is a set of positive integers and S is a single positive integer, A subset sum 
instance (A, S) is satisfiable 1~there exists a subset A c A such that ~a=S. (6) aGA Deciding l~an instance 
of the subset sum problem is satisjiab[e is an NP-complete problem[7]. To show that deciding frictional 
consistency is NP-hard we take an arbitrary instance (A ,S) of the subset sum problem and construct (in 
polynomial time) a configuration of bodies C. The configuration C will have the property that C is consistent 
if and only if (A, S) is satisfiable. Theorem 2. Deciding frictional consistency is NP -hard. Proof. 
Consider the configuration of figure 5. Body B of figure 5 is initially at rest and is positioned by 
four fixed triangular wedges that contact Et without friction. Body B is therefore free to move horizontally, 
but can neither rotate nor move vertically. On either side of body B are thin rods E, and E2. E, and 
E2 have no angu­lar velocity and have a linear velocity as indicated. E, and E2 contact B in the same 
manner as the configuration of figure 4 (although the frames of reference for E, and E2 are rotated by 
90° with respect to figure 4). In figure 4, inconsistency occurred if external forces accelerated A towards 
B or vice versa. The same holds true for figure 5. If B has an acceleration leftwards Figure 5. B is 
constrained by the fixed wedges and can only move horizontally. However, the configuration is consistent 
only if B is not subject to a net horizontal force. (towards E,), then inconsistency occurs. Likewise, 
if B has an acceleration nghtwards (towards E ~), then inconsistency also occurs. Thus, the configuration 
of figure 5 is consistent only if the net horizontal acceleration of B is zero. In this case, the rods 
E, and E2 skim along the surface of B as in figure 4b. Now consider figure 6, where a collection of thin 
rods RI, ...,R. have been added. In addition, an external horizontal force with magnitude ~ acts on B, 
trying to accelerate B to the right. Each rod Ri has mass m,. The configuration between each rod /ti 
and B is the same as the configuration of figure 3; thus each rod R, has angular velocity ~ and is subject 
to an external gravity force. Let f be the magnitude of the normal force between R, and B. As in figure 
3, the only valid solutions for ~ are ~ = O and fi = m,. If j = O, then no friction force acts between 
Ri and B. Otherwise, fi = mi and a friction force of magnitude ~, acts between R, and B. The friction 
force pushes R, to the right and B to the left, with magnitude pn,. The friction force on B therefore 
acts to oppose the external force of magnitude ~. I R,R, Rw,. - l Lf d El w v E2 - Pf I -Pf2 - Pfn T 
? J B a L 7 -)) Figure 6. The configuration is consistent if and only if the fric­tion forces on B 
sum to P.S. In order for the configuration of figure 6 to be consistent, B must have no net horizontal 
acceleration. This means that the friction forces exerted on B from the n rods must sum to p.S, balancing 
the external force applied to B. Thus, the configuration is consistent if and only if (7) ,Zl Since 
each ~ is either O or m,, the configuration is consistent if and only if some subset of {m,, . . . .mn} 
sums to S. We can now perform the reduction from subset sum to show NP-hardness. Given any set A ={a,, 
....a ] and any tar­get sum S, construct the configuration of figure 6. Assign mi = a, for 1< i <n, and 
let an external horizontal force of@ act on B as shown in figure 6. By the above dkeussion, the configuration 
is consistent if and only if there exists a subset of [m,, ....mfl] that sums to S. But since A ={m,, 
....mn), the configuration is consistent if and only if (A, S) is satisfiable. We conclude that the problem 
of deciding frictional consistency is NP-hard. Theorem 3. Deciding frictional consistency is NP -complete, 
 Proof. The result follows immediately from Theorem I and Theorem 2. Corollary 1. Computing contact 
forces ([~ they e.rist) for a crmjiguration is NP -hard. Proof. Since deciding if a set of contact forces 
exists is an NP­complete problem, computing the contact forces (if they exist) is an NP-hard problem. 
 5.1 Implications At this point, il may seem that the above results, while pos­sibly of some (marginal) 
theoretical interest, have no bearing on any practical problem. Certainly, the above configurations were 
carefully constructed to produce configurations whose consistency was difficult to determine. But how 
likely is it that a configuration this carefully constructed could occur during simu­lation? For that 
matter, suppose the occurrence of any incon­sistent configuration is so unlikely that the possibility 
can be com­pletely disregarded. (This may be a reasonable assumption. We have not encountered an inconsistent 
configuration during simula­tion when v < 1.) Can a polynomial time algorithm that com­putes contact 
forces only for consistent configurations be con­structed? The answer to this is no, unless it turns 
out that P and NP are equivalent, and it is widely believed that they are not. Corollary 2. A polynomial 
time a[gorirhrn jiw computing va[id conruct forces ,f[w consisten[ corrjigurafions e.risrs ]~ and only 
]~ P = NP. Proof. Suppose that P = NP. Since quadratic programming lies in NP, P =NP implies a polynomial 
time algorithm for finding the solution to a QP. Since valid contact forces for a consistent configuration 
of bodies can be found by solving an associated QP, valid contact forces are computable in polynomial 
time if P = NP. Conversely, suppose that contact forces for consistent configurations can be computed 
in polynomial time. Then there exists a machine M and a polynomial p with the following behavior. Whenever 
M is given a consistent configuration C as input, M outputs a valid set of contact forces within time 
p( IC I). M s behavior when C is inconsistent is undefined. Given any configuration C, not necessarily 
consistent, M can be used to decide consistency in polynomial time as follows. Let C be input to M and 
run for p( IC I) time. If M fails to output within this time, then C is inconsistent. Otherwise, M has 
produced some output. Since deciding frictional consistency is in NP, the validity of M s output can 
be decided in an additional amount of time that is also a polynomial function of IC 1. If M s output 
is a valid set of contact forces, then clearly C is consistent. If M s output is invalid, then C must 
be inconsistent (else M would have output a valid answer). In any event, the consistency of C has been 
decided in polynomial time, Since deciding consistency is NP-complete, we conclude that the existence 
of a polynomial time algorithm for computing contact forces on consistent configurations would imply 
that P= NP.a Given the above conclusions, it is unlikely that an efficient algorithm for computing contact 
forces can be found. This depressing result can be viewed in several ways. First, the simu­lation of 
rigid bodies with friction can be considered an intract­able problem, unless the number of contact points 
with friction in a configuration is small. Second, the general simulation problem can be rejected as 
being too difficult a problem, although we might hope to tind some natural class of configurations with 
fric­tion for which contact forces can be computed efficiently. Such a class would have to be sufficiently 
general to cover situations  Computer Graphics, Volume 25, Number 4, July 1991 likely to be encountered 
in practice. Third, heuristic methods for computing contact forces can be considered. However, this is 
essentially the same as hoping to find a natural class of configurations with easily computed contact 
forces. Rather than adopt any of these viewpoints, the next section presents a physical model of inconsistency 
that leads to a natural reformulation of the problem of computing contact forces. 6. Physical Models 
In this section, a physical model for both inconsistency and indeterminacy is presented, Certainly, other 
models are possible, and a different choice of model might lead to different conclu­sions and results, 
The model in this section was develo~d in order to understand the behavior of inconsistent and indeterminate 
configurations. After the model was developed, we found that the model leads to a natural refutation 
of the principle of constraints. By abandoning this principle, the problem of computing contact forces 
is naturally reformulated and a correspondingly efficient way of computing contact forces is found. The 
model in this sec­tion is not an ad hoc attempt at dealing with friction, We feel that the model is not 
unreasonably based on the physical proper­ties of rigid bodies, and sensible in the context of simulating 
rigid bodies with friction. The model and subsequent reformulation of the problem is presented in this 
section. In the next section, a computational algorithm is presented for solving the reformulated problem. 
The motivation of a physical model stems from the need to answer the following basic question: what should 
be the result of a simulation when inconsistency is encountered? For inconsistent configurations, such 
as figure 4a, the only resolution is the intro­duction of an impulsive contact force at pa [9, 13]. Impulses, 
how­ever, arise from collisions between bodies. Given the fact that p. has no velocity normal to B (so 
that A and B do not appear to be colliding), why should an impulse be applied between A and B? We answer 
this by presenting our physical model of incon­sistency. The physical model we present is based on questioning 
the rigid body assumption. In the physical world, there is of course no such thing as a perfectly rigid 
body. For near rigid bodies, contact forces arise as a result of small elastic deformations in the neighborhcmd 
of the contact area. Rather than geometrically model deformations, we shall (conceptually) allow bodies 
to inter-penetrate slightly, and consider a deformation in the contact surfaces proportional to the amount 
of inter-penetration. (We do not of course imagine that real bodies actually inter-penetrate), As the 
inter-penetration depth increases, a restoring normal force acts to oppose the inter-penetration. This 
is the so called penalty method , a simulation method that models contact between bodies as spring and 
damper systems. The normal force between two bodies is zero when the amount of inter-penetration is zero, 
and increases monotonically as the inter-penetration increases. Typi­cally, the normal force is modeled 
as a linear spring force -Kd, where K is the spring constant and d is the amount of inter­penetration. 
Although this is a very useful conceptual model, it is not well suited to simulation of very rigid bodies[ 
1,3]. We will use the penalty method to conceptually model inconsistency and indeterminacy, but we will 
not use the penalty method as a simu­lation technique. 6.1 A Model of Inconsistency Figure 7 shows the 
behavior of the inconsistent configuration of 4a when the penalty method is applied. At time ro, consider 
the tip of the rod, pa, to be resting exactly on B, with zero inter-penetration. Since there is no inter-penetration, 
the nor­mal force is zero, Even though p<, is sliding along B, the friction Time to: Time to+At : Time 
r(,: Time to+AI : zero inter-penetration d, inter-penetration zero inter-penetration L A m<qi . .. n 
P Figure 7. At time 10, only gravity acts on A. At time t{, + Ar, the inter-penetration distance is 
d, and both a penalty and a grav­ity force act on A, causing p. s downwards acceleration to in­crease. 
force is zero since the normal force is zero. Since the only force acting on A is the external gravity 
force m<q~, PO accelerates downwards. At time r(l + Ar, p. has inter-penetrated B by an amount d,, so 
a normal force Kd,; acts on A. Since p. is still sliding, a friction force of VKd, ? also acts on A. 
The net result, from equation (2), is that this causes p,, to accelerate downwards even faster than before. 
As the penalty force continues to increase, it causes more inter-penetration between A and B; a form 
of positive feedback. Accordingly, both the friction and the nor­mal force increase, and the cycle continues. 
Since we are trying to model A and B as rigid bodies, tbe spring constant K must be allowed to be arbitrarily 
large. (It is this feature that makes the penalty method ill-suited to rigid body simulation). The larger 
K is, the faster inter-penetration increases and the faster the normal and friction forces build. Recall 
that the friction force opposes the sliding motion of A across B. By making K arbitrarily large, the 
friction force brings p,, to rest (horizontally) in an arbitrarily short time. Now, suppose K is adjusted 
so that pa comes to rest within time A/. Then the amount of inter-penetration is O (At2 ), since the 
vertical distance traveled by p<, depends quadratically on the time for which it travels. In the limit 
as K goes to infinity, the contact force on A acts as an impulse and instantaneously brings p,, to rest 
horizontal y, without inter-penetration occurring. This impulse also causes p. to acquire a normal velocity 
towards B, bringing them into colliding contact. The (second) impulse resulting from this colliding contact 
can be computed according to [ 16]. Once p. is at rest horizontally, dynamic friction is replaced by 
static friction. The Coulomb friction model states that the magnitude ~$,ti,,, of static friction satisfies 
~,,.,,( < ~~ whereas ~d,,,.n,,, = Uf for dynamic friction. (Actually, p is typically larger for static 
friction than dynamic friction, but this has no bearing on the model being developed.) Because static 
friction is less con­strained than dynamic friction, once static friction occurs, a valid solution exists 
and the inconsistency is removed. 6.2 A Model of Indeterminacy Consider the indeterminate configuration 
of figure 3, which has solutions ~= O and ~ = m. Using the penalty method, the indeterminacy can be removed 
by assuming some amount of ini­tial inter-penetration between A and B. If the initial inter­penetration 
between A and B is zero (figure 8) then no normal P<! B B Figure 8. The initial inter-penetration is 
zero and only gravity acts on A. The centripetal acceleration of A pulls p. away from B and contact is 
broken. force exists, and contact is immediately broken (due to the cen­tripetal acceleration of pa away 
from f?). The behavior is the same as in figure 3a. However, if tbe initial inter-penetration pro­duces 
a normal force magnitude of m, then the normal and friction forces prevent A from breaking contact with 
B. In figure 9, let the initial inter-penetration d, be ~. Time t{): Time to +At : d, inter-penetration 
d2 z d, inter-penetration -.. B i p,, =0 B n.po=O i / Kd , (;+p; ) Kd2(;+y;) Figure 9. The initial 
inter-penetration is d,. Both gravity and a penalty force act on A. A slides and falls without breaking 
contact with B. Then tbe normal force magnitude at time/0 is m. Since p. is slid­ing on B, a friction 
force acts on A as shown. As A falls, main­taining contact with B, the inter-penetration varies smoothly, 
pro­duce a varying normal force. At time /0 + At, A still inter­penetrates B by an amount d, Ed2, and 
the behavior of the conftgumtion is that of figure 3b. Thus, the initial amount of inter-penetration 
determines which behavior occurs. The simulation method of computing and applying contact forces and 
impulses to bodies does not model inter-penetration. Instead of determining behavior by initial choice 
of inter­penetration, we can consider an initial normal force between bodies at contact points, and use 
that to determine subsequent behavior. For the applications we are interested in, we generally have no 
basis for preferring one set of initial normal forces over another. The numerical routines used for solving 
the contact force equations arbitrarily determine the behavior simulated. This may or may not be sensible 
for other applications. 6.3 The Principle of Constraints The principle of corrstmints, applied to configurations 
with friciion. states the following: when computing forces for a configuration of bodies, impulsive forces 
should be used only if non-impulsive forces do not exist for the contigur-mien. In other words. if a 
configuration is consistent, non-impulsive forces should be computed and applied to the configuration: 
otherwise impulsive forces must be introduced into the system. Initially, this seems like a sensible 
principle, but we know of no real justiticatiorr for it. If the physical model presented in this section 
is adopted, then this principle must be abandoned (at least in the context of rigid body simulation ). 
Consider tigure 1(). Once again, the combination of gravity and the angular velocity of R, is the same 
as in figures 5 and 6. Similarly, a horizontal acceleration of B results in inconsistency. F@re 10. ,fl 
must be either O or m, to be valid. However, l ! =mi causes inconsistency. The only valid solution is 
/ , = (). If E, is ignored for the moment, then both ,/ 1=() and ~1 = M, ore valid solutions for j ,. 
The only valid solution for the configuration as a whole though, is ,fl =();,f, = rr7, pushes B to the 
left, causing inconsistency. However. using the physical model of indeterminacy, the value j ] assumes 
depends on the ini­tial inter-penetration between R, and B. If we adopt the physical model presented, 
we must conclude the following: even though the configuration is consistent, there is no a priori reason 
to prefer impulse-free behavior to non-impulse-free behavior for this configuration. The inconsistency 
resulting from j , = m,, and sub­sequent application of impulsive contact forces is u.$mlrptuldc u behi~],if~r 
as the application of non-impulsive contact forces resulting from j , = (). Even though the configuration 
in figure 1f) has only one valid solution of contact forces, (f, = ()), it has two possible bebaviors 
and is thus indeterminate. 6A Reformulating the Contact Force Problem Up to now, we have viewed the problem 
of computing valid contact forces as: given a contigur~tion, efficiently compute a vidid set of contact 
fbrces, (f Ihq e.yis[. This viewpoint is based on tbe principle of constraints: that is, impulsive forces 
should be applied if and only if the configuration is inconsistent. [t is this absolute imi.rfen(c on 
a non-impulsive solution, if it exists, that makes tbe problem of computing contact forces so difficult. 
How­ever, now that we have abandoned the principle of constrairrt~. a different viewpoint of tbe problem 
is possible. Wc reformulate the problem of computing contact forces as: given a corrtigumtion. efficiently 
compute cilhcr a valid set of contact f orcm (U it valid set of contact impulses. (Validity for contact 
impulses is defined in section 7). Under the physical model we h~vc assumed, there is no intrinsic reason 
to prefer valid contuct forces over valid contact impulses. By computing a particular set of valid contact 
forces or impulses, a particular behavior is chosen for the configuration, and other possible bebaviors 
ignored. This means that we do not bother to decide if a eonti.guration is consistent or not. If a valid 
set of contact impulses are computed. it will not be known if the configuration was consistent and could 
have been wived with contact forces: however, this ]s unimportant. In the next section, an efficient 
method is presented for computing valid contact forces or impulses. 7. Computing Valid Contact Forces 
and Impulses Before an efficient method for computing either contact forces or impulses can be considered. 
tbe definition of validity must be extended to cover contact impulses. We first define vali­dity for 
contact impulse~ and then present a computational algo­rithm. 7.1 Valid Contact Impulses [n the penalty 
method interpretation of figure 7. an impulse occurred because no matter bow strong tbc normal force 
became, i( ww insufficient to prevent inter-penetration. As a result, after the contact impulse was applied, 
the relatiw velocity of tbe bodiei at the contact point was directed inwards. Since contact impulse~ 
may need to be applied to configurations involving more than one contact point, validity must be defined 
for u set of contact impulses. For example, in tigure lo, if the /, = m , behavior is chosen. a contact 
impulse should occur between E, and B. How­ever. there should be no contact impulse between R, and B. 
In order for our definition of validity to be uieful. till inconsistent configurations should have a 
valid set of contact impulws. We show in section 7.2 that our dctinition of validity for contact impulses 
satisfies this requirement. We call u set of contact impulses valid under the following two conditions. 
First, the contact impulses must convert at least one of the contact points with dynamic friction to 
\tatic friction. Second, every contact point at which a contact impulse occurs must end up with a non-po~itive 
relative normal velocity: that is. after the contact impulses are applied, bodies should mJ( be separating 
wherever contact impulses occurred. The justification for this is that the contoct impulies occur only 
when the normal force grow~ without bound to oppose inter-penetration. intui­tively. valid contact impulse~ 
are the limiting rewlt of increa~ing nom~al forces without bound under the penalty method. If bodie~ 
are separating at a contact point after contact impulses are applied, then the normal force at the contact 
point should not have grown without bound into a contact impul~e. As in \ection 6.1, bodies will bc colliding 
at some contact points after valid contact impulses are applied. and a ~econdary set of impul~es will 
have to be ~pplied. These impulses may be calculated according to [16]. 7.2 Computing Contact Forces 
and Impulses with Lernke s Algorithm How can either contact forces or impulses be computed efficiently, 
given that computing contact forcm alone is hard? In section 3, it was stated that every configuration 
of n contact points bad ~nassociated quadratic programming problem oftt variables. Let a set of valid 
normal force magnitudes (if it exists) be denoted by the unknown mvector ~ : tbe magnitude of the ith 
normal force is given by ~. If/+ exists. it can be found by solving the QP ,a ­ + f ? () minimize ,/-~(A./+ 
+ /r ) subject to (8) /\A~+;2;1 + where A and IJ are determ~ned by the configuration. A i~ an nx~J inverse 
mass matrix and h isjm n-vector of known external and inertial accelerations. A/ +b represents the relative 
accelem­tiom at contact points. (See [ 1.2,6. I I j for a discussion of tbe numerical properties of A 
and method~ for c[)mputlng A). Every ~ such that equation (8) attains zero is valid. If equation (8) 
can­not attain zero subject to the above restrictions, then the configflration has no valid solution 
and is inconsistent. Thus, a valid ~ IS a solution to the equation (9) Equation (9) is what is known 
as a linear complementarily (LCP) problem. Equation (9) is called a positive semidefinite (PSD) LCP ifA 
is PSD[14]. One of [he first algorithms for solving linear complemen­tarily problems was introduced by 
Lemke[ 12] and is known as Lemke s algorithm. Lemke s algorithm is a pivoting method, similar to the 
simplex method of linear programming and has similar numerical properties. The algorithm is exponential 
in the worst case, but has an expected running time polynomial in n[ 14]. Lemke s algorithm progresses, 
like the simplex method, by trying various descent directions. If an LCP is PS D and has no solution 
then Lemke s algorithm will at some point encounter an unbounded ray; a descent direction along which 
one can travel infinitely far without making any progress. Otherwise, if a PSD LCP has a solution, then 
no unbounded ray exists for that LCP, and Lemke s algorithm terminates by finding a solution to the LCP. 
The algorithm is viewed as a practical solution method to the problem of solving PSD LCP S. However, 
for non-PSD LCP S, Lemke s algorithm is not guaranteed to terminate correctly (although it still takes 
only expected polynomial time to do so). For a non-PSD LCP, if there is no solution, Lemke s algorithm 
terminates by encountering an unbounded ray. Unfortunately, if there is a sohstion, the algorithm is 
not guaranteed to find it. For non-PSD LCP S with solutions, Lemke s algorithm terminates either by finding 
a solution or by encountering an unbounded ray. 1 As a result, Lemke s algorithm is not suitable for 
solving non-PSD LCP S. However, when Lemke s algorithm terminates by encountering an unbounded ray, it 
has found an n-vector ~ with the property[ 14] F 2 ~ and Vi such that F , >0, (AZ )i <0 (lo) where (A~)i 
is the ith component of the vector Ai . Why is this property of interest? Suppose that a set of contact 
impulses are applied to the configuration, with the magnitude of the normal impulse at the ith contact 
point denoted by Z ,. Then it can be shown[2, 6] that the relative velocity at the ith contact point 
after the impulse is (A Z )i. If the vector Z satisfies equation (10) then every contact point subject 
to a non-zero contact impulse Z , >0 ends up with a non-positive relative normal velocity (A;), s O. 
Thus, the vector ~ found by Lemke s algorithm gives rise to a valid set of contact impulses. To fully 
satisfy the definition of validity, .= must be scaled upwards from zero until it causes a contact point 
with dynamic friction to be converted to static fri­ction. After this, a real impact occurs, as described 
in section 6.1. The behavior of Lemke s algorithm exactly matches our new view of the problem of computing 
contact forces. If the configuration has no valid contact impulse solutions, Lemke s algorithm cannot 
terminate with the special vector Z and must therefore find a valid contact force solution. For inconsistent 
configurations, no valid contact force solution exists, so Lemke s algorithm must terminate with the 
vector ~, providing a contact impulse solution. For configurations with both a valid force and impulse 
solution, Lemke s algorithm will terminate by computing 1Encounteringan unboundedray when there is a 
solution is analogousto getting stuckata non-globalminimum in anon-convexminimization problem. one or 
the other. Whenever @xttke s algorithm termimtes by computing a contact impulse solution, it will still 
be unknown whether or not the configuration was consistent. For frictionless systems, the LCP is always 
PSD and has a solution, so frictionless configurations do not have valid impulse solutions. Thus, the 
reformulation of the problem does not add any new solutions to simulations of frictionless systems. Although 
Lemke s algorithm runs, practically speaking, in polynomial time, this is not a proof that finding either 
valid con­tact forces or impulses is a polynomial time problem. From a practical standpoint, though, 
Lemke s algorithm provides an efficient algorithm for computing valid contact forces or impulses. The 
computational complexity of either solving an LCP or finding an unbounded ray is unknown. 8. Approaches 
for Static Friction We conclude with two approaches to dealing with static friction. We stress that these 
approaches are only a first step towards dealing with the problems of static friction. Both approaches 
have their drawbacks, and currently have only limited applicability. The two approaches appear to produce 
(approxi­mately the same) reasonably realistic results for the configurations we have simulated. Consider 
the ith contact point of a configuration, and let the normal force magnitude there be ~. The coefficient 
of friction, p, is not indexed and may be different for each contact point. No distinction is made between 
the coefficient of static and dynamic friction, and both are assumed to be isotropic. In what follows, 
there is no difficulty in using a different value of w depending on whether the friction force is static 
or dynamic. The next few com­putations take place in the tangent plane of the contact surface at each 
contact point; vectors are expressed in this plane as pairs (.x-,y) where (1,0) and (O, 1) are orthonotmtal. 
Let ~Ii,$i) be the friction force, and (v,i,vYi) and (aXi,aY,) the relative tangential velocity and acceleration 
between bodies at the ith contact point.2 If (v.,, q,) is non-zero, then dynamic friction occurs and 
and the friction force has magnitude ~j and is anti-parallel to the vector (V.,,>vy,). Static friction 
is more compIex. For static friction, lvx,Ji)12 =L,2 +fy, ~ (vJ)*. (11) The main difficulty in static 
friction is determining when a contact points makes a transition from sticking to sliding. When the static 
friction force is sufficient to prevent sliding, any direction of the friction force constraining (ax,,ay,) 
to be zero is valid. If the body begins to slide, then (jCi,~., ) must at least partially oppose the 
acceleration; that is, tixi.L,) (ax,.aYi) ~ 0. (12) Also, if (aXi,uY,) is non-zero, then the friction 
force magnitude must attain its upper bound of ~fi. The law for static friction can be summarized as 
~,,2 +~y,z < (pJ)z , (fr,,~,,). (a,i,a,,) <0 and ((V.L)*-V=,*+f.Yiz))(a1,2 + aVi2) = O (13) where the 
last condition forces either (~fi)2 = f1,2 + fy,2 or *= 0 Unfoflunately, equation (13) is too complex 
0 b a,,2 + aY, . Ware mustbe takenhere. The relative acceleration(a,,,a,, ) is calculatedby taking tk 
firstderivativeofavelocityconstraint,nottk secondderivativeofaspatialccm­straint. See Goyal[8] for details. 
formulated as part of a quadratic program. It also does not appear practical to solve with current non-linear 
programming tech­niques. 8.1 The Dynamic Friction Approximation This approach for approximating static 
friction is extremely simple to implement. In order to determine whether static friction or dynamic friction 
should occur at a contact point. a simulator must have some threshold value e. If I(v,,, V,,)I 2 E, then 
dynamic friction occurs. Otherwise I(} ,,,v,, ) I < &#38;and static friction occurs. Since dynamic friction 
is (14) we approximate static friction as (l,,,l ,, ) (v,, , },,, )~f (f,,!f,, )= ~ M (15) l(~ ,,.~ 
,,)1 t(~ ,,.v),)l = E Thus, we really use a dynamic friction force that varies in magni­tude from zero 
to an upper limit of pj as the relative contact speed varies from O to E. This allows us to use the method 
of sec­tion 7.2 to compute both static and dynamic friction. Since static friction occurs only when the 
relative tangen­tial velocity is non-zero, bodies must acquire some small amount of crawl in order to 
maintain a static friction force. This approach is reminiscent of the penalty method, where bodies must 
acquire some degree of imer-penetration for a sufficient normal force to exist. However, in the penalty 
method, it is necessary to increase the spring constant K without bound as the mass of bodies increases. 
Our approximation method does not suffer from this problem. If E is made small enough, the crawling behavior 
of bodies is not visible, no matter what masses or forces exist. If &#38; is made excessively small, 
the differential equations of motion[ 1, 3] may become stiffi otherwise, the approach has a rea­sonable 
performance. The major advantage to this approach is that it is guaranteed to produce a result, using 
Lemke s algorithm as described in section 7.2. Thus, either a set of contact forces or impu Ises is computed. 
The major disadvantage to this approach is that it is an ad hoc approximation to the law of static friction. 
8.2 Modeling Static Friction by Quadratic Programming This approach is much more ambitious. We attempt 
to model static friction as a quadratic programming problem, which can be solved to find the contact 
forces. We approximate the static friction law as follows. Equation ( I I ) is rewritten as Unfortunate] 
y, this allows the static friction force magnitude to exceed pfi (by as much as a factor of AV), unless 
the friction force happens to be aligned with a coordinate axis of the tangent plane. One possible solution 
is to iterate several times, trying to choose a coordinate system so either f,, or f,, is zero, for each 
contact point. For two-dimensional configurations however, the friction force is constrained to a line, 
not a plane, and is described by a single variable $,,. In this case, the constraint p~ S f,, S pfi is 
exact. To satisfy equation ( 12), we add the conditions (17)A,, sgn~,l ) 20 and a,, sgnti,) ~ O where 
sgn(.~) = 1 if .1 20 and I otherwise. These conditions Computer Graphics, Volume 25, Number 4, July 
1991 ensure that (f,,, f,, ). (a,, ,u,, ) S O. The condition that static friction attains its upper bound 
when dipping begins is written (Vj -~,, sgn(f,, ))(at, sgn(f,, )) = O (18)(M -f,, sgn(f,,))(a,, sgnv,, 
)) = O. Finally, we add the standard constraint on the normal forces that ~20. u,20and~a, =() (19) where 
a, is tbe relative normal acceleration of the ith contact point. If the signs of the f,, and f,, are 
known, then the above sys­tem of equations has unknown variables f, f,,, ~,, (for each con­tact point) 
which are used to express tbe a,, a,, and a,, terms. The entire system can be solved by a quadratic program 
because the sgn functions become known. How can the signs of the f,, and f,, variables be determined? 
Iterative methods for quadratic programming and linear complementarily exist that can be adopted to this 
problem[ 14]. These iterative techniques are very similar to the Gauss-Seidel or Jacobi iterative methods 
used to solve linear systems. Iterative methods for quadratic programming are modified in a straightfor­ward 
fashion to solve tbe system of equations ( 16) thru ( 19), without initially knowing the signs of the 
f,, and f,,. Unfor­ tunately, convergence results are not available for the modified iterative methods. 
If the modified method fails to converge (or even before full convergence), the signs of f,, and f,, 
can be guessed by examining the unconverted solution. Quadratic pro­gramming is then used to solve equation 
( 16) thru ( 19) as a qua­dratic program, given the estimate of the signs of the variables. If the estimate 
is correct, a solution is obtained for the friction forces. However, the approach can break down at any 
number of places. If the method fails to converge, the estimates of the signs of the variables may not 
be correct. Even if the signs of the vari­ables are correct, the form of the linear constraints in equation 
(16) do not allow us to use Lemke s algorithm for linear com­plementarily. Although we can apply standard 
quadratic pro­gramming methods, we know of no algorithm that will solve tbe quadratic program or indicate 
contact impulses, as Lemke s algo­rithm does. With regard to the entire issue of consistency and Nf-hardness, 
this method for static friction is back to square one. It is possible that when the iterative step fails 
to converge, an analysis of the divergence of the iterates will indicate a valid set of contact impulses. 
At this time, however, we do not know how to perform such an analysis. We have found however that the 
second approach, when it works, yields a very acceptable result. For large numbers of con­tact points 
(n = 40), the second approach sometimes breaks down, while tbe tirst approach does not. We have bad reasonable 
suc­cess with the second approach for configurations with 40 contact points or less. 9. Conclusion An 
efficient algorithm for dealing with configurations of bodies with only dynamic friction has been presented. 
Instead of attempting to force a behavior that avoids contact impulses, the algorithm allows either contact 
forces or contact impulses to occur. Two preliminary approaches for dealing with static fric­tion are 
presented. The first approach is an approximation using the algorithm developed for simulating dynamic 
friction. The second approach is more exact but also more prone to failure than the first approach. Simulation 
of a complex configuration with static and dynamic friction is shown in figure 11.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122723</article_id>
		<sort_key>41</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Design and simulation of opera lighting and projection effects]]></title>
		<page_from>41</page_from>
		<page_to>50</page_to>
		<doi_number>10.1145/122718.122723</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122723</url>
		<abstract>
			<par><![CDATA[A major problem challenging opera designers is the inability to co-ordinate lighting, projection systems, and set designs in the preliminary planning phase. New computer graphics techniques, which provide the set and lighting designer the opportunity to evaluate, test, and control opera designs prior to the construction of full scale systems are presented. These techniques---light source input, simulation of directional lighting, modeling of scenic projection systems, and full three-dimensional simulation---show the potential for the use of computer graphics in theater design.The light source input component consists of a program for assigning light source attributes with a set of theater lighting icons. This module allows a designer to specify light source characteristics in a way familiar to the discipline and to make preliminary evaluations of the lighting conditions.An extended progressive radiosity method is introduced to simulate the directional lighting characteristics which are specified by the input program.A new projection approach is presented to simulate the optical effects of scenic projectors. In addition, a solution to the distortion problem produced by angular projections is described.The above components are integrated to produce full three-dimensional simulations of the global illumination effects in an opera scene.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Arts, fine and performing**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P150904</person_id>
				<author_profile_id><![CDATA[81100369597]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[O'B.]]></middle_name>
				<last_name><![CDATA[Dorsey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P84841</person_id>
				<author_profile_id><![CDATA[81100402503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fran&#231;is]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Sillion]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74367</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baum, Daniel R., Holly E. Rushmeier, and James M. Winger. "Improving Radiosity Solutions Through the Use of Analytically Determined Form-Factors," Proceedings of SIG- GRAPH'89 (Boston, Massachusetts, July 31 - August 4, 1989), in Computer Graphics, 23(3), July 1989, pages 325- 334.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bemstein, Ralph. Digital Image Processing of Earth Observation Sensor Data, IBM J. Res. Develop., 1976.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cayless, M. A. and A. M. Marsden. Lamps and Lighting, Edward Arnold, London, 1983.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael E, Shenchang Eric Chen, John R. Wallace, and Donald E Greenberg. "A Progressive Refinement Approach to Fast Radiosity Image Generation," Proceediags of SIGGRAPH'88 (Atlanta, Georgia, August 1-5, 1988), in Computer Graphics, 22(4), August 1988, pages 75-84.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael E and Donald E Greenberg. "A Radiosity Solution for Complex Environments," Proceedings of SIG- GRAPH'85 (San Francisco, California, July 22-26, 1985), in Computer Graphics, 19(3), July 1985, pages 31-40.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael E, Donald E Greenberg, David S. Immel, and Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, 6(3), March 1986, pages 26-35.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dorsey, Julie O'B. Computer Graphics for the Design and Visualization of Opera Lighting Effects, Master's thesis, Program of Computer Graphics, Comell University, Ithaca, NY 14853, January 1990.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gilette, Michael J. Designing With Light, Mayfield Publishing Company, Palo Alto, 1978.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M., Kenneth E. Torrance, Donald E Greenberg, and Bennett Battaile. "Modeling the Interaction of Light Between Diffuse Surfaces," Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984), in Computer Graphics, 18(3), July 1984, pages 213-222.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Haralick, Robert M. "Automatic Remote Sensor Image Processing," Topics in Applied Physics, 11, 1976, pages 5-63.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hartmann, Rudolf. Opera, William Morrow and Company, New York, N.Y., 1977.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul S. Fundametttals of Texture Mapping and Image Warping, Master's thesis, Department of EECS, UC Berkeley, Berkeley, CA 94720, June 1989.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kaufman, John E. IES Lighting Handbook - Application Volume, Illuminating Engineering Society of North America, New York, 1987.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Max, Nelson L. "Computer Graphics Distortion for IMAX and OMNIMAX Projection," in Proceedings of Nicograph'83, 1983,]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37437</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki, Yasuhiro Miyawaki, and Eihachiro Nakamae. "A Shading Model for Atmospheric Scattering Considering Luminous Intensity Distribution of Light Sources," Proceedings of SIGGRAPH'87 (Anaheim, California, July 27-31, 1987), in Computer Graphics, 21(4), July 1987, pages 303-310.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuld and Eihachiro Nakamae. "Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and interreflections," Proceedings of SIGGRAPH'85 (San Francisco, California, July 22-26, 1985), in Computer Graphics, 19(3), July 1985, pages 23-30.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>282938</ref_obj_id>
				<ref_obj_pid>282918</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Nishita, Tomoyuki, Isao Okamura, and Eihachiro Nakamae. "Shading Models for Point and Linear Sources," ACM Transactions on Graphics, 4(2), April 1985, pages 124-146.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Parker, W. Oren and Harvey K. Smith. Scene Design and Stage Lighting, Holt, Rinehart and Winston, Inc., New York, 1979.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Pilbrow, Richard. Stage Lighting, Von Nostrand Reinhold Company, New York, 1979.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Sellman, Hunton D. and Merrill Lessley. Essentials of Stage Lighting, Prentice-Hall, Inc, Englewood Cliffs, 1982.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert and John R. Howell. Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sillion, Frar~ois and Claude Puech. "A General Two-Pass Method Integrating Specular and Diffuse Reflection," Proceedings of SIGGRAPH'89 (Boston, Massachusetts, July 31 - August 4, 1989), in Computer Graphics, 23(3), July 1989, pages 335-344.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Verbeck, Channing E and Donald E Greenberg. "A Comprehensive Light-Source Description for Computer Graphics," IEEE Computer Graphics and Applications, 4(7), July 1984, pages 66-75.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Kells A. Elmquist, and Eric A. Haines. "A Ray Tracing Algorithm for Progressive Radiosity," Proceedings of SIGGRAPH'89 (Boston, Massachusetts, July 31 - August 4, 1989), in Computer Graphics, 23(3), July 1989, pages 315-324.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801127</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Warn, David R. "Lighting Controls for Synthetic Images," Proceedings of SIGGRAPH'83 (Detroit, Michigan, July 25- 29, 1983), in Computer Graphics, 17(3), July 1983, pages 13- 21.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Watson, Lee. Lighting Design Handbook, McGraw-Hill, New York, 1990.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Wilfred, Thomas. Projected Scenery - A Technical Manual, The Drama Book Shop, New York, 1965.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>528718</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Wolberg, George. Digital Image Warping, IEEE Computer Society Press., Los Alamitos, CA, 1990.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Design and Simulation of  Opera Lighting and 
Projection Effects Julie O B. Dorse.y Fran~ois X. Sillion Donald P. Greenberg Program of Computer Graphics 
Cornell University Ithaca, New York i 4853 Abstract A major problem challenging opera designers is 
the inability to co­ordinate lighting, projection systems, and set designs in the prelim­inary planning 
phase. New computer graphics techniques, which provide the set and lighting designer [be opportunity 
to evaluate, test, and control opera designs prior to the construction of full scale systems are presented, 
These techniques light source input. simu­lation of directional lighting, modeling of scenic projection 
systems, and full three-dimensional simulation show the potential for the use of computer graphics in 
theater design, The light source input component consists of a program for as­signing light source attributes 
with a set of theater lighting icons. This module allows a designer to specify light source characteristics 
in a way familiar to the discipline and to make preliminary evalua­tions of the lighting conditions. 
An extended progressive radiosity method is introduced to sim­ulate the directional lighting characteristics 
which are specified by the input program. A new projection approach is presented to simulate the optical 
effects of scenic projectors. In addition, a solution to the distortion problem produced by angular projections 
is described. The above components are integrated to produce full three­dimensional simulations of the 
global illumination effects in an opera scene. CR Categories and Subject Descriptors: 1.3.0 [Computer 
Graphics]: General; 1.3.7 [Computer Graphics]: Three Dimen­sional Graphics and Realism; J.2 [Computer 
Applications]: Per­forming Arts. General Terms: Algorithms Additional Keywords and Phrases: opera and 
stage design, angu­lar projection. simulation, radiosity, directional light sources, tex­ture mapping. 
 Introduction Opera stage design is an extremely difficult task as, in addition to tbe standard architectural 
and aesthetic considerations, a number of Pcrm!ssmrrIO ci~py without fee all nr part of this material 
is gmrwaf provided that (hc copies we not made or distributed for direct commercml udvantagc, [he ACM 
copyright nntice and the title of the publiciaiorr and its date appear. and notice is givmr that copying 
is by permission of the Association for Compu!ing Machinery. To copy otherwise. or to republish. requires 
a fee andkx specific prmission. additional issues are present, such as dynamic and intricate lighting 
and sets, projected background scenery, changing focus of attention, manipulation of implied perspective, 
multiple viewing points, mo­ tion of performers, and synchronization with music. Stage and light­ ing 
designers, as well as conductors, rarely have [he opportunity to evaluate these effects together, Consequently, 
stage set and lighting designs are currently developed separately being combined only in the Iast step 
of the process. Presently. the only feasible method available for combining a limited stage and lighting 
design is the construction of small scale models. While this process dms give some insight into the visual 
impact of the final production, it is a laborious. costly, incomplete, and time-consuming endeavor. Furthermore, 
because of their small scale, these models are so inadequate for the evaluation of complex lighting effects 
that they are not commonly used, Thus, in pmctice, the stage and lighting designers will often work in 
isolation from each other. The bulk of the lighting designer s task. then. occurs at the last minute 
after the sets are assembled and in place on the stage. The primary objective of this paper is to provide 
the stage and lighting designer the opportunity to design and e\ a/uat~ /he Ii<qhring and projected scenery 
prim-to (he actual implementutimr. In partic ­ular, techniques for light source descriptions and specification, 
the simulation of directional lighting, and the modeling of scenic pro­jection systems have been developed. 
In addition, a solu(ion for the distortion problem in angular projections is introduced. The proce­dures 
have been combined to provide full three-dimensional simula­tions so that the proposed design strategy 
can be evaluated from any viewer position, The variables are the positions of the stage sets, the locations, 
orientation, spatial emittance, and color of the lights, the number of lights which are illuminated, 
the background projection systems and scenery, all within the given theater geometry. Three famous opera 
houses have been selected to demonstrate the system: the Metropolitan Opera at Lincoln Center in New 
York City, La Scala in Milan, Italy, and the Staatsoper in Vienna, Austria. Due to space limitations. 
only the Metropolitan Opera is illustrated. 2 Input for Lights In general, light sources have well-defined 
tinite geometries that greatly affect the distribution of the light emitted from the source. There are 
three types of abstract emissive geometries: point sources (zero dimensional), linear sources (one dimensional), 
and area sources (two dimensional) [23 ]. The light sources used in opera production can be treated as 
point sources, since the lights are very small and are located at a significant distance from the stage. 
Perhaps the most important characteristic of a Iuminaire that must be included in a complete model of 
a light source is the luminous ( 199! AcM-()-89791-436-H/91 /(M)7/(MMl $00.7s SIGGRAPH 91 Las Veaas. 
28 JuIv-2 Auaust 1991 intensity distribution. In contrast to the assumption typically used in computer 
graphics, most of the lights used in opera production do not emit light of constant intensity in all 
directions. A non-uniform intensity distribution must be specified, which describes the variations of 
the emitted intensity with direction. llte lighting industry uses goniometric diagrams to represent these 
vector-valued functions for easy interpretation [3]. These diagrams represent a planar slice through 
the vector field and thus plot the relative intensity as a function of angular direction (Figure 1). 
For g I12. 12.5 ~20m 93 w f 67, 1.5$ m b ml -50 0 50 Ial angle (a) (b) Figure 1: A sample emission 
distribution. (a) Polar goniometric diagram. (b) Corresponding cartesian diagram. htrninaires with concentrated 
beams, such as spotlights, cartesian coordinates are preferred because of the need for more precision 
than a polar curve allows. 2.1 Instruments and Lamps In lighting design for opera, many different types 
of Iuminaires are used. Although there appear to be a large number of different in­strument styles used, 
each style is a variation on five particukw in­struments: the ellipsoidal reflector spotligh~ the Frcsnel 
spotlight; the stripligh~ the ellipsoidal reflector floodlight; and the beam pro­jector. The optical 
characteristics of each of these instruments (and variations thereof) have been modeled. 2.2 Assigning 
Light Source Attributes An interactive graphical program has been developed to allow one to design a 
lighting scenario. While a final lighting layout is primar­ily a tool for communicating the designer 
s concept and intentions to the electricians, lighting crews, and board operators, who must hang the 
design and execute it in a performance, this program provides the means to develop ideas. experiment, 
move and change instruments and their attributes, and iteratively refine a design. The input program 
allows for the complete specification of at­tributes for stage lighting. The user can specify the position 
of each instrument, its intensity pattern, color, projection pattern, and the area which it illuminates 
in addhion to indicating its height above the floor and the angles of the beams of light. As the parameters 
as­sociated with a light are adjusted, the lamp is instantly updated with the resulting beam and field 
angles as well as throw distance. This feature makes it possible to combine light sources and evahrate 
the design implications (e.g. if their beams overlap). Thus, while still in the modeling phase, one has 
a good idea of the overall lighting scheme. Once a preliminary design is specified, the user can simu­late 
the illumination effects and, with a separate program, view the results to further refine the lighting 
design. An attempt has beerr made to carefully design the graphical in­terface so the process of assigning 
attributes is similar to the way in which it is physically performed. A menu is available which con­tains 
a two dimensional graphical representation of the five major 42 categories of lights used in opera production. 
Once a category has beerr selected, it is possible to choose from a variety of instrument types and manufacturers 
within that category. Most of the Iuminaircs used in theater production have a spot and flood focus intensity 
distribution associated with them. When a lamp has been selected, a two dimensional icon is drawn in 
one window, and the components of the lamp which move during the focusing of that particular instrument 
can be varied interactively, making it possible to focus the instrument to the desired setting (Figure 
2). To specify the intensity distribution, one window shows either a cartesian or polar goniometric diagram 
of the current lu­ minous intensity dh-ibution or candle power distribution curve for the light source. 
This diagram is updated continuously as the instru­ment is focused. To scale the dkribution, the maximum 
intensity which the lamp emits at the center of its beam is specified in units of cartdelas. Each light 
source can have a unique pattern or slide. A library of patterns and slides to be used in projection 
has been compiled. The designer can select a pattern from the library and associate it with a given light 
source. Color can be controlled by placing a transparent color filter be­tween the light source and the 
receiving surface(s). Using the filter section of the input program, an interactive color tool allows 
the user to vary the characteristics of the filter used to color the light emitted by a lamp. It is possible 
to position a lamp at arty location relative to the stage environment. Most light sources are positioned 
on the light bridges, but occasionally they are placed on the front edge of the stage as footlights or 
on temporary ladder-like structures along the sides. To aid the user in positioning the hunps, one viewport 
displays the light source with three dimensional transparent cones attached to it (op­tionally displayed) 
in the model of the stage. These cones represent the beam and field angles as well as the throw distance 
of the in­strument (see Appendix A). As the lights are positioned relative to the stage area, the cones 
allow the user to visualize the direction in which the light will be emitted as well as how much illumination 
a particular area will receive. 3 Simulation of Theater Lighting Conditions Radiosity methods, derived 
from the field of radiative heat transfer, have been successfully applied to the area of realistic image 
synthe­sis [4, 5, 6, 9, 16, 24]. The radiosity method has the attractive char­acteristic of providing 
a view-independent solution. Hence, once the solution has been performed, a hwdware renderer can be used 
to display the scene from changing viewpoints at interactive rates. 3.1 Modeling Directional Light Sources 
with Progres­sive Radiosity The progressive radiosity method [4] can be extended to account for directional 
variations in a light source with non-uniform emission distributions (Figure 1). In this implementation, 
the form-factors are computed using the ray-traced form-factor approach proposed by Wallace et al. [24]. 
To account for the variation in light source di­rectionality, the form factor from the light source to 
a vertex is com­puted as usual and then weighted by a directionality scaling factor, s. Each directional 
light source has a distribution associated with it which describes its normalized light source intensity 
versus angle. The value ofs is obtained from this distribution for each element vertex based on the direction 
82 (the angle between the direction vector of the light source and the direction of an element vertex). 
In this way, the amount of light which is transfemed from the light source to the environment is weighted 
accordhg to the directional    SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 point in the viewer space 
is the same as the color obtained by ideally transforming the original picture using the transformation 
T: V(zvgv2u) F(tiiginal_slide( (zvyoz.)T - )) = F(d2storted_slide((zv gvzv)D- )) (7) A simple way of 
guaranteeing this is to define the distorted slide as: V(2PyPzP) distorted_slide(xpyPzP) = original .sJ2de((zPyPzP)DT 
1) (8) 4.4.2 Producing a Pre-distorted Slide An algorithm to produce a pre-distorted slide which simulates 
the actual process used by lighting engineers is presented below. By us­ing Equation (8), the color at 
every point on the slide is computed. In order to evaluate this equation, a way to compute the distortion 
D is needed. In general, D is a complex non-linear transformation, and thus it is not practical to evaluate 
it analytically. The algorithm proposed computes D exactly for a small number of points and uses a linear 
interpolation to approximate D at all other points. A regular orthogonal grid (the resolution of which 
can be varied) cart be used as a means to quantify the distortion function, D. Rays are sent out from 
the projector at regular intervals (based on the resolution of the grid and the beam angle of the projector) 
to the projection surface. By transforming the set of grid points from the projector coordi­ m v (Xpypzp)Pv 
r , d ideal viewer Figure 8: Modeling the distortion in a projection. A regular grid is projected from 
the projector to the backdrop and mapped to the viewer. The projection system P maps a point from the 
projector to the screen. The observer s eye-system V maps a point from the screen to the viewer. nates, 
XPVPZP to the coordinates on the backdrop/projection surface Xb!/b.zbthe function p is simulated. Next, 
the projected points are transformed into the viewer s coordkates, Zing z., based on a cam­era specification 
which represents the view of an ideal spectator. This transformation represents the function V. The relationship 
between the original undistorted grid (the set of points ZPVP,ZP)and the resulting points as seen by 
the viewer (zvyvzu) represents the distortion, D, which was produced by the projection (Figure 8). To 
compute the final slide, the following steps we taken: First, the virtual, undistorted grid is overlayed 
onto the slide to be generated as shown in Figure 9. Next, for each point of the slide, (Zpyp.zp): Original 
picture (xp,y;,z~) ) ( 1 I I Predistorted slide (+.Yp.zp) I I I I I I I \ (x, ,yv,2 Viewer s image 
[deal transformation Physical transformation space Figure 9: Process for finding the color of a point 
in the pre-distorted slide. 1. Find which grid cell of the undistorted grid the point is in, 2. Find 
the coordinates (u, v) of the point within the undistorted grid cell (the local coordinates within the 
cell), 3. Compute the coordinates of the transformed point (xVyVz.) in the distorted grid. This computation 
is accomplished by bilin­ear interpolation (or a higher order interpolation if necessary) using the four 
transformed comers of the cell. (At this point the effect of D has been evaluated), 4. Find the point 
(z~y~z~) in the original image associated to z.%zV by the ideal transformation T 1. This is a standard 
windowing operation involving a simple affine transforma­tion,  5. The color of the distorted slide 
at point (zPyP ZP) is the color of the original slide at point (z~y~z~).  The result of this procedure 
is the predistorted slide. Figure 10 shows a projected image of a New York City sky­line onto a curved 
backdrop along with an illustration of the corrected/pre-distorted slide which was generated using the 
above method. 5 Simulation Results The geometric information in the opera hall is su~tvided into two 
parts, the geometry of the permanent structure and the geometry and position of the stage sets. Fixed 
Geometry. Definition of the Opera Hall The geometry of the structure, such as the shell or roof over 
the stage, as well as the auditorium in general, is fixed. Since the focus of the simulation is only 
on the stage, a detailed model of the stage portion of the hall has been constructed along with an abstract 
overall building model. This detailed model includes the proscenium and stage with operable stage lifts 
as well as the light bridges/gantries where the lights are positioned. The model was      SIGGRAPH 
91 Las Veaas. 28 JuIv-2 Auaust 1991 [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] 
Cohen, Michael F., Shenchang Eric Chen, John R. Wallace, and Donald P. Greenberg. ~ Progressive Refinement 
Ap­proach to Fast Radlosity Image Generation; Proceedings of SIGGRAPH 88 (Atlanta, Georgia, August 1-5, 
1988), in Computer Graphics, 22(4), August 1988, pages 75-84. Cohen, Michael F. and Donald P. Greenberg. 
A Radiosity Solution for Complex Environments, Proceedings of SIG-GRAPH 85 (San Francisco, Califomi&#38; 
July 22-26, 1985), in Computer Graphics, 19(3), July 1985, pages 3140. Cohen, Michael F., Donald P. Greenberg, 
David S. Immel, and Philip J. Brock, An Efficient Radiosity Approach for Realis­tic Image Synthesis, 
IEEE Computer Graphics and Applica­tions, 6(3), March 1986, pages 26-35. Dorsey, Julie O B. Computer 
Graphics for the Design and Visualization of Opera Lighting Effects, Master s thesis, Pro­gram of Computer 
Graphics, Cornell University, Ithaca, NY 14853, January 1990. Gilette, Michael J. Designing With Light, 
Mayfield Publishing Company, Palo Aho, 1978. Goral, Cindy M., Kenneth E. Torrance, Donald P. Greenberg, 
and Bennett Battaile. Modeling the Interaction of Light Between Diffuse Surfaces: Proceedings of SIGGRAPH 
84 (Minneapolis, Minnesota, July 23 27, 1984), in Compurer Graphics, 18(3), July 1984, pages 213-222. 
Haralick, Robert M. Automatic Remote Sensor Image Pro­cessing: Topics in Applied Physics, 11, 1976, pages 
5-63, Hartmann, Rudolf. Opera, WWiam Morrow and Company, New York, N. Y., 1977, . Heckbert, Paul S. Fundamentals 
of Texture Mapping and Image Warping, Master s thesis, Department of EECS, UC Berkeley, Berkeley, CA 
94720, June 1989. Kaufman, John E. IES Lighting Handbook -Application Volume, Illuminating Engineering 
Society of North America, New York, 1987. Max, Nelson L. Computer Graphics Distortion for IMAX and OMNIMAX 
Projection, in Proceedings of Nico­graph 83, 1983, Nishita, Tomoyuki, Yasuhiro Miyawaki, and Eihachiro 
Naka­mae. A Shtilng Model for Atmospheric Scattering Con­sidering Luminous Intensity Distribution of 
Light Sources, Proceedings of SIGGRAPH 87 (Anaheim, California, July 27 3 1, 1987), in Computer Graphics, 
21(4), July 1987, pages 303-310. Nishita, Tomoyuki and Eihachiro Nskamae. Continu­ous Tone Representation 
of Three-Dimensional Objects Tak­ing Account of Shadows and Interreflections, Proceedings of SIGGRAPH 
85 (San Francisco, California, July 22-26, 1985), in Computer Graphics, 19(3), July 1985, pages 23-30. 
Nishita, Tomoyuki, Isao Okamura, and Eihachiro Nakamae. Shading Models for Point and Lktear Sources, 
ACM Trans­actions on Graphics, 4(2), April 1985, pages 124-146. Parker, W. Oren and Harvey K. Smith. 
Scene Design and Stage Lighting, HoIt, Rinehart and Winston, Inc., New York, 1979. [19] Pilbrow, Richard. 
Stage Lighting, Von Nostrand Reinhold Company, New York, 1979. [20] Sellman, Hunton D. and Merrill Lessley. 
Essentials of Stage Lighting, Prentice-Hall, Inc, Englewood Cliffs, 1982. [21] Siegel, Robert and John 
R. Howell. Thermal Radiation Heat Transfer, Hemisphere Publishing Corp., Washington DC., 1981. [22] Sillion, 
Fr~ois and Claude Puech. A General Two-Pass Method Integrating Specular and Diffuse Reflection, Pro­ceedings 
of SIGGRAPH 89 (Boston, Massachusetts, July 31 -August 4, 1989), in Computer Graphics, 23(3), July 1989, 
pages 335 344. [23] Verbeck, charming P. and Donald P. Greenberg. A Compre­hensive Light-Source Description 
for Computer Graphics: IEEE Computer Graphics and Applications, 4(7), July 1984, pages 66-75. [24] Wallace, 
John R., Kens A. Elrnquist, and Eric A. Haines. A Ray Tracing Algorithm for Progressive Radiosity, Pro­ceedings 
of SIGGRAPH 89 (Boston, Massachusetts, July 31 -August 4, 1989), in Computer Graphics, 23(3), July 1989, 
pages 315-324. [25] Warn, David R. Lighting Controls for Synthetic Images, Proceedings of SIGGRAPH 83 
(Detroit, Michigan, July 25­29, 1983), in Computer Graphics, 17(3), July 1983, pages 13 21. [26] Watson, 
Lee Lighting Design Handbook, McGraw-Hill, New York, 1990. [27] Wilfred, Thomas. Projected Scenery -A 
Technical Manual, The Drama Book Shop, New York, 1%5. [28] Wolberg, Gwrge. Digital Image Warping, IEEE 
Computer Society Press., Los Ahunitos, CA, 1990. Appendix A Beam and Field Angles The beam angle is 
the central cone of light emitted from an instru­ment (Figure 14). The limit of the beam angle is usually 
defined as field an Ie (18%) . P -i / $ L9J Flgurc 14: Relationship between the beam and field angles 
of a lighting instrument. that point where the light diminishes to 50 percent of its intensity when compared 
with the center of the beam: The field angle is des­cribed as that point where the light diminishes to 
10 percent of the output of the center of the beam.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122724</article_id>
		<sort_key>51</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Making radiosity usable]]></title>
		<subtitle><![CDATA[automatic preprocessing and meshing techniques for the generation of accurate radiosity solutions]]></subtitle>
		<page_from>51</page_from>
		<page_to>60</page_to>
		<doi_number>10.1145/122718.122724</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122724</url>
		<abstract>
			<par><![CDATA[Generating accurate radiosity solutions of real world environments is user-intensive and requires significant knowledge of the method. As a result, few end-users such as architects and designers use it. The output of most commercial modeling packages must be substantially "cleaned up" to satisfy the geometrical and topological criteria imposed by radiosity solution algorithms. Furthermore, the mesh used as the basis of the radiosity computation must meet several additional requirements for the solution to be accurate.A set of geometrical and topological requirements is formalized that when satisfied yields an accurate radiosity solution. A series of algorithms is introduced that automatically processes raw model databases to meet these requirements. Thus, the end-user can concentrate on the design rather than on the details of the radiosity solution process. These algorithms are generally independent of the radiosity solution technique used, and thus apply to all mesh based radiosity methods.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[mesh-generation]]></kw>
			<kw><![CDATA[radiosity]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31034813</person_id>
				<author_profile_id><![CDATA[81100268787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Baum]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35022772</person_id>
				<author_profile_id><![CDATA[81100013633]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of Washington, Seattle, Wa and Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31097079</person_id>
				<author_profile_id><![CDATA[81332528304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of California, Berkeley, Ca and Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P133848</person_id>
				<author_profile_id><![CDATA[81100128670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Winget]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd., Mountain View, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>378516</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Akeley, Kurt and Tom Jermoluk, "High Performance Polygon Rendering," Computer Graphics (SIGGRAPH '88 Proceedings), Vo122. No. 4., August 1988. pp. 239-246.]]></ref_text>
				<ref_id>AKEL88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baehann, Peggy L., Scott L. Wittchen, Mark S. Shepard, Kurt R. Grice, and Mark A. Yerry, "Robust, Geometrically Based, Automatic 2D Mesh Generation," Int. Journal for Numerical Methods in Engineering, Voi. 24, 1987, pp. I043-1078.]]></ref_text>
				<ref_id>BAEH87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74367</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baum, Daniel R., Holly E. Rushmeier, and James M. Winget, "Improving Radiosity Solutions Through The User of Analytically Determined Form-factors," Computer Graphics (SIGGRAPH "89 Proceedings), Vol. 23. No. 3, July 1989, pp. 325-334.]]></ref_text>
				<ref_id>BAUM89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bullis, James M., "Models and Algorithms for Computing Realistic Images Containing Diffuse Reflections," Master's Thesis, U. of Minnesota, 1989.]]></ref_text>
				<ref_id>BULL89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97896</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Campbell, A. T. III. and Donald S. Fussell, "Adaptive Mesh Generation," Computer Graphics (SIGGRAPH '90 Proceedings), Vo124. No. 4., August 1990. pp. 155-164.]]></ref_text>
				<ref_id>CAMP90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chew, L. Paul, Guaranteed-Quality Triangular Meshes, Technical Report TR 89-983, April 1989, Department of Computer Science, Comell University, Ithaca, New York.]]></ref_text>
				<ref_id>CHEW89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F. "A Radiosity Method for the Realistic Image Synthesis of Complex Diffuse Environments," Master's Thesis, Cornell U., August 1985.]]></ref_text>
				<ref_id>COHE85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Frey, William H., "Selective Refinement: A New Strategy For Automatic Node Placement in Graded Triangular Meshes," Int. Journal for Numerical Methods in Engineering, Vol. 24, 1987, pp. 2183-2200.]]></ref_text>
				<ref_id>FREY87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97913</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Haeberli, Paul and Kurt Akeley, "The Accumulation Buffer: Hardware Support for High-Quality Rendering,'" Computer Graphics (SIGGRAPH "90 Proceedings), Vol. 24, No. 4, August, 1990.]]></ref_text>
				<ref_id>HAEB90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617601</ref_obj_id>
				<ref_obj_pid>616014</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hall, Mark and Joe Warren, "Adaptive Polygonalization of Implicitly Defined Surfaces," IEEE Computer Graphics &amp; Applications, Vol. 10, No. 6, Nov. 1990, pp. 33-42.]]></ref_text>
				<ref_id>HALL90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, Pat and David Salzman, "A Rapid Hierarchical Radiosity Algorithm for Unoccluded Environments," Proc. of Eurographics Workshop on Photosimulation, Realism and Physics in Computer Graphics, Rennes, France, June 1990, pp. 151-171.]]></ref_text>
				<ref_id>HANR90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>894053</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul S. and James M. Winget, "Finite Element Methods for Global mumination," tech memo, CS Division, EECS Dept., U.C. Berkeley, May 1991.]]></ref_text>
				<ref_id>HECK91</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hugues, Thomas J. R., The Finite Element Method. Prentice-Hall, Englewood Cliffs, NJ, 1987.]]></ref_text>
				<ref_id>HUGU87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kela, Ajay, "Automatic Finite Element Mesh Generation And Self-Adaptive Incremental Analysis Through Geometric Modeling," Doctoral Dissertation, Univ. Of Rochester, January 1987.]]></ref_text>
				<ref_id>KELA87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617588</ref_obj_id>
				<ref_obj_pid>616013</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Lathrop, Olin, David Kirk and Doug Voorhies, "Accurate Rendering by Subpixel Addressing," IEEE Computer Graphics &amp; Applications, Vol. 10, No. 5, Sept. 1990, pp. 45-52.]]></ref_text>
				<ref_id>LATH90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44106</ref_obj_id>
				<ref_obj_pid>44102</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Segal, Mark and Carlo H. Sequin, "Partitioning Polyhedral Objects Into Non-intersecting Parts," IEEE Computer Graphics &amp; Applications, Vol. 8, No. 1, Jan. 1988, pp. 53-67.]]></ref_text>
				<ref_id>SEGA88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97891</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Segal, Mark, "Using Tolerances to Guarantee Valid Polyhedral Modeling Results," Computer Graphics (SIGGRAPH '90 Proceedings), Vo124. No. 4., August 1990. pp. 105-1 I4.]]></ref_text>
				<ref_id>SEGA90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Seuss, Dr. "The Sneetches," in The Sneetches and Other Stories, pp. 2-25, Random House, NY 1953.]]></ref_text>
				<ref_id>SEUS53</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4333</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Shamos, Michael I. and Franco P. Preparata, editors, Computational Geometry: an Introduction, Springer- Verlag, 1985.]]></ref_text>
				<ref_id>SHAM85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Kells A. Elmquist and Eric A. Haines, "A Ray Tracing Algorithm for Progressive Radiosity," Computer Graphics (SIGGRAPH "89 Proceedings) Vol. 23. No. 3, July 1989, pp. 315-324.]]></ref_text>
				<ref_id>WALL89</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Making Radiosity Usable: Automatic Preprocessing and Meshing Techniques for the Generation of Accurate 
Radiosity Solutions Daniel R. Baum, Stephen Mann?, Kevin P. Smith*~, and James M. Winget Silicon Graphics 
Computer Systems 2011 N. Shoreline Blvd. Mountain View. Department of Computer Science University of 
Washington, Seattle, Wa. 98105 ABSTRACT Generating accurate radiosity solutions of real world envi­ronments 
is user-intensive and requires significant knowledge of the method. As a result, few end-users such as 
architects and de­signers use it. The output of most commercial modeling packages must be substantially 
cleaned up to satisfy the geometrical and to­pological criteria imposed by radiosity solution algorithms. 
Fur­thermore, the mesh used as the basis of the radiosity computation must meet several additional requirements 
for the solution to be ac­curate. A set of geometrical and topological requirements is for­malized that 
when satisfied yields an accurate radiosity solution. A series of algorithms is introduced that automatically 
processes raw model databases to meet these requirements. Thus, the end-user can concentrate on the design 
rather than on the details of the radiosity solution process. These algorithms are generally independent 
of the radiosity solution technique used, and thus apply to all mesh based radiosity methods. CR Categories 
and Subject Descriptors: 1.3.3 [Computer Graph­ics]: Picture/Image Generation; 1.3.7 [Computer Graphics]: 
Three- Dimensional Graphics and Realism. General Terms: Algorithms. Additional Key Words: Radiosity, 
mesh-generation. 1. INTRODUCTION Why is radiosity not more widely used today by its intended audience, 
the architect or designer? Aside from the computational expense of the method, the primary reason is 
that arriving at an ac­curate radiosity solution of a real world environment is a laborious process. 
The user must rework an input model by hand until it sat­isfies a set of technical criteria imposed by 
the radiosity solution al­gorithm in use. Most users are ill-equipped and disinclined to carry out this 
conversion. To generate a solution, mesh based radiosity methods gen­erally follow the pipeline outlined 
in Figure 1. First, the input model must be preprrxessed. Output of popular CAD packages such as Permission 
to copy wi~hout fee all or part of this material is granted provided that the copies are not made or 
distributed for direc! commercial advantage, the ACM copyright notice and the title of the publication 
and its date apptar. and notice is given that copying is by pmnission of the Associationfor ComputingMachinery.To 
copy otherwise, or to republish. requires a fee and/or specific permission. 01991 ACM-O-89791$00.75 -436-8/91/007/0051 
CA 94039-73 I I t~Department of Computer Science University of California, Berkeley, Ca, 94720 AutoCADm 
do not provide suitable input for radiosity algorithms without significant modification. Environment 
preprocess­ing includes cleaning the input geometry and topology as well as initial mesh generation. 
During the subsequent solution phase, the initial mesh may be adaptively refined. Achieving an accurate 
solu­tion imposes several constraints on the input model and subsequent mesh. For example, the mesh must 
be sufficiently dense to capture high intensity gradients and shadow boundaries. Further, it must be 
topologically well-fomted to avoid solution and display artifacts. Until now, preprocessing a complex 
model required a per­son with expertise in the method. This person had to make many it­erations through 
the solution process while interacting with the radiosity pipeline by either tweaking the model or manually 
adjust­ing the mesh. Even with user interaction, the solution might not have been accurate enough, resulting 
in a variety of visual anoma­lies. Not surprisingly, the difficulties in generating accurate radiosity 
solutions are similar to those encountered in the finite element method (FEM). Although much research 
in FEM has concentrated on environment preprocessing and automatic mesh generation (for a review see 
[KELA87]), only recently has some attention been paid to similar problems for radiosity [BULL89] [CAMP90]. 
Figure 1. The Radiosity Pipeline. The purpose of this paper is to introduce techniques that let the designer 
produce accurate radiosity rendered images of their model without knowledge of the radiosity method. 
More specifical­ly, this paper introduces a series of algorithms that take databases from existing modeling 
packages as input. These new algorithms convert the input model database into a form that is geometrically 
and topologically suitable for radiosity solution algorithms. Addi­tionally (and perhaps more importantly 
from the user s perspec­tive), these algorithms accurately process complex input models automatically. 
Furthermore, since the concepts and techniques in­troduced in this paper are independent of the radiosity 
solution al­gorithm used, they are applicable to all mesh based radiosit y methods. The remainder of 
the paper is organized as follows. Section 2 specifies a number of geometrical and topological requirements 
that must be satisfied in the radiosity pipeline for accurate radiosity solution generation. Section 
3 introduces environment preprocessing algorithms that satisfy the requirements formalized in Section 
2. In Section 4. a technique for adaptive mesh refinement within the solution phase is described. Finally, 
Section 5 presents results.  2. RADIOSITY PIPELINE REQUIREMENTS Generating and displaying an accurate 
radiosity solution imposes many geometrical and topological requirements on the representations of data 
at various stages in the radiosity pipeline; the output at one stage in the pipeline must satisfy the 
input require­ments of the next. For each stage there are two types of input re­quirements. The first, 
internal, is required by a particular stage of the pipeline to function. The second is pass-through, 
a re­quirement that must be met further downstream and has already been satisfied at an earlier stage. 
The output of a particular stage must satisfy such pass-through requirements, even if they are not internal 
requirements of that stage. There is more than one way to impose requirements within the radiosity pipeline. 
For instance, one could design radiosity specific model ing software that would constrain the user to 
construct geometry in a fashion amenable to radiosity processing. This approach, however, would not function 
for existing modelers or existing databases. Other conceivable approaches may fall short when considering 
computational efficiency or numerical precision issues. The next three subsections outline a practical 
set of radiosity pipeline requirements that when imposed correct flaws in existing methods. 2.1 Model 
Geometry Requirements [n order to formalize the radiosity pipeline requirements, some terminology is 
first defined. An input model consists of sur­faces, where a surface S is a connected region with homogeneous 
material properties and continuous normals. Nonplanar surfaces are approximated with a set of planar 
faces. During mesh generation, surfaces are further discretized into collections of convex faces. These 
faces provide the underlying geometrical basis for the radi­osity calculations. Radiosity receiver nodes 
are points in this discretization where radiosity values are computed and stored for subsequent interactive 
display. Receiver nodes frequently corre­spond to face vertices, facilitating the use of Gouraud interpolation 
for display. Radiators are those faces in the discretization that are used during the radiosity computation 
to radiate energy to the receiver nodes. Because radiosity is a physically based global illumination 
technique, a physically based model is needed in order to obtain an accurate solution. Such a model is 
composed of solid objects. Thus, the first and foremost requirement imposed on the model geometry database 
is that it contain the information equivalent to that of a solid model. A true solid model representation 
allows the un­ambiguous classification of points into those lying inside of, out­side of, or on an object 
s surface. Furthermore, for points on the object s surface, a solid model defines a unique outward pointing 
normal for each face. Unfortunately, this solid modeling requirement is rarely met in practice and thus 
must be relaxed and supplemented to make au­tomatic and accurate radiosity processing tractable. In particular, 
the single most common exception to the solid model database is the addition of facades: open single 
sided surfaces. In fact, many low-end commercial modelers used by architects encourage the user to construct 
facade objects. More precisely, two types of facades occu~ valid facades and invalid facades. A valid 
facade is one for which only the ex­terior surface radiates energy (i.e. no part of the interior surface 
is visible from anywhere in the viewing environment). An example of a valid facade is a box constructed 
without the bottom face, where the box is resting on a floor. Radiosity solution algorithms cannot correctly 
determine il­lumination in environments containing valid facades unless they have a means to determine 
the outward pointing normal for each fa­cade. Thus, even when valid facades are present in the model 
data­base, an additional requirement known as normal consistency must be imposed. If the sign of a face 
normal is not explicitly de­fined for a valid facade, it is assumed to be defined from the vertex ordering 
(e.g. all face vertexes occur in a counter-clockwise orien­tation the face). An invalid facade, on the 
other hand, is one for which both sides are involved in the illumination computation. Consider what happens 
if the bottomless box is lifted off the floor. Energy ra­diated by the floor passes through the interior 
of the box. The in­terior of the box, because it is backfacing to the floor, becomes effectively invisible, 
leading to the computation of incorrect form­factors and subsequent solution inaccuracies. Determination 
of a facade s validity is computationally de­manding, thus complete identification of invalid facades 
is imprac­tical prior to the solution phase. One option, which initially makes all facades double sided, 
fixes this particular problem but introdtrc­es several others. The most significant is a doubling of 
the problem complexity to unnecessarily model the dark interior of many ob­jects. It also leads to substantially 
increased difficulties in numeri­cal precision. In the current implementation the input model is limited 
to valid facades. One additional complication introduced by facades is coplanar faces. Overlapping coplanar 
faces exist in a solid model when two objects are adjacent to one another (such as the bottom of a box 
sitting on a desktop). These coplanar faces cause no difficulties, as they are not visible. However, 
by allowing valid facades, a pair of coplanar faces might be visible, such as a facade sheet of paper 
on a desktop. Such overlapping coplanar face pairs cause difficulties for any rendering program as it 
is unclear which face should be seen and which should be occluded, For a radiosity program to function 
correctly, one of the coplanar faces must be removed. 2.2 Radiosity Mesh Requirements The radiosity 
solution algorithm imposes its own input re­quirements on the radiosity mesh database. Fundamentally, 
obtain­ing an accurate radiosity solution involves both sampling and interpolation of an initially unknown 
function. The solution sam­pling is associated with radiator and receiver node density while in­terpolation 
is based on mesh topology. Radiosity solutions are potentially discontinuous across surface boundaries 
due to the discontinuities in normals and mate­rial properties. Elsewhere, in regions without sharp shadow 
bound­aries, the radiosity solution maintains a degree of continuity. [t is important to continue to 
support the appropriate level of continuity in the solution as the surfaces are reduced to a collection 
of individ­ual mesh faces. Thus, the first mesh requirement is the ability to perform continuous interpolation 
over individual srufaces after meshing. SatisF~ction of this requirement can be guaranteed through two 
associated meshing restrictions. First. the mesh must be composed of primitive faces: triangles or l,on\%e.v 
quadrikuerul.s. While arbitrary simple polygons could be used, restricting mesh faces 10 triangles and 
convex quadrilaterals substantially simplifies the associated local interpolation. In conjunction with 
this restriction is the further restriction that the meshing algorithm generate )70 T-lvrtices between 
adjacent faces within the same surface [Fig, 2]. The combination of these two mesh restrictions allows 
the use of finite element basis funclions [HLJGUfi7] to satisfy the desired level of continuity in the 
radiosity solution and in the subsequent display of the solution. In particular, these continuity requirements 
are useful in higher order finite element based radiosity solution techniques [HECK9 I ]. Since the radiosity 
solution can be discontinuous across surface boundaries by definition. T-vertices are acceptable between 
surtices, A B CE Q D Figure 2. T-vertices, If the face on the right is defined by the vertices A,D,E, 
then there is a T-vertex at C, The second requirement is that the faces be ~4e//-shaped. For triangles 
and convex quadrilaterals. the shape of a face can be characterized by its aspect ratio, p, where p is 
defined as the ratio of the radius of the inscribed circle to the radius of the circum­scribed circle 
of the face [FREY87 ], The closer p is to one, the bet­ter the shape of the face. Well-shaped faces are 
important to the radiosity solution phase for two reasons. First, approximations used during the solution 
phase are more accurate when based on well­shaped hces [BAUM89]. Second, these faces make the most effi­cient 
use of receiver nodes per unit area. The third requirement is that the mesh have suficient rudiulor drmiry. 
If the radiators are too large, the solution will be inaccurate IBAUM89], On the other hand, if the radiators 
are too small, the scene will be overly complex. and the solution time will be longer than necessary. 
The fourth requirement is that the mesh have suficienr ret wi~w mxle density. If the spat ing bet ween 
receiver nodes is inadequate, the radiosity solution will not accurately capture the true intensity grddients. 
On the other hand, if the node density is too high, intensity gradients will be over-determined at the 
expense of unnecessary computation. Some radiosity algorithms use adaptive refinement techniques to arrive 
at the appropriate node density [COHE8S]. When using adaptive refinement, the initial mesh must have 
sufficient node density to allow automatic adaption criteria to be accumtely evaluated. A second problem 
with insufficient node density is that it may make it impossible to meet the previously stat­ed well-shaped 
face requirement [FREY87]. The fifth meshing requirement is that any interseuling jiufes nws( be t .tpli(it/y 
repre.wred. Failure to meet this requirement results in what is commonly referred to as light or shadow 
leakage. Consider the box in Color Plate 1. Although the box implicitly intersects the mesh of the ground, 
the ground con­tains no explicit contour representing the intersection. As a result, the box covers one 
of the receiver nodes associated with a face but not the entire face. When displaying the solution using 
Gouraud shading, a shadow incorrectly leaks out from beneath the box. If the box/ground intersection 
were explicitly represented, the box would completely cover the shadowed face, thus eliminating any leakage. 
Comectly removing these gradient discontinuities a priori avoids costly repeated adaptive subdivision 
to generate an approximate so­lution and is necessary for computing higher order radiosity solu­tions 
[HECK9 I j. Shadow leakage has been noted in both [BULL89] and [CAMPW]. Campbell approaches this problem 
by generating a mesh with the aid of shadow volumes. The mesh is constructed by projecting the shadow 
boundary created by a light source and occluding surface onto the occluded surface. The resulting mesh 
prevents shadow leakage and prcxiuces accurate shadow boundaries. However, wch a mesh tends to exhibit 
poor aspect ratios and contains T-vertices. Additionally, because of the computational cost, the method 
does not appear to scale well to complex models.  2.3 Display Requirements The display stage of the 
pipeline imposes its own require­ments on the radiosity solution database. In particular, there can be 
no T-vertices in the solution database since it may cause cracks (sometimes referred to as pixel dropouts) 
to appear. Cracking oc­curs because the finite precision of the scan-conversion tilgorithms gives two 
different results along an edge where one side is split by an additional vertex [LATH90]. Although the 
radiosity mesh requirement implies that no T­vertices occur between faces of the same surface, there 
may be T­vertices between surfaces. Thus for display purposes, edges shared by more than one surface 
must be :iplo(ked, Ziplocking is a combined topological and geometric operation that fuses adjacent surfaces 
without affecting the interpolation of the solution within the individual surfaces. In Figure 2, ziplocking 
would convert the triangle A,D,E to the quadrilateral A.C.D,E. Finally, well-shaped faces are also desirable 
in the display stage to avoid display artifacts sometimes induced when poorly shaped faces are Gouraud 
shaded [HALL90]. A summary of the radiosity pipeline requirements is given in Table 1. Ia. solid model 
reD. + valid facades ] >> I R I I 1b. normal consistency I t -.. . ?. ... . no T.verrices - :-: -%rsections 
2c. no overlapping coplanar 2d. simple me: csn races 2e, well-shape­xl .­faces I 2f. sufficient radiator 
density  IRIRI I G]R I R G\R faces G]R R 1 I elm u I K G] D,- LI 1 G R 2g. sufficient receiver density 
G R 3a. ziplocking G * R Table 1: Radiosity Pipeline Requirements. >: Pass-through, C,: Generated, R: 
Required, D: Desired  3. SATISFYING THE RADIOSITY PIPELINE REQUIREMENTS This section introduces several 
algorithms which perform the environment preprocessing stage of the radiosity pipeline. The algorithms 
have been implemented as a series of geometry filters that when appropriately inserted into the radiosity 
pipeline yield substantially more accurate results. The expanded version of the environment preprocessing 
stage of the radiosity pipeline appears in Figure 3. I 1 Figure 3: Expanded Environment Preprocessing 
Pipeline Most of the requirements internal to the augmented environ­ment preprocessing stage correspond 
to the radiosity pipeline re­quirements of Section 2. However, there is an additional requirement that 
the database contains maximally connected planar faces. lltat is, a planar region of homogeneous material 
must be represented as a single general face rather than a number of connected simpler faces. To understand 
why this requirement is important, consider the green concave ground face with the hole in Color Plate 
1. Many modelers will pre-tessellate concave faces (with or without holes) into a number of simpler canonical 
types such as convex quadrilat­erals because they lack the ability to handle general faces. In doing 
this, the modeler imposes unnecessary constraints on meshing algo­rithms. Later independent meshing of 
the rectangles comprising the ground results in T-vertices along the shared edges. This in turn ap­pears 
as shading discontinuities, or seams, during solution display [Color Plate 1]. Note that these same T-vertices 
also violate Re­quirement 3a, resulting in cracking. In [BULL89], Bullis notes the necessity for maximally 
connected planar faces although he does not provide an algorithm to process faces that fail to meet this 
re­quirement. A summary of the expanded environment preprocessing requirements is given in Table 2. GICPE 
rsomm oe Pee Uc Iss m ptnhh I la. solid model reD. + valid facades I >> ! >> ! >> I >> I >> ! I lb. 
normal consistence IRI>}IRI>>I>>I ] lc. max. connected Dlanar faces IGIRI>>IRI I I 2a. no T-vertices 
IGI>>I>>I>>I>>I I 2b. no imdicit intersections I IGIRIJJIJJI . 2c. no overlapping coplanar faces G * 
> 2d. simple mesh faces G >> 2e. well-shaped faces G >> 2f. sufficient radiator density G >> \ 2g. sufficient 
receiver density ]G I III 3a, ziplocking Gl>>l>l>l>> Table 2: Environment Preprocessing Requirements 
~: Pass-through, G: Generated, R: Required 3.1 Geometry Merging -The Grouper The first filter, called 
the Grouper, is responsible for two tasks: generating surface comectivity information so that ziplock­ing 
can be performed at a later stage and forming maximally con­nected planar faces from adjacent coplanar 
faces. Note that T­vertices are removed as a result of forming maximally connected faces. As shown in 
Table 2, the Grouper requires an input model with consistent normals (lb) and has the pass-through requirement 
(la). To construct connectivity information, the Grouper first collapses sets of nearly coincident (where 
nearly is defined by a scene relative tolerance, T) vertices into one vertex. This is done by storing 
all model vertices into an octree. Each time another vertex is inserted, the algorithm checks if a vertex 
exists within T of the same position. If so, the new vertex is replaced by the existing one. Otherwise, 
the new vertex is inserted into the octree. Vertex merg­ing is depicted in Figures 4a,b.   Dm3HHml 
 Before any After vertex After vertex Afterface merging merging edge merging merging (a) (b) (c) (d) 
 Figure 4. Steps performed by the Grouper. Next, the Grouper iterates through all edges in the model 
and recursively searches the octree for any vertices that lie within T of that edge. These vertices are 
then inserted into the edge. At tlis point, the Grouper has created all of the connectivity information 
needed downstream in the pipeline [Fig. 4c]. The last step performed by the Grouper deals with the joining 
of coplanar faces that share edges. This is easily achieved by representing the model with a winged-edge 
data structure. Every edge in the data structure is examined, and if two coplanar faces of like material 
share that edge, then the two faces are merged [Fig. 4d]. 3.2 Face Interjection -lead The next filter 
in the pipeline solves the shadow leakage problem by converting implicit face intersections into explicit 
face intersections. Ttds is accomplished by identifying all pairs of inter­secting faces and cutting 
them along their lines of intersection. The input to this filter is a set of maximally connected faces. 
Its output will be the same set of maximally comected faces split along their lines of intersection. 
An existing program known as Isecr performs these operations while paying particular attention to producing 
valid results in the presence of limited numerical precision. The Isect algorithms are detailed in [SEGA88][SEGA!M]. 
 3.3 Overlapping Coplanar Faca Removal There are two classes of coplanar faces that must be considered: 
when both faces are of the same material and when they are of different materials. The first case is 
trivial. Since Isrmt ensures that the faces have identical geometry, one of the faces is simply discarded. 
An example of the second case occurs when a piece of paper is placed on a desktop. The face from the 
desktop should be removed since the paper is supposed to be above the desktop. [n general, however, it 
is impossible to determine which face is intended to be visible. A good heuristic is to remove the face 
that came from the larger surface. 3.4 Mesh Generation The output of the Grouper/Isect/Coplanar has 
properties 1a-c and 2a-c from Table 2. However it fails to have the other prop­erties in group 2: the 
faces may have any number of sides (though they will have at least three): they need not be convex (indeed, 
they may have holes); and there are no restrictions on their shapes or siz­es. The purpose of the mesh 
generation software is to convert such a face set into a mesh that has the additional properties 2d-g. 
The initial mesh generation strategy includes the substruc­turing concept developed by Cohen et al. [COHE85] 
which is based on a hierarchy of surfaces. Each surface is first subdivided into rel­atively large subsurfaces 
or padres. Each patch is then further subdivided into e/ements. During form-factor calculations, ener­gy 
is radiated from patches and received by elements. Cohen intro­duced patch/element substructunng to increase 
solution detail without substantially increasing the size of the computation. Patch/element substructunng 
serves an additional purpose in the augmented radiosity pipeline. In general, a radiosity mesh in­cludes 
many more elements than patches. Furthermore, elements are frequently further subdivided during the radiosity 
solution phase if adaptive mesh refinement schemes are used [COHE85]. For these reasons, it is desirable 
that the element mesh generation algorithm and associated data structures be very efficient in both computation 
time and storage. This leads to the following strategy for patch/element mesh generation. During patch 
generation much attention is paid ensuring that properties 2d-f are met. Given well-shaped triangular 
or convex quadrilateral patches, a very efficient algorithm can be designed to further subdivide these 
patches into well-shaped elements that achieve the necessary receiver node density (property 2g). 3.4.1 
Patch Meshing Pmesh creates a patch mesh by first uniformly subdividing the face edges according to 
the desired patch edge length and the face geometry. A local rectangular grid is then placed on top of 
each face (note that other grids such as an equilateral triangular grid could be used as well). Any grid 
box that lies entirely within the in­terior of the face can be simply output as a rectangular patch. 
The remainder of the face is triangulated [Ftg. 5]. A given radiator density imposes a maximum limit 
on the length of the patch edges, l-. The edges of the faces are uni­formly subdivided so as not to exceed 
this length: an edge of length / is divided into ceiling(fll-) subedges, each of length l/ceil­ing(///m). 
Since the radiator density is identical for all faces that share an edge, no T-vertices are created. 
The grid edge length is a function of the desired patch edge length. One of the grid directions is aligned 
with the longest edge of the face. The grid edge length in this direction is the same as the subdivision 
size of this longest edge. The second grid direction is perpendicular to the first. The grid edge length 
in this direction is set to be h/ceiling(h//W), where h is the height of the face rel­ative to its longest 
edge. While most of the output patches produced by this method will be well-shaped, there are situations 
which may induce poorly shaped patches. One such situation is when one of the grid boxes that lies entirely 
inside the face has a comer near an edge of the face. This may result in a long skinny triangle. The 
problem is eas­ily avoided by considering a grid box to he outside if one of its comers is near the edge 
of the face [Figs. 6a,b].   A2FL423 (a) (b) Figure 6. Invalidating grid boxes. A second situation 
that results in poorly shaped patches oc­curs when the edge length of the input face is small compared 
to the length of the grid edges. One way to avoid this problem is to de­crease the grid edge length so 
that it is more nearly equal to the min­imum edge length of the face. However, this has the undesirable 
side effect of producing more output patches than needed by the ra­diosity solution program. This problem 
is alleviated by using different radiator densi­ties for different surfaces. Surfaces that have short 
edges can have a small grid edge length, while those without short edges can use a longer grid edge length. 
Thus, for each surface, the required radia­tor density will be based on an input minimum density and 
the min­imum edge size of the faces in the surface. Varying grid edge length on a surface by surface 
basis is only a partial sohstion since a singIe surface that has many faces might only have one edge 
that is short. In this case, all of the faces for that surface would use a smaI1 grid size, while a large 
size would suffice for most of them. Initial experience with non-adaptive Delaunay triangulation [SHAM85] 
failed to provide a better solution. What is needed is an adaptive method that creates smaller patches 
where needed and uses larger patches elsewhere, with a gradual change in size between the two regions. 
We are currently investigating methods to address this problem [CHEW89] [FREY87]. 3.4.2 Element Meshing 
Library Since the receiving element density generally needs to b greater than the radiating patch density, 
an initial element mesh must be generated from the patch mesh. Once the radiosity compu­tation has begun 
using the initial element mesh, the radiosity pro­gram may detect variations in intensity indicating 
that the element mesh node density needs to be further increased in certain areas. What is needed is 
an abstract data type for managing element mesh generation that allows the radiosity program to dynamically 
subdi­vide elements as needed. An element meshing library was created that allows the ra- Face Wkh Overlay 
Grid Final Patch Mesh diosity program to create the initial element mesh and to refine the mesh as the 
radiosity solution progresses. The element mesh library Figure 5. Subdivision created by Pmesh. 55  
guarantees that the mesh meets certain constraints, but leaves all de­cisions concerning when and where 
to mesh to the initial element mesher, Enresh, and the solution program. 1.......1 / jj (a) (b) Figure 
7. 4-to-l Subdivision Mesh elements are refined by making four-to-one midpoint subdivisions [Figs. 7a,b]. 
Using this type of subdivision, if the input patch is well-shaped, the child elements also will be well-shaped. 
Certain constraints on the element mesh need to be maintained when subdividing, however. In particular. 
there should be a gradual change from regions of high node density to low node density. Thus, the element 
mesh should remain bakrnced. That is, two neighboring elements in the same surface should only have subdi­vision 
levels that differ by at most one [Fig. 8a]. A second con­straint is that T-vertices not be introduced 
upon subdivision. None of the published radiosity methods that discuss mesh generation meet both these 
constraints [COHE85][BULL89] [CAMP89] [HANR90]. @ Balanced Balanced + Anchored (a) (b) Figure 8. Balanced 
and Anchored Subdivisions The operations to be performed on the data set include iter­ating over all 
of the vertices, iterating over all of the leaf elements, finding the neighbors of an elemenl, and subdividing 
a set of ele­ments. As previously mentioned, there will be large numbers of el­emenw, necessitating a 
memory efficient data structure. With all these considerations in mind, a new structure relat­ed toaquad 
tree was developed to store the elements. Since input patches can be triangular, the quadtree structure 
had to be extended to handle triangles, hence the name /ri-quad wee. At the top lev­el, there are a set 
of patches: the input Fdces. Each patch points to a tri-quad tree whose root is an element identical 
to the patch. Before subdividing, it is assumed that the structure is balanced. A list of leaf elements 
is given to be subdivided. Subdividing these elements may unbalance the structure. The following pseudocode 
indicates how to rebalance the tree: Subdivide (Element: E) Perform subdivision of E If (Level(E) -Level 
(Neighbor of E) > 1) Then Subdivide (Neighbor of E) where Level(E) isthedepth of the leaves of Erelative 
to the root. This procedure isguaranteed toterminate since in each recursive call, the level of argument 
E is less than it was in the previous call. The element mesh library is also designed so as not to create 
T-vertices. If an element is subdivided without subdividing its neighbors, T-vertices arecreated atthesebourrdaries 
[Fig. 8a]. To eliminate these T-vertices, elements neighboring newly subdivided elements are anchored. 
That is, the neighbors are split to remove the T-vertices. To keep the adjustment local, the splits must 
only in­volve the T-vertices and the comer vertices of aneighboringele­ment [Fig. 8b]. Disregarding symmetry, 
there are two such arrangements for triangles, and four for rectangles [Fig. 9]. If a new T-vertex is 
added to an anchored element, the element is unan­choredand then reanchored using the new setof T-vertices. 
Rather than add a third anchor point to a triangle or a fourth one to a rect­angle, the element is simply 
subdivided. Anchors are only neces­sary for leaf elements of the tri-quad tree, so if a leaf of an anchored 
element is to be subdivided, the anchored element is first unan­chored and then subdivided. Figure9.SixTypes 
ofAnchors Balancing and anchoring have previously been applied to FEM mesh generation as a post process 
(for example, see [BAEH87]). The method presented here differs in that it balances and anchors dynamically. 
Such dynamic techniques are computationally beneficial for performing adaptive subdivision. Additionally, 
the tri-quad tree handles triangles and quadrilaterals simultaneously rather than just one or the other 
as in previous methods.  3.4.3 Initial ElementSubdivision The element meshing library provides the mechanism 
to form a suitabie input mesh for the radiosity solution program, but it is up to the initial element 
mesher to determine the sufficient receiv­ing element node density. It is important that the initial 
element node density be adequate to capture high intensity gradients such as shadow boundaries. Iftheinitial 
element density istoolow, subse­quent adaptive mesh refinement schemes may not converge. The algorithms 
for meeting theradiosity pipeline require­ments are generally independent of the technique used during 
the radiosity solution phase. However, there are a few pertinent fea­tures of the solution algorithm 
used that simplify both the initial and adaptive mesh refinement strategies. A modified version of the 
pro­gressive refinement algorithm presented in [BAUM89] is used. The primary difference is that all differential 
area-to-area form-factors are computed analytically and are computed from element vertices to the radiating 
patch rather than from points within the interior of the element. Element vertex visibility from the 
viewpoint of the ra­diating patch is computed directly using a proprietary algorithm embedded in the 
graphics hardware [AKEL88]. Adaptive refine­ment decisions are made using radiosity values at element 
vertices. Placing the radiosity receiver nodes at element vertices eliminates the need to interpolate 
radiosities from adjacent eiements in order to arrive at vertex radiosities. Computing vertex radiosities 
directly is also advantageous when displaying the resultant solution using Gouraud interpolation [WALL89]. 
To ensure sufficient initial element node density, shadow boundaries must be identified a priori. The 
techniques of Camp­beli and Fusseil analytically locate shadow boundaries and incorpo­rate these boundaries 
into the initial element mesh [CAMP90]. For complex models, such an analytical approach is computationally 
infeasible. Thus, a numerical technique was developed to determine the necessary initial element node 
density. This entails detecting and further subdividing elements that are partially occluded from the 
light source. Since the radiosity program computes vertex risi­bilities directly, a candidate element 
for subdivision can be trivially identified if only some of its vertices are visible to the light source. 
The challenging case occurs when the vertices of a partially occlud­ed element are either all visible 
to or all hidden from the light source, Partially occluded elements whose vertices are all hidden from 
or all visible to the light source are detected by performing the following operations for each light 
source. First, all elements are rendered onto a hemi-cube using the standard hemi-cube algorithm [COHE85]. 
The hemi-cube item and Z buffers are then scanned for two adjacent hemi-cube pixels that are owned by 
different elements and that have significantly different Z values. In such a pair, the element owning 
the further pixel is marked as being partially occluded. A conservative heuristic is used to determine 
when the difference in Z vislues is large enough to warrant subdivision (note this occasionally results 
in unnecessary subdivision). 4. ADAPTIVE MESI-IREFINEMENT Initial element subdivision concentrates on 
providing suffi­cient element ncsdedensity forcapturing shadow boundaries. How­ever, intensity gradients 
resulting from indirect reelections are not known until thesolution phase is invoked, Adaptive mesh refine­ment 
detects such gradients and further subdivides sections of the mesh to achieve the necessary receiver 
node density. Since the ele­merit meshing library is used, newly created mesh elements main­lain properties 
2d-f, An element issubdivided iftheintensity gradient across an edge is too high, and that edge is longer 
than a specified length. Since element subdivision adds new receiver nodes to the scene, the question 
remains as to what radiosity values should be assigned to these new nodes. Consider thesituation in Figure 
11. Assume a substantial intensity gradient exists across the edge so that the refinement algo­rithm 
creates a new node W. To obtain the correct value for W, the effect of all previously shot radiators 
must be accounted for. For example, if 20 progressive refinement iterations had been per­formed before 
creating W, those 20 patches would have to be reshot a[ W. ~~ Figure Il. What value should be assigned 
to W ? A less expensive method of estimating the radiosity value at W is to inle~late from the radiosities 
at U and V before the current radiating patch is shot. Only the current radiator is reshot at newly created 
element nodes (just W in this case) to accurately account for the energy contributed by the current rddiating 
patch. If the intensi­ty gradient along the edge UV is monotonic, the maximum error in­duced by this 
estimate is less than one half of the intensity difference, At additional expense, the correct values 
for all nodes cre­ated by adaptive refinement are computed by restarting the solution phase after a specified 
number of iterations. The refined mesh is then used as the input for the next pass through the solution 
phase. element meshing library. The determination of when to adaptively subdivide the !lddiator is made 
using the techniques from [BAUM89]. 5. RESULTS Each stage from the expanded environment preprocessing 
pipeline in Section 3 was implemented as a separate C program on a Silicon Graphics IRIS 4D/3 If) GTX 
superworkstation. The adap­tive mesh refinement scheme was integrated into the radiosity solu­tion program. 
By configuring these programs as a UnixTWpipeline, the user inputs the raw model geometry to the front 
of the pipeline and receives the accurate rddiosity solution database as output. The same raw input model 
that was used to generate the ra­diosity solution for Color Plate I was passed through the expanded environment 
preprocessing pipeline before being input to the solu­tion program. The result is shown in Color Plate 
2, Since the radi­osity pipeline requirements were met, (he resulting solution is free from the inaccuracies 
and visual artifacts present in the original \o-Iution. Specifically, note the absence of shadow leakage 
under the box, and lack of shading discontinuities and cracks on the ground. Furthermore, there is now 
sufficient receiver node density to cap­ture shadow boundaries. Clearly the lamp post model is trivial, 
and the radiusity pipeline requirements could have been met using human interven­tion during the modeling 
and meshing stages. However, user inter­vention is not practical for complex models, often making accurate 
radiosity solutions of complex models unobtainable. To demonstrate the accuracy and robustness of the 
expand­ed pipeline, radiosity solutions for two complex models were gen­erated. The first is a model 
of the residence of Dr. Fred Brooks of UNC Chapel Hill. The model was created using AutoCAD by UNC graduate 
students: Harry Marples, Michael Zaretsky. John Alspaugh, and Amitabh Varshney. The solution was performed 
on the entire house; the resulting mesh after adaptive refinement con­tains 420,026 elements. A view 
of the piano room is shown in Color Plate 3. The second model was designed by Mark Mack Architects for 
a proposed theater near Candlestick Park in San Frdnciwo. The theater model was built using CDS software 
by Charles Ehrlich from the Dept. of Architecture, UC Berkeley. At 1,061,543 ele­ments, the Candlestick 
Theater is, to the authors knowledge, the most complex radiosity solution yet computed. Two views of 
the theater are shown in Color Plates 4 and 5. The corresponding mesh is found in Color Plate 6. In Color 
Plate 4, note the shadow~ cast by the rungs of the catwalk onto the adjoining catwalk frame. Timings 
and statistics for both models are summarized in Table 3. After testing the expanded radiosity pipeline 
on complex models, some areas for improvement and further research were identified. The numerical approach 
for detecting shadow boundaries is limited by the resolution of the hemi-cube. This problem can be rectified 
using the anti-aliasing techniques of [HAEB90]. Furthermore, since shadow boundaries are not necessarily 
aligned with the element mesh, a jagged shadow edge may result. Finally, although the implementation 
is reasonably fast, there is ample room for performance improvements. All stages of the pipeline are 
currently implemented sequentially, and there are several stages that could take advantage of parallel 
processing techniques. Sufficient radiator density is also achieved using the Grouper time 2:47 min 2:50 
min #of input surfaces 8,623 5,276 #of patches 68,186 78,094 #of elements 420,026 1,061,543 I Isect 
time I 2:23 min 4:01 min Pmesh time 6:30 min 25:53 min Emesh time 5 sec 32 sec Depth Buffer Subdivision 
not used 3:40 mirdfight Solution time per iteration 2:16 min 7:12 ~in II Number of iterations 2000 1600 
Table 3. Program Timings and Statistics (all timings were done on a single processor IRIS4D/310 GTX) 
 6. CONCLUSIONS Producing an accurate radiosity solution for a complex model is difficult because the 
output of most modeling packages does not satisfy the geometrical and topological criteria imposed by 
radiosity solution algorithms. Generating an accurate solution has required a user to interact with the 
radiosity solution process by tweaking the model and adjusting the mesh. A set of radiosity pipeline 
requirements have been specified that, when satisfied, yield accurate radiosity solutions. A series of 
model cleaning and mesh generation algorithms that automatical­ly convert raw model databases to meet 
these pipeline requirements were then introduced, eliminating the need for user intervention. Since the 
algorithms are generally independent of the radiosity so­lution technique used, they apply to all mesh 
based radiosity meth­ods. Earlier work by the authors focused on improving the accuracy of radiosity 
solution techniques [BAUM89]. Combining accurate solution algorithms with the automatic preprocessing 
techniques presented here provide the foundation for a practical radiosity rendering system. [t is hoped 
that this work will put the radiosity method into the hands of those who will benefit from it most: architects 
and designers.  ACKNOWLEDGEMENTS The authors thank Mark Segaf for support on Isect and helpful comments 
on the paper. REFERENCES [AKEL88] Akeley, Kurt and Tom Jermoluk, High Performance Polygon Rendenng~ 
Computer Graphics (SIGGRAPH 88 Proceedings), Vol 22. No. 4., August 1988. pp. 239-246. [BAEH87] Baehann, 
Peggy L., Scott L. Wittchen, Mark S. Shepard, Kurt R. Gnce, and Mark A. Yerry, Robust, Geometrically 
Based, Automatic 2D Mesh Generation, Int. .lournalfor Numerical Methods in Engineering, Vol. 24, 1987, 
pp. 1043-1078. [BAUM89] Baum, Daniel R., Holly E. Rushmeier, and James M. Winget, Improving Radiosity 
Solutions Through The User of Analytically Determined Form-factors, Computer Graphics {SIGGRAPH 89Proceedings), 
Vol. 23. No. 3, July 1989, pp. 325-334. [BULL89] Bullis, James M., Models and Algorithms for Computing 
Realistic Images Containing Diffuse Reflections, Master s Thesis, U. of Minnesota, 1989. [CAMP90] Campbell, 
A. T. III. and Donald S. Fussell, Adaptive Mesh Generation, Computer Graphics (SIGGRAPH 90 Proceedings), 
Vol 24. No. 4., August 1990. pp. 155-164. [CHEW89] Chew, L. Paul, Guaranteed-Quality Triangular Meshes, 
Technicaf Report TR 89-983, April 1989, Department of Computer Science, Cornell University, Ithaca, New 
York. [COHE85] Cohen, Michael F. A Radiosity Method for the Realistic Image Synthesis of Complex Diffuse 
Environments, Master s Thesis, Cornell U., August 1985. [FREY87] Frey, William H., Selective Refinement: 
A New Strategy For Automatic Node Placement in Graded Triangular Meshes, Int, Journal for Numerical Methods 
in Engineering, Vol. 24,1987, pp. 2183-2200. [HAEB90] Haebedi, Paul and Kurt Akeley, The Accumulation 
Buffet Hardware Support for High-Quality Renderingfl Computer Graphics (SIGGlL4PH 90 Proceedings), Vol. 
24, No. 4, August, 1990. [HALL90] Hall, Mark and Joe Warren, Adaptive Polygonalization of Implicitly 
Defined Surfaces, IEEE Computer Graphics &#38; Applications, Vol. 10, No. 6, Nov. 1990, pp. 33-42. [HANR90] 
Hanrahan, Pat and David Salzman, A Rapid Hierarchical Radiosity Algorithm for Unoccluded Environments, 
Proc. of Eurographics Workshop on Photosimrdation, Realism and Physics in Computer Graphics, Rennes, 
France, June 1990, pp. 151-171. [HECK91] Heckben Paul S. and James M. Wmge4 Finite Efetnent Methoda for 
Global IUuminationfl tech memo, CS Division, EECS Dept., U.C. Berkeley, May 1991. [HUGU87] Hugues, Thomas 
J. R., The Finite Element Method. Prentice-Hall, Englewood Cliffs, NJ, 1987. [KELA87] Kela, Ajay, Automatic 
Finite Element Mesh Generation And Self-Adaptive Incremental Analysis Through Geometric Modeling, Doctoral 
Dissertation, Univ. Of Rochester, January 1987. [LATH90] Lathrop, Olin, David Kirk and Doug Voorhies, 
Accurate Rendering by Subpixel Addressing, IEEE Computer Graphics &#38; Applications, Vol. 10, No. 5, 
Sept. 1990, pp. 45-52. [SEGA88] Segal, Mark and Carlo H. Sequin, Partitioning Polyhedra Objects Into 
Non-intersecting Parts, IEEE Computer Graphics &#38; Applications, Vol. 8, No. 1, Jan. 1988, pp. 53-67. 
[SEGA90] Segal, Mark, Using Tolerances to Guarantee Valid Polyhedral Modeling Results, Computer Graphics 
(SIGGRAPH 90 Proceedings), Vol 24. No. 4., August 1990. pp. 105-114.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122725</article_id>
		<sort_key>61</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Visibility preprocessing for interactive walkthroughs]]></title>
		<page_from>61</page_from>
		<page_to>70</page_to>
		<doi_number>10.1145/122718.122725</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122725</url>
		<abstract>
			<par><![CDATA[The number of polygons comprising interesting architectural models is many more than can be rendered at interactive frame rates. However, due to occlusion by opaque surfaces (e.g., walls), only a small fraction of a typical model is visible from most viewpoints.We describe a method of visibility preprocessing that is efficient and effective for axis-aligned or <i>axial</i> architectural models. A model is subdivided into rectangular <i>cells</i> whose boundaries coincide with major opaque surfaces. Non-opaque <i>portals</i> are identified on cell boundaries, and used to form an <i>adjacency graph</i> connecting the cells of the subdivision. Next, the <i>cell-to-cell</i> visibility is computed for each cell of the subdivision, by linking pairs of cells between which unobstructed <i>sightlines</i> exist.During an interactive <i>walkthrough</i> phase, an observer with a known position and <i>view cone</i> moves through the model. At each frame, the cell containing the observer is identified, and the contents of potentially visible cells are retrieved from storage. The set of potentially visible cells is further reduced by culling it against the observer's view cone, producing the <i>eye-to-cell visibility</i>. The contents of the remaining visible cells are then sent to a graphics pipeline for hidden-surface removal and rendering.Tests on moderately complex 2-D and 3-D axial models reveal substantially reduced rendering loads.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[architectural simulation]]></kw>
			<kw><![CDATA[superset visibility]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Hidden line/surface removal</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39080034</person_id>
				<author_profile_id><![CDATA[81100244355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Seth]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Teller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, University of California at Berkeley, Ca]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P41115</person_id>
				<author_profile_id><![CDATA[81100058395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carlo]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[S&#233;quin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Science Department, University of California at Berkeley, Ca]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>917685</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[John M. Airey. Ire'teasing Update Rates in the Building Walkthrough System ~'ith Automatic ModeI-Sl~a~'e Subdivision and Potentially Visible Set Cah'ulations. PhD thesis, UNC Chapel Hill, 1990,]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91416</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[John M. Airey, John H. Rohlf, and Frederick P. Brooks Jr. Towards image realism with interactive update rates in complex virtual building environments. ACM SIGGRAPH Special Issue on 1990 Symposium on Interacti~'e 3D Graphics, 24(2):41-50, 1990.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617502</ref_obj_id>
				<ref_obj_pid>616006</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kurl Akeley. The Silicon Graphics 4D/240GTX superworkstation. IEEE Computer Graphi~'s and Appli~'ations, 9(4 ):239- 246, 1989,]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J.L. Bentley. Multidimensional binary search trees used for associative searching. Communications qfthe ACM, 18:509- 517, 1975.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>323252</ref_obj_id>
				<ref_obj_pid>323233</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Chazelle and L.J. Guibas. Visibility and intersection problems in plane geometry, In Pro~'. !'~ ACM Symposium on Comtmtational Geometry, pages 135-1,46, 1985.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563901</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Frank C. Crow. Shadow algorithms for computer graphics. Conqmter Graphi~'s (Pro~'. SIGGRAPtt "77), 11(2):242-248, 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[David R Dobkin and Diane L. Souvaine. Detecting the intersection of convex objects in the plane. Technical Report No. 89-9, DIMACS, 1989.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs, Z. Kedem, and B. Naylor, On visible surface generalion by a priori tree structures. Computer Graphics (Pro~'. SIG- GRAPH '80), 14(3):124-133, July 1980.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Akira Fujimolo and Kansei lwata. Accelerated ray tracing. In Computer Graphi~'s: Visual Te~'hnohJ.~y and Art (Pro~. Computer Graphi~'s Tokyo ',~~5 ), pages 41-65, 1985.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Benjamin Garlick, Daniel R. Baum, and James M. Winger, Interactive viewing of large geometric databases using multiprocessor graphics workstations. In SIGGRAPtt '90 Cours(' Notes (Parallel Algorithms and Ar~'hite~tures }?~r 3D Image Generation ), August 1990.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Andrew S. Glassner. Space subdivision for fast ray tracing. IEEE Computer Graphi~.s ctttd Appli~'ations, 4( 10):15-22, October 1984.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37564</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[John E. Hershberger. Effu'ient AIgorithrn.~ for Shortest Path and Visibility Problems. PhD thesis, Stanford University. June 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Michael E. Hohmeyer and Seth J, Teller. Slabbing isothetic rectangles and boxes in O(~ Ig ~) time (in preparation).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97912</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[David Kirk and Douglas Voorhies. The rendering architecture of the DNI(X)()OVS. Computer Graphi~s ~Ptw~'. SIGGRAPH '90), 24(4):299-307, August 1990.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[N. Megiddo. Linear-time algorithms for linear programming in R~ and related problems, SIAM Journal (_'rmtputing, 12:759- 776. 1983.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>40599</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Joseph O' Rourke. Art Gallery Theorems and Algorithms. Oxford University Press, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91767</ref_obj_id>
				<ref_obj_pid>91763</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Michael S. Paterson and F. Frances Yao. Efficient binary space partitions for hidden-surface removal and solid modeling. Dis- ~rete and Computational Geometry, 5(5 ):485-503, 199(t.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[W. H. Plantinga and C. R. Dyer. An algorithm for constructing the aspect graph, In Piw~'. IEEE Syrup. Foundations of Computer Scienc'e, pages 123-131, ! 986.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>98570</ref_obj_id>
				<ref_obj_pid>98524</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Raimund Seidel. Linear programming and convex hulls made easy. in Pro~'. 6~J' ACM Symposium on Computational Geometry, pages 211-215, 1990.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Michael lan Shamos and Franco P. Preparata. Computational Geometry: an lntrodu~tion. Springer-Verlag, 1985.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Seth J. Teller and Michael E. Hohmeyer. Stabbing oriented convex polygons in randomized O(~2) time ~in preparation).]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>88746</ref_obj_id>
				<ref_obj_pid>88723</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Gert Vegter. The visibility diagram: a data structure for visibility problems and motion planning. In Pro~. 2'''t S~andinavian ~wkshop tm Algorithm Theory, pages 97-11(), 1990.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Visibility Preprocessing For interactive Walkthroughs Seth J. Teller Carlo H. !%quin University of California 
at Berkeleyt Abstract The number of polygons comprising interesting architectural mod­els is many more 
than can be rendered at interactive frame rates. However, due to occlusion by opaque surfaces (e.g., 
walls), only a small fraction of atypical model is visible from most viewpoints. We describe a method 
of visibility preprocessing that is efficient andeffective foraxis-aligned oril.ria/ architectural m[}dels, 
A model is subdivided into rectangular cc//.$ whose boundaries coincide with major opaque surfaces, Non-opaque 
p(~rtc~/.rare identified rm cell boundaries. and used to form nectingthe ana~ju{~ n~y,q)f~/>//concells 
nfthesubdivisicm. Next. theccl/-r/~-cc// visibility is computed for each cell of the subdivisirrn, by 
linking pairs of cells between which unobstructed .si,q/~t/inr. ~exist. During an interactive ww/krhrm/,q/~ 
phase, an observer with a known ~~sition and\it)M~~~)~t>movmodel. esthrc>ughthe At each frame, the cell 
containingthe observer is identified, and the con­tents {]fp{>tentially visible cells areretrieved from 
storage. The set of potentially visible cells is further reduced by culling it against theobserver s 
view cone, producing i,$ibi/ify, the ~)yt>-r~]-t(>//\The contents of the remaining visible cells arc 
then sent to a graphics pipeline for hidden-surface removal and rendering, Tests onmoderatelyc mnplex 
2-D and 3-D axial models reveal substantially reduced rendering loads, CR Categrsries and Subject Descriptors: 
[Computer {;raph­ics]: l.3.5Compuiational GeonletW and Object Model ing-,qe~~~~~ef­ri( a(,qorilhnf.j, 
/<In,qMJ,qes,and ,sv.stetiI,s:1.3.7 Three-Dimensional Graphics and Realism ~i.siblc /irrc/.rrfi:fiwr 
u/,cywi/hms. Additional Key Words and Phrases: architectural simulation, linear progmmming. superset 
visibility. Permwmmlocopy wnhout leeall(~r part f>fthis material isgrantcd provided that the copies are 
not made or distributed for direct commercial advantage, the ACM copyright notice mrd the title of the 
fsublicatitrn and ih date appear. and notice is given that copying is by permission ,,( the Association 
for Comput ing Machinery. To copy otherwise, ormrcpuh[ish. requmcsa fee mrd/orspec itic pm-mission. 
 1 Introduction Interesting architectural models of furnished buildings mfiy crrn~ist of several million 
pcrlygorw. This i\manymore thantodtty \work­stations can render in a fmction of a \econd, us ii necessary 
for smooth interactive walkthroughs. However, such scmwstypicallyco nsistofl wgecnnnectedele­ments of 
opaque material (e. g., w:ills), so that from most vwt(age points only a small fructionof the model can 
be seen. The \cene can be spatially subdivided into cc//.\. and the model partitioned intrrsets ofpolygorw 
uttached toe~ch cell. Approximate visibility information can then be computed offline. and associated 
with each cell for later usc in an intemctive rendering phase. This approxi­mate in fomlation must contain 
a wtpersct of the polygon~ visible from any viewpoint in the cell. lfthis poterrtially visiblewt or PVS 
[11 excluded wrme visible polygon fo ran obierver position. the interactive rendering pha~e wrruld exhibit 
flashing or holes there. detracting from the simulation s accuracy :ind realism. 1.1 Visibility Precomputation 
Several researchers have proposed spatial wdxiivision techniques for rendering acceleration. We broadly 
refer to these methods as visibility precomputatimm, \incc by performing work offline they reduce the 
effort invol~ed in solving the hidden-w-face problem. Much tittention ha$ focuwi on computing CI{III 
visibility (e.g.. [5, 12, 16,2(), 221); that i\, c(Jmputing:in exact de\criptionofthc visible elements 
of the scene data for every qualitatively di~tinct region ofviewpoin[s. Such completc descriptimri may 
becombim­torially complex anddifticult (oimplement[lfi. 1%1.even forhighly restricted viewpoint regirrns 
(e.g., viewpoints tit infinity). The binary space partition rrr BSP tree data slructurc [8] obvi­ates 
the hidden-surface computation by producing a bac-k-twfrrrru ordering of polygon~ from wry viewpoint. 
Thi$ technique ha~ the drawback that, for an rl-polygon scene, the splitting opemtimw needed to construct 
the BSP tree miry genemte ()( J)?) new polygmr~ 1171. Fixed-grid andoctrcc \patial subdivisions [9, Illaccelecitc 
ray-traced rendering by cfticiently answering queries ;ibout rays propagating throughnrdered ~etsof parallclepipedal 
celli. To our knowledge, these ray-propagation techniques have not bum used in interact ivedispi;iy systems. 
Given the wide availability of fait polygon-rendering hardware [3, 14], itseenls rea\()nablc t()search 
l(~r~implcr, f:t$teralgorithnl\ which may {~1( )t .~(int(ll( the set of visible polygons. computing a 
,supcr.wf of the true answer. (h aphlCS hardware can then solve the ACM-O-X9791-436-WI m)7mrl I KS) 75 
!16i RAfn 11­ obstacle 4invisible eye / object El \ Figure I: Cone-octree culling: the boxed object 
is reported visible. hidden-surface problem for this polygon superset in screen-space. One approach involves 
intersecting a view cone with an octree­based spatial subdivision of the input [10]. This method has 
the undesirable property that it can report as visible an arbitrarily large part of the scene when, in 
fact, only a tiny portion can be seen (Figure 1). The algorithm may also have poor average case behavior 
for scenes with high depth complexity; i.e., many viewpoints for which a large number of overlapping 
fiolygons paint the same screen pixel. Another overestimation method involves finding portals, or non­opaque 
regions, in otherwise opaque model elements, and treating these as lineal (in 2-D) or areal (in 3-D) 
light sources [1]. Opaque polygons in the model then cause shadow volumes [6] to arise with respect to 
the light sources; those parts of the model inside the shadow volumes can be marked invisible for any 
observer on the originating portal. This portal-polygon occlusion algorithm has not found use in practice 
due to implementation difficukies and high computational complexity [I, 2]. obstacles visible object 
El Figure 2: Ray casting: the boxed object is not reported visible. A third approach estimates visibility 
using discrete sampling, after spatial subdivision. Conceptually, rays are cast outward from a stochastic, 
finite point set on the boundary of each spatial cell. Polygons hit by the rays are included in the PVS 
for that cell [l]. This approach can underesrima?e the cell s PVS by failing to report visible polygons 
(Figure 2). In practice, an extremely large number of rays must be cast to overcome this problem.  1.2 
Overview This paper describes a new approach to spatial subdivision and the visibility problem. The scene 
space is subdivided along its ma­jor opaque features; small, detailed scene elements are considered non-occluding 
and are ignored. After subdivision, a maximal set of sighdines is found from each cell to the rest of 
the subchision. A novel aspect of our algorithm is that sightliness are not cast from discrete sample 
locations. Instead, cell-to-ce/l visibility is estab­ lished if a sightline exists from any point in 
one cell to any point in another. As a consequence, the cells reached by sightliness provably contain 
a superset of the PVS for any given cell. The data structure created during this gross visibility determi­nation 
is stored with each cell, for use during an interactive walk­through phase. The cell-to-cell visibility 
can be further dynamically culled against the view cone of an observer, again producing a re­liable superset 
of the visible scene data, the eye-to-cell visibility. The detailed data contained in each visible cell, 
along with asso­ciated normal, color, texture data etc., are passed to a hardware renderer for removal 
of hidden surfaces (including, crucially, those polygons invisible to the obsewer). The two-fold model 
pruning described admits a dramatic reduction in the complexity of the exact hidden-surface determination 
that must be performed by a real-time rendering system. We describe the spatial subdivision along major 
structural ele­ments in Section 2, and the cell-to-cell visibility computation in Section 3. Section 
4 describes the additional culling possible when the position and viewing direction of the observer are 
known. Some quantitative experimental results are given in Section 5, based on an implementation for 
axial 2-D models. Section 6 describes work in progress toward a more general algorithm.  2 The Spatial 
Subdivision 2.1 Assumptions About Input We make two simplifying assumptions. First, we restrict our atten­ 
tion to faces that are axial line segments in the plane; that is, line segments parallel to either the 
x-or y-axis. These admit a particu­ larly simple subdivision technique, and are useful for visualization 
and expository purposes. Second, we assume that the coordinate data occur on a grid; this allows exact 
comparisons between po­ sitions, lengths, and areas. Relaxing either assumption would not affect the 
algorithms conceptually, but would of course increase the complexity of any robust implementation. Throughout 
the paper we use example data suggestive of archi­ tectural floorplans, since realizing truly interactive 
architectural and environmental simulations is a primary goal of our research. How­ ever, we note that 
the methods we describe have a modular nature and can be used to accelerate a range of graphics computations, 
for example ray-tracing and radiosity methods, flight simulators, and object-space animation and shadowing 
algorithms. 2.2 Subdivision Requirements We require that any spatial subdivision employed consist of 
convex cells, and support point location, portal enumeration on cell bound­aries, and rreighhor jinding. 
We will demonstrate the algorithm s correctness for any such spatial subdivision. Its effectiveness, 
how­ever, depends on the more subjective criterion that cell boundaries in the subdivision be mostly 
opaque.  2.3 Subdivision Method The input or .x,cne data consists of n axial faces. We perform the 
spatial subdivision using a BSP tree [8] whose splitting planes contain the major axial faces. For the 
special case of planar, axial data, the BSP tree becomes an instance of a k-D tree [4] with k = 2. Every 
node of a k-D tree is associated with a spatial cell bounded by k half-open r.rfenrs [w),,,,,,, ... X(,,,,,,,J), 
.... [ok_,,,,,,,, . x,._,.,,,a=). If a k-D node is not a leaf, it has a split dimension s such that O< 
s< k:a split abscissa a such that r.,,,,,,, < a < x..,,,,,=; and km and high child nodes with extents 
equivalent to that of the parent in every dimension except k = s, for which the extents are [T,.,,,,,,, 
...o) and [a....r..,,,,,,~), respectively. A balanced k-D tree supports logarithmic-time point location 
and linear-time neighbor queries.  Computer Graphics, Volume 25, Number 4, July 1991 We say that face 
A dea} es face B if the line suppofiing A inter­ sects B at a point in B s relative interior (Fig. 3-u). 
We recursively subdivide the root node, repeatedly subjecting each leaf cell of the k-D tree to the following 
procedure: . If the k-D cell bas no incident faces (its interior is empty). do nothing; . if any spanning 
faces exist, split on the median spanning face;  c otherwise, split on a sufficiently obscured minimum 
cleaving abscissa; i.e., along a face A cleaving a minimal set of faces orthogonal to A. Sufticientiy 
obscured means that the iengtbs of tbe faces at this abscissa sum to more than some threshold. If several 
abscissae are of the input (Fig, 3-a). Each input face F is classified with respect The k-D tree root 
cell s extent is initialized to the bounding box minimally cieaving, the candidate closest is chosen. 
Figure 4 depicts four minimaily cleaving to the root cell as: marked as O; the median abscissa is marked 
as *. . disjoint if F has no intersection with the cell; I Ill 111111 ~--. . spanning if F partitions 
the cell interior into components that * 1-7 intersect only on their boundaries: II I I 1I - ,_ D. 
~ _ *-4 2--* . covering if F lies on the cell boundary and intersects the bound-Ill 11111ary s relative 
interior; Ill 11111 ( - , --- 2-- r - I I 4 . incident otherwise. I III I III ()-- Spanning, covering, 
and incident faces, but not disjoint faces, 1 v-r are stored with each node. Clearly no face can be disjoint 
from I III the root cell. The disjoint class becomes relevant after subdivision, ,,, :*:!!! when a parent 
may contain faces disjoint from one or the other of 0 101 101 110 its children.     1 to that of 
the median face abscissae in r, (a) input faces I .: ::::.:iii,iil kd ceiia x=m (b) Figure 3: (a): A 
K-D tree root celi and input face classifications. (b): The right-hand cell and contents after the first 
split at I = m. Figure 4: Cleaving abscissae (the split abscissa is marked *). After each split, the 
contents of the parent node are reclassified as disjoint, spanning, covering, or incident with respect 
to each child, and all but the disjoint faces are stored with the child. Figure 3-u depicts a k-D tree 
root node; after this node is spiit at I = ui, Figure 3-b shows the reclassification of the root s contents 
with respect to its high (i.e., right-hand) child. This recursive subdivision continues until no suitable 
split abscis­sae are identified. We have found that these criteria, although \ome­what naive, yield a 
tree whose cell structure reflects the rooms of tbe architectural models fairly well. Moreover, the splitting 
proce­dure can be applied quickly. At tbe cost of performing an initial O(n Ig n) sort, the split dimension 
and abscissa can be determined in time O(j) at each split. where ~ is the number of faces stored with 
the node. After subdivision terminates, tbe portals (i.e., non-opaque por­tions of shared boundaries) 
are enumerated and stored with each leaf cell, along with an identifier for the neighboring cell to which 
the portal leads (Ftgure 5). Enumerating the portals in this fashion amounts to constructing an adjacency 
graph over tbe subdivision leaf cells, in which two leaves (vertices) are adjacent (share an edge) if 
and only if there is a portal connecting them. 3 Cell-to-Cell Visibility Once tbe spatiai subdivision 
has been constructed, we compute ce//-fcellll visibility information about the ieaf cells by determining 
63 -- not completely opaque. Each connected non-opaque region of this V,., .,,,,  shared boundary 
is a portal from P to Q. Given any starting cell C for which we wish to compute visible cells, a recursive 
depth-first search (DFS) of C s neighbors, rooted at C, produces candidate .,,., .,,,... z ,,, I portal 
sequences. Searching proceeds incrementally; when a can-I didate portal sequence no longer admits a sightline 
(according to 1 I the criterion described below), the depth-first search on that portal sequence terminates. 
The cells reached by the DFS are stored in a sralr rree (see below) as they are encountered. intmt faces 
-- cell boundaries , portals . adjacency graph vertices adjacency graph edges Figure 5: Subdivision, 
with portals and adjacency graph. cells between which an unobstructed sighdine exists. Clearly such a 
sightline must be disjoint from any opaque faces and thus must intersect, or .wub, a portal in order 
to pass from one cell to the next. Sightliness connecting cells that are not immediate neighbors must 
tmverse a ports/ sequence, each member of which lies on the boundary of an intervening cell. Observe 
that it is sufficient to consider sightliness originating and terminating on portals since, if there 
exists a sightline through two points in two cells interiors, there must be a sightline intersecting 
a portal from each cell. The problem of finding sightlines between cell areas reduces to finding sightliness 
between line segments on cell boundaries. L (a) L (b) (c) Figure 6: Oriented portal sequences, and separable 
sets L and R. We say that a portal sequence admirs a sightline if there exists a line that stabs every 
portal of the sequence. Figure 6 depicts four cells A. B, C, and D. There are four portal sequences originating 
at A that admit sightlines: [A/B, B/C , C /D], [A/C, C /B, B/D], 1.4/13, B/D], and [A/C, C/D], where 
P/Q denotes a portal from cell P to cell Q. Thus A,B, C, and D are mutually visible. 3.1 Generating Portal 
Sequences To find sightliness, we must generate candidate poflal sequences, and identify those sequences 
that admit sightlines. We find candi­date portal sequences with a graph traversal on the cell adjacency 
graph. Two cells P and Q are trei,qhbm-s if their shared boundary is 64  3.2 Finding SightlinessThrough 
Portal Sequences The fact that portal sequences arise from directed paths in the sub­division adjacency 
graph allows us to orienr each portal in the sequence and find sightliness easily. As the DFS encounters 
each portal, it places the portal endpoints in a set L or R, according to the portal s orientation (Figure 
6). A sightline can stab this portal sequence fand only if the point sets L and R are linearly separable; 
that is, iff there exists a line S such that S. L>O, VLEL S. R<O, VRER. (1) For a portal sequence of 
length m, this is a linear programming problem of 2m constraints. Both deterministic [ 15] and randomized 
[ 19] algorithms exist to solve this linear program (i.e., find a line stabbing the portal sequence) 
in linear time; that is, time O(m). If no such stabbing line exists, the algorithms report this fact. 
 3.3 The Algorithm Assume the existence of a routine S?abbing.Line(P) that, given a portal sequence P, 
determines either a stabbing line for P or determines that no such stabbing line exists. All cells visible 
from a source cell C can then be found with the recursive procedure: Find-Visible-Ce/l.r (cell C. portal 
sequence P, visible cell set V) V=vuc for each neighbor N of C for each portal p connecting C and N orient 
p from C toN P = P concatenate p if .Wabbirrgline (P ) exists then Firrd.Visib/e.Ce//.s (N, P , V) Figure 
7 depicts a spatial subdivision and the result of invoking Find_ Visible_Ce//s (cell 1, P = empty, V 
= a). The invocation stack can be schematically represented as Fin,J-Visible.Cell.f (1, P= [],V= 0) Find. 
Visible.Cells (F, P = [1/F], V = {1}) Find-Visible-Cells (J?, P = [I/F, F/B], V = {1, F}) Find. Visible.Cells 
(E, P=[I/F, F/E], V = {1, F, B}) Find. Visible.Celh (~, P= [1/F. F/E, E/C]. V = {I, F, B, E}) Find_Visi/de_Cells(J, 
P = [1/.11,V = {1, F,B, E, C}) Find_Visiblc.Cells (H, P= [1/J, Jlff,l, V = {1, F. B, E. C ,J}) Find-Visihl<,-Cells( 
H, P=[IJ.J,JIH2],V = {I,F,l?, E, C ,J, H}) The last line shows that the cell-to-cell visibility V returned 
is {1, F.B, E,C.J,H}. The recursive nature of Find-Visib/e-Cellso suggests an efficient data structure: 
the .s/ab tree (Figure 8). Each node or vertex of the stab tree corresponds to a cell visible from the 
source ceil (cell I in Fig. 7). Each edge of the stab tree corresponds to a portal stabbed as part of 
a portal sequence originating on a boundary of Our algorithm does not yet fully exploit the coherence 
and sym­metry of the visibility relationship. Visibility is found one cell at a time, and the sigbtlines 
so generated are effectively useful only _ I\> H D BE @ F c G Figure 7: F;nding sightliness from 1, 
 the source cell, Note thal the stab tree is isomorphic to the call graph of Fin[l-t isilde .Cells( ) 
above, and that leaf cells are included in the stab tree once for each distinct portal sequence reaching 
them. A stab tree is computed and stored with each leaf cell of the spatial subdivision; the cell-to-cell 
visibility is explicitly recoverable as the set of stab tree vertices. f-n IIF FIB EIC (3/ c Figure 8: 
The stab tree rooted at I  3.4 Algorithmic Complexity Since linear progrorns are dvable in linear 
time, Fi)?t/-Vi,rib/~~-Ct,//,~ adds or reject~ efich candidate visible cell in time linear in the length 
of the portal sequence retiching that cell. Determining a useful upper bound on the total number of such 
sequences as a function of IVI seems challenging. as this quantity appears to depend on the sputitsl 
subdivision in a complicated way. However, for architectural models. we expect the length of most portal 
sequences to be a small con~tant. since mo~; cells will not see more than a constant number of other 
cells. Were this not so. most of the model would be visible from most vontage points. and visibility 
preprocessing would be futile, to tbe source cell. Later visibility computations on other cells do not 
reuse the already computed sightlines, but instead regener­ate them from scratch. To see why reusing 
sightliness is not easily accomplished, consider a general cell with several portals. Many sigbtlines 
traverse this cell, each arriving with a different history or portal sequence. Upon encountering a cell, 
it may be more work for a sightline to check every prior-arriving sigbtline than it is for tbe new sigbtline 
to simply generate the (typically bigbly constrained) set of sightliness that can reach the cell s neighbors. 
The algorithm as stated may require storage quadratic in the number of leaf cells (since, in tbe worst 
case, every leaf cell may see every other through many different portal sequences). In practice we expect 
the storage required to be linear in the number of leaf cells, with a constant close to the average portal 
sequence length. Nevertheless, we are seeking ways to combine uII of the stab tree> into a single, suitably 
annotated adjacency graph. 4 Eye-to-Cell Visibility The cell-to-cell visibility is an upper bound on 
the view of an un­~wn.sfrairred ob.wnvr in a particular cell: that is. one able to look simultaneously 
in all directions from all positions inside the cell. During an interactive walkthrougb phase, bowever, 
the observer is at a known point and has vision limited to a \ ic~ cone emanating from this point (in 
two dimensions, the cone can be defined by a view direction and field of view; in three dimensions, by 
tbe usual left, right, top, and bottom clip planes). We define the [ ye-/o-ce// visibility as the set 
of cells partially or completely visible to an ob­server with a specified view cone (Figure 9), Clearly 
the eye-to-cell visibility of any observer is a subset of the cell-to-cell visibility for the cell containing 
the observer. 4.1 Eye-to-Cell Culling Methods Let O be the cell containing the observer. C the view cone. 
S the stab tree rooted at 0. and V the set of cells visible from O (i. e.. {0, D. E, F, G. Ff}). We compute 
the observers eye-to-cell visi­bility by ~w//in,g S and V against ( . We discuss several methods of performing 
this cull, in order of increasing effectiveness and computational complexity. All but the last method 
yield an overes­timation of the eye-to-cell visibility: that is, they can fail to remove a cell from 
V for which no sightline exists in C . Tbe last method compute~ exact eye-to-cell visibility. Disjoint 
cell. The \implest cull removes from V those cells that are disjoint from C ; for example. cells E and 
F in Figure 9-u. This can be done in O(lV~ ) time, hut does not remove all invisible cells. Cell (7 in 
Figure% has a non-empty intersection with C . but is not visible; any sigbtline to it must traverse the 
cell F , which is disjoint from C . More generally, in the cell adjacency grdpb, the visible cells must 
form a single wnnec[ed mrtrponenf, each cell of which has a non-empty intersection with ( . This connected 
component must also, of course, contain the cell 0. Connected component. Thus. a more effective cull 
employ~ a depth-tirst search from () in S. subject to the constraint that every cell traversed must intersect 
the interior of ( . Tbi\ requires time 0( ISI ), and remove~ cell G in Figure 9-(/. However. it f~il~ 
to remove G in Figure Y-b, even though G is invisible from the portal, the wedge is either suitably 
narrowed by the portal s extrema (e.g., portal I/F in Figure 10), or completely eliminated if the I m 
  a)FM I (b) (c)  Figure 9: Culling O s stab tree against a view cone C. observer (because all 
sightliness in C from the observer to G must traverse some opaque input face). Incident portals. The 
culling method can be refined further by searching only through cells reachable via portals that intersect 
C s interior. Figure 9-c shows that this is still not sufficient to obtain an accurate list of visible 
cells; cell H passes this test, but is not visible in C, since no sightline from the observer can stab 
the three portals necessary to reach H. Exact eye-to-cell. The important observation is that for a cell 
to be visible, some portal sequence to that cell must admit a sightline that lies inside C and con[ains 
the view, position. Retaining the stab tree S permits an efficient implementation of this sufficient 
criterion, since S stores with O every portal sequence originating at O. Suppose the portal sequence 
to some cell has length m. As before, this sequence implies 2m linear constraints on any stabbing line. 
To these we add three linear constraints: one demanding that the stabbing line contain the observer s 
view point, and two demanding that the stabbing ray lie inside the two halfspaces whose intersection 
defines C (in two dimensions). The resulting linear program of 2m +3 constraints can be solved in time 
O(m), i.e., 0( [VI) for each portal sequence. This final refinement of the culling algorithm computes 
exact eye­to-ceil visibility. Figure 9-c shows that the cull removes H from the observer s eye-to-cell 
visibility since the portal sequence [0/F, F/G, G/H] does not admit a sightline through the view point. 
During the walkthrough phase, the visible area (volume, in 3-D) can readily be computed from the stored 
stab tree. The visible area in any cell is always the intersection of that (convex) cell with one or 
more (convex) wedges emanating from the observer s position (Figure 10). The stab tree depth-first search 
starts at the source cell, and propagates outward along the stab tree. Upon passing through a wedge is 
disjoint from the portal (e.g., portal F/B in Figure 10). In this case, the DFS branch terminates, descending 
no further into the stab tree. Figure 10: The view cone during the stab tree DFS. 4.2 Frame-to-Frame 
Coherence In practice, there is considerable frame-to-frame coherence to be exploited in the eye-to-cell 
visibility computation. During smooth observer motion, the observer s view point will typically spend 
several frame-times in each cell it encounters. Thus, the stab tree for that cell can be cached in fast 
memory as long as the observer remains in the cell. Moreover, the cell adjacency graph allows sub­stantial 
predictive power over the observer s motion. For instance, an observer exiting a known cell must emerge 
in a neighbor of that cell. An intelligent walkthrough program might prefetch all poly­gons visible to 
that cell before the observer s arrival, minimizing or eliminating the waiting times associated with 
typical high-latency mass-storage databases. 5 Experimental Results We have implemented the algorithms 
described for 2-D axial en­vironments, and all but the eye-to-cell computation for 3-D axial environments. 
The subdivision and visibility computation routines contain roughly five thousand lines of C language, 
embedded in an interactive visualization program written for a dual-processor, 50-MIP, 10-MFLOPS graphics 
superworkstation, the Silicon Graphics 320 GTX. Our test model was a tloorplan with 1000 axial faces 
(Figure 1I -a). Subdividing the k-D tree to termination with the procedure of Section 2.3 required 15 
CPU seconds, allocated 1 Mb of main memory, and produced about 700 leaf cells. Portal enumeration, creation 
of the cell adjacency graph, and the cell-to-cell visibility computation were then performed for every 
leaf cell. This required 30 CPU seconds and increased the memory usage to 2 Mb. Roughly 10,500 total 
stab tree vertices were allocated to store all of the 700 leaf cells stab trees (Figure 11-b). Thus the 
average stab tree size was about I5.   We empirically evaluated the efficacy of cell-to-cell visibility 
pruning and several eye-to-cell culling methods using the above floorplan. We performed 10,(X)Ovisibility 
queries at random loca­tions within the model, with the view direction chosen randomly, and for both 
360° and 60° view cones (Figures 1l-c and 1I-d). For every generated view cone, visibility was computed 
with each of the culling methods of Sections 3 and 4. The area of the potentially visible region was 
averaged over the random trials to produce the figures tabulated below. The quantities shown are generally 
sums of cell areas and are expressed as percentages of total model area. The last row displays the total 
area of the view cone s irrfa-sectiorr with all cells reached by the stab tree DFS (e.g., the shaded 
areas in Figure 1O). culling method 360° view cone 60° view cone l is. reduction vis. reduction area 
factor area facIor none (cell-to-cell vis.) 8.1% lox 8.170 lox disjoint cell 8.1% lox 3.19Z0 30X connected 
component 8.1% lox 2.4Yc 40X incident portals 8.1% lox 2.2YC 40X exact eye-to-cell 4.9% 20X 1.8% 50X 
exact visible area 2.1% 50X T0.3% 300X 6 Extensions and Discussion We briefly discuss extensions of 
the visibility computation algo­rithms to three-dimensional scenes. 6.1 Three-Dimensional Models Here 
we assume that all faces are rectangles whose normals and edges are parallel to the r, y, or z axis. 
Subdivision again proceeds with a k-D tree (and k = 3). The face classification and splitting criteria 
extend directly to three dimensions. Portals are no longer line segments, but are instead rectilinear 
non-convex regions formed by (rectangular) cell boundaries minus unions of covering faces. There are 
at least two ways to accommodate these more general portals. First. given any set of non-convex portals, 
rectangular large por[als maybe created by computing the axial bounding box of the set. Replacing collections 
of portals (e.g., all portals through a boundary) with large portals can only increase the computed cell­to-cell 
visibility estimation, ensuring that it remains a superset of the true visibility. A second alternative 
is to decompose each non-rectangular portal into rectangles. This approach should produce smaller potentially 
visible sets than the one above, since it does not overestimate portal sizes. However, this improved 
upper bound comes at the cost of increased combinatorial complexity, since many invocations of Find-Visib/e-Ce//.r 
will be spawned in order to explore the more numerous portals. In either event, sightliness are found 
by stabbing oriented rect­angle sequences (Figure 12), in analogy to the two-dimensional case. To accomplish 
this, we have developed and implemented a novel algorithm that determines sightlines through rectangles 
[ 13]. Briefly, the algorithm operates in a dual space in which the problem reduces to performing a linear 
number of convex polygon-polygon intersections, each requiring logarithmic time [7]. The algorithm finds 
a stabbing line through n oriented, axis-aligned rectangles, or determines that no such stabbing line 
exists, in O(rr lg n) time. Assuming a rectangular dkplay for rendering, culling against a three-dimensional 
view pyramid is a direct extension of the planar 68 Figure 12: Stabbing a sequence of rectangular portals 
in 3-D. culling methods described earlier. When the observer s position is known, each portal edge contributes 
a linear constraint on the eye­to-cell visibility. The view pyramid implies four additional linear constraints; 
one each for the left, right, top, and bottom clipping planes. Thus, computing eye-to-cell visibility 
in three dimensions again reduces to a linear-time linear programming problem. Generalizing the visibility 
computations described here to non­axial scenes appears to pose problems both conceptual and technical 
in nature. First, suitable techniques must be found for decom­posing large collections of general polygons 
into convex spatial subdivisions, generating an appropriate cell adjacency graph, and enumerating the 
portals of each subdivision cell. Second, efficient algorithms are needed for stabbing portal sequences 
comprised of general polygons in three dimensions. We have made some head­way against the latter problem 
by developing a randomized 0(rr2 ) algorithm that stabs sequences of n oriented convex polygons [21]. 
6.2 Discussion The methods described here are particularly appropriate for input with somewhat restricted 
true visibility, such as that occurring in many architectural models. However, adversarially chosen input 
can produce unbalanced spatial subdN ision trees under our naive criteria, slowing basic operations on 
the subdivision. Input with a large number of portals per cell boundary (for example, walls with tens 
or hundreds of windows) may confound the cell-to-cell visibility algorithm with a combinatorially explosive 
set of sight-Iines. Large portals ameliorate this problem, at the possible cost of decreasing the usefulness 
of the attained (overlarge) visibility estimates. It may occur that subdivision on the scene s major 
structural ele­ments alone does not sufficiently limit cell-to-cell visibility. In this instance, further 
refinement of the spatial subdivision might help (if it indeed reduces visibility) or hurt (if it leaves 
visibility unchanged but increases the combinatorial complexity of tinding sightlines). Again, there 
is an ameliorating factor: when subdividing a leaf cell, its children can see only a subset of the cells 
seen by their parent, since no new exterior portals are introduced (and the childrens freedom of vision 
is reduced). Thus each child s sightline search is heavily constrained by its parent s portal/visibility 
list. Moreover, the portals generated by the subdivision will generally restrict vis­ibility during the 
walkthrough phase. We are studying the issue of how to subdivide spatial cells as a function of cell-to-cell 
visibility and cell data density. Conclusion We have implemented und utwlyzed an eftkient and effective 
vis­ibility preprocewing tind query algorithm for axial architectural models, The algorithm s effectiveness 
depends on a decomposition of the [models into rectangular or parallelepipeds cells in which signitictint 
parts of most cell boundaries tire optique. The cell-based visibility determination relies on an efficient 
search for sightliness connecting pairs of ccll~ through non-opaque portalf, In two dimensions, this 
search reduces to d linear pro­grwnming problem. Finding sightliness through portals in three dimensions 
is somewhat harder. We show that, when relevant por­ttil sequence~ are retained, determining viewpoint-based 
visibility in both two and three dimensions also reduces to a linear programming problem. We present 
some empirical evidence of rendering speedups for axial two-dimensional environments. The visibility 
computation cm be performed :it reasonable preprocessing and storage costs and. for most viewpoints. 
dramatically reduces the number of polygons that must be procmsed by the renderer. Acknowledgments Gur 
special thanks go to Jim Winget. who has always held an ac­tive, supportive role in our research. We 
gratefully acknowledge the support of Silicon Graphics. Inc.. and particularly thank Paul Haeberli for 
his help in preparing this material for submission and publication. Michael Hohmeyer contributed much 
valuable insight and an implementation of Raimund Seidel s randomized linear pro­gramming algorithm. 
Finally we thank Mark Segal, Eti Fogel, and the SIGCJRAPH referees for their many helpful comments and 
suggestions. References [1] John M. Airey. /wreasiJl,q Updutc Rc]fc.sin thr Bfliiditl,? Wulk­Ihrwf,qh 
.$y.wem with A 11r(m7uri1Mcdd-Spucr St~bdi~ision and P<~fc~lrid/y\ Ys/h/r Set Cdtu/u/i~~n.r. PhD thesis, 
UNC Chapel Hill, 1990. [~1 John M. Airey, John H. Rohlf, and Frederick P. Brooks Jr. To­wards image realism 
with interactive update rates in complex virtual building environments. ACM SKWRAPH .$pccia/ /.wne (v11990 
Sympo,:ilfm (N1Inlcru[ri}v .?DGruphi(.r. 24(2 ):4I 50, I990. [3] Kurt Akeley. The Silicon Graphics 4D/24f)GTX 
superwork­station. /EEE CompI/fm Graphics CJd App/il utions. 9(4 ):239 246, I989. [4] J.L. Bentley. Multidimensional 
binary search trees used for associative searching. Conrmuniwfimu {f [he ,4CM, 18:509 517.1975. [5] B. 
C hazelle and L.J. Guibas, Visibility and intersection prob­lems in plane geometry. In Prwc. I t ACM 
Symposium on C,~n//]///t//1{~/l{//Gcfmuvrv. pages 135-146, 1985. [6] Frank C. Crow. Shadow algorithms 
for computer graphics. CompuIcr Gr@i~~ (Pnx. S IGGRAPH 77). 1I(2):242-24X. 1977. [7] David P. Dobkin 
and Diane L. Souvaine. Detecting tbe inter­section of convex objects in the plane. Technical Report No. 
89-9. DIMACS, 1989, [8] H, Fuchs, Z. Kedetn, and B. Naylor. (W visible wnface generat­ion by a priori 
tree structures. ( ompufcr Gruphit.s (Pnx. .WG-GRAPH 80). 14(3): 124133. July 1980. [9] Akira Fujimoto 
tind Kwrsei Iwata. Accelerated my tracing. In Cwrlp{<fcr Gwphi(s: \ ) \mIl Tc<hncJ/[Jy.Yund AIY (PrYIc. 
C/m­ pfIret Gruphi[.s Zf)kyt, X.$). pages 4 I45. I985. [lo] Benjamin Garlick, Daniel R. Baum, and James 
M. Winget. Interactive viewing of large geometric databases using multi­processor graphici workstations. 
In .$IGC;RAPH W) Cm(r.w Nores (Ptirullei A I,yori[hms atrd An J]itt>[tIIw.s fhr 3D Imu,qe Gencru/icm). 
August 1990. [11] Andrew S. Glassner. Space subdivision for Pd$t ray tmcing. /EEE C~mipIIfcr Gr@i~.$ 
and App/i~urim~.s, 4( 10): 15-22, Oc­ tober I984, []~] John E. Hershbcrger. E/ji~icn/ A/,q,wi/hms /iJr 
Sh~w/e.sf PuIh and I isibilify Pr~Ncms. PhD thesi~. Stanford University. June 1987. [13] Michael E. Hohmeyer 
and Seth J. Teller. Stabbing i~othetic rectangles and boxes in ()(u lg n ) time (in preparation). [14] 
David Kirk and Dougla\ Voorhies. The rendering architecture of the DN 100C0VS. C{mrpI~wr Grwphi(s /PtYx. 
SKXRAPH Y()), 24(4):299-307, August 1990, [15] N. Megiddo. Linear-time algorithms for linear progmmming 
in R and related problems, . VAM Jwrmd C~m?p///it~,y,12:759­776.1983. [16] Joseph 0 Rourke. AM Gu//cry 
Thcowm.\ u~]d A/,y/wi/hm\. Oxford University Pre\s. 1987. [17] Michael S. Paterson and F. Frances Ym. 
Efficient binary space partitions for hidden-w.mfiace removal and solid modeling. Di.\­IW(C <JndCorr~pl/fu[ionu/ 
Ge{mIcfr-y. 5(5 ):485 503, t99{). [18] W. H. Plantinga and C, R. Dyer. An algorithm for construct­ing 
the aspect graph. In Pro[~.IEEE Symp. F{mtidufiom of CmrIpIIfer Scienw, pages I23-I3I, I986. [19] Raimund 
Seidel. Linear programming and convex hulls made ~!II ~\cM s~nlp<),yi[lmon Cc>mpltfuti~nwl [;l ­ easy. 
In Prw. mnfvry, pages 21 I 2 I5. 1990. [20] Michael Ian Shames and Franco P. Preparata. C/m~p~//u/ifma/ 
Gcomc[ry: ,JH/nfr,du,/i,vt. Springer-Verlag. 19X5. [21] Seth J. Teller and Michael E, Hohmeyer. Stabbing 
oriented convex polygon~ in randomized O( rt~) time (in preparation). [22] Gert Vegter. The vi~ibility 
diagram: a data \tructure for visibil­ity problems and motion planning. In PJYX. 2 .$cunffinutiun Wbrk.fh,,p 
,M A/,q,wifhm T/Jc{Jry, page~ 97-110.1990.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122726</article_id>
		<sort_key>71</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Model-based matching and hinting of fonts]]></title>
		<page_from>71</page_from>
		<page_to>80</page_to>
		<doi_number>10.1145/122718.122726</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122726</url>
		<abstract>
			<par><![CDATA[In today's digital computers, phototypesetters and printers, typographic fonts are mainly given by their outline descriptions. Outline descriptions alone do not provide any information about character parts like stems serifs, shoulders, and bowls. But, in order to produce the best looking characters at a given size on a specific printer, non-linear operations must be applied to parts of the character shape. At low-resolution, grid-fitting of character outlines is required for generating nice and regular raster characters. For this reason, grid-fitting rules called hints are added to the character description. Grid-fitting rules require as parameters certain characteristic points within the shape outlines. In order to be able to detect these characteristic points in any given input font, a topological model representing the essence of the shapes found in typographic latin typefaces is proposed. This model includes sufficient information for matching existing non-fancy outline fonts to the model description. For automatic hint generation, a table of applicable hints is added into the topological model description. After matching a given input shape to the model, hints which can be applied to the shape of the given font are taken and added to its outline description. Furthermore, a structural description of individual letter shape parts using characteristic model points can be added to the model. Such a description provides knowledge about typographic structure elements like stems, serifs and bowls.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[digital typography]]></kw>
			<kw><![CDATA[grid-fitting automatic hinting]]></kw>
			<kw><![CDATA[outline fonts]]></kw>
			<kw><![CDATA[shape matching]]></kw>
			<kw><![CDATA[topological model]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Line and curve generation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15020442</person_id>
				<author_profile_id><![CDATA[81100044881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Roger]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Hersch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Swiss Federal Institute of Technology (EPFL), CH-1015 Lausanne, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P48911</person_id>
				<author_profile_id><![CDATA[81100507132]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Claude]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Betrisey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Swiss Federal Institute of Technology (EPFL), CH-1015 Lausanne, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Adams, "abcdefg: a better constraint driven environment for font generation", in Andre, Hersch (eds.), Raster Imaging and Digital Typography, Cambridge University Press, 1989. 54-70]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Apple Computer, TrueType Spec- The TrueType Font Format Specification, July ! 990]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Andler, "Automatic Generation of Gridfitting Hints for Rasterization of Outline Fonts or Graphics", EPgO- Proceedings of the International Conferen~'e on Electronic Publishing, Document Manipulation &amp; Typography, September 90, (R. Furuta, Ed.) Cambridge University Press, 221-234]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Berthold Types, H. Berthold AG, Berlin, 1988]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Betrisey, R.D. Hersch, "Flexible Application of Outline Grid Constraints". in Andre, Hersch (eds.), Raster Imaging and Digital Typography, Cambridge University Press, 1989, 242-250]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Coueignoux, "Character Generation by Computer", Computer Graphics and Image Processing, Vol. 16, 1981, pp 240- 269.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Eden, "Handwriting and pattern recognition". IRE Trans. Inform. Theory, Vol IT-8, 1962, pp 160-166.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H.E Feng, T. Pavlidis, "Decomposition of polygons into simpler components: Feature generation for syntactic pattern recognition", IEEE Transactions on Comp,ters, Vol C-24, June 1975, pp 636-650.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Flowers, "Digital type manufacture: an interactive approach", IEEE Computer, May 1984, pp. 40-48.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Gaskell, "A Nomenclature for the Letterforms of Roman Type", Vixible Language, Vol 10, No 1.1976.4 I-51.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37431</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R.D. Hersch, "Character Generation under Grid Constraints", Proceedings SIGGRAPH'87, ACM Computer Graphics, Vol 21, No. 4, July 1987,243-252]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Karow, Digital Formats for Typefaces, URW Verlag, Hamburg, 1987.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>536122</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Knuth, Computer Modern Typefaces, Addison-Wesley, 1986.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42470</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Rubinstein,Digital Typography, An Introduc;ion to Type and Composition for Computer System Design, Addison-Wesley, 1988.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[L.G. Shapiro, "A Structural Model of Shape", IEEE PAMI, Vol PAMI-2, No 2, March 1980, pp 111-126.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[W. Tracy, "Letters of Credit, a view of type design", Gordon Fraser, London, 1986, pp 52-55.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Model-basedMatchingandHintingof Fonts Roger D, Hersch, Claude Betrisey Swiss Federal Institute of Technology 
(EPFL) CH-1015 Lausanne. Switzerland Abstract In today s digital computers, phototypesetters and printers, 
typo­graphic fonts are mainly given by their outline descriptions. Outline descriptions alone do not 
provide any information about charac­ter parts like stems, serifs, shoulders, and bowls. But, in order 
to produce the best looking characters at a given size on a specific printer, non-linear operations must 
be applied to parts of the char­acter shape. At low-resolution, grid-fitting of character outlines is 
required for generating nice and regular raster characters. For this reason, grid-titting rules called 
hints are added to the character description. Grid-fitting rules require as parameters certain charac­teristic 
points within the shape outlines. In order to be able to detect these characteristic points in any given 
input font, a topological model representing the essence of the shapes found in typographic Iatin typefaces 
is proposed. This model includes sufficient infor­mation for matching existing non-fancy outline fonts 
to the model description. For automatic hint generation. a table of applicable hints is added into the 
topological model description. After match­ing a given inpu( shape to the model, hints which can be applied 
to the shape of the given font are taken and added to its outline descrip­tion. Furthermore, a structural 
description of individual letter shape parts using characteristic model points can be added to the model. 
Such a description provides knowledge about typographic structure elements like stems, serifs and bowls. 
CR Categories and Subject Descriptors: 1.3.3 [Computer Graph­ics ]: Picture/fmage Generation; 1.3.5 [Computer 
Graphics]: Com­putational Geometry and Object Modeling. Additional Key Words and Phrases: Digital typography, 
outline fonts, topological model, shape matching, grid-fitting, automatic hinting. Introduction In the 
last century, hundreds of new font families have been created for metal type and photocomposition. Photocomposition 
equipment manufacturers and font trading companies now offer thousands of different fonts. Digital fonts 
are described by their outlines, mainly in the form of straight line and spline segments. Character outline 
descriptions however are by no means adequate for creating and manipulating typographic shapes. They 
are only suitable for generating scalable fonts on high-resolution photocom­posers. Outline characters 
should be considered only as the result of the font design process. During type design, type creators 
mainly consider important font features like stoke width relationships, cur- Permission to copy without 
lee all or part of this materialis grwried provided [hat the copies arc not made or distributed for direct 
commercial advantage, the ACM copyright notice and the Iitlc of the publication and i[s date appear. 
and notice is given [hat copying is by pmmission nf the Association ftw Computing Machinery. To copy 
otherwise, or to republish, requires a fce A/or specific permiwion. ,C,lqo, ACM-()-897911/037/007WO.75 
-436-WYI arm 1. horizontal \ half serif N bow I stem d spur h b Figure I: Structural letter parts [ 
10] vature of rounded shapes, serif thickness and length, junctions be­tween serifs and stems, alternation 
of white and black space, etc.. Previous work in digital typography has shown that typefaces can be assembled 
by using structural shape parts incorporating the ba­sic font features [6] [13]. Computer-aided type 
design [9] starts with the study of structural letter parts like serifs, arms, shoulders, bowls, junctions 
and terminal endings (figure 1) and the genera­tion of variants of representative characters (E, H, O, 
n, b, o, a, e. i). The remaining letters, numbers and signs of an alphabet can be partly synthesized 
into outline characters by assembling these structural letter parts, Previous attempts to develop computer 
tools for converting automatically structural descriptions into outline de­scriptions and vice-versa 
produced only limited results [ I ]. Font outline descriptions are not sufficient for rendering outline 
fonts on middle and low-resolution devices like 300 dpi printers and 100 dpi displays. Recently, techniques 
have been developed for the grid-fitting of character outlines to a given rasterization grid [ 11j [2] 
[12]. These techniques require additional information in the form of rules specifying the kind of constraints 
to be applied on certain character parts. These rules, called hinrs or grid con.strairrfs refer to selected 
outline support points defining the width or thickness of particular character parts like staight stems, 
bowls, serifs and diagonals. The application of grid constraints adapts the original outline shape to 
the grid in order to maintain symmetry and regularity in the produced discrete shape. For a given font 
size, the rasterized characters will have equal stem width, identical serifs and nice discrete arcs. 
Manually incorporating hints into outline font descriptions is tedious and labor intensive. Due to the 
large amount of available outline SIGGRAPH 91 Las Vegas, 28 JuIY-2 Auwst 1991 fonts, automated creation 
of hinted outline fonts is a necessity. For the application of basic hints on stems, bowls and shoulders, 
au­tomatic hinting can be based on the recognition of horizontal and vertical bars and on the recognition 
of curvilinear shape extremas [3]. For the generation of more accurate hints like the control of serifs, 
of diagonal bars and the control of uniform weight at small sizes, there is a need for more elaborate 
hints, like those found in the TrueType language [2]. Such hints, which are tuned to the individual letter 
shapes, cannot be generated easily by a general purpose topo­logical shape analyser. The model-based 
approach presented here enables advanced meta-hints to be associated with the model de­scription of individual 
letter shapes. After having matched a given input font to the model, corresponding meta-hints are adapted 
to the features of the input font (saris-serif, italic) and reported into its outline description. Model 
shape : Input shape : 56 34 2 4 3 DD7 5 6 .99710 D10 11 ,2 D 12 BD 011 10 External outline : ModelPtO 
= lnputPt 1 ModelPtl = lnputPt 1 ModelPt2 = lnputPtl ModelPt3 . lnputPt2 ModelPt4 = lnputPt2 ModelPt5 
= lnputPt2 ModelPt6 = lnputPt3 ModelPt7 = lnputPt5 ModelPt8 = lnputPt6 ModelPt9 . lnpu:Pt8 ModelPt 10 
= Inputpt I I ModelPt 11 = lnputptCt Figure 2: Association of input shape suppofi points with character­istic 
model points This paper proposes a topological font-independent model for the description of each letter 
shape, This model incorporates a loose outline description valid for all non-fancy instances of the corre­sponding 
letter shape. Model outlines are described by character­istic points and by their interconnecting outline 
segments. Char­acteristic points are essentially either local maximas or minimas or discontinuity points. 
They specify starting, intermediate and end­ing points of different shape parts (stems, serifs, shoulders, 
bowls, diagonals). Their location within the character shape is given by their relative position in the 
plane. Outline segments are specified by their relative length, their approximate orientation and the 
way they connect to neighbotsring segments. Relevant knowledge can be associated with characteristic 
points and their interconnections. For example, structure elements like half-serifs can be defined by 
a series of characteristic points (starting point, intermediate points, ending point). Mets-descriptions 
of grid constraints referencing characteristic points can easily be incorporated into the topological 
model. This paper addresses the problem of identifying characteristic points in given character shapes. 
In order to solve it, we propose to match the suppotl points of existing real letter shapes to their 
corresponding characteristic points in the model (figure 2). Automatic Iabelling of character parts becomes 
a shape and point matching problem. A given input character is matched with the cor­respondent model 
character, its glyphs and contours are matched to the model character s glyphs and contours. By using 
the topological rules associated with each characteristic point, candidate points in the input description 
are successively checked, kept or eliminated. A successful match leads to one point in the input character 
for each characteristic model point. For the purpose of automated hint generation, points of a given 
input font are matched to characteristic points of the model font. Then, it becomes easy to adapt the 
constraint descriptions from the model font to the given input font and to replace the characteristic 
glyph, contour and point numbers by the corresponding input font glyph, contour and point numbers.  
2 Topological modelling of letter shapes The shape of Iatin characters has evolved over the last centuries 
but, with the exception of script and ornamental types, the topology of most character shapes has remained 
identical. In order to establish a topological model of latin characters, we have tried to define meaningful 
points on their outline (characteristic points). These points are generally either local extremas, or 
junction points between different contours parts. The topological model incorporates the topological 
essence of the shapes of the members of an alphabet. It should be valid for all its non-fancy instances, 
e.g. for the font families which can be found in tvue collections such as Berthold Types [4]. sup CapsOptCor 
CapsLine high XHeight t middle 1 contour O- Wo ristic IOw BaseLin&#38; BaseOptCo= inf Descender DesOptCo~ 
Iowinf inf low mexleft Imiddle I high I aup maxright Figure 3: Loose representation of characteristic 
contour points of character B Previous scientific approaches to topological modelling of letter shapes 
were established for the purpose of character recognition. Pto Ptl Pt2 quadrant2 quadrant 1 Pt3 +negative 
Pt4 +positive Pt5 Pt6 Pt7quadrant3 quadrant4 + Pte Pt9 Ptlo Ptll Pt12 5 67 0 Pt13 438 19 Pt14 11 Pt15 
21 8 Pt16 Pt17 Pt18 12 Pt192 1J7 13 Pt20 r!n 14 24 15 Pt21 Pt22 Pt23 Pt24 : [Iow, base] : (low, inf+lowl 
: (low, low) : (low, middle+ high) [\OW, high+sup) i (Iow, high+sup) : [Iow+middle, xheightoptcor] : 
(Iow+middle, high+sup] [Iow+middle, high) : [Iow+middle, high] : [middle, xheightoptcorl : (high, middle+ 
high] : (high, low] : (high, inf+low) : [high, base] : (middle+ high, base line) : [middle+ high, inf+low) 
: (middle+ high, low) : [middle +high, middle +high] : [middle, high) : [Iow+middle, middle+ high] : 
(Iow+middle, middle+ high] : (Iow+middle, low) ­ : (Iow+middle, inf+low) : [Iow+middle, base line) a) 
Synthetic model font b) Characteristic points CurveO : PTO -> PT2 Curvel : PT2 -> PT3 Curve2 : PT3 -> 
PT5 Curve3 : PT5 -> PT6 Curve4 : PT6 -> PT7 Curve5 : PT7 -> PT8 Curve6 : PT8 -> PT9 Curve7 : PT9 -> PTIO 
Curve8 : PTIO -> PT1l Curve9 : PT1 1 -> PT12 Curve10 : PT12 -> PT14 Curvel 1 : PT14 -> PT15 Curve12 : 
PT15 -> PT17 Curve13 : PT17 -> PT18 Curve14 : PT18 -> PT19 Curve15 : PT19 -> PT20 Curvel 6 : PT20 -> 
PT21 Curvel 7 : PT21 -> PT22 Curve18 : PT22 -> PT24 Curvel 9 : PT24 -> PTO c) Characteristic curve Figure 
4: Shape model of character n They used topological features with a high discrimination potential and 
goodness evaluation parameters to match an input shape with unknown ASCII code to the correct character 
shape in the set of ASCII letter shapes [71 [8] [ 15]. Since our task consists in matching a given inpul 
letter shape with a known ASCII code to its reference model, the matching problem is limited to matching 
the shape s glyphs (individual shapes of a character), contours and characteristic points. A successful 
match however requires that each characteristic model point be matched without contradictions to one 
input shape outline support point. In order to match glyphs. contours and characteristic points, the 
topo­logical model incorporates rough positional information, as well as information concerning the position 
of a characteristic point rela­tive to its neighboring points. Unprecise positional information can be 
given by partitioning the character space into a very coarse coordinate grid, [n the present implementation. 
5 horizontal and 6 vertical subspaces (low-inferior, inferior, low, middle, high, su­perior) are used. 
This grid definition matches nicely the geometry of Iatin shapes: lower-case letters fit in a space defined 
by three horizontal and two vertical subspaces, capitals fit in a three by three space and special characters 
like the $ use the full vertical space (6 subspaces). Characters extending beyond their left and right 
refer­ence lines like italics use all 5 horizontal subspaces. Shape locations arc defined in an unprecise 
way by specifying their approximate lo­cation on this coarse grid (figure 3). Further uncertainty can 
be introduced by allowing given model points to belong to one of two neighboring coarse grid locations. 
Glyphs and contour parts, like the interior contours of character B are situated on the grid by considering 
the position of their bounding-box center. Contour pafls are also characterized as being exterior or 
interior contours, depending on their orientation. Shape locations are specified in a precise way if 
they lie on certain reference lines like baseline, x-height, capsline and their respective optical correction 
lines. Characteristic points also have topological attributes in relation to the contour they belong 
to. They can be either local or global extrema in x or in y direction. Pairs of neighboring characteristic 
points are also characterized by the outline Segment joining them. An outline segment is either a ~traight 
or newly straight segment w a curve segment. Straight line segments are shon or long. (footaerif, up+right] 
 (Iong+vertical, up] (headserif, up+left] [diagonal, right) (corner, downright ) [vertical, down] (corner, 
right] [arc, quadrant2+negat, ve] [arc, quadrant 1+negat ive] [Iong+vertical, down] (footserif, downright) 
(horizontal, left] [footserif, up+right) [Iong+vertical, up) [arc, quadrantl +positlve) (arc, quadrant2+posit, 
vel [corner, quadrant2+pos, t,vel [Iong+vertical, down] (footserif, downright] (horizontal, left) parts 
They have either a vertical or a horizontal primary direction. Curved segments have positive or negative 
orientation. They lie within a given quadrant (figure 4), Relative positional information about glyphs 
and contours is used to match subparts of an input character shape to its corresponding model subpatts 
(figure 5). Glyphs and contours cannot be matched if topological contradictions are found between the 
input shape and the model shape. For exam­ple, character shape % cannot be matched with model character 
7c , Therefore the same character may have a model description including several shape variants. At matching 
time, either the vari­ant is known in advance (figure 6) or the program tries to match the input shape 
successively to all variants, until a match without contradictions is found. 3 Matching characteristic 
points As explained in the introduction, characteristic points define the different shape parts completely. 
In order to stan the matching process, a list of matching candidate points of a given input font will 
be associated to each characteristic point of the model font, The selected candidate points must have 
the same approximate Ioeation as their corresponding characteristic point. This first association based 
on the approximate geometric location of model points and shape points will produce many candidates for 
each characteristic model point. Subsequently, a hierarchical succession of matching criteria is used 
in order to eliminate unsuitable candidates from the candidate list until one candidate remains as a 
match for one characteristic point of the topological description. The matching process proceeds suc­cessively 
from specific strong features to more global uncertain features of model letter shapes. If one or several 
candidates match a criterion associated with a characteristic point. they are kept in the candidate list 
and all other candidates who do not match this crite­rion are eliminated, If no candidate matches a given 
criterion. no candidates are eliminated and the matching process proceeds with the next criterion. SIGGRAPH 
91 Las Vegas, 28 JuIY-2 Auaust 1991 Criterion 4; Synthetic model Input font: font : contour 1 D D contour 
1 / contour 2 3 \c contour O contour 1 Model contour positions : Contour O : [middle, middle) Contour 
1 : (middle, UPI Contour 2 : [middle, down) Model font contour sequence : hor. direction : (ModelContO 
= ModelContl = ModelCont2] vert. direction : (ModelCont2 < ModelContO < ModelCont 1] Input font contour 
sequence : her. direction : (lnputContO < lnputCont2 < lnputCont 1) vert. direction : [lnputCont 1 < 
lnputContO < lnputCont21 Contour mstching list : ModelContO . lnputContO ModelContl = lnputCont2 ModelCont2 
= lnputCont 1  Figure 5: Matching input contours of character B to correspondent model contours Candidate 
acceptance is based on the following topological criteria: Criterion i: caps line candidate D point belongs 
a reference to line (base, x-height, base capital lines) D -- - --D line. . . .. Criterion 2: Y within 
a given contour, candidate point is a o o local extremum in Xmdy I/0 ~x Criterion 3: v Criterion 5: n 
 u Criterion 6: (r Criterion 7: E Criterion 8: c Variant 1 agijs Variant 2 agijs Variant 3 candidate 
point is a departure or an arrival point of a long straight line segment candidate point is not situated 
between straight line segments having similar slopes candidate point is a local extremum in the x or 
y direction candidate point is both an arrival and a departure point of two oriented straight line segments 
with given directions candidate point is both an arrival and a departure point of two oriented straight 
line or curve segments with given directions t wJsw369%&#38; $ tw J sw 369 ?40&#38; $ tw w&#38; 0 within 
a given contour, candidate point is a global extremum inxory Figure 6: Examples of fonts having different 
shape variants Criterion 9 Model shape: Input shape: E candidate point is an extremity point of an oriented 
straight line segment with ~7106 Ow given direction contour O 6 S4 / m< ,contour 3 ,0 contour1,211 012 
60 c ,21 12  Bl!4 0 11 0 candidate point is an extremity point of an ModelContO = lnputContO ModelCont1 
= lnputCont2 oriented straight line ModalPtO = lnputPt 1 ModelPtO = lnputPt6 or curve segment with ModelPt 
1 = lnputPt 1 ModalPt 1 = lnputPt6 given direction ModalPt2 = lnputPtl ModelPt2 = lnputPtO ModelPt3 = 
lnputPt2 ModelPt3 = lnputPt2 ModelPt4 = lnputPt2 ModelPt4 = lnputPt4 ModalPt5 = lnputPt2 ModelPt5 . lnputPt5 
 Criterion 11. ModalPt6 = lnputPt3 ModelPt6 = lnputPt5 ModelPt7 = lnputPt5 ModelCont2 = lnputContl s 
ModelPt8 = lnputPtS ModelPt9 = lnputPt8 ModelPtO = lnputPt6candidate point is ModelPt 10 = lnputPt 11 
ModelPt 1 = lnputPt6 an inflexion point ModelPtl 1 = lnputPtO ModalPt2 = lnputPtO ModelPt3 = lnpulPt2 
ModelPt4 = lnputPt4 ModelPt5 = tnputPt5 ModelPt6 = lnputPt5 Figure 8: Characteristic point table includes 
the correspondences Criterion 12, between input shape points and model E caps line candidate point lies 
close to a reference line (baseline, descender The model description associates characteristic points 
with infor­ line, x-height line, mation about their approximate location and about their topological 
basa properties (local or global extrema, position on or close to a given capital line) line reference 
line, direction of arrival and departure segments). The mcxlel also includes outline part descriptors 
(figure 9). These de­scriptors specify depamsre and arrival point numbers of given out­line segments 
and their type (straight, curved of serif). Straight line segments are characterized by their primary 
direction (horizontal, Model shape: Input shape: vertical or diagonal) and orientation. Curve segments 
are character­5 6 ized by their respective quadrant numlxr and orientation. Outline 4 segments can be 
short or long segments. 3 D 7 The previously enumerated criteria for the matching of characteristic 
points are hierarchical. Stronger and more specific features are tested first (location on reference 
lines, local extrema in x and y, [middle+ high global extrema in x or y). If applicable to a given model 
point, they D middle) result in rapid elimination of inappropriate candidate points. 10 Criteria (4) 
to (5) incorporate knowledge about incoming and out­going outline segments. Again more specific criteria 
are tested first ,2 (criterion 4: extremity ofa long straight line segment). Criterion (5)II 0 11 is 
used in order to remove candidate points, since model points do not lie between straight line segments 
having similar slopes. Crite­ria (7) to (10) use [be directions of incoming and outgoing outline tolerance 
segments for the further discrimination of input points. Criteria (11) and (12) are two remaining criteria 
which provide additional infor-Candidates for ModelPt8 on external contour: mation in order to find the 
best match between tbe few remaining Criterion: geometric location : candidate points,(lnputPt5, lnputPt6, 
lnputPt7, Inputpts, Inpwptgl Next applicable criterion : After applying each criterion and eliminating 
unsuitable candidate Local extrema in x-or in y-direction, points, tbe outline description of the remaining 
candidates is checked ==> Selection of lnputPt7 (Xminl for coherence. Contradictions are detected and 
inappropriate candi­ date points are removed from the candidate point list. Figure7: Matching theintersection 
point oftwoarcs in character Figures 7 and 10 illustrate the matching process for associating input B 
points to corresponding model points. 75 . : SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 . EE SICOIAPI11- 
Sup Features associated with points : CapsOptical- Point 0: ( low, baseline) , local minimum in y CorrectionLine 
_ Point 1 : [low, inf+low) , local minimum in x CapsLine  Point 2: [Iowplowl, local maximum in x Point 
3: [ 10W,highl , local maximum in x high Point 4: ( kIW,hlgh+sup) , local minimum In x Point 5: [ low 
,capslinel , local maximum in y XHeightLine Point 6: [middle, capsline ) local maximum in y Point 7: 
(maxrlght ,hlgh ) , local maximum in x middle Point 8,9: [middle+ high, high , local minimum in x contour 
O- Point 10: (maxright, low) , global maximum in x Point 11: [middle ,baseline) , local minimum in y 
 Features associated with outline parts : contour part 0: aerlf, rlght+up low contour part 1: long+vertica[ 
, UP contour part 2: serif, up+leftBaseLine_ contour part 3: Iong+horizontal , rightBaseOptical- contour 
part 4: arc, quadrant 1+negative CorrectionLine contour part 5: arc , quadrant4+negative inf contour 
part 6: arc, quadrant 1+negat ive contour part 7: arc, quadrant4+negativeDescenderLine_ contour part 
8: Iong+horizontal , leftDescenderOptical- CorrectionLine inf Iowinf maxleft maxright Figure 9: Model 
description of character B ModefPtO = lnputPt4ModelPtO: -point located on the base linepoint Iocsted 
on the base line Iocsl minimum in y-direction -local minimum in y-direction arrival of a horizontal right 
to -arrival of a horizontal right to left segment left segment Doint located close to base 6t t 2 22 
iine ModelPt 1 = lnputPt5 ModelPtl : 1 23 -local minimum in x-direction -local minimum in x-direction 
45-; )-!2 0 24 -intermediate point within a intermediate point within a serif serif Input font:Model 
font ModelPt2: departure of a long vertical to high segment low Times Roman ModeiPt2 = lnputPt6 -departure 
of a long vertical to high segment low 6u 5 Input font: Helvetica ModelPtO = lnputPt6 point located on 
the base iine local minimum in y-direction arrival of a horizontal right to left segment ModelPtl = lnputPt6 
-intermediate point within a ModelPt2 = lnputPt6 departure of a long vertical high segment serif low 
to Figure 10: Matching serifs extremities D A: hint speciflcatlon: vertical phase control of reference 
Iines hint application: complete character B: hint apecificatlon: horizontal phase control of vertical 
stem stem width given by PtO, Pt 12 hint appl icat ion: complete character C: hint specification: horizontal 
phase control of vertical stem stem width given by Pt8, Pt7 hint application: fixed displacement: Pt6 
to Pt9 proportional displacement: Pt4 to Pt6 fixpoint: Pt4 max. displacement point: Pt6 proportional 
displacement: Pt9 to Pt 11 Iixpoint: Ptl 1 max. displacement point: Pt9 D: hint specification: vertical 
phase control of shoulder with respect to reference Iines shoulder thickness qiven by Pt 10. Pt5 hint 
application: proportional displacement: Pt4 to Pt6 fixpoint: Pt4, Pt6 max. displacement point: Pt5 proportional 
displacement: Pt9 to Ptl 1 fixpoint: Pt9, Ptl 1 max. displacement point: Pt10 Figure I 1: Support points 
for the specification of grid constraints The result of the matching process is fed back into the input 
shape outline description as a characteristic point table (figure !3). Each table entry specifies a given 
model point and its associated input point given by its glyph. contour and point number. A model description 
has been established for all Iatin alphanumeric characters. Italic characters do not need a special model 
descrip­tion: before matching, they are rectified by inverse slanting. After rectification, the normal 
matching process can be applied to them. The matching program has been tested on 7(I different fonts. 
in­cluding italic fonts. Among these fonts, a full match has been obtained on 997( of all cbardcters, 
For tbe remaining I To of the characters, the program announces that no correct match has been found. 
Characters which could not be matched to the model belong to fonts having slightly rounded vertical. 
horizontal and diagonal strokes like Optima, Palatino orZapf Book. Such characters require the implementation 
of additional processing steps for assimilating their long low-curvature outline parts to long vertical, 
horizontal or diagonal outline segments. Automatic hinting Hints are grid-fitting rules specifying which 
parts of outline charac­ters should be adapted to the grid in order to obtain nice regular raster characters 
[11]. These grid-fitting rules mainly apply to character reference lines. stems, bowls and serifs. Grid-fitting 
rules for fitting stems and bowls require two outline support points specifying the stem or bowl width. 
The evaluation of a given hint produces a subpixel displacement which must be applied to certain parts 
of the outline. The ap­plication part specifies the character parts on which the computed displacement 
is applied by giving their statting and ending outline support points (figure 1I). Similarly, special 
grid-fitting rules control the discrete appearance of serifs. They require outline support points for 
the control of serif Iengtb and serif thickness (figure 12). Thanks to grid-fitting. the discrete size 
of serifs will decrease contin­uously and disfippearat once when decreasing font size (figure 13). Foot 
serif: Vertical serif: I> thickness control T -L7 % S ~ thickness T+ -half-serif width control control 
 e+ half-serif width control Head serif : + J t thickness control 7 Figure 12: Serif control hints Only 
those hints whose parameters are characteristic points of a given letter shape can be generated automatically. 
Their meta­description is inserted into the character model, When the corre­spondence between characteristic 
points of the model and points of the input shape has been found, applicable hints described in the model 
are copied into the input shape description and model point numbers are replaced by references to corresponding 
input shape point numbers, Some input shapes only partially match model shapes. Matching saris-serif 
fonts with the model produces one input point for several characteristic points at serif locations (figure 
10). Degenerated ser­ifs are detected by the automatic hinting procedure. Hints whose parameters are 
two identical points are not copied into the input  SIGGRAPH 91 Las Veaas, 28 JuIv-2 Auwst 1991  Elf. 
slssllfhfl­ shape description. As mentioned in the previous section, italic characters are matched to 
their model after applying inverse slanting. Mets-hints associated with the model are defined in a way 
which ensures that correct hints can be derived both for upright and italic typefaces. For the vertical 
phase control of horizontal bars, hint specifications remain essentially the same: the current displacement 
direction will follow the direction of the vertical stems (figure 14). Support points used for horizontal 
phase control of vertical or italized stems can be defined in such a way that hints for both cases derive 
from the same meta-hint description. Italic serif shapes differ considerably from reman serifs. Such 
shape variations can be detected and meta-hints associated to such shapes need not be copied into the 
input typeface description (figure 15). ab~dcf$ hijklmn ~pqrsttr~wxy IA BCC JEFGHIJK kbcdet~hijkl~nopqrstuv 
wxyz ABC DEFG  abcdefghij kl~opqr stuvwxys AECI abcdef~hij klmnopqrstuvw x~s AI ab~d~f~hljklm~~pqr~tu~wxy~ 
abcdefghij klm~opqrstuvwx abcdefghij klmn~pqrstu VT abcdefghijk lmnopqrstu abcdefghij klmnopqrst abcdefghijklmnopqr 
abcdefghijklmrmpq  abcdefghijklmnop Figure 13: Serif appearance with decreasing font size Using the 
same topological description and identical meta-hints for upright and italic typefaces, one achieves 
quite acceptable results (figure 16). Characters including features not described by the model description 
are hinted manually. These hints are very special. Generally, they can be left out since their effect 
is rather limited. Such hints may be used for example for controlling the tail of character Q or the 
terminal drop of character j . The number of special hints that may be added explicitel y is smaller 
than 370. The automatically generated hints already produce high quality character descriptions that 
can be rendered at any given screen or printer resolution. 5 Character structure elements Most computer-aided 
font design systems incorporate either inter­active or descriptive outline manipulation capabilities. 
Shape parts like shoulders, stems and serifs need to be specified and stored ex­plicitly. These parts 
may then be reused for the synthesis of other similar letter shapes [14]. Metafon/ for example is a typographic 
synthesizing system based on a programming model that is used to superimpose parametrised character parts 
in order to generate the resulting letter shape. Parameters for defining and assembling char­acter parts 
are specified explicitly using suitable expressions [13]. The complete shape is generated as a superimposition 
of each in­ 78 1256 1256  H H c o 11 87 011 07 f Ma:tfl;tic.l main vertical r direction A: hint specification: 
vartical phaae control of horizontal bar bar width given by Ptl O, Pt3 hint .Dollcatlon: .. varticmlacement 
along main direction of horizontal bar: Pt3Pt4, Pt 10Pt9 B: hint apeclfication: horizontal phase control 
of vertical stem; stem suc.port points qiven by PtO, Pt2 hint app flcatlon: - displacement of stem bordera 
m, -, Pt 10Ptl 1 if vertical stem: horizontal phase control only if oblique stem: horizontal and diagonal 
phase control Figure 14: Common hints for upright and italic characters model serif: italic serif: ;&#38;; 
(L&#38; /! helf-serif ~; .?width negative width: ==> no constraint Figure 15: Detection of important 
shape variations in italic serifs dividual shape. Metafont however provides no tools for extracting character 
parts from existing outline fonts. This section shows how our topological model is used in order to build 
higher level structure elements from outline descriptions for describing character parts like serifs 
and stems. Serifs are specified directly by the topological model as outline parts having the serf attribute 
(see figure 4). In fact, each head serif is given by one and each foot or vertical serif is given by 
two half-serifs (see figure 12). Each half-serif is given by a starting point lying at the end of a long 
vertical or horizontal bar, by one intermediate point giving the serif s extension and by an end point 
lying on the continuation of the stroke base. A complete foot serif is given by its two component half-serifs. 
With such a description, a program can automatically extract the serifs of a given outline font. For 
uniformization purposes, new regularized serifs can be inserted in place of the original ones. Furthermore, 
vertical and horizontal stems and bowl pieces embedded in the character outline can be described by specifying 
corresponding stroke pieces (figure 17). Description of stroke pieces maybe useful for adjusting stroke 
thick­ Stroke piece O: Stroke piece 3: Vertical stem piece Verticel bowl part stroke contour O: segment 
(Pt2 to Pt3) contour 1: arc extremity: Pt3 ~ p/ece5G contour 1: segment [Pt6 to PtO) contour 0: arc extremity: 
Pt7 ~%&#38;. . continuity: with stroke piece 1 continuity: nil 43 654 stroke Stroke piece 1: Stroke piece 
4: piece 3 Vertical stem piece Horizontal stroke piececontour 1stroke 7 contour O: segment (Pt2 to Pt3) 
contour 2: segment [Pt4 to Pt5)piece o 3 m contour 2: segment [Pt6 to PtO] contour 1: segment [Ptl to 
Pt21 continuity: nil continuity: nil 012 Stroke piece 2: Stroke piece 5:contour O 8,9 Vertical bowl part 
Horizontal stroke piece on CapsL!ne contour 2: erc extremity: Pt3 54 stroke contour 1: segment [Pt4 
to Pt5) contour O: arc extremity: Ptl O ptece 2 contour O: segment [Pt5 to Pt61 stroke continuity: nil 
continuity: nil place 1 ont ou 3 10 Stroke piece 6: * 021 2 Horizontal stroke piece on BaseL1ne contour 
0: segment [Ptl 1 to Pto]1 stroke D contour 2: segment [Ptl to Pt21 0 stroke 11 piece 4 continuity: nil 
place 6 Figure 17: Description of stroke pieces embedded in the model character outline Acknowledgements 
ABC DEFGH:JKLMNOPI The authors would like to thank Andre Gurtler from the School ABcHMFGHUKLMNC? of 
Design, Basel, for his contribution to visual aspects of digital type. We would also like to thank Jakob 
Gonczarowski and Justin ABCDEFGHLKLMN Bur for their critical review of our typographic font-independent 
topological model. This research was funded by the Commission d Encouragement de la Recherche Scientifique 
of Switzerland. ABCDEFGHUKL(M  CD EFGHLMZJ AB Bibliography HHKL Al? CD EFG [1] D. Adams, abcdefg: a 
better constraint driven environment for font generation , in Andre, Hersch (eds. ), Rasfer /rnugirrg 
urrd Digikd ~vpogr-aphy, Cambridge University Press, 1989.54-70  ABCDEFGHIJK [2] Apple Computer, TrueTvpe 
Spe[-The TrueTvpe Font For-mar Specificariarr, July 1990 Figure 16: Rasterization of automatically hinted 
italic outline char­ acters [3] S. Andler, Automatic Generation of Gridfitting Hints for Ras ­terization 
of Outline Fonts or Graphics , Ef 90 Prweeding.s of the international Conferenceon Electronic, Publish 
irr~,Doc­ument Manipulation &#38; Typography, September 90, (R. Furuta, ness and position, which is important 
for producing more legible Ed.) Cambridge University Press, 22 I -234 fonts at small sizes. [4] Bertho/d 
~vpes, H, Berthold AC, Berlin, 1988 [5] C. Betnsey, R.D. Hersch, Flexible Application of Outline Grid 
Constraints . in Andre, Hersch (eds. ), Raster Imaging and Dig-  Conclusions ifa/ Typography. Cambridge 
University Press, 1989, 242-250 [6] P, Coueignoux, Character Generation by Computer , Com- A topological 
model representing the essence of the shapes of ty­puter Graphics and Image Prrwessin,q, Vol. 16, 1981, 
pp 240­ pographic Iatin typefaces has been developed. This model provides 269. sufficiently general information 
for it to be valid for all non-fancy typefaces, serif and saris-serif. It also provides sufficient topologi­ 
[7] M. Eden, Handwriting and pattern recognition . /RE Trans. cal information and relationships to match 
typefaces given by their Inf(v-m. Theory, Vol IT-8, 1962, pp 160-166. outline description to the model 
shape. [8] H.F. Feng, T. Pavlidis, Decomposition of polygons into sim-The correspondence between characteristic 
model and input shape pler components: Feature generation for syntactic patternpoints is of great importance 
for further processing of character out­ recognition , IEEE Transactions on Computers, Vol C-24, June 
 line descriptions, Grid-titting meta-hints can be taken automatically 1975. pp 636-650. from the model, 
adapted and associated to any given input typeface. Furthermore. higher-order structures can be built 
upon characteris­ [9] J. Flowers, Digital type manufacture: an interactive ap­tic points for describing 
structural character parts like serifs, stems, proach , IEEE Computer. May 1984, pp. 40-48. bowls and 
junctions. Mapping continuous outline descriptions into structural descriptions and vice-versa offers 
new opportunities for [ 10] P. Gaskell, A Nomenclature for the Letter-forms of Roman developing advanced 
computer-aided font design tools. Type , Visible Lan,gua,qe, Vol 10. No 1, 1976.41-51. [11] R.D. Hersch, 
Character Generation under Grid Constraints , [14] R. Rubinstein, Digital Typography,An lntroduciion 
to Type and Proceedings SIGGRAPH 87, ACM Computer Graphics, Composition for Computer System Design, Addison-Wesley, 
Vol21, No. 4, hdy 1987,243-252 1988. [12] P, Karow, Digits/ Formats for Typefaces, URW Verlag, Ham-[15] 
L.G. Shapiro, A Structural Model of Shape , IEEE PAMI, Vol burg, 1987. PAMI-2, No 2, March 1980, pp 111-126. 
[13] D. Knuth, Computer Modern Typefaces, Addison-Wesley, [16] W. Tracy, Letters of Credit, a view of 
type design , Gordon 1986. Fraser, London, 1986, pp 52-55. Annex: Matching typographic letter shapes 
to their topological model ,.~~$, ,, \\ ,,. ,, D D ,.,?  B IElc1 a) Model shape b) Times c) Helvetica 
D % -; B DB B d) Madeleine e) Courier f) Lucida n ml n a) Model shape b) Times c) Helvetica ,  Ir14Irl 
d) Madeleine e) Courier f) Lucida  &#38;iiK9 QI a) Model shape b) Times c) Helvetica .,, o ..* .,. 
,.6% *  !I ~ t!i3o d) Madeleine e) Courier f) Lucida 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122727</article_id>
		<sort_key>81</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Digital halftoning with space filling curves]]></title>
		<page_from>81</page_from>
		<page_to>90</page_to>
		<doi_number>10.1145/122718.122727</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122727</url>
		<abstract>
			<par><![CDATA[This paper introduces a new digital halftoning technique that uses space filling curves to generate aperiodic patterns of clustered dots. This method allows the parameterization of the size of pixel clusters, which can vary in one pixel steps. The algorithm unifies, in this way, the dispersed and clustered-dot dithering techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[bilevel display]]></kw>
			<kw><![CDATA[digital halftoning]]></kw>
			<kw><![CDATA[dithering]]></kw>
			<kw><![CDATA[quantization]]></kw>
			<kw><![CDATA[space filling curves]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15025597</person_id>
				<author_profile_id><![CDATA[81100202267]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Luiz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Velho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto and IMPA - Instituto de Matematic&#225;tica Pura e Aplicada, Estrada Dona Castorina, 110, 22460, Rio de Janeiro, Brazil]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31077713</person_id>
				<author_profile_id><![CDATA[81452615467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jonas]]></first_name>
				<middle_name><![CDATA[de Miranda]]></middle_name>
				<last_name><![CDATA[Gomes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IMPA - Instituto de Matematic&#225;tica Pura e Aplicada, Estrada Dona Castorina, 110, 22460, Rio de Janeiro, Brazil]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>102723</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adobe Systems, (1985): Postscript Language Reference Manual. Addison Wesley Reading Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617550</ref_obj_id>
				<ref_obj_pid>616010</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blinn, J, (1990): The Truth About Texture Mapping. IEEE Computer. Graphics and Applications, March 1990, 78-83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807417</ref_obj_id>
				<ref_obj_pid>800249</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Catmull, E. (1979): A Tutorial on Compensation Tables. Proceedings SIGGRAPH "79.in Computer Graphics, Vol. 13,1-7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fiume. E and. Ouellette, M. (1989): On Distributed Probabilistic Algorithms for Computer Graphics, Proeedings of Graphics Interface 89, 211-218.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Floyd. R, and Steinberg, L, (1975): An Adaptive Algorithm for Spatial Gray Scale SID Symposium, 1975, 36-37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>93271</ref_obj_id>
				<ref_obj_pid>93267</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Geist, R., and Reynolds, R. (1990): Colored Noise Inversion in Digital Halftoning. Proceedings of Graphics Interface 90.31- 38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Jarvis J., Judice, C and Ninke, W., (1976): A Survey of Techniques for The Display of Continuos.Tone Pictures on Bilevel Displays. Computer Graphics and Image Processing. n. 5, 13- 40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kirkpatrick. S., C. D. Gelatt Jr., and M.E Vecchi., (1982): Op. timization by Simulated Annealing. IBM Research Report 9355.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>35040</ref_obj_id>
				<ref_obj_pid>35039</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Knuth, D., (1987): Digital Halftones by Dot Diffusion. ACM Transations on Graphics, V. 6 N. 4, OCt 1987, 245-273.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Koo-Yan-Too, H. C (1988), A Peano Scan Approach to Multivariate Data Clustering. with an Application. Master Thesis, Dept. C.S., Univ,of Regina.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Limb, J. O, (1969): Design of Dither Waveforms for Quantized Visual Signals. Bell Systems Technical Journal, v. 48, a. 7, 2555-2582.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mandelbrot, B., (1977): The Fractal Geomgtry of Nature, W. H. Freeman, New York]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83596</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz P., and A. Lindenmayer (1990): The Algorithmic Beauty of Plants. Springer-verlag,. New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Sonnenberg, H., (1983): Designing Scanners for Laser Printers. Lasers &amp; Applications, April 1983, 67-70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Stevens, R.J. Lehar, F.A. and Persrton, F.H. (1983): Manipulation and Preservation of Multidimensional Image Data using the Peano Scan. IEEE Trans. on.Pattern Analysis and Machine Intelligence, 5,520-526.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>27674</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Ulichney; R., (1987): Digital Halfioning.MIT Press, Cambridge Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Witten, I. H., and Neal, M., (1982): using Peano Curves for Bilevel Display of Continuous Tone Images. IEEE Computer Gmphics and Applications, May 1982, 47-52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wyszecki. G, and Stiles, W. (1982): Color Science: Concepts and Methods., Quantitative Data and Formulae. Second edition. John Wiley &amp; Sons.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Digital Halftoning with Space Filling Curves 
Luiz Velho* Jonas de Miranda Gomes lMPA Instituto de Matematica Pura e Aplicada Estrada Dona Castorina, 
110 22460, Rio de Janeiro, Brazil ABSTRACT This paper introduces a new digital halftoning technique that 
uses space filling curves to generate aperiodic pat­terns of clustered dots. This method allows the parameterization 
of the size of pixel clusters. which can vary in one pixel steps. The algorithm unities, in this way, 
the dispersed and clustered-dot dithering techniques. Keywords: digital hidftoning, quantization, dithering, 
space fill­ing curves. bilevel display. 1. INTRODUCTION The display of gray scale images on bilevel graphic 
devices re­quires a preprocessing step in order to adapt the data to the charac­teristics of the equipment. 
In particular, a process called )df(onirr,q creates the illusion of continuous-tone through the careful 
arrange­ment of the state of individual display cells. This process can be analog or digital, depending 
upon the underlying technology of the imaging system. The analog form of halftoning is well under­stood, 
and has been used in the printing industry for more than one century, Di,qita/ ha/@nirrg, also known 
as .spa[iu/ dirhering, is as­sociated with the computer display of pictures, and has been object of intensive 
research. 1.1 MOTIVATION The initial motivation for the development of dithering techniques was the popularity 
of graphic display devices, such as plasma panels. liquid crystal and CRT monitors. More recently, the 
availability of high resolution hardcopy devices such as laser printers and digital phototypesetters 
created a new motivation for the development of digital halftoning techniques. The majority of existing 
dithering algorithms were designed for a class of graphic display devices that have a relatively low 
spatial resolution and allow precise control of individual pixels. These al­gorithms perform poorly on 
some hardcopy devices that do not have these pmpenies and cannot properly reproduce isolated dots. *Author 
s current address: University of Toronto. PermissimrI()copy with{wlfcc all or part of [his matcri~l is 
granted pnwided that the cnpim arc no[ made or d}smibutecifor direct commcrciid tictwnttige.the ACM copyright 
notice andthe title of the publicatwrranditsdate~ppear,andnn[iccisgiventhatcnpyingis hy permission01[hc 
Awwialion for Computing Muchmery. T,)copy otherwiw. or to republish. requircs a fee mrd/or specitic permission. 
 An important class of devices of this type is the popular laser printer, based on electrophotographic 
technology. The work presented in this paper addresses this problem. We propose an algorithm that is 
flexible enough to be used in a wide range of graphic devices. 1.2OVERViEW The organization of the paper 
is as follows: In Section 2 we describe the architecture of an imaging system for bilevel displays; in 
Section 3 we give an introduction to digital halftoning; a brief review of space filling curves is provided 
in Section 4. The main aspects of the clustered-dot dithering method using space filling curves are described 
in Section 5. Implementation details of our method are provided in Section 6. Examples of images generated 
by the method and comparisons with other dithering methods are presented in Section 7. Concluding remarks 
and perspectives of future work are discussed in Section 8.  2. IMAGING SYSTEM FOR BILEVEL DISPLAYS 
 The imaging system must perform several preprocessing opera­tions in order to generate the proper representation 
of a con­tinuous-tone picture on a specific graphic display device. This process must also take into 
account the particular characteristics of the device to produce the best possible rendition of the picture. 
The device s characteristics can be modeled as a mathematical function, defined on the space of images, 
called the physical reconstruction function. The preprocessing operations generally include: tone scale 
adjustment, sharpenin~ and halftoning. This pipeline is illustrated in Figure I ([ f-flichney 87]). The 
tone scale adjustment, also known as gamma correction, is necessary because most devices have a non-linear 
intensity reconstruction function. This operation compensates, for example, the overlapping of contiguous 
dots, typical of some hardcopy devices. Detailed explanation on how to construct compensation tables 
for CRT monitors can be found in the literature (see for ex­ample [Catmull 79]). This procedure can be 
generalized for other types of graphic devices. The sharpening is desirable because the dithering normal] 
y causes some reduction of the image spatial resolution. The quality of the final image can be greatly 
improved by an edge enhancement operation that emphasizes high frequencies bringing out the fine image 
details. Alternatively, the sharpening operation can be incor­ 1, 1991 AC\l-()-X97()l-436 -X {)1 (K170081 
$(s(17s 81 Gray Scala Image o Gamma Corredlon 1 Edge Enhancement I I c I Haiftoning I 1 Binary Imaga 
9 Physical ReconstructionFunction n Diaplayed Image Figure 1 Imaging pipeline for bilevel displays 
 prated into the halftoning process, as was observed by Jarvis [Jarvis et al 76]. 3. HALFTONING Ihe existenee 
of only two levels to be used in the display of con­tinuous-tone images introduces visual artifacts, 
often manifested as false contours separating regions of different levels. Dithering alleviates this 
problem by properI y controlling the dktribution of bilevel intensities over the displayed image. The 
dithering process is based on psychophysical characteristics of the human visual system. The eye integrates 
luminous stimuli over a solid angle of about 2 degrees [Wyszecki et al 82]. This means that we actually 
see the average intensities corresponding to small solid angles in our visual field. Dithering algorithms 
exploit this phenomenon, effectively redistributing the state of pixels in such a way that the average 
intensity in small areas of the dithered image is approximately the same of the original gray scale image. 
Given a pixel P of the image with intensity I(P), it will be mapped into a pixel P of the dithered image 
whose intensity l(p ) is O or 1. The value of /(P ) is obtained by comparing the intensity I(P) with 
a given intensity threshold /0. The difference /(P) f(P ) is the quarttiza[ion error for the pixel P. 
In general, given a region of the image with N pixels, PI, P2 ,..., P~, N+l intensity levels can be represented 
by turning these pixels on and off . The quantiza­tion error for this region is the difference j=l j=i 
 between the sum of intensities of the gray scale image in the region and the sum of the intensities 
of the corresponding region in the dithered image. Dithering algorithms distribute the error over small 
neighborhoods of the image in such a way that the average quantization error is as close to zero as possible. 
There are two main strategies to define the states of the pixels on the dithered image in order to achieve 
this goal. One of them perturbs the intensity threshold 10 in a predefine way, so that the error is statistically 
neglectabl~ the other strategy perturbs the threshold for a pixel P based on the quantization error in 
a neighborhood of P, obtaining an exact min­imization of the error. In both cases, the perceived intensity 
of the dithered image at a given neighborhood will be close to that of the original image. This technique 
implies in a trade-off between spatial and tonal resolution: as we spread the error over larger areas 
of the image, more tones can be represented at the cost of a poorer rendition of fine details. The gray 
levels are rendered as patterns of black and white pixels eliminating high frequency information. In 
this process contouring artifacts are transformed into patterning fea­tures. 3.1 DITHERING TECHNIQUES 
Spatial dithering techniques can be classified according to the na­ture of patterns they generate and 
to the type of pixel configuration they prcxluce. These two criteria capture the main features of the 
textures created to represent areas of uniform gray, one of the most important aspects of the halftoning 
process. Textures can be rendered by periodic or aperiodic patterns. In general, periodic patterns are 
generated by deterministic processes based on regular sampling grids. Aperiodic patterns are generally 
associated with methods that cart be modeled as stochastic proces­ses. The type of pixel configuration 
produced is determined by the spa­tial distribution of the on or off state of the image elements. Dispersed-dor 
methods depict a gray level by covering a small area with evenly distributed dots, while clustered-dot 
methods concentrate the dots in small groups. 3.2 PREVIOUS WORK The most popular halftoning method is 
the ordered dither techni­que. h uses a deterministic perturbation to generate periodic pat­terns, and 
according to the distribution of perturbations it can produce dispetxd or clustered dots. Other important 
methods are the error diffusion techniques. The well known algorithms in this category are the Floyd-Steinberg, 
and Knuth s dotdiffusion algo­rithm. They generate aperiodic patterns as the result of neighbor­hood 
operations. All published error diffusion algorithms fall into the dispersed-dot category. The ordered 
dither algorithm determines a matrix of quantization thresholds that is replicated over the image. This 
is essentially a set of pseudo-random numbers uniformly distributed over the in­tensity range. The arrangement 
of thresholds is designed to avoid the introduction of low spatial frequency noise into the image. This 
algorithm is generally identified as a dispersed-dot technique [Limb 69], but if the intensity threshold 
levels are spatially con­centrated it results in a c1ustered-dot dithering. @@ The F kyd-.$[einherg 
algorithm [Floyd et al 75] computes the quantization error incurred in one image element and propagates 
it to the neighbors to the right and below. In this way, the local quan­tization error is distributed, 
minimizing globally the intensity dif­ference between the original and quantized images. The dot diffu.$ion 
algorithm [Knuth 87] combines some charac­teristics of ordered dither and error diffusion techniques. 
Similarly to ordered dither it uses a matrix that is replicated over the entire image. This matrix gives 
the order by which the quantization error in one display cell will k distributed among its neighbors 
in the cell. A comparison between dithering algorithms can be found in the survey [Jarvis et al 76]. 
A comprehensive study of dithering tech­niques with an analysis of the statistical properties can be 
found in [Ulichney 87]. We propose a digital halftoning method based on space filling cur­ves, which 
uses the path of the curve to distribute the quantization error over the image. Witten and Neal [Witten 
et al 82] also described a dispersed-dot dithering algorithm that propagates the quantization error along 
a Peano curve. Our technique parametrizes the dot aggregation factor allowing a precise control of the 
cluster size, which can vary in one pixel steps, This is the first algorithm that effectively unifies 
the dis­persed and clustered-dot techniques. When the cluster size is one pixel it reduces to a dispersed-dot 
dithering using error diffusion. Therefore. Wltten and Neal s algorithm is a particular case of our method. 
As mentioned before, a large class of hardcopy devices cannot reproduce well configurations of sparse 
on and off pixels. For this reason, most page description languages employ clustered-dot ordered dithering, 
as the standard halftoning method [Adobe 85]. The method presented in this paper offers an altern­ativesolution 
to the halftoning problem. It works very effectively in graphic displays as well as in hardcopy devices, 
and has potential applications in higher resolution printing. 4. SPACE FILLING CURVES A continuous p/ane 
nine is a continuous map C:1+R2 from the unit interval / = [0. I ] of the real line to the two-dimensional 
euclidean plane Rz = (.],y) ;.r,y . RI. The image c(l) is called the fratv of the curve C. A space j71/ing 
rune is a continuous curve such that its trace covers the unit square / 2 = [0, 1] x [0, I ] of the plane. 
Therefore, for each point f in the square 12 there exists a real number I in the interval / such that 
c(r) = P. Intuitively, this means that the curve provides an ordered way to visit all points of the square 
as the parameter r moves from O to 1. Space filling curves were first discovered by the Italian mathe­maticimr 
Giuseppe Peano in 1890, and they constitute the first ex­amples of the mathematical objects that Benoit 
Mandelbrot called fractal sets [Mandelbrot 77]. The mathematical construction of a space filling curve 
c is done as a limiting process. We consider a sequence c~:I+l 2 of curves in the unit square, and we 
define c as the limit c = Iim c,] n+=­ when this limit exists. The curves c~ constitute approximations 
of c, and as we increase n it visits a greater number of points in the unit square. It is possible to 
construct space filling curves for which each curve c,, is simple, i.e. the map is I 1. This means that 
Computer Graphics, Volume 25, Number 4, July 1991 it does not visit a point in the square more than once. 
In general it is possible to construct the sequence c1, c2,, ... c~,... of ap­proximating cumes in a 
recursive way. In a certain sense a space filling curve defines a relationship between the area of subregions 
of the unit square 12 and the length of subintervals of the unit in­terval /. 4.1 COMPUTATIONAL METHODS 
 Space filling curves can be properly specified by a formal geometric language. Sentences in this language 
are defined by a parallel graph grammar, and they are constructed by recursively applying a set of rewriting 
rules. Each sentence corresponds to a curve c. from the approximating sequence of the space filling curve. 
We will refer sometimes to this approximation itself as a space tilling curve. A dismssion about computational 
methods to generate space filling curves can be found in [Prusinkiewicz 90]. 4.2 CLASSIC CURVES The 
classic space filling curves are the Peano curve, the Hilberf cun e, and the Sierpinsky curve. Figure 
2(a)(b)(c) shows art ap­proximation of these curves. All curves in the approximating se­quence of these 
curves are simple. 4.3 IMAGE SCAN When each curve C. in the approximating sequence of a space fill­ing 
curve is simple, we obtain a method to visit, in a unique and ordered way, a subset of points of the 
square. The number of points visited increases as we increase the value of n. If we con­sider the square 
grid defined by the pixels of a raster image it is possible to address uniquely all pixels using a simple 
approximat­ing curve c~ of a space filling curve. Therefore, these curves con­stitute an effective method 
to scan a raster image. This idea has been exploited in the field of Digital Image Processing [Km-Yan-Too 
88], I.Stevens et al 83]. The scan method described above has several advantages over the traditional 
scarrline method for some class of image operations. The recursive nature of the construction of space 
filling curves allow a subdivision of the image into regions where each region is mapped to some subinterval 
of the unit interval f. This implies in a certain sense a reduction of the dimensionality of the problem, 
and simplifies immensely algorithms that deal with small regions of the image, as well as the computations 
involved. The path followed by the space filling curve results in an image scan free of directional features 
presented by the traditional scan-Iine raster pattern. 5. APERIODIC CLUSTERED-DOT DITHERING The digital 
halftoning method using space filling curves exploits the properties of these mathematical objects to 
perform neighbor­hood operations essential to the spatial dithering process. This sec­ tion presents 
the overall structure of the methcd and describes in detail its main aspects. 5.1 THE METHOD The method 
consists of the following steps:  . Subdivision of the source image into small regions based on the 
trace of the space tilling curve; . Computation of the average intensities of each region;  . Determination 
of the dot patterns of the dithered image cor­responding to each intensity;  (c) Figure2 Approximationsof:(a)Peano,(b)Hilberi,(c)sierpinsldspace 
fillingcurves. 5.2 IMAGE SUBDIVISION Tire method takes advantage of some properties of space filling 
curves that allow a subdivision of a raster image into regions with desirable characteristics. Let cn:I+f 
2 be an approximation of a space filling curve c that visits uniquely all pixels of the image. Let 11,12, 
.... f. be a subdivision of the unit interval I into n sub­intervals. By restricting the ctme c~ to each 
subintemd /j we ob­tain n subregions RI, R2, .... R. of the image. The size of each region Rj varies 
proportionally with the length of the correspond­ing subhtervaI lj. This gives an ordered way to visit 
all regions Rj, and also to visit all points in each of these regions. Besides this, the restriction 
cj:lj+Rj is by itself a space filling curve, that is a scaled version of the original curve c, because 
of the self­simikrrity properties of the space tilling curves. This characteristic minimizes the grid 
effect often manifested in dithering methods that use standard methods of image scan. 84 5.3 DOT GENERATION 
The dot generation strategy is a direct consequence of scanning the image with a space filling curve. 
The objective is to produce, for a given region, a configuration of clustered dots that will result in 
a perception equivalent to the intensity of the original image. This depends on the area of the region, 
the average intensity over the region, and the graphic device s physical reconstruction func­tion. As 
described above, the trace of the space filling curve determines a relationship between the area of the 
region and the length of the curve. Suppose that the average intensity of a region R is 1. Ideally, the 
desirable perceptual results would be obtained by partitioning R=RIUR2 into two subregions RI of white 
pixels, and R2 of black pixels, such that RI corresponds to a subinterval of length propor­tional to 
I and R2 corresponds to a subinterval of length propor­tional to 1 1. In practice, this subdivision cannot 
be done exactly because there is a discretization process involved that is influenced by the physical 
characteristics of the output device. The graphics output device is able to display only a discrete num­ber 
of fixed size dots at a determined resolution. In general, the shape of the dot is not completely regukw, 
and there is some over­lapping between contiguous dots. This fact implies in a degree of non-linearity 
in the reconstruction function. As mentioned in Sec­tion 2, it is possible to account for the device 
s non-linear response by means of an independent preprocessing step. The dot configuration produced by 
the space filling curve method results in an aggregate of pixels connected not only sequentially by the 
curve, but also in other directions because of the inter­twined way the space filling curve traces the 
region. Consequently, the cluster of dots obtained is confined within the limits of a ball that has an 
area close to the area of the region. As a whole, the pat­terns generated by this type of dots are evenly 
distributed but not peritilc. In order to account for the fine details of the image, it is desirable 
that the dot configuration grows outwards from the point of highest intensity of the region. This can 
be accomplished by centering the white subregion with a proper translation of the cor­responding subhrterval. 
Figure 3 illustrates clusters of dots corresponding to intensities 15/1 6 to O for the Hilbert curve, 
in a region of 4x4 pixels. In Fig­ure 4 we used the method to render a black to white gradation using 
different sizes for the dot aggregation. 5.4 ERROR DIFFUSION The discrete nature of the reproduction 
prccess, as we have seen, may result in quantization errors. This error can k propagated along the path 
of the space filling curve in order to minimize the total quantization error. This is similar to the 
disprsed-dot error diffusion dithering techniques, but works on display cells of more than one pixel. 
6. IMPLEMENTATION The halftoning method presented in this paper was developed under the VISGRAF project, 
as part of an image processing system in the Computer Graphics laborato~ at IMPA. The computing environment 
is integrated by a network of Sun workstations and the primary graphics hardcopy devices are 300 dpi 
Postscript laser printers. Computer Graphics, Volume 25, Number 4, Julv 1991 The algorithm was implemented 
using the C language in the Unix operating system. 6.1 SCAN LIBRARY The image scan pattern generation 
is implemented by a library of functions with a common interface. This simplifies the addition of new 
types of space filling curves to the dithering operation, and encourages experimentation. The library 
s front-end consists of two functions. The first one selects the curve to be used for the image scan 
and, if necessary, executes initialization and setup procedures. The second function moves forward and 
backwards along the path incrementally returning the coordinates of image points to be visited. It should 
be called once for each element processed. 6.2 ALGORITHM The pseudo-code below gives a description of 
the basic algorithm. R is the maximum pixel intensity (255 for images with 8 bits of resolution), and 
N is the cluster size in pixels. Select image scan curve ; Initialize intensity accumulator ; While (image 
elements to be processed ) [ Advance image pointer along the scan path to the end of interval ; Move 
backward N pixels, accumulating the intensity of the input image ; Move forward N pixels along the path, 
setting the output pixels : Figure 3 -Configuration of dots corresponding to intensity levels 15116 to 
0, for a cluster of 16 pixels using the Hilbert space filling curve. if ( accumulator = R ) then ( decrement 
R from accumulator set output pixel on ; ; I eke 1 set output pixel ofs ; I ,.,.... p-., . . .. r:+. 
y.<. Note that the algorithm implicitly accounts for the quantization error, propagating it along the 
path. . ,;.e!.:. .. ... .. ..y ,. . i........ . : ,(;-$:!.,;,.:. The processing structure of the algorithm 
allows the same buffer y:p;;;;:,..,. ;...i. , to be used for both input and output image. <*::y;,..: 
,..< /..,..;.. i .: . -;z.;...! , , ., i. ., I: . 7. RESULTS Although the method works well in low resolution 
devices, the clustered-dot dithering using space filling curves is primarily in-tended for medium to 
high resolution bilevel devices that cannot accommodate isolated black or white pixels. For this reason, 
the tests of the method were performed using a 300 dpi laser printer as the graphics output device. 7.1 
EXAMPLES Two different images were chosen as representatives of the com-mon types of pictures in graphics 
applications. The first image, Figure 5, was captured from a black and white photographic reproduction 
of a study for the mural painting, Escola dos Jesuitas , by the Brazilian artist Candid0 Portinari. This 
drawing Figure 4 -Stripes with gradation dithered with the space filling curve of an indian boy head 
was done using charcoal, red ocher and algorithm (Hilbert curve) using different cluster sizes. From 
top to bottom, sepia on paper, and dates from 1938. The image was digitized clusters of 2, 6, 12,20,32,60 
and 120 pixels. using a 300 dpi, 8 bits gray scale scanner. The second image is a 85 Figure 5 - Digitized 
test image: A drawing by the Brazilian artist Candid0 Pottinari (1938). computer generated image designed 
to include a wide range of Figure 8 (A), (B) and (C) shows halftoned versions of the two im-features. 
It consists of a circular gradation inside a disc over a ages processed respectively by the space filling 
curve, the Floyd- background with horizontal bands. Both images contain areas of Steinberg and the clustered-dot 
ordered dither algorithms. They smooth intensity variation as well as areas of high contrast and were 
included to compare the results of the new method with both fine detail. a standard error-diffusion technique 
and with the clustered-dot method used in most hardcopy devices. For the last comparison In the preprocessing 
step, only tone scale adjustment was per-we used a 8x8 matrix in the clustered-dot ordered dither and 
a formed prior to the halftoning operation. We decided not to do any cluster size of 32 pixels in the 
space filling curve dither. These edge enhancement in order to have a better feeling on how the al- choices 
produce clusters of approximately the same size. Before gorithm handles fine details. dithering the two 
images were scaled down to 75 dpi. Figures 6 and 7 illustrate the clustered-dot dithering algorithm 7.2 
ANALYSIS using Hilbert s space filling curve. The clustering size was of 11 pixels. Before dithering 
the two images were scaled down to 150 The space tilling curve dithering algorithm generates aperiodic 
dpi. By increasing the viewing distance we can simulate the be-patterns of evenly distributed dots without 
directional artifacts. It haviour of the algorithm in higher resolution. renders well the gray levels, 
and captures the fine details. These  Figure 7-Computer generated picture at 150 dpi dithered with 
the space filling curve algorithm (Hilbert curve), using clusters of 11 pixels. allowing the image rendition 
to match precisely the limits of the physical reconstruction function of the display device. The algo-rithm 
is computationally efficient requiring only 1 addition, 1 sub- traction and 1 comparison per image element 
processed. The main drawback of the algorithm is its high memory require-ment, since it buffers the entire 
image because of its non-standard access pattern. This is probably not a serious restriction, except 
for very high resolution images. In this case, the problem can be ad- dressed in two ways: the image 
can be subdivided in small blocks, and the algorithm is performed more or less independently in each 
one. This requires buffering of small strips of the image. Another solution is to store the image in 
a non-standard way such that its structure favors the access pattern. This is discussed by Blinn in the 
context of texture mapping [Blinn 901. One inherent limitation of the method is that it is not truly 
bidimensional. For this reason, the error propagation is not totally uniform. This weakness is shared 
to some extent with all the pub- lished dithering techniques. The error diffusion can be cast as an equilibrium 
problem, which can be solved by relaxation techni-ques, such as simulated anealling [Kirkpatrick et al, 
19821, [Fiume 891. The computational effort required for an accurate solution is very expensive and has 
not yet been tried for this type of applica- tion. 8.2 FUTURE RESEARCH Future work includes the extension 
of the method to process full color images, experiments with higher resolution graphics devices and the 
investigation of adaptive clustering techniques. @aComputer Graphics, Volume 25, Number 4, July 1991 
w.-,: ,/ . (4 , (W ................ ................ ........ ...................... ............. 
 ........................... ...................................  Figure 8 - The two test images at 
75 dpi dithered with three different algorithms: (A) Space filling curve algorithm (Hilbetl curve), using 
clusters of 32 pixels; (B) Floyd-Steinberg algorithm; (C) Clustered-dot ordered dither algorithm, using 
a matrix of order 8. The method has also a potential to be used for illustration pur-poses. Other kinds 
of rendering effects can be obtained by a com- bination with image processing techniques. An example 
of this process, simulating pen-and-ink drawing, is shown in Figure 9. 9. ACKNOWLEDGEMENTS The authors 
would like to thank Jogo Candid0 Portinari, and Por- tinari Project s team for kindly providing the photographic 
reproduction of the study for the indian boy head. We also ap preciate the helpful and encouraging comments 
provided by the reviewers. . 10. REFERENCES Adobe Systems, (1985): Postscript Language Reference Manual. 
Addison-Wesley, Reading Massachusetts. Blinn, J. (1990): The Truth About Texture Mapping. IEEE Com-puter 
Graphics and Applications, March 1990,78-83. Catmull, E. (1979): A Tutorial on Compensation Tables. Proceed-ings 
SIGGRAPH 79, in Computer Graphics, Vol. 13, l-7. Fiume, E. and Ouellette, M. (1989): On Distributed Probabilistic 
Algorithms for Computer Graphics. Proceedings of Graphics Interface 89,211-218. Floyd, R. and Steinberg, 
L., (1975): An Adaptive Algorithm for Spatial Gray Scale. SID Symposium, 1975,36-37. Geist, R. and Reynolds, 
R. (1990): Colored Noise Inversion in Digital Halftoning. Proceedings of Graphics Interface 90, 3 l- 
38. Jarvis, J., Judice, C. and Ninke, W., (1976): A Survey of Techni- ques for The Display of Continuous 
Tone Pictures on Bilevel Displays. Computer Graphics and Image Processing, n. 5, 13- 40. Kirkpatrick, 
S., C. D. Gelatt Jr., and M. P. Vecchi, (1982): Op-timization by Simulated Annealing, IBM Research Report 
RC 9355. Knuth, D., (1987): Digital Halftones by Dot Diffusion. ACM Transactions on Graphics, V. 6 N. 
4,Oct 1987,245-273 Koo-Yan-Too, H. C., (1988): A Peano Scan Approach to Multi- variate Data Clustering, 
with an Application. Master Thesis, Dept. C. S., Univ. of Regina. Limb, J. O., (1969): Design of Dither 
Waveforms for Quantized Visual Signals. Bell Systems Technical Journal, v. 48, n. 7, 2555-2582. Mandelbrot, 
B., (1977): The Fractal Geometty of Nature. W. H. Freeman, New York Prusinkiewicz P., and A. Lindenmayer 
(1990): The Algorithmic Beauty of Plants. Springer-Verlag. New York. Sonnenberg, H., (1983): Designing 
Scanners for Laser Printers. Lasers &#38; Applications, April 1983,67-70. Stevens, R. J., Lehar, F. A. 
and Perston, E H. (1983): Manipula-tion and Preservation of Multidimensional Image Data using the Peano 
Scan. IEEE Trans. on Pattern Analysis and Machine Intelligence, 5,520-526. Ulichney, R., (1987): Digital 
Halftoning. MIT Press, Cambridge Massachusetts. Witten, I. H., and Neal, M., (1982): Using Peano Curves 
for Bilevel Display of Continuous Tone Images. IEEE Computer Graphics and Applications, May 1982,47-52. 
Wyszecki, G. and Stiles, W. (1982): Color Science: Concepts and Methods, Quantitative Data and Formulae. 
Second edition. John Wiley &#38; Sons. Figure 9 - A pen-and-ink drawing effect obtained using image processing 
and the space filling curve dithering.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122728</article_id>
		<sort_key>91</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Efficient antialiased rendering of 3-D linear fractals]]></title>
		<page_from>91</page_from>
		<page_to>100</page_to>
		<doi_number>10.1145/122718.122728</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122728</url>
		<abstract>
			<par><![CDATA[Object instancing is the efficient method of representing an hierarchical object with a directed graph instead of a tree. If this graph contains a cycle then the object it represents is a linear fractal. Linear fractals are difficult to render for three specific reasons: (1) ray-fractal intersection is not trivial, (2) surface normals are undefined and (3) the object aliases at all sampling resolutions.Ray-fractal intersections are efficiently approximated to sub-pixel accuracy using procedural bounding volumes and a careful determination of the size of a pixel, giving the perception that the surface is infinitely detailed. Furthermore, a surface normal for these non-differentiable surfaces is defined and analyzed. Finally, the concept of antialiasing "covers" is adapted and used to solve the problem of sampling fractal surfaces.An initial bounding volume estimation method is also described, allowing a linear fractal to be rendered given only its iterated, function system. A parallel implementation of these methods is described and applications of these results to the rendering of other fractal models are given.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[covers]]></kw>
			<kw><![CDATA[fractal]]></kw>
			<kw><![CDATA[object instancing]]></kw>
			<kw><![CDATA[procedural modeling]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Fractals</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Hierarchy and geometric transformations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Visible line/surface algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010377</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Visibility</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010244</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Hierarchical representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40023957</person_id>
				<author_profile_id><![CDATA[81100123210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electronic Visualization Laboratory, University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15032129</person_id>
				<author_profile_id><![CDATA[81100432746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[DeFanti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electronic Visualization Laboratory, University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BARNSLEY, M. F., ERVIN, V., HARDIN, D., AND LANCASTER, j. Solution of an inverse problem for fractals and other sets. Proceedings of the National Academy of Science 83 (April 1986), 1975-1977.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378502</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BARNSLEY, M. F., JACQUIN, A., }~{AL- LASSENET, F., RUETER, L., AND SLOAN, A. D. Ilarnessing chaos for image synthesis. Computer Graphics 22, 4 (1988), 131-140.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15918</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[BARR, A. H. Ray tracing deformed surfaces. Computer Graphics 20, 4 (1986), 287-296.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325176</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BOUVILLE, C. Bounding ellipsoids for rayfractal intersection. Computer Graphics 19, 3 (1985), 4 5-51.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325245</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[DEMKO, S., tIot)6ES, L., AND NAYLOR, B. Construction of fractal objects with iterated function systems. Computer Graphics 19, 3 (1985), 271-278.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74363</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[HART, J. C., SANDIN, D. J., AND KAUFFMAN, L. It. Ray tracing deterministic 3-D fractals. Computer Graphics 23, 3 (1989), 289-296.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[HEPTING, D., PRUSINKIEWICZ, P., AND SAUPE, D. Rendering methods for iterated function systems. In Proceedings of Fractals '90 (1990), IFIP.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[HUTCHINSON, J. Fractals and self-similarity. Indiana University Mathematics Journal 30, 5 (1981), 713-747.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J AQUIN, A. E. Image coding based on a fractal theory of iterated contractive image transformations. Preprint, 1990.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357324</ref_obj_id>
				<ref_obj_pid>357323</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[KAJIYA, J. T. New techniques for ray tracing procedurally defined objects. A CM Transactions on Graphics 2, 3 (1983), 161-181. Also appeared in Computer Graphics 17, 3 (1983), 91-102.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15916</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[KAY, T. L., AND KAJIYA, J. T. Ray tracing complex scenes. Computer Graphics 20, 4 (1986), 269-278.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[MANDELBROT, B. B. The Fractai Geometry of Nature, 2nd ed. Freeman, San Francisco, 1982.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[MITCHELL, D. P., Summer 1990. personal communication.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[MITCHELL, D. P., AND AMANATIDES, J. Megacycles. SIGGRAPH Video Review 51 (1989), #14.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801263</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[NORTON, A. Generation and rendering of geometric fractals in 3-D. Computer Graphics 16, 3 (1982), 61-67.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[PORTER, T., AND DUFF, T. Compositing digital images. Computer Graphics 18, 3 (1984), 253-259.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[PRESS, W. H., FLANNERY, B. P., TEUKOL- SKY, S. A., AND VETTERLING, W. T. Numerical Recipes in C. Cambridge University Press, 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617540</ref_obj_id>
				<ref_obj_pid>616010</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[PRUSINKIEWlCZ, P. About the cover: Exploring the beauty of plants. 1EEE Computer Graphics and Applications 10, 2 (March 1990), 3-6.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83596</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[PRUSINKI~.WlCZ, P., AND LINDENMAYER, A. The Algorithmic Beauty of Plants. Springer- Verlag, New York, 1990.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807479</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[ROBIN, S. M., AND IVHITTED, T. A 3- dimensional representation for fast rendering of complex scenes. Compuler Graphics 14, 3 (1980), 110-116.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[SHANNON, C. E. Communication in the presence of noise. Proceedings of the Institute of Radio Engineers 37, 1 (January 1949), 10-21.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37408</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[SHINYA, M., TAKAIIAStlI, T., AND NAITO, S. Principles and applications of pencil tracing. Computer Graphics 21, 4 (1987), 45-54.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37417</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[SNYDER, J. M., AND BARR, A. H. Ray tracing complex models containing surface tessellations. Computer Graphics 21, 4 (1987), 119-128.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[STRANG, G. Linear Algebra and its Applications, 3rd ed. Harcourt Brace Jovanovich, 1988.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>810742</ref_obj_id>
				<ref_obj_pid>800265</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[SOTHERLAND, I. E. Sketchpad: A man-machine graphical communication system. Proceedings of the Spring Joint Computer Conference (1963).]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>72531</ref_obj_id>
				<ref_obj_pid>72527</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[THOMAS, D., NETRAVALI, A. N., AND FOX, D. S. Antialiased ray tracing with covers. Computer Graphics Forum 8, 4 (December 1989), 325-336.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>93110</ref_obj_id>
				<ref_obj_pid>93023</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[VRSCAY, E. R., AND ROEHRIG, C. J. Iterated function systems and the inverse problem of fractal construction using moments. In Computers and Mathematics (New York, 1989), E. Kaltofen and S. M. Watt, Eds., Springer-Verlag, pp. 250- 259.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Efficient Antialiasecl Rendering of 3-D Linear 
Fractals John C. Hart Thomas Electronic Visualization University of Illinoisan A. DeFanti Laboratory 
Chicago Abstract Object instancing is the efficient method of representing an hierarchical object with 
a directed graph instead of a tree. If this graph contains a cycle then the object it rep­resents is 
a linear fractal. Linear fractals are diff~cult to render for three specific reasons: (1) ray-fractal 
intersec­tion is not trivial, (2) surface normals are undefined and (3) the object aliases at all sampling 
resolutions. Ray-fractal intersections are efficiently approximated to sub-pixel accuracy using procedural 
bounding volumes and a careful determination of the size of a pixel, giv­ing the perception that the 
surface is infinitely detailed, Furthermore, a surface normal for these non-differentiable surfaces is 
defined and analyzed. Finally, the concept of antialiasing covers is adapted and used to solve the problem 
of sampling fractal surfaces. An initial bounding volume estimation method is also described, allowing 
a linear fractal to be rendered given only its iterated function system. A parallel implemen­tation of 
these methods is described and applications of t}iese results to the rendering of other fractal models 
are given. CR Categories and Subject Descriptors: 1.3.5 [Computer Graphics]: Computational Geometry and 
Ob­ject Modeling Hierarchical and geometric transforn~a­tions. 1.3.7 [Compntcr Graphics]: Three-Dinlensional 
Graphics and Realism Color, shading, shadowing and texture; visible surface algorithms. General Terms: 
Algorithms, Theory. Additional Key Words and Phrases: covers, fractal, object instancing, procedural 
modc]ing, ray tracing. Author s current address: EU, EECS Dept. hi/C 154, UIC, Chicago, 11,60680-4348. 
E-mail: hart@ uicbert.cccs. nic.edu Permisswn 10 copy without fee all ur part of this material is granted 
provided lhalthe copies areno( made ordistribute dfurdirect commercial ~dvwrtagc, the ACM copyright rrodcc 
and ihe ti[lc of the publicationand itsdateappear,and notice is given that cnpyirrg is by frernlission 
ot tbe Association for Cumputing Machinery. To cnpy otherwise. or[orcpublish, requires J fee and/nr specilic 
permission.  1 Introduction The use of bounding volumes has greatly increased the efficiency of ray 
tracing, particularly when they are organized hierarchically as a tree. By modeling objects canonically 
and using relative positioning at each node in the tree hierarchy, then subtrees denot­ ing the same 
objects at different places in a scene are redundant. One subtree would suffice in this case but its 
root node would have more than one parent in the hierarchy. The tree is condensed into an acyclic directed 
graph, a process called object instancing. This paper investigates and solves the problems that arise 
when this directed graph is allowed to be cyclic, representing a linear fractal. 1.1 History Object instancing 
is an old technique, first used in Ivan Sutherland s Sketchpad [25]. It was first used for ray tracing 
in [20] as a method of reducing the size of object databases. In [20], the city of Pitts­ burgh (38,000 
primitives) was rendered efficiently us­ing little memory by storing only 600 actual primi­tives. Of 
particular interest was their treatment of hi-parametric surfaces. Using convex hull and subdi­vision 
properties, they were able to create a hierarchy of bounding boxes procedurally during ray intersec­tion. 
At a fixed terminal level of the hierarchy, these bounding boxes were treated as point primitives. Object 
instancing of fractal objects was first dis­cussed in [10] where procedural cheesecake extents (extruded 
triangles) hierarchically bounded a fractal mountain. A later improvement used bounding ellip­soids [4]. 
One ray-traced fract al mountain mesh con­taining 262,144 primitives was shown in [10] and two fractal 
mountains appeared in [4] where the number of primitives was not listed. Parallelepipeds were used as 
bounding volumes in [1 I]. They also maintained a heap of intersected bounding volumes rather than a 
list which improved the first-hit computation time complexity from O(n) to O(log n). Using these tighter 
bounding volume hi­ erarchies, a forest of trees (over 110,000 primitives) (!1991 ACM-()-89791$(X).75 
91 -436-89I/KK}7/C091  Ji!!!$k AAAAAAA AA A (a) (b) (c) (d) (e) Figure 1: Hierarchical model topologies 
and corresponding images: (a) tree hierarchy; (b) object instancing hierarchy; (c) recursive object described 
by both tree with cycles; (e) linear fractal described bycyclicdigraph surrounding a cement pond was 
rendered. In [23], bounding boxes were used aa well as both list and 3-D grid structures of objects. 
All this plus fast triangle and bounding box intersection routines enabled the authors to ray trace a 
carpet (125,000 primitives), a forest (2 billion primitives) and the still unsurpassed field of grass 
(over 400 billion primi­tives). Most recently, object instancing was used in an ani­mation of a multitude 
of robots cycling along a plane­!Nling fractal curve [14]. Also, some have modeled linear fractal shapes 
using tiny spheres [18, 7, 13] but their ray-tracing programs (Craig Kolb s rayshade and Don Mitchell 
s FX ), though optimal for many other shapes, Iilmited the renderable resolution of these linear fractal 
models. 1.2 Overview When an object-instancing directed graph is allowed to cycle, the object it describes 
may be infinitely de­tailed, in other words, fractal. This causes three dis­tinct problems when rendering 
such a model: 1. Intersection of a ray with a fractal sur­face is not trivial. There is no simple equation 
whose solution is the first intersection of a ray with the infinite geometry of a fractal surface. 2. 
Surface normals are undefined. A surface normal is orthogonal to the surface s derivative. The derivative 
of a fractal surface is undefined because its differentials do not converge as their span decreases. 
 3. The object aliases at all san>pling resolu­tions. Fractal surfaces have infiiite ~etail and thus 
require infinitely high sampling frequencies to avoid aliasing.  Problem 1 is solved in Sec. 3, where 
the ray­bounding volume intersections form a sequence 92 (a) and acyclic digraph (b); (d) object instancing 
hierarchy (d). through the bounding volume hierarchy that con­verges to the ray-fractal intersection. 
Ray-fractal in­tersections are approximated to a perceived infinite level of recursion by allowing objects 
to cycle until their projected image is smaller than a pixel. The closeness criterion from [3], also 
called clarit y in [6], is rederived here in Sec. 3.1 and used to find the size of a pixel at a specific 
distance from the view­point. Furthermore, the use of bounding volumes for linear fractals is justified 
in Sec. 2. Surface normals have been approximated for fractal surfaces using neighboring Z-buffer values 
[15] and gradients [6]. Problem 2 is solved in Sec. 4 by defining the fractal surface normal hierarchically 
as a weighted sum of surface normals across scale. Three weighting functions are described, illustrated 
and analyzed. The concept of antialiasing covers is an object­space sampling method that uses single 
pixel thick bounding volumes [26]. This method arbitrary bounding volume hierarchies solves Problem 3, 
antialiasing rendered using only one sample per pixel. Another problem is the specification initial bounding 
volume. Many times, is extended to in Sec. 5 and fractal images of an efficient fractal shapes are specified 
without any prior knowledge of what they will look like. An iterative method is derived in Sec. 3.3 that, 
given an iterated function system, produces a bounding sphere that contains the fractal shape it described. 
The result is a ray tracing method that renders a linear fractal described only by its IFS. 2 Linear 
Fractals Linear fractals are shapes that from finitely many smaller affine The Cantor set and Sierpinski 
s introductory examples of linear linear fractal models have been can be constructed copies of themselves. 
gasket [12] are good fractal shapes. Other useful for texturing [5], image synthesis [2] and natural 
modeling [19]. @ @ Computer Graphics, Volume 25, Number 4, July 1991 2.1 Iterated Function Systems A 
linear fractal can be specified by an iterated func­tion system (II S for short) consisting of a finite 
set of contractivc affhle maps (denoted Wio, i = 1 . . . N) [8]. An afhe map w : R + R3 can be specified 
by the popular homogeneous 4 x 4 matrix so long as its fourth column is (0,0,0, 1)~. This map is contractile 
if and only if there exists an s E [0, 1), called the con fraclivity ~actor, such t,hat Iw(x) w(y)l 
< SIX VI Vz, g E R3. (1) For example, if an afline map w is a similtudel spec­ified by a 4 x 4 homogeneous 
transformation matrix then the contractility factor s of w is the cube-root of the determinant, of its 
upper-left 3 x 3 submatrix. The contractility factor s of an IFS, {ll)i}~l, is given t)y s = Inax St 
(2) i where Si is the contract ivit.y fact,or of map V)l. The Ifutchinson opera tor-, w, on agiven set 
~ is defined as Iv w(A) = (J ~~i(ii). (3) i=l Using it, we can define the set A, called the atlracior 
of the ll;S, as the Illliqllc solution of A = W(A). (4) The attractor is so named because other sets 
will transform to it after repeated applications of the maps of an IFS. Specifically, A = ,~~~ W (A) 
(.5) where w ~ is the n-fold colnposit, ion of w and .4 is any bounded non-empty set in R3. 2.2 The Inverse 
Problem Currently, many rcscarcllcrs are trying to solve the inverse problem, that is, to develop an 
automatic method for finding an IFS t Ilat will generate a given sflape. One step tolvard solving this 
problem is the Col­lage Theorem [1]. The Collage Theorem states that if a shape can be vague]y tiled 
out of smaller self­replicas, then it can be modeled approximately by an IFS. The Inaps of the IFS are 
jllst the transforma­t ions that t alie the whole t o CilCll d its smaller self­replicas. It, provides 
tllc insight required to model a given s]lape as a linear fract,al. 1112-T), the solution to the inverse 
problem can be IISC(J to co]ni)rcss image dat, a. III 3-11, it could com­press volumetric data, Current 
]ncthods for finding . . 1/1 .!imiltllde is tlIc composition of a rotation, a translation and a llniform 
scaling, these transformations in R2 have had limited success [27, 9] and appear to be extendable to 
R as well. If such a volumetric compression algorithm is devised, the methods described in this paper 
would be able to directly visualize compressed volumetric data.  2.3 A Theorem Justifying Bounding 
Volumes The Hausdorfrnetric h measures the distance between two subsets A and B of a bounded set in R3 
as2 It is basically the shortest distance of any point in B to the point in A farthest from B, plus the 
shortest distance of any point in A to the points in B farthest from A. Itis commonly used as a measurement 
of how similar two shapes appear. The following lemma is from [8] and was used in [1] to prove the Collage 
Theorem. Lemma: Let A and B be nonempiy, bounded subsets of R and let w be the Hutch inson operator of 
an IFS {~i]~l with confrac~iuity factors G [0, 1). Then h(w(A), w(B)) < sh(A, B). (7) . Its proof is 
from [1] and utilizes the definitions of contractility and Hausdorf distance to produce a chain of inequalities. 
Proofi h(w(A), w(B)) = ITITIib~lj l~i(a) Wj(b)l + ~~li ~~~j l~i(b) ~j(a)l (8) < max min l~i(a) wi(b)l 
+ a~A,i bEB ~~yi ~iy Iwi(b) ~i(a)l (9) < sh(A, B). 0 (lo) The Lemma is used to prove the following theorem, 
actually just a simple corollary, which shows that the bounding volume hierarchy used by the ray intersec­tion 
routine described in Sec. 3 is both valid (the union of bounding volumes contain the attractor at each 
level in the hierarchy) and efficient (the bound­ing volumes get tighter). Theorem: Let A be the attractor, 
and w be the Hutchinson operator, of an IFS {Wi}~l with contrac­tility factor s G [0, 1). Let B be a 
bounding volume of A. Then A C w(B) (11) 2In the original texts, the supremum and infinum ~ u~. However, 
since the attractor and its bounding volumes am com­pact, and thus closed, it is permissible to use the 
more common maximum and minimum. 93  @ 6 Comcwter GraDhics, Volume 25, Number 4, JUIV1991 max p(t) 
/ p(t) Figure 4: Pixel size geometry. Two particularly difficult situations can occur in the shadows 
of linear fractals. Both problems hap­pen when the resolution of a shadow differs from the resolution 
of the surface it is cast upon. The first case occurs when a linear fractal is illumi­nated from a distant 
light source, casting a shadow onto a surface near the linear fractal and the eye. If the light rays 
are cast from the light source, then the resolution of the shadows will be lower than the reso­lution 
of the surface. On the other hand, if the light rays are cast from the surface to the light source, then 
shadow s resolution will be greater than the surface s. The second case happens when the shadow of a 
dis­tant linear fractal near the light source is cast onto a surface inspected from a viewpoint somewhere 
be­tween the surface and the fractal. In this case, if the rays are cast from the light source then the 
resolu­tion of the linear fractal s shadow that will be higher than the resolution of the surface, Alternatively, 
if the rays are cast from the surface then the shadow s resolution is lower than the surface s. Let t, 
and tl be the distance from the eye to the surface and the distance from the surface to the light, respectively. 
If the rays are cast from the light source to the surface then the size of a pixel p{(t) at distance 
t from the lig}lt source, as shown in Fig. 5, is given by p,(t) = y t. (16) If the rays are cast from 
the surface to the light source, then the size of a pixel at distance t from the surface is (17) 3.1.3 
Reflect ion and Refraction Rays Planar reflection causes a new ray to be generated. The formula for 
the size of a pixel from this new ray origin almost always differs from the previous for­mula. The reflected 
size of a pixel is computed using a new viewpoint El found by reflecting the original view­point, denoted 
as Eo, across the plane P = (a, b, c, d). Let AI= (a, b, C)T be the unit, normal vector of plane ?u(tl) 
= P(L) Figure 5: Light ray pixel size geometry. Pandletx=Ro+ tRd be the point that ray R intersects plane 
P. The new viewpoint is then El = E() 21~ .(EII X)l~, (18) and the reflected size of a pixel is given 
by (t ) (t+ IRo-E,I), (19) r(t) = lRo -E,l where R. is the origin of the reflection ray and p(t, ) is 
the size of a pixel at the previous ray-plane intersec­tion point RO. The size of a pixel through a refracting 
plane can be derived similarly. Reflection and refraction from curved surfaces can change the size of 
a pixel dramatically. Convex re­flection will increase the size of a pixel whereas con­cave reflection 
can increase and decrease the size of a pixel. A ray tracing microscope is alluded to in [3] which could 
be constructed out of refractive solids. Nonetheless, the size of a pixel in each of these cases is still 
a linear function. Even so, derivation of the new viewpoints for curved reflective or refractive sur­faces 
is a difficult task and beyond the scope of this paper. See [22]. 3.2 The Contractility of an Affine 
Map Cycles in a linear fractal instancing graph are termi­nated when the bounding volumes are smaller 
than a pixel. In order to find the diameter of a bound­ing volume, the contractility of the affine map 
that instances the shape from its canonical form must be determined. A simple method for determining 
the contractil­ity factor of an affine map is to accumulate the con­tractility factors explicitly by 
storing an associated contractility factor with each map. As maps are composed, the contractivities are 
multiplied. This method is accurate only when every scaling transfor­mation is uniform in all three dimensions. 
A better method determines the diameter of the el]im.oid resultin~ from the affine transformation of 
a un(t sphere S. L~t A be the linear part of affine map w, specified by its upper-left 3 x 3 submatrix. 
Since A is a real, square and invertible, it can be factored A=QS (20) where Q is orthogonal (the rotation/inversion 
part) and S is positive definite (the scaling part), a process called Polar Decomposition [24]. Furthermore, 
S2 = ATA, (21) hence S2 is svmmetric and its ei~envalues Al, ~z, As can be found algorithmically using 
Jacobi Transfor­ mations [17]. T~us, the diameter-of the ellipsoid is found as o (22) 3.3 Initial Bounding 
Volume Determi­nation The initial bounding volume 1? does not need to con­tain the images of itself under 
the affine maps of the IFS. That is, w(B) g B. However it is necessary for d c 1?.If not, then A B will 
be chopped off along with all of its images, w(A B), w z(d B), .... This can be useful but, in general, 
this kind of fractal clipping is not desired and a suitable ini­tial bounding volume must be found. An 
iterative method that progressively refines an approximate bounding sphere given an IFS and an arbitrary 
initial sphere appears to work well. Let S be an approximate bounding sphere, (say, at the start, S = 
S, the unit sphere at the origin). Then the next sphere in the sequence, S , is found as (23) s; = max 
max la SJI, (24) i=l.,.N a~w, (s) where SO and S. are the origin and radius of sphere S and likewise 
for sphere S . Equation (24) may be approximated using the up­per bound3 max la YOl < llO:(So)-$l+ iam(~(s)) 
. (25) aEw, (S) When wi is a similtude then diam(wi(S)) = 2siS0 and the upper bound is always achieved. 
If not, then wi(S) is an ellipsoid, and its diameter can be found using the eigenvalue technique described 
in Sec. 3.2. 4 Antialiased Surface Normal Formulation Fractal surfaces are not differentiable since they 
have detail at every level of magnification. This means that 3The diameter diam(A) of set A is the maximum 
distance between any two points a, b E A. 96 surface normals are analytically undefined for fractal surfaces. 
Fractal surface normals have been approximated several ways. If the surface is generated to a fixed resolution, 
then the surface normal of the primitive used to approximate the surface can be used, as in [10]. In 
[15], points were accumulated in a Z-buffer and neighboring Z-buffer values were used to approx­ imate 
the surface normal. In [6], the gradient of a distance estimate function provided a good approxi­ mate 
surface normal. Linear fractals, as rendered in this paper, are not generated to a set resolution, nor 
is a Z-buffer used. A distance estimate exists for linear fractals [7] but is not very efficient for 
these objects. Instead, the sur­face normal is approximated for linear fractal surfaces using the bounding 
volume information from ray in­tersection. Consider a natural, almost linear, fractal shape: cauliflower. 
The surface of a cauliflower is made of an extremely large number of small buds but if the illu­mination 
from these buds was to be computed from point samples, the Nyquist limit would suggest that at least 
twice as many samples as buds be taken [21]. A more tractable solution is based on the fact that the 
cauliflower surface reflects light diffusely as a sphere since the small buds, albeit noisily, loosely 
ap­proximate the surface of a sphere. The cauliflower reflects light more like several medium-sized spheres 
since the buds more closely approximate them. The illumination of many smaller spheres even more ac­curately 
represents the light reflected by these buds. This suggests that linear fractals should be shaded hierarchically. 
This hierarchical shading is computed using the en­countered surface normals. The resulting surface nor­mal 
is the weighted sum of the surface normals at the intersections of the ray with the ancestry of bound­ing 
volumes that surround the ray-fractal intersection point4. 4.1 Weighting Methods Several weighting methods 
are described. Each en­countered surface normal is accumulated in IV which is initialized with (O, O, 
O)* and will need to be nor­malized when used. Let ~B (x) denote the surface normal of bounding volume 
B at point x. The Constant weighting sums all encountered bounding volume surface normals equally so 
that the surface normal of the initial bounding volume con­tributes as much as the surface normal from 
a ter­minal bounding volume. The weights are shown in 4One drawback to this formulation of the surface 
normal is that it is view dependent. Thus, changing the viewpoint may change the appearance of a surface. 
However, this property has not yet become conspicuous in renderings and animations thus far.   #of 
points  -d 1/2 11/2 11/2 NC. NP N/ .NP Nh -NP Figure 8: Distribution of surface normals for Eqs. (26), 
(27) and (28). The diameter of the intersected cover is used to 6 Conclusion compute the transfer function 
that combines the color of the cover with the rest of the ray s encountered col-The result is a rendering 
algorithm that, given only an ors. Several transfer functions are available from the IFS, finds an initial 
bounding volumes, efficiently ap­area of volume rendering; the simplest are the linear proximates ray-fractal 
intersections, computes well­ approximations used for image compositing [16]. behaved surface normals 
and produces an antialiased If c and cr are the current encountered ray color and image of the IFS s 
linear fractal attractor. opacity and cB and (lB are the color and opacity of The ray intersection method 
provides an arbitrar­bounding volume B, then the linear transfer functions ily precise ray-fractal intersection. 
The surface nor­ are mal method is only an approximation based on ap­pearance. Much work remains to rigorously 
define a fractal surface normal. Surface shading is simulated c= c+ (1 cr)cr~c~ (29) diffusely, but 
fractals, having detail smaller than the @ = @+(l ~)&#38;B (30) wavelengths of light, should exhibit 
spectral patterns when correctly shaded. The object-space cover for source to surface ray traversal, 
and dampens aliases on silhouette edges but the sampling of fractal shapes is an interesting problem 
that should be investigated further. c = (1 -cr~)c+ a~c~ (31) a = ~+(l ~)~B (32) 6.1 Results for surface 
to source ray traversal (sometimes used Two images are produced here that demonstrate thefor light rays). 
varied shapes that an IFS can model. The first, Fig. 9, A range of bounding volume diameters is needed. 
illustrates the fractal equivalents of the Five PlatonicThe upper limit, ~max, is the scale at which 
bound-Solids. Each of these solids has infinite surface areaing volumes take on non-zero opacity and 
should be and zero volume, a common characteristic of fractal set to 2p(t), twice the size of a pixel. 
The lower shapes. Each IFS consists only of uniform scales andlimit, ~min, is the scale at which bounding 
volumes translations. They make good tutorial examples. are completely opaque, thus no further subdivision 
is The second image, Fig. 10, shows some fractal mod­performed. This lower bound is recommended to be 
els of nature. The fir trees are not meant to be accu­&#38;p(t) in [3], which appears to be about right. 
rate and the elm trees have no leaves, just tiny greenA simple piecewise linear function of diameter 
pro­branches. Nonetheless, this scene is perhaps one ofduces the desired opacity values, the more complex 
in computer graphics. 1 if diam(l?) < ~min, 6.2 Implementation di~(B)-Tmim ~B = l if ~min s diam(l?) 
< ~max, rm.x-r-i. Currently, the ray tracing algorithm is implemented o otherwise. { on an AT&#38;T 
Pixel Machine 964dX, a 64 processor,(33) 640 MFLOPS, MIMD parallel image computer. EachThis results in 
a smooth gradation from the object processor races5 the others to finish an interleavedto its surroundings 
at its silhouette edges. subset of the screen s 1280 x 1024 pixela. The bounding volume hierarchy may 
be visualized Each of the Pixel Machine s 64 processors has onlyif Tmax = oa and a constant fractional 
opacity value 36KB available for programs and non-image data. In is used independent of the diameter. 
This makes all of the bounding volumes uniformly translucent. An 5 No inte~~~~~~ ctJmmfiC8tiOn Or SWdUOIIiZ3ti(XI 
s example of this appears in Fig. 2. used.   Steve Bourne and the software group at AT&#38;T Pixel 
Machines deserve credit for supporting this re­search during the Summer of 1990. Alan Norton and his 
group at the IBM T. J. Watson Research Center should also be noted for their support during the very 
initial stages of this research at the end of the Sum­mer of 1989 and for Alan s continuing involvement 
with this project. Thanks also to Don Mitchell and his group at AT&#38;T Bell Labs, Murray Hill, New 
Jersey, for their communication during the Summer of 1990. References [1] BARNSLEY, hf. F., ERVIN, V., 
HARDIN, D., AND LANCASTER) J. Solution of an inverse prob­lem for fractals and other sets. Proceedings 
of the National Academy oj Science 83 (April 1986), 1975-1977. [2] BARNSLEY, M. F., JACQUIN, A., h lAL-LASSENET, 
F., RUETER, L., ANII SLOAN, A. D. Harnessing chaos for image synthesis. Computer Graphics 22, 4 (1988), 
131-140. [3] BARR, A. H. Ray tracing deformed surfaces. Computer Graphics 20, 4 (1986), 287-296. [4] 
BOUWLLE, C. Bounding ellipsoids for ray­fractal intersection. Computer Graphics 19, 3 (1985), 45-51. 
[5] DEMKO, S., HODGES, L., AFID NAYLOR, B. Construction of fractal objects with iterated function systems. 
Computer Graphics 19, 3 (1985), 271-278. [6] HART, J. C., SANDIN, D. J., AND KAUFFMAN, L. H. Ray tracing 
deterministic 3-D fractals. Computer Graphics 23, 3 (1989), 289-296. [7] HEPTING, D., PRUSINKIEWiCZ, 
P., AND SAUPE, D. Rendering methods for iterated func­tion systems. In Proceedings of Fractals 90 (1990), 
IFIP. [8] HUTCHINSON} J. Fractals and self-similarity. Indiana University Mathematics Journa! 30, 5 (1981), 
713-747. [9] JAQUIN, A. E. Image coding based on a fractal theory of iterated contractile image transforma­tions. 
Preprint, 1990. [10] KAJIYA, J. T. New techniques for ray tracing procedurally defined objects. A Chf 
Transactions ora Graphics 2, 3 (1983), 161 181. Also appeared in Computer Graphics 17, 3 (1983), 91 102. 
[11] KAY, T. L,, AND KAJIYA, J. T. Ray trac­ ing complex scenes. Computer Graphics 20, 4 (1986), 269-278. 
[12] MANDELBROT, B. B. The Fractal Geometry of Nature, 2nd ed. Freeman, San Francisco, 1982. [13] MITCHELL, 
D. P., Summer 1990. personal com­munication. [14] MITCHELL, D. P., AND AMANATIDES, J. Mega­cycles. SIGGRAPH 
Video Review 51 (1989), #14. [15] NORTON, A. Generation and rendering of geo­metric fractals in 3-D. 
Computer Graphics 16, 3 (1982), 61-67. [16] PORTER, T., AND DUFF, T. Compositing dig­ital images. Computer 
Graphics 18, 3 (1984), 253-259. [17] PRESS, W. H., FLANNERY, B. P., TEUKOL-SKY, S. A., AND VETTERLING, 
W. T. Numer­icai Recipes in C. Cambridge University Press, 1988. [18] PRUSINKIEWICZ, P. About the cover: 
Exploring the beauty of plants. IEEE Computer Graphics and Applications 10, 2 (hfarch 1990), 3 6. [19] 
PRUSINKIEWICZ, P., AND LINDENMAYER, A. The Algorithmic Beauty of Plants. Springer-Verlag, New York, 1990. 
[20] RUBIN, S. M., AND WHITTED, T. A 3­dimensional representation for fast rendering of complex scenes. 
Computer Graphics 14, 3 (1980), 110-116. [21] SHANNON, C. E. Communication in the pres­ence of noise. 
Proceedings of the Institute of Ra­dio Engineers 37, 1 (January 1949), 10-21. [22] SHINYA, M., TAKAIIASHI, 
T., AND NAITO, S. Principles and applications of pencil tracing. Computer Graphics 21, 4 (1987), 45-54. 
[23] SNYDER, J. h~., AND BARR, A. H. Ray tracing complex models containing surface tessellations. Computer 
Graphics 21, 4 (1987), 11%128. [24] STRANG, G. Linear Algebra and its Applica­tions, 3rd ed. Harcourt 
Brace Jovanovich, 1988. [25] SUTHERLAND, I. E. Sketchpad: A man-machine graphical communication system. 
Proceedings oj the Spring Joint Computer Conference (1963). [26] THOMAS, D., NETRAVALI, A. N., AND Fox, 
D. S. Antialiased ray tracing with covers. Com­puter Graphics Forum 8, 4 (December 1989), 325-336. [27] 
VRSCAY, E. R., AND ROEHRIG, C. J. Iterated function systems and the inverse problem of frac­tal construction 
using moments. In Computers and Mathematics (New York, 1989), E. Kaltofen and S. M. Watt, Eds., Springer-Verlag, 
pp. 250 259.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122729</article_id>
		<sort_key>101</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Trichromatic approximation for computer graphics illumination models]]></title>
		<page_from>101</page_from>
		<page_to>104</page_to>
		<doi_number>10.1145/122718.122729</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122729</url>
		<abstract>
			<par><![CDATA[The complexity of computer graphics illumination models and the associated need to find ways of reducing evaluation time has led to the use of two methods for simplifying the spectral data needed for an exact solution. The first method, where spectral data is sampled at a number of discrete points, has been extensively investigated and bounds for the error are known. Unfortunately, the second method, where spectral data is replaced with tristimulus values (such as RGB values), is very little understood even though it is widely used. In this paper we examine the error incurred by the use of this method by investigating the problem of approximating the tristimulus coordinates of light reflected from a surface from those of the source and the surface. A variation on a well known and widely used approximation is presented. This variation used the XYZ primaries which have unique properties that yield straightforward analytic bounds for the approximation error. This analysis is important because it gives a sound mathematical footing to the widely used method of trichromatic approximation. The error bounds will give some insights into the factors that affect accuracy and will indicate why this method often works quite well in practice.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Seminorm]]></kw>
			<kw><![CDATA[illumination models]]></kw>
			<kw><![CDATA[spectral power density (SPD)]]></kw>
			<kw><![CDATA[spectral reflectance]]></kw>
			<kw><![CDATA[trichromatic approximation]]></kw>
			<kw><![CDATA[tristimulus coordinates]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P41155</person_id>
				<author_profile_id><![CDATA[81100298966]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Borges]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Laboratory, Division of Computer Science, University of California, Davis, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>917425</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BORGES, C.F. Numerical Methods for Illumination Models in Realistic Image Synthesis. Ph.D. dissertation, University of California, Davis, 1990.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[COWAN, W., ANO WARE, C. Tutorial on color perception. In SIGGRAPH (July 1983).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[HALL, R., AND GREENBErtG, D. A testbed for realistic image synthesis. IEEE CGg.4A (November 1983), 10-20.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[KREYSZIO, E. Introductory Functional Analysis with Applications. John Wiley &amp; Sons, 1978.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>45601</ref_obj_id>
				<ref_obj_pid>45596</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[MEYER, G. Wavelength selection for synthetic image generation. Compuier Vision, Graphics, and Image Processing (January 1988), 57-79.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[MEYER, G., AND GrtEENB~.rtO, D. Colorimetry and computer graphics. In SIGGRAPH- State of the Art Tutorial on Color Spaces (1984).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W^LLIS, IZ. Fast computation of tristimulus values by use of Gaussian quadrature. J. Optical Soc. Am. (January 1975), 91-94.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[WYSZECKI, G., AND STILES, W. Color Science: Concepts and Methods, Quantitative Data and Formulae. John Wiley and Sons, 1982.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Trichromatic Approximation for Computer Graphics 
Illumination Models Carlos F. Borges Computer Graphics Research Laboratory Division of Computer Science 
University of California Davis, California 95616 Abstract The complexity of computer graphics illumination 
llmdels and the associated need to find ways of reduc­ing evaluation time has led to the use of two methods 
Ior silnplifying the spectral data needed for an exact sol{lt,ion, T]le first method, where spectral 
data is sam­ l~lccl at a number of discrete points, has been exten­sivt>ly investigated and bounds for 
the error are known, (1111 ortunat,ely, the second method, where spectral data i, r~>placed with tristimulus 
values (such as RGB val-U{>S), is very litt Ie understood even though it is widely ~]scd, In this paper 
we examine the error incurred by III{ llse of this method by investigating the problem of al)l}roximi~ting 
the tristimulus coordinates of light re­{I(ct cd from a surface from those of the source and the sllrface, 
A variation on a well known and widely used ~ll~llroximation is presented. This variation uses the X 
r Z primaries which have unique properties that yield 5(rilightforward analytic bounds for the approximation 
,Srr{)r. This analysis is important because it gives a sc~(]lld mathematical footing to the widely used 
method of t dichromatic approximation. The error bounds will gi Y,>some insights into the factors that 
affect accuracy alId will indicate why this method often works quite Jvell in practice. Keywords: Illumination 
Models, llichromatic Ap­I,mxinlation, Tristimulus Coordinates, Spectral Power l}ellsity (SPD), Spectral 
Reflectance, Seminorm. CR, Categories: 1.3.7 [Computer Graphics]: Three­ I)ilncl]sional Graphics and 
Realism -Color, shading, sl)adolfilig, and texture. 1 Introduction One of the most common procedures 
in computer graphics is that of evaluating an illumination model in order to determine the color of light 
emanating from some point on an object. This is a costly operation and is repeated many thousands of 
times in any rendering algorithm. Of course, any method for simplifying this task cart yield a significant 
savings over the course of rendering an image and will be useful if it does not ex­cessively degrade 
the fidelity of the final image. One very common approach reduces the number of floating point operations 
by using simplified representa­tions of the spectral data that characterizes the sources and surfaces 
in the scene. This is typically done in one of two ways. The first, and most intuitive method uses sampled 
representations of the SPD S and spectral re­flectance that describe the sources and surfaces in the 
scene. These are used directly in the illumination model and yield a sampled representation of the SPD 
of light emanating from the surface which can be readily trans­formed into an appropriate coordinate 
system for ren­dering (e.g. RGB). This is the method of choice when high accuracy is a must; the error 
is clearly bounded only by the error of the quadrature method used to con­vert a point sampled SPD into 
tristimulus coordinates. Since the quadrature methods used are classical (Simp­son s rule, etc.) the 
error is easily analyzed. A number of methods for implementing this approach have been examined and their 
performance has been found to be quite good (see [3,5,6,7]). There is a second approach that is somewhat 
less intuitive. Here we replace the SPD S and spectral reflectance with tristimulus coordinates (e.g. 
RG B values).1 This approach has several useful properties: only three numbers are required to represent 
an SPD or spectral reflectance (contrast this with the nine or more 10f course, surfaces do not have 
tristimulus values. However, for pedagogical expedience it is common to calI the tristimulus values of 
a given surface under spectrally white illumination of unit intensity the tristimulus values of the surface. 
 11991 .4chl-(1-8Y7 )1-436.x 91 ()()7()]()1 $(M)75 SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 sample 
points usually required by the first method), additive color mixtures and specular reflections can be 
modelled exactly (by respectively adding or scaling the tristimulus coordinates),, no spectral data is 
necessary (this can be hard to come by for certain objects). How­ever, this approach has one substantial 
flaw, tristim-UIUS coordinates do not contain enough information to correctly model non-specular reflecti&#38;. 
For exam­ple, given the tristimulus coordinates of a colored light source and a colored matte surface 
it is not possible, using the Young-Helmholtz trichromatic theory, to de­termine the tristimulus coordinates 
of the surface when illuminated by the given light. Fortunately, it is possi­ ble to make an approximation 
by multiplying the tris­timulus coordinates of the source with those of the sur­face. This is called 
a trichromatic approximation and is widely used. It haa been pointed out that some of these methods work 
relatively well for realistic scenes, but no one knows why [2]. We will explore such an approx­imate 
method and give a full mathematical analysis of the error. This analysis will allow us to determine when 
the trichromatic approach is good enough and when we should fall back on a more stable sampling approach. 
We will also indicate why one might expect the trichr~ matic method to work well in a realistic scene. 
First we note that the trichromatic approach is ex­ act for additive mixtures and specular reflections; 
since these phenomena do not introduce any error, we will not discuss them any further, Instead, since 
it is a paradigm for the non-specular reflections that concern us, we will completely restrict our attention 
to approximating the color of a Larnbertian surface under a single source of illumination. 2 Trichromatic 
Approximation for an Illumi­nated Lambertian Surface We are interested in determining the color appearance 
of an illuminated Lambertian surface. In an ideal phys­ical model light emanating from the surface hss 
a spec­tral radiant power distribution that is proportional to P~p(A), the product of the spectral radiant 
power of the illuminant, PA, and the spectral reflectance of the surface, p(~). Following the Young-Helmholtz 
theory, the tristimulus coordinates of the reflected light, and hence the colot appearance of the surface, 
can be found by evaluating the following definite integrals:  R = Jv P,p(J)F(A)dA G = J-vP,p(A)g(A)dA 
(1) where F(J), g(~), and b(~) are the color matching func­ tions, and V is the interval corresponding 
to the visible 102  spectrum (see [8]). This is a convenient physical model but requires that the spectral 
properties of both the source and surface be known in full since the RGB coordinates do not contain sufficient 
information to predict the outcome of such an interaction. The problem stems from the fact that metameric 
sources (lights with distinct spectral radiant power distributions but identical tristimulus values) 
do not always produce the same color when illuminating surfaces that are not spectrally white. Similarly, 
a pair of surfaces may have identical color appearance under spectrally white illumination, and hence 
the same tris­timulus values, but dissimilar appearance under some other illuminant (this phenomenon 
is familiar to any­one who has had their hand stamped with an invisible design that only appears under 
UV illumination). Let us consider an approximate method of a form that is very common in computer graphics 
and simply mimics the exact method used in the spectral domain. In particular, the tristimulus values 
of the illuminated surface are approximated by the product of the trist im-UIUSvalues of the source and 
the surface. This approx­imation works quite well in practice. Indeed, Cowan and Ware [2] describe a 
similar method and note that it works relatively well in realistic scenes. Motivated by this, we shall 
consider a similar approximation but will use the XYZ primaries instead of the RGB pri­maries. In particular: 
 XR@~C~~~ % Xsmr=exsurja=e yRefl~~t~d * Sour. ey..urjace (2) ~R~jleCted % Zso..eezsurjace Note that 
the choice of system here is not at all ar­bitrary. The XYZ system is chosen because it has con­venient 
properties that will simplify the derivation of bounds on the approximation error. They are: 1. All realizable 
stimuli (those that satisfy PA~ O) have non-negative tristimulus coordinates. 2. The tristimulus coordinates 
of an equal energy white (PAs 1.0)areX=Y=Z=1.0.  The first property implies that the XYZ matching functions 
are non-negative over the visible interval, that is ic(~),y(~),~(~) >0 for all J E V. The second prop­erty 
implies that: Ji(A)d,=~y(A)dA= ~z,A)dA=l.o (3) Matching functions that satisfy equation 3 are called 
normalized. To be more precise, we will be using the matching functions for the CIE 1931 Standard C olorimetm 
c Observer. @@ Error Analysis To simplify the analysis that follows we consider the error associated 
with a single genem c primary with a normalized non-negative matching function. Determin­ ing the behavior 
of the error for this primary is suffi­cient because the results can later be applied directly to the 
XYZ primaries since they also have normalized non­negative matching functions. Let the matching function 
of this generic primary be denoted rn(~). The approx­imation error is given by: Err (f, g) = ~grn(~)d~ 
 ~rn(~)d~ grn(~)d~ /v 11 (4) where f and g represent a power distribution and a reflectance function 
(there is no reason to enforce any distinction between the two objects, both are simply functions). For 
mathematical expedience assume that n~(~), f(~), and g(~) are all elements of Cv the set of real-valued 
functions that are continuous on V, this will ensure that all of the integrals exist and are bounded. 
Given the problem in this form we can bound the er­ror using techniques from functional analysis ([4] 
is an excellent reference for this material). First, it is not dif­ficult to verify that Err(., .) is 
an Hermitian form3 that maps C v x Cv to ?3?.Second, notice that the error term is also positive semi-definite. 
To verify this consider: Err (~, f)= f2rn(J)dA Iv {l frn@)d }2 5) Since rn(~) is non-negative the Schwarz 
inequality im­plies that: Hence the error functional is positive semi-definite. Since the Schwarz inequality 
holds for any positive semi-definite Hermitian form ([4], p. 195) it holds for the error functional. 
In particular: {Err (~, g)}2 ~ Err(f, ~) Err (g, g) (7) This is a bound on the error of the approximation. 
Now, note that:  Ilflliil = Jf rn(w -{~fw)dA}2 (8) is a seminorm on the space C v ([4], p. 195). Hence, 
the error bound can be written: 3If X is a vector space over the real field 32,and if h : X x X + 3? 
is bilinear and symmetric then h is called an Hemnitian form. Computer Graphics, Volume 25, Number 4, 
Julv 1991 lErr (j)g) I ~ ll~]lmllgllm (9) and it is seen that the absolute error can be no worse than 
the product of the seminorms of the spectral re­ flectance and the SPD with respect to the matching function. 
This ia useful because it makes it possible to determine, a priom , whether this method is an ap­ propriate 
approximation for a given set of sources and surfaces (one could store the seminorms in a materials library 
along with other information about the various sources and surfaces). If the various spectral functions 
are sufficiently small with respect to this seminorm then it is reasonable to assume the method will 
work well. We point out that this method (multiplying the tris­timulus values) can be used with any tristimulus 
space. However, without normalized non-negative matching functions the error analysis is quite involved 
(it is omit­ted here but can be found in [1]). Now, suppose that the source (or surface) is spec­trally 
white, that is f(~) Ea for some o E %. Equation 4 yields, after some manipulation:  Err (~,g) = [l-~rn(A)dA]@~,(A)rn(J)dA 
(10) Since the matching function is normalized the error is zero and the approximation is exact when 
applied to spectrally white sources or surfaces. This will illustrate one of the remns why this approximation 
works so well in realistic situations. Note that most common sources of illumination, like daylight and 
incandescent lights, are very nearly white. It is reasonable to rep resent a nearly white source with 
a spectral radiant power distribution of the following form: PA=c(~) +a (11) where a is a constant, 
and c(~) is non-negative and small in comparison with a. If p(~) is the spectral re­flectance of the 
surface, then bilinearity and equation 10 yields: Err (c(A) + CY,p) = Err (c(J), p) (12) the relative 
absolute error is given by: lErr (c(J),p) I (13) [a+ C(A)] panda /v which, following equation 9 and the 
fact that c(A) and P(J) are non-negative, is certainly less than: Ilc(J)llml[p\lm (14)  pandaa J v 
and will be small if c(~) << a on the interval V. 103 SIGGRAPH 91 Las Vegas, 28 JuIY-2 Aucwst 1991 4 
An Example 17J Green  o 0.8 We briefly demonstrate this method with two surfaces 3 0.6 (one rose and 
one green) and a standard daylight energy source whose spectral distributions appear in figures 1 &#38; 
().2 and 2. Only primary reflection is considered here, ef­fects related to scene geometry are ignored 
( e.g. Lam-o t bert s cosine law, the inverse square law, etc.). It is 400 500 600 700 straightforward 
to compute the actual and approximate Wavelength (rim) XYZ coordinates of the illuminated surfaces; these 
ap­pear in table 1 along with the corresponding RGB C* Figure 1: Reflectance functions of the two example 
sur­ ordinates for a 24-bit frame buffer. Note how close the faces. approximate values are to the actual 
ones; the two are virtually indistinguishable on a standard display device. lm~ o~ 400 500 600 7(H3 
R 83 85 31 30 G  o 1 134 132 Wavelength (rim) B]28 31 21 19 I II Figure 2: Spectral radiant power 
of daylight (CIE Stan-Table 1: Actual and approximate tristimulus values for dard Illurninant D55). the 
example in XYZ coordinates and in standard RGB coordinates for a 24-bit frame buffer. References Another 
brief calculation yields the error bounds and [1] BORGES, C.F. Numerical Methods for Illumination the 
observed approximation errors that appear in table Models in Realistic Image Sgnthesis. Ph.D. disser­ 
2. The error bounds indicate that the approximations tation, University of California, Davis, 1990. will 
be accurate to within +670 for the X and Y pri­maries, and + 15V0 for the Z primary. This is an excel­ 
[2] COWAN, W., AND WARE, C. ~torial on color lent result considering how little information is used to 
perception. In SIGGRAPH (July 1983). make the approximations. [3] HALL, R., AND GREENBERG, D. A testbed 
for Daylight-Rose I Daylight-Green realistic image synthesis. IEEE CGOA (November Error I Bound I Error 
I Bound 1983), 10-20. [4] KREYSZIG, E. Introductory Functional Analysis with Applications. John Wiley 
&#38; Sons, 1978. [5] MEYER, G. Wavelength selection for synthetic im-Table 2: Observed errors and analytic 
error bounds age generation. Computer Vision, Gmphics, and of the trichromatic approximate ions from 
the example Image Processing (January 1988), 57-79. (XYZ coordinates). [6] MEYER, G., AND GREENBERG, 
D. Calorimetry and computer graphics. In SIGGRA PH -State of the Art Zktorial on Color Spaces (1984). 
5 Conclusions [7] WALLIS, R. Fast computation of tristimulus values We have presented a variation on 
a widely used approx­ by use of Gaussian quadrature. J. Optical Sot. Am. imation for computer graphics. 
This method is appeal­(January 1975), 91-94. ing because of its low computational costs and mini­mal 
storage requirements. We derived simple analytic [8] WYSZECKI, G., AND STILES, W. Co/or Science: bounds 
on the associated error using classical results Concepts and Methods, Quantitative Data and For­from 
functional analysis and indicated why it might be mulae. John Wiley and Sons, 1982. expected to work 
relative] y well in realistic scenes. 104  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122730</article_id>
		<sort_key>105</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[An object-oriented framework for the integration of interactive animation techniques]]></title>
		<page_from>105</page_from>
		<page_to>112</page_to>
		<doi_number>10.1145/122718.122730</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122730</url>
		<abstract>
			<par><![CDATA[We present an interactive modeling and animation system that facilitates the integration of a variety of simulation and animation paradigms. This system permits the modeling of diverse objects that change in shape, appearance, and behaviour over time. Our system thus extends modeling tools to include animation controls. Changes can be effected by various methods of control, including scripted, gestural, and behavioral specification. The system is an extensible testbed that supports research in the interaction of disparate control methods embodied in controller objects. This paper discusses some of the issues involved in modeling such interactions and the mechanisms implemented to provide solutions to some of these issues.The system's object-oriented architecture uses delegation hierarchies to let objects change all of their attributes dynamically. Objects include displayable objects, controllers, cameras, lights, renderers, and user interfaces. Techniques used to obtain interactive performance include the use of data-dependency networks, lazy evaluation, and extensive caching to exploit inter- and intra-frame coherency.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[delegation]]></kw>
			<kw><![CDATA[electronic books]]></kw>
			<kw><![CDATA[interactive illustrations]]></kw>
			<kw><![CDATA[object-oriented design]]></kw>
			<kw><![CDATA[real-time animation]]></kw>
			<kw><![CDATA[user interaction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Application packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Graphics packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P246989</person_id>
				<author_profile_id><![CDATA[81100099358]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Zeleznik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31023465</person_id>
				<author_profile_id><![CDATA[81100019411]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[Brookshire]]></middle_name>
				<last_name><![CDATA[Conner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051899</person_id>
				<author_profile_id><![CDATA[81341498231]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Matthias]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Wloka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P58480</person_id>
				<author_profile_id><![CDATA[81100218141]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Aliaga]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207596</person_id>
				<author_profile_id><![CDATA[81452602806]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31080375</person_id>
				<author_profile_id><![CDATA[81100381490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Hubbard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31023195</person_id>
				<author_profile_id><![CDATA[81100013114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Knep]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P109576</person_id>
				<author_profile_id><![CDATA[81538426656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaufman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024462</person_id>
				<author_profile_id><![CDATA[81100166298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Hughes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027057</person_id>
				<author_profile_id><![CDATA[81452592989]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Andries]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Dam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15907</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Phil Ambum, Eric Grant, and Turner Whitted. Managing geometric complexity with enhanced procedural models. In Proceedings of the ACM SIGGRAPH, Computer Graphics, volume 20(4), pages 189-195, August 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alan H. Barr. Global and local deformations of solid primitives. In Proceedings of the ACM SIGGRAPH, Computer Graphics, volume 18(3), pages 21-30, July 1984.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ronen Barzel and Alan H. Barr. A modeling system based on dynamic constraints. In Proceedings of the ACM SIGGRAPH, Computer Graphics, volume 22(4), pages 179-188, August 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Lisa K. Borden. Articulated objects in BAGS. Master's thesis, Brown University, May 1990.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>324538</ref_obj_id>
				<ref_obj_pid>324493</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. H. Boming. Classes versus prototypes in object-oriented languages. In IEEE/ACM Fall Joint Computer Conference, pages 36-40, 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ingfei Chert and David Busath. Animating a cellular transport mechanism. Pixel Magazine, l (2), 1990.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83600</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Gerald Farin. Curves and Surfaces for Computer-Aided Geometric Design. Academic Press, second edition, 1990.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Tinsley A. Galyean. Sculpt: Interactive volumetric modeling. Master's thesis, Brown University, May 1990.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>90767</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Andrew Glassner, editor. Graphics Gems. Academic Press, 1990.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>36166</ref_obj_id>
				<ref_obj_pid>36160</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Brent Halperin and Van Nguyen. A model for object-based inheritance. In Peter Wegner and Bruce Shriver, editors, Research Directions in Object-Oriented Programming. The MIT Press, 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>864697</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Philip M. Hubbard, Matthias M. Wloka, Robert C. Zeleznik, Daniel G. Aliaga, and Nathan Huang. UGA: A unified graphics architecture. Technical Report CS-91-30, Brown University, 1991.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>917779</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Devendra Kaira. A Unified Framework for Constraint-Based Modeling. PhD thesis, California Institute of Technology, 1990.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Matthew Moore and Jane Wilhelms. Collision detection and response for computer animation. In Proceedings of the ACM SIGGRAPH, Computer Graphics, volume 22(4), pages 289- 298, August 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91452</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Car), B. Phillips, Jianmin Zhao, and Norman I. Badler. Interactive real-time articulated figure manipulation using multiple kinematic constraints. In Proceedings of the Symposium on Interactive 3D Graphics, pages 245-250, 1990.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[William H. Press, Brian E Flannery, Saul A. Teukolsky, and William T. Vetterling. Numerical Recipes in C. Cambridge University Press, 1988.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. W. Sederberg and S. R. Parry. Free-form deformation of solid geometric models. In Proceedings of the ACM SIG- GRAPH, Computer Graphics, volume 20(4), pages 151-160, August 1986.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617603</ref_obj_id>
				<ref_obj_pid>616014</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Paul S. Strauss. A realistic lighting model for computer animators. IEEE Computer Graphics and Applications, 10(6), November 1990.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>36175</ref_obj_id>
				<ref_obj_pid>36160</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Peter Wegner. The object-oriented classification paradigm. In Peter Wegner and Bruce Shriver, editors, Research Directions in Object-Oriented Programming. The MIT Press, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Jerry Weil. A simplified approach to animating cloth objects. Unpublished report written for Optomystic, 1988.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Peter Wisskirchen. Object-Oriented Graphics. Spfinger- Vedag, 1990.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>4407</ref_obj_id>
				<ref_obj_pid>4406</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[N. Yankelovich, N. Meyrowitz, and Andries van Dam. Reading and writing the electronic book. IEEE Computer, 18(10), October 1985.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Object-Oriented Framework for the Integration of Interactive Animation Techniques Robert C. Zeleznik, 
D. Brookshire Conner, Matthias M. Wloka, Daniel G, Aliaga, Nathan T. Huang, Philip Brian Knep, Henry 
Kaufman, John F. Hughes and Andnes M, Hubbard, van Dam Department of Computer Science Brown University 
Providence, RI 02912 ABSTRACT We present an interactive modeling and animation system that fa­cilitates 
the integration of a variety of simulation and animation paradigms. This system permits the modeling 
of diverse objects that change in shape, appearance, and behavior over time. Our system thus extends 
modeling tools to include animation controls. Changes can be effected by various methods of control, 
including scripted, gestural, and behavioral specification. The system is an extensible testbed that 
supports research in the interaction of dis­parate control methods embodied in controller objects. This 
paper discusses some of the issues involved in modeling such interactions and the mechanisms implemented 
to provide solutions to some of these issues, The system s object-oriented architecture uses delegation 
hier­archies to let objects change all of their attributes dynamically. Objects include displayable objects, 
controllers, cameras, lights, renderers, and user interfaces. Techniques used to obtain interac­tive 
performance include the use of data-dependency networks, lazy evaluation. and extensive caching to exploit 
inter-and intra-frame coherency. CR Categories and Subject Descriptors 1.3.2 Graphics Systems; 1.3.4 
Graphics Utilities, Application Pack­ages, Graphics Packages; 1.3.7 Three-Dimensional Graphics and Realism, 
Animation; 1.6,3 Simulation and Modeling Applications; D.3.3 Language Constructs Keywords Real-time 
animation, object-oriented design, delegation, simula­tion, user interaction, electronic books, interactive 
illustrations. Introduction Over the last two decades, graphics research has concentrated on three main 
areas, loosely categorized as image synthesis, shape modeling, and behavioral modeling. While image synthesis 
(ren­dering) was stressed in the late 70s and early 80s, the emphasis has recently shifted to the modeling 
of various objects and phenomena indeed, many researchers believe that graphics today is model­ing. 
We wish to expand the definition of modeling to include the realms of simulation, animation, rendering, 
and user interaction. f%rmissionto copy withom tcc all or part {It th]s matcotd is granted provided that 
the copies arc not made or chstributedfor dircc[ cmnmcrciid advantage.ihc ACMcopyrigh~noticeandthe titIcc~fthe 
putslica[ionumt its ctttlcappear, md notw ii given [hat copying is h] permissl~mtf the Ass(~i~tion for 
Compu[lng Machinery, T{} c{Ipy othcrwlw. {w tt~republish, requires a fee andjor \pecilic pcrm]sii[m 1, 
,Iy)l AcM-()-x97Yl-436-x#9)oo7()lo.5 W 75 Since the mid-60s, our research has focused on tools for creating 
electronic books, specifically hypermedia documents with interac­tive illustrations [21 ]. Such illustrations 
allow readers to interact not just with a canned movie but with a stored, parameterized model of a phenomenon 
they are trying to understand. Interactive illustra­tions require simulation and animation of the underlying 
model in an interactive, real-time environment. Because we want to create interactive illustrations for 
a wide range of topics, our modeling tools must handle large (and exten­sible) sets of objects and operations 
on those objects that change any of their physical attributes over time. We need a rich collection of 
methods for controlling the time-varying structure and behavior of the objects, especially as they interact 
under various application­dependent systems of rules. In other words, we cannot use a single. silver-bullet 
modeling or animation technique. The essence of animation control is the specification of time­varying 
properties. Traditional graphics package~ (such as PHIGS+, Dorf, and RenderMan), however, have no explicit 
notion of time. In these packages, time can be specified only implicitly, as the byproduct of a sequence 
of editing operations on the database or display-list representation. While today s animation systems 
do allow time to be explicitly specified, they generally permit only a subset of an object s propetiies 
to vary over time, They also tend to be restricted in the objects, properties and behaviors they sup­port. 
Most limiting, they force the designer to conceptualize the animation process as a traditional pipeline 
of modeling, animation. and rendering phases. By contrast, we have concentrated on inte­grating modeling, 
animation, and rendering into a unified. coherent framework. 2 An Overview Our system provides a general 
and extensible set of objects that may have geometric. algorithmic, or interactive (i.e.. user-interface­controlled) 
properties, Geometric objects include quadrics, su­perqttadncs, constructive solid geometry objects (C3GS) 
and other hierarchical collections of objects, spline patches, objects of revo­lution, prisms, generalized 
cylinders or ducts [9] (objects obtained by extruding a varying cross-section along a spline path), and 
im­plicit surfaces. Non-geometric objects include cameras, lights, and renderers. Behaviors such as gestural 
controls. spring constraints, finite-element techniques for cloth simulation [ 19], dynamics [131, inverse 
kinematics [4] [ 14], and constraint solvers [3] are also en­capsulated as objects. Objects can send 
and receive messages. These messages are persistent a copy of each message is retained in the receiving 
object. They provide information on how an object should change itself over time. Objects can also inquire 
information from each other, information that depends on the nature and content of the messages a particular 
object has retained. Through messages, ob­jects can be transformed (with scales. rotations, trwmlatiom. 
shears.  SIGGRAPH 91 Las Veqas, 28 JuIY-2 August 1991 and rstlections), deformed (with bends, twists, 
tapers, waves [2], and free-form deformations [16]), colored, shaded [171, texture­mapped, dynamically 
moved (with forces, torques, velocities, and accelerations), and volumetrically carved [8]. Messages 
are functions of time and, since objects retain them, they may be edited. An object s list of messages 
describes the object s time-varying structure and behavior. By editing this list, through inserting, 
deleting, adding, or modifying messages, that structure and behavior can be altered. Editing can be performed 
either by objects or by entities (e.g., a user) external to the set of objects comprising the model. 
Our objects have several important characteristics. First, since they can have interactive properties, 
any object can have a graphical user interface as one of its attributes. Typically, an object supports 
a user interface for its own specialized information, for instance, a dynamics simulator may permit a 
user to specify its initial conditions with sliders. Other objects are primarily interactive, such as 
an object encapsulating a mouse which is queried by other objects for position information, or an object 
encapsulating constraints editor. Second, objects exploit communication, because they contain in­formation 
that is often essential to other objects. A renderer needs information from other objects in order to 
make global lighting cal­culations. Constraint methods also require information from many objects to 
perform their calculations. Constructive solid geometry objects need information about the boundary representation 
of their component objects in order to compute their own boundary repre­sentations. A camera needs to 
know the position of another object in order to track it. Finally, an object in our system is not part 
of a classical class­instance hierarchy, such as is found in the C++ and Smalltalk pro­gramming languages. 
The constantly changing nature of our mod­els makes a static relationship such as class-instance too 
restrictive, since, for example, transforming a sphere into a torus would typi­cally require a change 
in class. Instead, our system is a delegation system [I g] [10]. In a class-instance system, objects 
have two SOttS of associations: the association of an instance with its class and the association of 
a class with its super-class. A delegation system, on the other hand, has only one relation, that between 
an object and its prototype. An object, termed the extension, can be created from another object, its 
pro/otype; an object in a delegation system inter­prets a message by using one of its prototype s techniques. 
Changes to the prototype affect both objects, but changes to the extension affect only the extension. 
Although it has been suggested [5] [20] that delegation might provide a simpler and more elegant method 
of solving computer graphics problems, we are not aware of work prior to ours incorporating delegation 
into animation and modeling systems. 3 The System Architecture 3.1 Control points At its simplest, a 
message is a name and a function of time. A message can be edited by changing the particular nature and 
form of its time-varying function, specified by the series of time-value pairs that we call control poinfs 
(see Figure 1). Thus, editing a message can mean adding or removing control points, associating control 
points with new times, or changing the value in a control point. The value in a control point maybe scalars, 
vectors, or arbitrarily complex expressions. For example, a scaling transformation can be given as a 
single real number for a uniform scale or a list of three real numbers for a non-unifotm scale. A control 
point specifying a CSG tree can be given as alistcontainingthreeitems: anobjectnameor alist (itselfaCSGtree),anidentifierspecifying 
a CSGoperation, and another object or list. Values can be functions of time: a translation can be given 
by a vector function of the position of another object in the scene. Function-based control points allow 
useful behaviotw such as objects following other objects or adjusting their colors to match those of 
other objects. Many systems support such tracking behavior as a special case for cameras, but our system 
allows any object to behave in this way.  n Message Control Points Figure 1: A message is a list of 
control points; a control point is a time and an associated value. The CSG tree example above points 
out that the values of control points can be nested lists. Control-point values are very similar to Lisp 
s-expressions in this regard. They can contain atomic values, including numbers, srnngs, vectors, data 
structures, and object iden­tifiers, or they can be lists of atomic values or other lists. Control point 
values are thus very flexible, permitting the use of mathemat­ical expressions based on values in the 
scene. Figure 2 shows some sample control point values. /*atomic values*/ 3.1416 /u/j ohn/paint .bi camera 
sin (3.14 * 11.7) /*a list of atoms*/ [1.0, 2.0, 3.01 /*a list of lists*/ [[1, 0,0], [2, [3.3,4.4]]] 
/*functions*/ /*obtain 2nd value of list*/ select ([l.O, sin(t) ,3.0], 2) /*changing position of an object*/ 
robot Head. pos i t i on Figure 2: Examples of control point values (fragments of a scripting language 
used to describe objects and their messages). Values at times not explicitly specified can be derived 
through an interpolation function, typically a weighted sum of contrul points. When interpolating a series 
of control points whose values are them­selves functions of time, the system cannot just pass direct 
values to an interpolation method, but must first evaluate each control point at the target time. The 
series of evaluated values (not functions) thus produced can then be interpolated. As an example, consider 
a camera tracking two moving objects, smoothly shifting its focus from the first to the second. The value 
of a message over time can change dramatically, depending on the interpolation method used. 3.2 Messages 
An important purpose of messages is to provide communication among objects. Objects such as a user interface 
or a physically based simulator apply and edit messages to other objects, thus mod­ifying their appearance 
and behavior. An object can also affect another object by sending it a message containing a reference 
back to the sender (i.e., the message contains a control point that refer­ences another object). Whenever 
this message is interpreted, the sending object is called back and asked to provide the appropriate information. 
We use the term controllers for objects that modify messages on other objects, either by actively editing 
or passively being called back. For example, large scientific visualization projects are often run in 
batch mode, separating a supercomputer analysis from an inter­active visualization of the results. A 
simple controller could read in the results of such batch simulations, obtaining a list of positions 
(or whatever information is appropriate) and creating a list of messages from it. These messages could 
then be given to the appropriate ob­jects, telling each how to behave in order to represent the scientific 
data [6]. Other more sophisticated controllers can apply and then edit a set of messages, adding new 
messages as they derive new results. Controllers will be discussed in more detail in Section 5. Our system 
has a variety of messages to support its many kinds of objects, Highly specialized messages can provide 
information for an unusual object (for example, the parameters of an implicit equation or the tolerances 
of a constraint solver). More general changes, such as transformations. deformations, and dynamics (force 
or torque), provide a diverse class of changes applicable to more common objects.  3.3 Objects Every 
object is represented by a retained list of all of the messages it has received. Allobjects are identical 
when first created, since no messages have yethensent, i.e., anew object's list is empty. The message 
list isthenmodified inorder togivethe object interesting behaviors or appearances. Figure3: Anobject 
isalist of messages. The interpretation of a message, i.e., its semantic meaning, is determined by the 
object that receives it. Forexample, a screen­aligned text object should not behave in the same way as 
a cube when it receivesa message roruw; the rotation of the text should beprojected onto theplane of 
the screen. Similarly, requests for information are handled in an object-specific mannen A sphere computes 
aray intersection differently from a cube. To handle variable semantics, an object has a set of methods 
(i.e., functions)to interpret messages that determine its behavior and appearance, Interpretation of 
a message can alter some or possibly all of the methods currently in use by an object, and thus can radically 
change its entire nature, This ability to change methods enables an object to adapt to different situations. 
For example, a deformed torus no Ionger performs ray intersections with itself by finding the roots ofaquartic 
equation. Rather than requiring the torus s ray-intersection method to handle all eventualities, the 
procedure that interprets the deformation method changes its ray intersection method to a more suitable 
one, such as one that performs ray intersection with a set of polygons. Many simple objects, such as 
spheres, cubes, and cylinders, have many methods in common. They handle most transformations identically 
and differ only in a few shape-specific methods, such as boundary representation, ray intersection, and 
computation of surface normals and parametric coordinates. 3.4 Anexample ofmaking objects A delegation 
system has straightforward mechanisms for object hi­erarchy [5] [10]. Recall that anobject. theex[ensimr, 
can bernade from another object, theprorofype. In our system, an object can receive a message stating 
that it is to inherit all the messages of an­other object, thus becoming that object s extension. The 
extension  ComDuter GraDhics, Volume 25. Number 4. JUIV1991 implicitly inherits the prototype s behavior 
as well, since its meth ­ods are initially defined bythe messagesin the prototype. Since the prototype-extension 
relationship in our system is specified with amessage, however. it can vary overtime, a feature not normally 
present inadelegation system. Forexample, thehistory ofautomo­biles can be modeled as a single object 
that uses a different model yearcar asitsprototype for each year. This behavior is described very simply 
by a single time-varying message, Objects can also be made from several objects. Consider a figure sitting 
in a chair, shown in figure 7. The chair is a CSG object, built from the parts ofmany different objects. 
The tigure is made ofseveral extruded duct objects, giving it a smooth, stylized appearance. A duct is 
itself a hierarchy of several objects, made from several spline path objects: onepathdescnbes the spine 
of the duct while the others describe the duct s cross-section along the Iengthofthat path. Paths arethemselves 
composed ofpoint objects used as the control points for the splines. lftheobjects composing the CStlobject 
change overtime, the CSG object itself will also change. The CsGobject asks itscompc­nents for their 
boundary representations at a specified time, and the component objects return the boundary representations 
as function~ of time. since the boundaries are specified by messages to the corre ­spondingobject. Thecomposition 
of these functions inacsc object isnecessarily afunction of time. Paths andducts behave similarly: as 
the points specifying the hull of a path move, the hulls change shape, changing the spline path. As a 
path changes its orientation andshape, aduct made from this path also changes. Suppose we want the figure 
to watch a fly a fly flitting about the scene. Wecanspecify themotionof the fly with a path object. making 
the fly move along a spline path. and the fly can ask the path for the position of points further along 
and for tangent information at those points. Thus the fly can be oriented along the path, as if it were 
flying through the air. Likewise, the figure s eyes can ask the fly forits position and use that information 
to track it, and the points and paths comprising the tigure s ducts can also ask the fly for its position 
and change their orientation accordingly. 4 Interpreting Messages 4.1 The Simple Case An object computes 
the answer to an inquiry by interpreting each of its messages in sequence. As we said earlier, a message 
can change the methods used to interpret subsequent messages: therefore, the particular order of messages 
is important. The object s message list itself provides this ordering. This linear traversal is satisfactory 
until we begin using references to other objects and making multiple inquiries of an object. Under these 
circumstances, work will be repeated unnecessarily, and it becomes useful to exploit coherence. as discussed 
in Section 4.2. Recall that some messages, like the deformations mentioned in Section 2, will, when interpreted, 
change the methods the object uses to interpret messages further along in the list, Note also that objects 
change their methods in different situations. For example, applying a deformation to a spline patch might 
not cause it to change its methods if the inaccuracy of applying the deformation to the control hull 
(and not the patch itself) is acceptable [7]. When objects depend on other objects. traversal becomes 
recur­sive. Consider the figure watching a fly discussed in Section 3.4. To determine the orientation 
of an eye, the position of the fly must be determined. When. in interpreting the messages of the eye, 
the message containing the reference to the fly (i.e., asking the fly for its position) is reached, a 
recursive traversal of the fly begins. The fly s position is determined by interpreting the fly s list 
of messages. and then interpretation of the eye s list continues. The interpretation mechanism implicitly 
utilizes lazy evaluation: no calculations are performed until an object is actively asked for information. 
For example, time would be wasted in computing   SIGGRAPH 91 Las Veqas, 28 JuIY-2 Auwst 1991 polygonal 
boundary representations of CSG objects if all inquiries concerned the tree hierarchy of the object. 
We use lazy evaluation and the caching scheme described next to simultaneously avoid un­necessary computation 
and exploit inter-and intra-frame coherency. 4.2 Caching Messages can be used to store arbitrary information. 
Objects can send messages to themselves in order to cache useful but computa­tionally expensive data. 
Since such data is a function of time and messages are also functions of time, messages are an appropriate 
mechanism for data caching. The first time an inquiry is made, the object computes the value for the 
time of inquiry and the time interval over which that value holds. If a second inquiry is made within 
the valid interval, the object simply returns the previously computed value (see Figure 4). Note that 
some messages contain data relevant to the cache. If such a message is modified, the cache is marked 
as invalid (see Figure 5). Multiple edits to these messages simply flag the cache as invalid multiple 
times, a very cheap operation. Thus, several edits can be batched into one, and interactive updates become 
much faster, since the data is not recomputed until actually requested. % Ouerv: What do yo~ look like? 
Add a Cache ! b-rep Figure 4: An inquiry adds a cache to the end of a list of messages. Here, the cache 
is of a boundary representation (b-rep) of the object. Editing and subsequently invalidating a cache 
is a selective pro­cess: editing a translation invalidates only a cache of a transfor­mation matrix, 
not a cache of a polygonal boundary representa­tion. Objects understand how different messages affect 
each other. [n particular, they know which messages invalidate which caches. Further, since each cache 
stores the interval over which it is valid, invalidation may merely change the size and shape of that 
intewal (perhaps splitting it into multiple intervals) instead of completely invalidating it. If the 
edit changes the value of a message halfway through the time span of the cache s interval, the interval 
will be halved. More detailed manipulations of intervals are also supported, such as scaling and Boolean 
operations. Profiling indicates that the improvement in performance with caching more than justifies 
its expense. By monitoring memory usage, we have seen that animations using extensive caching use aPPmximately 
thirty percent more memory but achieve as much as a tenfold speedup. In these animations, the caching 
mechanism caches essentially all inquired data, for any time of inquiry, thereby minimizing the need 
to recalculate coherent data. Note that inter­ frame coherency is automatically exploited, since caches 
are valid over intervals of time. b-rep * A Edit this Messsage # This change marks the cache as invalid 
$ Figure 5: Editing a message before a cache can invalidate the cache. 4.3 Message list traversal with 
caching To see how the system works with caching, let s consider a sim­ple example: rendering all objects 
in a scene with a z-buffer. The renderer asks each object in the frame for its polygonal boundary representation. 
When inquired for the first time, each object com­putes its polygonal representation and caches it, marking 
it with the interval over which it is valid, and then gives the data to the renderer. The renderer then 
z-buffers the polygons, producing a frame. When the renderer asks an object for its polygons in the next 
frame, the object merely returns the previously computed boundary representation, if it is valid for 
the requested frame. Caching helps expedite inquiry within a frame as well. If we ask the same object 
more than once for the same data, inquiries after the first will perform much faster by just returning 
the cache. Consider a car with four tires, each alike (up to a linear transformation). The tire could 
be an expensive-to-compute spline surface, yet this surface could be computed only once, not four times. 
As another example, consider upd sting the figure in the fly ani­mation of Section 3.4. Suppose one of 
the points used in a path is translated. This translation invalidates the point s CTM cache (cur­rent 
transformation matrix). Since caches are generated when an object is asked for information, the identity 
of the inquiring object (here, the path) is also stored in the cache. Thus, when the cache is invalidated, 
the path is informed and invalidates its own caches. These caches include references to the duct made 
from the path, so the duct s cache of its boundary representation is also marked as in­valid. When the 
duct needs to provide its polygonal representation again, it will see its invalid cache and retraverse 
its list of messages, asking the path for the spline equations. The spline will notice its own invalid 
cache and recalculate the spline equations, asking the moved point for its new position. 5 Controllers 
As mentioned in Section 2, behavior can be encapsulated in objects we call controllers. A controller 
affects other objects by sending them messages that refer back to the controller. Consider an inverse 
kinematics controller that must make an articulated arm reach for a goal (see Figure 8). Each joint is 
an object with a message that specifies its orientation through a reference to the inverse kinematics 
controller. This dependency allows the controller to indicate the amount of translation and rotation 
produced by any joint at any given time. Interactive techniques can be considered controllers as well, 
for example, when a user specifies the initial conditions of a simulation (see Figure 9). In this case, 
the simulated objects reference a user interface object. The use of dependencies in this situation is 
similar to that de­scribed in Section 4.1, Thus. when the position of an object in the linkage is needed 
at a particular time t, the serial interpreta~ion of the object s messages begins. Upon reaching the 
translation or rotation message referencing the controller, the object asks the controller for the correct 
value. and the controller then supplies the necessary translation or rotation for the given time t. The 
messages sent to a controlled object by a controller are inten­tionally as abstract as possible. The 
responsibility of determining how these messages affect a controlled object is left to the object it­self, 
Essentially, a controller determines M>//atto do and a controlled object determines ltmr to do it. Consider, 
for example, a rigid-body dynamics simulation involving collision detection and response, It would be 
possible to have one controller handle all aspects of the simulation. exerting control by sending only 
translation and rota­tion messages to the controlled objects. However, we use instead a collision-response 
controller that sends it collision message to each controlled object: the object itself interprets the 
details of the collision message in terms of velocity (for momentum transfers) or acceleration (for continuous 
contact). This object-oriented approach to control has several advantages. First, it reduces the complexity 
of controller implementation. A controller need not keep track of how it is actually changing the specitic 
attributes of a controlled object, and this controller thus can store less information than might be 
needed by another controller affecting the same object, reducing the need for communication be­tween 
controllers. Second, our approach increases the efficiency of communication between controllers and objects. 
A single abstrdct message that directs changes to many attributes of an object requires less system overhead 
than many messages each of which concerns only a single imribute. Third. our approach allows different 
types of objects to respond differently to tbe same abstract command, so (hai a flexible object like 
cloth, for instiotce, can interpret a collision message ditierently from a rigid object,  6 Controller 
Interaction Allowing heterogeneous controllers to coexist and communicate in the same environment has 
been a research goal in computer graphics for several years [1] [12]. Such interaction between controllers 
should allow many powerful behavioral control techniques to affect a common set of objects in a meaningful 
way, The ideal system should be flexible. extensible and efficient. 6.1 Problems with interaction A number 
of difficult problems must be solved to achieve the goal of heterogeneous controller interaction. The 
first involves identi­fying Ihe aspects of interacting controllers that hinder successful cooperation. 
Consider the situation depicted in Figure6. The rod with end­points aandbhaslengthl. Thedistance between 
thetwowallsd and B is also 1, so it should bepossible to make the rod span the walls, Assume that we 
have d controller that can move a to A and a controller that can move b to B, and assume also that we 
constrain the rod to remain rigid, The simplest way to make the rod span the WUIISis to invoke the two 
controllers independently so that each handles the task of moving one endpoint to the appropriate wall. 
This solution does not necessarily work, however. Each controller might, for instance, decide that the 
simplest way to move an end­point to tbe wall is to tmnslate the rigid rod. Neither controller will realize 
that the rod must be rotated to allow both endpoints to touch the walls, so spanning will not be achieved. 
This problem cannot be solved until tbe controllers consider both endpoints. Diagnosing  Computer Graphics, 
volume 25, Number 4, July 1991 u 1 A \ h I Figure 6: An example of incompatible controllers. and correcting 
this lack of cooperation currently requires human intervention, and automation of the process does not 
seem feasible without severely restricting the possible controller types (e.g., to constraint solvers). 
Another issue in controller interaction is data incompatibility. This arises, for example. when a kinematic 
controller and a dy­namic controller both affect the same object. The dynamic con­troller works with 
velocity and acceleration data that the kinematic controller does not understand. When the kinematic 
controller changes the position of the object over time. however. the velocity of the object appears 
to change. If the dynamic controller is not made aware of this apparent change in velocity, its computation 
may produce visual inconsistencies. Controllers that work iteratively present a third problem. The iterations 
of different controllers may proceed at different rates. and aliasing may result. This problem can appear 
when several controllers perform numerical integration with different time step~. Our system provides 
several mechanisms that facilitate controller interaction, while trying to handle some of these problems. 
These mechanisms allow us to conduct further research into interaction policies. 6.2 Some solutions Certain 
attributes of an object are dependent on its other attributes. The object s position, for instance, is 
related to its velocity and acceleration. Our system provides a mechanism to maintain the relationships 
among the attributes of an object. When a controller inquires an attribute of a controlled object, the 
system keeps that at­tribute consistent with any related attributes, even if those attributes have been 
changed by other controllers. Consider, for example, a controller that handles momentum transfers in 
response to colli­sions. This controller adds a collision-response message to each object it controls; 
the velocity resulting from the message is non­zero only if the object has just penetrated another object. 
If some other controller needs to know the position of an object whose mm mentum was changed, the controlled 
object will conven the change in momentum to a change in velocity; the colli>ion-response con­troller 
need not be concerned with this issue. Caching and its relation to controllers are especially important 
for attributes related by differential equations (parametenzed by time). By caching the acceleration 
and velocity of an object at one instant in time, the system can use Euler s method [15] to obtain the 
velocity and position of that object at the next instant. We are currently investigating how to use the 
Runge-Kutta method of integration. This method is more effective overall than Euler s method. but because 
of our interobject dependencies, computing the necessary intermediate values may require global information: 
thus it cannot be implemented as easily in our system, which distributes I09 < . . SIGGRAPH 91 Las Vegas, 
28 July-2 August 1991  I!l% sl!6n APHtl ­ this global information and its interpretation among objects. 
Caching is also useful for the numerical differentiation of at­tributes, helpful in solving the data 
incompatibility between kine­matics and dynamics mentioned at the start of this section. A velocity corresponding 
to a kinematic change can be approximated by dividing the most recent displacement created by the kinematics 
controller by the elapsed time (in the animation s time units) from the previous displacement. A variety 
of interesting controller interactions can be created simply by using the mechanisms for maintaining 
related attributes. When multiple controllers send messages to the same object, the relative ordering 
of the messages determines how the effects of the controllers combine to determine the object s overall 
behavioc messages earlier in the list affect the object first, because of the order of traversal. We 
call this type of interaction srrict priority ordering. By allowing different orderings of the messages, 
the system can provide different effects, since messages are in general non-commutative (e.g., a translate 
followed by a rotate is not the same as a rotate followed by a translate). A more general mechanism for 
controller interaction is supported by allowing multiple controllers to affect one or more objects indi­rectly 
through an intermediary controller. The multiple controllers are referenced by messages to the intermediary 
controller, not to the controlled object, and the controlled objects reference only the intermediary 
controller. The job of the intermediary controller is to combine the effects of the multiple controllers 
into a meaningful result and convey this result to the controlled objects. Such inter­mediary controllers 
can be used whenever strict priority ordering is not sufficient, e.g., when the behavior of an object 
should be the weighted average of the effects of two controllers. A toolbox of standard intermediary 
controllers that perform useful functions (such as the weighted average) could be added to the system. 
7 An Example 3D Pong To see how this system works in practice, let s look at a sample inter­active environment: 
a 3D pong game in which a sphere represents the ball, and two cylinders, appropriately scaled and translated, 
rep­resent the paddles. We can play our game inside a court that is an object of revolution lying on 
its side, using scaled cylinders capping the ends of the revolve object for the back walls, the ones 
that the ball should not hit. Two pairs of dial objects control the paddles, so that two users can manipulate 
the paddles next to the appropriate walls. A collision­detection object checks for intersections between 
the ball, the re­volve object, the back walls, and the paddles. Finally, collision­response objects tell 
different objects what to do, One is responsible for collisions between the ball and anything except 
the back walls: when the ball hits the object of revolution, this object produces physically based collision-response 
messages. The ball then moves accordingly, while the revolve object uses a null interpretation of the 
response message and thus is unaffected by collisions. When the ball collides with a paddle, it uses 
the same collision-response interpretation as before, but the paddle would use its own, a dif­ferent 
one, perhaps one that makes the paddle visually light up. A second collision-response object will be 
responsible for collisions between the ball and the back walls. When the ball hits one of the back walls, 
the ball will receive a different kind of collision re­sponse message, since it will not bounce back. 
The wall s collision response interpretation will add a point to the current score. Many interesting 
features could be added to this game. For ex­ample, the walls of the court could change as the game progressed 
(possibly in response to collisions with the ball). The ball could move faster when hit by a faster paddle, 
despite the fact that the paddles are under kinematic control and have no intrinsic notion of velocity. 
Users could control their paddles in different ways, for ex­ample, using polar coordinates or Euclidean 
coordinates, simply by 110 changing the messages between the dials and the paddles. Moving obstacles 
could be placed between the two players, perhaps obsta­cles that follow the ball, or follow a pre-scnpted 
plan of motion. Since objects can be asked to display themselves at any time, instant replay of a game 
works automatically, allowing users to see what they just did, and change it. Finally, these features 
can be added interactively by the game players. 8 Summary We have designed and implemented an interactive 
graphics system [11 ] with an unusually close integration of modeling and anima­tion. All modeling is 
done through time-varying messages and thus all modeling tools can be used for animation. The system 
is object-oriented and provides a time-varying delegation hierarchy for maximum flexibility. Behavioral 
control is supported by giving controllers the respon­sibility for calculating what controlled objects 
are to do, while let­ting each object interpret the abstract instructions according to its own methods. 
Multiple controllers can operate independently by instructing their objects in priority order. Alternatively, 
intenrtedi­ary controllers can be written to integrate the behavior of control mechanisms. The system 
currently contains a large class of geo­metric primitives and a growing collection of user-interface 
objects and controllers. A number of efficiency mechanisms contribute to interactive performance. In 
particular, lazy evaluation and caching exploit all inherent inter-and intra-frame coherence. By distributing 
the database, we expect to further improve the performance of the sys­tem. It should be possible for 
each object to evaluate its messages in parallel, but we will have to consider scheduling problems when 
objects depend on each other. Our system is meant to go the next step beyond the scope of traditional 
graphics systems such as PHIGS+ or Dor&#38; Such systems enforce a rigidly divided modeiingfanimation/rendering 
pipeline. We believe our system provides some indications of where the next generation of graphics systems 
software is headed: towards an environment with both time and behavior as first-class notions, and not 
just shape description and rendering. 9 Acknowledgements We cannot begin to thank all the people that 
have made a system of this complexity possible. We would like to thank the many people who have commented 
on this paper, especially the reviewers. We would also like to thank Paul Strauss and Michael Natkin, 
architects of an earlier version of the system that provided much insight into the problem of a general 
animation system. In addition, the entire Brown Graphics Group, especially the artists, have provided 
much valuable criticism of the system s capabilities. References [1] Phil Ambum, Eric Grant, and Turner 
Whitted. Managing geometric complexity with enhanced procedural models. In Proceedings of the ACM SIGGRAPH, 
Computer Graphics, volume 20(4), pages 189-195, August 1986. [2] Alan H. Barr. Global and local deformations 
of solid prim­itives. In Proceedings of the ACM SIGGRAPH, Computer Graphics, volume 18(3), pages 2 1 
30, July 1984. [3] Ronen Barzel and Alan H. Barr. A modeling system based on dynamic constraints. In 
Proceedings of the ACM SIGGRAPH, Compurer Graphics, volume 22(4), pages 179 I 88, August 1988. [4] Lisa 
K. Borden. Articulated objects in BAGS. Master s thesis, Brown University, May 1990. [5] A. H, Boming. 
Classes versus prototypes in object-oriented languages. In IEEEIACM Fall Joint Computer Conference, pages 
36-40, 1986. [6] Ingfei Chen and David Busath. Animating a ceIIular transpotl mechanism. Pixel Magazine, 
1(2), 1990. [7] Gerald Farin. Curves and Surfaces for Computer-Aided Gee­memic Design. Academic Press, 
second edition, 1990.  [8] Tinsley A. Galyean. Sculpt: Interactive volumetric modeling. Master s thesis, 
Brown University, May 1990. [9] Andrew Glassner, editor. Graphics Gems. Academic Press, 1990, [10] Brent 
Halperin and Van Nguyen. A model for object-based inheritance. In Peter Wegner and Bruce Shriver, editorx, 
Re­search Directions in Object-Oriented Programming. The MIT preSS, 1987. [11 ] Philip M. Hubbard, Matthias 
M. Wloka, Robert C. Zeleznik, Daniel G. Aliaga, and Nathan Huang. UGA: A unified graph­ics architecture. 
Technical Report CS-91 -30, Brown Univer­sity, 1991. [12] Devendra Kalra. A Un@ed Framework for Constraint-Based 
Modeling. PhD thesis, California Institute of Technology, 1990. [13] Matthew Moore and Jane Wilhelms. 
Collision detection and response for computer animation. In Proceedings ofrhe ACM SIGGRAPH, Computer 
Graphics, volume 22(4), pages 289­298, August 1988, [14] Cary B. Phillips, Jianmin Zhao, and Norman I. 
Badler. hrter­active real-time articulated figure manipulation using multiple kinematic constraints. 
In Proceedings of the Symposium on interactive 3D Graphics, pages 245-250, 1990. [15] William H. Press, 
Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling. Numerical Recipes in C. Cambridge University 
Press, 1988. [ 16] T. W. Sederberg and S. R. Parry. Free-form deformation of solid geometric models. 
In Proceedings of the ACM SIG-GRAPH, Computer Graphics, volume 20(4), pages 151-160, August 1986. [17] 
Paul S. Strauss. A realistic lighting model for computer an­imators. IEEE Computer Graphics and Applications, 
10(6), November 1990. [ 18] Peter Wegner. The object-oriented classification paradigm. In Peter Wegner 
and Bruce Shriver, editors, Research Directions in Object-Oriented Programming. The MIT Press, 1987. 
[19] Jerry Weil. A simplified approach to animating cloth objects. Unpublished report written for Optomystic, 
1988. [20] Peter Wisskirchen. Object-Oriented Graphics. Springer-Verlag, 1990. [2 1] N. Yankelovich, 
N. Meyrowitz, and Andries van Dam. Read­ing and writing the electronic book. fEEE Computer, 18(10), October 
1985.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122731</article_id>
		<sort_key>113</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Inkwell]]></title>
		<subtitle><![CDATA[A 2-D animation system]]></subtitle>
		<page_from>113</page_from>
		<page_to>122</page_to>
		<doi_number>10.1145/122718.122731</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122731</url>
		<abstract>
			<par><![CDATA[Inkwell, an experimental 2 1/2-D keyframe animation system, is the subject of this paper. Inkwell provides an intuitive user interface for creating and animating polygons, ellipses and splines. These primitives may be outlined and filled with a variety of patterns to create animated diagrams, graphs and charts, and simple characters and cartoons. Inkwell also has a patch primitive that facilitates deformation and animation of textured regions. The system provides editing features that include shape and timing control as well as digital filtering of parameters. Finally, Inkwell has deformation primitives that enable an animator to warp geometry in an intuitive manner. Inkwell was used to produce <i>Pigment Promenade</i>, a computer animated short shown at SIGGRAPH 1990.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[character animation]]></kw>
			<kw><![CDATA[free form deformation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Interaction styles (e.g., commands, menus, forms, direct manipulation)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Paint systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P224653</person_id>
				<author_profile_id><![CDATA[81100614748]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Litwinowicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baecker, R. "Picture Driven Animation," Interactive Computer Graphics, edited by Herbert Freeman, IEEE Computer Society, 1980. Originally published in Conference Proceedings, Spring Joint Computer Conference, AFIPS, 1969.]]></ref_text>
				<ref_id>Baeck69</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N. and M. Wein. "Computer-Generated Key-Frame Animation." J. Society Motion Picture and Television Engineers. Vol 80, Number 3, 1971, pp. 149-153.]]></ref_text>
				<ref_id>Burt71</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360357</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Burtnyk, N. and M. Wein. "Interactive Skeleton Techniques for Enhancing Motion Dynamics in Key Frame Animation," CACM, Vol 19, Number 10, October 1976.]]></ref_text>
				<ref_id>Burt76</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Catmull,E. Tween Users' Manual. New York: CGL Inc., 1983.]]></ref_text>
				<ref_id>Catmull83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>889976</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Coons, S. Surfaces for Computer-aided Design of Space Forms, M.I.T MAC-TR-41, June 1967.]]></ref_text>
				<ref_id>Coons67</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83600</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Farin, G. Curves and Surfaces for Computer Aided Geometric Design, A Practical Guide. Second Edition. Academic Press, Inc., 1990.]]></ref_text>
				<ref_id>Farin90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Forrest, A. "On Coons and Other Methods for the Representation of Curved Surfaces," Computer Graphics and Image Processing, 1, 1972, pp. 341-369.]]></ref_text>
				<ref_id>Forr72</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gomez, J. "TWIXT: A 3D Animation System," Computers and Graphics, 9, Pergamon Press Ltd., 1985, pp. 291- 298. Originally in Proceedings of Eurographics "84.]]></ref_text>
				<ref_id>Gomez84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Honey, F. J., "Computer Animated Episodes by Single-Axis Rotations: CAESAR," Proceedings of the lOth UAIDE, 1971, pp. 3.210-3.226.]]></ref_text>
				<ref_id>Honey71</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808575</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kochanek, D. and R. Barrels. "Interpolating Splines with Local Tension, Continuity and Bias Control," Computer Graphics, Vol 18, Number 3, July 1984, pp. 33-41.]]></ref_text>
				<ref_id>Koch84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Linton, M., P. Calder and J. Vlissides. "The Design and Implementation of InterViews," Proceedings of the USENIX C+ + Workshop, November 1987.]]></ref_text>
				<ref_id>Lint87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[MacDraw (users' manual). Apple Computer, Product Number M1509.]]></ref_text>
				<ref_id>Mac84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>77000</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Oppenheim, A. and R. Schafer. Digital Signal Processing, Prentice-Hall, 1975.]]></ref_text>
				<ref_id>Oppen75</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Patterson, E., P. Litwinowicz, and N. Greene, "Facial Animation by Spatial Mapping." Computer Animation 1991.]]></ref_text>
				<ref_id>Patt91</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806814</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Reeves, W. "lnbetweening for Computer Animation Utilizing Moving Point Constraints," Computer Graphics, Vol 15, Number 3, August 1981, pp. 263-269.]]></ref_text>
				<ref_id>Reeves81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801293</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. "Computer Animation with Scripts and Actors," Computer Graphics, Vol 16, Number 3, July 1982, pp. 157-166.]]></ref_text>
				<ref_id>Reyn82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. and S. Parry. "Free-Form Deformation of Solid Geometric Models," Computer Graphics, Vol 20, Number 4, August 1986, pp. 151-160.]]></ref_text>
				<ref_id>Sed86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325243</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Steketee, Scott N. and N. Badler. "Parametric Key Frame Interpolation Incorporating Kinetic and Phrasing Control," Computer Graphics, Vol 19, Number 3, July 1985, pp. 255-262.]]></ref_text>
				<ref_id>Stek85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Sturman, D. "Interactive Keyframe Animation of 3D Articulated Models," Course notes, SIGGRAPH Course Number 10, Computer Animation: 3D Motion Specification and Control, July 1985, pp. 17-25.]]></ref_text>
				<ref_id>Sturm85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. "Sketchpad: A Man-Machine Graphical Communication System," MIT Lincoln Laboratory Technical Report, Number 296, January 1963.]]></ref_text>
				<ref_id>Suth63</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Witkin, A. and W. Welch. "Fast Animation and Control of Nonrigid Structures," Computer Graphics, Vol 24, Number 4, August 1990, pp. 243-250.]]></ref_text>
				<ref_id>Witk90</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Inkwell: A 2%-D Animation System Peter C. Litwinowicz Advanced Technology Group Apple Computer Inc. 
 ABSTRACT Inkwell, an experimental 214-D key frame animation system, is the subject of this paper. Inkwell 
provides an intuitive user interface for creating and animating polygons, ellipses and splines. These 
primitives may be outlined and filled with a variety of patterns to create animated diagrams, graphs 
and charts, and simple characters and cartoons. Inkwell also has a patch primitive that facilitates deformation 
and animation of textured regions. The system provides editing features that include shape and timing 
control as well as digital filtering of parameters. Fhtally, Inkwell has deformation primitives that 
enable an animator to warp geometry in an intuitive manner. Inkwell was used to produce Pigment Promenade, 
a computer animated short shown at SIGGRAPH 1990. CR Categories and Subject Descriptors: 1.3.6 [Computer 
Graphics]: Methodology and Techniques -Interaction Tech­niques. Additional Key Words and Phrases: Animation. 
character ani­mation, free form deformation. Interaction with pictures has been a focus of computer 
graphics since Sutherland s Sketchpad [Suth63]. It wasn t long before computer animation systems were 
created 10 choreograph draw­ings in motion. An early system, Genesys [Baeck69], enabled an animator to 
hand draw pictures, hierarchically arrange and transform them, and specify how to play them back. Another 
early system, described in [Burt71 ], performed actual metamorphoses between drawings, breaking up or 
combining lines if the number of primitives did not match between the two drawings. Tween, a commercial 
system developed at NYIT, provided for the animation of antialiased colored lines and tilled regions 
[Catmul183]. Computer animation systems have become much more sophisticated since then. In most animation 
systems, when a parameter is set for a particular frame all other parameters need not be specified. Because 
of this, keyframing as such has taken Permission to copy without fcc all m part of th]s material is granted 
pruvided that the cnpics are nnl made or distributed for direct commercial advantage. the ACMcopyrightnoticeandthe 
title of the publicationand its datetippew,and noticeis given that copying is by permission of the Associationfnr 
Computing Machinery. TCIcopy otherwise, or tt>republish, requires a fce mrdk)r specific permission. on 
an entirely new meaning. Each parameter ( track ) in the animation can have its own set of independent 
key frames [Gomez84]. Many techniques have been developed to give better control of parameters. These 
range from shape controls [Sturm85] to speed and acceleration controls [Stek85]. Parameter values may 
also be derived from video tracking or computed via computer simulations. Scripting is an alternative 
to direct manipulation which may Ee a helpful supplement to direct manipulation for some applications 
[Reyn82]. Dynamic simulation of non-rigid 2D bodies in an interactive system (where the user specifies 
constraints and initial conditions) has been explored in ~itk90]. INTRODUCTION Creating a 2112-Danimation 
system that is comprehensive and in. tuitive presents a real challenge. A 2111-Danimation system is defined 
here to be a system that maintains a drawing order for 2D objects causing the objtits to appear to be 
layered on top of each other. We have borrowed many ideas from the systems referred to previously, added 
a few new ideas of our own and have tied them together with an intuitive user interface. Designing and 
building the user interface was the most difficult part of develop­ing the system and will be the main 
focus of this paper. In building Inkwell, we had three goals in mind. The first was to provide an animation 
system that is a natural extension of drawing and painting, and is as intuitive as possible. We believe 
that char­acter animation is the most difficult challenge to a computer ani­mation system so we adopted 
it as a benchmark: users had to be able to create believable personalities, feelings and expression through 
motion. Fktally, we required that Inkwell provide a test­bcd for researching clip motion: the flexible 
re-use of defined motion sequences. In order to keep Inkwell intuitive, all of its capabilities may be 
exercised by direct manipulation. Inkwell allows animators to translate, rotate, scale and stretch 2D 
objects, either interactively or by entering precise values via the keyboard. Polylines, polygons and 
splines maybe more generally deformed by simply moving their control points to change their shape. Objects 
may also be deformed using space warping operations. Objects can be hierarchically arranged into groups 
and then manipulated as a single object. Patch primitives may be rendered with color, translucency, and 
displacement maps. When displacement maps ACM -()-89791-43&#38;tf/9 l/(x)7/(1113 sfK1.75 5 SIGGRAPH 
91 Las Vegas, 28 July-2 August 1991 Figure 1. This is Inkwell s drawing area. The top row of buttons 
are VCR-like controls that en- able the animator to single step, rewind, fast forward and play the animation. 
The second row shows the current frame number, and the time span of current interest (the Loop, LoopBack, 
and Rock commands use the designated time span). A background picture is displayed and a number of splined 
birds are being animated. One of the birds is being edited at frame 0, and its control points are shown. 
are applied, patches can be shaded as 3D objects. After keyframes have been specified, the various transformations 
are interpolated to create inbetweens. The animator can conmol the interpolation process with a variety 
of tools. At any time the animator can preview the animation with a set of VCR-like controls. Once the 
previewed motion is satisfactory, rendering occurs in a separate post-process. [Figure 1] depicts InkwelI 
s main drawing area. The current implementation of Inkwell is an extension of Stanford s Idraw program, 
built upon Stanfords InterViews interaction toolkit [Lint87], which has been ported to Apple s Quickdraw 
library, the X Window System, and Silicon Graphics Graphics Libra~. Hence, Inkwell runs on a Macintosh, 
or any machine running X, and rakes full advantage of the hardware graphics pipeline on an SGI Iris. 
DRAWING INTERACTION Drawing is a natural means of communication through pictures, and people without 
highly developed drawing skills can use com­puters to produce useful, communicative images and diagrams. 
Inkwell attempts to extend interactive drawing metaphors to gov­ern time and motion. Inkwell s drawing 
interaction is borrowed largely from AltoDraw, developed at Xerox Pare, and Claris MacDraw [Mac84]. The 
animator is supplied a variety of tools that fit into two categories, creation and action tools. The 
creation tools allow the animator to make new objects, including polylines, polygons, and both open and 
closed B-splines. The borders of objects may have a variety of different 1ine types and may be filled 
with a number of different patterns. Each object has specified colors for its pattern fill and border. 
Inkwell has a large palette of action tools that allow the animator to manipulate objects. First, the 
animator selects an object to be manipulated. Many objects may be selected at the same time by depressing 
the shift key while picking. The animator may then translate, scale, stretch or rotate the selection(s). 
These transformations work about a center that may be set by the animator. The animator may change the 
shape of an object by moving some or all of its control points when the reshape tool has been chosen. 
Objects may be grouped together by selecting them together and applying the groupcommand. A group is 
an object that can be scaled, rotated, stretched and translated as a unit. A group may then be incorporated 
into larger groups. In MacDraw, once objects are grouped the individual objects can no longer be accessed. 
This is not acceptable in an animation program. The animator needs to be able to select and manipulate 
leaf nodes of the hierarchy, as well as the various groups and subgroups. This, of course, means that 
the way objects are selected must differ. Fkst, if the cursor is actually touching a geometric primitive, 
it is picked, even if it is at a leaf node of a hierarchy. If the cursor does not touch a primitive, 
the smallest group whose bounding box encloses the cursor is chosen. If there is ambiguity, the object 
closest to the front is picked (the drawing order of objects, and thus their implicit front-to-back ordering, 
are initially determined by the order in which they are entere&#38; editing commands are provided to 
change object priority). he animator can cycle through a series of objects over a given point by continuing 
to click the mouse. After selecting an object, the animator can optionally select its parent by invoking 
a Go-Up-The-Hierarchy command. Computer Graphics, Volume 25, Number 4, JUIV1991 Inkwell, being an animation 
program, must allow for the editing of objects in time. Inkwell supports this by maintaining the notion 
of a current frame (and its associated time). When manipulating an object the animator is defining a 
key at the current frame for whatever parameter is being e&#38;ted (translation, rotation, etc.). If 
the control button is depressed when an object is manipulated, the transformation specified is applied 
to the entire animation (all keys) of the selection. As an example, consider a user of the system who 
has animated a bird flying around a building. The animator then decides to move the building to the other 
side of the frame. Instead of having to redo every key for the bird so that it moves around the newly 
positioned building, all he needs to do is reposition one of the keys while holding the control button 
down, and the bird will then fly around the new position of the building. This obviates the need for 
creating another level of hierarchy for the bird, which should not be necessary simply to reposition 
the animated sequence. Creating another level of the hierarchy is often a very useful tactic as well, 
since this allows the user to transform the animation at any desired set of sparse keys. A simple walk 
cycle can be looped by copying keys, then adapted to a desired path for the character by transforming 
the extra level of the hierarchy. The character may be scaled, moved, and rotated at any set of frames 
(frames that may not have been keys in the original cycle), and the reinterpolated character will execute 
his walk along the desired path. By applying negative scales, the character can even turn around or flip 
over, although an anorexic intermediate profile will result. This opens the door to significant adaptation 
and re-use of motion sequences, and suggests a very powerful form of animation based on modifying and 
blending Iibraries of motion. Background pictures may be read into Inkwell. The animator may then create 
and interact with objects on top of the picture. fIris fa­cilitates rotoscoping as weil as texture map 
placement for patches (to be described subsequently). The animator also has at his disposal a computerized 
light table. The animator can pick up to six frames (at times other than at the current frame) that will 
be faintly drawn ( ghosted) into the current frame. In this way the animator can determine how the shape 
and placement of the cument frame relates to other frames. I I Figure 2. Three sets of identical keys 
with different types of interpolations. CONTROLLING PARAMETERS  Interpolation of Keys A key frame is 
created automatically every time the animator changes a parameter, and every parameter is keyed separately. 
As the animator creates keys, they are, by default, inserted as knots SIGGRAPH 91 Las Veaas, 28 JuIv-2 
Aum.tst 1991 into an interpolating cubic spline with local tension, bias and continuity control as described 
in [Koch84]. If desired, the animator can specify that the keys for a parameter should be linearly or 
stepwise interpolated [figure 2]. When selecting an object, its transformation parameter curves show 
up in a function editor window. The parameter curves may be edited dkectly here instead of manipulating 
objects in the main drawing area. The function editor allows simple editing, such as setting the tension, 
bias and continuity parameters for spline knots, deleting and moving spline knots, and cutting and pasting 
portions of curves. Filtering of parameters The animator can create filters that smooth, overshoot, 
or add wiggle to a parameter [figure 3]. Filters essentially model the behavior of linear systems (the 
shock absorbers of a car, for example) at a high level of abstraction, with a direct visual representation 
of their effects. After specifying a particular filter, the animator can apply it to a parameter over 
a specified range of time. With the filter command the animator may smooth noisy data arising from hand 
input or some outside source such as video. The animator can also add dynamic effects that are easy to 
control, cheap to compute, and occur at exactly the times desired. In order to provide even greater visual 
control over filtering, the animator will be able to draw finite immtlse resoonses directlv in .. a 
future release of Inkwell. Figure 3. The top curve represents a parameter to be filtered. The lower two 
curves are the results after applying the filters shown in Figure 4. In order to visualize the effects 
of a particular filter, a step function is displayed along with the step response to the filter [figure 
4]. The filter may be modified by three sliders which control the gain, decay and amount of oscillation 
of the filter. Let k, r and 9 be the variables for gain, decay and oscillation, respectively. We use 
a 3-tap infinite impulse response (IIR) filter, which has the following formula: X i= a xi+ b X i-l+ 
c X i-z where x variables represent values after the application of the filter [Oppen75]. We set a, b 
and c to be: a=k b= 2 r COS(0) c=-r 2 where in practice we let r e [0,.95], k G [-3.0,3.0] and e E [O,rt]. 
The initial values for k, r and e are 1.0, 0.0 and 0.0 respectively,  Figure 4. Two of many III? filters 
that can be specified in Inkwell. giving the identity filter. The gain at DC of this filter is: l/(1 
-2rc0s(t3) +?) lt has been our experience that most users prefer that when k=l, they see a gain of 1.0 
at DC. We therefore modify the first tap on the filter to have the formula: a=k*(l-2r cos(t3)+#) In this 
way, k is a direct control of the gain of the filter at DC. This formal statement of the filter s specification 
is of no concern to animators. In practice, the filter parameters adjust the magni­tude, wiggle, and 
lag of a filtered motion, and these effects are easily controlled with a little practice. Editing a 
Curve with Dsnseiy Spaced Knots Conventional spline editing falls flat when a parameter has a key at 
every (or nearly every) frame. Densely spaced keys can occur from editing by hand, but more commonly 
occur after filtering a parameter or acquiring data from some other source, such as tracked video. When 
knots are densely spaced, editing one of these control points can introduce an undesired jump in the 
animation. To aid in smoothing the transition, Inkwell allows the animator to blend a key into its neighboring 
keys [figure 5]. A cosine window is used to blend in the change forward and backward in time, and can 
be scaled separately in each direction. WARPING GEOMETRY AND TEXTURE Coons Patches This section discusses 
how the animator controls non-rigid body 63 + I Figure 5. On the top a curve has been edited that has 
densely spaced knots. The lower curve shows the ef- fects of blending this change into the eight previous 
and fifteen subsequent frames. transformations. The animator is able to specify the shape of polylines, 
polygons, and splines at given times (as described above) and then have Inkwell calculate the inbetweens. 
In this way the animator can metamorphose an object from one shape to another. But there is a geometric 
primitive not yet discussed that allows the animator to deform textured regions as well. This is the 
Coons patch [Coons67][Forr72]. Coons patches are natural to use because they are specified solely by 
their boundaries, which may be hand-drawn curves as well as polylines or splines. A space warping algorithm 
using linear skeletons is described in [Burt76]; a Coons-patch version should permit curved bones. Other 
space-warping techniques using a 3D lattice of control points are described in [Sed86] and [Farin90]; 
these have their counterparts in Coons volumes, which should extend the deformations naturally to 3D. 
In [Reeve&#38;l], an algorithm using Coons patches was described to warp shapes over time, where two 
sides of the Coons patch represented a curve s shape at two different times and the other two boundaries 
represented the path of the curve s endpoints over a specified span of time. All of these possibilities 
support our interest in Coons parameterization for animation purposes. Thus far, we have only explored 
Coons Figure 6. On the left, four boundaries for a Coons patch are drawn around a background picture 
containing a cartoon shark. On the right, the region of the back- ground picture that is covered by the 
Coons patch has been inverse texture mapped to the unit square. It is this square texture that is used 
to texture map the patches in Figure 7. Comwter GraDhics. Volume 25. Number 4. Julv 1991 patches as 
a means of animating textured shapes, with optional alpha mattes and displacement maps. The animator 
first creates four splines or polylines that will en-close regions for animation. After selecting four 
of them, a Make-Coons-Patch command makes the four selected curves the boundaries for a bilinear Coons 
patch. If one or more of the objects selected is already part of a Coons patch, Inkwell adds the patch 
to a mesh of Coons patches where boundaries are shared. Inkwell also facilitates the placement of texture 
maps for Coons patches. As described previously, a background picture may be loaded into the drawing 
area so that an animator may draw on top of it (or rotoscope from it). In [figure 6, left], the animator 
has drawn four boundaries of a Coons patch on top of the background image containing a shark. After creating 
a Coons patch, the animator may execute a command that acquires the portion of the picture under the 
Coons patch as its texture map. Inkwell performs inverse texture mapping to warp the portion of the picture 
underneath the Coons patch to the unit square [figure 6, right]. In subsequent frames, as the Coons patch 
metamorphosizes, the texture will also [figure 71. Figure 7. In the first row, boundaries for a Coons 
patch are shown at three different times. The second row shows the parameterizations for the patches. 
The third row shows the textured patches. Displacement maps are read in as gray scale pictures, with 
white being nearest the viewer and black the farthest away. Once again, the animator may execute a command 
that acquires the portion of the picture under the Coons patch as its displacement map. In the rendering 
phase, the height of the object will be derived from the displacement map. In this way a 3D relief surface 
can be animated by manipulating its 2D outline. Color texture, translucency and displacement maps may 
be changed over time. The values of the maps between keys are linearly interpolated (cross-dissolved). 
This offers another dimension of color and 3D shape control. Other types of transi- tions between textures 
such as wipes and pushes are planned for a future release of Inkwell. In [figure 81 a more complex example 
is shown. In the top row, the animator has specified a walk cycle with ellipses. This is a typical instance 
of animation created using hierarchically transformed rigid geometric primitives. After refining the 
motion to get the timing desired, the animator then created and animated, by hand, Coons patches to 
follow the ellipses, as shown in the second row. The same Coons patches have been used to animate a number 
of different characters, as shown in the third, fourth and fifth rows. Now this patch animation can be 
applied to any texture maps, displacement maps, and mattes the user should desire. This sortof''rubber 
doll' `animation of bocfy parts mapped onto deformable regions is actually a throwback to very early 
digital-analog hybrid animation systems [Honey71]. Our strictly digital implementation provides a number 
of advantages (more general deformations, true 24-bit color, and better repeatability), but shares the 
basic flexibility of animating deformations that can subsequently be applied to different characters. 
This form of Coons patch animation isanotherpowerftsl tool for the reuse of motion. In future enhancements, 
Coons patches will also be used as deformation functions for geometric primitives as well as textures. 
 Warping with Cosine Windows Animations that contain a large number of primitives present the animator 
with many variables to orchestrate, including a set of transformations for each primitive and a potentially 
large number of control points for splines and polylines. It is often desirable to have higher levels 
of control. Currently, InkweIl provides a space warping operation that warps geometry using cosine (Harming) 
basis window functions. The animator specifies a neutral position and extent for a warping window; as 
the warping window moves it pulls and pushes on the geometry around it. This is simply the 2D, spatial 
counterpart of blending changes in parameter values into the surrounding time-sequence, described earlier 
in Editing a Curve with Densely Spaced Knots. The space warping algorithm used in Inkwell requires a 
displacement vector and a radius of extent for each warping window. The animator first creates a warping 
window primitive (it is shown as a circle with a dot for the center). The original placement, or neutral 
position, of the window is one point used in detenrnining the displacement vector. The second point used 
is the position of the window at the current frame. This window is scaled by the animator to the appropriate 
size and hence, extent. As the animator moves the wa~ing window about, it will pull and push on the geometry 
near its neutral position towards the current position, with the geometry nearest the neutral position 
being pushed the most. (The neutral position can be changed if the original placement of the window is 
unsatisfactory). To actually warp geometry, the animator selects the cosine window primitive along with 
the polylines and splines that are to be warped, and then executes the Warp-Geometry command. The lines 
and splines are warped depending on their proximity to the center of the neutral position of the warping 
window [fig 9]. The facial animation in The Audirkm was edited with Inkwell using this technique. The 
initial motion for the centers of the windows were tracked and mapped from a live performer and read 
into {he program [Patt91 ]. The animator could then edit the positions of the warp windows to exaggerate 
or otherwise enhance the motion [figure 10]. Preview of the newly positioned warping functions and their 
effects can be seen in near real time.  OUTPUT Scenes may be rendered and sent to a video device for 
playback. Computer Graphics, Volume 25, Number 4, July 1991 Figure 9. The neutral position of a warping 
window and geometric primitives to be warped are shown on the left. The warping window is then moved 
and the underlying ge­ ometry is warped as shown on the right. The arrow shows the displacement vector. 
This is the 2D counterpart of the cosine-window blending applied to edit a parameter curve in Figure 
5. But since the information is kept in a resolution independent format, Inkwell animations could also 
be sent to film or a laser printer for higher resolution output (and, in fact, short flip books have 
been printed).  CONCLUSIONS, EXPERIENCE AND FUTURE DIREC-TIONS Inkwell has been used in-house to produce 
a variety of animations. Pigment Promenade was produced in two weeks (including soundtrack!) by two animators, 
without recourse to overtime or weekends. Using cosine warping windows and an overshooting IIR filter, 
an animation of a spider dropping onto its web, with bouncing, springy effects, was specified in one 
hour, A walk cycle, animated by Kim Tempest, required only a half day to specify with Inkwell, and has 
been used to animate three characters with minimal preparation and set-up time (1 hour each for the second 
and third characters). In our introductory remarks, we stated three goals for Inkwell. The first was 
to achieve an easy and intuitive user interface for animation. The results are encouraging. One coworker 
s first animation consisted of a Mazda Miata zooming into the distance, accomplished in only three hours 
of work, after a couple of hours of instruction. We also stated that animation should be a natural extension 
of painting and drawing. Inkwell to date is not really a drawing program. Rather, Inkwell is more like 
a drafting pro­gram, forcing the user to input control points of splines and polylines. A drawing interface 
that allows curves to be input without placing control points is desirable, and should be easy to implement. 
The paradigm of moving each knot point in a spl ine or poiyline to animate it is also somewhat restrictive. 
It would be nice to simply redraw the new shape, specifying which object becomes the newly drawn shape 
at the current frame. Having a strictly prioritized drawing order can create problems when animating. 
To animate an arm it is sometimes desirable to detach the arm from the body and animate it as a separate 
Coons patch mesh. When doing this, it is impossible to have the top of the arm drawn behind the torso, 
while the hand is in front of the body. Cumently, there are two solutions: 1) place the arm entirely 
in front of (or behind) the body or 2) break the arm into two pieces. Neither solution, in this case, 
is entirely satisfactory. h would be desirable to specify intermesh ordering of patches, but it   
REFERENCES [Baeck69] Baecker, R. Picture Driven Animation, Irrteruc­rive Cornpufer Graphics, edited 
by Herbert Freeman, IEEE Computer Society, 1980. Originally published in Conference Proceedings, Spring 
Joint Computer Conference, AFIPS, 1969. [Burt71] Burtnyk, N. and M. Wein. Computer-Generated Key-Frame 
Animation. J. Society Motion Picture and Television Engineers, VO180, Number 3, 1971, pp. 149-153. [Burt76] 
Burtnyk, N. and M. Wein. Interactive Skeleton Techniques for Enhancing Motion Dynamics in Key Frame Animation, 
CACIU, Vol 19, Number 10, October 1976. [Catmul183] Catmull,E. Tween Users Manual. New York: CCL Inc., 
1983. [Coons67] Coons, S. Su~aces for Computer-aided Design of Space Forms, M.LT MAC-TR-41, June 1967. 
[Farin90] Farin, G. Curves and Surjacesfor Computer Aided Geometric Design, A Practical Guide. Second 
Edition. Academic Press, Inc., 1990. [Forr72] Forrest, A. On Coons and Other Methods for the Representation 
of Curved Surfaces, Computer Graphics and Image Processing, 1, 1972, pp. 341-369. [Gomez84] Gomez, J. 
TWIXT A 3D Animation System, Computers and Graphics, 9, Pergamon Press Ltd., 1985, pp. 291­ 298. Original] 
yin Proceedings of Eurographics 84. [Honey71 ] Honey, F. J., Computtr Animated Episodes by Single-Axis 
Rotations: CAESAR, Proceedings of the 10th UAIDE, 1971, pp. 3.210-3.226. [Koch84] Kochanek, D. and R. 
Bartels. Interpolating Splines with Local Tension, Continuity and Bias Control, Com­puter Graphics, Vol 
18, Number 3, July 1984, pp. 33-41. [Lint87] Linton, M., P. Calder and J. Vlissides. The Design and Implementation 
of InterViews, Proceedings of the USENIX C+ + Workshop, November 1987. [Mac84] MacDraw (users manual). 
Apple Computer, Product Number Ml 509. [@pen751 Oppenheim, A. and R. Schafer. Digital Signal Processing, 
Prentice-Hall, 1975. [Patt91] Patterson, E., P. Litwinowicz, and N. Greene, Facial Animation by Spatial 
Mapping. Computer Animation 1991. [Reeves81 ] Reeves, W. Inbetweening for Computer Animation Utilizing 
Moving Point Constraints, Computer Graphics, Vol 15, Number 3, August 1981, pp. 263-269. [Reynt32] Reynolds, 
C. Computer Animation with Scripts and Actors, Computer Graphics, Vol 16, Number 3, July 1982, pp. 157-166. 
 Deformation of Solid Geometric Models, Compufer Graphics, Vol 20, Number 4, August 1986, pp. 151-160. 
[Stek85] Steketee, Scott N. and N. Badler. Parametric Key Frame Interpolation Incorporating Kinetic and 
phrasing Control, Computer Graphics, Vol 19, Number 3, July 1985, pp. 255-262. [Sturm85] Sturman, D. 
Interactive Keyframe Animation of 3D Articulated Models, Course notes, SIGGRAPH Course Number 10, Computer 
Animation: 3D Motion Specljication and Control, July 1985, pp. 17-25. [Suth63] Sutherland, I. Sketchpad: 
A Man-Machine Graphical Communication System, MIT Lincoln Laboratory Technical Report, Number 296, January 
1%3. [Witk90] Witkin, A. and W. Welch. Fast Animation and Control of Nonrigid Structures, Computer Graphics, 
Vol 24, Number 4, August 1990, pp. 243-250. APPENDIX A Blending into Densely Spsced Knots After an animator 
makes an adjustment to a curve, as shown in [figure 5, top], he can then blend this change into the previous 
and subsequent frames. Let the number of previous and subsequent frames be denoted by p and s respectively, 
and the current frame be denoted by c. Let the variables denoting the values of the curves &#38;fore 
and after the blend be denoted by old­val and newval respectively. The following pseudo code will calculate 
the desired blend: for i=pto c-1 step 1 Note that the weighting factor ranges porn O to 1 as i ranges 
from p-1 to c notfrom p to c. Therefore, we have the term (c-pwi) in the denominator, instead of (C-P) 
weight =(1 +cos(n*(c-i)/(c-p+l )))/ 2.0, newval[i] = oldval[i] * weight + oldval[c]*( 1-weight); for 
i =c+l tos step 1 weight =(1 +cos(rt*(s-i)/(s-c+l ))) / 2.0 newval[i] = oldval[i] * weight + oldval[c]*( 
1-weight); [Figure 5, bottom] shows the curve after blending an edit into the eight previous and fifteen 
subsequent frames. [sed86] Sederberg, T. and S. Parry. Free-Form EE: SIGGRAPH 91 Las Vegas, 28 July-2 
August 1991 . !l$61A?n 11- APPENDIX B Warping with Cosine Windows The following pseudo code describes 
how warping is accomplished. n = neutral position of a warping window e = extent of the warping window 
 note: this is a scalar d= displacement vector p= a point of a geometric primitive that is to be warped 
p = p after warping   if (length(p -n) > e) The point is not part of the affected region for the given 
cosine window, so no warping occurs p =p else [ Modifi the displacement by a scalar based on distance 
from the neutral position and then add it to the point to be warped.  ; = p + d*((l +cos(n*length(p 
-n)/e))/ 2.0 See [Patt91] for a discussion of how warping is handled when two or more warping windows 
overlap.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122732</article_id>
		<sort_key>123</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Automated generation of intent-based 3D Illustrations]]></title>
		<page_from>123</page_from>
		<page_to>132</page_to>
		<doi_number>10.1145/122718.122732</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122732</url>
		<abstract>
			<par><![CDATA[This paper describes an automated intent-based approach to illustration. An <i>illustrution</i> is a picture that is designed to fulfill a communicative intent such as showing the location of an object or showing how an object is manipulated. An illustration is generated by implementing a set of stylistic decisions, ranging from determining the way in which an individual object is lit, to deciding the general composition of the illustration. The design of an illustration is treated as a goal-driven process within a system of constraints. The goal is to achieve communicative intent; the constraints are the illustrative techniques an illustrator can apply.We have developed IBIS (Intent-Based Illustration System), a system that puts these ideas into practice. IBIS designs illustrations using a generate-and-test approach, relying upon a rule-based system of methods and evaluators. Methods are rules that specify how to accomplish visual effects, while evaluators are rules that specify how to determine how well a visual effect is accomplished in an illustration. Examples of illustrations designed by IBIS are included.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[automated picture generation]]></kw>
			<kw><![CDATA[illustrations]]></kw>
			<kw><![CDATA[knowledge-based graphics]]></kw>
			<kw><![CDATA[non-photorealistic rendering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Viewing algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Picture description languages**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011050.10011023</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Context specific languages->Specialized application languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P69228</person_id>
				<author_profile_id><![CDATA[81100194989]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dor&#233;e]]></first_name>
				<middle_name><![CDATA[Duncan]]></middle_name>
				<last_name><![CDATA[Seligmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Columbia University, New York, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39042315</person_id>
				<author_profile_id><![CDATA[81100427474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feiner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Columbia University, New York, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chakravarty, I., and Freeman, H. Characteristic Views as a Basis for Three-Dimensional Object Recognition. In <i>Proc. Society for Photo-Optical Instrumentation Engineers Conf. on Robot Vision</i>, Bellingham, WA, SPIE, vol. 336, 1982. 37-54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74343</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chin, N. and Feiner S. Near Real-Time Shadow Generation using BSP Trees. In <i>Proc. ACM SIGGRAPH 89</i> (<i>Computer Graphics</i>, 23(3), July 1989), Boston, MA, July 31-August 4, 1989, 99-106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Culbert, C. <i>CLIPS Reference Manual</i>. NASA/Johnson Space Center, TX, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>91422</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dooley, D. and Cohen, M. Automatic Illustration of 3D Geometric Models: Lines. In <i>Proc. 1990 Symp. on Interactive 3D Graphics</i> (<i>Computer Graphics 24(2)</i>, March 1990), Snowbird, UT, March 25-28, 1990, 77-82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949579</ref_obj_id>
				<ref_obj_pid>949531</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dooley, D. and Cohen, M. Automatic Illustration of 3D Geometric Models: Surfaces. In <i>Proc. Visualization '90</i>, San Francisco, CA, October 23-26, 1990, 307-314.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Elhadad, M., Seligmann, D.D., Feiner, S., and McKeown, K. A Common Intention Description Language for Interactive Multi-Media Systems. <i>IJCAI-89 Workshop on Intelligent Interfaces</i>, Detroit, MI, August 22, 1989, 46-52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Feiner, Steven K. APEX: An Experiment in the Automated Creation of Pictoral Explanations. <i>IEEE Computer Graphics and Applications 5(11)</i>, November 1985, 29-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>96797</ref_obj_id>
				<ref_obj_pid>96751</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Feiner, S. and McKeown, K. Generating Coordinated Multimedia Explanations. In <i>Proc. CAIA90 (6th IEEE Conf. on Artificial Intelligence Applications)</i>, Santa Barbara, CA, March 5-9, 1900, 290-296.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Feiner, S. and McKeown, K. Coordinating text and graphics in explanation generation. In <i>Proc. AAAI-90</i>, Boston, MA, July 29-August 3,199O. 442-449.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Feiner, S. and Seligmann, D.D. Dynamic 3D Illustrations with Visibility Constraints. In <i>Proc. Computer Graphics International 91</i>, Cambridge, MA, June 24-28, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Foley, J., van Dam, A., Feiner, S., and Hughes, J. <i>Computer Graphics: Principles and Practice 2nd Edition</i>. Addison-Wesley, Reading, MA, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808577</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Friedell, M. Automatic Synthesis of Graphical Object Descriptions. <i>Computer Graphics 18(3)</i>, July 1984, 53-62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1208132</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Giesecke, F., Mitchell, A., and Spencer, H. <i>Technical Drawing</i>. New York, The Macmillan Co., 1936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>35042</ref_obj_id>
				<ref_obj_pid>35039</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kamada, T. and Kawai, S. An Enhanced Treatment of Hidden Lines. <i>ACM Trans. on Graphics</i> 6(4), October, 1987, 308-323.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>45600</ref_obj_id>
				<ref_obj_pid>45596</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kamada, T. and Kawai, S. A Simple Method for Computing General Position in Displaying Three-Dimensional Objects. <i>Computer Vision, Graphics and Image Processing 41(1)</i>, January, 1988, 43-56.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>22950</ref_obj_id>
				<ref_obj_pid>22949</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Mackinlay, J. Automating the Design of Graphical Presentations of Relational Information. <i>ACM Trans. on Graphics 5(2)</i>, April 1986, 110-141.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Martin, J. <i>High Tech Illustration</i>. Cincinnati, OH, North Light Books, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Neiman, D. Graphical Animation from Knowledge. In <i>Proc. AAAI '82</i>, Pittsburgh, PA, August 18-20, 1982, 373-376.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97901</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Saito, T. and Takahashi, T. Comprehensible Rendering of 3-D Shapes. In <i>Proc. ACM SIGGRAPH '90 (Computer Graphics, 24(4)</i>, August 1990). Dallas, TX, August 6-10, 1990, 197-206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Seligmann, D. D. Intent-Based Illustration: A Visual Language for 3D Worlds. Thesis Proposal. Department of Computer Science, Columbia University. New York, January 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>73661</ref_obj_id>
				<ref_obj_pid>73660</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Seligmann, D. D., and Feiner, S. Specifying Composite Illustrations with Communicative Goals. In <i>Proc. UIST '89</i>. Williamsburg, VA, November 13-15, 1989, 1-9.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>980200</ref_obj_id>
				<ref_obj_pid>980190</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Simmons, R. F. The Clowns Microworld. In <i>Proc. TINLAP '75</i>, 17-19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Strothotte, T. Pictures in Advice-Giving Dialog Systems: From Knowledge Representation to the User Interface. In <i>Proc. Graphics Interface '89</i>, London Ontario, June 19-23, 1989, 94-99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Thomas, T.A. <i>Technical Illustration, 2nd. Edition</i>. McGraw-Hill, New York, NY. 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ Computer Graphics, Volume 25, Number 4, July 1991 Automated Generation of Intent-Based 3D Illustrations 
Dor6e Duncan Seligmann Steven Feiner Department of Computer Science Columbia University New York, New 
York 10027  Abstract This paper describes an automated intent-based approach to illustration. An illustr,~tion 
is a picture that is designed to fulfill a communicative intent such as showing the location of an object 
or showing how an object is manipulated. An illustration is generated by implementing a set of stylistic 
decisions, ranging from determining the way in which an individual object is lit, to deciding the general 
composition of the illustration. The design of an illustration is treated as a goal-driven process within 
a system of constraints. The goal is to achieve communicative intent; the constraints are the illustrative 
techniques an illustrator can apply. We have developed IBIS (Intent-Based Illustration System), a system 
that puts these ideas into practice. IBIS designs illustrations using a generate-and-test approach, relying 
upon a rule-based system of methods and evaluators. Methods are rules that specify how to accomplish 
visual effects, while evaluators are rules that specify how to determine how well a visual effect is 
accomplished in an illustration. Examples of illustrations designed by IBIS are included. CR Categories 
and Subject Descriptors: 1.3.3[Computer Graphics]: Picture/Image Generation-display algorithms, viewing 
algorithms; 1.3.4[Computer Graphics]: Graphics Utilities-Picture description languages; I. 3.7[Computer 
Graphics]: Three- dimensional graphics and realism; 1.2.1 [Artificial Intelligence]: Applications and 
Expert Systems. Additional Keywords and Phrases: illustrations, automated picture generation, knowledge-based 
graphics, non-photorealistic rendering.  Introduction The development over the last few centuries of 
printing and photographic technologies, and more recently of electronic mass media, has revolutionized 
communication by making the exact same presentation accessible to larger and larger groups of people. 
Nevertheless, communication involves both intent and Permission to copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, 
requires a fee and/or specific permission. interpretation. The same presentation, viewed by several people, 
may be interpreted to mean different things, while different presentations may be interpreted to mean 
the same thing. To further complicate matters, none of these interpretations may be the one intended 
by the presenter. With recent advances in computer technology, we may now embark upon a new phase of 
communication. By formalizing the intent of a communication, the language or medium to be used, the audience 
and context of the communication, and the way in which the language is used to achieve intent, we may 
create systems that generate presentations, each designed to satisfy the same communicative intent for 
a particular audience, thus making the exact same meaning accessible to many different people. This paper 
describes the first steps in developing such a system for illustration. An illustration is a picture 
that has been designed to fulfill a communicative intent. For example, the intent of an illustration 
may be to show an object's material, size, or orientation. The intent might be more complex. It may, 
for example, be more important to show how to turn a dial, and less important to show where the dial 
is located. Human illustrators plan and replan an illustration, considering at all times how the final 
illustration will look. An illustrator may try something on paper and then, after evaluating it, erase 
it and adopt another plan. Or, the illustrator may be so skilled that it is enough for'her to simply 
imagine the consequqnces of a stylistic choice. This characterization of illustration serves as the foundation 
for intent-based illustration. An intent-based illustration system designs illustrations to fulfill a 
high-level description of the communicative intent. The illustration process can be formalized as a goal-driven 
process: the goal is to achieve a specified communicative intent within a complex of stylistic choices. 
In order to use a generate-and-test approach, such a system must represent style in two ways. First, 
each stylistic choice represents a method for achieving a particular goal. For example, in order to highlight 
an object, it may be brightened or it may be colored in a special way. Second, each stylistic choice 
is associated with a set of criteria used to judge how well it has been accomplished. This paper describes 
IBIS (Intent-Based Illustration System), concentrating on its rule base, architecture, and design process. 
It explains how IBIS both achieves and evaluates the highlighting, recognizability and visibility of 
objects using several examples. &#38;#169; 1991 ACM-O-89791-436-8/91/O07/0123 $00.75 | 23 SIGGRAPH '91 
Las Vegas, 28 July-2 August 1991 i i SIGGRAPH" 91 IBIS Overview IBIS utilizes a generate-and-test approach 
to illustration design. Starting with a description of the communicative intent and a knowledge base 
representing the world to be depicted, IBIS begins to design an illustration. The communicative intent 
is specified using a language of communicative goals. For example, a communicative goal may be to show 
how an object has been moved or to show its color. For each communicative goal there exists at least 
one design rule in IBIS's rule base. A design rule specifies a prioritized set of style strategies. A 
style strategy specifies a visual effect, such as highlighting and is achieved by a set of style rules. 
A style rule determines some part of the traditional computer graphics specification of an image: a viewing 
specification, a lighting specification, the objects to be depicted, and rendering instructions. A style 
rule calls upon procedures that directly access and manipulate illustrations. Illustrators select style 
strategies by selecting design rules to accomplish communicative goals. Drafters select illustration 
methods by selecting style rules to accomplish style strategies. The following subsections describe all 
the components of the system and their interaction. Input: Communicative Goals IBIS currently supports 
communicative goals that have been designed to satisfy the needs imposed by COMET, a knowledge- based 
multi-media explanation generation system for which IBIS generates graphics [Elhadad et al. 89, Feiner 
and McKeown 90a, Feiner and McKeown 90b]. COMET designs explanations for equipment maintenance and repair 
that include pictures and text. Its current domain is the army radio shown in the figures in this paper. 
The communicative goals that IBIS can satisfy are: location:show the location of an object in a context 
(either explicitly specified or derived by the system)  relative location: show the relative location 
of two or more objects in terms- of a specified or derived context  property: show one of the following 
physical properties of an object: material, color, size, shape  state:show an object's state  charge: 
show the difference between a set of states  Both the goals state and change may be further qualified 
by concepts that refer to how the object is manipulated or has changed. For example, the state of a dial 
can be shown in terms of an agent turning it. IBIS currently supports three dozen concepts useful to 
our maintenance and repair domain, among them, pushing, pulling, loosening, lifting, inserting and blinking. 
 In response to a user request for information, COMET's content planner generates a description of the 
communicative intent for an explanation that is sent to COMET's media-coordinator. The media-coordinator 
annotates the intent specification to indicate which generators should communicate which information 
and passes the same intent specification to COMET's media generators. All generators work from the same 
annotated intent specification [Elhadad et al. 89]. IBIS translates the intent description into a prioritized 
list of communicative goals. This translation is more or less direct; concepts such as location and turn 
are identified in the intent specification. IBIS associates with each goal an indication of its importance, 
which in turn is used to calculate an acceptable degree of success when the goals are evaluated. Knowledge 
Base- IBIS has a knowledge base of the physical objects to be illustrated that includes not only geometric 
and material information, but also information about the object's features, physical properties, and 
abstract properties. Information about the features and abstract properties of physical objects is a 
superset of the information traditionally passed to a graphics system. It is, however, necessary to an 
intent-based system that designs its own pictures. For example, it may be important to represent how 
an object moves or its limits of articulation. IBIS currently utilizes a very simple model for object 
states. For example, the dials on the radio are represented as having discrete or continuous ranges with 
associated orientations; the latches have two states: snapped and unsnapped, Design Rules: Mapping Intent 
to Stylistic Choice Design rules describe on a high level bow illustrations should be put together. 
A design rule consists of a communicative goal and a set of style strategies. There are two types of 
design rules: design methods and design evaluators. Design methods specify how to accomplish communicative 
goals; design evaluators determine how well communicative goals have been accomplished. A design method 
specifies what style strategies must be achieved, in addition to how well each should be achieved in 
order to accomplish a communicative goal. A design evaluator determines how well a communicative goal 
is achieved based on the achievement ratings of a collection of style strategies. Each communicative 
goal formalized in IBIS's intent-specification language [Seligmann 91] must have one or more design rule 
to accomplish and evaluate it. Showing Location Figure 1 lists two design rules for satisfying the 
communicative goal location. Figures 2 and 3 are illustrations that IBIS generated using design rules 
1 and 2. In both illustrations, the location of the function dial is shown in context of the parent object, 
the radio. (How design rules are activated is described later.) Design Rule 1 specifies that to show 
the location of an object (?object) in a specific context (?context-object), the following style strategies 
must be accomplished: The object must be included in the illustration. The achievement threshold "highest" 
indicates that this style strategy must be fully satisfied.  The object must be recognizable.  The 
context object must be included.  The object must be visible.  The object must be highlighted.  The 
context object must also be recognizable, but with a lower threshold.  The context object must also 
be visible, but with a lower threshold.  Design Rule 2 requires that a landmark object of the context 
object be visible and recognizable. A landmark is an object that serves as a key for identification, 
position, and/or location [Feiner 85]. IBIS uses a simplistic approach for identifying landmarks. It 
   ~ Computer Graphics, Volume 25, Number 4, July 1991 ILLUSTRATOR I DRAFTER SWIe IllustrationCommunicative 
MATCH Strategies ~'- MAiCH ~ Goals Design Style Methods Methods DESIGN STYLE ............................ 
Illustration RULES Design RULES StyleEvaluators Evaluatorsl~ Evaluated Evaluated i Communicative Style 
~. MATCH ~.~ MATCH Evaluators Goals Strategies I  Figure 8. IB1S's illustration process Figure 7, in 
which the global lighting is dimmed by 25%, IBIS decides that the brightened channel dial is sufficiently 
contrasted with other objects and that no additional muting is necessary. Architecture Illustrators 
An IBIS illustration is designed by a component called an illustrator. An illustrator is assigned a set 
of communicative goals to fulfill. After trying the techniques at hand, an illustrator may detect that 
it cannot fulfill the complete set of communicative goals in just one illustration. For example, the 
communicative intent may be to show the opposite faces of the same object, or to show parts of an object 
in great detail, but also in context of a much larger object that must also be legible. No one view can 
satisfy these constraints. 1BIS's rules allow it to create a composite illustration, which is defined 
as a set of related illustrations that in concert fulfill the communicative intent [Seligmann and Feiner 
89]. Composite illustrations are made up of several sub° illustrations, each of which may be inside, 
overlapping, or next to others. The illustrator creates subordinate illustrators to which it contracts 
sets of communicative goals. One subordinate illustrator is responsible for the work already completed; 
the rest are assigned the remaining communicative goals. The original illustrator, which we call the 
master illustrator, is responsible for the work of the subordinates and the placement and sizing of their 
sub-illustrations. Although illustrations may have arbitrarily deep recursive hierarchies in theory, 
in practice the hierarchy is usually not very deep or broad. While illustrators map communicative goals 
to style strategies with design methods and evaluate the success of communicative goals with design evafuators, 
they assign to drafters the task of accomplishing and evaluating style strategies. Drafters Drafters 
do not know about communicative intent. They are the unheralded workers who translate the illustrators' 
plans into reality. Drafters are tied to the hardware they utilize. For example, it is the drafters who 
apply the procedures that examine the contents of the frarnebuffer. Drafters share a body of style rules. 
Each style rule specifies illustration methods or evaluators to call in order to achieve or evaluate 
visual effects. Drafters report back to the illustrators with the achievement rating of the various style 
strategies they implement. Once an illustration has been approved by the master illustrator, it is the 
drafters who render the illustration. Illustration Objects, Physical Objects, and their Relations An 
illustration contains a set of illustration objects, each of which is created for that illustration. 
The drafter generates illustration objects when achieving style strategies. IBIS selects the objects 
to depict based on the communicative goals and design rules activated. Each illustration object usually 
depicts one or more corresponding physical objects in the knowledge base. Some illustration objects, 
however, may not correspond to any physical object, such as the arrow appearing in Figure 7. Such objects 
are called meta-objects [Feiner 85]. They are generated by the system to serve as visual annotations 
that illustrate those concepts that do not directly correspond to physical objects in the world being 
illustrated, such as the concept of turning in Figure 7. An illustration includes a set of object relations 
that specifies the relationship between each illustration object and zero or more corresponding physical 
objects. Some physical objects have no corresponding illustration objects. These are the objects IBIS 
selects not to depict. In contrast, a physical object may correspond to several illustration objects. 
For example, two or more illustration objects can depict the same object in different states.  Generate 
and Test Approach Figure 8 summarizes IBIS's illustration design process. Communicative goals match with 
a design method in the illustrator's design rule base. The design method asserts a set of style strategies. 
Style strategies match with style methods in the drafter's style rule base. This, in turn, activates 
a set of illustration methods that access the illustration object directly. Correspondin'g style evaluators 
activate a set of illustration evaluators that also access the illustration. The illustration evaluators 
match with style evaluators to assert the success ratings   ~ Computer Graphics, Volume 25, Number 
4, July 1991 I the object must occupy and a list of properties that must be depicted. Style Methods for 
Visibility and Recognizability The drafter maintains a set of possible view specifications for every 
object that must be recognizable. A view specification satisfies the recognizability goals associated 
with these objects if the viewpoint lies within the intersection of the characteristic views' volumes 
and if the additional constraints are satisfied. The visibility of each unoccludable object is maintained, 
if possible, by selecting a view in which unoccludable objects are not obscured. IBIS has several different 
methods for realizing visibility constraints when an unoccludable object is obscured by another object 
(that is not itself unoccludable). The first and simplest method is to remove from an illustration an 
object that obscures an unoccludable object. An object can be made visible by removing from the illustration 
all the objects that obscure it. This solution is problematic. In some cases, it would be misleading 
to remove objects from the scene. In other cases, it would be ideal. A variety of illustrative styles 
have been developed by technical illustrators to depict obscured objects more clearly without completely 
eliminating those that obscure them [Giesecke et al. 36, Thomas 68, Martin 89]. These techniques include 
cutaways, transparency, and ghosting. We have developed several approaches for efficiently applying simple 
versions of these techniques interactively using z-buffer-based graphics systems [Seligmann and Feiner 
89, Feiner and McKeown 90a, Feiner and Seligmann 91].  Interactive Illustrations So far, we have treated 
IBIS's illustrations as static presentations. However, the same mechanisms that enable IBIS to design 
illustrations are utilized to maintain illustrations in their interactive state. An interactive illustration 
may be manipulated by a user. Currently, IBIS supports user-controlled view specification. In traditional 
user-controlled navigation, when the user specifies a new view, the same set of illustration objects 
is rendered from that view. In contrast, navigation in an illustrated 3D environment is more complex. 
The illustration is bound to the communicative goals with which it is specified. The illustration system's 
task is to satisfy continuously these communicative goals while the user changes the view specification. 
For example, consider an illustration in which the illustrator has determined that certain objects are 
unoccludable. As the user alters the view, these unoccludable objects may be obscured by other objects. 
The appearance of these otherwise occluding objects must be modified dynamically to maintain the unoccludable 
objects' visibility. (In [Feiner and Seligmann 91] we describe techniques for automatically maintaining 
visibility during an interactive session.) Alternatively, different design rules may be activated to 
satisfy a communicative goal as the view specification changes. Consider an interactive session beginning 
with Figure 2, in which the communicative goal is to show the location of the function dial. Figure 2's 
view specification is generated by IBIS. As the user zooms in, using IBIS's interactive interface, Design 
Rule l's evaluator is no longer satisfied: the context object is no longer completely recognizable and 
visible. However, Design Rule 2's evaluator is activated because the current view includes the keypad 
buttons, which are unique objects on the radio and considered landmarks of the radio. The communicative 
goal to show location is maintained and IBIS does not have to redesign the illustration. The user continues 
to zoom. Now, only the function dial is visible and recognizable. If design rules 1 and 2 are the only 
rules for showing location, then the communicative goal has been violated, since no design rule is satisfied. 
IBIS opts to generate a composite illustration, and designs and positions an inset illustration (using 
Design Rule 1), which pops up during the interactive session. The resulting il[ustration is shown in 
Figure 9.  Composite Illustrations Here we describe some of the top-level decisions IBIS made when designing 
the illustration shown in Figure 10. The illustration is intended to show the user how to snap the latches 
of the primary battery box, as well as to indicate, with lesser importance, where another battery (the 
holding battery) is located. The master illustrator is assigned the following communicative goals: (state 
latchl snapped highest) (state latch2 snapped highest) (state latch3 snapped highest) (state latch4 snapped 
highest) (location holding-battery radio medium-low) These communicative goals activate the following 
design rules that specify the following style strategies. For each latch: (include latch highest) (context 
latch medium) (recognizable latch high) (visible latch high) (highlight latch high) (change latch snapped 
highest) (meta-object latch snapped highest) For the battery: (include holding-battery highest) (visible 
h oldi n g- batter3j~ n,redium-low) (recognizable holding-battery low) (context holding-battery medium-low) 
(highlight holding-battery medium-low) The illustrator's drafter tries to satisfy the highest priority 
style strategies first and begins by generating illustration objects for the latches, holding battery, 
and the rest of the radio. The recognizability constraints are set up for each object. The drafter fails 
when trying to make the fourth latch recognizable. Since all goal cannot be satisfied, IBIS decides that 
a composite illustration is needed. The master illustrator contracts two subordinate illustrators to 
handle the following communicative goals: Illustrator One: (state latch 1 snapped highest) (state latch2 
snapped highest) (state latch3 snapped highest) (location holding-battery radio medium-low) Illustrator 
Two: (state latch4 snapped highest)  ~  Related Work Several researchers have addressed the problem 
of automatic picture generation. Simmons's CLOWNS [Simmons 75] generates simple line drawings of a 2D 
clown. Neiman's GAK [Neiman 82] generates animated pictures for a CAD system help facility. Both these 
systems, however, rely on predesigned vector objects. Friedell [Friedell 84] has generated synthesized 
3D graphic environments using evaluators and backtracking, but this work emphasized modeling environments, 
rather than designing pictures. Feiner's APEX [Feiner 85] system designs pictures that depict actions 
performed in a 3D world, but without backtracking, self-evaluation, style combination, or visibility 
checks. Mackinlay's APT system [Mackinlay 86] designs 2D presentation graphics for quantitative data 
using a system of evaluation and backtracking, which enables the system to combine styles. Strothotte's 
chemistry explanation system [Strothotte 89] generates pictorial explanations automatically, but relies 
on handmade bitmapped images. Other researchers have addressed rendering problems related to the illustration 
of objects. Kamada and Kawai [Kamada and Kawai 87] have developed techniques for generating line drawings 
that show the internal structure of complex objects. Saito and Takahashi [Saito and Takahashi 90] and 
Dooley and Cohen [Dooley and Cohen 90a, Dooley and Cohen 90b] have also developed non real-time techniques 
using transparency, cross-hatching, and different line styles to generate high-quality images that convey 
shape and construction. The work described here differs from previous work in a number of ways emphasized 
in this paper. Our approach to automated illustration of 3D worlds is intent-based and depends upon a 
system of methods and evaluators that enables multi-level backtracking based on evaluations of a partially 
generated illustration. Illustration objects are generated based on both the representation of the physical 
object as well as the communicative intent. IBIS's evaluation process attempts to approximate the relationship 
between the visual appearance of an object in the real world (limited by the models used) and its appearance 
in the illustration. Finally, IBIS introduces an approach for generating composite illustrations, as 
well as semantically bound interactive illustrations. Implementation IBIS is written in C++ and the 
CLIPS production system language [Culbert 88]. It runs under UNIX on an HP 9000 375 TurboSRX workstation, 
which provides hardware support for realtime 3D shaded graphics. Drafters currently use the HP Starbase 
3D graphics package, while the user interface is written inX. The radio featured in the illustrations 
consists of over 8000 polygons rendered at 1280 x 1024 resolution. IBIS took .8 seconds to design Figure 
7 and 7 seconds for IBIS to design Figure 10. It takes approximately .3 seconds to render either illustration. 
 Summary and Future Work IBIS demonstrates an automated intent-based approach to illustration. Illustrations 
are designed by first considering a specified communicative intent and the world depicted. IBIS treats 
illustration as a goal-driven process using a generate-and-test approach and relies upon a rule base 
to make stylistic and design choices. These rules are represented as both Computer Graphics, Volume 25, 
Number 4, July 1991 methods for accomplishing visual effects and evaluators for determining how well 
visual effects have been accomplished in an illustration. Any choice may negatively affect the success 
of others; IBIS backtracks to find alternative solutions. Our current efforts concentrate on the development 
of a visual language for 3D worlds [Seligmann 91] that will incorporate formalisms for communicative 
intent, style, design, viewer model, and session model. Communicative intent will be extended to include 
goals to represent the purpose of the communication, such as warnings and reminders. Style rules are 
being arranged into a hierarchy of constraints, ranging from those that identify conformant classes of 
illustration elements (e.g. colors and lines) to those that identify unaesthetic choices. We are also 
developing meta-rules to select methods based on the overall problem (rather than searching for the first 
adequate solution). For example, while IBIS currently generates composite illustrations only as a last 
resort, a meta-rule could allow them to be created as a regular design option. Finally, IBIS is being 
enhanced to allow for user control on all levels of specification, including the choice of design rules 
and style strategies.  Acknowledgments This work is supported in part by the Defense Advanced Research 
Projects Agency under Contract N00039-84-C-0165 and the Hewlett-Packard Company under its AI University 
Grants Program. Esther Woo, John Edmark, Garry Johnson and Alan Waxman implemented portions of the system. 
Norman Chin developed the efficient procedures that we use to manipulate shadow volumes. Michael Elhadad 
is a a fellow comrade in arms in the COMET project. Conversations with Tom Ellman, J.R. Ensor, Allen 
Ginsberg, Jacques Robin, Frank Smadja have been more than helpful. Much appreciation is due to Suzanne 
Oboler and Cynthia King for their critical reading of this paper. Many thanks to David Kurlander and 
Rick Beach for help with the color separations. References Chakravarty, I., and Freeman, H. Characteristic 
Views as a Basis for Three-Dimensional Object Recognition. In Proc. Societyfor Photo-Optical Instrumentation 
Engineers Conf. on Robot Vision, Bellingham, WA, SPIE, vol. 336, 1982.37-54. Chin, N. and Feiner S. Near 
Real-Time Shadow Generation using BSP Trees. In Proc. ACM SIGGRAPH 89 (Computer Graphics, 23(3), July 
1989), Boston, MA, July 31-August 4, 1989, 99-106. Culbert, C. CLIPS Reference Manual. NASA/Johnson Space 
Center, TX, 1988. Dooley, D. and Cohen, M. Automatic Illustration of 3D Geometric Models: Lines. In Proc. 
t99o Syrup. on Interactive 3D Graphics (Computer Graphics 24(2), March 1990), Snowbird, UT, March 25-28, 
1990, 77-82. Dooley, D. and Cohen, M. Automatic Illustration of 3D Geometric Models: Surfaces. In Proc. 
Visualization '9o, San Francisco, CA, October 23-26, 1990, 307-314. Elhadad, M., Seligmann, D.D., Feiner, 
S., and McKeown, K. A Common Intention Description Language for Interactive Multi- SIGGRAPH '91 Las 
Vegas, 28 July-2 August 1991 SIGGRAPH 91 " Media Systems. IJCAI-89 Workshop on Intelligent Interfaces, 
Detroit, M1, August 22, 1989, 46-52. Feiner, Steven K. APEX: An Experiment in the Automated Creation 
of Pictoral Explanations. IEEE Computer Graphics and Applications 5(t t), November 1985, 29-38. Feiner, 
S. and McKeown, K. Generating Coordinated Multimedia Explanations. In Proc. CAIA9o ( 6th IEEE Conf. on 
Artificial Intelligence Applications), Santa Barbara, CA, March 5-9, 1900, 290-296. Feiner, S. and McKeown, 
K. Coordinating text and graphics in explanation generation. In Proc. AAAI-9o, Boston, MA, July 29-August 
3,199O. 442-449. Feiner, S. and Seligmann, D.D. Dynamic 3D Illustrations with Visibility Constraints. 
In Proc. Computer Graphics International 9t, Cambridge, MA, June 24-28, 1991. Foley, J., van Dam, A., 
Feiner, S., and Hughes, J. Computer Graphics: Principles and Practice 2nd Edition. Addison-Wesley, Reading, 
MA, 1990. Friedell, M. Automatic Synthesis of Graphical Object Descriptions. Computer Graphics t8(3), 
July 1984, 53-62. Giesecke, F., Mitchell, A., and Spencer, H. Technical Drawing. New York, The Macmillan 
Co., 1936. Kamada, T. and Kawai, S. An Enhanced Treatment of Hidden Lines. ACM Trans. on Graphics 6(4), 
October, 1987, 308-323. Kamada, T. and Kawai, S. A Simple Method for Computing General Position in Displaying 
Three-Dimensional Objects. Computer Vision, Graphics and Image Processing 4 t (t), January, 1988, 43-56. 
 Mackinlay, J. Automating the Design of Graphical Presentations of Relational Information. ACM Trans. 
on Graphics 5(2), April 1986, 110-141. Martin, J. High Tech Illustration. Cincinnati, OH, North Light 
Books, 1989. Neiman, D. Graphical Animation from Knowledge. In Proc. AAAI '82, Pittsburgh, PA, August 
18-20, 1982, 373-376. Saito, T. and Takahashi, T. Comprehensible Rendering of 3-D Shapes. In Proc. ACM 
SIGGRAPH '90 (Computer Graphics, 24(4), August 1990). Dallas, TX, August 6-10, 1990, 197-206. Seligmann, 
D. D. Intent-Based Illustration: A Visual Language for 3D Worlds. Thesis Proposal. Department of Computer 
Science, Columbia University. New York, January 1991. Seligmann, D. D., and Feiner, S. Specifying Composite 
Illustrations with Communicative Goals. In Proc. UIST '89. Williamsburg, VA, November 13-15, 1989, 1-9. 
 Simmons, R. F. The Clowns Microworld. In Proc. TINLAP '75, 17-19. Strothotte, T. Pictures in Advice-Giving 
Dialog Systems: From Knowledge Representation to the User Interface. In Proc. Graphics Interface '89, 
London Ontario, June 19-23, 1989, 94-99. Thomas, T.A. Technical Illustration, 2nd. Edition. McGraw-Hill, 
New York, NY. 1968.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122733</article_id>
		<sort_key>133</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[A new simple and efficient antialiasing with subpixel masks]]></title>
		<page_from>133</page_from>
		<page_to>141</page_to>
		<doi_number>10.1145/122718.122733</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122733</url>
		<abstract>
			<par><![CDATA[Antialiasing of edges is often performed with the help of subpixel masks that indicate which parts of the pixel are covered by the object that has to be drawn. For this purpose, subpixel masks have to be generated during the scan conversion of an image. This paper introduces a new algorithm for creating subpixel masks that avoids some problems of traditional algorithms, like aliasing of high frequencies or blinking of small moving objects. The new algorithms can be implemented by lookup tables that make use of the inherent symmetry of the algorithm. The results are compared with conventional supersampling. A hardware implementation is described.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[antialiasing]]></kw>
			<kw><![CDATA[exact area subpixel algorithm]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Raster display devices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Antialiasing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010373</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Rasterization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010386</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Antialiasing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP35046236</person_id>
				<author_profile_id><![CDATA[81100595324]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schilling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Wilhelm-Schickard-Institut f&#252;r Informatik, Graphisch-Interaktive Systeme, Auf der Morgenstelle 10/C9 7400 T&#252;bingen, Bundesrepublik Deutschland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>325177</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ABRAM, G., WESTOVER, L., AND WHITTED, T. Efficient alias-free rendering using bit-masks and look-up tables. Computer Graphics 19, 3 (July 1985), 53-59.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617463</ref_obj_id>
				<ref_obj_pid>616003</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BLINN1 J. F. What we need around here is more aliasing. IEEE Computer Graphics ~ Applications (Jan. 1989), 75-79.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808585</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[CARPENTER, L. The a-buffer, an antialiased hidden surface method. Computer Graphics 18, 3 (July 1984), 103-108.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[COOK, R. L. Stochastic sampling in computer graphics. A CM ~'ansactions on Graphics 5, 1 (January 1986), 51-72.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[DIPPE, M. A. Z., AND WOLD, E. H. Antialiasing through stochastic sampling. Computer Graphics 19, 3 (July 1985), 69-78.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801143</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[FIUME, E., FOURNIER, A., AND RUDOLPH, L. A parallel scan conversion algorithm with antialiasing for a general-purpose ultracomputer. Computer Graphics 17, 3 (July 1983), 141-150.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325205</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[FUCHS, H., GOLDFEATHER, J., HULTQUIST, J. P., SPACH, S., AUSTIN, J. D., BROOKS, F. P., EYLES, J. G., AND POULTON, J. Fast spheres, shadows, textures, transparencies, and image enhancements in pixel-planes. Computer Graphics 19, 3 (July 1985), 111-120.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74341</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[FUCHS, H., POULTON, J., EYLES, J., GREER, T., GOLDFEATHER, J., ELLSWoRTH, D., MOL- NAR, S., TURK, G., TEBBS, B., AND ISRAEL, L. Pixel-p|anes 5" A heterogeneous multiprocessor graphics system using processor-enhanced memoties. Computer Graphics ~3, 3 (July 1989), 79-88.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[HOFFERT, E. M., AND BISHOP, G. Exact and efficient area sampling techniques for spatial antialiasing. Technical Memorandum, AT &amp; T Be}} Laboratories, December 1985.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[MUNSCIt, P. Private communication. On the occasion of a meeting in Rennes, France, Dec. 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378457</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[PINEDA, J. A parallel algorithm for polygon rasterization. Computer Graphics ~, 4 (Aug. 1988), 17-20.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[SCHNEIDER, B.-O. Eine objektorientierte Architektur f~r Hochleistungs-Display-Prozessoren. PhD thesis, Eberhard-Ksrls-Universit~it Tiibingen, 1990.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A New Simple and Efficient Antialiasing with Subpixel Masks Andreas Schilling Universit5.t Tiibingen 
Bundesrepublik Deutschland * Abstract Antialiasing of edges is often performed with the help of subpixel 
masks that indicate which parts of the pixel are covered by the object that haa to be drawn. For this 
purpose, subpixel masks have to be generated dur­ing the scan conversion of an image. This paper in­troduces 
a new algorithm for creating subpixel masks that avoids some problems of traditional algorithms, like 
aliasing of high frequencies or blinking of small mov­ing objects. The new algorithm can be implemented 
by lookup tables that make use of the inherent symmetry of the algorithm, The results are compared with 
con­ventional supersampling ]. A hardware implementation is described. CR Categories and Subject Descriptors: 
1.3.1 [Computer Graphics]: Hardware Architecture ­raster display devices; 1.3.3 [Computer Graphics]: 
Picture/Image generation -display algorithms Additional Key Words and Phrases: antialiaaing, exact area 
subpixel algorithm. 1 Introduction The use of a subpixel mask for antialiasing purposes is very common 
[6, 7, 3, 9, 1]. It has several advantages compared with other antialiasing techniques. First, it preserves 
spatial information that is lost, when other methods are used. This information is very important .WJlhehn-Schickard-Inr3 
titut ~W ~foj-matik, Graphisch-Interaktive Systeme, Auf der MorgenateUe 10/C9, 74oOTubhtgen, Email: andreasOgris.informatik.uni-tuebhgen.de. 
1The eXPerienc~, dtibd here were gained in a m=ar&#38; project, partly supported by the Commission of 
the European Communities through the ESPRIT II-Project SPIRIT, Project No. 2484. Permissiont{,copywithoutfecall 
or part of this materialis granted pruvided Ihat [hc copies are not made m distributed for direct commercial 
advantage. the ACMcnpyrightnoticeandthe title of the puhlicationanditsdatetippcar.andnoticeis giventhat 
copying is by permission nf the Association for Computing Machinery To copy olhcrwisc.(n{(>rcpuhllsh.requiresa 
feeand/orspecific~rmissmn if more than two objects contribute to a pixel. Second, it can be determined 
quite easily. At the end of the rendering process, the final brightness of the pixel can be calculated 
easily by adding up the contributions from the subpixels. However, the subpixel mask is usually computed 
in a way that introduces avoidable errors. In the following section, the artifacts that occur when using 
supersam­pling are shown. Analyzing these artifacts leads to a simple algorithm, the Exact Area Subpixel 
Algorithm, that can avoid the described disadvantagea by combin­ing the benefits of the subpixel mask 
with the calcula­tion of the exact pixel coverage. 2 The Problem The easiest and therefore most common 
way to deter­mine the subpixel mask is by sampling at the subpixel centers. The subpixel is on, if the 
subpixel center is inside the polygon, otherwise it is off (Of course, the re­sults of this calculation 
can be precomputed and stored in a lookup table). The problems with that method are obvious. Con­sider 
for example the following case (Fig. 1). The pixels consist of 4 x 4 subpixels. An object with a horizontal 
lower edge is moving slowly downward across the pixel. Nothing happens, until the edge reaches the topmost 
line of subpixel centers. As soon as the subpixel centers are reached, all the four upper subpixels are 
switched on at the same time. As a result, the brightness of the pixel is increased in four big steps 
instead of the 16 steps, which we would like to obtain with 16 subpixels. This is shown in Fig. 2 a), 
where the number of sub­pixels that are set is plotted as a function of the exact area, covered by the 
polygon. The same applies for diagonal lines. In Fig. 2 b) we see the result for edges with a slope of 
45 0. Fig. 2 c) rep­resents the ideal function that we would like to obtain. This function is achieved 
with the algorithm introduced in the next section. If the objects are very small (smaller than a subpixel), 
the effect of the errors of the conventional approach is I Figure 1: Problems with oversampling: horizontal 
edge m&#38;ing downward over a pixel, consisting of 4 x 4 sub­pixels. The first line of subpixels is 
switched on simul­taneously, EEE Figure 2: Number of set subpixels vs. area covered. a) Result of supersampling 
with a horizontal or vertical line, b) Supersampling with a diagonal line, c) Ideal function. especially 
bothersome. The whole object appears and disappears again as itmoves across the screen. A thin line or 
the end of a skinny triangle appeara as a dashed line (Fig. 3). A way to minimize alkises, generated 
by regular su­persampling, is the use of stochastic sampling [5, 1, 4]. Although the moat annoying artifact 
(alias effect) is replaced by an artifact (noise) that is more tolerable, other objectionable effects, 
like the blinking of small moving objects or holes in thin lines etc. are not dealt with correctly. 
 3 Exact Area Subpixel Algo­ rit hm Our new approach, therefore does not sample at the subpixel centers. 
Instead, the exact portion of the pixel area is calculated, But in contrast to other approaches that 
also calculate this area, but then have to store it as an extra value for later processing [3], we convert 
the area into a subpixel count that represents the area por­tion best. In the following, the algorithm 
is explained for 4 x 4 subpixels, later on, a generalization for n x n 134 4 3 2 . 1 Figure 3: Problems 
with oversampling (thin line and sharp triangle). Each pixel consists of 4 x 4 subpixels. Subpixels that 
are set are indicated by filled circles. The density of the hatching indicatea the final pixel bright­ness. 
subpixela is presented. Let us look again at the horizon­tal edge, mentioned above. With the new approach, 
we get a coverage of one subpixel, when the line is 1/16 of the pixel width under the upper pixel edge 
(in fact we get one subpixel between a coverage of 1/32 and 3/32 of the pixel area). If the line has 
reached 2/16, we get a coverage of 2 subpixels instead of O or 4 with the old method. Now, the only problem 
that remains to be solved is to find the right locations for those subpixels. A sim­ple observation can 
help us. If we look at an edge of a certain slope that moves slowly over a pixel, we see that the subpixels 
are touched in a certain order. We would get the same sequence, if we observed the order, in which the 
subpixel centers are covered, or the order in which the subpixels are covered totally (e.g. Fig. 4 c) 
or d)). Normally it starts with a subpixel at one corner. The next in the row will be the neighbora of 
the firat one and so on until the opposite corner is reached. Now we can show, that there is only a certain 
number of dif­ferent ordera that are possible. In Fig. 4 we see, that all edges that have a slope between 
that of El and EZ cover the subpixels in the same order. The total number of possible sequences is only 
32 for a subpixel mask of 4 x 4 subpixela. Now we can assign one of these sequences to each slope. At 
the bordera, where two aequencea would be possible, we choose one and make sure that an edge of the opposite 
orientation gets the opposite sequence. Such we can ensure that two adjacent objects that cover the whole 
pixel cause all subpixela to be set in any case. In Fig. 4 a) the numbering scheme for the subpixela 
is shown. Fig. 4 b) shows the different sequences that are possible for edges between 0° and 45°. As 
examples, a) d) Figure 4: Numbering scheme and possible sequences for subpixel coverage. (See Section 
3 for explanation) lines of type A and B are drawn in Fig. 4 c) and d) reap. The figures show how the 
subpixel centers are touched by the edges in different sequences.  4 Exact Area Subpixel Algo­rithm 
for n x n subpixels In the following, we have to make use of an arbitrary representation of the polygons. 
The representation with edge functions, chosen for this paper is explained in Appendix A. For then x 
n subpixel mask, the approach is the same as in the 4 x 4 case. First we calculate the number of subpixels 
we want to set (no, ) with the general formula2: floor (A* n + 0.5) : 0< slope< 180°nO, = ceil (A *n2 
 0.5) : 180° < slope { A denotes the area of the pixel that is covered by the half plane defined by 
the polygon edge. (The two cases have to be distinguished in order to ensure that two adjacent polygons 
always complement each other, i.e. that we don t get a total coverage of more than nx n subpixels. ) 
The next step is a sort of the subpixels S1 . . .Sn~n. They are sorted in a way that the most covered 
one is the first, the least covered one the last in the list (falling edge function). If there exist 
groups of subpixels with equal coverage (equal edge function), the subpixels of these groups are sorted 
using a function that results from the original edge function through a rotation by +90°. Now we take 
the first no, subpixels from the list and set them to 1, all othera to O. -In a final step, the resulting 
subpixel masks for all edges of the (convex) polygon are ANDed together. 5 Hardware Implemental ion 
Several problems had to be solved in order to implement the coverage unit in hardware. The function of 
the unit is simple. We can think of it as a single lookup table 2jIoor(s) memo the largest integer not 
greater than z, ceil(z) mearw the smalleot integer not less thao r.  $ +_l-liaa (dcx) Figure 5: Lookup 
table for the subpixel mask. D 0 o.ii o : m: o 0:01 1 :  Q: .10 1 1.10 0 : 1.01 : 1 1.01 :  1 1.00 
: 1 1.00 A:  Figure 6: Problems with truncating numbers repre­sented in the two s complement. like 
the one shown in Fig. 5. Input parameters are the distance or error term e and the x-increment of the 
edge function de=, which serves ss a me~ure for the slope of the edge . In addition to that we need only 
the sign of the y-increment dev. The first question was the required precision of the input parameters. 
Under the condition that the result of the quantization error has to be smaller than one subpixel we 
get required resolutions for the distance or error term e of 5 bits and for the slope measure de= of 
4 bits. The condition for the slope measure with regard to the sequence leads to the same resolution 
of 5 bits for de=. In order to cover all directions, the signs of de% and dev have to be considered also. 
AS a result, we get a total of 11 input bits which correspond to a lookup table size of 2k x 16 bits. 
But if we look into the details, we still have to in­crease the size. The rezwm for this is that our 
input . SIitnl!l !l­ 21 4E0-B12 . &#38; from Edge 1fUnit El? E13 -El? 5, / MOD E Figure 7: Modification 
parameters are coded in the two s complement form, meaning, that if we only truncate the numbers to the 
required bit count, we always round down to the next smaller number (Fig. 6; the bits are numbered EO 
(LSB) to E18 (MSB), ES is the sign bit). However, we want the two adjacent polygons to complement each 
other ex­actly. This means that the sum of subpixels for a given error term and slope adda up to 16 subpixels, 
if the error terms add up to O (el s e2). But with the prop erty of the two s complement, that truncation 
always rounds down, this cannot be fulfilled. An example can clarify this. If we truncate as shown in 
Fig. 6, we want to obtain the same result for an input of 0/0.100 and 0/0.101. Now consider the negative 
value for both of these numbers: for 0/0.100 we get 1/1.100, for 0/0.101 1/1 .011. If we truncate these 
negative numbers, we do not get the same result anymore: 1/1.10 and 1/1 ,01 are not equal. This simple 
example shows that one more input bit for the lookup table is required for each input parameter. This 
bit has to indicate whether a value was changed by truncation or if we already had a flat num­ber. This 
bit can be generated by ORing all truncated (lower) bits together. A single stage lookup table would 
thus have a size of 8k by 16 bits. 5.1 Multi Stage Implementation The size of the lookup table can be 
reduced by a factor of more than 8, if it is implemented in several stages. The easiest approach, then, 
is to replicate the logical structure of the algorithm into the hardware structure. Thus the unit consists 
of three subunits, which per­form the following functions: 1. Determination of the subpixel count, 2. 
Determination of the angle index (se­quence), 3. Determination of the final subpixel mask. A more explicit 
examination leads to a three stage design (Fig, 8). In the first stage, the input data coming from 136 
? 5, taLUt No9 / 5, unit for distance e. the three units that calculate the edge functions (EU1 -EU3) 
is modified in order to eliminate the problems wit h the twe s complement. The blocks are labelled MOD 
E and MOD DEX. The stage MOD E is used to modify the error term e, in the stage MOD DEX the slope parameter 
including the sign bits is modified. The need to modify the sign bits comes out of similar ob­servations 
to those about the two s complement. This modification is performed with a PLA that is also used to determine 
one bit of the angle index. A schematic of the unit MOD E (Fig. 7) shows how the modificw tion is performed, 
however the adder was replaced by a PLA with the same function in the final design. The second stage 
consists of the lookup table for the sub­pixel count and the lookup table for the remaining two bits 
of the angle index. In the third stage, those two parameters are used to lookup the final subpixel mask. 
Three special cases are also handled in this stage: 1. The edge unit is disabled -all 16 subpixel bits 
are set to 1 (Line DE). 2. The error term is greater or equal to 0.5-all 16 subpixel bits are set to 
1 (Line E.GE.0P5). 3. The error term is smaller than -0.5-all 16 subpixel bits are set to O (Line E-LT-MOP5). 
 The whole coverage unit consists of three of the described multi-stage lookup tables (one for each 
edge). The final subpixel mask is the result of ANDing together on a bit-by-bit basis the three outputs 
for each edge. Fig. 9 shows the result for the slim line and the sharp triangle of Fig. 3. In Figures 
10-12, simulation results for the exact area subpixel algorithm compared with supersampling and no antialiasing 
at all are shown. km EU3+ I1--- I horn EU2 from EU1 :J$Rf !iw; sign ES); increment (I)EXO- DEX18, sign 
DEXS) increment sign DEYS n -CIT m MOE&#38; E &#38; L PM LUT Number of Subpixels PLA ~ 1< L LUT Mask 
PLA \ -­\­\ a DEX -m~ Figure 8: Coverage Unit, 4 3 2 1 lzzzl Figure 9: Thin line and sharp triangle 
treated correctly. The density of the hatching indi~ates the final pixel brightness. 6 Conclusion An 
algorithm for antialiasing and its realization in hard­ware has been presented that obtains better results 
than other methods with comparable supersampling (see Figures 10 that already use subpixel mask to apply 
this algorithm simply of the lookup tablea at nearly simplicity, e.g. regular 12). Existing systems lookup, 
can be modified by changing the contents no costs. 7 Acknowledgement I thank Paul Munsch of Caption for 
the idea with the square distance representation. Claudia Romanova provided me with a lot of useful information 
and lit­erature on the topic of antialiasing. 1 also appreciate the guidance of Wolfgang Stra&#38;r and 
the cooperation with my colleagues at the Graphics Department of the University of Ttibingen. A Appendix 
A.1 Representation of polygon edges Polygons can be represented by edge functions, that are negative 
on one, and positive on the other side of the I37 . 1 Figure 10: Sharp triangle of Figures. 9 and 3 without 
ant.ialiasing. w Figure 11: Sharp triangle of Figures. 9 and 3. Problems with conventional supersampling. 
I ,.,.,, .,..,:,,.,. ..,. ..:., ,,..,..,.,,. :;,, .,. ,:..;. 1 Figure 12: Sharp triangle of Figures. 
9 and 3. Correct treatment with Exact Area Subpixel Algorithm.  rdl c, B) Figure 13: Rendering machine, 
functionality. .\ *S *$ AU three Edge *+% functions positive = Inside triangle *@*# Figure 14: Example 
of Edge Ihmctions for Rendering. edge. This representation is used in rendering hard­ware like PRC)OF 
[12], Pixel Planes [8] or in software algorithms like the one described by Pineda [11]. In Fig. 13, the 
rendering with the Pineda algorithm is illus­trated and the desired results of the rendering process 
are shown. The process of rendering consists of deciding wether or not pixels belong to a given polygon. 
For a rendering algorithms like the above mentioned, we need an edge function that behavea like the ones 
shown in Fig. 14. It is positive on one side and negative on the other side of the edge. With three units 
that can calculate such edge functions, we can now decide whether a certain point lies inside the triangle 
or outside. If all three edge functions are positive, the point is inside, otherwise it is outside. A.1.l 
How can we get such a function? The eaaieat way is to choose a linear function E(z, y)=(z X)de= +(y Y)deY 
with the condition: de=AX + deYAY = (1 If we use de= = AY Figure 15: X and Y Increments of the Edge Function. 
as x increment and deY = AX as increment in y direction, we get the formula sug­gested by Pineda with 
the advantage that the calcula­tion is very simple. Now the edge units can be built of only adders, without 
multipliers, as we only have to add the increments proceeding from one pixel to ita neigh­bor. We can 
scale the above formula by an arbitrary fac­tor. So if we need the euclidean distance, we can nor­malize 
the increments de= and dev by dividing the val­ues by the euclidean length of the vector (L2 norm). We 
then get the following increments: AY de= = ~AX2 + AYf and AX dev = 4AX2 t-AYf and we can still use the 
same edge units, because the distance is a linear function in x and y (see example edge in Fig. 15). 
A.1.2 Why do we need this distance? Until now, we used only the sign of the edge function for the decision 
if we are in or out. So the value of the distance is of no interest. But if we want to calculate subpixel 
information for later antialiasing (which ie in fact the scope of this paper), we need exact data about 
the edge. In this case, the normalization is essential [7]. The distance, together with the slope information 
is enough to look up the subpixel maak, i.e. the infor­mation, which part of the pixel is covered (see 
Fig. 13). One little detail has to be noticed. We now have to con­sider not only pixels with their center 
inside the poly­gon (positive edge function), but also pixela that are covered leas than half (edge function 
between O and  O.something). We cannot give a fixed distance, because it is different for edges with 
different slopes (l/@ for edges with a slope of 45°, 1/2 for vertical or horizontal edges). So if we 
take all pixels not more than l/@ away from the edge into consideration, we will get too . : SIGGRAPH 
91 Las Vegas, 28 July-2 August 1991 Es: s16tn Afm !l- Figure 16: Circular Distance. many pixels, but 
that is better than losing pixels that we wanted to get. Fig. 16 shows, that all edgea that have a given 
distance from the pixel center form a cir­cle. Now there is a formula for the increments that solves 
several problems at one time3. If we look at the moat demanding part of the increment calculation above, 
we see the square root in that formula. Now the simplest solution is to omit the root and take the sum 
of the abm lute valuea of AX and AY instead. Speaking in mathe­matical terms, we divide by the L1 norm 
or Manhattan distance instead of the L2norm. The new increments are: de. = [AX:+YIAYI and dey = IAX;+XIAYI 
The result is a change in the distance function. It is not independent of the angle anymore, which was 
the case for the euclidean distance. But if we do not want to do a more complex filtering (like e.g. 
a convolution with sinc(dist)), than we need something like a rectan­gular box filter. A circular filter 
never would result in a homogeneous coverage of the screen. So this formula which is easier to calculate 
is not an approximation for something else, we originally wanted to get, it gives in fact a more desired 
result. Fig. 17 shows, that all edgea that have a given distance from the pixel center form a square. 
For the calculation of the subpixel mask, the square distance is as useful as the euclidean distance, 
because . all information about the edge is contained in the dis­tance and the increments (for the slope 
of the edge). s1 got thjs fom~a from Paul Munsch, who developed ~ver~ distance formulas, to be mud as 
an approximation for the eu­clidean distance, among them an octagonal distance and the square distance 
, described here. Figure 17: Square Distance. References ABRAM, G., WESTOVER, L., AND WHITTED, T. Efficient 
alias-free rendering using bit-masks and look-up tablea. Computer Gmphics 19, 3 (July 1985), 53-59. BLINN, 
J. F. What we need around here is more aliaaing. IEEE Computer Graphics &#38; Applications (Jan. 1989), 
75-79. CARPENTER, L. The a-buffer, an antialiased hid­den surface method. Compuier Gruphics 18, 3 (July 
1984), 103-108. CooK, R. L. Stochastic sampling in computer graphics. ACM lkansactions on Gmphics 5, 
1 (January 1986), 51-72. DIPPti, M. A. Z., AND WOLD, E. H. Antialiaaing through stochastic sampling. 
Computer Gmphics J9, 3 (Ju]y 1985), 69-78. FNJME, E., FOURNIER, A., AND RUDOLPH, L. A parallel scan conversion 
algorithm with anti­aliasing for a general-purpose ultracomputer. Com­puter Graphics 17, 3 (July 1983), 
141-150. FUCHS, H., GOLDFEATHER, J., HULTqUMT, J. P., SPACH, S., AUSTIN, J. D., BROOKS, F. P., EYLES, 
J. G., AND POULTON, J. Fast spherea, shadows, textures, transparencies, and image en­hancements in pixel-plan=. 
Computer Gmphics 19, 3 (July 1985), 111-120. FUCHS, H., POULTON, J., EYLES, J., GREER, T., GOLDFEATHER, 
J., ELLSWORTH, D., MOL-NAR, S., TURK, G., TEBBS, B., AND ISRAEL, L. Pixel-planea 5: A heterogeneous multiprocessor 
graphics system using proceaaor-enhanced mem~ ries. Computer Gmphics 29, 3 (July 1989), 79-88. [1] [2] 
[3] [4] [5] [6] [7] [8] [9] HOFFERT, E. M., AND BISHOP, G. Exact and efficient area sampling techniques 
for spatial an­tialiasing. Technical Memorandum, AT &#38; T Bell Laboratories, December 1985. [10] MUNSCH, 
P. Private communication. On the oc­casion of a meeting in Rennes, France, Dec. 1989. [11] PCNEDA, J. 
A parallel algorithm for polygon ras­terization. Computer Graphics 22, 4 (Aug. 1988), 17-20. [12] SCHNEIDER, 
B.-O. Eine objektorieniierte Ar­chitektur fi-r Hochleistungs-Display-Prozessoren. PhD thesis, Eberhard-Karla-Univeraitat 
Tubingen, 1990! 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122734</article_id>
		<sort_key>143</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[An efficient antialiasing technique]]></title>
		<page_from>143</page_from>
		<page_to>152</page_to>
		<doi_number>10.1145/122718.122734</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122734</url>
		<abstract>
			<par><![CDATA[An intuitive concept of antialiasing is developed into very efficient antialiased line and circle generators that require even less amount of integer arithmetic than Bresenham's line and circle algorithms. Unlike its predecessors, the new antialiasing technique is derived in spatial domain (raster plane) under a subjectively meaningful error measure to preserve the dynamics of curve and object boundaries. A formal analysis of the new antialiasing technique in frequency domain is also conducted. It is shown that our antialiasing technique computes the same antialiased images as Fujimoto-Iwata's algorithm but at a fraction of the latter's computational cost. The simplicities of the new antialiased line and circle generators also mean their easy hardware implementations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[antialiasing]]></kw>
			<kw><![CDATA[convolution]]></kw>
			<kw><![CDATA[curve digitization]]></kw>
			<kw><![CDATA[digital geometry]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Digitizing and scanning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Antialiasing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010506</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document scanning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010386</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Antialiasing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14226134</person_id>
				<author_profile_id><![CDATA[81384618840]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaolin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, University of Western Ontario, London, Ontario, Canada N6A 5B7]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>97914</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. C. Barkans, "High speed high quality antialiased vector generation," Computer Graphics, vol. 24, no. 4, p. 319-326, Aug. 1990.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. E. Bresenham, "Algorithm for computer control of digital plotter," IBM Syst. J., vol. 4, no. 1, 1965, p. 25-30.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359432</ref_obj_id>
				<ref_obj_pid>359423</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. E. Bresenham, "A linear algorithm for incremental digital display of circular arcs", Comm. A CM, vol. 20, no. 2, 1977, p. 750-752.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359869</ref_obj_id>
				<ref_obj_pid>359863</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Crow, "The alia.sing problem in computergenerated shaded images," Comm. ACM, vol. 20, no. 11, Nov. 1977.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>7054</ref_obj_id>
				<ref_obj_pid>7053</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Field, "Algorithms for drawing anti-aliased circles and ellipses," Computer Vision, Graphics, and Image Proc., vol. 33, p. 1-15, 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Fujimoto and K. Iwata, "Jay-free images on " IEEE CG~A, vol. 3, no. 9, p 26- raster displays, 34, Dec. 1983.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806783</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Gupta and R. F. Sproull, "Filtering edges for gray-scale displays," Computer Graphics, vol. 15, no. 3, p. 1-5, Aug. 1981.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359027</ref_obj_id>
				<ref_obj_pid>359024</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Pitteway and D. Watkinson, "Bresenham's algorithm with gray scale," Comm. A CM, vol 23, no. 11, November 1980.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27994</ref_obj_id>
				<ref_obj_pid>27993</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[X. Wu and J. Rokne, "Double-step incremental generation of lines and circles", Computer Vision, Graphics, Image Proc., vol. 37, 1987, p. 331-344.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>628420</ref_obj_id>
				<ref_obj_pid>58308</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[X. Wu and J. Rokne, "On properties of discretized convex curves," IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 11, p. 217-223, Feb. 1989.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617488</ref_obj_id>
				<ref_obj_pid>616005</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[X. Wu and J. Rokne, "Double-step generation of ellipses", IEEE CG~A, vol. 9, no. 3. p. 56-69, May 1989.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[X. Wu and J. Rokne, "Dynamic error measure for curve scan-conversion," Proc. Graph. ics//lnterface'89, London, Ontario, p. 183-190, June 1989.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>88572</ref_obj_id>
				<ref_obj_pid>88560</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Rokne, B. Wyvill and X. Wu, "Fast line scanconversion," A CM Trans. on Graphics, vol. 9, no. 4, p. 377~388, Oct. 1990.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[X. Wu, "A frame buffer architecture for parallel vector generation," Proc. Graphics//Interface'91, Calgary, June 1991.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 An Efficient Antialiasing Technique Xiaolin Wu Department of Computer Science University of Western 
Ontario London, Ontario, Canada N6A 5B7 Abstract An intuitive concept of antialiasing is developed into 
very efficient antialiased line and cir­cle generators that require even less amount of inte­ger arithmetic 
than Bresenham s line and circle algo­rithms. Unlike its predecessors, the new antialiasing technique 
is derived in spatial domain (raster plane) under a subjectively meaningful error measure to pre­serve 
the dynamics of curve and object boundaries. A formal analysis of the new antialiasing technique in fre­quency 
domain is also conducted. It is shown that our antialiasing technique computes the same antialiased images 
as Fujimoto-Iwata s algorithm but at a fraction of the Iat ter s computational cost. The simplicities 
of the new antialiased line and circle generators also mean their easy hardware implementations. CR Category: 
1.3.3 [Computer Graphics]: Pic­ ture/Image Generation -display algorithms. Key Words: Antialiasing, curve 
digitization, digital geometry, convolution. Introduction Curve-rendering on raster devices, a fundamental 
oper­ation in computer graphics, is essentially a process of quantizing (digitizing) continuous two-dimensional 
vi­sual signals at the sampling rate of device resolution. This sampling rate is usually significantly 
lower than twice the maximum frequency of object boundaries and Perm}ssmn10copywithoutfeeall or part 
nf this material is grarrled provided that the copies are rtol made or distributed for direct cnmrnerclal 
advantage. the ACM cnpyright notwc and [he [itle of the publication and m date appear. and notice is 
given [hat cupying is by permissmn of the Association fur Cumputing Machinery. To copy otherwise, nr 
to republish. requires i fee and/nr specific pmrrission curve edges, 1 resulting in loss of information 
as ex­plained by the Shannon sampling theorem. This in­formation loss is the reason for the existence 
of visu­ally unpleasant aliasing (staircasing effect) on dig­itized object boundaries and curves. There 
are two ways to attack the problem: increasing the sampling rate and removing high frequency components 
of the image. The first approach calls for increasing the res­olution of the raster device. But the size 
of frame buffer and consequently the rendering costs increase quadratically in the resolution. Even at 
a resolution of 1024 x 1024, objectionable staircasing effects still exist. High-resolution alone is 
not an economic solu­tion to the problem. The second approach of filtering high frequency components 
of the image was adopted by many researchers [1, 4, 5, 6, 7, 8] to combat alias­ing. These techniques 
utilize grayscales to increase the effective spatial resolution. The disadvantages of the second approach 
are high computational cost involved in low-pass filtering operations, and fuzzy object edges. Proposed 
in this paper is a new concept of an­tialiasing that leads to efficient smooth curve render­ing algorithms. 
Our antialiasing research is done in both spatial and frequency domains. The new algo­rithms achieve 
exactly the same antialiasing effects as Fujimot~Iwata s algorithm for line segments but at a fraction 
of the latter s cost. A new antialiased line gen­erator is designed for smooth line generation that re­quires 
only half as much integer arithmetic as Bresen­ham s line algorithm [2]. And the antialiased line gener­ation 
can be easily implemented by hardware. Smooth circles can also be generated by the new technique I For 
phy~i~~ di~plays a curve should be mOdekd = a narrow 2-dimensional image rather than a l-dimensional 
mathematical entity of no area. , 1991 .4CM-()-89791-43h-X 9 1/M7/()143 $0075 I43 at a lower cost than 
Breaenham s circle algorithm [3]. The paper is organized as follows. In the next section a dynamic error 
measure for the quality of digitized curves is introduced, and the correspondence between the measure 
and the image quality is demonstrated. Then based on this error measure the new antialias­ing concept 
is introduced in section 3. The rationale for the new antialiasing algorithm is also established using 
convolution theorem, hence it is in principle con­gruent to the current antialiasing algorithms. In sec­tion 
4 we prove the equivalence between our algorithm and Fujimot-Iwata s algorithm. In sections 5 and 6 the 
high efficiency of the new antialiasing technique is demonstrated by the development of fast antialiased 
line and circle generators. Section 7 deals with the gen­eralization of the new antialiasing technique 
to general curves and to antialiased object boundaries blent in col­orful background.  2 Dynamic Error 
in Curve Digit izat ion Previously image aliasing was investigated in the fre­quency domain. In this 
section we study image aliasing in the spatial domain (rcder plane). Some of our pre­vious results in 
digital geometry [10, 12] are used to study the quality of digitized curves. Let y = ~(z) be a differentiable 
curve to be digitized in the raster plane, and partition the curve into segments where ei­ther O < 1~ 
(z)l ~ 1 or 1 < l~(z)l < co, called x­dominant and y-dominant segments, respectively. Now consider an 
x-dominant curve segment without loss of generality (the discussion on y-dominant curve seg­ments is 
the same through symmetry). Then the digiti­zation of this curve segment is defined to be an ordered 
point set {(i, Y~) : 1 ~ i ~ N}. This definition means that the curve segment is sampled in unit raster 
steps along the x axis, and the sample value ~(i) is quantized to Yi. Due to the finite precision of 
the raster plane Yi must be an integer, resulting in the commonly used quantization scheme y= f(i)+~ 
(1) [J to minimize the y distance between the sampled value ~(i) and its image point in the raster plane, 
But how meaningful in terms of human perception is this simple criterion Eq( 1)? Let us consider the 
geometry of Fig. 1 where the three pixels indicated by solid dots are chosen 144 .................. .................. 
... -{-o -  -  o  -­ --  q -~ 2  i  -6  -    - Figure 1: Dynamic error in curve digitization 
by Eq(l) as the discrete image of the continuous curve. If, however, the pixel labeled by o replaces 
the one just above it, then the so-called dynamic error defined by Ei,j = f(i) -.f(~) [Yj U] (2) is 
minimized. The above dynamic error relates to the first-order difference and hence characterizes the 
dig­itization error in curve dynamics. Visually, the new pixel configuration obtained by pulling the 
pixel in the middle column down by one raster unit presents a bet­ter approximation to the original curve. 
This improve­ ment results because the pixel pattern of the solid dots distorts the dynamic context of 
the original curve seg­ ment. Namely, the convex curve ~(z) is mapped to a concave pixel pattern. By 
moving the middle pixel down by a raster unit, the convexity is preserved, re­sulting in a more pleasant 
rendering. Human eyes are more sensitive to the dynamic context of a curve than to its absolute spatial 
position. It is difficult for view­ers to detect a translation of an object if the amount of shift is 
relatively small compared with the size of background, but easy to catch a slight distortion of the dynamic 
context of the object as a disturbing image alias. This observation suggests that the error mea­sure 
Eq(2) is subjectively more meaningful than Eq(l), and antialiasing should aim for minimizing the loss 
of dynamic information of original curves due to digitiza­tion. Given an x-dominant curve segment ~(z) 
and its digitization {(i, Yi) : l~i~N}, an NxN matrix of dynamic errors {Ei,j }, 1~ i,j <N, is defined 
(see [12] for more detailed discussions on the dynamic error matrix E). Our goal is to minimize II E 
l!, the norm of the error matrix. For binary raster displays minimiz­ing II E II is a very difficult 
optimization problem [12]. Fortunately, for grayscale devices we can have a simple solution to the problem. 
Two-Point AntLAliasing Scheme  The dynamic error is caused by rounding f(i) to an integer Yi. The dynamic 
error matrix E becames a zero matrix, i.e., II E II= O, if Yi were chaen to be ~(i). We would like to 
have an addressable pixel centered at the coordinates (i, f(i)). Let l[i, j] be the intensity of the 
pixel (i, j) and 10 be the intended intensity for the curve. Then the imaginary pixel (i, ~(i)) may be 
visually simulated by setting l[i, [~(i)j] = ZO([/(i)l -~(i)) (3)Z[i, ~f(i)l] = ~o(~(i) [f(i)]) { If 
we consider the pixel (i, j) as a unit square centered at (i, j) containing light energy l[i, j], then 
point PP = (i, f(i)) is the center of gravity of the two lit points PO = (i, [~(i)j) and PI = (i, [~(i)l), 
because 10PP = l[i, lf(i)J]pO + ~[j, [f(i)llm (4) Therefore, the overall effect of Eq(3) is a lit area 
of en­ergy 10 focused at the real point pP = (i, f(i)) which is a perceived pixel exactly on the original 
curve ~(x). The ordered set {(i, ~(i)) : 1 ~ i s IV} of those perceived pixels renders a perceived curve. 
Clearly the dynamic error II E IIfor this perceived curve is zero, eliminating the loss of dynamic information. 
The practical signif­icance of Eq(3) is its simplicity which leads very fast anti-aliasing algorithms 
as we will see later. Eq(3) is a two-point antialiasing scheme. We plot all pixels in the two-pixel wide 
band that bounds the true curve y = ~(z) with their intensities inversely proportional to the distances 
between these pixels to the curve. The closer is a pixel to the line, the brighter it is, then the overall 
visual effect of this band will be the illumination area of the lit curve at its real position after 
our eyes integrate the contributions of all pixels in the band. In addition to being intuitively appealing 
the an­tialiasing scheme Eq(3) can also relates to removing high frequency components of sharp intensity 
jumps at the image edges. In order to apply a filter to the image we no longer treat y = j(z) as a mathematical 
curve of no width; instead we model the curve by a two­dimensiona] grayscale signal g(z, y) with interior 
inten­sity 10 and exterior intensity O. The curve y = j(z) is the center line of the tw~dimensional signal 
g(~, y). The image intensity l(i, j) after applying a low-pass filter to g(z, y) is given by I[i, j] 
= ti(u, v)g(i u,j v)dudv. (5) // y= /7%) I Figure 2: The two-dimensional signal g(z, y) modeling the 
physical image of the curve y = ~(z) before filtering. The convolution kernel 6(u, u) is determined by 
the in­tensity density of a pixel in its neighborhood. It is easy to verify that if we choose the box 
filter 1 IUI<*,IVI<+ 6(U,V) = (6) O otherwise { and model the curve y = j(z) in raster plane by the 
two-dimensional signal 10 [Y f(l~+;J)[s4 g(x, y) = (7) O otherwise { then the solution of the convolution 
Eq(5) is the simple expression of Eq(3). The signal g(z, y) is a chain of two-dimensional unit square 
impulses as depicted by Fig. 2. The above analysis reveals that the tw~point anti-aliasing scheme Eq(3) 
is a two-step process. First the image of the curve y = j(x) is modeled by the two dimensional impulse 
signal signal g(z, y) of Eq(7), then the impulse signal is put through the box filters r5(u, v) centered 
at individual pixels. The additive responses of these atomic filters yields the antialiased digital curve. 
Admittedly the above anti-aliasing model is far from ideal. The box filter does not reflect the fact 
that the intensity density of a pixel has Gaussian-like rather than uniform shape. Moreover, the curve 
y = ~(x) is modeled by a stripe image g(z, y) whose edge is not smooth. But aliasing is primarily caused 
by sharp in­tensity changes (high frequency components at the in­tensity transition from g(x, y) = O 
to g(z, y) = l.). The low-pass filtering aims at smoothing the steep intensity jump not at smoothing 
the geometric shape of the input signal. The tendency of g(x, y) to preserve the dynamic information 
of y = f(r) is far more important than its geometric smoothness in our principle of antialiasing. I45 
The staircase appearance of the g(z, y) will be eventu­ ally subdued since the low-pass filter will 
blur the input image g(z, y) anyway. For comparison Fig.3 gives three groups of Iinea with various orientations 
done by Bresenham s, Gupta­Sproull s and the tw~point antialiasing scheme Eq(3). Gupta-Sproull s antialiased 
line algorithm [7], generally regarded as a better performed one, uses a cone-shaped low-pass filter 
as an approximation of Gaussian filter to suppress the jaggies. The algorithm understand­ably is quite 
computationally demanding. The photos show that the line images produced by the new tech­nique are not 
inferior in quality to those produced by GuptaA3prou11 s algorithm in quality. Note that Gupta­Sproull 
s algorithm is a three-point antialiasing scheme in the sense that in each column three pixels are usually 
set to different intensities. Consequently, the lines gen­erated by this algorithm look fuzzier than 
those done by the tw~point scheme. Our real motive for developing the model Eq(7) is to convert the convolution 
integration of Eq(5) to the sim­ple intensity interpolation between two adjacent pixels in Eq(3), gaining 
computational efficiency of antialias­ing as we will see in sections 5 and 6. 4 Equivalence to Fujimoto­ 
Iwata s Algorithm Interestingly, we can prove the equivalence between the simple formula Eq(3) and the 
seemingly more compli­cated antialiasing operation by Fujimoto and Iwata [6]. Indeed, after some intricate 
derivation, Fujimoto and Iwata arrived at Z[i, [f(i)j] = I(d 2d~)/d (8) I[i, [f(i)l] = l(d 2d~)/d, 
 where, as marked in Fig. 4, d= 2 cos a, dl and d2 are the distances from the pixels (i, Lf(i)] )) and 
(i, [~(i)l ) to the true line. Eq(8) is the formula for antialiased lines using the smallest Fourier 
window. It is apparent from the figure that Figure 3: Lines generated by Bresenham s (above), Gupta-Sproull 
s (middle) and the two-point antialias­ dl = (f(i) Lf(i)j ) cosa (9) ing (bottom) algorithms. dz = 
([f(i)l f(i)) COScr. Plugging dl and dz into Eq(8) we can simplify Eq(8) to Eq(3). The above simplification 
gives Fujimot~Iwata s an­tialiasing algorithm a more intuitive interpretation of 146 Figure 4: The geometry 
of Fujimot~Iwata s ant ialias­ing algorithm. Eq(3), another analytical basis formed by Eqs(5)-(7), and 
more importantly, a simpler and more efficient im­plementation.  5 Fast Ant LAliased Line Generator 
In this section we convert the simple antialiasing scheme Eq(3) to a fast antialiased line generator. 
Without Icss of generality only lines in the first octant are consid­ered. Other cases follow trivially 
through symmetry. Let (zO, yO), (zl, yl), Z2 > z1, y2 > yl, be the two points in the raster plane defining 
a line. We translate the point (zO, yO) to the origin, so the equation of the line becomes y = kx, O< 
k= ~ <1. Then Eq(3) can be rewritten for ~(z) = kz as 1(z, [kzl ) = 10(kz lkxj) 1(2, lkzJ ) = z~ 1(Z, 
[kXl). (lo) where (x, Lkxj ) and (z, ~krl) are the two adjacent pix­els in the z column that are immediately 
below and above the true line. Clearly, the total intensity in a column is the constant 1, so the even 
brightness of the band can be achieved. To implement the antialiasing scheme Eq(lO), we need to determine 
for a given z the pixel positions (z, Lkz] ) and (z, [kzl ) (they coincide if kx is an in­teger) and 
their intensities 1(z, [kx] ) and l(z, (kxl ). Computer Graphics, Volume 25, Number 4, July 1991 These 
four values can be determined by an elegant in­ cremental algorithm operating on a single integer D represented 
by a machine word of n bits. The integer increment involved is d = [k2n + 0.5J. As the initial­ ization, 
we set D = O, Z(ZO, yO) = Z. Then we march z from ZO to Z1 and increment D by d at unit step. The operation 
D * D+d is a module 2 addition with the overflow recorded. Whenever D overflows the t we-point high pixel 
band pixel moves diagonally; otherwise it moves horizontally. This is essentially a classical DDA method. 
The only difference is in that both the z and y increments, namely, Ax = 1 and Ay = d, are inte­ ger 
rather than real values. For the following analysis we may consider D as a fixed point number with the 
decimal point before its most significant bit, or concep­ tually perceive the proposed integer arithmetic 
aa fixed point arithmetic. Thus the error between the real DDA increment and our integer DDA increment 
is e=k d2-n. (11) Clearly, Iel < 2-n, and this error will be shown to be negligible. All gray-scale 
raster devices have 2~, for some m> 1, discrete intensity levels from O (absolutely black) to 2m 1 (absolute 
white). Thus the intensity inter­polation between the two vertically adjacent pixels of Eq( 10) becomes 
a hi-partition of t he integer 1, the max­imum intensity. The intensity of the upper pixel for the line 
is I(x, [kzl) = Io(kz [kzj) = (2m -l)(D2-n + e~) = D2m-n i-(2M l)ez D2- .(12) Since the intensity 
Z(Z, (Iczl ) must be an integer, we approximate it by the first term of Eq(12), D2m-n, assuming n> m. 
This approximation gains great com­putational efficiency while the error incurred (the last two terms 
of Eq(12) has no or little impact on image quality 2s we will analyze later. The approximated I(z, [kzl 
) sz D2m-n is simply presented by the m most significant bits of D. More­over. it is evident that the 
intensity of the lower pixel I(z, Lkzj ) = 10 I(z, (kzl ) = l(x, rkrl ), where Z(Z, (kzl ) is the integer 
obtained by the bitwise-inverse operation on 1(z, ~kxl ). This is because the bit pat­ tern for the integer 
2m -1 _ D2m-n is the inverse of that for D2M- due to the fact 10 = 2m -1. Now we can see that the integer 
D controls both pixel positions I I(xO,yO) := I(xl,yl) := I ; D:=O: Comparison N N;2 I I d:=Ltin+o.5J; 
I Buffer Writing N < 2N Table 1: The number of different operations required 0+1; by Bresenham s algorithm 
and the new antialiased line l-l; algorithm. plotting a line of length N required by Bresenham s < algorithm 
and the new antialiased line algorithm are tabulated in Table 1. The new algorithm requires twice as 
many buffer writes as Bresenham s algorithm, but still its buffer )+dJ access, a bottleneck in rendering, 
is a minimum (tie with -Fujimoto and Iwata s algorithm with the small­est Fourier window) among all current 
antialiased line Yes generators.  flow An attractive feature of the new antialiased line gen­ * erator 
is that it simultaneously meets two usually mu­tually exclusive criteria: good image quality and high 
computational efficiency. At the same time the logic of the new line algorithm remains simple and its 
hardware implementation is straightforward. An integer adder for D is all we need with its overflow controlling 
the pixel positioning and its original and inverse values being the I(xo,yo+l):=r(x 1,yl -l):=I(xo,yo); 
required intensities. Historically, we used a very crude fifty-fifty intensity split scheme as a trick 
to speed upI curve scan-conversion [9, 11] under a guise of antialias­ ing. The above work drew a satisfactory 
conclusion to Figure 5: The antialiased line generator (O s k < 1). our attempt to unify antialiasing 
and scan-conversion. The new algorithm is not complete without an error bound for the approximation it 
employs. The error in and intensities, and the inner loop of the algorithm only approximating 1(z, [kz] 
) by D2m- is determined by requires an integer addition to D. the magnitude of z and the difference n 
 m. Let L Furthermore, since the line segment has mirror sym­be the line length. If 2~-1 < L s 2*, f 
>0, then the metry with respect to its center, we can plot it from the truncation error can be bounded 
by two ends toward the center using the same logic [13], saving half of the computations. The new algorithm 
for IZo(kz-[kzj) -D2m- I < (2m-1)2- 2 - + D2-n lines with O ~ k~ 1 is described by the flowchart in < 
Z -n- (zl)+)+ 1. (13) Fig. 5. Unlike all its predecessors, the above antialiased line In the above inequality 
we used the facts that D< 2 , generator requires only integer addition and bit manip-Iel < 2-n, and x 
< L/2 due to symmetric generation ulations. While producing smooth lines, the new algo-of the antialiased 
line. For L< 2n m+l the error in rithm requires only half ss many operations as Bresen-I(z, [kzl ) has 
a magnitude less than 2. In our exper­ham s algorithm because it propagates two pixels per iments, a 
10~0 relative error in distributing 1 between iteration while using the same amount of computations two 
adjacent pixels does not lead to noticeable degra­per iteration. The numbers of different operations 
for dation in image quality. It was also observed that 32 different gray scales are sufficient to eliminate 
the most of aliasing, For a 1024 x 1024 display, the maximum L <211 (t = 11). Suppose that 32 gray scales 
(m = 5) is used for antialiasing. Then we need n ~ 15 to bound the error in I(r, [kzl ) by 2, or the 
relative error by 0,063. This only requires D to be a twobytes integer. Our recent research revealed 
that the proposed an­tialiased line algorithm is particularly suitable to be in­corporated into a logic-enhanced 
frame buffer to solve the bottleneck of frame buffer access [14]. An intelligent frame buffer architecture 
in the form of wavefront ar­ray processors was designed to scan-convert lines right inside the frame 
buffer. This design achieves extremely high rendering throughput with very low frame buffer bandwidth 
requirement.  6 Fast Anti-Aliased Circle Generator Due to the 8-way symmetry of the circle, it sutfices 
to consider the circle X2 + yz ,= r2 in the first octant. For the circle equation, the two-point antialiasing 
scheme Eq(3) becomes (14) Now we derive the algorithm to compute Eq(14) as j marches in the y axis from 
O to > in scan-converting the first octant circular arc. The first issue is to de­termine when the integer-valued 
function ~­ 11 decreases by 1 as j increases. We need the critical val­ ues tsuch that r -(t 1)2] [/-] 
= 1to 1~ 2 move the pixel band being plotted to the left by one step. This computation can be simplified 
by the follow­ing lemma. LEMMA 1 ~~e relation [/r -(~-1)21 -[m= 1 holds if and only if [/r -(t-1)2] -~r2-(t 
-1) > [/-] -J-.  Proof. Since ~~ is monotonically decreasing in r  (t 1)2> [~~1 ~? [@-(~-1) ] -/ = 
implies [/r -(~-1) 1 -I=> o Computer Graphics, Volume 25, Number 4, July 1991 But in the first octant 
we have r2 ( l)2 <-<l (15) prohibiting [i. -(f-1)21 -[~~1 > I hence r (t 1)2 (<=1 =1. 1~ 1 The only-if 
part can be proven by contradiction. Assume that ({r,-(t -1)~1 -~~~~ = I but [/r -(f -1) ] -<r -(~-1)2 
s [J-1 ­~. This requires ~ r2 (t 1)2 ~~>1, an impossibility in the first octant. l For given r the values 
~­ 1--!1< [ ~<~, serve dual purposes: determining the pixel po­sitions as suggested by the above lemma 
and determin­ing the pixel intensities as in Eq( 14). Let the intensity range for the display be from 
O to 2m 1 and define the integer variable D(r, j) = I(2M 1) ([/m] -J-) +0.5J (16) Then it follows from 
Eq( 14) that 1 (~~~1 ,j) = D(r,j) (1I-)j 1) = D(r, j), l<j< ;,(17) where D(r, j) is the integer value 
obtained through bitwise-inverse operation on D(r, j) since ~([=l,.i)+~([~]jj)= 1=2 1 (18) and since 
the intensity values are integers. By Eq(16) every decrement of the function <~ ~­ [1 as j increases 
is reflected by a decrement of D(r, j), thus D(r, j) can be used to control the scan-conversion of the 
circle. The new antialiased circle algorithm based on precomputed D(r, j) is extremely simple and fast. 
The algorithm for the first octant is described by the flowchart in Fig. 6. The inner loop of the antialiased 
circle algorithm re­quires even fewer operations than Bresenham s circle algorithm. Of course, the gains 
in image quality and scan-conversion speed are obtained by using the D(r, j) table. If R~~x is the maximum 
radius handled by the circle generator, then the table size will be ~Rma=. It is my opinion that the 
rapidly decreasing memory cost makes the above simple idea a viable solution to real­time antialiased 
circle generation. For instance, for a 64K bytes ROM the above algorithm can display an­tialiased circular 
arcs of radius up to 430, \Vithout the I 49 . : SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 EE $ICG!APH 
11­ i:=r; j:=q I(i,j):=I; T:= O;  C Yes -terminate Yes 1 No i := i-1; I t - I(i,j):=~, I(i-1 ,j):=D(r,j); 
T:=D(r,j); I Figure 6: Antialiased circle generator (lst octant). precomputed table D(r, j) the antialissed 
circle alg~ rithm can be implemented by computing the function D(r, j). The performance of the new antialiased 
circle alg~ rithm is demonstrated by Fig. 7.  Other Antialiasing Issues We demonstrated that the new 
antialiasing technique is particularly efficient for generating antialiased lines Figure 7: Circles by 
Bresenham s (above) and the new and circles since Eq(3) can be incorporated into the antialiasing algorithms 
(below). classical incremental curve scan-conversion framework. But it is not restricted to those two 
graphics primi­tives. The intensity interpolation of Eq(3) applies to any curves or object edges. We 
should not partition a general curve into line segments and then antialias line dynamic information 
of the original curves or object edges. The behaviour of this antialiasing scheme in fre­quency domain 
was also analyzed. It was shown that the new antialiasing technique can generate smooth line segments 
and circular arcs at even higher speeds than those of Bresenham s line and circle algorithms. The hardware 
or assembly-language realization of our new antialiasing algorithms ia straightforward. These fea­tures 
have practical significance when antialiasing is performed on small economical graphics devices or in 
time-constrained applications. Acknowledgment The author gratefully acknowledges the financial sup­port 
of the Canadian Government through NSERC grant 0GPO041926 and thanks SIGGRAPH reviewers for their polishing 
of his original manuscript. References [1] A. C. Barkans, High speed high quality an­tialiased vector 
generation, Computer Graphics, vol. 24, no. 4, p. 319-326, Aug. 1990. [2] J. E. Bresenham, Algorithm 
for computer control of digital plotter, IBM Syst. J., vol. 4, no. 1, 1965, p. 25-30. [3] J. E. Bresenham, 
A linear algorithm for incremen­tal digital display of circular arcs , Comm. ACM, vol. 20, no. 2, 1977, 
p. 750-752. [4] F. Crow, The aliasing problem in computer­generated shaded images: Comm. ACM, vol. 20, 
no. 11, Nov. 1977. [5] D. Field, Algorithms for drawing anti-aliased cir­cles and ellipses, Computer 
Vision, Graphics, and Image l%oc., vol. 33, p. 1-15, 1986. [6] A. Fujimoto and K. Iwata, Jay-free images 
on raster displays, IEEE CG&#38;A, vol. 3, no. 9, p. 26­34, Dec. 1983. [7] S. Gupta and R. F. Sproull, 
Filtering edges for gray-scale displays, Computer Graphics, vol. 15, no. 3, p. 1-5, Aug. 1981. [8] M. 
Pitteway and D. Watkinson, Bresenham s al­gorithm with gray scale: Comm. ACM, vol 23, no. 11, November 
1980. [9] X. Wu and J. Rokne, Double-step incremental generation of lines and circles , Computer Vision, 
Graphics, Image Proc., vol. 37, 1987, p. 331-344. 10] X. Wu and J. Rokne, On properties of discretized 
convex curves, IEEE Thans. Pattern Analysis and Machine Intelligence, vol. 11, p. 217-223, Feb. 1989. 
11] X. Wu and J. Rokne, Double-step generation of ellipses , IEEE CG&#38;A, vol. 9, no. 3. p. 56-69, 
May 1989. [12] X. Wu and J. Rokne, Dynamic error mea­sure for curve scan-conversion, Proc. Graph­ics/interface 
89, London, Ontario, p. 183-190, June 1989. [13] J. Rokne, B. Wyvill and X. Wu, Fast line scan­conversion 
~ ACM Trans. on Graphics, vol. 9, no. 4, p. 377-388, oct. 1990, [14] X. Wu, A frame buffer architecture 
for parallel vector generation, Proc. Graphics/Interface 91, Calgary, June 1991. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122735</article_id>
		<sort_key>153</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Unbiased sampling techniques for image synthesis]]></title>
		<page_from>153</page_from>
		<page_to>156</page_to>
		<doi_number>10.1145/122718.122735</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122735</url>
		<abstract>
			<par><![CDATA[We examine a class of adaptive sampling techniques employed in image synthesis and show that those commonly used for efficient anti-aliasing are statistically biased. This bias is dependent upon the image function being sampled as well as the strategy for determining the number of samples to use. It is most prominent in areas of high contrast and is attributable to early stages of sampling systematically favoring one extreme or the other. If the expected outcome of the entire adaptive sampling algorithm is considered, we find that the bias of the early decisions is still present in the final estimator. We propose an alternative strategy for performing adaptive sampling that is unbiased but potentially more costly. We conclude that it may not always be practical to mitigate this source of bias, but as a source of error it should be considered when high accuracy and image fidelity are a central concern.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Monte Carlo]]></kw>
			<kw><![CDATA[adaptive sampling]]></kw>
			<kw><![CDATA[antialiasing]]></kw>
			<kw><![CDATA[statistical bias]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.4.1</cat_node>
				<descriptor>Sampling</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Antialiasing**</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010386</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Antialiasing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14068580</person_id>
				<author_profile_id><![CDATA[81100166914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kirk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology, Computer Graphics 350-74, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14183802</person_id>
				<author_profile_id><![CDATA[81100529394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arvo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>97886</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arvo, james, and David Kirk, "Particle Transport and Image Synthesis," Computer graphics, 24(4) August 1990,pp, 63-66.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dippe, Mark A. Z., and Erling Henry Wold, "An tialiasing through stochastic sampling," Computer Graphics, 19(3), July 1985, pp.69-78.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>19253</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Freund, Jhon Ei., and Ronald E.Walpole, Mathematical Statistics, 4th edition, Prentice Hall, New Jersey, 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>94789</ref_obj_id>
				<ref_obj_pid>94788</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Glassner, Andrew S., "An oevrview of Ray Tracing," in An Introduction to Ray Tracing, A, S, Glassner, ed,, Academic Press, New York, 1989.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kajiya,J. T:,,The Rendering Eqiuation," Computer Graphics, 20(4), August 1986,pp.143-150.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lee, Mark. E. Richard A.Redner, and Samuel P. Uselton, "Statistically Optimized Sampling for Distributed Ray Tracing," Computer Graphics, 19(3), July 1985,pp.61-68.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Mitchell,. Don P., "Generating Antialiased Images at Low Sampling Densities," computer Graphics, 21(4) July 1987,pp,65-69.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74362</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Painter, James,and Kenneth Sloan, "Antialiased Ray Tracing by Adaptive Progressive Refinement," Computer Graphics, 23(3), July 1989, pp,281-288.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Purgathofer, W, "A Statistical Method for Adaptive Stcthostic sampling," in Proceedings of Eurographics 86, ed.A.A.G. Reauicha, Elsevier, North-Holland, 1986,pp.145-152.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>539488</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Rubinstein, R.Y., Simulation and the Monte Carlo Method, J.Wiley, New york, 1981.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Whitted,turner, "An Improved Illumination model for Shaded Display, " Communication of the ACM, 32(6), June 1980, pp.343-349.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Unbiased Sampling Techniques for Image Synthesis 
David Kirk James Arvo California Institute of Technology Program of Computer Graphics Computer Graphics 
350-74 Cornell University Pasadena, CA 91125 Ithaca, NY 14853 Abstract We examine a class of adaptive 
sampling techniques em­ployed in image synthesis and show that those com­ monly used for efficient anti-aliasing 
are statistically bi­ ased. This bias is dependent upon the image function being sampled as well as the 
strategy for determining the number of samples to use. It is most prominent in ar­eas of high contrast 
and is attributable to early stages of sampling systematically favoring one extreme or the other. If 
the expected outcome of the entire adaptive sampling algorithm is considered, we find that the bias of 
the early decisions is still present in the final estima­tor. We propose an alternative strategy for 
performing adaptive sampling that is unbiased but potentially more costly. We conclude that it may not 
always be practical to mitigate this source of bhs, but as a source of error it should be considered 
when high accuracy and image fidelity are a central concern. CR Categories and Subject Descriptors: 
I.3.7 [Computer Graphics]: Three-Dimensional Graph­ics and Realism; 1.3.3 [Computer Graphics]: Pic­ture/Image 
Generation; General Terms: Algorithms, Graphics Additional Key Words and Phrases: Adaptive Sam­pling, 
Anti-aliasing, Monte Carlo, Statistical Bias. Introduction Many of the sampling techniques employed in 
computer graphics are adaptive in the sense that they attempt to concentrate effort in areas where complexity 
is high. In particular, adaptive anti-aliasing schemes choose to sam­ple at a higher rate where the scene 
is interesting, such as near edges. Many such schemes have been devised, both deterministic [11, 4] and 
stochastic [6, 2, 9, 7, 8]. The latter category has received the most attention and es­sentially consists 
of multi-stage Monte Carlo integration techniques. Common to all of these is the notion of using a small 
number of samples to detect regions where addi­tional sampling is required to achieve a reliable answer, 
that is, one with an acceptably low level of noise. Pcrmlswm 10 copy without fee all or pwt of this material 
is grmmxi provided Ihm the copieh me not made or d]wrihuted for direct commercial ~dvwrtage, the ACM 
copyright notice wrd ihe litle of the publicati(m and its dfite appear, andnoticeis giventhatcnpyirrgis 
by permis~ltm{~fthe Asweiation for ComputingMachinery.To copy (~thcrwIW, or to republish,rcqums J fcc 
wrd/orspecilicl~,rml+kion. While all of these methods have been reasonably suc­ cessful in achieving 
this goal, it is important to under­ stand the statistical effects of such a strategy. To do this we 
must examine multi-stage sampling plans in toto and characterize their statistical behavior. In particular, 
we wish to determine whether they in fact attain the correct answer on average. Every stochastic anti-aliasing 
algorithm can be viewed as defining a random variable at each pixel to estimate the quantity of interest. 
This quantity is typically the unknown image function integrated with a filter kernel such as a gaussian 
or a box-filter. The purpose of adap­tive sampling is to reduce the variance of these random variables, 
or estimators, with minimal increase in com­putation. If the expected value of an estimator is the solution 
we are seeking, it is said to be unbiased. If the estimator has a bias that can be made arbitrarily small, 
perhaps by increasing the number of initial samples suf­ficiently, then it is said to be consistent [3]. 
By analyzing the behavior of a prototypical multi­stage sampling algorithm operating on a simple class 
of test cases, we will show that most adaptive sampling plans fall into the category of consistent but 
biased estimators. Although the bias is typically small, this is a source of error that should be taken 
into consideration when hirzh accuracy is required.  2 Common Sources of Sias Sources of statistical 
bizs can be found in many seemingly innocuous operations in image synthesis. For example, pixel values 
are frequently truncated or otherwise trans­formed so as to fall within the gamut of color monitors. 
Removing out-of-gamut colors can shift the distribution mean. At a very low level, the pseudo-random 
number generators at the heart of Monte Carlo approaches often have a built-in bkt. At higher levels, 
the practice of im­portance sampling [5, 10] red uces variance by sampling more frequently where the 
result is large, which requires precise renormalization if the original expected value is to be maintained. 
Another example is the practice of trun­cating excessively deep ray trees in ray tracing. This can cause 
a systematic bias by eliminating a large number of small contributions [I]. In general, whenever we depart 
from naive Monte Carlo in an attempt to improve statistical efficiency, care must be taken to avoid introducing 
unnecessary bias. This is also true in screen space, for example, when anti­ c 1991 A( kl-()-x9791-436 
-xJ9101)70153 w) 75 I53  SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 EstimateMean(X, begin n, c) Draw 
a set of n identically samples from X. distributed random sn-{xl, x2,.. .,xn}; if Variation (S~) < c 
then begin This is the easy case: use the sample mean as an estimate o} the true mean. ~4-x; end  
else begin This is the hard case: invoke a costly oracle to compute the true mean. f-TrueMean(X); end 
  return f; end Figure 1: A hypothetical adaptive sampling algorithm similar in spirit to mmt existing 
algorithms. This is biased for most inputa. aliaaing at the pixel level. As we show in the following 
section, adaptive anti-aliasing algorithms can introduce a systematic bias dependent upon the image function. 
This bias is greatest in areas of high contrast and is caused by early stages of sampling systematically 
favoring one ex­treme or the other. In Section 4 we propose a modified approach that is unbiased. 3 
Bias From Adaptive Sampling In this section, we examine the statistical behavior of common adaptive anti-aliaaing 
algorithms. We begin by formulating a hypothetical sampling algorithm that re­tains the salient features 
of most multi-level sampling plans yet is simple enough to allow convenient analy­sis. The basic strategy 
is to use samples sparingly except where more work is deemed necessary. The decision to invoke a more 
costly method as a second stage is baaed upon a statistic we will call variation, a function of the first-stage, 
or pilot, sample. This could be the sam­ple variance, the contrast , or a function of the sample size 
and variance as in [6] and [9]. An idealized algo­rithm using this strategy is shown in Figure 1, where 
X is the populationn whose mean we wish to estimate. For anti-aliasing, X will be the set of image values 
with prob abilities influenced by the filter kernel. Although the meaning of variation differs among 
the various approaches, a universal feature is that it goes to zero as the maximum deviation within the 
sample goes to zero. Thus, any such algorithm would be satisfied with only the first-stage sample when 
all values are identical. If the variation is greater than some c, then we will classify the population 
as hard to sample, and invoke a more expensive second-stage sampling technique. For simplicity we will 
assume here that the second-stage or­ 154 acle computes the exact mean; in reality, this action would 
be simulated through a large number of samples. Because this ideal can be approximated to any given pre­cision, 
our conclusions carry over to real algorithms, al­though the actual amount of bias witl differ. To demonstrate 
that the strategy in Figure 1 can be problematic we need only examine its behavior on a sim­ple class 
of inputs. In particular, we will assume that X consists of a finite number of distinct values, ~1, 12, 
..., Ik, with corresponding probabilities w, wz, ..., LJk. This sit­uation occurs, for example, when 
applying a box filter to a pixel area consisting of k constant-intensity region% the Z s would represent 
the intensities within the pixel and the w s would represent their fractional coverages. The actual mean 
is then (1) With this characterization of X we can easily compute the expected value of the random variable 
< returned by the algorithm in Figure 1. Using conditional expectations based on a classification of 
easy or hard , indicating that the variation of S~ is below or above the threshold c, respectively, we 
have E[~] = E[~ Ieasy] x Prob[easy] + E[< I hard] x Prob[hard] (2) The oracle guarantees that E[~ I 
hard] = 1, the true mean. To analyze the conditional expectations we ob­serve that any sample, S., can 
be characterized as a k­tuple, (nl, nz, ..., nk ), where nj is the number of samples assuming the value 
Ij. Then nl +.-. + nk = n and the probability of a k-tuple is given by the multinominal dis­tribution 
[3]: 4 w...w.k prob[nl, nz, . . ..nk] = n1fn21+. .nk! n!. (3) .. Using this fact, we cau compute E[<] 
for any input of the form described above. We simply step the algorithm through all distinct k-tuplez 
and sum the resulting values of f weighted by the corresponding probabilities. How­ever, if we assume 
c to be sufficiently small that S~ will be classified as easy only when all n samples are of the same 
value, then Equation 2 reduces to a very simple expression. In this case we have Prob[easy] = w; + w: 
+ . ..+ w; (4) and the expected value of <, given that the initial sample was found to be easy , is 
(5) Substituting these into Equation 2 and observing that Prob~ard] = 1 Prob[easy] we arrive at the 
expression (6) i=l Because 1 is the true mean, the summation on the right of Equation 6 is the amount 
of bias. This will be nonzero @ @ Computer Graphics, Volume 25, Number 4, July 1991 for all but a small 
class of inputs. The bias diminishes as the number of initial samples increases, indicating that the 
estimator is consistent. In Section 5 we present ex­perimental data obtained from Equation 6. 4 An Unbiased 
Adaptive Sampling Plan The hidden flaw in the algorithm above is that the first­stage samples deemed 
eas y are not completely random, and therefore may not fairly represent the entire popula­tion. That 
is, the test for accepting a first-stage sample is usually correlated in some way with the mean of the 
sample. There is a straightforward modification of the above sampling plan to avoid this bias. First 
select a small subset of the area X, call it R, and draw a sample of size n from this subset. We may 
examine this sample to determine the number of samples to draw from the rest of the region, X R, but 
in any case we use the initial sample mean to estimate the mean of R. Because we do not alter the estimate 
of R, no bias is introduced there. Also, because the second stage is simply a choice among two or more 
unbiased estimators for a dis~int region, it also remains unbiased. It follows that a weighted sum of 
the these sample means, weighted proportionately by area, results in an unbiased estimate over the entire 
region. This approach is outlined in Figure 2. As with any multi-stage scheme, the goal is to estimate 
the population variance by means of a first-stage sample. To the extent that the region R is representative 
of the entire region, drawing the pilot sample from it will serve this purpose. This suggests that R 
should be scattered throughout X. As a special case of this strategy, note what happens if we allow the 
area of region R to shrink to zero. The result is a strategy whereby the pilot sample is used solely 
to select the sample size for the second stage not for estimating the mean. This clearly avoids any 
possibility of a correlation between the estimator of the mean and the variation of the pilot sample. 
These examples suggest a simple rule that will avoid introducing bias in multi-stage sampling schemes: 
decide how a sample is going to be used before it is drawn not based on the actual values drawn. Observing 
this rule prevents us from modifying estimates in any way that may be correlated with the result. This 
technique can be applied in a hierarchical fashion and stratified, similar to [6]. After the first decision 
has been made baaed on the pilot sample, we can make addi­ tional decisions later, provided that we either 
discard the samples used to influence the strategy, or decide ahead of time that they will be used to 
estimate the mean over the subregion from which they were drawn. The main disadvantage of using a technique 
such as this is that it is difficult to avoid either wssting samples or producing a high-variance result 
that cannot be remedied. The former occurs if R is chosen to be so small that the pilot sample contributes 
very little to the final estimate. The latter occurs if R is large and the pilot sample fails to provide 
a sufficiently reliable estimate of its mean. We are then left with a poor estimate. Improving it with 
further sampling will, in most cases, alter the distribution of the easy cases and introduce bias. UnbiasedEstimateMean(X, 
R,p, n], nz, c)  begin Draw a set of p identically distributtxi random samples from R C X.  SPt{xl, 
xz,. ... xp}cli; if Variation < c then n + nl else n+ nz; Draw a set of n identically distributed random 
samples from the rest of X. S.+{ X1, X2,..., }CXCR R Compute [ based on the unbiased estimates of the 
two disjoint components. (-3xlRl+~xlX Rl; return (; end Figure 2: An unbiased adaptive sampling algorithm. 
It is aszumedtbat RC X andnl < na. Figure 3: Absolute Bias as a function of initial sample size n for 
a collection of fractional areas.  5 Results To study the extent of the biasing problem we have com­puted 
the exact bias introduced by the algorighm in Fig­ure 1 for a range of initial sample sizes and a variety 
of tw~intensity pixels. In this case Equation 6 provides the actual bias. Both Figures Fig. 3 and Fig. 
4 show curves for WI ranging from 0.125 to 0.875. For each of these curves, W2 = 1 U1, 11 = O, and 12 
= 1. Note that while the absolute bias is symmetric about zero, the percent bias increases as the actual 
mean decreases. While these figures are informative, it is difficult to see how this really afTects an 
image. Fig. 5a (upper left)  : SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 Figure 4: Percent Bias as 
a function of initial sample size n for a collection of fractional areas. Figure 5: a) Unbiased image, 
b) Unbiased image (hi-res), c) Biased image, d) Biased image (hi-res) shows a black / white edge, and 
a thin white polygon on a black background, at 32x32 resolution. Fig. 5b (upper right) is a hi-res version 
of Fig. 5a. Fig. 5a &#38; b were computed using the expected value of the unbiased algo-rithm from Figure 
2. Fig. 5c &#38; d were computed using the expected value of the biased algorithm described in Figure 
1. Therefore, these images illustrate the tenden- cies of these algorithms, not actual results. Pixels 
in all figures were integrated using a box filter. Note that in Fig. 5c &#38; d, the familiar roping 
in the antialiased edges is worse than in Fig. 5a &#38; b. This is because the small partial coverages 
in each pixel are un- derestimated in the biased approach. Likewise, the large partial coverages are 
overestimated. In this case, the bias accentuates problems with antialiasing of edges. 6 Conclusions 
We have shown that common adaptive anti-al&#38;zing algo- rithms can be statistically biased, and have 
proposed an alternative algorithm that is unbiased. It may not always be worthwhile to remove this source 
of bias. The error is typically small, especially when the initial sample is large. Our alternative sampling 
plan, while unbiased, possesses other drawbacks in terms of additional cost and parameter selection. 
For each ap-plication the cost must be weighed against the benefit of improved accuracy. The analysis 
presented here has identified a subtle deficiency hidden within most anti-abasing approaches which should 
be addressed in future schemes. Acknowledgements Much of this research was performed while the authors 
were employed at Apollo Computer and Hewlett-Packard. The authors also wish to thank the anonymous reviewers 
for their thoughtful and detailed comments. References Arvo, James, and David Kirk, Particle Transport 
PI and Image Synthesis, Computer Graphics, 24(4), August 1990, pp. 63-66. Dippe, Mark A. Z., and Erling 
Henry Wold, An- PI tialiasing through Stochastic Sampling, Computer Graphics, 19(3), July 1985, pp. 
69-78. Freund, John E., and Ronald E. Walpole, Mathemat-ical Statistics, 4th edition, Prentice Hall, 
New Jersey, [31 1987. Glassner, Andrew S., An Overview of Ray Tracing, [41 in An Introduction to Ray 
Tracing, A. S. Glassner, ed., Academic Press, New York, 1989. Kajiya, J. T., The Rendering Equation, 
Computer [51 Graphics, 20(4), August 1986, pp. 143-150. Lee, Mark E., Richard A. Redner, and Samuel P. 
Uselton, Statistically Optimized Sampling for Dis- tributed Ray Tracing, Computer Graphics, 19(3), July 
1985, pp. 61-68. PI Mitchell, Don P., Generating Antialiased Images at PI Low Sampling Densities, Computer 
Graphics, 21(4), July 1987, pp. 65-69. Painter, James, and Kenneth Sloan, Antialiased PI Ray Tracing 
by Adaptive Progressive Refinement, Computer Graphics, 23(3), July 1989, pp. 281-288. Purgathofer, W., 
A Statistical Method for Adaptive Stochastic Sampling, in Proceedings of Eurographics 86, ed. A.A.G. 
Requicha, Elsevier, North-Holland, 1986, pp. 145-152. PI [lo] Rubinstein, R. Y., Simulation and the 
Monte Carlo Method, J. Wiley, New York, 1981. [ll] Whitted, Turner, An Improved Illumination Model for 
Shaded Display, Communications of the ACM, 32(6), June 1980, pp. 343-349.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122736</article_id>
		<sort_key>157</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Spectrally optimal sampling for distribution ray tracing]]></title>
		<page_from>157</page_from>
		<page_to>164</page_to>
		<doi_number>10.1145/122718.122736</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122736</url>
		<abstract>
			<par><![CDATA[Nonuniform sampling of images is a useful technique in computer graphics, because a properly designed pattern of samples can make aliasing take the form of high-frequency random noise. In this paper, the technique of nonuniform sampling is extended from two dimensions to include the extra parameter dimensions of distribution ray tracing. A condition for optimality is suggested, and algorithms for approximating optimal sampling are developed. The technique is demonstrated at low sampling densities, so the characteristics of aliasing noise are clearly visible. At supersampling rates, this technique should move noise into frequencies above the passband of the pixel-reconstruction filter.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[antialiasing]]></kw>
			<kw><![CDATA[distribution Ray tracing]]></kw>
			<kw><![CDATA[noise perception]]></kw>
			<kw><![CDATA[nonuniform sampling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.1</cat_node>
				<descriptor>Sampling</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Antialiasing**</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010386</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Antialiasing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP14128889</person_id>
				<author_profile_id><![CDATA[81100360165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Don]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Mitchell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Bell Laboratories, Murray Hitt, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bouatouch, K., Bouvflle, C., Tellier, P. Low sampiing densities using a psychovisual approach. Eurographics '91, to appear.]]></ref_text>
				<ref_id>Bouatouch91</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L., Porter, T., Carpenter, L. Distributed ray tracing. Computer Graphics, 18, 3 (July 1984), 137-145.]]></ref_text>
				<ref_id>Cook84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, R. L. Stochastic sampling in computer graphics. ACM Trans. Graphics, 5, 1 (January 1986), 51-72.]]></ref_text>
				<ref_id>Cook86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dipl~, M. A. Z. and Wold, E. H. Antialiasing through stochastic sampling. Computer Graphics, 19, 3 (July 1985), 69-78.]]></ref_text>
				<ref_id>Dipp&#233;85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97895</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Heckbert, P. S. Adaptive radiosity textures for bidirectional ray tracing. Computer Graphics. 24, 4 (August 1990), 145-154.]]></ref_text>
				<ref_id>Heckbert90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajiya, J. T. The rendering equation. Computer Graphics, 20, 4 (July 1986), 143-150.]]></ref_text>
				<ref_id>Kajiya86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lee, M., Redner, R. A., Uselton, S.P. Statistically optimized sampling for distributed ray tracing. Computer Graphics, 19, 3 (July 1985), 61-67.]]></ref_text>
				<ref_id>Lee85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Marvasti, F. A. A Unified Approach to Zero- Crossings and Nonuniform Sampling, Nonuniform Press (1987).]]></ref_text>
				<ref_id>Marvasti87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37410</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mitchell, D. P. Generating antialiased images at low sampling densities. Computer Graphics, 21, 4 (July 1987), 65-72.]]></ref_text>
				<ref_id>Mitchell87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74362</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Painter, J., and Sloan, K. Antialiased ray tracing by adaptive progressive refinement. Computer Graphics, 23, 3 (July 1989), 281-288.]]></ref_text>
				<ref_id>Painter89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ripley, B. D. Modeling spatial patterns. J. Roy. Statist. Soc. B, 39, (1977), 172-212.]]></ref_text>
				<ref_id>Ripley77</ref_id>
			</ref>
			<ref>
				<ref_obj_id>124947</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Shirley, P. Physically based lighting calculations for computer graphics. PhD Thesis, University of minois, (1990).]]></ref_text>
				<ref_id>Shirley90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Whitted, T. An improved illumination model for shaded display. Comm. ACM, 23, 6 (June 1980), 343-349.]]></ref_text>
				<ref_id>Whitted80</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[YeIlott, J. L Jr. Spectral consequences of photoreceptor sampling in the rhesus retina. Science, 221, (1983), 382-385.]]></ref_text>
				<ref_id>Yellott83</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Spectrally Optimal Sampling for Distribution Ray Tracing Don P. Mitchell AT&#38;T Bell Laboratories 
Murray Hitt, NJ 07974  Abstract Nonuniform sarnpting of images is a useful technique in computer graphics, 
because a properly designed pattern of samples can make alisaing take the form of high-frequency random 
noise. In this paper, the technique of nonuniform sampling is extended from two dimensions to include 
the ex~a parameter dimensions of distribu­tion ray tracing. A condition for optirnslity is suggested, 
and algo­rithms for approximating optimal sampling are developed. The technique is demonstrated at low 
sampling densities, so the charac­teristics of aliasing noise are clearly visible. At superaarnpling 
rates, this technique should move noise into frequencim above the paasband of the pixel-reconstruction 
filter. CR Categories and Subject Descriptions: 1.3.3 [ Computer Graphics ]: Picmre/Irnage Generation 
1.3.7 [ Computer Graphics ]: Three-Dimensinrtal Graphics and Realism General Terms: Algorithms Additional 
Keywords and Phrases: Antialiasing, Distribution Ray Tracing, Nonrmifomr Sampling, Noise Perception 1. 
Introduction In 1979, Whitted demonstrated that ray tracing could be used to simulate a number of realistic 
shading effects [Whitted80], Unfor­tunately, ray tracing has a special ditllcuky with aJiaaing, a problem 
sometimes encountered when sampling signals. To focus on this issue, Whitted s sdgorithm can be cast 
into the form of a two­dimensional sampling problem. At each point (x ,y) on the image plane, a bnghmess 
sample is defiied by calculating the radiance of a ray from the viewpoint through that point. Assuming 
the irnage­phme coordinates range between zero and one, the image brighmess is detlmed by the mapping: 
~: [0,1]2 + radiance (1) Any synthetic image might be deacnbed as (1), but the details of ray tracing 
have special implications: the vrdues of f can only be evaluated at a @nt, and it is virtually impossible 
to symbolically intergrate or low-pass filter the function. In other words, the signat can be sampled 
but generally cannot be prefiitered to avoid aliaaing. An interesting approach to this problem is nonuniform 
sampling which an yield aliaaing in the form of high-frequency random noise [Dipp485, Cook86, Mitchel187]. 
Permission to copy wi[hout fee alI or pm nf this material is granted provided thatthecopiesarenotmadeor 
distributedfor direct commercialadvwr!age. the ACM copyright notice irnd the title of the puhlicatitm 
md itsdateappear,andnotice ii given that cnpyirrg is by permission of Ihe Association f,w Computing Machinery. 
Tn copy otherwise, or 10 republish. requlrc~ a fcc and/or specific permission. An elegant extension of 
Whitted s algorithm is distribution ray tracing (previously distributed ray tracing ), introduced by 
Cook, Porter and Carpenter [Cook84]. Their algorithm simulat~ motion blur, shadow penumbras from ftite-area 
light sources, depth-of­field effects, and glossy reflections from partially polished surfaces. This 
is achieved by sarnptittg in an additional set of parameter dimensions. For example, an object in motion 
will have a position in the scene parametrized by the time t, and motion blurred pixels can be calculated 
by averaging over many different samples of r. Depth-of-field effects are associated with a finite aperture 
on the camera sod are simulated by &#38;flecting rays through different points on the lens, parametrized 
by two more variables a ,b. Glcmy reflection results from varying the direction of a surface normal, 
as if the surface were made up of randomly distributed microscopic facets parametenzed by an orientation 
e,$. WitA these extra parameters, distribution ray tracing defines a multidimensional brighmess function 
f (x, y; r, u, . ). A sample of this function is evaluated by ~rforming a Whitted-style ray tracing operation. 
However, first moving objects would be transformed to their hxation at time r, a point light source is 
defined by (u,v) representing a sample of the area light, the primary ray from the camera is deflected 
through a final point from a position (a,b) on the lens, ete. Grtee the scene is prepared for a given 
set of parametervalues, a ray-tracing cakutation can be done. Assuming -x,Y, ~d D -2 parameters range 
from zero to one, we have the brighmess mapping: f : [O,l]D + radiance (2) The two-dimensional image 
is an integrationover the parameters 11 ~(x,Y) = JJ j~ (x, y;r, u, . )dtdu. (3) 00 0 Addhionstl integration 
or convolution (with a filter) may be done in .x and y to define a bandlimited image function i(.r, y 
) suitable for atias-free digitization. The integration in (3) cannot be evahsated analytically, but 
the process of distribution ray &#38;acing estimates f(-x,Y) by averagingmanysamplesper pixel. This prmxss 
can be viewed as a Monte Carlo integration, or as a classical statistical sampling probiem of estimating 
the mesrrrvalue off in a region of the image plane, or it can be viewed as a sampling problem in the 
signal processing sense. These viewpoints are not independent, and all of them can &#38; found with varying 
degrees of emphasis in discussions of distribution ray tracing [Cook84, 1...ee85,Cook86, Kajiya86, Shirley90]. 
The question investigated in this paper is how to extend the tedrniques of normnifomr sampling, used 
in Wldtted-style ray fraeing, to the multiple dimensions of distribution ray tracing. This is not simply 
the problem of generating a Dimensional image from samples of ~ , which might be a obvious extension 
of the twodtmensional methods. We are still interested in the characteristics of noise in a two-dimensionat 
image, and we expect AcM-(1-89791-436-8191$00.75  /ot)70157 157  SIGGRAPH 91 Las Vegas, 28 Juiy-2 August 
1991 the parameter dimensions r, u, v, ., 0 to play a qualitatively different role than the image coordinates 
x, y. 2. fncompleta Block Sampling Designs An important problem in distribution ray tracing k how to 
choose samples effectively to produce the highest qur@ image with the fewest rays. We might simpl choose 
samples randomly with a uni- X form disbibution in [0,1] . In sequential sampling, random samples are 
made until we are statistically cotildent that the average value has a low variance px%5, Kajiya86]. 
This procedure is usually improved by stratified sampling, where the intem al [0, 1] is divided into 
N levels, dropping a random sample into each subirrtenal. This spreads the samples out more evenly and 
often results in a lower variance of the average. In the twodimensiorral antisliaaing problem of whined-style 
ray tracing, each pixel area [0,1]2 can be divided into N x N subsquares for stratitkd sampling, This 
is more or less the same as jittered sampling, a common approach to the antialiiing problem ~ippt%5, 
Cook86, Kajiya86, I%mter89]. However, this is not a practical approach to srunpliig the parameter space 
of distribution ray tracing because of the high number of dimensions. Stratifkation of all D dimensions 
wordd result in ND blocks to be sampled. This could easily be tens of thousands of samplw per pixel, 
many more than would be reasonable or necessary. In practice, stratilcation has been applied to distribution 
ray tracing, but with incomplete block sampling designs that donot tldly populate the ND blocks. Cook 
created incomplete bbxk deaigrts by subdividing the pixel area into an N x N mesh of subsquares. he time 
dirmmsion was divided into N2 levels, and pairs of area-like parameters like (u,v) and (a ,b) were subdividing 
into N x N m=hes. N2 samples are then made which projected onto each subsquarc of the pixel once, each 
level of time once, each subsquare of the (u ,v) dimension once, etc. Thus only N2 of the possible ND 
blocks are occupied by a sample. Little has been said about how these associations betweem blocks should 
be chosen, but it is clear that linear correlation between parameter values should be avoided [Cook86]. 
Linear correlation would mean a tendemcy for samples to fall on hyperplanes in [0,1] D which could cause 
aliasing. The visual consequences of parameter correlation are objectionable and conspicuous. Shirley 
describes another incomplete block design called N-rook sampling, where N out of ND blocks are populated 
[Shirley90]. Let rrI, nz,..rtD.l b~u~tiomoftiesqwne(o,l, . . . ,N -1). Then we choose one asmple in each 
aubmterval of each parameter dimension. The nh sample is placed in level n of the x dimension, in level 
n I(n) of they dimemsiott,level nz(n) of the r dimension, etc. Once again, little is known about what 
are good or bad choices for the permutations, except to avoid linear correlation. An example in two dimensions 
is shown below: Figure 1. An 8-Rook Sampling Design in Two Dmensiorts There seems to remain an important 
piece of mrfiished business. We do not really know very much about what constitutes a good sampling design 
versus a bad one. Avoiding linear correlation is known to be important. Explicit in the two incomplete 
blcck designs described above is the property that the sampling pattern is good when projected onto certain 
lower-dimensional planes or axes. For example, the N-rook patterns are futly ~putated strstitkd designs 
when projected onto arty coordinate axis. Linear correlation could be avoided by randomly choosing sampling 
designs of either Cook s style or Shirley s. Mc$eover, sequential sampling (i.e., sampling until statistical 
cordMettce is achieved) is probably capable of giving satisfactory image quality [LeeS51, whether the 
sarnpliig design is good or not. The danger is that many more samplea might be computed than are necessary. 
3. Nonuniform Sampling in Two Dmensions Before tackling the problem of sampling in D dimensions, it will 
be usefrd to review the two-dimensional problem of sampling in the (x,y) dimensions. This is the problem 
in whined-style ray txacing. Typically, the image is supersarnpled at a high rate (by casting rays), 
and then filtered and resampled to a lower rate to produce the pixels of a digittd image. The filter 
may be an average over the pixel area, or it may be a more sophisticated low-pass filter. The process 
of sampling is represented mathematically by multiplication of the image signal with delta-function pulses, 
as diagramed below 1~~ I supersample pixel-rate pulses pulses Figure 2. Convemion of Ray-Casting Samples 
into Pixels The reconstruction filter interpolates samples to recreate a continu­ous image. The low-pass 
filter makes sure that image is bandlim­ited so sliasing witl not resutt when it is reaampled at the 
pixel rate. These two falters are uaditiomdly combined into one, but when supersarnphng is nonuniform, 
it is often the case that reconstruction and low-pass filtering are dktinctly separate stages [Mitchel187, 
Painter89]. If the supersamplmg pattern is nonuniform, and its spectrum has certain characteristics, 
the sampling error (or alksing) will take the form of random noise at high frequencies. llda is desirable 
for two reasons. If noise is concett@ated in the high frequencies, more of it will be attenuated by the 
low-pass filter pictured in Figure 2. Secondly, randomness and high frequency both help to make the noise 
less perceptible to a human observer. This can be understood by looking at the sampling process in the 
frequestcy domain. Let ~(x,y) represent the continuous image, S(X,y) represents the sarrtplig pattern 
(delta functions), and let r(x ,y) be the combined reconstruction/low-pass fflter. F, S, and R will represent 
the corresponding spectsa. In the spatiat domain, the sampling and filtering process is expressed by 
i(x,y) = r(x,y)*[f(x,y) .S(x,y)] (4) And in the frequency domain: I(roX,toY) = R(@,,rDY)-[~(rO., WY) 
*Mroz.@Y)l (5) where. and * represent multiplication and convolution respectively. The reconstruction 
fdtcr is described above as a linear low-pass filter, which is ideal for uniform samples but cart give 
a distotted reconstmction of nonuniform samples. Nonuniform reconstruction for images is not perfectly 
understc@ but in practice, ttordinear or space-wuying falters (which are not representable by a convolution) 
give better results ~ipp&#38;S5, Mitchel187, Marvasti87]. The result is still some type of low-pass filter 
(i.e., a smooth surface interpolat­ing the sample spikes). When the reconstmcth and low-pass stages (in 
F@re 2) are implemented separately, the low-pass stage could be a linear filter rainter89]. If the superaampling 
rate is much higher than the pixel rate, the linear low-pass stage should dominate the behavior of the 
system. We will model the recottatntc­tion as a linear low-pass filter for the purposes of qualitative 
analysis. The spectrum of the sampling psttem S will be a delta-function spike at the origin (the DC 
compent) and some pattern of noise aurrormding it. The convolution F* S (shown in F@ure 3) of a image 
spectrum with the nommiform-aarnpling spectrum gives a copy of the true image spectrum (the symmetric 
shape at the center of the figure) and a halo of noise energy (represented by the scat­tered dots). The 
low-pass fiiter R (represented by the dotted box) attenuates energy outaide its bounds. @Y t - (irX 
Figure 3. Spectrum of Nonuniformly Sampled Image tf the spectrum of the sampling pattern has energy concentrated 
in high frequencies, then the halo of noise will be pushed farther out from the origin, and more of it 
will be outside of the paas band of the filter. The best krtown patterns having this high-frequency characteristic 
are the Poisson-Disk stochastic point processes. These patterns are random, but include a constraint 
that no two points can be closer than some miniitrm distance (as if each point was surrounded by a hard 
disk) [Ripley77], The spectral consequences of this sampling pattern were first investigated by Yellott, 
who found this arrangement in the photoreceptors of monkey retinas [Yellott83]. More commonly used are 
patterns based on jirter processes. These are formed by randomly perturbing the points in a perimiic 
uniform lattice. Jitter samptirrg contains more Iow-tlequency energy m its spectrum than Poiasondisk 
patterns, and images produced with it have a more grainy appearance at low sampling rates ~tchel187]. 
However, jitter sampling is easy to generate, and straightforward adaptive-sampling schemes exist for 
generating jitter samples at variable density [Dipp6t35,Ccak86, Kajiya86, Pairtter89]. Smne of these 
methods could atso be described as stratified sampling. 4. Sequential Poisson-D~k Sampting Poissondiak 
samples are typicatly generated by a dart-throwing atgorithm which is computationally expensive and which 
makes it diff cult to control the ful density of samples (one initially choaes the hard-disk diameter, 
not the desired sample density) ~ipp685, Mitchel187]. With the following new algorithm, it is possible 
to generate good high-frequency sampling patterns with sequentially increasing dett­sity. Begin by choosing 
the fwt sample at random in a region. To add the (n + 1)* sample, generate mn uniformly distributed ran­dom 
candidate points (where m is a constant parameter). For each of these random points, compute the distance 
to the closest of the n Computer Graphics, Volume 25, Number 4, July 1991 points already in the pattern. 
Tlten chose the candidate poim with the largest closest-point distance, and add it to the pattern. By 
scal­ ing up the number of random candidate pointa, m proportion to n, we maintain a constant ratio m 
of cattdidateato patternpoints in the process. llms we expect the statistics of the pattern (the autocorre­ 
lation, etc) to alao scale and resnairr similar as the sample density increases. The high-frequency quality 
of the pattesn increased with m. This is art O(n 2) algorithm, but it is an improvement over the poorly 
defined temtination of the dart-throwing algorithm (which runs until it cannot add new santplea). The 
spx.d was improved dramatically by using grid methods for the nearest-neighbor cakula­tion. This point 
process is not strictly harckdbk, because it is possi­ble (although unlikely) for samples to lie very 
close together. How­ever, the resulting patternsare excellent if m is not too small. TYte following figure 
shows some snapshots from this process, using m=10 .* * I.-**.*-*. .. **..*:* . , .** .. . .*** . ... 
..*1 . . .**.. .* * .. . .*.**** * . .. o . *.**** .. . ..*.* . * 1-lI-JU Figure 4. Sequential Generation 
of High-Frequency Samples It is sometimes useful to perform this algorithm with wrap-around boundary 
conditions, so the psttern can be replicated periodicatty over the plane (with much longer pericd than 
the pixel rate, of course). The algorithm can be extended to higher dimensions, and it could also be 
used to generate isotropic high-frequency sampting patterna on ttre surface of a sphere. That may be 
useful because area light sources and gtoasy reflections require sampling solid angles. The alternative 
of stratitkd sampling of latitu&#38; and longitude is not isotropic because strata near the pde are very 
different in ahape than equatorial strata. The concept of choosing the best samplea from random candklates 
will be used again in the algorithms applied to distribution ray tracing, By hard disk we usuatly mean 
a circutar region of avoidance around each sample. By using an ellipse or other shape, the s~m of ttM 
pattern can be made anisolropic in some fashion. The human visual sensitivity extenda higher into vertical 
and horizontal frequencies ttrarrit doea into diagonal frequencies, so a Poissorrdiamond pattern might 
be better than Poisson-disk. Bcutouch et af support this idea in Ureirexpximents with uniform qrdrrcrmx 
sampling [Bouatoucb91]. This is an issue that could be studied further. S. Motion Blur and Spatiotemporal 
Sampling If two-dimensional sampling can push noise into high frequencies, can the same effect be obtained 
while sampling the extra parameters of dkaribution ray tracing? Let us be@rt by considering motion blur 
effects, where a single extra parameterr is added. tltis is not an obvious three-dirrremsional genesaIixationof 
the problem of the pre­vious swtion. ~ (x,y; t) is sampled in three dimensions,but we are stitl concerned 
with the resulting sampling noise in the two­ dinrensiorralimage i(x,y). To derive the spectrum of i(x,y), 
let ~,(x,y,r) = ~ (x,y; r) .s(x,y,t) be the sampled mrdtiparameter image function, whese s(x,y,r) is 
a distribution of delta furrtiorts in spac@ittte. The sampled image function is low-pass filtered spatially 
with r(x, y), and integrated over an exposure-time itrtervat for motion blur I i(x,y) = r(x,y)* ~f. (x,Y, 
r) dt (6) o I59  SIGGRAPH 91 Las Vegas, 28 JuIY-2 August 1991 The spectrum is a littfe easier to derive 
if we replace the integration over a time itttetvat with the equivalent operations of convolution with 
a box function in r followed by sampling one slice through t. Then using the Convolution Theorem, we 
fmd the spectxum of i(x,y) to bet . I(fJx,rDy) = R(cox,@Y) ~ Sinc(w,/2x)F.(@x. mY,@,)d@, (7) - The important 
difference between the expression for the static­itnage spectrum (5) and the spectrum of the motion-blurred 
image (7) is the integration over 0,, This means tbe three-difnertaiorutI spectrum (at least, the portion 
passed by the R and Nnc filters) will be projectedonto the spatiaf (fox ,roY) ptane, Ideally, we woutd 
tike the noisy part of this spectrum to be pushed out of a cylirtdricat region around the ro, axis, so 
its projection wiU contain onty the highest possible spatial noise frequencies. Figure 5. Cylinders of 
Medium and Low Spatial Frequencies Ttds suggests that the best general santpfing pattern will be one 
with little power in the low-spatial-frequency region around the O, axis. Figure 5 depicts the spectrum 
of the sampling pattern with cylirrdri­cal regions around the rot axis enclosing spatial frequencies 
below some brmdtimit. The wide cytinder on the left contains frequencies up to some medium vafue, and 
the cytinder on the right represents a lower bandlimit. We would like these cylinders to be as vacant 
of power as possible. In fact, the practicat requirement is to have the power within each cylinder be 
concentrated at the ftigheat possible frequencies. It is fdso important to give the highest priority 
to removing the lowest spatial frequencies, so we require the power in the right-hand cylinder to be 
concentrated at higher temporal fre­quencies than in the left-hand cylinder. t / Y Figure 6. Margittaf 
Distributions of %rnples in Space and Time These conditions in the frequency domain imply some conditions 
on the arrangement of samplea in space and time. l he two grapha in F@ure 6 illustrate situations corresponding 
to the spectra in F@re 5. They show the projection of samples onto the spatiaf plane (dots) and onto 
the time axis (tick marks). We are not yet certain where t flrisactuatlycorrespondstotheintegraticmoftimefrom-X 
to%. A phase-shiftfwtorcoutdbeaddedtoreflectintegrationfrmrOto 1. sine(x) = sin(rrx)lrrx. Utese samples 
shoutd be in spacdtinte, but we will be able to give conditiom on their projections into apace and time. 
If there is no movement in a region of the image, then onty the apa­tiat projection of the pattern is 
importan~ so we could begin by con­straining it to form an optimal distribution, like Poissorxlisk. We 
are interested in the power contained within cylinders of spatial tkequextcies,in Figure 5, and in the 
temporal-frequency distribution of that power. Imagine that we have convolved the spectnutt with a cylinder 
and sampled the reardt on the 0)1axis (this is equivafenf to averaging ova apatiaf frequencies inside 
the cylinders). llmt opera­tion cormponds approximately to selecting the samples within a cylindrical 
region of space, and considering their dme distribution. The ttarmwer cylinder of frequerwies in Figure 
5 corresponds to a wider region of space in F@rre 6. The temporal distribution of samples, shown in FQure 
6, represent one-dimensional patterns of the highest possible ihquertcy (such as Poisson-rod distributions). 
Therefore, the desired propmty of space/time sampling patterns is that in any cylindrical region of space, 
the dhibution of samples in dme witt be a high-frequency pattern. Aft interesting consequence of this 
is that samples which are adjacent in space ahotdd differ greatty in time or other parameter coordinates. 
This is quite dif­ferent from the most obvious tbreedirnensional anatog of Poiason­disk sampling. A Poisson-sphere 
point distribution woufd not necessarily have this property of high-frequency time distribution.  6. 
A Scanning Sample-Generation Atgorithm A simple scanning algorithm is one possible way to generate satn­ 
pliig patterns which approximate the conditions described in the previous section. Begin by stratifying 
the x and y dimensions into a mesh of subsqrrares, assuming that one jittered sample is contained in 
each. The goal is to assign each sample a vatue of the parameter t. This is done in scatming order, from 
left to right, and top to bot­tom. Sssss SPPPS sP -EEEl F@ue 7. Neighborhood of the Next Unprocessed 
Subsquare Figure 7 itluatrates the situation at some point in the scanning pro­cess. We wish to choose 
a parameter vatue for the subsquare con­taining the dot. In the 5 x 5 region surrounding the dot, some 
subsquara above and behind (indicated by P or S ) have already been assigned t values. Catl these the 
P-cetfs and S-cells (meaning primary and =ortdary). We woutd like the newt vatue to tit into a high-frequency 
Poisson­rod distribution, as shown in F@rtre 6. In a manner reminiscent of the sequential Poissottdisk 
atgorithm of section 4, we generate a set of primary candidate t vaturM with uniform random distribution 
in [0, 1], For example, let us say we generate 100 primary candidates. The candidate are sorted by their 
maximum cloaeat distance to the t vrdues of the P-cells. Distance is dtimed with wrap-around borrn­dary 
cotrditions, so the pattern can used periodicatty from frame to frame.. From the sorted list, we might 
pick (for example) the 10 with largest max-mitr distance. Any one of these 10 values shoufd be a good 
choice to complete a coarse Poisson-rod diatibrttion as suggested on the left of Figure 6. The set of 
10 vafrres selected above are now considered as secondary candidates. For each secondary candidate, compute 
the maximum closest distance to the r values of the S-cells, and pick the one with the largest msx-min 
distance. This should be a good choice to com­plete the denser distribution as suggested on the right 
of Figure 6. We are trying to meet two constraints, picking 100 primary candi­dates and evaluating how 
weff they match the situation on the left of Figure 6, then selecting 10 secondary candidates to match 
the condi­tions on the right. 7. Experiments with Scan-Generated Sampling Patterns F@ues 8 and 9 demonstratethe 
use of ttds sampling patternon a ray-tracedscene containing spinning wheels. F@re 8 was made by choosing 
t vatues with a uniform random distribution. Figure 9 uses the spectrally optimized r values generated 
by the scanning algo­rithm. In fact, a 32 x 32 pattern of samples was generated and repli­cated periodically 
on the plane. Both image were generated with just one sample per pixel so the sampling noise cart be 
seen clearly. Essentially, we are looking at the raw superaamples~., which would be passed into the filter 
stages of F@ure 2 in order to make an antialiaaed digital image. Figures 10a and 10b ahow the correapondlng 
noise spectra (with lighter shades indicating higher power). These were obtained by subtracting F@rres 
8 and 9 from a reference image (generated with 100 rays per pixel), to create an error image. The discrete 
Fourier transform of the error images show a typical white noise spectrum in Figure 10a, corresponding 
to the random sampling. However, Figure 10b shows a considerable concentration of power in the higher 
frequencies. Even though the mean square error of F@res 8 and 9 are about the same, the frequency distribution 
of power has a large impact on subjective appearance. A series of rarsdornty-sampled images like Figure 
8 were generated using from 1 to 9 samples per pixel, and seversf expert observers were asked to select 
the best comparison with Figure 9. F@sre 9 was obviously better looking that 1 sample per pixel and obviously 
worse than 9. The consensus was that three or four random time samples psr pixel were required to match 
the subjective quality of Figure 9. Figures 11 and 12 show a similar comparison of the tedutique applied 
to depth-of-field effects. F@rsre 11 was generated with uniformly random vahsea of (a, b ), the parameters 
controlling the deflection of primary rays through the camera aperture. F@sre 12 used parameter values 
generated by the scanning algorithm. The only difference from scanning generation of t values is the 
use of a twodlmensional Euclidean distance for the max-mio distance selections. Once again, both figures 
were generated with one ray per pixel. Figure 11 shows the clumpy pattern of sampling error characteristic 
of white noise, and Figure 12 shows the timer structure of high-frequency .oise. A cnticrd observer may 
notice, from the point-spread, that the simulated camera has a square lens. There is no special problem 
in simulating a round lens, which should have been done if this were not a simple experimental ray tracer. 
Figures 13 and 14 demonstrate another two-parameter experiment, using parameter values to perturb the 
normal vector of a surface and simulate glossy reflection. F@e 13 uses random perturbations and Figure 
14 uses scan-generated parameters. These images provide evidence that the condition for optimal parameter 
sampling is correct. The acruming sample-generation iilgori thm should not be thought of as a defrrtitive 
way to generate optimal samples, however. It is an ad hoc way to genexate a pattern with approximates 
the conditions defined in section 5, but only in a s x s region, and probably not with perfect isotropy. 
There is a great deal of opportunity for experiment and improvement. 8. N-Parameter Sampfing Suppose 
an image of the spinning-wheels picture (seen in Figures 8 and 9) is generated with motion blur and afso 
an area light source, creating shadows with penumbras. Using assoptimized pattern of r parameters ensures 
that the spinning spokes of the wheels are wefl sampfed as in Figure 9. Using an optimized pattemrof 
(u, v) param­eters erwres that the penumbra around the rim of the wheels has good high-frequency sampling 
noise. However, in regions where both distribution ray-tracing effects are combined-in a moving penumbra-the 
sampling noise baa a coarser white-noise appear­ance. Figure 15. t3-RookSampling Patterns It is not stilcient 
to optimize the t and (u ,v) distributions of sam­ples alone. fhe joint distribution of (r,u ,v) matters. 
Figure 15 demonstrates this concept. Here, two patterns btb have the same projected ( marginal ) distributions 
in u and v (in this case, uniform periodic). However, the overall joint distributions of the two pat­terns 
we very different. Suppose a signal was sampled with the pat­tern on the right. If the sigrud contains 
only variations in Useu or onty in the v dnensions, it may be sampled well enough. But if the image contains 
variation along the dmgonal perpendicular to the row of samples, severe afiaaing might occur. In distribution 
ray tracing, a similar situation can occur, and aliasing caused by paor joint dk­tribution of the parameter 
samples can be projetted onto the image. It is also not sufficient to just optimize the joint dktribution 
of (t,u,v) withcut considering the marginal distributions of r and (u,v). The scanning algorithm was 
used to generate samples in (r,u,v) with Poisson-sphere joint diatibutions, and this resulted in relatively 
poor image quatity. The region of moving penumbra was much improved, however. The beat image quatity 
in the moving-penumbra teat was achieved by generadng sampling patterns in which both the joint distribution 
and the marginal distributions are spectrality optimized. F@ure 16 shows the spinning wheels image, using 
a sampfing pattern which combws a joiit diminution of (r ,U,v) which is Poisson-sphere, and a margitraf 
distribution of r which is Poisson-rod. This suggests that as the parameter space becomes higher in dimension, 
sampliig patterns must be found which meet the conditions of Figure 6 in a combination of marginal and 
joint distributions. This combination of conditions was met by extending the scanning algorithm to select 
a series of primary, secondary, and terdary candidate. 9. Adaptive Sampling No matter how optimal a supersamplkrg 
pattern may be, we camot ignore the computational eftlciency of adaptive sampling. It is often the case 
(except in the most complex scenes) that many portions of artimage cats be sampled at relatively low 
density. A simple sohr­tion might be to use a few discrete levels of sampling density. The two-level 
sampling rdgorithm described by the author in [Mitchel187] was very easily adapted to use a fivedimensional 
(x,y,r,u,v) periodic pattern of 1024 samples. In that scheme, an image is sampled at a low base rate. 
h is a good idea to make this base rate selectable by the user, and typically one or a few samples per 
pixel area are sufficient. The results of the .  SIGGRAPH 91 Las Vegas, 28 JuIY-2 Auwst 1991 E!E slG6mAfHll 
­ base-rate sampling are then used to estimate local bandwidth and identify regions that require sampling 
at a higher rate. Variable sampling rates can be achieved by simply scaling the stored pattero. If the 
pattern is optimal in the sense discussed above, it will only be necessary to scale the pattern in x, 
y. Aa the sampling rate per pixel area increases, the rate per parameter dimension should also increase 
and the distribution should remain spectrally optimal, as indicated in Figure 6. 10. Conclusions Gptirnalnonuniform 
sampling is a familiar approach to the aliasirrg problem in Wtdtted s ray-tracing algorithm. I?&#38; 
paper takes a fwt step ia extending this technique to the muhidirnensiomd atgorithnr of distribution 
ray traciog. This is nontrivial for two reasons. Fret, a simpte extension of the stratitM/jitter sarnpting 
techniques to higher dimensions requires a number of samples exponential in the dimension. Secondly, 
this is not simply the problem of generating a D-dimensional image, which would be an obvious extension 
of the twodlmensiorud theory. ArI analysis of the sampling problem in distribution ray @acingsug­gests 
a critesia for sampling patterns that can force aliasing noise into higher frequencies. Samples contained 
in any circular region in space (on the x,y image plane) should have parameter values which form a pattern 
of the highest possible frequency. It appears that in addition to requiriog the overall joint distribution 
of parameter vatues to be high-frequency (e.g., a Poisson-hypcrsphere distribu­tion), it is important 
to insure that certain marginal disnibutions are of the highest frequency (e.g., time values beiig Poisson-rod, 
(u ,v) parameters being Poisson-dhk etc.). This problem could be studied further. A scanning sample-generation 
algorithm is proposed, which givea sampling patterns which locally approximate the opdrnal. This was 
good enough to demonstrate the correcmeas of the optimrdity condi­tion iII a numtw.r of teat images. 
Further work could be done on better sample-generation rdgorithrna, perhaps using exhaustive Monte Carlo 
search. Much more diffbdt sampling problesns arise in the current mmst advamxd rendering algorithms. 
These probIetns are made explicit in several recent works [Kajiya86, Heckbert90, Shirley!)O].  11. Acknowledgements 
I would like to thank John Arnanatidea,Pat Hanmban, Pad Heck­ bert, Peter Shirley, and the SIGGRAPH reviewera 
for their helpfut comments on this work and discussions of sampling issues. 12. References [Bouatouch91] 
Bouatouch, K., Bouville, C., Teltkn, P. Low aam­plirtg densities using a psychovisual approach. Bawgraphics 
91, to appem. [Cook84] Cook, R. L., Porter, T., Carpenter, L. Distributed ray tracing. Compurer Graphics, 
18, 3 (July 1984), 137-145. [Cook86] Cook, R. L. Stochastic aarnptiig in computer gmphics. ACM Trans. 
Graphics, 5, 1 (January 1986), 51-72. ~Ipp.585] Dip@, M. A. Z. and Weld, E. H. Antialiasirrg through 
stochastic sampling. CornpurerGraphics, 19,3 (holy 1985), 69-78. @eckbert90] Heckbert, P. S, Adaptive 
radiosity texture for bidirectional ray tracing. Computer Graphics. 24, 4 (August 1990), 145-154. ~ajiya86] 
Kajiya, J. T. The rendering equation. Computer Graphics, 20,4 (July 1986), 143-150. [Lee85] Lee, M., 
Redner, R. A., Uselton, S. P. Statistically [Marvasti87] ~tchel187] plinter89] ~ipley77] [Shirley90] 
~tted80] [Yeltott83] optimized sampling for distributed ray traciug. CornPurer Graphics, 19,3 (July 
1985), 61-67. Marvasti, F. A. A Unified Approach to Zero- Crossings and Nonuniform Sampling, Nonuniform 
R(23S(1987). Mitchell, D. P. Generating sntialh.sed images at low sampling densities. Computer Graphics, 
21,4 (holy 1987), 65-72. Painter, J., and Sloan, K. AntiaMsed ray tracing by adaptive progressive refinement. 
Compurer Graphics, 23,3 (July 1989), 281-288. Ripley, B. D. Modeling spatial patterns. J. Roy. s&#38;rrist..$oc.lt, 
39, (1977), 172-212. Shirley, P. Physically based lighting calculations for computer graphics. PhD Thesis, 
University of Illinois, (1990). Whitted, T. An improved illumination model for Shrld~ disphly, Conun. 
ACM, 23, 6 (June 1980), 343-349. Yetlott, J. I. Jr. !lpectxal consequences of ph@ore­ceptor samp~mg 
in the rhesus retina. Science, 221, (1983), 382-385.  : SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122737</article_id>
		<sort_key>165</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[A progressive multi-pass method for global illumination]]></title>
		<page_from>165</page_from>
		<page_to>174</page_to>
		<doi_number>10.1145/122718.122737</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122737</url>
		<abstract>
			<par><![CDATA[A new progressive global illumination method is presented which produces approximate images quickly, and then continues to systematically produce more accurate images. The method combines the existing methods of progressive refinement radiosity, Monte Carlo path tracing and light ray tracing. The method does not place any limitation on surface properties such as ideal Lambertian or mirror-like. To increase efficiency and accuracy, the new concepts of light source reclassification, caustics reconstruction, Monte Carlo path tracing with a radiosity preprocess and an interruptible radiosity solution are introduced. The method presents the user with most useful information about the scene as early as possible by reorganizing the method into a radiosity pass, a high frequency refinement pass and a low frequency refinement pass. The implementation of the method is demonstrated, and sample images are presented.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Monte Carlo]]></kw>
			<kw><![CDATA[Ray Tracing]]></kw>
			<kw><![CDATA[caustics]]></kw>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[progressive refinement]]></kw>
			<kw><![CDATA[radiosity]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14048866</person_id>
				<author_profile_id><![CDATA[81451598765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shenchang]]></first_name>
				<middle_name><![CDATA[Eric]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P111526</person_id>
				<author_profile_id><![CDATA[81100255828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Holly]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Rushmeier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The George Woodruff School of Mechanical Engineering, Georgia Institute of Technology and Advanced Technology Group, Apple Computer Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39080514</person_id>
				<author_profile_id><![CDATA[81332515728]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gavin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14089571</person_id>
				<author_profile_id><![CDATA[81540156656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Douglass]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technology Group, Apple Computer Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Larry Bergman, Henry Fuchs, Eric Grant, Susan Spach, "Image Rendering by Adaptive Refinement," Computer Graphics (SIGGRAPH '86 Proceedings), V 20, N 4, Aug. 1986, 29-38.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Michael Cohen, Shenchang Eric Chela, John R. Wallace, Donald P. Greenberg, "A Progressive Ref'mement Approach to Fast Radiosity Image Generation," Computer Graphics (SIGGRAPH '88 Proceedings), V 22, N 4, Aug. 1988, 75-84.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74362</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[James Painter and Kenneth SIoan, ,Antialiased Ray Tracing by Adaptive Progressive Refinement," Computer Graphics (SIGGRAPH '89 Proceedings, V 23, N 3, July 1989, 281- 288.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gregory j. Ward, "RADIANCE: A Tool for Computing Luminance and Synthetic Images," to appear in Lighting Design and Applications.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Michael Cohen, Donald P. Greenberg "The Hemi-cube: A Radiosity Solution for Complex Environments," Computer Graphics (SIGGRAPH '85 Proceedings) V 19, N 3, July 1985, 31-40.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97896</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A.T. Campbell,III, Donald S. Fussell, "Adaptive Mesh Generation for Global Diffuse Illumination," Computer Graphics (SIGGRAPH '90 Proceedings) V 24, N 4, August 1990, 155-164.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[David S. Immel, Michael F. Cohen, Donald P. Greenberg, "A Radiosity Method for Non-Diffuse Environments," Computer Graphics (SIGGRAPH '86 Proceedings), V 20, N 4, Aug. 1986, 133-142.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Thomas J.V. Malley, A Shading Method for Computer Generated Images, Master's Thesis, University of Utah, June 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya, "The Rendering Equation," Computer Graphics (SIGGRAPH '86 Proceedings), V 20, N 4, Aug. 1986, 143-150.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gregory J. Ward, Francis M. Rubinstein, Robert D. Clear, "A Ray Tracing Solution for Diffuse Interreflection," Computer Graphics (SIGGRAPH '88 Proc.eeAings)," V 22, N 4, Aug. 1988, 85-92.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[James Arvo,"Backward Ray Tracing," SIGGRAPH '86 Developments in Ray Tracing seminar notes V 12, Aug. 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97920</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mark Watt, "Light-Water Interaction using Backward Beam Tracing," Computer Graphics (SIGGRAPH '90 Proceedings), V 24, N 4, August 1990, 377-385.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Tomoyuki Nishita, Eihachiro Nakamae, "Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection," Computer Graphics (SIGGRAPH '85 Proceedings), V 19, N 3, July 1985, 23-30.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[John R. Wallace, Michael F. Cohen, Donald P. Greenberg, "A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radiosity Methods," Computer Graphics, (SIGGRAPH '87 Proceedings), V 21, N 4, July 1987, 311-320.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Francois Sillion, Claude Puech, "A General Two-Pass Method Integrating Specular and Diffuse Reflection," Computer Graphics (SIGGRAPH '89 Proceedings), V 23, N 3, July 1989, 335-344.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>93316</ref_obj_id>
				<ref_obj_pid>93267</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley, "A Ray Tracing Method for Illumination Calculation in Diffuse-Specular Scenes," Proceedings of Graphics Interface '90, May 1990, 205-212.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Robert L. Cook, Thomas Porter and Loren Carpenter, "Distributed Ray Tracing," Computer Graphics (SIGGRAPH '84 Proceedings), V 18, N 3, July 1984, 137-144.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97895</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Paul Heckbert, "Adaptive Radiosity Textures for Bidirectional Ray Tracing," Computer Graphics (SIGGRAPH '90 Proceedings), V 24, N 4, August 1990, 145-154.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>914720</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Holly Rushmeier, Realistic Image Synthesis for Scenes with Radiatively Participating Media, Doctoral Thesis, Comell University, May 1988.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97886</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[James Arvo, David Kirk, "Particle Transport and Image Synthesis," Computer Graphics (SIGGRAPH '90 Proceedings) V 24, N 4, August 1990, 63-66.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Werner Purgatohofer, "A Statistical Method for Adaptive Stochastic Sampling," Computers and Graphics, V I I, N 2, 157-162, 1987.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325179</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Mark E. Lee, Richard A. Redncr, Samuel P. Uselton, "Statistically Optimized Sampling for Distributed Ray Tracing," Computer Graphics (SIGGRAPH '85 Proceedings), V 19, N 3, July 1985, 61-68.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Cindy M. Goral, Kenneth E. Torrance, Donald P.Grccnberg and Bennett Battaile, "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics (SIGGRAPH '84 Proceedings), V 18, N 3, July 1984, 213-222.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Lance Williams, "Pyramidal Parametrics," Computer Graphics (SIGGRAPH '83 Proceedings), V 17, N 3, July 1983, I-9.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Frank Crow, "Summed-Area Tables for Texture Mapping", Computer Graphics (SIGGRAPH '84 Proceedings), V i 8, N 3, July 1984, 207-212.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357335</ref_obj_id>
				<ref_obj_pid>357332</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[H. Weghorst, Gary Hooper, and Donald. P. Grecnberg, "Improved Computational Methods for Ray Tracing," ACM Transactions on Graphics, V 3, N I, January 1984, 52-69.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[B. W. Silvcrman, Density Estimation for Statistics and Data Analysis, Chapman and Hall, ISBN 0 412 24620 I, 1986.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Michael Cohen, Donald P. Grccnberg, Dave S. Immel, Philip J. Brock, "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, V 6, N 3, March 1986, 26-35.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Michael Cohen, Donald P. Greenberg "The Hemi-cubc: A Radiosity Solution for Complex Environments," Computer Graphics (SIGGRAPH '85 Proceedings) V 19, N 3, July 1985, 31-40.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 A Progressive Multi-Pass Method for Global Illumination 
ShenchangEric Chen, Holly E. Rushmeiert, Gavin Miller, Douglass Turner Advanced Technology Group Apple 
Computer Inc. The George Woodruff School of Mechanical Engineering Georgia Institute of Technology ABSTRACT 
A new progressive global illumination method is presented which produces approximate images quickly, 
and then continues to systematically produce more accurate images. The method combines the existing methods 
of progressive refinement radiosity, Monte Carlo path tracing and light ray tracing. The method does 
not place any limitation on surface properties such as ideal Lambertian or mirror-like. To increase efficiency 
and accuracy, the new concepts of light source reclassification, caustics reconstruction, Monte Carlo 
path tracing with a radiosity preprocess and an interruptible radiosity solution are introduced. The 
method presents the user with most useful information about the scene as early as possible by reorganizing 
the method into a radiosity pass, a high frequency refinement pass and a low frequency refinement pass. 
The implementation of the method is demonstrated, and sample images are presented. CR Categories and 
Subject Descriptors: 1.3.3 [Computer Graphics]: Picture/Image Generation -Display Algorithms. 1.3.7 [Computer 
Graphics]: Three-Dimensional Graphics and Realism General Terms: Algorithms Additional Key Words and 
Phrases: Radiosity, Ray Tracing, Monte Carlo, Caustics, Global Illumination, Progressive Refine­ ment. 
INTRODUCTION Generating realistic images of complex scenes is still far from a real time process. To 
handle this problem, Bergman et. al, III in­troduced the concept of adaptive refinement for generating 
high quality images. An adaptive refinement method has two fundamental properties: the image continues 
to improve indefinitely with time, and the most useful information is produced earliest in the rendering 
process. In this paper we present a global illumination method for generating physically accurate images 
which follows the adaptive refinement paradigm. In Bergman s adaptive refinement method, only simple 
shading models are presented. The global illumination effects, such as Pcrmissinn to copy without (CCall 
or part of thli material is granted provided that the copies are not made or distributed for direct commercial 
advantage. [be ACMcopyrightnotweandthe title of the publicationfind its date appear, and notice IS given 
that copying is by permission of the Aw+ocia(ionfor Computing Machinery. To copy otherwise. or k) republish. 
requires a fee and/or specific ~m]ission. shadowing and inter-reflection between surfaces, are ignored. 
In addition, the refinement process leaps from one shading model to another. The transition between refinement 
steps is not smooth. Cohen et. al. 12] subsequently extended the concept to develop a progressive refinement 
radiosity method that allows the user to view the images as the radiosity solution evolves, The new method 
uses a more sophisticated global illumination model and generates images that progress smoothly and gracefully 
to the final image. The idea of progressive refinement is readily applied to ray tracing methods as well. 
Painter, Sloan 131 and Ward 141 have presented ray tracing methods that evolve by casting increasing 
numbers of rays to increasing numbers of pixels. Both pure radiosity and pure ray tracing solutions to 
the global illumination problem have disadvantages. Radiosity methods require careful, detailed meshing 
to correctly capture shadows, which may have very high spatial frequency [51, [61. Radiosity methods 
also require an excessive computation time and storage to directly solve for non-diffuse reflections 
[7]. While radiosity methcds have keen developed with the capability of capturing caustic effects (e.g., 
181), meshing methods to guarantee the capture of these effects do not exist. Ray tracing methods can 
be formulated to produce physically accurate solutions (i.e., [9], I]01). However, such methods require 
huge numbers of rays to be cast per pixel to avoid perceptible noise in the image. While caustic effects 
can be captured with eye ray tracing, using backward ray tracing (i.e., light ray tracing) and caustic 
maps ([I [], 11.21)is generally more effective. Because of the relative advantages and disadvantages 
of radiosity and ray tracing, many hybrid or multi-pass methods have been developed. The first such multi-pass 
method was the radiosity method developed by Nishita and Nakamae II3], in which different techniques 
were used for direct and indirect illumination. Wallace et. al. [141 and Sillion and Peuch [ ISI developed 
hybrid methods in which an extended radiosity method was followed by a ray tracing pass to solve for 
view dependent directional reflections. Shirley [16] developed the most extensive multi-pass method to 
date. In Shirley s method, radiosity is used for indirect illumination, Monte Carlo ray tracing is used 
for direct illumination, and light ray tracing is used for caustics. While multi-pass methods such as 
Shirley s can produce excellent and physically accurate images, they may still produce noticeable artifacts. 
The surface discretization from the radiosity pass is still used in the final image. If the environment 
has strong indirect illumination, the quality of the final image will be strongly dependent on the meshing 
of the visible surfaces. Diffuse surfaces are still assumed to be ideal Lambertian in the final image. 
There is no mechanism for rendering surfaces which are neither strongly ( 1991 ACM-()-W791-436-X914M17K)IM 
W).75    SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 directional nor ideal Lambenian. Another drawback 
of all the previous multi-pass methods is that they do not provide intermediate feedback to the user. 
Since global illumination rendering is generally a very lengthy process, intermediate feedback is very 
important in detecting mistakes early on . In the case of Shirley s method, the user must wait for many 
higher order diffuse interreflections which produce little new information about the scene in the progressive 
radiosity phase before sharp shadows, textures and surface bumps can he obtained in the Monte Carlo ray 
tracing phase. The ray tracing phase then progresses in the order of pixels. No complete image is available 
for fast feedback until every pixel is finished. We present an extended, reorganized version of the multi-pass 
concept which is designed to overcome these disadvantages. The method consists of a series of passes 
which continuously provide user feedback. The rendering process begins with a progressive refinement 
radiosity pass with extended form factors computed by ray tracing for non-diffuse surfaces. TMs paas 
provides a good approximation to the overall illumination. A high frequency refinement pass follows to 
perform a Monte Carlo path tracing from the eye and the lights to create shadows and caustics. Unlike 
earlier methods, the path tracing is only directed at surfaces that are considered bright enough to create 
high frequency details. A caustics reconstruction technique is introduced to compute a caustic map for 
each surface. A low frequency refinement pass continues to refine the image using Monte Carlo path tracing 
for accurate low frequency illumination effects such as color bleeding. The low frequency refinement 
makes use of the results from the radiosity pass for high order reflections. Therefore, it should be 
faster than pure path tracing. Since the pass is per­formed pixel by pixel, the radiosity meshing artifacts 
are invisible in the final image. In the new method, the user does not need to wait for the first pass 
to finish before the next pass begins. The radiosity paas can be interrupted to compute the high frequency 
details. All the three passes potentially can be run in parallel. We begin with a description of the 
multi-pass method in the next section. We then describe how the method is organized into a progressive 
refinement solution, followed by a description of im­plementation and results. Conclusions and future 
directions are presented at the end. EXTENDED MULTI-PASS METHOD A solution for global illumination must 
account for alI of the ener­gy which can pass from sources of light to the eye. In the follow­ing sections, 
we present two ways of examining how our method solves the global illumination problem. Fhtly, we examine 
how all possible light paths between the sources and the eye are ac­counted for, Secondly, we examine 
how all the terms in the ren­dering equations P] are accounted for. We then present a detailed discussion 
of two new features of our method-light source reclas­sification and caustics reconstructions. Finally, 
we contrast the new extended method with existing multi-pass methods. Accounting for Ali Light Paths 
We use three techniques to find all the significant light paths: 1. Progressive Refinement Radiosity 
(PRR), with ray tracing for extended form factors. 2. Light Ray Tracing (LRT), which traces rays from 
light sources for caustic map generation.  3. Monte Carlo Path Tracing (MCPT), with distributed ray 
tracing 117] being a subset of MCPT. We divide all possible light paths into four classes. Let s be a 
reflection or transmission off of a specular-like surface (i.e. highly directional but not necessarily 
a perfect mirror), and d be a reflection or transmission off of a dlffuae-like surface (i.e. weakly direction 
but not necessarily Lambertian). Usings and d to denote reflectionhrtsmission events, the four path classes 
are shown in Fig. 1. Dk2t Illumination Patha I !  MCFI Caustic Paths LRT MCPT  Highlight Paths = Diffuse-like 
(D) :% LS*E B . Specular-like (S) v~ ;# Light (L) ~ Eye (E) Q L * O or more MCPT + at least 1 Radiosity 
Paths El P! PRR MCPT Fig. 1. Four classes of light paths are shown both pictorially and with Heckbert 
s style of notations] 8]. The paths are fol­ lowed with three te.chniques-PRR, LRT and MCPT. Arrows in­ 
dicate the direction in which the path is followed. Direct illumination paths refer to paths from sources 
to the eye via one d followed by zero or more S S. These paths are followed using MCPT.As soonasaraytracedfromtheeye 
hitsad, anoth­er ray is cast at a light source. The direction of thk aecmd ray is chosen using a probability 
dansity function (p&#38;t baaed on the area distribution of energy/time on the light sources. An example 
of these paths is the shadowing effects created by light sources, Caustic paths contain one or more s 
s, a single d, and zero or more s s before the eye. These paths are followed using LRT and the results 
are deposited on the caustic maps attached to diffuse surfaces. The caustic maps are created from the 
intersections of the caustic paths with the diffuse surfaces using a reconstmction method that will be 
described in Caustic Reconstruction . @@ Highlight paths consist of zero or more s s and are traced by 
MCPT. Highlight paths account for the direct rendering of light sources, the rendering of light sources 
through specular-like transmitters, and the production of specular-like highlights in opaque surfaces. 
Radiosity paths contain at leas~ two U S. Radiosity paths are followed using a combination of PRR and 
MCFT. Paths from the eye up to the second d are followed using MCPT. Paths which continue on through 
any number of s and d until reaching the source are followed using PRR. Radiosity paths produce the classic 
radiosity effects such as color bleeding. These four paths encompass paths with any combination ofs and 
d between the source and the eye. This can be shown with the number of d s contained in the paths. Any 
path that has at least two d s is a radiosity path. Paths with one d is either a caustic path or a direct 
illumination path. Paths contain zero d belong to the highlight path.  Solving the Rendering Equation 
 In this section we describe how the strategies outlined above produce a solution to the rendering equation. 
The quantity of light which we compute at each step in the solution is the radiance, I, the light energy 
per unit time, projected area and solid angle (also called the intensity). The reflectance of each surface 
is given by its bidirectional reflectance, pM(ei, $i; Or, @r), which is the radiance reflected in a direction 
r as the result of incident energy per unit time area and solid angle from a direction i. As outline 
in the previous section, our method combines PRR, LRT and MCPT. MCPT involves using Monte Carlo methods 
to estimate integrals of various forms. The methods for estimating in[egrals are well established. To 
simplify the discussion in this section, many of the details of the Monte Carlo estimates will he omitted. 
These details can be found elsewhere, such as in 1191. For a particular view, an image is formed by finding 
an approxi­mate solution to the following rendering equation for each pixel: I (p,er, Or) f(xs/ys)eixsdYs 
 lpixel = ~pixel_ama 0 (eq. 1) where IPiXel is the pixel radiance, Io(p, E)r,$r) is the radiance leaving 
a point p in the scene visible through screen location (xs,ys) in direction ( 13r,$r ) to the eye, and 
f(xs,ys) is a filtering function for anti-aliasing. 10 is a function of wavelength, and RGB values must 
be determined for Ip&#38;el. To simplify dkcussion, we omit explicit wavelength dependencies and the 
transformations which convert a discrete wavelength sampling 10 to RGB values for Ipi~e, Pixel radiance 
is computed by averaging the results of many trial estimates of IPixel. Each trial begins by tracing 
a ray from the eye through the pixel using a pdf based on f(xs,ys). Io(p,f3r,~r) must be found for the 
surface which the ray hits, The radiance leaving a surface as the sum of the emitted and reflected radiance: 
 Io(prer, $r)=Ie(p,er,$r) +Ir(p,er,$r) ~~ emitted reflected (eq. 2) In general, there is a transmitted 
radiance as well. However, since it is treated exactly analogously to the reflected component, we will 
omit transmission for now.  Comfwter GraDhics, Volume 25, Number 4. Julv 1991 Ie(p,er, $r) must be 
specified, and Ir(p,8r,r$r) is given by: Ir(p,er,~r) =~flPM(ei,oi;8r,0 r) Ii(6i/@i)COSeidWi (eq. 4) 
where li(ei,~i) is the radiance incident from a direction i, ei is the angle between the surface normal 
and the direction i, dwi is a differential solid angle, and the integral is over the incident hemisphere. 
Formally, we can rewrite pM(ei,$i;er,@r) in terms of a diffuse­ like comPonent pl(6i, $i;6r, @r), whichhas 
a weak dependence on direction, and a specular-hke component ph(ei,$i;Etr,$r), which has a strong dependence 
on direction: ~bd( i,~i;or~~r) = Pl(ei~@i;er~&#38;)+ ~h(eif@i;er,@r) (eq. 5) We use f31 and Ph rather 
than Pd and PS to avoid confusion with . idealized Lambertian p~=~~~.iar?;nd %%;;: (p = p,/c0st3d 01) 
reflectance. re P ectances may be included in PI and ph , but this decomposition does not require assuming 
these idealized reflectance. We can express Ir(p, E)r,@r) as the sum of Ih(p,or, $r) and ll(p, t3r,$r), 
where: Ih(p, er, $r) = ~mPh(ei, oi; er, ~r)Ii(ei, @i) COSeidWi (eq. 6) I1(P, er, ~r) = JnP1(ei, oi;er, 
@,) Ii(ei, ~i)COSeid@i (eq. 7) Ih is the radiance reflected from the specular-like component and I, 
is the radiance reflected from the diffuse-like component. I is evaluated by MCPT. A direction is chosen 
using a pdf base d on the reflectance, and the surface visible in that direction is found by ray casting. 
This process is performed recursively until a light source or a diffuse-like surface is encountered. 
f he integral for Ih is then approximated using 11 of the last surface. I] is evaluated by decomposing 
it into four parts: (eq. 8) Il=ll,s+I],c +ll,h+Il,l where Il,s is light directly from light sources, 
Il,c is light from light sources via a series of specular-like reflections, I~,h is light from non-light 
sources via a a series of specular-like reflections, and 11,] is light from other diffuse-like surfaces. 
These four parts are expressed in the following equation: It,p(prer,$r) = ~OPl(ei/@i;er,@ r) Ii, b(ei,@i)COSeidWi 
(q. 9) where ~=s, c,h,l All of the values on the right hand side for ll,S are known. The integral for 
11,~ is reexpressed as a sum of area tntegrals over each source g: 11,s= Z.(A Pl(ei, @i;er,$r)Ig(eg,$g)cose 
icosegVdAg / r2 ag (eq. 1O) where Ag is the area of Iight source g, og is the angle between tbe normal 
to surface dAg and the direction to p (i.e. the point where radiance is being evaluated) and r is the 
distance from dAg top. The integral over a source is estimated by casting a ray at a random point on 
the source. The term V is one if the light is visible in the direction, and is zero otherwise. The integral 
is then 167  SIGGRAPH 91 Las Vsgas, 28 July-2 August 1991 approximated using the value of the integrand 
in that direction. I1,C is found by LRT and is stored in a caustic map. When a ray from the eye hits 
a diffuse-like surface, the value of I1,C is com­puted from the map and then added to the radiance for 
that ray. II ~ is evaluated recursively just as Ih is, with the exception that p&#38;hs leading to the 
light source via a series of specular-like re­flections are excluded to prevent double counting the caustic 
paths. 11,1 is evaluated as an integral in which the whole right hand side is known, by using the values 
of I, calculated from the PRR solution to approximate the values of Ii,l. A ray is cast into a random 
direction in the incident hemisphere to determine the direction for evaluating the integrand. To avoid 
double counting the direct illumination paths, surfaces which are treated as light sources are not included 
in this integral. The techniques described above are used to calculate trial values for each pixel. Let 
pl,pve and ph,ave be average reflectance. In an individual trial Ir M estimated using Russian Roulette 
IZOI by rewriting Ir in the equivalent form: Ir = l%,ave(Il i Pl,ave) +Ph,ave(Ih f Ph,ave) + (1 -I%,ave 
-Ph,ave)o (eq.11) Based on a choice of a uniformly distributed random number, II is estimated as either 
11/ pl ,ave, I h / ph,ave or zero. Ih M estimated by recursion. II is estimated by findhg a trial value 
of 1] ~, adding Il,c and using Russian Roulette again to either es~imate 11,1or I~,h. The number of trials 
required depends on the vahte of the sample standard deviation of the estimated Iptid compared to a user 
selected level of accuracy (i.e., [211, [22]). Light Sourca Reclassification Like many other global 
illumination methods, much more work is done in our method to estimate the radiances from light sources 
than from other surfaces. This is justified by the substantially greater radiosity of lights. Usually 
all self-emitting surfaces are defined as sources. In many environments, however, some non­emitting surfaces 
reflect enough energy to warrant treatment as light sources. Conversely, some self-emitters are very 
dim, and special treatment of these is not necessary. Coral et. al. [23] have treated surfaces directly 
illuminated by point lights as emitters. However, their motivation is to handle point lights rather than 
to capture strong indirect illumination. Light source classification is performed after the PRR pass. 
A sur­face is classified as a light source if its radiosity, computed in the PRR pass, is considered 
large enough. Some self-emitters may not be considered as light sources and will be treated like the 
other re­flecting surfaces. Caustics Reconstruction The caustic maps are constructed in the following 
steps: First, the caustic map resolutions are determined for each surface either from a particular view 
or from the area of the surface if view independent solutions are desired. To compute view depen­dent 
resolutions, the scene is ray traced from the eye. The smallest ray-surface intersection kernel required 
for each surface by tlis pass determines the resolution of the caustic map required for that surface. 
This approach creates uniform maps instead of hierarchi­ 168 cal ones like [181.This is convenient when 
using MIP maps (24] or summed area tables [n] for caustic map anti-aliasing in the final pass. The algorithm 
will be conservative in that it will create more detailed caustic maps than required for objects which 
occupy both the foreground and the background. However, it will always provide adequate resolution for 
the near-by parts of a surface. Second, for each light in turn, rays are fired off towards the specular 
surfaces. This may be achieved either by Monte Carlo sampling over a hemisphere, or by using one or more 
hemi-cubes 151for item-buffer preprocessing [26}. Each ray is generated such that it carries the same 
amount of energy. The rays are reflected or refracted when they hh specular-like surfaces and stop when 
they encounter diffuse-like surfaces. All the decisions of treating a surface as specular-like or diffuse-like 
are made using Russian Roulette discussed previously. llte result of this pass is that each diffuse-like 
surface haa a list of ray-surface intersections for caustic rays. Third, for each surface, the list of 
intersections is used to reconstruct a smooth caustic map. In the method proposed by Arvo [1II, each 
ray deposits energy over four pixels with a bilinear ramp of the intensity. This is equivalent to depositing 
a square convolution kernel one pixel wide into the caustic map. The energy of a ray wilI h deposited 
into a rectangle which is du wide and dv high in the parameter space where du is 1 / nu and dv is I / 
nv, and nu and nv are the resolutions of the caustic map in the u and v directions respectively. Since 
the caustic map is scaled by the tangent vector magnitudes when it is transformed to the world space 
during rendering, it is necessary to scale the intensity of the kernel in the caustic map (b) so that 
it will correspond to the ray energy (E) in the world space. For the sake of simplicity we assume that 
the tangent vectors are constant over the extent of the kernel. A kernel with intensity b in the parameter 
space will correspond to an energy E in the world space according to the following equa­tion. b= E/ (dudvlpuxpvl) 
(eq. 12) where pu is the u-tangent vector for the surface at the ray-surface intersection and pV is the 
v-tangent vector. Equation (eq. 12) is used to find b, which is deposited onto the final reconstructed 
caustic map. For regions of the caustic map in which there are less than about four overlapping kernels 
per caustic map pixel, the resultant image will be very noisy (i.e., some pixels may not be hit by any 
ray at all). One method to diminish the noise is to use a larger convolution kernel for light deposition. 
This is called the fixed kernel method for the reconstmction of pdfs 1271.It has the disadvantage that 
it is hard to set the kernel size in a way which filters out the noise in sparse regions of the map and 
keeps high frequency detail in dense regions. Because of this limitation, adaptive kernel size methods 
should be used in which the size of the deposition kernel depends on the local density. This becomes 
a chicken and egg problem, in that the kernel size depends on the density, which in turn is the very 
thing we are trying to compute. In this paper, a nearest neighbors method is used [27]. This involves 
expanding each convolution kernel until it covers n neighbors. A preprocessing step, for the sake of 
computational efficiency, is used to produce an accumulation image, at the reconstruction resolution, 
in which one pixel wide convolution @ @ Computer Graphics, Volume 25, Number 4, July 1991 kernels are 
deposited for each ray (i.e., these kernels all have the amplitude of one). Then, around each ray-intersection, 
a rectangular region is expanded until it covers n neighbors, with n being computed by integrating the 
image over the rectangle. The ratio of the width to height of the rectangular region is set to the ratio 
of the corresponding tangent vector magnitudes. This means that the rectangle in the parameter space 
maps to an approximately square region in the world space. The dimensions of the rectangular region are 
then used to scale an elliptical­conical kernel which is deposited onto the final caustic map. The kernel 
amplitude is first set to normalize the filter and then mukiplied by the intensity computed using eq. 
12 to take into account the effects of the tangent vector magnitudes. This algorithm is illustrated in 
Fig. 2. Fis. 2. Caustic map reconstruction The integral of the accumulation image over the rectangular 
region may either be evaluated by direct summation or it could be computed using a summed-area table 
[251. This would allow a binary search to be made on the rectangle size and would speed up the reconstruction 
process when ray intersections are very sparse. However, the subsequent large convolution kernels would 
still need to be deposited into the reconstructed map. When there are half the number of ray-surface 
intersections, the convolution kernels have twice the area. The computation time for the reconstruction 
depends linearly on the number of caustic map pixels, and is relatively insensitive to the number of 
ray-surface intersect ions. Finally, the results are read out from the caustic maps during the Monte 
Carlo path tracing step as described previously. Comparison to Previous Formulations Previous global 
illumination methods can be described in the terms used in Solving the Rendering Equation. In Wallace 
s methodi 1~], Ir is decomposed into II and lh, and PI is Lambertian, II is given by the radiosity solution 
and [h by distributed ray tracing. in Shirley s methodi161, II is decomposed into 1],s , ll,c and Il,]+h. 
11,sis evaluated as in our method (except that only self­emitters are sources). lI,C is calctdated by 
interpolating a caustic map, rather than by reconstruction. Il,l+h is taken directly from the radiosity 
solution. Our reclassification of light sources allows improved shadows and caustics cast by indirect 
sources. The reconstruction produces a txtter representation of caustics. Finding Il,]+h by Monte Carlo 
integration, rather than using the PRR solution directly has fwo advantages. First, in the final rendering, 
the true bidirectional reflectance can be used. Second, the surface discretization used in the radiosity 
solution never appears in the final image, reducing the work required in meshing. Kajiya s pure MCPT 
approach is accurate but inefficient. Several researchers(e.g.l 18]) have discussed the advantages of 
using LRT for caustics. Our major improvements are the caustic reconstruc­tion and the use of PRR for 
higher order interreflections. Using the PRR solution has two advantages. The length of each individual 
trial is reduced, since paths end at diffuse-like surfaces. Also, the variance in the trials is reduced, 
reducing the number of trials for a particular level of accuracy. This variance reduction results from 
the value of Ii,] being known, rather than being a high variance quantity which itself must be evaluated 
by recursion. Ward [IO] used a similar strategy to reduce path length and variance by using cached radiance 
values for higher order interreflections.  PROGRESSIVE REFINEMENT The method described in the previous 
section is not organized to present the user with the most important information at the earliest time 
possible. In this section we present a reorganization of the extended multi-pass method into a true progressive 
refinement method. The key ideas in this reorganization are an interruptible PRR, a high frequency refinement 
and a low frequency refine­ment pass. First of all, the information to be presented must be prioritized. 
We have chosen the following ordering: Overall global illumination of the environment: Approximate direct 
illumination . Approximate diffuse-like interreflections Approximate specular-like reflections . Approximate 
caustics High spatial frequency variations in illumination: . Sharp shadows . Textures and surface bumps 
Specular-like reflections . Caustics Low spatial frequency variations in illumination: Accurate diffuse-like 
reflections The user is presented with the overall global illumination using the first steps in a PRR 
solution. High spatial frequency variations are then presented by computing direct illumination, caustic 
and highlight paths. The low spatial frequency variations are calculated by computing the radiosity path. 
 Interruptible PRR The first several iterations of a PRR solution provide a large quantity of useful 
information per unit time. However, as the method goes on, the rate at which images improve decreases 
dramatically. Each additional shot produces little visible effect on the solution. However, the solution 
must run for many more iterations to produce an accurate, converged solution. In our method an interrupted 
PRR solution is used to produce more detailed images, with the results of the completed PRR solution 
added in later. An interrupted PRR solution can be used because of the linearity of the rendering equation. 
Let Iint be the interrupted PRR solution and Ifinal be the final PRR solution. Roughly, the process can 
be thought of as using the values of lint as the radiosity values for the extended multi-pass method 
in one image, and the values of (Ifina] -Iint) in a second image, and then summing the results. I 69 
  SIGGRAPH 91 Las Veaas, 28 JuIY-2 Auwst 1991 High Frequency Refinement After the the PRR solution haa 
been interrupted by the user, and a view chosen, high frequency refinement begins. Initially all surfaces 
are displayed with the values lint . To approximate spec­ular reflections quickly, a pass is made in 
which specular-like sur­faces are ray traced from the eye (with the initial assumption that they are 
mirror-like). In this pass the interrupted PRR solution can also be modified using texture maps. Next, 
the dkect illumination, highlights and caustics resulting from each light source are calculated. To make 
the transition in the solution smooth, these effects are added into the image source by source. Three 
types of radiance values are calculated for each pixel Iapprox, l~e and Idisp. Iappnx is the value for 
the pixel found from PRR. I~e is the vahte which has been accurately calculated for the pixel by MCPT. 
Misp is the value displayed, and is the sum of Iapp~x and I~e. In the pass for each source g, the portion 
of lapp~x for each diffuse-l kesurface due to direct illumination and caustics from g is subtracted out, 
and value of I~e is increased by using the caustic map for g and by following direct illumination paths 
from g. In estimating direct illumination, the bump maps and texture maps for that surface can be used. 
For each specular-like surface, the vahtes of Iapprox and Itme are replaced using the values of Iapprox 
and hrrre for the diffuse-like surfaces visible through the surface. The true value of ph is used for 
the surface to find the visible diffuse-like surface (i.e., Note that the diffuse-like surface may be 
visible through a chain of specular-like reflections.) Treating specttlar­ !ike surfaces in this way 
insures that diffuse-like surfaces will be treated in the same way when seen through a specular-like 
surface as when seen direct] y. Let Ie be the emission, IpIT be the radiosity result maintained for each 
surface, and let the initial value of Iprr k Iint. The following is simplified pseudo-code for adding 
in the effect of each source g: HighFrequencyPass(g) ( Shoot out negative light from g to remove the 
effects of direct illumination and caustics of g from all Iprr s; Build caustic maps by shooting out 
caustic rays from g; For each pixel p ( converged = false; trial = O sum_approx = O sum_trtre = O, While 
not converged { trial++; shoot ray at p using f(p) as weighting function to find surface_hiE GetRadiance(g, 
surface_hit, trial_Iapprox, trial_Itrue); sum_approx += trial_Iapprox; sttm_true +. trird_Itrue; new_Iapprox 
= sum_approx/trial; new_ltrtte = sum-true/trial; trial_Idisp = Itrue(p) + new_Iapprox + new_Itmq If ((standard_deviation( 
new_Itrue)/trial_Idisp) < accuracy) ( converged = true; Itrtte(p) += new_Itrue; Idisp(p) = trial_Idis~ 
) ) ) ) GetRadiance(g, surface_hit@ial_Iapprox, triaI_Itrtte) { If 11chosen by Russian Roulette { trial_Iapprox 
= Iprr(surface hit); trial_Itrtte = estimate of Il,s~ obtained by shooting at source g, trial_Itrue += 
estimate of Il,c~ from caustic map of strrface_hit; ) Else If Ih chosen { Shoot ray in direction given 
by pdf based on Ph; GetRadirmce(next_surface_hit, trird_I approx, trial_I trueh trial_Itrue = trial_I 
trtreT; trial_Iapprox = trial_I approx~; )] For ease of explanation several details have been omitted 
from the pseudo-code. For example, more variables need to be saved to check the convergence of the value 
of radiance for each pixel. The convergence check does not need to be made after each trial, but after 
a group of trials. The number of trials in a group is deter­mined on the fly, baaed on the initial estimates 
of the variance of the trials. I%e accuracy used in the convergence check must be smaller than the overall 
accuracy required for each pixel, because the errors from several passes will be summed. However, the 
effect of the higher accuracy requirement is mitigated by consi&#38;ring the sample standard deviation 
as a fraction of the total radiance for the pixel, not as the fraction of the current value of Itrue 
being estimated. The quantities marked with a ~ need to be weighted to account for the Russian Roulette 
selection and multiplied by the surface reflectance. As noted by Arvo and Kirk, trees of rays, rather 
than srnct paths may result in lower variances. Null results for rays directly to the eye increase the 
variance, so null selection in Rus­sian Roulette is only used for higher order interreflections. At the 
end of the high frequency refinement, the radiance of all direct illumination, caustic, and highlight 
paths have been accurately estimated. The user can either resume the interrupted PRR solution or can 
move on to the low frequency refinement pass. Low Frequency Refinement In the final pass, more accurate 
values for Iapprox ~ fotmd by evaluating radiosity paths by MCPT with results from PRR. The vahte of 
Ipn for all light sources is set to lfin~ -lint, since the direct and caustic contributions of Iint from 
these sources on other surfaces have already been calculated. f?te value of IpIT for all other surfaces 
is set to lfin~ since the effects of interreflections from these surfaces are now going to be estimated 
by integration over the hemisphere. As in high frequency refinement, trials are made pixel by pixel until 
I~e converges. Pseudo-code for calculating radiance in the low frequency refinement is given by: /* hit_d 
indicates if a diffuse surface has been hit along the path. Initially, hit_d is false */ GetLRadiance(surface_hit, 
trial_Itrue, hit_d) { If II chosen by Russian Roulette { If hit_d is false {/ hit the first d */ Shoot 
ray out into hemisphere above sttrface_hh to find next_surface_hiC hit_d=true; GetLRadiance(next_surface_hit, 
trial_I true, hit_d);     .  SIGGRAPH 91 Las Veqas, 28 JuIY-2 Auwst 1991 .E $16! !Af Hll ­ solution 
and the high spatial frequency variations caused by rendering large numbers of small objects needs to 
be examined. Parallel processing of the radlosity, ldgh and low frequency refinement passes is straightforward. 
The potential of distributing the computation to a larger number of processors nosds to be investigated. 
 ACKNOWLEDGEMENTS We greatly appreciate Apple Computer for providing an exciting environment in which 
this research was conducted. The algorithm was implemented in a rendering testbed developed by Ken Turkowskl, 
Douglass Turner and Shenchang Eric Chen. We would like to thank reviewers for their helpful suggestions, 
espe­cially the 13-page hand-written comments from one of them. The second author would like to acknowledge 
the support in part by a grant from the National Science Foundation, ECS-8909251, Pro­gressive Refinement 
Algorithms for Radiant Transfer. Thanks also go to Robin Myers for his help in printing the color images. 
 REFERENCES [1] Larry Bergman, Henry Fuchs, Eric Grant, Susan Spach, Image Rendering by A&#38;ptive Refinement, 
Computer Graphics (SIGGRAPH 86 Proceedings), V 20, N 4, Aug. 1986,29-38. [2] Michael Cohen, Shenchang 
Eric Chen, John R. Wallace, Donald P. Greenberg, A Progressive Refmernent Approach to Fast Radiosity 
Image Generation, Computer Graphics (SIGGRAPH 88 Proceedings), V 22, N 4, Aug. 1988,75-84. [3] James 
Painter and Kenneth Sloan, Antialiased Ray Tracing by Adaptive Progressive Refinement, Computer Graphics 
(SIGGRAPH 89 Proceedings, V 23, N 3, July 1989, 281­ 288. [4] GregoV J. W@ RADIANCE. A Tool for Computing 
Luminance and Synthetic Images, to appear in Lighting Design and Applications. [5] Michael Cohen, Donald 
P. Greenberg The Hemi-cube: A Radiosity Solution for Complex Environments, Computer Graphics (SIGGRAPH 
85 proceedings) V 19, N3, July 1985, 31-40. [6] A.T. Carnpbell,III, Donald S. Fussell, Adaptive Mesh 
Generation for Global Diffuse Illumination, Computer Graphics (SIGGRAPH 90 Proceedings) V 24, N 4, August 
1990, 155-164. [7] David S. Immel, Michael F. Cohen, Donald P. Greenberg, A Radiosity Method for Non-Diffuse 
Environments, Computer Graphics (SIGGRAPH 86 Proceedings), V 20, N 4, Aug. 1986, 133-142. [8] Thomas 
J.V. Malley, A Shading Method for Computer Generated images, Master s Thesis, University of Utah, June 
1988. [9] James T. Kajiya, The Rendering Equation, Computer Graphics (SIGGRAPH 86 Proceedings), V 20, 
N 4, Aug. 1986, 143-150. [10] Gregory J. Ward, Francis M. Rubinstein, Robert D. Clear, A Ray Tracing 
Solution for Diffuse Interreflection~ Computer Graphics (SIGGRAPH 88 Proceedings), V 22, N 4, Aug. 1988,85-92. 
[11] James Arvo, Backward Ray Tracing, SIGGRAPH 86 Developments in Ray Tracing seminar notes V 12, Aug. 
1986. [12] Mark Watt, Light-Water Interaction using Backward Beam Tracing: Computer Graphics (SIGGRAPH 
90 Proceedhgs), V 24, N 4, August 1990,377-385. [13] Tomoyuki Nishita, Eihachiro Nakamae, Continuous 
Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interrefhxtion, Computer 
Graphics (SIGGRAPH 85 Proceedings), V 19, N 3, July 1985,23-30. [14] John R. Wallace, Michael F. Cohen, 
Donald P. Greenberg, A Two-Pass Solution to the Rendering Equation: A Synthesis of Ray Tracing and Radiosity 
Methods, Computer Graphics, (SIGGRAPH 87 Proceedhgs), V 21, N 4, July 1987,311-320. r151 Francois Sillion. 
Claude Puech. A General Two-Pass .. Method Integrating Specular &#38;d Diffuse Reflection, Computer Graphics 
(SIGGRAPH 89 Proceedings), V 23, N 3, July 1989,335-344. [16] Peter Shirley, A Ray Tracing Method for 
Illumination Calculation in Diffuse-Specular Scenes, proceedings of Graphics Interface 90, May 1990, 
205-212. [17] Robert L. Cook, Thomas Porter and Loren Carpenter, Dis­tributed Ray Tracing, Computer Graphics 
(SIGGRAPH 84 Proceedings), V 18, N 3, July 1984,137-144. [18] Paul Hecktwt, Adaptive Radiosity Textures 
for Bid-tion­al Ray Tracingt Computer Graphics (SIGGRAPH 90 Proceedings), V 24, N 4, August 1990, 145-154. 
[19] Holly Rushmeier, Realistic Image Synthesis for Scenes with Radiative/y Participating Media, Doctoral 
Thesis, Cornell University, May 1988. [20] James Arvo, David Kwk, Particle Transport and Image Synthesis: 
Computer Graphics (SIGGRAPH 90 proceeding:) V 24, N 4, August 1990,63-66. [21 ] Werner Purgatohofer, 
 A Statistical Method for Adaptive Stochastic Sampling, Computers and Graphics, V 11, N 2, 157-162, 1987. 
[22] Mark E. Lee, Richard A. Redner, Samuel P. Uselton, Statistically Optimized Sampling for Distributed 
Ray Tracing; Computer Graphics (SIGGRAPH 85 Proceedings), V 19, N 3, July 1985,61-68. [23] Cindy M. Gorrd, 
Kenneth E. Torrance, Donald P.Greenberg and Bennett Battaile, Modeling the Interaction of L@t Be­tween 
Diffuse Surfaces: Computer Graphics (SIGGRAPH 84 Proceedings), V 18, N 3, July 1984,213-222. [24] Lance 
Williams, pyramidal Parametric, Computer Graph­ics (SIGGRAPH 83 F rrxeedhgs), V 17, N 3, July 1983, 
1-9. [25] Frank Crow, Summed-Area Tables for Texture Mapping , Computer Graphics (SIGGRAPH 84 Proceedings), 
V 18, N 3, July 1984,207-212. [26] H. Weghorst, Gary Hooper, and Donald. P. Greenberg, Improved Computational 
Methods for Ray Tracing; ACM Transactions on Graphics, V 3, N 1, January 1984,52-69. [27] B. W. Silverman, 
Density Estimation for Statistics and Data Analysis, Chapman and Hall, ISBN 0412246201, 1986. [28] Michael 
Cohen, Donald P. Greenberg, Dave S. Immel, Philip J. Brock, An Efficient Radiosity Approach for Realistic 
Image Synthesis, IEEE Computer Graphics and Applications, V 6, N 3, March 1986,2635. [29] Michael Cohen, 
Donald P. Greenberg The Hemi-cube: A Radiosity Solution for Complex Environments, Computer Graphics (SIGGRAPH 
85 Proceedings) V 19, N 3, July 1985, 31-40. 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122738</article_id>
		<sort_key>175</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[A comprehensive physical model for light reflection]]></title>
		<page_from>175</page_from>
		<page_to>186</page_to>
		<doi_number>10.1145/122718.122738</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122738</url>
		<abstract>
			<par><![CDATA[A new general reflectance model for computer graphics is presented. The model is based on physical optics and describes specular, directional diffuse, and uniform diffuse reflection by a surface. The reflected light pattern depends on wavelength, incidence angle, two surface roughness parameters, and surface refractive index. The formulation is self consistent in terms of polarization, surface roughness, masking/shadowing, and energy. The model applies to a wide range of materials and surface finishes and provides a smooth transition from diffuse-like to specular reflection as the wavelength and incidence angle are increased or the surface roughness is decreased. The model is analytic and suitable for Computer Graphics applications. Predicted reflectance distributions compare favorably with experiment. The model is applied to metallic, nonmetallic, and plastic materials, with smooth and rough surfaces.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[comparison with experiment]]></kw>
			<kw><![CDATA[reflectance model]]></kw>
			<kw><![CDATA[specular and diffuse reflection]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.2</cat_node>
				<descriptor>Physics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010441</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Physics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P301827</person_id>
				<author_profile_id><![CDATA[81100332285]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiao]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31097274</person_id>
				<author_profile_id><![CDATA[81332531868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kenneth]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Torrance]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P84966</person_id>
				<author_profile_id><![CDATA[81100402503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Fran&#231;ois]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Sillion]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bahar, E. and S. Chakrabarti. "Full wave theory applied to computer-aided graphics for 3-D objects," IEEE Computer Graphics and Applications, 7(7), 1987, pages 46--60.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bahar, Ezekiel. "Review of the full wave solutions for rough surface scattering and depolarization," Journal of Geophysical Research, May 1987, pages 5209-5227.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bass, EG. and I.M. Fuks. Wave Scattering from Statistically Rough Surfaces, Pergamon Press, 1979.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Beckmann, Petr. "Shadowing of Random Rough Surfaces," IEEE Transactions on Antennas and Propagation, May 1965, pages 384-388.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Beckmann, Petr and Andr6 Spizzichino. The Scattering of Electromagnetic Waves from Rough Surfaces, Pergamon Press, 1963.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>563893</ref_obj_id>
				<ref_obj_pid>563858</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blinn, James E "'Models of Light Reflection for Computer Synthesized Pictures," Computer Graphics, I1, 1977, pages 192-198. (Proceedings SIGGRAPH '77.)]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Brockelman, R. A. and T. Hagfors. "Note on the Effect of Shadowing on the Backscattering of Waves from a Random Rough Surfaces," IEEE Transactions on Antennas and Propagation, AP-14(5), September 1966, pages 621-629.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357293</ref_obj_id>
				<ref_obj_pid>357290</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L. and Kenneth E. Torrance. "A Reflectance Model for Compuler Graphics," ACM Transactions on Graphics, 1, 1982, pages 7-24.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Feng, Xiaofen. Comparison of methods for generation of absolute reflectam'e factors for BRDF studies, Master's thesis, Rochester Institute of Technology, 1990.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hering, R.G. and T.E Smith. "Apparent radiation properties of a rough surface," Application to Thermal Design of Spacecraft, 23, 1970, pages 337-361.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Himlan, Theodore H., Michael C. Monks, Stephan H. Westin, Donald P. Greenberg, and Kenneth E. Torrance. "Physical measurement Techniques for Improving and Evaluating Computer Graphic Simulations.," 1991. (To be published.)]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jackson, John D. Classical Electrodynamics, John Wiley &amp; Son Inc., 1975.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360839</ref_obj_id>
				<ref_obj_pid>360825</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Phong, Bui Tuong. "Illumination for Computer Generated Pictures," Communications of the ACM, 18(6), June 1975, pages 311-317.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Siegel, Robert and John R. Howell. Thermal Radiation Heat Transfer, McGraw-Hill book Company, 2nd edition, 1981.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>122739</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Sillion, Franqois, James Arvo, Stephen Westin, and Donald P. Greenberg. "A Global Illumination Solution for General Reflectance Distributions," Computer Graphics, 25(4), August 1991. (Proceedings SIGGRAPH '91 in Las Vegas.)]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Smith, Bruce G. "Geometrical Shadowing of a Random Rough Surface," IEEE Transactions on Antennas and Propagation, AP-15(5), September 1967, pages 668-671.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Smith, T.E and K.E. Nichols. "Effects of polarization on bidirectional reflectance of a one-dimensional randomly rough surface," Spacecraft Radiative Transfer and Temperature Control, 83, 198 !, pages 3-21.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Stogryn, Alex. "'Electromagnetic Scattering From Rough, Finilely Conducting Surfaces," Radio Science, 2(4), 1967, pages 415--428.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Torrance, K.E. and E.M. Sparrow. "Off-Specular Peaks in the Directional Distribution of Reflected Thermal Radiation," Journal of Heat Transfer- Transactions of the ASME, May 1966, pages 223-230.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Torrance, K.E. and E.M. Sparrow. "Theory for Off-Specular Reflection from Roughened Surfaces," Journal of the Optical Society of America, 57(9), September 1967, pages 1105-1114.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Comprehensive Physical Model for Light Reflection XiaoD . He Kenneth E. Torrance Francois X. Sillion 
Donald P. Greenberg Program of Computer Graphics Cornell University Ithaca, NY 14853 Abstract Anewgeneralreflectance 
model forcomputer graphicsispresented. The model is based on physical optics and describes specular, 
di­rectional diffuse, and uniform diffuse reflection by a surface. The reflected light pattern depends 
on wavelength , incidence angle, two surfaceroughnessparameters,andsurfacerefractiveindex. Thefor­mulation 
is self consistent in terms of polarization , surface rough­ness, masking/shadowing, and energy. The 
model applies to a wide range of materials and surface finishes and provides a smooth tran­sition from 
diffuse-like to specular reflection as the wavelength and incidence angle are increased or the surface 
roughness is decreased. The model is analytic and suitable for Computer Graphics appli­cations. Predicted 
reflectance distributions compare favorably with experiment. The model is applied to metallic, nonmetallic, 
and plas­tic materials, with smooth and rough surfaces. CR Categories and Subject Descriptors: L3.7-[Computer 
Graphics]: Three-Dimensional Graphics and Realism; 1.3.3­[Computer Graphics]: Picture/Image Generation 
; J.2-[Physical Sciences and Engineering] : Physics. Additional Key Words and Phrases: reflectance model, 
specular and diffuse reflection, comparison with experiment. 1 Introduction Photorealistic image generation 
is an active research area in Com­puter Graphics. Ray-tracing and Radiosity have been developed to obtain 
realistic images for specular and diffuse environments, re­spectively. However, applications of these 
methods to general en­vironments have been hindered by the lack of a broadly-applicable local light reflection 
model. To obtain a true global illumination so­lution of a general environment, a physically based reflection 
model of general applicability is needed. A comprehen sive light reflection model is presented in this 
pa­per. The model compares favorably with experiment and describes specular, directional diffuse, uniform 
diffuse and combined types of Permission to copy without fee all or part of this material is granted 
provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or 
specific permission. reflection behavior. The model is analytic and provides a smooth transition from 
specular to diffuse-like behavior as a function of wavelength, incidence angle and surface roughness. 
As illustrated in Figure I, we classify the reflection process from an arbitrary surface as consisting 
of first-surface reflections and multiple surface and/or subsurface reflections. The first-surface re­flection 
process is described by physical optics and is strongly di­rectional. As the surface becomes smooth this 
part evolves toward specular or mirror-like behavior. As the surface becomes rough, a diffuse-like behavior 
due to diffraction and interference effects be­comes more important and, at larger roughnesse s, it controls 
the di­rectional distribution of the first-surface reflected light. The model partitions energy into 
specular and diffuse-like components accord­ing to the roughness of the surface. The multiple surface 
and sub­surface reflections sketched in Figure I are geometrically complex, but may be expected to be 
less strongly directional than the first­surface reflected light. Hence, they are approximated as uniform 
diffuse. Our model leads to analytic expressions suitable for the full range of surface roughnesses and 
thus is useful for implementation in computer graphics. The present model builds on, and extends, existing 
models from optics [3] [5]. It allows for polarization and masking/shadowing ef­fects. The model extends 
the geometric optics model of Cook [8] to the physical optics region, and correctly includes specular 
reflec­tion as the surface roughness is decreased. The model is physically based in contrast to empirical 
approaches [13]. The following sections provide a conceptual introduction, the model, a comparison with 
physical experiments, and example im­plementations. The mathematical derivation of the model appears 
in Appendix A. For unpolarized incident light, the reflectance model is summarized in Appendix B.  175 
&#38;#169;1991 ACM-0-89791-436-8/9 l!OO7/0175 $00.75 .. SI GGAAPH ' 9I A BRDF projected area of the 
surface (Figure 5) bidirectional reflectance distribution function v x y x,f),z Jvi + v~ unit vectors 
in Cartesian coordinates C (r ) correlation coefficient, equation (48) z surface height c complex coefficient 
of polarization state r area of bounding surface, Figure 2 D distribution function, equation (78) ~ delta 
function Es,Es F scalar and vector electric fields Fresnel reflection coefficient, equation (44) if e,¢ 
horizontal distance vector, equation (28) polar and azimuthal angles (Figure 5) IFI2 P G G' 9 I Fresnel 
reflectivity Fresnel matrix, equation (44) geometrical factor, equation (76) Green 's function, equation 
(2) surface roughness function, equation (9) intensit y A e(x , y) Pbd Pdh Phd iJ2 wavelength Gaussian 
distributed random function bidirectional reflectivity, equation (4) directional -hemispherical reflectivity 
hemispherical-directional reflectivity apparent variance of z = e(x , y) I unit tensor iJ~ variance of 
z = e(x , y) i k unit imaginary number, i.e., i = R wave number, i.e., k = 211"/ A T w autocorrelation 
length, equation (48) solid angle k k L t.i .t., m n n nb p p(z) R wave vector unit vector in wave direction 
length length dimensions of the surface summation index refractive index local surface normal, unit vector 
bisecting unit vector, equation (51) incident polarization state vector, equation (34) Gaussian distribution 
function, equation (3) distance from origin to field point a b bd dd p r s sp ud Subscripts ambient bisecting 
bidirectional directional-diffuse incident p polarization reflected s polarization specular uniform-diffuse 
R r S position al vector to field point positional vector of a surface point shadowing function , equation 
(23) X, Y,z 1,2 Cartesian coordinates surface points 8,ft f' v s and p polarization unit vectors transformation 
matrix, equation (39) wave vector change, equation (20) n * Superscripts local plane complex conjugate 
 Table 1: Nomenclature 2 Theory of light reflection of surface reflection models, known as "physical 
or wave optics" models, to be derived [5]. "Physical optics" uses a complete phys­This section introduces 
the principal techniques often used to an­ical or wave description of the reflection process, thus allowing 
for alyze the reflection of an electromagnetic wave by a general sur­diffraction and interference effects. 
Wave effects must be included face [3] [5]. The improved model presented later in this paper uses if 
a reflection model is to describe both specular and diffuse-like all of these techniques. reflection 
from a surface. 2.1 Kirchhoff theory Consider the geomet ry sketched in Figure 2. According to classical 
electromagnetic theory, the scalar electromagnetic field E(R) at an arbitrary point in space can be expressed 
as a function of the scalar field E; and its normal derivati ve oE s/ on on any enclosing surface r. 
The governing equation is [5] E(R) = J... r (Es(i) oG'(R ,i) _ G' (R ,i) OEs(i») dr (I) 411" } r on on 
where G' is the free space Green' s function given by [12]  (2) Equation (1) is an integral representation 
of the wave equation and is known as the Kirchhoff integral of scalar diffraction theory. For a single 
reflecting surface, the domain of integration r re­duces to the area of the reflecting surface. This 
has allowed a class 2.2 Tangent plane approximation For reflection processes, the Kirchhoff formulation 
reduces the gen­eral problem of computing the field everywhere in space to the sim­pleroneofdetermining 
thefieldonthereflectingsurface. However, even this is a complex task, and the so-called "tangent plane 
approx­imation" is often used. This is done by setting the value of the field at a given point on the 
surface to be the value that would exist if the surface were replaced by its local tangent plane. This 
is sketched in Figure 3 where E, and E; are the incident and scattered fields, respectively, and F(8) 
is the local Fresnel (electric field) reflection coefficient. The approximation is valid when the local 
radius of curvature of the surface is large compared to the wavelength. The reflected field depends on 
the Fresnel reflection coefficients for hor­izontal and vertical polarizations, as well as on the local 
slope and position of the reflecting point.  2.3 Statistical surfaces The complete geometrical specification 
of a reflecting surface is rarely known, but information at length scales comparable to the radiation 
wavelength is required when the Kirchhoff theory is used. However, small scale variations of the electromagnetic 
field on the surface areaveraged out whenviewed from adistance. This averag­ing over points on a surface 
is statistically equivalent to averaging over an entire class of surfaces with the same statistical description. 
Interesting quantities , such as the reflected intensity in a given di­rection, can then be obtained 
by a weighted average of the Kirchhoff integral. Frequently, the height distribution on a surface (Figure 
3) is as­sumed to be Gaussian and spatially isotropic. Under such condi­tions, the probability that a 
surface point falls in the height range z to z + dz is given by p(z)dz, with a probability distribution 
 (3) A mean value of z = 0 is assumed and ao is the rms roughness of the surface. To fully specify an 
isotropic surface a horizontal length measure is also needed. One such measure is the autocor­relation 
length T (defined in equation (48», which is a measure of the spacing between surface peaks. The rms 
slope of the surface is proportional to ao/ T. 2.4 Shadowing and masking The effect of self-shadowing 
and self-masking by a rough sur­face (Figure 4) was introduced in computer graphics by Blinn [6] and 
Cook [8]. This effect manifests itself at large angles of in­cidence or reflection, where parts of the 
surface are shadowed and/or masked by other parts, reducing the amount of reflection. Beckmann [4] argued 
that to first order, the effect of shadow- Shadowing Masking Figure 4: Shadowing and masking. ing/masking 
can be obtained by using a multiplicative factor which accounts for the fraction of the surface that 
is visible both to the source and the receiver. Such a concept was used by both Blinn and Cook in their 
geometrical optics approaches, but the V-groove shadowing/masking factor they used [20] is first-derivative 
discon­tinuous . Many other shadowing/masking factors have appeared in the literature. Of these, the 
one due to Smith [16] is continuous in all derivatives and has been found to agree with statistical numerical 
simulations of a Gaussian rough surface [7]. 2.5 Discussion An early comprehensive model of light reflection 
from a rough sur­face, using physical optics, was introduced by Beckmann [5]. 'Beck­mann applied the 
scalar form of the Kirchhoff theory, used the tan­gent plane approximation, and performed a statistical 
average over the distribution of heights to get the reflected intensity. The Beck­mann distribution function 
was used by Blinn and Cook for their computer graphics applications. Stogryn applied a more general, 
vector form of the Kirchhoff the­ory, thus taking polarization effects and the correct dependency of 
the Fresnel reflectivity into account [18]. Furthermore, he used a more complete statistical averaging 
scheme that averages over both height and slope. However, shadowing/masking was not consid­ered, and 
the derivation of the reflected intensity was limited to spe­cial cases of incident polarization. A more 
general model, which accounts for polarization, Fresnel, and shadowing/masking effects, has been described 
by Bahar [1] [2]. However, it is difficult to im­plement because it relies on the solution of a set of 
coupled integro­differential equations. Finally, it should be noted that these models were very rarely 
compared with experimental results. 3 An improved model This section presents an improved light reflection 
model of broad applicability. Section 3.1 summarizes the techniques and key as­sumptions; Section 3.2 
presents the improved model. Details of the mathematical derivation appear in Appendix A and a full set 
of equations for unpolarized incident light in Appendix B. 3.1 Techniquesand key assumptions To develop 
a general reflection model which avoids many of the lim­itations of previous models, the overall formulation 
of Beckmann was used, but with the following improvements: The vector form of the Kirchhoff diffraction 
theory is used. This allows, for the first time, a complete treatment of polar­ization and directional 
Fresnel effects to be included. Such SIGGA APH . 91 effects are required for a comprehensive formulation 
. The model permits abitrary incident polarization states (e.g., plane, circular, unpolarized, partially 
polarized, etc.) and includes effects like depolarization and cross-polarization.  The surface averaging 
scheme of Stogryn [18] is employed with its improved representation of the effects of surface height 
and slope. Averaging of the Kirchhoff integral is over a four-fold joint probability function (i.e., 
height, slope, and two spatial points).  The scheme of Stogryn [18] is extended to average only over 
the illuminated (unshadowed/unmasked) parts of the surface. This requires a modified probability function 
with an effec­tive roughness, a , given by equation (53). When roughness valleys are shadowed/masked 
(Figure 4), the effective surface roughness can be significantly smaller than the rms roughness, 0"0, 
especially at grazing angles of incidence or reflection. For the first time, the concept of an effective 
roughness, which de­pends on the angles of illumination and reflection, is applied.  The geometrical 
shadowing/masking factor of Smith [16] is introduced as a multiplicative factor. The function has appro­priate 
smoothness and symmetry.  With the above, the model leads to a fairly-complex integral for­mulation. 
Simplifications result by making the local tangent-plane approximation and assuming gentle roughness 
slopes. These as­sumptions should be realistic for many surfaces over a wide range of radiation wavelengths 
. Significantly, the assumptions lead to an analytical form for the light reflection model. 3.2 The improved 
light-reflection model The light reflection model is presented in terms of the bidirectional reflectivity 
Pbd, also called the bidirectional reflectance distribu­tion function (BRDF). The coordinates are shown 
in Figure 5, to­gether with the propagation unit vectors (ki, kr ) and the polarization unit vectors 
(s, jj) for the polarization components perpendicular (s) and parallel (jj) to the incident and reflecting 
planes (i.e., the (k, z) planes). The total BRDF is defined as the ratio of the total reflected   
z Pr ~~~~~~~~'-----~~ x t.-~ Figure 5: Coordinates of illumination and reflection. intensity (i.e., 
the sum of reflected sand p intensities) in the direc­tion (Or, ,pr) to the energy incident per unit 
time and per unit area onto the surface from the direction (Oi, ,pi) [14]. The incident en­ergy flux 
may be expressed in terms of the incident intensity L. and the incident solid angle dWi:  The BRDF may 
also be defined for each polarization component of the reflected intensity (see Appendix A). Equation 
(4) gives the frequently -used total BRDF. We propose a bidirectional reflectivity consisting of three 
com­ponents: Pbd Pbd,sp + Pbd,dd + Pbd,ud (5) The additional subscripts correspond to specular (sp), 
directional­diffuse (dd), and uniform-diffuse (ud) reflection. Thefirsttwocom­ponents in (5) result from 
the first-surface reflection process (see Figure 1) and are respectively due to specular reflection by 
the mean surface and diffraction scattering by the surface roughness. The third component, taken as uniform 
diffuse, is attributed to multiple surface and/or subsurface reflections. An example of a light intensity 
distribution corresponding to equation (5) is shown in Figure 6. A general reflecting surface is 1---. 
Ideal specular ~Directional diffuse Ideal diffuse Figure 6: Example of a light intensity distribution. 
 assumed, with some specular reflection, some diffraction scatter­ing due to roughness, and some multiple 
or subsurface scattering. The specularly-reflected part is contained within the specular cone of reflection. 
The diffraction-scattered part shows a directional dis­tribution which is far from ideal diffuse. The 
last part is uniform diffuse (Lambertian). An analytic form for the first two terms in (5) is derived 
in Ap­pendix A. With the local-tangent-plane and gentle-slope assump­tions for the first-surface reflection 
process, and for arbitrary inci­dent polarization, we have: Pbd,sp ps (6) Pbd,dd (7) Pbd,ud a().) (8) 
 where Ps is the specular reflectivity of the surface, l.!. is a delta func­tion which is unity in the 
specular cone of reflection and zero other­wise, 1F1 2 is the Fresnel reflectivity which depends on the 
index of refraction (ft().» of the surface material [14, p.100J, 9 is a function of the effective surface 
roughness given by (9) S is the shadowing function (see equation (23», F is a function involving the 
Fresnel reflection coefficients (see equations (68) and (59), (60)), p is the polarization state vector 
of the incident light (see equation (34)), Vx y is a function which depends on the illumination and reflection 
angles (see equation (20)), and a(-\) is a parameter to be discussed later.  For convenience and for 
the special case of incident unpolarized light, the governing equations are gathered together and presented 
in Appendix B. The directional-diffuse term in this appendix (equation (71)) uses nomenclature to permit 
comparison with the geometric optics model of Cook-Torrance [8]. The physical basis of the three reflection 
components in (5) is discussed in the following subsections. Before proceeding, we note that the dependence 
of the specular component on dWi drops out if equation (5) is converted to an intensity basis by multiplying 
by I, cos ()idwi. From (6), the specular term becomes PsIi~, which is the well known form used in Ray-tracing. 
The specular intensity is then independent of dWi' but the directional-diffuse and uniform­diffuse intensities 
are proportional to dWi. 3.2.1 Specular contribution: Pbd,sp The specular term accounts for mirror-like 
reflection from the mean plane of the reflecting surface. The term is proportional to the Fres­ 2 nel 
or mirror reflectivity, IF1 For rough surfaces, the specular term is reduced by the roughness and shadowing 
factors e-9 and S, re­spectively. For a smooth surface, as the wavelength of the incident light be­comes 
large relative to the projected surface roughness, i.e., -\ » a cos ()i, the specular term is not attenuated 
since 9 -4 0and S -4 1. Also in this limit, the specular component dominates the first-surface reflection 
process, since the contribution from equa­ tion (7) diminishes as 9 O. For smooth surfaces, equation 
(6) reduces to (10) which is the usual form of the bidirectional reflectivity for a specular surface. 
 3.2.2 Directional diffuse contribution: Pbd,dd When the wavelength of the incident light is comparable 
to or smaller than the projected size of surface roughness elements (i.e., -\ f'V a cos ()i), the first-surface 
reflection process introduces diffrac­tion and interference effects. The reflected field is spread out 
to the hemisphere above the reflecting surface. We call this directional diffuse, to indicate that the 
field is diffused to the hemisphere but may have a directional, nonuniform character. The reflected light 
pattern given by equation (7) depends on sur­face statistics through the effective roughness a and the 
autocorre­lation length T. For smooth surfaces, as a / -\ or 9 approach zero, the bidirectional reflectivity 
given by equation (7) diminishes to zero. For rough surfaces, with a / -\ or 9 large, equation (7) describes 
the directional distribution of the first-surface reflected light. The re­flected pattern can be complex 
with maximal values in the specular direction for slightly rough surfaces, at off-specular angles for 
inter­mediate roughnesses, or at grazing reflection angles for very rough surfaces. 3.2.3 Uniform diffuse 
contribution: Pbd,ud The light reflected by multiple surface reflections or by subsurface reflections 
is generally more difficult to describe analytically than light reflected by the first-surface reflection 
process. This contribu­tion is small for metallic (opaque) surfaces with shallow roughness slopes. However, 
the contribution can be important for surfaces with large slopes, or for nonmetals if significant radiation 
crosses the first surface and is reflected by subsurface scattering centers (e.g., paints, ceramics, 
plastics). Estimates of the multiple-reflection process within surface V-grooves, based on geometrical 
optics, have been carried out [10] [17]. Also, estimates of the subsurface scattering are avail­able 
[14]. The analytical results often suggest that the reflected field due to these two processes may be 
approximated as nearly direction­ally uniform. Therefore, the multiply-reflected and/or subsurface scattered 
light is approximated as uniform-diffuse (i.e., Lambertian), and we denote it by a(-\). The coefficient 
a(-\) can be estimated theoretically if the V­groove geometry is applicable, or if the subsurface scattering 
param­eters are known. Alternatively, a(-\) can be estimated experimen­tally if equation (5) is integrated 
over the reflecting hemisphere, and the results are compared with measured values of the directional­hemispherical 
reflectivity, Pdh. This reflectivity is equal to the hemispherical-directional reflectivity Phd (for 
the case of uniform incident intensity [14]), and which can be easily measured using an integrating sphere 
reflectometer. For the present paper, in the ab­sence of additional surface or subsurface scattering 
parameters, or experimental measurements, we will treat a(-\) as a constrained, but otherwise free, parameter. 
The constraint is based on energy con­servation and gives an upper bound for a(-\). 3.3 Discussion 
The theoretical model described by equation (5) allows specu­lar, directional-diffuse, and uniform-diffuse 
reflection behavior as sketched in Figure 6. The governing equations in general form are given in equations 
(5) to (8) and Appendix A, or for unpolarized incident light in Appendix B. The actual reflection patterns 
depend on wavelength, incidence angle, surface roughness and subsurface parameters, and index of refraction. 
The model provides a unified approach for a wide range of materials and surface finishes, and is in aform 
suitable for use in computer graphics. 4 Comparison with experiments In this section we compare the 
reflection model with experimen­tal measurements. Appropriate comparison experiments appear only infrequently 
in the literature, since well-characterized sur­faces as well as good wavelength and directional resolution 
are required. The measurements selected for comparison consist of BRDF's for roughened aluminum [19], 
roughened magnesium ox­ide ceramic [19], sandpaper [9], and smooth plastic [11]. The com­parisons cover 
a wide range of materials (metallic, nonmetallic) and reflection behavior (specular, directional diffuse, 
uniform diffuse). Polar comparisons are presented in Figures 7 to 10. Results are shown in the plane 
of incidence; the polar angle is ()r and the curve parameter is the angle of incidence ()i. Theoretical 
predictions are shown with solid lines and experimental measurements with dashed lines. The polar radius 
is the BRDF normalized with respect to the specular reflecting ray direction, i.e., Pbd«()i, 0; ()r, 
cPr) (11) Pbd«()i, 0; ()i, 0) Results for an aluminum surface (very pure; measured rough­ness: ao' = 
0.28j.lm) are shown in Figures 7 and 8, respectively, for wavelengths of -\ = 2.0j.lm and 0.5j.lm. These 
figures illus­trate the effects of wavelength and incidence angle. The autocor­relation length and measured 
hemispherical reflectances were not reported. Therefore, values of T = 1.77urri and a(-\) =0 were se­lected 
as best fits at both wavelengths. Several points can be noted. SI GG RAPH. 91  Figure 7: Normalized 
BRDF's of roughened aluminum as ob­tained from theory (solid lines) and experiment (dashed lines) for 
incidence angles of ()i = 10°, 45°, and 75°. A = 2.0/-tm. This is the same surface as in Figure 8. The 
surface shows strong specular reflection at this wavelength . Figure 9: Normalized BRDF's of roughened 
magnesium ox­ide ceramic as obtained from theory (solid lines) and experi ­ment (dashed lines) for incidence 
angles of ()i = 10°,45°,60°, and 75°. A= 0.5/-tm. The surface shows strong uniform dif­fuse and emerging 
specular reflection. When 0"0 is small compared to A, as in Figure 7, strong specular re­flection occurs. 
The angular width of the measured specular peak is determined by the solid angles of incident and received 
light in the experiments (dWi = dco; = 11"/1024). To allow comparisons, the theoretical peaks have been 
averaged over the same solid an­gles. For incidence at ()i = 10°, the reflected pattern displays both 
specular and directional diffuse components. In Figure 8, when the roughness is more comparable to the 
wavelength, a strong direc­tional diffuse pattern appears , and for ()i = 10°, 30° ,45°, and 60°, thereflectedintensityismaximal 
atlarger-than-specularangles.For ()i = 75°, a specular peak emerges as the surface appears somewhat smoother 
to the incident radiation. A comparison with a magnesium oxide ceramic (very pure; mea­sured roughness 
: 0"0 = 1.90/-tm, but model best fit 0"0 = 1.45/-tm) at A =0.5/-tm is displayed in Figure 9. This surface 
shows nearly uniform diffuse behavior at ()i = 10° and an emerging specular peak for larger values of 
()i. The model employed best-fit parameters of 7= 13.2/-tm and a(A) = 0.9, the latter expressing the 
relatively stronger role of subsurface scattering as compared to the aluminum surface. Significantly, 
the experimental and theoretical trends in Figures 7 to 9 for both the metal and the nonmetal are in 
qualitative accord . Importantly, both materials display an emerging specular peak as the angle of incidence 
is increased, and, for the metal, as the wavelength is increased. Further, the metal shows a strong di­rectional 
diffuse pattern, and the nonmetal a strong uniform diffuse 180 Figure 8: Normalized BRDF's of roughened 
aluminum as ob­tained from theory (solid lines) and experiment (dashed lines) for incidence angles of 
()i = 10°, 30°, 45°, 60°, and 75°. A= 0.5/-tm. This is the same surface as in Figure 7. The surface shows 
strong directional diffuse and emerging specu­lar reflection at this wavelength. pattern, both of which 
are in accord with the model. A dramatically different reflection pattern is displayed in Fig­ure 10, 
corresponding to 220 grit sandpaper at ()i = 0° and A = O.55J.Lm. Parameters used for the comparison 
are 0"0/7 = 4.4 and a(A) =O. For very rough surfaces, only the ratio 0"0/7 is required , not 0"0 and 
7 separately [5]. Although the large ratio of 0"0/7 chal­lenges the gentle slope assumption of the model, 
the agreement be­tween experiment and theory is striking as both display large re­flected intensities 
at grazing angles of reflection. A comparison of experiment and theory in terms of absolute BRDF's is 
shown in semilog form in Figure 11 for a smooth blue plastic at A = 0.46/-tm. The shape of the specular 
spikes is deter­mined by the geometry of the incident and receiving optical systems . The distributions 
for four incidence angles reveal a linear combina­tion of specular and uniform diffuse behavior. This 
is consistent with the model (equations (5) to (8». For a smooth surface with 0"0 = 0, the directional-diffuse 
term drops out and the specular term reduces to equation (10). The directional-hemispherical reflectiv­ity 
at ()i =0° and A= 0.46/-tm was measured (Pdh = 0.195) and yields the value a(A) = 0.15 used for the uniform 
diffuse term in the model. The agreement between experiment and theory in Figure 11 in terms of shape 
and absolute magnitude is encouraging. In conclusion, the experimentally-measured directional distribu­tions 
in Figures 7 to 11 show a wide range of behavior and com­plexity. The present model describes the major 
features of the dis­ I I 6iJ ~ Computer Graphics, Volume 25, Number4, July 1991 100 10 1 - , , ' 1\\, 
,:''A:'' , ,n , , , ,  1\: :: II II , II II !( ,,, , , " ' '. I ~  J\fl ,I ", , , ,, . , .t -,, J, 
...<'_ ~ . . .J  -90 -60 -30o 30 60 90 6 r Figure 11: Absolute BRDF's for smooth blue plastic as obtained 
from theory (solid lines) and experiment (dashed lines) for inci­dence angles of ()i = 15°, 30°, 45°, 
and 60°. )" = 0.46p,m. This surface shows a typical smooth plastic reflection pattern with com­bined 
specular and uniform diffuse behavior. tributions . 5 Example scenes The reflection model described by 
equations (5) to (8) can be in­corporated in ray-tracing or extended radiosity [15] methods. We have 
employed ray tracing. A single reflected ray is used together with ambient and point source illumination 
. The reflected intensity is given by Nl 2 Ir ()") L {IF«()i)1 e -9i . S . LX + [(Pbd ,dd)i + a(),,)] 
i= J . cos ()i . dWi} . I i( ),,) + Phd(),,) . I a ( )") (12) where NI is the number of light sources, 
subscript i denotes the ith light source, the terms inside the braces respectively correspond to the 
three terms in equation (5), Phd(),,) is the hemispherical­directional reflectivity of the surface (taken 
as a function of )" only, and found from experiment or by integrating (5) over the inci­dent hemisphere), 
and I a is the uniform ambient illumination . The directional-diffuse term is included only for light 
sources. To in­clude a directional-diffuse term from the environment, a distributed ray-tracer or an 
extended radiosity method [15] must be employed. Figure 12 displays six aluminum cylinders in front of 
a brick wall. Each cylinder is rendered in isolation. Cylinders (a) to (f) are in order of increasing 
surface roughness. Other parameters are T = 3.0p,m for cylinders (a) to (e) and T = l6 .0p,m for cylinder 
(f), and a(),,) = O. Note that the sharp specular image in the top faces of the cylinders diminishes, 
but is not blurred, with increasing surface roughness , and the image of the light source on the front 
ver­tical face spreads out. These are characteristics, respectively, of the specular and directional 
diffuse terms in the reflection model that are derived from physical optics. Note also that the apparent 
rough­ness of a given cylinder varies with viewing angle. The top and lat­eral edges can appear specular 
or nearly specular at grazing angles, even when the vertical face on the front side appears to be rough. 
A slight color shift is also apparent for a given rough surface (i.e., as )"in (TO I)" varies). For visible 
light, this is most apparent in the blue shift on the front faces of the cylinders. The enhanced red 
shift of the specular images is not so apparent. Clearly, the specular and directional diffuse terms 
of the model vary with wavelength , inci­dence angle, and roughness, and are responsible for the realism 
of the cylinders in Figure 12. The aluminum cylinders (a) to (c) in Figure 13 illustrate limiting cases 
of each of the three terms in the reflection model. Cylinder (a) in Figure 13 is the same as cylinder 
(f) in Figure 12. Cylinder (b) is a smooth cylinder described by the specular term, in which the reflectance 
is a function of incidence angle according to the Fres­nel reflectivity. Specular images are apparent 
on the top and lateral edges. (To emphasize the specular images, we have set the ambient illumination 
term to zero in rendering cylinder (b).) Cylinder (a) represents the directional diffuse term in the 
limit of (TO I)" -+ CXJ with (ToiT fixed at 0.16 (i.e., a limiting form for very rough sur­faces). Cylinder 
(c) is ideal diffuse and is described by the uniform diffuse term. Note the striking differences between 
the three cylin­ders. Figure 14 illustrates a scene consisting of a rough aluminum cylinder «(TO = 0.18p,m, 
T = 3.0p,m, a(),,) = 0), a rough copper sphere «(TO =0.13p,m, T = 1.2p,m, a(),,) =0), and a smooth plastic 
cube «(TO =0, T =2.0p,m, a()" =0.55p,m) =0.28), all resting on a rough plastic table «(TO =0.20p,m, T 
= 2.0p,m, a()" = 0.55p,m) = 0.28). The cube and table have the same Fresnel reflectivity. Several effects 
can be noted in Figure 14. On the faces of the cube, the specular image varies with reflection angle, 
an effect caused solely by the Fresnel reflectivity 1F12 in equation (6). The specular images on the 
table top also vary with reflection angle (and disappear), but this is caused mainly by roughness effects 
(i.e., e-g) in equation (6). The cylinder in Figure 14 corresponds to cylin­der (a) in Figure 12 and 
displays some of the specular and direc­tional diffuse characteristics of that image. Figure 14 gives 
a hint of the comprehensiveness of the light re­flection model derived in this paper. Several materials 
of different roughnesses appear. A given surface can display specular or diffuse­like behavior depending 
on reflection angles and surface properties . Specular images appear or disappear based on correct physical 
prin­ciples . The high level of realism in Figure 14 is due to a physically ­correct treatment of specular, 
directional diffuse, and uniform dif­fuse effects by the reflection model. 6 Conclusions 1. The general 
reflection model given by equations (5) to (8), in a single formulation, describes specular, directional 
diffuse, and uniform diffuse behavior. For unpolarized incident light, the model reduces to the form 
given in Appendix B. All of the parameters of the model are physically based. 2. The model compares 
favorably with experimental measure­ments of reflected radiation for metals, nonmetals, and plas­tics, 
with smooth and rough surfaces. 3. The model accurately predicts the emergence of specular re­flection 
with increasing wavelength or angle of incidence, or decreasing surface roughness . 4. The model predicts 
a directional-diffuse pattern which can have maximal values at specular, off-specular, or grazing an­gles, 
depending on surface roughness. 5. The model is in analytical form and can improve the realism of synthetic 
images. 6. The model can be employed for ray-tracing or extended ra­diosity [15] methods.  181 SI6GRAP 
H. 91 7. The model highlights the need for tabulated databases of pa­rameterized bidirectional reflectivities. 
The parameters in­clude two surface roughness parameters (0"0, T), the index of ref~action (as a function 
of wavelength), and the constrained parameter a(A). The latter can be inferred from measured hemispherical 
reflectivities . In conclusion, the reflection model is comprehensive, physically­based, and provides 
an accurate transition from specular to diffuse­like reflection. Further, the model is computable and 
thus useful for graphics applications. (a)O"o =2.5 (b)O"o = 0.0 (c) diffuse Figure 13: Aluminum cylinders 
in extreme limiting cases. Each cylinder corresponds to one of the three terms in the reflection model. 
0"0 is in urn, (a) Directional diffuse reflection; (b) Ideal specular reflection; (c) Uniform diffuse 
(Lambertian) reflection. Acknowledgments We acknowledge the support of the National Science Founda­tion 
under a grant entitled "Interactive Input and Display Tech­niques" (CCR8617880) and the Hewlett-Packard 
Corporation and the Digital Equipment Corporation for generous donations of equip­ment. The authors are 
indebted to many individuals, including Kevin Koestner and Lisa Maynes for early work on a reflection 
model, to Xiaofen Feng and Professor John Schott of the Rochester Institute of Technology for providing 
access to their laboratory and to unpublished data, to Stephen Westin for preparing some of the di­agrams, 
to Ted Himlan, Michael Monks, and Jim Arvo for helpful Figure 14: A general scene with metallic and plastic 
objects in the foreground , with smooth and rough surfaces . The specular images in the smooth plastic 
box vary with incidence angle due to the Fres­nel effect, In the table top, the decay of the specular 
images with reflection angle is due to roughness . In the rough metallic surfaces , the glossy highlights 
result from directional diffuse reflection. discussions, and to Emil Ghinger for photographing the raster 
im­ages. We thank the reviewers for their extensive and constructive comments which have helped to clarify 
a difficult paper. References [1] Bahar, E. and S. Chakrabarti. "Full wave theory applied to computer-aided 
graphics for 3-D objects ," IEEE Computer Graphics and Applications, 7(7), 1987, pages 46-60. [2] Bahar, 
Ezekiel. "Review of the full wave solutions for rough surface scattering and depolarization," Journal 
ofGeophysical Research, May 1987, pages 5209-5227. [3] Bass, EG. and LM. Fuks. Wave Scattering from Statistically 
Rough Surfaces, Pergamon Press, 1979. [4] Beckmann, Petro "Shadowing of Random Rough Surfaces," IEEE 
Transactions on Antennas and Propagation, May 1965, pages 384-388. [5] Beckmann, Petr and Andre Spizzichino. 
The Scattering of Electromagnetic Waves from Rough Surfaces, Pergamon Press, 1963. [6] Blinn, James F. 
"Models of Light Reflection for Com­puter Synthesized Pictures," Computer Graphics, 11, 1977, pages 192-198. 
(Proceedings SIGGRAPH '77.) [7] Brockelman, R. A. and T. Hagfors. "Note on the Effect of Shadowing on 
the Backscattering of Waves from a Random Rough Surfaces," IEEE Transactions on Antennas and Prop­agation, 
AP-14(5), September 1966, pages 621-629. [8] Cook, Robert L. and Kenneth E. Torrance. "A Reflectance 
Model for Computer Graphics," ACM Transactions on Graph­ics, 1, 1982, pages 7-24. [9] Feng, Xiaofen. 
Comparison ofmethods for generation ofab­solute reflectance factors for BRDF studies, Master's thesis, 
Rochester Institute of Technology, 1990. [10] Hering, R.G. and T.F. Smith. "Apparent radiation properties 
of a rough surface," Application to Thermal Design ofSpace­craft, 23, 1970, pages 337-361. [11] Himlan, 
Theodore H., Michael C. Monks, Stephan H. Westin, Donald P. Greenberg, and Kenneth E. Torrance. "Physical 
measurement Techniques for Improving and Evaluating Com­puter Graphic Simulations.," 1991. (To be published.) 
[12] Jackson, John D. Classical Electrodynamics, John Wiley &#38; Son Inc., 1975. [13] Phong, Bui Tuong. 
"Illumination for Computer Generated Pictures," Communications of the ACM, 18(6), June 1975, pages 311-317. 
[14] Siegel, Robert and John R. Howell. Thermal Radiation Heat Transfer, McGraw-Hill book Company, 2nd 
edition, 1981. [15] Sillion, Francois, James Arvo, Stephen Westin, and Donald P. Greenberg. "A Global 
Illumination Solution for General Re­flectance Distributions," Computer Graphics, 25(4), August 1991. 
(Proceedings SIGGRAPH '91 in Las Vegas.) [16] Smith, Bruce G. "Geometrical Shadowing of a Random Rough 
Surface," IEEE Transactions on Antennas and Prop­agation, AP-15(5), September 1967, pages 668-671. [17] 
Smith, T.F. and K.E. Nichols. "Effects of polarization on bidirectional reflectance of a one-dimensional 
randomly rough surface," Spacecraft Radiative Transfer and Tempera­ture Control, 83, 1981, p~ges 3-21. 
[18] Stogryn, Alex. "Electromagnetic Scattering From Rough, Finitely Conducting Surfaces," Radio Science, 
2(4), 1967, pages 415-428. [19] Torrance, K.E. and E.M. Sparrow. "Off-Specular Peaks in the Directional 
Distribution of Reflected Thermal Radiation," Journal of Heat Transfer Transactions of the ASME, 1966, 
pages 223-230. [20] Torrance, K.E. and E.M. Sparrow. "Theory for Reflection from Roughened Surfaces," 
Journal Society ofAmerica, 57(9), September 1967, pages A Appendix: Derivations A.l Reflected intensities 
The reflected intensities for the s and p components of polarizations are given by [14][18] R2 A· cos 
R2  A· cos where the coordinates are as shown in Figure 5, ErCR) is the re­flected field in vector 
form, R is the distance from the origin to an arbitrary point in space, A is the area of the reflecting 
surface projected on the x-y plane, and sr, Pr are unit polarization vectors, given by i; x2 Sr x 21 
Pr sr x kr (14) which are normal and parallel, respectively, to the plane formed by the viewing direction 
and the mean surface normal. The symbol < > denotes an average over the joint probability distribution 
function of the random rough surface characterized by z =e(x, y). (15) The reflected field can be expressed 
in terms of the scattered field on the surface by using the vector form of the Kirchhoff diffraction 
theory [12]: ikR e (1-krkr) . 1{-ikr x uts x n) -(\7 x is) x ii} zr (16) where ki, kr are wave vectors 
in the incident and reflection direc­ tions, \k \= 21r/ A is the wave number, r is the position vector 
for a point on the surface, and the tensor I -krkr = srsr + PrPr is introduced to to make the reflected 
field transverse. Substituting (16) into (13), we have dIs  < 11 {ikPr .(Es x n) + sr. [(\7 x Es) x 
na} dr\2 > .u, 1  < 11 {iksr .(Es x n) -Pr . [(\7 x Es) x n]} dr\2 > (17) To evaluate the right side 
of (17), the surface element dr is ex­pressed in terms of the planar surface area dA = dx . dy by dr 
=dA/(n . 2) (18) Further, the squares of the absolute values of the integrals in (17) can be expanded 
in terms of double surface integrals. We find  SIGGRAPH 91 <1dA\ 1dA2e-iii.(1'\-T2) . (e-iki'T\ {h) 
(e-iki'T2{h) * /(n\ . z)(n2' z) > (19) where v is the wave vector change v=k(kr -ki ), (20) * denotes 
a complex conjugate, {} refers to the terms in braces in (17), and the subscripts refer to points on 
area elements dAI and dA2. The <> in (19) commutes with the surface integral and a term of the form < 
e -iiJ·z(et-ez){}l{}i /(nl . z)(n2 . z) > (21) results. Since the surface is assumed to be isotropic 
and stationary, (21) is a function only of Xl X2 and YI Y2. Thus, by making the change of variables I 
X = Xl -X2 X " = X2 y' = YI Y2 y" = Y2 (22) the integrals over x" and y" may be carried out separately 
to give a factor S . A, where S is the fraction of the surface that is both il­luminated and viewed and 
represents the shadowing function given by [16]: (23) where 1 T cot Oi (1 '2erfc( ~))/(A(cotOi) + 1) 
1 TcotO r (1 '2erfc( ~))/(A(cotOr ) + 1) (24) and 1(2 0"0 T cot 0) A(cot 0) = -2 ~/2' erfc(-2--) (25) 
1r T cot 0"0 Hence, the reflected intensities in (17) are S ----[+:[:dx'dy' e-iii·;;B. (26) cos S ----1+00 
1+00 dx'dy' e-iii·;;e, (27) cos -00 -00 where if= x'x + y'y (28) and (29) where T( A A) -iki .(rt-rz)/ 
( A A)( A A) .r n I ,n2 s = e n I. Z n2' Z . ({ikPr' eEs x n)+Sr' [(\7 x Es)x n]})l . ({ikPr' (Es x n)+Sr' 
[(\7 x Es) x n]})~ (30) . z)(n2 ·2) Pr . [(\7 x Es) x n]})I . [(\7 x Es) x n]})~ (31) The functions 
B; and Bp in (29) depend only on x' and y'. No­tice that dl; and dIp are the s and P polarized reflected 
intensities, respectively. The total reflected intensity, as used in equation (4), is given by (32) 
A.2 Tangent plane approximation The reflected intensities in (26) and (27) are expressed in terms of 
the scattered field Es on the surface. In tum, Es depends on the incident field, and may be related to 
the incident field by using the local tangent plane approximation. For the case of a unidirectional incident 
field, we have Eoeiki·rp (33) p CsSi+ CpPi (34) where Eo is the wave amplitude, p is the polarization 
state vector of the incident radiation, Cs,cp are called the polarization coefficientsI, and Si ,Pi are 
unit polarization vectors with respect to the plane of incidence (ki, z). The unit vectors are given 
by ki X 2 Si x 21 Pi Si x ki (35) Equation (33) can be written in the more compact matrix form (36) 
Si, Pi decompose into incident local polarization unit vectors si, pi with respect to the local incident 
plane (ki ,n), given by An xn s, X nl An Pi si X ki (37) Therefore, (38) where Tin is the transformation 
matrix from incident coordinates to local coordinates (39) Substituting (38) into (36), we have the incident 
field in terms of An An s; ,Pi as (40) Reflections of the si,pi fields are found from the local Fresnel 
re­flection coefficients for each component of polarization, i.e., si ---+ r.. s~ (41) pi ---+ Fp ' P~ 
 I For example: for s polarization, Cs = 1.0, cp =0; for p polarization, c, =0, cp = 1. ~~ Computer Graphics, 
Volume 25, Number 4, July 1991 where F, and Fp are the Fresnel reflection coefficients for s and p polarizations, 
respectively [14, p.l00]. The unit vectors s~, p~ are the local polarization unit vectors for reflection 
from the tangent plane: An kr X ii Sr (42) xnl An Pr s~ X kr where kr is the unit vector in the specular 
direction from the tangent plane, given by (43) Using the Fresnel matrix  (44) we have in more compact 
form  (45) From equations (40) and (45), the scattered field on the surface can be expressed as a linear 
combination of the Fresnel reflection coefficients ). (46) The scattered field is a function of the 
incident polarization state, the local surface normal ii, the Fresnel reflection coefficients F; and 
Fp of the surface, and the incident and reflection directions ki,kr . A.3 Representation of the surface 
 Specification of the surface topography is required to carry out the surface integrals and surface averages 
appearing in equa­tions (26), (27) and (29). Without losing generality, we assume the surface to be Gaussian 
distributed [5], i.e., we assume the surface height in (15) to be a stationary normally distributed random 
process whose mean value is zero. In addition we assume the surface to be directionally isotropic. An 
appropriate two-point joint probability function is given by exp  (47) 2 where r= (XI-X2)2+(Yl -Y2)2, 
0"5 is the variance of Zl = e(Xl, Yl) and Z2 = e(X2, Y2), and G(r) is the correlation coefficient, which 
is assumed to be [5] 2 r G(r) = e -:;:2 (48) where 'T is the autocorrelation length. The parameters 
0"0 and 'T are the only two surface parameters required for the surface integrations. A.4 Analytic evaluation 
of the integrals Substituting (46) into (29) to (31), Bs and Bp are expressed in terms of known quantities 
and depend on the surface only through the nor­mals nl and n: at two surface points. Further, the integrals 
in equa­tions (26) and (27) can be written as: +00 1+00 e-iv-if <  1-00 -00  (49) Stogryn [18] has 
shown that an integral and average of the form in (49) can be approximatly evaluated under either of 
the following two conditions: the surface is very rough (i.e., (v zO")2 » 1)  the surface has gentle 
slopes (i.e. (%) « 1)  As a result, (49) reduces to  +00 1+00 -6) > dxdy F(nb, nb,p). -00 < -00 1 
(50) where F is evaluated at nb,which is the unit vector bisecting ki and t.; given by (51) Furthermore, 
the <> in (50) can be shown to be [5]:  (52) where G(T]) is given by (48). Note that 0" in (52) is 
the effective surface roughness, not 0"0. This is because the surface averaging is carried over illuminated 
and visible parts only. 0" is given by [4]: (53) where Zo depends on ()i, and ()r and is the root of 
the following equation -z = O"oK· exp(--)  {f z2 2 20"5 and K «.» «, 1 'T -tan ().. erfc(-cot ().) 
4 20"0 1, 1, 1 'T 4: tan ()r . erfc( 20"0 cot ()r) The double integral in (50) can be evaluated analytically 
[5]: +00 1+00 N 1-00 -00 00  2L: 22/ 1f'T " exp (-vxy'T 4m) m.·m m=l   SIGGRAPH' 91 where L y are 
the dimensions of the reflecting surface. Since we are only interested in cases when Lx, Ly » ,x, the 
first term is nonzero only in the specular direction and zero otherwise. For the case of unidirectional 
incidence with solid angle dWi and Lx, Ly » ,x, the averaged form of the first term in (56) is A· sinc2(vxLx)sinc2(vyLy) 
(21T,X)2. ~/(dWi . cos Or) (57) Hence, (56) becomes Ne -g . (21T ,X)2 . ~/(dWi . cos Or) + 2/4m) ~, . 
exp(-V;y7(58) L...t m.·m rn=1 Next, F, and Fp in (30) and (31) are evaluated. First, nl, n2 are replaced 
by rib defined in (51). Then they are substituted into (30) and (31). After lengthy vector manipulations, 
we find F(nb, nb, p), 8 ·lcsMss + cpMspl2 (59) F(nb, nb, p)p 8 ·lcsMps + cpMppl 2 (60) where (Fs(Pi . 
k r)(Pr . ki) + Fp(Si . i; )(sr . ki)) (61)  (Fs(Si . kr)(Pr . ki) -Fp(Pi . i;)(Sr . ki)) (62) (Fs(Si 
. t;)(sr . ki) + Fp(Pi . i; )(Pr . ki)) (63) (Fs(Pi . k r)(sr . ki) Fp(Si· t;)(Pr . ki)) (64) 21T 2 (65)8 
 (T) . A A (A Ikr x k; 1 4 z· (kr- The Fresnel reflection coefficients F; and Fp in (61) to (64) are 
evaluated at the bisecting angle given by cos-1 (I kr -ki 1/2). Using (59)-(65) and (58) in (26) and 
(27), we find an analytical expression for the reflected intensity cos IEol2 F(AA )N (66) 2 nb,nb,p 
» ' cos Or (41T) where the square of the absolute value of the incident field ampli­ 2 tude, IEo, is 
related to the incident intensity I, by I (67) Note that the right side of (66) has the correct dimensions 
of inten­sity since N has dimension [L2] whereas the F's have dimension [L-2]. Finally, substituting 
(67) into (66) and using (4) and (32), we get exactly the first two terms in (5), given that F(ki, kr, 
p) = F(nb, nb, p)s + F(nb, nb, p)p (68) since the BRDF defined in (4) is the total BRDF, which is the 
sum the BRDF's for the reflected s and p components. B Appendix: Governing equations of the re­flectance 
model for unpolarized incident arbitrarily-polarized incident light. In most applications, however, we 
are only interested in the BRDF for unpolarized incident light. The expressions for the BRDF are greatly 
simplified for this spe­cial but useful case. For convenience, the BRDF equations for un­polarized incident 
light are presented in this appendix. The reader should refer to Figure 5 and the nomenclature list in 
Table 1 for the angular coordinates and other physical parameters that appear in the reflectance model: 
Pbd Pbd (,x, 0"0, 7, fi('x), a('x)) Pbd,sp + Pbd,dd + Pbd,ud (69) .~ Pbd,sp (70) cos IFI 2. G·S·D Pbd,dd 
(71) 1T cos cos Pbd,ud a('x) (72) g.S ps IFI2.e- (73) if in specular cone ~ (74) {~ otherwise 122 _ 
 IFI2 2(Fs + Fp) = f(Oi, Or, n('x)) (75) v·v 1 G (~ ~r . [(Sr· ki)2 + (Pr . ki)2] . Vz [(Si . kr)2 + 
(Pi . k r)2] (76) S S(Oi, Or, 0"0/7) (77) 1T272 D .I: . exp(-V2xy7 2/4m) (78) -m. rn=1 9 [(21T0" /,x) 
(cos Oi+ cos Or)]2 (79) 0" 0"0 . [1 + (ZO )2]-1/2 (80)0"0 0"0 Z5 ~zo 4"(Ki + K r) . exp (-20"5) (81) 
7 Ki tan Oi . erfc( 2 cot Oi) (82) 0"0 7 Kr tan Or . erfc(2cotOr) (83) 0"0 V kr -i; Vxy = (84) ki 
x ii Si fJi = Si X k; (85) x nl' i; x n Sr Pr = Sr x kr (86)  x nl where ii is the index of refraction, 
ps is the specular reflectivity, ~ is a delta function, IFI2 is the Fresnel reflectivity for unpolar­ized 
light [14, p.100] evaluated at the bisecting angle given by cos-1(lkr-ki 1/2), G is a geometrical factor, 
S is the shadow­ing/masking factor given in equation (23), and D is a distribution function for the directional 
diffuse reflection term. together with the defining equations for all to (8) completely define the general 
BRDF for    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122739</article_id>
		<sort_key>187</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[A global illumination solution for general reflectance distributions]]></title>
		<page_from>187</page_from>
		<page_to>196</page_to>
		<doi_number>10.1145/122718.122739</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122739</url>
		<abstract>
			<par><![CDATA[A general light transfer simulation algorithm for environments composed of materials with arbitrary reflectance functions is presented. This algorithm removes the previous practical restriction to ideal specular and/or ideal diffuse environments, and supports complex physically based reflectance distributions, This is accomplished by extending previous two-pass ray-casting radiosity approaches to handle non-uniform intensity distributions, and resolving all possible energy transfers between sample points. An implementation is described based on a spherical harmonic decomposition for encoding both bidirectional reflectance distribution functions for materials, and directional intensity distributions for illuminated surfaces. The method compares favorably with experimental measurements.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[BRDF]]></kw>
			<kw><![CDATA[directional-diffuse]]></kw>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[progressive radiosity]]></kw>
			<kw><![CDATA[specular reflection]]></kw>
			<kw><![CDATA[spherical harmonics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P84841</person_id>
				<author_profile_id><![CDATA[81100402503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fran&#231;is]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Sillion]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P131603</person_id>
				<author_profile_id><![CDATA[81100529394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Arvo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31100375</person_id>
				<author_profile_id><![CDATA[81100345625]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Westin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P68459</person_id>
				<author_profile_id><![CDATA[81100196982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Donald]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Greenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Program of Computer Graphics, Cornell University, Ithaca, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>74342</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Buckalew, Chris and Donald Fussell. "Illumination Networks: Fast Realistic Rendering with General Reflectance Functions," Computer Graphics, 23(3), July 1989, pages 89- 98. (Proceedings SIGGRAPH '89 in Boston.)]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37434</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cabral, Brian, Nelson L. Max, and Rebecca Springmayer. "Bidirectional Reflection Functions from Surface Bump Maps," Computer Graphics, 21 (4), July 1987, pages 273-28 !. (Proceedings SIGGRAPH '87 in Anaheim.)]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael E, Shenchang Eric Chen, John R. Wallace, and Donald P. Greenberg. "A Progressive Refinement Approach to Fast Radiosity Image Generation," Computer Graphics, 22(4), August 1988, pages 75-84. (Proceedings SIGGRAPH '88 in Atlanta.)]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cohen, Michael F., Donald P. Greenberg, David S. Immei, and Philip J. Brock. "An Efficient Radiosity Approach for Realistic Image Synthesis," IEEE Computer Graphics and Applications, 6(3), March 1986, pages 25-35.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808590</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cook, Robert L., Thomas Porter, and Loren Carpenter. "Distributed Ray Tracing," Computer Graphics, 18, July 1984, pages 137-147. (Proceedings SIGGRAPH '84 in Minneapolis.)]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Courant, R. and D. Hilbert. Methods of Mathematical Physics, Interscience Publishers, Inc., New York, 1953.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808601</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Goral, Cindy M,, Kenneth E. Torrance, Donald P. Greenberg, and Bennett Battaile. "Modeling the Interaction of Light Between Diffuse Surfaces," Computer Graphics, 18{3), July 1984, pages 213-222. {Proceedings SIGGRAPH "84 in Minneapolis. )]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>122738</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[He, XiaoDong, Kenneth E. Torrance, Franqois Sillion, and Donald P. Greenberg. "A comprehensive Physical Model for Light Reflection," Computer Graphics, 25(4), August 1991. (Proceedings SIGGRAPH '91 in Las Vegas.)]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97895</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul S. "Adaptive Radiosity Textures for Bidirectional Ray Tracing," Computer Graphics, 24(4), August 1990, pages 145-154. (Proceedings SIGGRAPH '90 in Dallas.)]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Himlan, Theodore H., Michael C. Monks, Stephen H. Westin, Donald P. Greenberg, and Kenneth E. Torrance. "Physical Measurement Techniques for Improving and Evaluating Computer Graphic Simulations" January 1991. (Submitted for publication.)]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15901</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Immel, David S., Michael E Cohen, and Donald P. Greenberg. "A Radiosity Method for Non-Diffuse Environments," Computer Graphics, 20(4), August 1986, pages 133-142. (Proceedings SIGGRAPH '86 in Dallas.)]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15902</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kajiya, James T. "The Rendering Equation," Computer" Graphicsl 20(4), August 1986, pages 143-150. (Proceedings SIGGRAPH '86 in Dallas.)]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Le Saec, Bertrand and Christophe Schlick. "A Progressive Ray-Tracing based Radiosity with General Reflectance Functions," June 1990. (Proceedings of the Eurographics Workshop on Photosimulation, Realism and Physics in Computer Graphics (Rennes, France).)]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325169</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Nishita, T. and E. Nakamae. "Continuous Tone Representation of Three-dimesional Objects Taking Account of Shadows and lnterreflection," Computer Graphics, 19(3), July 1985, pages 23-30. (Proceedings SIGGRAPH '85 in San Francisco.)]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Press, William H., Brian P. Flannery, and Saul A. Teukolsky. Numerical Recipes, Cambridge University Press, New York, 1986.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>77636</ref_obj_id>
				<ref_obj_pid>77635</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Rushmeier, Holly E. and Kenneth E. Torrance. "Extending the Radiosity Method to Include Specularly Reflecting and Translucent Materials," ACM Transactions on Graphics, 9( 1 ), January 1990, pages 1-27.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sillion, Franqois and Claude Puech. "A General Two-Pass Method Integrating Specular and Diffuse Reflection " Computer Graphics, 23(4), August 1989. (Proceedings SIG- GRAPH '89 in Boston.)]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37438</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Michael E Cohen, and Donald P. Greenberg. "A Two-Pass Solution to the Rendering Equation' a Synthesis of Ray-Tracing and Radiosity methods," Computer Graphics, 21(4), July 1987, pages 311-320. (proceedings SIGGRAPH '87 in Anaheim.)]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wallace, John R., Kells A. Elmquist~ and Eric A. Haines. "A Ray Tracing Algorithm for Progressive Radiosity," Computer Graphics, 23(3), July 1989, pages 315-324. (Proceedings SIGGRAPH '89 in Boston.)]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358882</ref_obj_id>
				<ref_obj_pid>358876</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Whitted, Turner. "An Improved Illumination Model for Shaded Display," Communications of the ACM, 23, 1980, pages 343-349.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 A Global Illumination Solution for General Reflectance 
Distributions Fran~ois X. Si!lion James R. Arvo Stephen H. Westin Donald P. Greenberg Program of Computer 
Graphics Cornell Ithaca, Abstract A general light transfer simulation algorithm for environments com­posed 
of materials with arbitrary reflectance functions is presented. This algorithm removes the previous practical 
restriction to ideal specular and/or ideal diffuse environments, and supports complex physically based 
reflectance distributions. This is accomplished by extending previous two-pass ray-casting radiosity 
approaches to handle non-uniform intensity distributions, and resolving all possi­ble energy transfers 
between sample points. An implementation is described based on a spherical harmonic decomposition for 
encod­ing both bidirectional reflectance distribution functions for materi­als, and directional intensity 
distributions for illuminated surfaces. The method compares favorably with experimental measurements. 
CR Categories and Subject Descriptors: 1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism; 
1.3.3 [Com­puter Graphics]: Picture/image Generation. Additional Keywords and Phrases : global illumination, 
BRDF, specular reflection, directional-diffuse, progressive radiosity, spher­ical harmonics. Introduction 
The simulation of global illumination is one of the major require­ments for realistic image synthesis. 
Global illumination effects pro­duced by multiple surface reflections are significant in all but tbe 
simplest environments. For instance, indirect lighting and color bleeding, or the transfer of color by 
reflection, can be observed in almost all indoor scenes. This paper presents a completely general algorithm 
designed to solve the global illumination problem for ar­bitrarily complex reflectance models. Solution 
techniques for the simulation of complex light transfer mechanisms, where every point in the environment 
can potentially act as an illuminator for all other points, have thus far been quite lim­ited. Two major 
paths have been explored. Light can be followed as it leaves the light sources and is propagated and 
reflected throughout the environment. For example, this approach is used by progressive Pcnni\si,m II, 
:I,py wl!htmt Icc all or part of !h]s rna{erial is grwrled providcrt tht[ the copim arc not made or distributed 
for direct cnrnnwrcial advwrt~gc, [hc ACM copyright rrntice and the title of the publication and m daw 
appear. and rro!icc is given that copying is by fwmlssimr <}1Ihc A\soci;il ion f{w C ornpufirrg Machinery. 
Tn copy {~therwiw, or h, rcpuhlish. rcqumesa fee tirrd/orspecific permission !( Iwl ACM-I-X9791-436-WY1!007/0[x7 
w) 7.5 University NY 14853 refinement radiosity algorithms, and can &#38; characterized as view­imiependenf 
shading [3]. Conversely, standard ray tracing [20] and its derivatives usually start from the eye and 
follow light paths in the reverse direction. It is therefore strongly view-dependent. These approaches 
work well for certain typss of reflective behav­iors, such as ideal diffuse (radiosity), ideal specular 
(ray tracing), or combinations of these [ 18, 17, 9]. The actual reflectance distribu­tions of most surfaces 
are far more complicated, exhibiting some directionality which must be taken into account for accurate 
simu­lation. The approach presented here extends the progressive radiosity method to include arbitrary 
reflectance distributions. While previ­ous algorithms incorporating general reflectance have relied upon 
a discrete set of directions [ 1i, 1, 13], no such restriction is intro­duced here. This is accomplished 
by using continuous functions to encode the directional dependence of intensity distributions. In the 
next section we discuss the applicability of \ iew­independent and i ien -dependent approaches to the 
case of general reflectance distributions and introduce a classification of reflectance types into ideal 
diffuse, ideal specular and directional dz~use com­ponents. The third section is devoted to the presentation 
of a com­plete algorithm to solve the general problem. Two specitic issues are then detailed: treatment 
of ideal specular reflection in Section 4, and storage of directional diffuse contributions in Section 
5.  2 Algorithmic choices for a general solution The goal of this research is to develop a method for 
the simulation of global illumination that is general enough to provide accurate solutions for scenes 
incorporating any reflectance distribution, The problems encountered in devising a completely general 
algorithm are reviewed below, together with some of their design implications. 2.1 General reflectance 
distributions The reflective properties of a surface are generally described by means of a bidirectional 
reflectance distribution function (BRDF), which is defined as tbe ratio of the reflected radiance in 
a given outgoing direction to the incoming energy flux (per unit area) in an­other direction. A similar 
quantity is defined for transmission. For the sake of clarity, we will refer only to reflection in this 
paper, al­though the algorithm is equally applicable to transmission. The two we] l-understood limiting 
cases are idea/ d~ffuse and ideal specular reflection. An ideal diffuse reflector has a constant BRDF, 
that is, the scat­tered intensity is the same in all directions. Diffuse reflection can thus be fully 
described by a single scalar value. . An ideal specular reflector has a Dirac delta function as its BRDF, 
where the only direction in which there is non-zero scattering is the mirrored direction. The relevant 
quantity to describe specular reflection is the ratio of the outgoing inten­sity in the specular direction 
to the incoming intensity, or spec­ular re~ectatrce. Most materials have BRDFs that are not this simple, 
exhibiting a more elaborate directionality. Recent work on light reflection mod­els has shown that different 
physical processes contribute to differ­ent parts of a BRDF [8], and the term direcrirmal d@iise has 
been introduced to describe the general BRDF excluding its ideal specu­lar component. (Figure l). e Ideal 
specular Directionaldifluse Ideal diffuse Figure 1: Different components of a general BRDF. The directional 
diffuse component of a BRDF is a function of many variables, includin~ surface finish (roughness), wavelength, 
and ~he electrical propert~es of the material. fiis produces a g~eat variety of behaviors, all of which 
must be correctly simulated. The algorithm presented below is capable of incorporating both arbitrary 
dkectional diffuse and ideal specular reflection into a global solu­tion. 2.2 View-independence vs. 
view-dependence View-independent methods in general require the storage of illumi­nation information 
on the surfaces, both for the purpose of the ilhs­mination computation and for use by a final ]tiew-deperrdent 
display algorithm. In the case of diffuse surfaces, storing a single radiosit y value per wavelength 
channel at each sample point is sufficient, re­sulting in reasonable storage demands. In the same spirit, 
Immel et al, stored the directional information regarding the reflected inten­sity at each point, using 
a discrete set of directions [ 1I]. If, however, the distribution of emitted or reflected light is sharply 
directional, as is the case with specular surfaces, storage becomes unmanageable if accurac y is to be 
maintained. On the ~ iew-dependerrt side, distribution ray tracing [5] uses brute force, tiring many 
reflection rays to simulate complex BRDFs, while path tracing [ 12] follows many paths through the scene 
to ob­tain a statistically reliable estimate. Here again, the property that made standard ray tracing 
[20] computationally tractable disappears (namely the restriction to ideal specular reflection that limits 
the number of rays), as rays must be tired towards all potential illu­minators. The method presented 
below combines elements of both strate­gies into a two-pass algorithm. The first pass computes a view­independent 
solution for the directional diffuse distribution of light, includhtg the effect of intermediate specular 
reflections, and the sec­ond pass supplies the view-dependent ideal specular effects. This partitioning 
of reflectance behaviors resembles earlier two-pass ap­proaches, but now accounts for all possible transport 
chains and in­corporates arbitrary reflectance distributions, not only the extreme cases of ideal diffuse 
and ideal specular. In the following discussion we use the vocabulary of radiosity ­style algorithms 
for two reasons. One reason is the energy consis­tency of the radiosity method: a physical consideration 
necessary .r -., -.+ .. Figure 2: Energy transfer between a patch and a differential area to obtain accurate 
simulations. The second reason is the appeal of the progressive refinement paradigm [3], where useful 
intermediate results can be obtained early in the computation. The notion of radiosity is extended to 
include the directional dif­fuse part of the light reflected at a given point. Because it does not include 
specularly reflected light, this intensity distribution is fairly smooth and thus can be stored at reasonable 
cost (See section 5). The ideal specular distribution of light is sharply discontinuous and is too costly 
to store on the surfaces; it is properly computed on the fly to resolve specular to directional dtfluse 
transfers. By using ray-casting, which has proven to lx an effective sam­pling method to evaluate light 
transfers, all sample points in the en­vironment are considered [19]. Furthermore, the use of ray casting 
imposes no restriction on the geometry of the environment and al­lows every illuminator to be sampled 
adaptively. The algorithm proceeds by successive steps similar to progres­sive radiosity shots , but 
directional intensity distributions are con­tinuously maintained on the surfaces instead of scalar radiosity 
val­ues. The ideal specular contributions to the energy transfers are propagated immediately so they 
need never be stored.  2.3 Energy transfers for non-diffuse surfaces Traditional radiosity methods assume 
an ideal diffuse behavior on all the surfaces, and express the transfers between surfaces by means of 
a form factor [7]. For the general case the amount of light re­flected from a point can be expressed 
as follows. Let us denote by I(TI, ii) the intensity (or radiance, expressed in Watts per unit solid 
angle per unit projected area) leaving a surface at point T!, in the direction of the unit vector d (Figure 
2). The energy dz E emitted by a differential surface area dA I around TI in the direction Zand falling 
on a differential surface dAZ around point Tt is given by : ( dA2 COS &#38; d2E = Z(T,, r7) (dA] COS&#38;) 
(1) , )\/ -projected area solid angle as seen from TI (2) This energy is scattered by the surface at 
Tz in all directions. By definition of the BRDF p2 at T2, the intensity leaving T1 in the di­rection 
Z, due to the incident light from dAl, is given by : dI(Tz, ti) = pz(ti, ti) ~ (3) where F = Z is the 
unit vector pointing from 1: to Tl.  @ @ Computer Graphics, Volume 25, Number 4, July 1991 To evaluate 
the total intensity leaving T2 in direction F, due (o the reflection of light originating from a finite 
area .41, Equation (2) must be integrated across .41 giving : Equation (4) represents the effect of the 
light emitted by a partic­ular surface on the light that is scattered around a point on another surface. 
It describes the elementary ,shooring operation of the ra­diosity method. The traditional radiosity method 
simplifies Equa­tion (4) in two ways : tirst, the BRDF p is assumed to be diffuse, which makes it a constant 
independent of both Fand rii, and can thus be moved out of the integral, The diffuse assumption also 
makes I(T,, IT)independent of U. Second, the radiosity ml(Tl ) is assumed to be constant across the surface 
of the patch. The intensity term can thus be moved out of the integral, which then becomes purely geometric 
and is called the (/jflere~~riu/fiJrn~fucrf~r. If more general BRDFs are considered for the surface at 
Tz, how­ever. the entire integrand must be considered. The next section ex­plains how a form factor computation 
algorithm is adapted for that purpose.  3 General solution for arbitrary reflectance A detailed description 
of the algorithm is presented below. The first pass, or solution pass. is very similar to progressive 
radiosity, and the implementation is a straightforward modification of an existing radiosit y program. 
The second pass employs a simple ray tracer to retrieve the directional intensity information stored 
on the surfaces. A central assumption of the method is that a directional intensity distribution 1(;) 
can be stored and accessed at each vertex of the environment. We discuss this topic further in section 
5, where an efficient storage scheme is presented. The method is explained here in terms of a meshed 
environment, composed of patches and elements [4], but it could be applied to radiosity textures [9] 
as well, if directional distributions are stored in the texture. The second (view-dependent) pass is 
described first, as it is a straightforward application of ray tracing. 3.1 Second pass Once the view-independent 
solution has been computed in the first pass, a simple ray tracing pass is used to supply the view-dependent 
portion and create the final image. When rays encounter surfaces with a directional dl~u.w component, 
the intensity leaving a surface is retrieved from the directional distributions computed and stored in 
the first pass. The intensity contributed by ideal spa ukv reflec­tion is obtained by recursively following 
reflected rays as in con­ventional ray tracing. Note that a specular rcflecfance function is used to 
attenuate the reflected rays instead of a simple specular coefficient . This allows a precise treatment 
of specular reflection, where roughness effects as well as Fresnel reflection are properly accounted 
for [8]. 3.2 First pass The first phase of the computation is an extension of progressive radiosit y, 
but directional distributions are used throughout the algo­rithm in place of diffuse radiosities. The 
basic shooting operation now uses the directional intensity distribution emitted by the shoot­ing patch 
to update the directional intensity distributions of the re­ceiving vertices according to Equation (4). 
This equation can be rewritten as a function of the intensity dis­tributions rather than scalar values. 
If p~( F, ) denotes the BRDF for an incoming direction F as a function of the outgoing direction, and 
1(T, ) denotes the intensity distribution at point T, then the effect of shooting from T, to TZ is Cos 
(?, Cos 6+ 1(7;,)= 1( T!,7i) p?( r, )dA I (5) / ,~1 r? The algorithm presented below follows Equation 
(5) and decom­poses the integral into a discrete sum. This is similar to the form factor computation 
algorithm of Wallace e( a/. [ 19], but modified to sum complete directional intensity distributions. 
Approximation of the integral To obtain the reflected intensity distribution given by (5). we follow 
the computation of the area-lo-dt~eren/ia/-area form factor used in [19]. Patch .41 is broken into a 
number of smaller pieces according to any given sampling scheme, and a contribution (a scalar cle/tu-f{mn­facror 
in the diffuse radiosity case. a directional distribution in our case) is computed for each piece. A 
variety of sampling strategies is available. and this formulation is independent of the particular scheme 
chosen. For .Y samples, the total integral is expressed as : (6) Given sample i, with area AA, centered 
at T,, the associated con­tribution to the integral in (4) could be crudely approximated by as­suming 
the integrand constant, yielding : To avoid possible singularities when Tl and T? are close together, 
we treat piece i as a finite area, and use the approximation of a disk­shaped area as in [19]. This amounts 
to assuming that the emitted intensity does not vary significantly over the area of the piece. which 
is a common assumption of the radiosity formulation. The contr­ibution of piece i is then : Introducing 
the incident energy flux (Watts per unit area) incident on point T2 from piece i Equation (5) can be 
conveniently rewritten as : h is apparent from equation ( If)) that 1 is simply a weighted sum of the 
BRDF at TI over a set of incident directions, Each energy flux term, MI,, is the product of the intensity 
leaving a sample print on the shooting patch in the direction of the receiving vertex and the de/fa-form:facror 
for that sample point. Do until convergence Select Shooting Patch P, Call SHOOT( P, , Sgeneric ) End 
Do Function SHOOT( Patch Pi , Occlusion function S ) ( For each Receiving Vertex Vi For each Sample Point 
TS on Pi . Evaluate occlusion c = S(T,, Vi) lf(c+O)Then 1 Obtain the incoming ener,qy&#38;x on Vi . Evaluate 
inten&#38;I, leaving T, tohard Vj, using intensity distribution of patch Pi . Compute 6F = delta-form-factor 
 0 between T, and Vj . Compute incident energy flux Cp = C. 6F. Id 0 Compute incident angfes in local 
axes at Vj . Retrieve BRDF p of surface at Vj for the incident angte 0 o Create intensity distribution 
AX = @ - p 0 Orient (rotate) 5X in local axes according to incident direction . Add nz to accumulated 
and unshot intensity distributions Z and U at V, End If End For End For Figure 3: Algorithm for first 
pass. Step D is explained in section 4 Discussion of the algorithm The shooting operation that propagates 
the accumulated energy of a patch into the environment is presented as a pseudocode subrou-tine (called 
SHOOT) in Figure 3. Given a shooting patch Pi and a receiving sample point (vertex Vj), the following 
operations are needed to update the directional intensity distribution of the vertex : Sample points 
are selected on the shooting patch according to a sampling algorithm. Our implementation uses an adaptive 
sampling technique where the number and location of the sample points de-pend on the results obtained 
from previous samples [19]. For each sample point, a contribution is added to the reflected intensity 
dis-tribution of the vertex. The first task of the algorithm is to compute the incident energy flux on 
the vertex, which is used to weight the BRDF as in equa- tion (10). This involves a visibility determination 
accomplished by the occlusion function S. In the simple cases where no ideal specular reflection is present, 
this function simply returns 0 or 1 to encode occlusion between the sample point and the vertex The more 
complex cases are explained in Section 4. If the two points Figure 4: Computation of the energy flux. 
can see each other, the intensity leaving the shooting patch is obtained from the stored directional 
distribution of the patch, and a delta-form-factor SF (geometric attenuation term) is computed (Figure 
3-A). The desired energy flux is the product of the inten-sity, the delta-form-factor and the attenuation 
given by the occlusion function (Figure 4). Z Figure 5: Orientation of the BRDF. (1) : obtaining the 
BRDF ac-cording to 8. (2) : rotating the BRDF according to 4. The second step is to compute the contribution 
of the current sam-ple point to the intensity distribution (Figure 3-B). We start by ob- taining a directional 
distribution representing p2(2;,, .), that is, the BRDF for the given incident direction. This is retrieved 
by means of the storage method described in section 5. The BRDF is then scaled by the energy flux value 
6@%, which results in the distribu- tion of reflected intensity LV due to the current sample point. If 
an isotropic BRDF is used, the directional distribution depends only on the incident elevation angle 
0, and is obtained in a canonical coordi-nate system : it must be rotated to be properly aligned with 
the inci- dent azimuth angle 4 in the local coordinate system of the receiver (Figure 5). Finally this 
contribution is added to the unshot intensity distribution and the accumulated intensity distribution, 
much as in traditional progressive radiosity (Figure 6). Previous work has shown that a complete treatment 
of light trans- fers requires exchanges incorporating different modes of reflection. Our shooting operation 
also includes a complete treatment of ideal specular reflection, so that the effect of specular reflection 
on the 63 Figure 6: Addition of directional distributions. intensity distributions is completely evaluated, 
but no specular in-tensity is stored (see section 2). Section 4 explains this part of the algorithm in 
more detail.  Ideal specular transfers As explained in Section 2, specularly reflected light is not 
stored in the directional distributions on the specular reflector. Instead it is immediately propagated 
to other surfaces where part of it will be stored in a directional distribution, and part may again be 
specularly reflected to other surfaces. Our implementation is an adaptation of the image method [ 161 
to the ray-traced form factor idea : if the specular surfaces are pla-nar, one can simply reflect the 
shooting patch across the surface, and shoot light from this virtual patch to all receiving vertices 
(Figure 7). Note that the direction for each shot is chosen determin-istically based on the position 
of a vertex; this is not a Monte Carlo sampling technique. Figure 7: Reflecting the shooting patch on 
a specular surface. Orig-inal vertices from the environment mesh are shown as dots. This method has several 
important benefits : . In contrast to the original image method , where the entire environment had to 
be reflected into a virtual environment, only the shooting patch need be reflected. 0 The evaluation 
of one specular reflection on a given specular surface can be implemented as a normal shooting step with 
a slightly modified occlusion testing routine. Furthermore, since we are shooting directly to vertices, 
it is possible to re- strict the expensive occlusion testing operation to the portions of the environment 
that can potentially receive reflected light, using a technique similar to a shadow volume [ 141. This 
allows us to retain benefits of the normal ray-casting method, such as adaptive meshing based on the 
results of a shot, and various sampling stategies for the shooting patch. Computer Graphics, Volume 25, 
Number 4, July 1991 . Multiple specular reflections can be implemented by recur-sively creating virtual 
patches. It should be noted that since the shooting patch is the only one that need be reflected, there 
is no explosion of the complexity of the scene. The current implementation is limited to planar specular 
surfaces. If more complex geometries are needed for the specular surfaces, it is no longer simple to 
construct a modified patch from which to shoot. Instead, specular rays can be fired from each receiving 
vertex lying on a specular surface, in a manner similar to [ 171. However, the distribution of specular 
rays then depends on the mesh of ver-tices on the specular surface, with no guarantee that all vertices 
in the environment will receive their share of the specularly reflected light. A major benefit of the 
ray-casting approach to radiosity is then lost. Furthermore, rays must be properly weighted, taking sur-face 
curvature into account, to ensure a physically correct energy transfer. 4.1 Algorithm The pseudo-code 
algorithm in Figure 3 contains two parts involv- ing specular reflection (note that the treatment of 
specular reflection within the first pass occurs entirely within the shooting operation). In the general 
loop that considers all receiving vertices in turn, specular surfaces are flagged whenever one of their 
vertices re-ceives some energy from the shooting patch (Figure 3-C). Entire surfaces (planar patches) 
are flagged regardless of their subdivision into patches or elements, or their number of vertices. Once 
all the vertices have had their directional intensity distri-butions updated with respect to the shooting 
patch, the specular re-flectors are then considered in turn (Figure 3-D). For each specular surface, 
a new patch is created and the occlusion testing function is modified in preparation for a recursive 
call to the shooting proce-dure SHOOT. The new patch is obtained by reflecting the original shooting 
patch and its attached coordinate system across the specular surface A. The new, virtual patch possesses 
the same intensity distributions as the original shooting patch except that they are reflected by virtue 
of the reflected coordinate system. A shot from the virtual patch Pi affects only those vertices in the 
environments that can see the original shooting patch in the spec- ular surface. This is easily accomplished 
by sampling the virtual patch as a normal shooting patch, but using a modified occlusion testing routine 
between the receiving vertex and the sample point. Figure 8 depicts the extended occlusion test. An occlusion 
function (called Sd in Figure 3, and described as pseudo-code in Figure 9) is first called : this function 
first looks for an intersection between the specular surface A and the ray linking the receiving vertex 
V, and a sample point on the virtual patch TS . If no intersection is found, there can be no light reflected 
in that direction, and the function returns. Next, if an intersection point ra was found, a normal occlusion 
test is performed between V, and TS. If the two points are visible to one another, the specular refectunce 
of the specular surface is computed for the appropriate reflection angle at 7-s. If SA returns a non-zero 
value, the only remaining operation con-sists in determining the occlusion between TS and a sample point 
on the original shooting patch, that is, the reflected image of TS (Fig-ure 8). This is accomplished 
by calling whatever occlusion function was in use at the current level of recursion : if we are dealing 
with a first specular reflection, the generic occlusion testing routine Sgenetic is used. At deeper levels 
of recursion, a composite function obtained by previous chaining operations is used. 191, -. T, Figure 
8: Chaining the occlusion functions. Once occlusion be­ tween Vj and ~~ is resolved, the composite occlusion 
test is per­formed between TS and the sample point on the original patch, pos­sibly involving several 
specular reflections. The entire operation can be described as chaining together the current occlusion 
testing function with the occlusion routine for the current specular surface. Note that once point TS 
has been found on the specultw surface, the order in which the two occlusion tests are carried out is 
arbitrary. However, since the occlusion test between TS and Jj is generally a simpler test, it is performed 
first. Function .9A ( Ts , Vj ){ . Find intersection rs between Vj T.s and A If ( No Intersection is 
Found) Then . Return O End If  . Evaluate occlusion c = SEeneriJTS,v]) If(C#l J)Then . Compute specular 
reflectance p> . Return c. qj Else  . Return O End If } Figure 9: Occlusion testing for a virtual 
patch 5 Storing Intensity Distributions The main departure of the current algorithm from previous progres­sive 
radiosity methods is that unshot and accumulated intensities now take the form of distribution functions 
at each vertex instead of scalar values. Because the number of vertices required for an accu­rate simulation 
can be quite large, it is cruciaf that the representation of these functions be economical in terms of 
storage. Moreover, the representation must allow for efficient shooting steps, which are performed many 
thousands of times in the course of a single simu­lation. To fit within tbe framework of progressive 
radiosity, intensity dis­tributions must also be computed incrementally by summing the di­rectional distributions 
resulting from impinging shots. After accu­mulating contributions shot from n sample points on other 
patches, the intensity distribution at vertex k on an isotropic surface is given by the following equation. 
192 II) ,=1 Here 0,, 0:, and A@, are the energy flux, angle of incidence, and azimuthal angle of the 
i th contribution respectively. Here we have expressed the BRDF parameters as angles with respect to 
a fixed local coordinate system at vertex k (Figure 5). The vertical axis of this coordinate system corresponds 
to the surface normal at that vertex though the other axes are arbitrary. We can interpret Equation (11) 
as a sequence of four operations applied to the underlying BRDF, p~, for each contribution arriving at 
vertex k: retrieving the directional distribution for a given an­gle of incidence, scaling and rotating 
this distribution, and finally adding it to the accumulated and unshot distributions stored at the vertex. 
These steps are shown in Figure 3-B. From these operations it is clear that the shape of each intensity 
distribution depends solely on the BRDF associated with the ver­tex and not on the distributions from 
which the energy was shot. While this constrains the class of distributions that can arise at any given 
vertex, the distributions resulting from marry contributions may nonetheless be quite irregular if the 
BRDF has a directional component (Figure 6). We therefore require a representation that is general enough 
to account for this variation while also accommodating the steps in Fig­ure 3-B. High-order continuity 
is also a requirement, since a discrete description, such as the global cube [1I], can result in severe 
alias­ing problems. Furthermore, derivative discontinuities in the inten­sity distributions can cause 
artifacts such as Mach-banding on the illuminated surfaces, even if a perfectly accurate transfer of 
light is computed. In the following sections we describe an approach based on spherical harmonics which 
meets these requirements. Using this mechanism we can compactly and accurately represent arbitrary BRDFs 
and their associated intensity distributions and efficiently perform all of the operations required for 
shooting and incremen­tal creation. It is therefore a nearly ideal mechanism for storing the intensity 
distributions for this global illumination algorithm. 5.1 Approximation using Spherical Harmonics Spherical 
harmonics form an orthogonal basis for the space of func­tions defined over the unit sphere [6]. This 
infinite collection of ba­sis functions is typically denoted by Yl,~(f3, +) where O s 1 < m and 1< m 
< 1. In direct analogy with Fourier series in one dimension, any square-integrable function, f(fl, ~), 
can be repre­sented by an infinite series of the form (12) where the coefficients are given by The practical 
value of this is that a finite number of terms can be used to approximate relatively smooth functions 
defined on the sphere. This allows us to store intensity distributions as a vector of N coeffi­cients, 
where N depends upon the characteristics of the underlying BRDF and the desired accuracy of the approximation. 
A diffuse, smoothly varying BRDF will typically require fewer coefficients than a very directional one. 
@@ To construct such a representation for the intensity distributions we begin by approximating the BRDFs 
in terms of spherical har­monics. In previous work, Cabral e~al, have used a similar approx­imation for 
the purpose of simulating diffuse and glossy reflections of the environment [2]. In the present work 
the dependence of the BRDF on the angle of incidence is accounted for by representing each spherical 
harmonic coefficient as a function of O .That is, for every BRDF we constmct a collection of scalar functions, 
131,m(,), such that 1=0 m-l In this way we can model the behavior of a BRDF over the entire range of 
incident angles. In our implementation the ~{, , functions are stored as one-dimensional cubic splines: 
one for each spheri­cal harmonic in the BRDF approximation. The cos @factor is in­cluded at this stage 
because it reduces evaluation time and tends to reduce ringing in the approximation. Figure 10 shows 
several of these curves for slightly rough aluminum. Additional details on this approximation can be 
found in Appendix A. I o X14 rr/2 Angle of Incidence Figure 10: Seven spherical harmonic coefficients 
for the BRDF of slightly rough aluminum plotted as functions of the incident angle.  5.2 Operations 
on Spherical Harmonic Coefficients Given a BRDF approximationof the form in equation (14) we can constructa 
correspondingintensitydistributionusing Equation( 11). For every intensity contribution we first evaluate 
the BRDF at the given angle of incidence, W, by computing the spherical harmonic coefficients of the 
resulting directional distribution. This consists of evaluating an interpolating spline, B1,~( .), for 
each cmfficient. Next, we scale the distribution by multiplying each of these co­efficients by the energy 
flux. The third step, rotating the distribution about the vertical axis, is made simple by the following 
property of spherical harmonics (shown in real form). Computer Graphics, Volume 25, Number 4, July 1991 
in the BRDF approximation. These coefficients reappear in the in­tensity distributions, however, because 
the symmetry is destroyed when the BRDFs undergo arbitrary rotations. This can be seen in step 3 of figure 
I 1. Initialize: C /,,, -0 For Each Contribution (0, f? , A@) arriving at Vertex k For Each index pair, 
(1, m), used in the approximation of p~ 1. Interpolate: .4~,,r,+ @~(13 ) 2. Scale: A ~,,,, + @ Al,,,, 
A I. m cos(rn A@) 3. Rotate: + A /. , A I. - , sin(m Ao) [1 1 A (, rn 4. Add: + .4 [.-m [$k:: 1+ [ $ 
: [1 End For End For Figure 11: Creating an intensity distribution, When m = O, steps 2 through 4 reduce 
to C~() -C $~)+ @.41,0. As the fourth and final step we add the resulting distribution to the current 
total by adding the corresponding coefficients. Thus, we have rephrased each of the steps in Figure 3-Bin 
terms of operations on spherical harmonic coefficients. The actual steps are shown in Figure 11 where 
the C~rn denote coefficients of an intensity distri­bution at vertex k. It is apparent from these operations 
that summing scaled and ro­tated instances of a single representation introduces no additional coefficients 
once the symmetry has been broken. Therefore, the storage required for a gi\ en intensity distribution 
does not gro~ as intensity is accumulated. Furthermore, the intensity distributions retain the full accuracy 
of the original BRDF approximations. To perform the shooting step we must evaluate an intensity dis­tribution 
in directions toward all vertices to which intensity is to be shot. This requires evaluating the YI,,,, 
functiortsassociatedwiththe coefficients of the intensity distribution in each of these directions. These 
evaluations can be performed efficiently using the recurrence relations shown in Appendix A.   6 Results 
Solutions have been computed for several test environments to demonstrate the feasibility of the simulation 
for wbitrary reflectance distributions. The resulting pictures exhibit all the expected visual effects 
produced by directional diffuse as well as ideal specular en­ergy transfers. Figure 12 shows a side by 
side comparison of a simulated envi­ ronment with a scanned physical environment. The scanned picture 
was obtained by scanning through three colored filters, where each   [:::~::::l=r:::::::)l Krn:e:l 
channel is spectrally integrated over a large range of wavelengths. This propefiy follows immediately 
from the definition of spherical Thus, the comparison with a simulation computed with three well­harmonics 
given in Appendix A. Rotation about this axis is partic-defirred monochromatic channels can only be qualitative 
(for exam­ ularly straightforward, and the usual symmetry of the BRDFs with ple the general color tone 
is noticably different). However, impor­respect to the incident plane simplifies it even further. Because 
neg-tant features such as the structure of the shadow on the left, or the atively subscripted spherical 
harmonics are odd functions with re-illumination of the ceiling via specular reflection from the top 
of the spect to O, we are guaranteed that all such coefficients will vanish tall box, appear to be very 
similar. A related research project is un­  [8] He, XiaoDong, Kenneth E. Torrance, Franfois Sillion, 
and Donald P. Greenberg. A comprehensive Physical Model for Light Reflection, Computer Graphics, 25(4), 
August 1991. (Proceedings SIGGRAPH 9 I in Las Vegas.) [9] Heckbert, Paul S. Adaptive Radiosity Textures 
for Bidirec­tional Ray Tracing, Computer Graphics, 24(4), August 1990, pages 145 I 54. (Proceedings SIGGRAPH 
90 in Dallas.) [10] HimIan, Theodore H., Michael C. Monks, Stephen H. Westin, Donald P. Greenberg, and 
Kenneth E. Torrance. Physical Measurement Techniques for Improving and Evaluating Com­puter Graphic Simulations, 
January 1991. (Submitted for publication.) [11] Immel, David S., Michael F. Cohen, and Donald P. Greenberg. 
A Radiosity Method for Non-Diffuse Environments, Com­puter Graphics, 20(4), August 1986, pages 133 142. 
(Pro­ceedings SIGGRAPH 86 in Dallas) [12] Kajiya, James T. The Rendering Equation, Computer Graphics, 
20(4), August 1986, pages 143 150. (Proceedings SIGGRAPH 86 in Dallas.) [13J Le Saec, Bertrand and Christopher 
Schlick. A Progressive Ray-Tracing based Radlosity with General Reflectance Func­tions, June 1990. (Proceedings 
of the Eurographics Work­shop on Photosimulation, Realism and Physics in Computer Graphics (Rennes, France).) 
[14] Nishita, T. and E. Nakamae. Continuous Tone Representa­tion of Three-dimesional Objects Taking Account 
of Shadows and Interreflection, Compurer Graphics, 19(3), July 1985. pages 23 30. (Proceedings SIGGRAPH 
85 in San Fran­cisco.) [15J Press, William H., Brian P. Flannery, and Saul A. Teukolsky. Numerical Recipes, 
Cambridge University Press, New York, 1986. [16] Rushmeier, Holly E. and Kenneth E. Torrance. Extending 
the Radiosity Method to Include Specularly Reflecting and Translucent Materials, ACM Transactions orI 
Graphics, 9( 1), January 1990, pages 1 27. [17] Sillion, Franqois and Claude Puech. A General Two-Pass 
Method Integrating Specular and Diffuse Reflection, Com­puter Graphics, 23(4), August 1989. (Proceedings 
SIG-GRAPH 89 in Boston.) [18] Wallace, John R., Michael F. Cohen, and Donald P. Greenberg. A Two-Pass 
Solution to the Rendering Equation: a Synthesis of Ray-Tracing and Radiosity methods, Computer Graphics, 
21(4), July 1987, pages 31 I 320. (Proceedings SIGGRAPH 87 in Anaheim.) [19] Wallace, John R., Kens A. 
Elmquist, and Eric A. Haines. A Ray Tracing Algorithm for Progressive Radiosity, Compu[er Graphics, 23(3), 
July 1989, pages 3 15 324. (Proceedings SIGGRAPH 89 in Boston.) [20] Whitted, Turner. An Improved Illumination 
Model for Shaded Display: Commun~ations of the ACM, 23, 1980, pages 343 349. Appendix A: More on spherical 
harmonics In real form, the normalized spherical harmonics are defined by Ivl,mPf,m(cos e) Cos(rnd) ifm>O 
K,m(o, @)= IVl,clP/.ll(cos e)/ti ifm=O (15) { N~,m Pl,lml(cos @)sin(lml@) ifrn <0 where the normalizing 
constants, IVl,~,, are given by (16) trrL=fw% and the Pl, n, (z) factors are associated Legendre polynomials. 
The latter can be evahrated with the recurrence relations P mm(x) = (1 2m)/=Pm_l,m-l(x) P l+l.m(z) = 
z(2rrl + l)pwt. m(x) PI,,,,(X) = z (~) 1 l. m(~) (*) PI Z, WL(Z) beginning with F o,o(z) = 1 [15]. Applying 
these in conjunction with recurrence relations for generating sin(~), sin(2@), . . . . sin(rn~) and COS(0), 
cos(2q5), . . . . cos(rqb), it is possi­ble to evaluate spherical harmonic expansions using approximately 
10 floating point operations per coefficient and no trigonometric function evaluations whatsoever. Evaluation 
of the spherical harmonic functions is required for two pu~ses: shooting from an intensity dktnbution 
and creating the initial BRDF approximations. The former is a straightforward application of Equation 
12 while the latter is more complicated and is performed once per distinct BRDF. To approximate an isotropic 
BRDF for all incident angles, we first compute forj=O, l,... qwhere O=O~ sO; ~ . . ~,0~ = n/2. Then the 
functions EJI,~ can be approximated by cubic mterpoiating splines through the the points (ON,b~,,n ), 
(O?, b~,m ),. . . . (o:, b~,m ). For each distinct BRDF, p, we select q as well as a specific set of 
spherical harmonic coefficients to achieve the desired accuracy of approximation over all incident angles. 
The value of q affects the accuracy of the interpolation but does not otherwise influence the intensity 
distributions. In contrast, the number of coefficients used in the BRDF approximation directly determines 
the sorage required for the intensity distributions. It is therefore important to keep this number reasonably 
small. If the BRDF that we wish to approximate is only defined on the upper hemisphere, as with an opaque 
material, we extend the func­tion to the lower hemisphere before computing the approximation. We do this 
in such a way that the complete BRDF satisfies (40 .0,4) = p(fY ,7r t?,qi), (18) This introduces a vertical 
symmetry which has the advantage of eliminating all spherical harmonics for which 1+ m k even. Italso 
maintains C 1continuity between the upper and lower hemispheres when the function is zero at the equator, 
a corrdhion that is guaran­teed if the cos O factor is included as described in section 5.1.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122740</article_id>
		<sort_key>197</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[A rapid hierarchical radiosity algorithm]]></title>
		<page_from>197</page_from>
		<page_to>206</page_to>
		<doi_number>10.1145/122718.122740</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122740</url>
		<abstract>
			<par><![CDATA[This paper presents a rapid hierarchical radiosity algorithm for illuminating scenes containing large polygonal patches. The algorithm constructs a hierarchical representation of the form factor matrix by adaptively subdividing patches into subpatches according to a user-supplied error bound. The algorithm guarantees that all form factors are calculated to the same precision, removing many common image artifacts due to inaccurate form factors. More importantly, the algorithm decomposes the form factor matrix into at most <i>O(n</i>) blocks (where <i>n</i> is the number of elements). Previous radiosity algorithms represented the element-to-element transport interactions with <i>n</i><sup>2</sup> form factors. Visibility algorithms are given that work well with this approach. Standard techniques for shooting and gathering can be used with the hierarchical representation to solve for equilibrium radiosities, but we also discuss using a brightness-weighted error criteria, in conjunction with multigridding, to even more rapidly progressively refine the image.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[global illumination]]></kw>
			<kw><![CDATA[n-body problem]]></kw>
			<kw><![CDATA[radiosity]]></kw>
			<kw><![CDATA[ray-tracing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Radiosity</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Raytracing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010374</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Ray tracing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372.10010376</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering->Reflectance modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15033698</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Princeton University, Princeton, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P63629</person_id>
				<author_profile_id><![CDATA[81100113721]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salzman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[68 Francis Avenue, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P168375</person_id>
				<author_profile_id><![CDATA[81100289210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Larry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aupperle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Princeton University, Princeton, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Appel, A.A. (1985) An efficient program for many-body simulation. SIAM J. Sci. Star. Computing 6(1), 85-103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barnes, J., Hut, P. (1986) A hierarchical O(NlogN) forcecalculation algorithm. Nature 324, 446-449.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74367</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Baum, D.R., Rushmeier, H.E., Winget, J.M.(1989) Improving radiosity solutions through the useof analytically determined form factors. Computer Graphics 23(3), 325-334.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bergman, L., Fuchs, If., Grant, E., Spach, S. (1986) Image rendering by adaptive refinement. Computer Graphics 20(4), 29-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617537</ref_obj_id>
				<ref_obj_pid>616009</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn, J. (1990) Triage Tables. IEEE Computer Graphics and Applications, 10(1) 70-75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97896</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Campbell, A.T., Fussel, D.S. (1990) Adaptive mesh generation for global diffuse illumination. Computer Graphics 24(4), 155-164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325171</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cohen, M.F., Greenberg, D.P. (1985) The hemi-cube: A radiosity approach for complex environments. Computer Graphics 19(3), 31-40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cohen, M.F., Greenberg, D.P., Immel, D.S., Brock, P.J. (1986) An efficient radiosity approach for realistic image synthesis. IEEE Computer Graphics and Applications 6(2), 26- 30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378487</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cohen, M.F., Chen, S.E., Wallace, J.R., Greenberg, D.P. (1988) A progressive refinement approach to fast radiosity image generation. Computer Graphics 22(4), 75-84.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>8927</ref_obj_id>
				<ref_obj_pid>7529</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Cook, R.L. (1986) Stochastic sampling in computer graphics. ACM Transactions on Graphics 5(1), 51-72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Esselink, E. (1989) About the order of Appel's algorithm. Computing Science Note KES-1, Department of Computer Science, University of Groningen.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Greengard, L. (1988) The rapid evaluation of potential fields in particle systems. MIT Press, Cambridge, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, P., Salzman, D.B. (1990) A rapid hierarchical radiosity algorithm for unoccluded environments. Published in K. Bouatouch, Photosimulation, Realism and Physics in Computer Graphics. Springer-Verlag (1991), Reprinted as Princeton University CS-TR-281-90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97895</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Heckbert, P.S. (1990) Adaptive radiosity textures for bidirectional ray tracing. Computer Graphics 24(4), 145-154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Medley, T.J.V. (1988) A shading method for computer generated images. Master's Thesis, The University of Utah]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Siegel, R., Howell, J.R. (1981) Thermal radiation heat trans. yet. Hemisphere Publishing Co., Washington, DC]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74368</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sillion, F., Puech, C. (1989) A general two-pass method for integrating specular and diffuse reflection. Computer Graphics 23(3), 335-344.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37421</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Thibault, W., Naylor, B. (198"/') Set operations on polyhedra using binary space partitioning trees. Computer Graphics 21(4), 153-162.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74366</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wallace, J.R., Elmquist, K.A., Haines, E.A. (_1989) A ray tracing algorithm for progressive radiosity. Computer Graphics 23(3), 315-324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>378490</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Ward, G.J., Rubinstein, F.M., Cleat, R.D. (1988) A ray txacing solution for ditfuse environments. Computer Graphics 22(3), 85-92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Warnock, J. (1969) A hidden-surface algorithm for computer-generated half-tone pictures. Technical Report TR 4-15, NTIS AD-?53 671, Computer Science Department, University of Utah.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Rapid Hierarchical Radiosity Algorithm Pat Hanrahan David Salzman Larry Aupperle Department of Computer 
Science 68 Francis Avenue Department of Computer Science Princeton University Cambridge, Princeton, 
NJ 08540 Abstract This paper presents a rapid hierarchical radiosity algorithm for illuminating scenes 
containing lar e polygonal patches. The afgorithm constructs a hierarchic J representation of the form 
factor matrix by adaptively subdividing patches into su bpatches according to a user-supplied error bound. 
The algorithm guarantees that all form factors are calculated to the same precision, removing many common 
image artifacts due to inaccurate form factors. More importantly, the al o­rithm decomposes the form 
factor matrix into at most O n) ? blocks (where n is the number of elements). Previous radios­ ity algorithms 
represented the element-to-element transport interactions with n2 form factors. Visibility algorithms 
are given that work well with this approach. Standard tech­niques for shooting and gathering can be used 
with the hi­erarchical representation to solve for equilibrium radiosities, but we also discuss using 
a brightness-weighted error crite­ria, in conjunction with multigrldding, to even more rapidly progressively 
refine the image. CR Categories and Subject Descriptors: 1.3.7 [Com­ puter Graphics]: Three-Dimensional 
Graphics and Realism. Key Words: radiosity, ray-tracing, globaf illumina tion, n­ body problem.  Introduction 
Developing a correct treatment of the physics of bidirec­tional reflectance and of light transport is 
an important fo­cus of modern research in image synthesis. Although effi­cient solutions to the fully 
general CSAWare not known, these physically-baaed models have produced some of the most realistic computer-generated 
images to date. The most suc­cessful approach has been mdiosity, which, by making the si mplifyi n assumption 
that all the surfaces are diffuse re­flectors, ? for straightforward computation of the equi­ al ows 
librium distribution of light for complex scene geometries. This paper presents efficient computational 
techniques for solving the transport equations that arise for radiosity in complex scenes. Our al~orithm 
draws from recent insights into fast numerical algorithms for solving the N-body prob lem (Appel 1985; 
Barnes and Hut 1986; Greengard 1988), Computational efficiency is achieved by carefully analyzing the 
error in performing form factor integrals. Without care­ful error analysis, pictures may contain artifacts 
where the form factors have large error. More importantly, many form factor computations are done at 
much higher precision than is necessary. Careful error anrdysis, in combhation with a multi-resolution 
representation, can be used to reduce sig­nificantly the number of interactions that are considered. 
Pcrmis$i{m I(I copy withtmt I&#38; Ill (M part ot th]s matcmd is gmnttxi provided [hit the cnpim arc 
not mak nr dismibutcd Ibr direct cmnmcrmid akmtage, the ACM cnpyright nnt icc d the title nf the puhtica(ion 
and ih Ate appeur. and nn(icc IS given tha[ copying i, by pcrmissinn 01 the Aw{wititmn for Cnmpu[ing 
Mfichlnery. T<) copy tlthcrwiw, ,Jr to rcpubl]sh, requirc~ a fm dnd){)r specific pem~]ssi{)n. MA 02138 
Princeton University Princeton, NJ 08540 Previously we analyzed the form factor calculation be­tween 
two unoccluded poly onal patches, discretized into n finer polygonaf elements (%anrahan and %lzman, 1990). 
We showed that the form factor matrix can +ways be ap proximate to within some preset numerical tolerance 
with at most O(n) terms, and often many fewer. This paper extends our previous radiosity algorithm to 
handle scenes wit h many polygons, where occlusion plays an important role. Occlusion, although costly 
to detect, reduces the num­ber of interactions even further. The form factor matrix is therefore sparser, 
allowing faster solution for equilibrium ra­diosities. The technique used for determining visibility 
is based on ray tracing, but two important optimizing heuris­tics are introduced. One takes advantage 
of visibility coher­ence between different levels of detail; the other is based on the observation that 
most interactions between patches are either totally visible or totally invisible with respect to each 
other. Finally, we show how to use multigridding in combi­nation with a brightness-weighted error estimate. 
This leads to a faster progressive radiosity algorithm. 2 Review of Previous Work 2.1 Radiosit y Radiosity 
algorithms assume the environment has been dis­cretized into small elements which have constant brightness. 
In this paper, we use the term element to describe the smaJlest piece of a surface subdivision, and the 
term patchn for any larger pieces, including the original polygon, formed by combining elements or other 
patches, Enforcing an en­ergy balance at every element yields a system of equations of the form: n B,= 
E,+ P,~F,l B] 3 where B, is the radiosity, E i is the emissivity, p, is the diffuse reflectance, F,J 
is the form factor (the percentage of light leaving element i that arrives at element j), and n is the 
number of elements in the scene. Similar equations exist for all elements, yielding a linear system of 
equations. ( 1 pl F],2 . . . /JIFl,n p2F2,1 p~F.,l -p~Fn,2 . . . 1 : 2: )(:)=(:) This system of equations 
can be efficiently solved using itera­tive algorithms such as the GausrAeidel method. Physically, the 
Gauss-Seidel method is equivalent to successively gather­ing incoming light. An alternative iteration 
scheme is to re­verse this process by successively shooting light from patches in order of their brightness 
(Cohen et al. 1988). This has the advantage that the solution converges more quickly, and if the scene 
is drawn during the iteration, successive images i 19YI A( M-()-x97Yl-436-x/91/(K171()197 $(Ki.7S I97 
  SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 gradually improve aa the computation proceeds (Bergman 
et al. 1986). The most expensive part of the calculation is computing the form factors. Assuming two 
infinitesimal elements, the differential form factor between them is given by The angle Oi (or e~) relates 
the normal vectir of element i (or j) to the vector joining the two elements. The form factor from an 
infinitesimal area to a finite area is the integral COS89 COS@j Fij = dAj, rrr~, J Aj and the form factor 
between two finite areas is the double integraf These form factor formulae do not take into account occlu­sion. 
To do th]s requires that differential form factors be accumulated only if the two infinitesimal elements 
are mu­t ually visible. The first practicaf approach to integrating visibility into form factor computations 
was the hemi-cube $%!;?~?;~a~d?~~~ ~~5keT~e!%~%#g current workstation graphics hardware. Al orithms based 
on ray tracin afso have been proposed for form factor cal­culation (Mal f ey 1988; Ward et al. 1988; 
Wallace et al. 1989; Sillion and Puech, 1989) There are two major sources of error when computing form 
factor integrals. F]rst, the integral is evaluated by sam­pling the patches in some way; since the results 
of uniform sampling process are subject to alhsing, early methods had noticeable aliasing errors. However, 
more recent methods (Wallace et al 1989) have overcome sampling errors by incor­porating stochastic sampling 
into a ray tracer (Cook, 1986). Secondj the form factor between two surface samples can be approximated 
by the differential form factor only if the dis­tance separatin the two samples is large compared to 
their This con f frequently occurs along edges and in size. ]tlon corners where polygons meet. To avoid 
this problem, Baum et al. (1989) switch to an analytically calculated form factor in these situations. 
Another approach, used by Wallace et af. (1989), is to supersample adaptively the integral. The form 
factor matrix is n by n, where n is the number of elements. This n2 growth causes time and memory problems 
for complex scenes, The firat method to reduce the computa­tional costs was motivated by the method of 
substructuring used in finite element calculations. The polygons comprising the scene are discretized 
at two levels Cohen et al. 1986). One level contains the patches into whit \ input polygons are broken, 
and the other level contains the elements into which each patch is broken. Normally, the number of patches 
and elements are determined a-pn ori, but the number of ele­ments can also be determined by recursive 
subdivision baaed on radiosity gradienta Cohen et rd.(1986). Other attempts to utilize adaptive subdivision 
are described in Campbell &#38; Fuasel (1990) and Heckbert (1990).   2.2 N-Body Problem The hierarchical 
subdivision algorithm proposed in this pw er is inspired by methods recently developed for solving the 
R-body problem. In the N-body problem, each of the n par­ticks exerts a force on all the other n -1 particles, 
implying n(n -1)/2 pairwiae interactions. The fast algorithms com­pute all the forces on a particle in 
leas than quadratic time, building on two key ideas: 198 11! Numencaf calculations are sub~ct to error, 
and therefore, t e force acting on a particle need only be calculated to within the given precision. 
2) The force due to a cluster of particles at some distant point can be approximated, within the given 
precision, with a single term-cutting down on the total number of interac­tions. Appel was the first 
to develop a hierarchical algorithm for solving the N-body problem, by approximating the forces be­tween 
particles in two clusters with a single force, when the separation between the clusters significantly 
exceeded their sizea. A topdown traversal of a h~erarch~cal k-d tree rep resentin the clusters yielded 
an O(n 10 n) algorithm (Ap 1 pel 1985. More recently, Esselink an a !yzed Appel s algo­rithm and showed 
that time needed to calculate the forces takes only O(n) time (Esselink 1989), and that the observed 
O(n log n) running time is a consequence of the preprocess­ing time required to build the hierarchical 
data structures. Barnes &#38; Hut developed a similar algorithm baaed on oc­trees (Barnes &#38; Hut 1986). 
Greengard and Rokhlin devised the first O(n) af orithm, using a p-term multipole expansion for the potenti~ 
due to any cluster: along with algorithms for splitting, mer ing, and translating the resulting multi­pole 
expansions (8 reengard 1988). The algorithm proposed in this paper ia moat closely related to Appel s 
and Barnes &#38; Hut s algorithms; it should be mentioned that these two algorithms are very easy implement, 
and only take a few hundred lines of code. The radbaity problem sharea many similarities with the N-body 
problem which suggest that these ideas can be used to increase its efficiency. In both the N-body and 
the ra­dioaity problem, there are n(n 1 /2 pairs of interactions. Moreover, just as gravitational i 
or e ectromagnetic forces fall off aa l/r2, the magnitude of the form factor between two patches also 
falls off as 1/r2. Finally, according to Newton s Third Law, gravitational forces are equaf and opposite, 
and, according to the reciprocity principle, form factors between two polygons are related. One major 
difference between the two problems is the manner in which the hierarchical data structures are formed. 
The N-body algorithms begin with n particles and cluster them into larger and larger groups. Our radioaity 
algo­rithm, however, begins with a few large polygons and sub divides them into smaller and smaller patches. 
Subdividing baaed on the error of a potential interaction provides an au­tomatic method for dlscretizing 
the scene within the given error bounds. The specifics of our subdivision algorithm is discussed in Section 
3. The separate problem of building clusters out of individual patches is not dealt with in this paper. 
Another difference is that the N-body algorithms take ad­vantage of linear superposition; the principle 
of superposi­tion states that the potentiaf due to a cluster of particles is the sum of the potentials 
of the individual particles. ThB principle does not afways apply to the radioaity problem, be­cause of 
occlusion: intervening opaque surfaces can block the transport of light between two other surfaces, which 
makes the system non-linear. Occlusion thereby introduces an ad­ditional cost to the radiosity problem. 
This is discussed in Section 4. Finally, the N-body problem is based on a differential equation, whereas 
the radioait y problem is baaed on an inte­graf equation. The integraf equation arising from the radios­ity 
problem can, however, be solved efficient] y using iterative matrix techniques. Fort unately, the hierarchy 
of interactions produced by our subdivision is equivalent to a block struc­tured matrix, and the iteration 
can be efficiently computed. This is discussed in Section 5. Form Factor Matrix Approximation This section 
describes a recursive refinement procedure which simultaneously decomposes a polygon into a hierarchy 
of patches and elements, and builds a hierarchical represen­tation of the form factor matrix by recording 
interactions at different levels of detail. We begin by describing the proce­dure and its results, and 
then proceed to analyze the error in the resulting form factors, and the number of interactions that 
need to be considered. This section is quite similar to Hanrahan and Salzman (1990). Consider the procedure 
Refine: Refine (Patch *p, Patch .q, float Feps, float Aeps) { float Fpq, Fqp; Fpq = FomPactorEstimate( 
p, q ); FW = FoflactorEstimate( q, p ); if( Fpq<Feps U Fqp<Feps ) Link( p, q ); else { if(Fpq>Fqp){ if( 
Subdiv( q, Aeps ) ) { Refine( p, q->ne, Feps, Aeps ); Refine( p, q->nw, Feps, Aeps ); Refine( p, q->se, 
Feps, Aeps ); Refine( p, q->sv, Feps, Aeps ); } else Link(p, q); } else { if( Subdiv( p, Aeps ) ) { Refine( 
q, p->ne, Feps, Aeps ); Refine( q, p-%m, Feps, Aeps ); Refine( q, p->se, Feps, Aeps ); Refine( q, p->sv, 
Feps, Aeps ); } else Link( p, q ); 3 } } Refine first estimates the form factor between two patches, 
and then either subdivides the patches and refines further, or terminates the recursion and records an 
inter­action between the two patches. If the form factor esti­mate is lees than Fc (Feps in the pro~ram), 
then the true form factor (not taking into consideration occlusion) can be approximated accuratel by 
the estimate (see below), and the patches are rdlow~to interact at this level of detail. (The procedure 
Link records the interaction between the two patches. ) However, if either of the form factor estimates 
is larger than F., then the form factor estimate is not accurate, and so the patch with the larger form 
factor is subdivided, andRefineis called recursively with thesmalle rsubpatches. Subdiv subdivides a 
patch into subpatches. In our im­plementation, a patch is a planar quadrilateral, and it is subdivided 
equally into four new quadrilaterals by splitting it at its center. The subdivision hierarchy is stored 
in a quadtree; the pointers tothe four children are stored in the freldsnu, ne, SW, and se. (This data 
structure is similar to adaptive radiosity textures propoeedin Heckbert 1990), al­though information 
is stored at all levels of the i ierarchy, not just at the leaf nodes, and each level also stores a list 
of its interactions. ) Subdiv returns false if the patch can­not be split; this condition occuraif the 
area of the patch is smaller than some absolute predetermined area Ac, and is uecessary to prevent infinite 
recursion in corners and along edges. If subdivision is not possible, we force the two patches to interact. 
Note that a patch may be refined against many patches, and so the actual subdivision of a patch may have 
Figure 1: The block form factor matrix for a particular bi­nary tree example. Each Iabelled block corresponds 
to a la­belled arc connecting nodes in the hierarchical subdivision. Although the blocks are all square 
in this example, that is not thecaae ingenerrd. been performed previously. When this occurs Subdiv need 
do no other work and simply returns true. The procedure FornFactorEsttiate returns an upper bound on 
the form factor from the first patch to the sec­ond patch, assuming the first patch has infinitesimal 
size and the second patch has finite size. The form factor can be estimated by either calculating the 
solid angle subtended by adiskwith crosesectionaf area equal tothe surface area of the patch (Wallace 
et al. 1989), or by circumscribing a sphere around the patch and estimating the solid angle sub tended 
by the sphere. An example of atree that might reproduced by Refine and its associated form factor matrix 
is shown in Figure 1. For simplicity, the figure illustrates the interactions between two hypothetical 
ID patches; in this case the hierarchy can be represented with a binary rather than quaternary tree. 
The two binary trees representin the induced subdivision, and are drawn side by side along t%eedgesof 
the form factor matrix. Since in this example each binary tree represents a polygon, no interactions 
are shown with itself. The leaves of the tree are the elements in the discretization. The combhm tion 
of all the leaf nodes completely cover the input patch. Interactions between patches at different levels 
are repre­sented by Iabelled blocks in the form factor matrix, and by labelled arcs between nodes in 
the trees. Notice that the size of the block in the form factor matrix depends on the level in the tree 
the patches interact at. The higher the level, the bigger the block. The first point in the analysis 
is the relationship between the termination criteria and the accuracy of the computed form factors. Obviously, 
the termination criteria causes the form factor corresponding to each interaction to have ap­proximately 
the same m nitude, because, if an estimated form factor were larger, Tt e patches would be sub&#38;vided, 
otherwise, they are allowed to interact. More importantly, the termination criteria also places an upper 
bound on the error associated with the form factor integral between the two interacting patches. This 
can be verified by examining SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 II Figure 2: Interactions of 
the node p with neighboring nodes in a one-dimensional subdivision. factor matrix has fewer than n2 blocks. 
To a certain extent this is obvious, because every time an interaction occurs at some higher level of 
detail, the number of interactions is re­ duce+ but we wish to count the interactions more precisely. 
For simplicity, again consider the lD problem of n equslly spaced patches along a line. Later we will 
consider what hap pens if the patches are 2D and non-uniformly distributed. Let us construct a binary 
tree above the patches by merg­ ing adjacent contiguous patches recursively. This is shown in Figure 
2. The error criterion says that two patches can inter­ act directly only if (r/R)2 < F,. In other words, 
two patches of size r can interact only if the distance R between them is greater than r/~. For concreteness, 
let us fix Fe so that this criterion is equivalent to saying that two patches at the same level in the 
b]nary tree can interact only if at least one other patch at that level is between them: Otherwise, they 
would subtend too large a solid angle and would subdivide, pushing the interaction down a level in the 
tree. Now con­sider the interactions of a patch p in the interior of the tree. At any level in the tree, 
the rule forbids the patch p from interacting with its immediate neighbors. These immediate neighbor 
interactions, therefore, must be handled by p s chil­dren. In the same way, p is only responsible for 
handling the interactions from its parent g s immediate neighbors. There­fore, p need only interact with 
the children of q s immediate neighbors. Figure 2 shows the node p and its parent q. The above considerations 
imply that p need only make three con­nections to nodes at its level. This argument applies to aU levels 
of the tree (except the top and the bottom, but these levels result in fewer interactions), and therefore 
each node in the tree connects to a constant number of other nodes. Figure 3: Interactions gons. the 
form factor from Fdi.k = R2+ ~ = between a pair of perpendicular poly- Thus, the total number of interactions 
is proportional to the number of nodes in the tree, which is O n . A similar anal­ ysis has been derived 
independently by [E?sselink 1989). Figure 3 shows the quadtree subdivision and the inter­ a point to 
a disk of radius r, actions between at each level in the hierarchy computed by Itef ine a pair of perpendicular 
polygons. This figure shows that each interior patch has a constant number of interac­ tions with other 
patches regardless of the level in the tree.    (i) ( -(i) +K) + )  Figure 4 plots the actual number 
of interactions versus the (11) where R is the distance from the point to the center of th~ disk. Thus, 
the error due to the finiteness of the geometry is given by terms involving powers of (r/R). Because 
F goes as r/R)2, when F is small (implying that the size of the pate i is small compared to the distance 
separating the patches), the differential form factor is also a good estimate of the true form factor. 
A more rigorous proof of this result can be obtained by forming the Taylor expansion of the form factor 
integral. In the N-body problem, this expansion is the multi pole expansion. However, one need not ever 
calculate the expansion explicitly to use this algorithm. The second point in the analysis is that the 
resulting form number of potential interactions at a fixed uniform level of discretization. The number 
of interactions for perpendicular polygons goes, surprisingly, as O(X). The subdivision in­duced between 
two perpendicular polygons is comparable to a bhmry tree turned on its side with its leaf nodes along 
the common edge, and the total number of nodes in such a side­ways binary tree will be 0(~. The worst 
case for Refine is two parallel polygons whose size is much larger than the distance separating them. 
In this case, there will be O(n) interactions. As the polygons move further apart, or are tilted relative 
to each other as in the case of perpendicular polygons, the number of interactions is reduced. Finally, 
as the two polygons move still farther apart, eventually only a **O** . .* . I o &#38;-- I I 1I o 50 
100 150 203 S@(N) Figure 4: Number of interactions vs. number of elements for a pair of perpendicular 
polygons. 47 . Perpndiculsr Polygons 30 . ParallelPolygon i :~  0.00 0.01 0.02 0.03 0.04 0.05 Reps Figure 
5: Measured relative percentage error vs. Fc. single interaction is required. To verify the accuracy 
of the form factors generated by our method, we compared the computed form factors with the analytical 
form factors which are available for the parallel and perpendicular geometries see, for example, (Siegel 
and Howell 1981)). To compute ti e form factor between two finite are=, Refine can be modified to return 
the sum of the form factors of a patch s children or, if the patch is a leaf, the product of the patch 
s area and the differential form factor to the other patch. Figure 5 shows the measured relative error 
between the computed and the analytical form factors as a function of FC. As ex ected, the actual error 
in the form factor is proportional tot [ e F< given to Ref tie, as predicted by the theory. Note that 
the plateaus in these figures are due to the discrete nature oft he subdivision. In summary, our hierarchical 
refinement method estimates the form factor matrix between two unoccluded patches to within a fixed error 
tolerance automatically . In the process it reorganizes the form factor matrix into O n) or fewer blocks; 
(the estimated form factor associated with each block has the same value and error as other blocks. 
4 Visibility The pairwise method for computing form factors described in the previous section is accurate 
as long as each patch is com letely visible with respect to the other patch. U nfort u­nate !y, occlusion 
exists in all realistic environments, and so this idealization is not very useful in practice. In this 
section we modify the algorithm to take into consideration visibility. Figure 6: Jittered rays fired 
between two polygons to deter­mine the percentage visibility. Intervening occluding surfaces can only 
decre-light transport between two patches, thus, the true form factor in the presence of occlusion is 
never greater than the form factor estimate described above. The effect of occlusion can be modeled by 
multiplying the estimated form factor by a visibility correction factor which estimates the percentage 
each patch sees of the other. F= VeF. where Fe is the estimated form factor without considering occlusion, 
and V= is the estimated visibility. If Vc = 1 then the two patches are totally visible; if V .= O then 
they are completely occluded; and otherwise they are partially visi­ble. Thus, assuming no visibility 
error, the level of detail for the interaction between twa patches need never be finer than that computed 
by the procedure Refine. Recall that all the form factor estimates computed by Refine have approximately 
the same error. This fact has two important consequences. First, since the form factor is not precise, 
the calculation of V, need only be estimated to the same precision. Ideally, the visibility module should 
take into account the precision required; in reality, current visibility modules probably compute visibility 
much more accurate] y than is necessary. Second, since all the visibil­ity estimates should have approximately 
the same error, it is reasonable to perform the same amount of work per esti­mate. This means that the 
total number of visibility tests required is proportional to the number of interactions. The total amount 
of work performed is:  T(rI) = F(n)V(n) where F n) is the number of computed form factors and V(n is 
t k e cost of performing the visibilit test for a given num Ler of elements. As has been shown, F ( n) 
varies at most linearly with n, so many fewer visibility tests need be done than with conventional radiosity 
algorithms. In our current implementation, we perform two types of visibility tests. The first visibility 
test determines whether two polygons face each other, face away from each other, or if the support plane 
of one polygon splits the other. This test considers only the two polygons and not the environment, and 
therefore can be done in constant time. The second vis­ibility test checks how much of each polygon is 
visible from the other polygon given the global environment. The test fires a fixed number of rays between 
the two patches, and computes the percentage of rays not blocked by intervening surfaces. The same number 
of rays are fired per interaction, because all the visibility estimates should have the same er­ror. 
Each patch is subdivided into a 2D grid (typically 4x4), and the cells in the grid are assigned numbers 
from a magrc square (Cook 1986). Each ray is really a line segment formed by joining jittered points 
within corresponding cells with the same number as shown in Figure 6. A naive ray intersection test takes 
O(n) time. In order to accelerate the visibility test, we use a modified version of the BSP-tree algorithm, 
 20 I 98 Wential elements 44773 Potential interactions 1002288378 Without vlslbdltv coherence Patches 
 7286 Elements 5489 Interactions 15526  Totally-invisible 4477 28.8% Totally-visible 8171 52.6% Partially-visible 
2878 18.5% 1ests Refinement tests 19117 Visibility tests 11123  Ray teats 177968 W 1th vm bdlt y coherence 
Patches 7350 Elements 5537 Interactions 15598 Totally-invisible interactions 4495 28.8% Totally-visible 
interactions 8249 52.9% Partially-visible interactions 2854 18.3% Tests Refinement tests 19213 Totally-invisible 
refines 3600 18.7~o Pre-Totally-invisible refines o 0.0% Totally-visible refines 10487 54.6% Pre-Totally-visible 
refines 9700 50.570 Partially-visible refines 5126 26.7% Partial visibility tests 9513 Ray teats 20527 
Visib~~tt~t; 4296 Y 68736 Table 1. Statistics for Figure 7. return a Dartial visibility result if the 
visibility situation is complex, as additional subdivision will tend [O reduce the complexity of the 
visibility calculation. This is very similar to Warnock s visible surface algorithm (Warnock 1969). The 
methods used to detect visibility are likely to be more accurate when patches are totally visible or 
totally invisible. When two patches are partially visible, we assume there is more likely to be an error 
in visibility and increase the error in the form factor estimate. This causes increased subdivi­sion 
in regions of partial visibility; the cost of this is minor because they occur so infrequently, however, 
the benefits are great because these often arise at shadow boundaries where there are sharp intensity 
gradients. Solution Techniques Once the form factors have been determined, the next step is to solve 
for the radiosities. The most efficient way to do this is to invert the matrix iteratively. Each it erat 
ion involves multiplying a matrix times a vector, which normally takes 0( n2 ) operations. However, because 
the form factor matrix is represented with O(n) blocks, each matrix multiplication can be done in linear 
time. In this section we give program fragments that implement the technique of gathering and briefly 
explain how to implement shooting. These techniques are quite similar to the unoccluded case, and we 
refer the reader to Hanrahan and %dzman (1990) for more details. 5.1 Shooting and Gathering The classic 
Jacobi iteration (which differs from the Gauw Seidel in that the brightneeeee are not updated in-place) 
can be implemented using the following simple recursive proce­dure. Gather( Patch *p ) { Patch *q; float 
Fpq; if(p){ p->llg = 0.0; ForAlllIlements ( q, p->interact ions ) { Fpq = Fox-mFactor( p->Bg += Fpq . 
p->&#38;? ;~>B; } Gather( p->sw ) ; Gather( p->se ) ; Gather( p->nv ) ; Gather( p->ne ) ; } } The average 
brightness of each patch is stored in B and its diffuse color is stored in Cd. The brightness gathered 
is stored in Bg, and is computed by receiving energy from all the patches q stored on the list of interactions 
of p (p->interactions). The total amount of energy received by an element is the sum of the energy received 
by it directly, plus the sum of all the energy received by its parent subpatchee. To update the energies 
for the next iteration, all the energy gathered is pushed down to the leaf nodes, and then pulled upward 
to­wards the root polygon. During this upward pass, the radios­ity of interior subpatches are set equal 
to the area weighted average of its children s radioeitiee. Both t heae operations can be done in a single 
depth-first traversal of the quadtree, which takes time proportional to the number of nodes in the hierarchy. 
The r-dioaity equation can be solved by shooting instead of gathering. All patches in the hierarchy are 
sorted into a pri;rity qu~ue has-d on their brightness. -A patch at a time is taken off the queue, and 
its energy shot to the patches that interact with it. This version of shooting, however, has a much smirdler 
granularity then the classic method of shooting used in progressive refinement. This is because in our 
algorithm each pat ch shoots light to a constant number of other patches, whereas in the previous algorithms 
a patch shoots light to the entire scene.   5.2 Multigridding and BF Refinement An interesting variation 
of shooting or gathering refines the hierarchy as the iteration proceeds. This is similar to the idea 
of multigridding, where a finite difference equation is solved first at a coarse resolution, and then 
at successively finer resolutions. The advantage of multigridding is that the coarse solution involves 
a low resolution iteration that can be performed cheaply. This coarse solution provides a better starting 
point for the costlier iterations at the finer resolu­tions, resulting in fewer expensive iterations 
before conver­gence. Multigriddin allows for an even more progressive ra­diosity algorithm: S%ooting 
is performed in the early stages at coarse resolutions to get a rough idea of the image, and then at 
successively finer and finer resolutions as the calcu­lation proceeds. Multigridding is easily incorporated 
into the algorithm by successively refining the mesh with smaller and smaller F{ s. The procedure Refine 
is extended to delete the link indicat­ing a previous interaction at a given level of detail, if subdi­vision 
is required. Refine is then called between iterations to increase the resolution of the grid. A final 
improvement to the afgorithm bases the refinement of two patches on BF; thatis, on the total amount of 
energy potentially transported between the patches. The procedure Refine is extended to use this test 
for subdivision rather than F alone. This causes refinement of the mesh to be put off until energy is 
actuafly available to be transported,    SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 applications 
fqr such ~gorithms are for rendering volumes and partlclpatmg media. One of the emerging themes of realistic 
image synthesis is that the geometric aspects of the roblem are becoming subservient to the optical aspects. 
fhe optical portion in­volves numerically solving an integral equation; the geomet­ric portion involves 
primarily determining visibility between the finite elementi used to discretize the equation. Unfor­tunately, 
most visibility algorithms developed in computer graphics were not developed with these numerical calcula­tions 
in mind. What are needed are fast algorithms that compute visibility to within a given precision. Ideally, 
the less the precision, the faster the algorithm. Visibility al­gorithms also need to be developed that 
consider patch-t­ patch interactions and not just point-t-patch interactions, as are almost exclusively 
the case. Fhmlly, what are needed to take advanta e of the coherence found m typical environ­ments are 
fast 3 gorithms for detecting whether patches are totsJly visible or totally invisible with respect to 
each other. 8 Acknowledgements The authors wish to thank Andrew Appel, Dan Baum, David Laur, Toby Orloff, 
Jeffrey Posdarner, and James Winget for helpful comments. Brian Danella and S.V. Krishnan pro­vided assistance 
with modeling and rendering.  9 References Appel, A.A. 1985) An efficient program for many-body sim­ 
ulation. SIA h J. SC;. StaL Computing 6(l), 85-103. Barnes, J., Hut, P. (1986) A hierarchical O(IVlogiV) 
force­calculation algorithm. Nature 324, 446-449. Baum, D. R., Rushmeier, H. E., Winget, J.M. 1989) Improv­ing 
radiosity solutions through the use of an J ytically deter­mined form factors. Computer Gmphics 23(3), 
325-334. Bergman, L., Fuchs, H., Grant, E., Spach, S. (1986) Image rendering by adaptive refinement. 
Computer Gmphics 20(4), 29-38. Blinn, J. (1990) Triage Tables. IEEE Computer Gmphics and Application, 
10(1) 70-75. Campbell, A.T., Fussel, D.S. (1990) Adaptive mesh gener­ ation for global diffuse illumination. 
Computer Gmphics 24(4), 155-164. Cohen, M. F., Greenberg, D.P. (1985) The hemi-cube: A radioslty ap roach 
for complex environments. Computer Graphics 19 3), 3]-40. r Cohen, M. F., Greenber~, D. P., Immel, D. 
S., Brock, P.J. (1986) An efficient radioslty approach for realistic image syn­thesis. IEEE Computer 
Gmphics and Applications 6(2), 26­ 30. Cohen, M. F., Chen, S. E., Wallace, J. R., Greenberg, D.P. (1988) 
A progressive refinement approach to fast radiosity image generation. Computer Gmphics 22(4), 75-84. 
Cook, R. L. (1986) Stochastic sampling in computer graphics. ACM Tmnsactkms on Gmphics 5(l), 51-72. Esselinkt 
E. (1989) About the order of Appel s algorithm. Computmg Science Note KE5-1, Department of Computer Science, 
University of Groningen. Greengard, L. (1988) The mpid evaluation ofpotentialfields in particle systems. 
MIT Press, Cambridge, MA. Hanrahan, P., Salzman, D.B. (1990) A rapid hierarchical radiosity sJgorithm 
for unoccluded environments. Published in K. Bouatouch, Photosimulation, Realism and Physics in Computer 
Graphics. Springer-Verlag (1991), Reprinted as Princeton University CS-TR-281-90. Heckbert, P.S. (1990) 
Adaptive radiosity textures for bidi­rectional ray tracing. Computer Gmphics 24(4), 145-154. 206 Malley, 
T. J.V. 1988) A shathg method for computer gen­erated images. L aster s Thesis, The University of Utah 
Siegel, R., Howell, J.R. (1981 Thermal mdiation heat tmns­ fer. Hemisphere Publishing L o., Washington, 
DC Sillion, F., Puech, C. (1989 A general tw~pass method for integrating specular and di d use reflection. 
Computer Gmph­ acs 23(3), 335-344. Thibault, W., Naylor, B. (1987) Set operations on polyhedra usin 
binary space partitioning trees. Computer Gmphics 21(4?, 153-162. Wallace, J. R., Elmquist, K. A., Haines, 
E.A. 1989 A $) ray tracing algorithm for progressive radiosit y. omputer Gmphics 23(3), 315-324. Ward, 
G. J., Rubhstein, F. M., Clear, R.D. (1988) A ray trac­ing solution for diffuse environments. Computer 
Gmphics 22(3), 85-92. Warnock, J. (1969 A hidden-surface algorithm for computer-generated 1?alf-tone 
pictures. Technical Report TR 4-15, NTIS AD-753 671, Computer Science Department, University of Utah. 
  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122741</article_id>
		<sort_key>207</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[NC machining with G-buffer method]]></title>
		<page_from>207</page_from>
		<page_to>216</page_to>
		<doi_number>10.1145/122718.122741</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122741</url>
		<abstract>
			<par><![CDATA[The G-buffer method is applied to NC machining. A total NC system is created that consists of all essential functions, such as tool path generation, path verification, and feed rate control. Moreover, any combination of object surface and tool shape is acceptable. By utilizing G-buffers created from a parallel projection, the required NC functions are realized as image processing operations. This ensures that the NC software is independent from surface description. Conventional rendering software can be used to make the G-buffers. Any surface can be milled if it can be rendered by parallel projection. Tool shape changes can be easily handled by changing the image processing filters. 3D examples of geometric surfaces, mesh data, and volume data are milled with this method, and the results show that the method is very effective.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[G-buffer method]]></kw>
			<kw><![CDATA[NC machine]]></kw>
			<kw><![CDATA[interference avoidance]]></kw>
			<kw><![CDATA[tool path]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.7</cat_node>
				<descriptor>Command and control</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010482.10010486</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Industry and manufacturing->Command and control</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31094956</person_id>
				<author_profile_id><![CDATA[81100652669]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Takafumi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saito]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Human Interface Laboratories, Nippon Telegraph and Telephone Corporation, 1-2356, Take, Yokosuka-shi, Kanagawa 238-03, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31096741</person_id>
				<author_profile_id><![CDATA[81332530949]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tokiichiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takahashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT Human Interface Laboratories, Nippon Telegraph and Telephone Corporation, 1-2356, Take, Yokosuka-shi, Kanagawa 238-03, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>10541</ref_obj_id>
				<ref_obj_pid>10515</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Zhang, D., and Bowyer, A., "CSG Set-Theoretic Solid Modeling and NC Machining of Blend Surfaces", Proc. Y2nd Annual A CM Conf. Computational Geometry, pp. 236-245, 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Sakuta, T., Kawai, M., and Am&amp;no, Y., "Development of an NC Machining System for Stamping Dies of Offset Surface Method~, Proc. Autofact '87, pp. 2-13 - 2- 27 (1987).]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kishinami, T., Kondo, T., and Saito, K., "Inverse Offset Method for Cutter Path Generation~, Proc. 6th Int'l Conf. Production Engineering, pp. 807-812, 1987.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Wang, W. P., and Wang, K. K., "Real-Time Verification of Multiaxis NC Programs with Raster Graphics", Proc. IEEE int'l Con}. Robotics and Automation, pp. 166-171, 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Wang, W. P., and Wang, K. K., "Geometric Modeling for Swept Volume of Moving Solids~, IEEE Computer Graphics and Applications, Vol. 6, No. 12, pp. 8-17 (1986).]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15887</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hook, T. V., ~Real-Time Shaded NC Milling Display~, Computer Graphics, Vol. 20, No. 4, (Proc. SIC;. GRAPH "86), pp. 15-20 (1986).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Atherton, P., Earl, C., and Fred, C., "A Graphical Simulation System for Dynamic Five-Axis NC Verification", Proc. Auto}act '87, pp. 2-1 - 2-12 (1987).]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kawashima, Y., Itoh, K., Nonaka, S., and Ejiri, K., "A Flexible, Quantitative Method for NC Machining Verification Using a Space Division Based Solid Model~, New Advances in Computer Graphics (Proc. CG Inter. national '89), pp. 421-437 (1989).]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Chappel, I. T., "The Use of Vectors to Simulate Material Removal by Numerically Controlled Milling", Computer Aided Design, Vol. 15, No. 3, pp. 156-158 (1983).]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>41971</ref_obj_id>
				<ref_obj_pid>41958</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Drysdale, R. L., mad Jerard, R. B., "Discrete Simulation of NC Machining", Proc. 3rd Annual ACM Cony. Computational Geometry, pp. 126-135, 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617458</ref_obj_id>
				<ref_obj_pid>616003</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jeraxd, R. B., Drysdale, R. L., Hauck, K., Schaudt, B., and Magewick, J., "Methods for Detecting Errors in Numerical Controlled Machining of Sculptured Surfaces", IEEE Computer Graphics and Applications, Vol. 9, No. 1, pp. 26-39 (1989).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jer~rd, R. B., Hussaini, S. Z., Drysdale, R. L., and Schaudt, B., "Approximate Methods for Simulation and Verification of Numerical Controlled Machining Programs", Visual Computer, Vol. 5, No. 6, pp. 329- 348 (1989).]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97901</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Saito, T., and Tak~hashi, T., "Comprehensible Rendering of 3-D Shapes", Computer Graphics, Vol. 24, No. 4, (Proc. SIGGRAPH '90), pp. 197-206 (1990).]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 NC Machining with G-buffer Method Takafumi Saito 
Tokiichiro Takahashi NTT Human Interface Laboratories Nippon Telegraph and Telephone Corporation 1-2356, 
Take, Yokmuka-shi Kanagawa 238-03, JAPAN Abstract The G-buffer method is applied to NC machining. A 
total NC system is created that consists of all essential functions, such as tool path generation, path 
verification, and feed rate con t rol. Moreover, any combination of object surface and tool shape is 
acceptable. By utilizing G-buffers created from a parallel pro~ction, the required NC functions are realized 
as image processing operations. This ensures that the NC software is independent from surface description. 
Conventional rendering soft ware can be used to make the G-buffers. Any surface can be milled if it can 
be rendered by parallel projection. Tool shape changes can be easily handled by changing the image processing 
filters. 3D ex­amples of geometric surfaces, mesh data, and volume data are milled with this method, 
and the results show that the method is very effective. CR Categories and Subject Descriptors: 1.3.3 
[Com­puter Graphics]: Picture/Image Generation; 1.4.9 [Image Processing]: Applications; J.6 [Computer-Aided 
Engineer­ing]: Computer-Aided Manufacturing. Additional Key Words and Phrases: NC machine, tool path, 
G-buffer method, interference avoidance, simulation. Permission to copy without fce all or part of this 
material is granied provided that the copies are not made or distributed for direct commermal advantage, 
the ACM copyright notice and the title of the publication and its date appear, and notice is given that 
copying is by permission of the Assmiation for Computing Machinery. To copy otherwise. or to republish. 
requires a fee ancflorspecific permission. 1 Introduction While the thrust of modern computer graphics 
is the visual­ization of the real world, people must use actual 3D objects to survive. One interface 
between conceptual and actual ok jects is that created by CAD/CAM systems coupled to nu­merically controlled 
(NC) milling machines. Unfortunately, this interface is not as efficient or productive as it should be. 
The problem lies in the large number of factors that must be considered when machining a complex object. 
CAD/CAM systems were initially used to produce rel­atively simple objects whose profiles could be described 
as combination of geometric primitives. The production of more complex objects demands the creation of 
highly so­phisticated tool paths. This is due to the following factors. 1. Shape accuracy: Over cutting 
must be prevented and the degree of under-cutting accurately evaluated. This requires the interference 
between tool and required surface to be constantly monitored. 9 . Tool load: Cutting rate must not exceed 
the limits of tool, milling machine, or workpiece. 3. Tool movements: Unplanned collisions between workpiece 
and tool or tool holder must be prevented. 4. Machining time: Tool selection, tool path, and feed rate 
should be opti­mized. 5. Variations in tool t~es and surface shapes: The tool path must accommodate 
the available tools and all possible workpiece shapes.  1~ ~hi~ ~apr, the words interference snd cO/h~tOn 
we used ~ the following meanings. interference: ReIation between tool and required surface It M a measure 
of over-cutting. collision: Contact of workpiece and upper part (without milling edge) of a tool. It 
damages the toel and/or the workpiece  ((91991 ACM-O-W791-436-8/9t/W7/0207 $OU.75 207    SIGGRAPH 
91 Las Vegas, 28 JuIY-2 Auwst 1991 A number of sophisticated methods have been devel­oped to address 
one or more of these factors, and some have turned into commercial systems. Each method can be characterized 
as one of two types: tool path generation, or machining simulation/verification. In path generation, 
the main purpose is to obtain an adequate tool path that pro­duces an accurate shape. The tool path can 
be obtained from the offset surface, i.e. the trace of the limit position of the tool center, and a lot 
of research has been performed to calculate an accurate offset surface [1,2]. Kkhlnami et al. have proposed 
a flexible algorithm called the Inverse Offset Method [3] which uses the rasterization technique. In 
simulation and verification, the tool path is verified for each factor listed above. Many systems have 
been developed for this purpose, and one of the major differences among them is the shape representation 
for interference calculw tion. Wang et al. [4,5], Hook [6], and Atherton et al. [7] all used a projection 
from a view point and applied a variation of the z-buffer algorithm. Thus, their methods are termed view 
based methods . Kawashirna et al. [8] implemented such a method by using an oct-tree data structure. 
Chap­pel [9] and Jerard et al. [10,1 1,12] represented the shape with direction vectors from discrete 
points distributed on the object s surfaces. Unfortunately, in conventional CAD/CAM systems, these two 
activities, tool path generation and simulw tion/verification, are usually independent of each other 
and based on different methodologies. This has two disadvan­tages. First, the entire software package 
is huge and exces­sive y complicated. This is because different programs are required for each activity 
in order to accommodate various shapes and tool types. Second, it is difficult to generate tool paths 
by using simulation results. This function is neces­sary because, for example, adequacy of a tool path 
for fine cutting depends on the result of rough cutting. To build a total NC program on one methodology, 
we extend the G-bufferz method [13] to 3 axis NC machining. A G-buffer (Geometric Buffer) is a 2 dimensional 
array, like an image. Each G-buffer contains one geometric property for all pixels such as depth, surface 
normal, etc.. By m­nipulating G-buffers, various kinds of rendering techniques can be realized with image 
processing operations. More­over, G-buffers generated from a parallel projection can also easily realize 
the many functions required for a totrd NC system by employing image processing operations. For ex­ample, 
it is easy to generate tool paths based on collision as well as interference. Many kinds of scanning 
operations are also available by referring to G-buffers. Tool paths can be simulated and evaluated with 
a series of image processing sequences. The optimum tool path and feed rate can be chosen from the evaluation 
results. Some functions of the proposed method are identical or similar to previously proposed functions, 
The offset surface generation algorithm is equivalent to Kishinami s Inverse Offset Method [3]. The simulation 
and verification methods can be regarded as simplifications of the conventional view based methods. However, 
these functions are very synergis­tic when implemented in a total G-buffer machining system. z~he pronunciation 
of (G, is ~~,~]~ ~~ the German alphabet [13] One of the notable advantages of the proposed method is 
that all parts of the NC software are independent of sur­face description. In order to make the G-buffers, 
conven­tional rendering software can be used. This means that any surface can be milled if it can be 
rendered by parallel pro~ction. Various tool shapes can be employed by simply changing the image processing 
filters. Dedicated graphics or image processing hardware, such as graphics workstations, can effectively 
perform all required computations. 2 G-buffers for NC Machining 2.1 Concept of G-buffer Method The G-buffer 
method []3] was originally developed for com­ prehensible rendering, and has the two following features: 
. The geometric properties for each pixel of the vtilble ob~ct are preserved in G-buffers; . Various 
rendering techniques are realized with image processing operations.  By using G-buffers as the intermediate 
result, geometric procedures (such as scan conversion and h~dden surface re­moval) and other procedures 
(such as shading, texture map ping, and enhancement) are completely separated. There­fore, they can be 
performed independently and efficiently. 2.2 G-buffer Set Required for NC The concept of the G-buffer 
method can be effectively ex­tended to 3 axis NC machining. By preparing a G-buffer set from a parallel 
pro~tion, it is possible to realize many kinds of NC software procedures as image processing operw tions. 
For NC machining, the following geometric properties are the typical contents of a set of G-buffers. 
. Z: world coordinate z (depth) . nx: normal vector z . ny: normal vector y  s nz: normal vector z 
. id: object/patch identifier . OU: patch coordinate u . ov: patch coordinate v  Only Z in this list 
is indispensable; the use of the other G­buffers depends on the procedures required for machining or 
verification. Figure 1 shows a shaded image and a Z-image of the famous Utah teapot. In this paper, rdl 
G-buffers and derived 2-dimensional arrays are called images. Images whose names begin with an upper 
case character contain absolute or relative height data. The unit height is equal to the pixel interval. 
   @@ 5.2 Sampling Error Sampling error is one disadvantage of G-buffer machining. Since height fields 
are calculated only at the center of each pixel, sampling errors occur at less than the pixel interval 
in horizontal directions. Over-cutting can be prevented by us­ing tool shapes with I pixel under-cutting, 
however, aliasing artijacts in large gradient regions cannot be avoided. Some anti-aliasing techniques 
in computer graphics can reduce sampling errors. Subpixel sampling is a powerful yet simple approach, 
but it requires a large amount of memory and computing power. According to Kishinami et al. [3], they 
succeeded in reducing the required memory capacity by employing the quad-tree data structure for path 
generation in their Inverse Offset Method. However, the quad-tree data structure makes the image processing 
operations for the NC functions so complicated that one of the most significant advantages of G-buffer 
machining, its simplicity, may be lost The tolerance of the machining result depends on the user s purpose. 
If the machined object is only to verify or evaluate the designed or given shape, then G-buffer ma­chining 
is acceptable. On the other hand, if the object is the final product, much more investigation about sampling 
error is required. 5.3 Computation Cost The proposed method incurs high computation cost when processing 
large objects with high precision. Table 1 shows the computation time to machine the examples in section 
4. This table presents the total time of path generation, simu­lation, and evaluation for each cutting 
phase. Although the values are reasonable for these examples, they become large for large objects. If 
the operations are simply implemented, the required memory space is CI(S=SM) and the computa­tion cost 
is fl(S=SV H.z ), where S, SMis the G-buffer size in pixels and H, is the tool radius in pixels. However, 
the problem of memory size will become less important in the near future since memory space of com­mercial 
computers is still increasing. Computation time can be reduced by using dedicated image processing hardware. 
Most operations are simple and iterative, so that vector pro­cessors or massively parallel processors 
can effectively accel­erate the calculation speed. There is also some possibility to reduce the computation 
cost with efficient algorithms, especially for flat endmills. 6 Conclusion We applied the G-buffer method 
to NC machining. By preparing G-buffers from a parallel projection, the various functions required for 
a NC system were realized with image processing operations. This allows any surface description and any 
tool shape to be used. Conventional hardware and software for computer graphics and image processing 
can be employed with this method. This makes NC system development much easier. Experimental results 
show that   Computer Graphics, Volume 25, Number 4, July 1991 our method can be effectively used in 
an actual machining process. The method should be a great tool, not only for CAD/CAM, but also for scientific 
visualization. Acknowledgements We would like to thank Dr. Rikuo Takano and Dr. Masashi Okudaira for 
their continuous support. We also wish to thank Hiroki Kobayashi for coding the programs of the ex­perimental 
system. We are very grateful to Dr. Jin Tamai of Nippon Medical School for providing us the original 
MR1 image data of Fig.15, and the colleagues in our section for helpfnl discussions. Table 1 Required 
memory space and computation time for G-buffer machining. Sun-4/370 was used for this experiment. Computation 
time for G-buffer generation is not included. Tool types are indicated as foflows. F6-:-4 = 6mm flat 
endmill; F3: ~ = 3mm flat endmill; Fl: d = lmm flat endmill; B3: R= 1.5mm ball endmill. Shape Fig.15 
(Brain) G-buffer Size (pixels) 200 x 200 Pixel Size %%%-+%% 0.30 mm Required Memory Space 0.56 MB Rough 
Cutting 224 Sec (F6) Fine Cutting 112 sec (B3 : lst) (B3) (B3 : lst) 181 Sec 54 sec (B3 :2r@ (B3 : 2nd) 
7 sec 188 sec (B3 :V) (FI : lst) 94 sec [Fl : ?nd) Corner Cutting SIGGRAPH 91 Las Vegas, 28 July-2 August 
1991 References [1] Zhang, D., and Bowyer, A., CSG Set-Theoretic Solid Modeling and NC Machining of Blend 
SUrfaces , Proc. %d Annual ACM Conf. Computational Geometry, pp. 236 245, 1986. [2] Sakuta, T., Kawai, 
M., and Amano, Y., Development of an NC Machining System for Stamping Dies of Off­set Surface Method 
, Proc. Autofact 87, pp. 2-13 2­27 (1987). [3] Kishinami, T., Kondo, T., and Saito, K., Inverse Off­set 
Method for Cutter Path Generation , Proc. 6th Int 1 Conf. Production Engineering, pp. 807-812, 1987. 
[4] Wang, W. P., and Wang, K. K., Real-Time Verifi­cation of Multiaxis NC Programs with Rsster Graph­ics 
, Proc. IEEE Int 1Conf. Robotics and Automation, pp. 166-171, 1986. [5] Wang, W. P., and Wang, K. K., 
Geometric Modeling for Swept Volume of Moving Solids , IEEE Computer Graphics and Applications, Vol. 
6, No. 12, pp. 8 17 (1986). [6] Hook, T. V., Real-Time Shaded NC Milling Dis­play , Computer Graphicu, 
Vol. 20, No. 4, (Proc. SIG-GRAPH 86), pp. 15-20 (1986). [7] Atherton, P., Earl, C., and Fred, C., A Graphical 
Simulation System for Dynamic Five-Axis NC Verifi­cation , Proc. A utofact 87, pp. 2-1 2-12 (1987). 
[8] Kawashima, Y., Itoh, K., Nonaka, S., and Ejiri, K., A Flexible, Quantitative Method for NC Machining 
Ver­ification Using a Space Division Based Solid Model , New Advances in Computer Graphics (Proc. CG 
Inter­national 89), pp. 421-437 (1989). [9] Chappel, I. T., The Use of Vectors to Simulate Ma­terial 
Removal by Numerically Controlled Milling , Computer Aided Design, Vol. 15, No. 3, pp. 156-158 (1983). 
[10] Drysdale, R. L., and Jerard, R. B., Discrete Simul­tion of NC Machiningn, Proc. $?rd Annual A CM 
Conf. Computational Geometry, pp. 126-135, 1987. [11] Jerard, R. B., Drysdale, R. L., Hauck, K., Schaudt, 
B., and Magewick, J., Methods for Detecting Errors in Numerical Controlled Machining of Sculptured Sur­facesn, 
IEEE Computer Graphics and Applications, Vol. 9, No. 1, pp. 26-39 (1989). [12] Jerard, R. B., Hussaini, 
S. Z., Drysdale, R. L., and Schaudt, B., Approximate Methods for Simulation and Verification of Numerical 
Controlled Machining Programs , Visual Computer, Vol. 5, No. 6, pp. 329­348 (1989). [13] Saito, T., and 
Takahashi, T., Comprehensible Ren­dering of 3-D Shapes , Computer Graphic8, Vol. 24, No. 4, (Proc. SIGGRAPH 
90), pp. 197-206 (1990). 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122742</article_id>
		<sort_key>217</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Geometrically deformed models]]></title>
		<subtitle><![CDATA[a method for extracting closed geometric models form volume data]]></subtitle>
		<page_from>217</page_from>
		<page_to>226</page_to>
		<doi_number>10.1145/122718.122742</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122742</url>
		<abstract>
			<par><![CDATA[We propose a new approach to the problem of generating a simple topologically-closed geometric model from a point-sampled volume data set. We call such a model a Geometrically Deformed Model or GDM. A GDM is created by placing a 'seed' model in the volume data set. The model is then deformed by a relaxation process that minimizes a set of constraints that provides a measure of how well the model fits the features in the data. Constraints are associated with each vertex in the model that control local deformation, interaction between the model and the data set, and the shape and topology of the model. Once generated, a GDM can be used for visualization, shape recognition, geometric measurements, or subjected to a series of geometric operations. This technique is of special importance because of the advent of nondestructive sensing equipment (CT, MRI) that generates point samples of true three-dimensional objects.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[constraint minimization]]></kw>
			<kw><![CDATA[deformable models]]></kw>
			<kw><![CDATA[geometric modelling]]></kw>
			<kw><![CDATA[volume modelling]]></kw>
			<kw><![CDATA[volume visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Viewing algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14068817</person_id>
				<author_profile_id><![CDATA[81537491156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Design Research Center, Rensselaer Polytechnic Institute]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39023663</person_id>
				<author_profile_id><![CDATA[81100023224]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Breen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Design Research Center, Rensselaer Polytechnic Institute]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P299459</person_id>
				<author_profile_id><![CDATA[81100054474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Lorensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[General Electric Company, Corporate Research and Development and Rensselaer Design Research Center, Rensselaer Polytechnic Institute]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31088940</person_id>
				<author_profile_id><![CDATA[81332519065]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[O'Bara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Design Research Center, Rensselaer Polytechnic Institute]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43118069</person_id>
				<author_profile_id><![CDATA[81100251533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Wozny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Design Research Center, Rensselaer Polytechnic Institute]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Serra. Image Analysis and Mathematic~al Morphology Volume !. Academic Press, 1982.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16523</ref_obj_id>
				<ref_obj_pid>16520</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S,R, Sternberg. Gray.scale morphology. Computer ~Tsion. Graphits, and Image Processing, (35):333-355, 1986.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R.A Drebin, L. Carpenter, and P, Hanrahan. Volume rendering. Computer Graphics, 22(4):65-74, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E, Artzy, G. Frieder, and G. Herman. The theory, design, implementation, and evaluation of a three-dimensional surface detection algorithm. Computer Graphits and Image Prot'essing, 15" 1-24, 1980.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>66976</ref_obj_id>
				<ref_obj_pid>66970</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W.C. Lin, S.Y. Chen, and C.T. Chen. A new surface interpolation technique for reconstructing 3d objects from serial cross-sections. Computer Vision, Graphie's. and Image Prot'essing, 48:124-143, 1989.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>359846</ref_obj_id>
				<ref_obj_pid>359842</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Fuchs, Kedem Z.M., and Uselton S.P. Optimal surface reconstruction from planar contours. Comm. ACM, 20( 10):693-702, 1977.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W.E. Lorensen and H.E. Cline. Marching cubes: A high resolution 3d surface construction algorithm. Computer Graphit's, 21(4):163-169, 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H.E. Cline, W.E. Lorensen, S. Ludke, Crawford C.R., and B.C. Teeter. Two algorithms for the three-dimensional reconstruction of tomograms. Medit'al Physics, 15(3):320- 327, 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Kass, A. Witkin, and D. Terzopoulos. Snakes: Active contour models. International Journal of Computer Vision, pages 321-331, 1988.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulus, A. Witkin, and M. Kass. Symmetry-seeking models and 3d object reconstruction. International Journal of Computer Vision, 1(3):211-221, October 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>949543</ref_obj_id>
				<ref_obj_pid>949531</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J,V. Miller, D.E. Breen, and M.J. Wozny. Extracting geometric models through constraint minimization. Visualization '90 Proceedings, pages 74-82, 1990.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>66684</ref_obj_id>
				<ref_obj_pid>66683</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Bajcsy and S. Kova~,i6. Multiresolution elastic matching. Computer Vision, Graphics and Image Processing, (46):1- 21, 1989.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37429</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Witkin, K. Fleischer, and A. Barr. Energy constraints on parameterized models. Computer Graphics, 21(4):225-232, July 1987.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D.E. Breen. Choreographing goal-oriented motion using cost functions. State-of-the-Art in Computer Animation (Computer Animation '89 Conference Proceedings), pages 141-151. eds N. Magnenat-Thalmann and D. Thalmann (Springer-Verlag, Tokyo, June 1989).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Fieischer. Deformable models. The Visual Computer, 4:306--311, 1988.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>22881</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R.C. Gonzalez and P. Wintz. Digital Image Processing. Addison-Wesley, 1987.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J.F. Canny. Finding edges and lines in images. Masters thesis, Massachusetts Institute of Technology, Cambridge, Massachusetts, June 1983.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[S. Kirkpatrick, C.D. Gelatt, and M.P. Vecchi. Optimization by simulated annealing. Science, 220(4598):671--680, 1983.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M.J. Wennington. Spherical Models. Cambridge Univerity Press.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J.V. Miller. On gdm's: Geometrically deformed models for the extraction of closed shapes from volume data. Masters thesis, Rensselaer Polytechnic Institute, Troy, New York, December 1990.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GeometricallyDeformed Models: A Method for Extracting Closed Geometric Models from Volume Data James 
V. Miller David E. Breen William E. Lorensent Robert M. O Bara Michael J. Wozny Rensselaer Design Research 
Center Rensselaer Polytechnic Institute General Electric Company Corporate Research ABSTRACT We propose 
a new approach to the problem of generating a simple topologically-c losed geometric model from a point-sampled 
vol­ume data set. We call such a model a Geometrically Deformed Model or GDM. A GDM is created by placing 
a seed model in the volume data set. The model is then deformed by a re­laxation process that minimizes 
a set of constraints that provides a measure of bow well (be model tits the features in the data. Constraints 
are associated with each vertex in the model that con­trol local deformation, interaction between the 
model and tbe data set. and the shape and topology of tbe model. Once generated, a GDM can be used for 
visualization. shape recognition, geometric measurements. or subjected to a series of geometric operations. 
This technique is of special importance because of the advent of nondestructive sensing equipment (CT, 
MRI ) that generates point samples of true three-dimensional objects. CR Categories: 1.3.3 [Computer 
Graphics]: Picture/fmage Generation di.rp/uy u/gori//vns iie~ ing a/gorirtms: 1.3.5 [~omputer Graphics]: 
 Computational Geometry and Object Modelling (wr~c. .ruffa~e, solid, and objec[ leprt .retltutif>~l.s; 
Additional Keywords and Phrases: Deformable Models, Geo­metric Modelling, Volume Visualization. Volume 
Modelling, Con­straint Minimization 1 INTRODUCTION The development of remote sensing and scanning technology 
per­mits the nondestructive examination of an object s internal struc­ture. This ability has proven to 
be essential in numerous engi­neering and medical fields. It allows for the inspection of me­chanical 
parts without destroying the product and tbe examination of internal organs without operating on the 
patient. Tbe technol­ogy generates a discrete tbree-dimensional scalar field where each value is a measure 
of some physical property, for example density. Since this data is produced via point sampling, it inherits 
all tbe Permission to copy wi[hmrt (cc atl or part of this mirrcrial is gmntcd pnwdcd [htii the copies 
arc nt>(made or distributed for cfircct commcrcid afvwmigc, the ACM cnpyright noticc and [he tilk of 
the publication imd its date appcur. wsd notice IS given that copying is by pcrmissi(m of {hc Aswcia[i{m 
fnr C(mpu(ing Machinery. To copy n!herwisc, (w to republish. rcquirci a fcc muf/or specific pcrmiwimr 
  and Development properties and problems of sampled data. These include artifacts. spatial aliasing, 
and noise. The scalar field can posed of a series of two-dimensional slices, that when form the three-dimensional 
volume. Traditionally, each was viewed separately, requiring a specialist to deduce sampling be com­stacked. 
2D slice tbe true 3D structure represented in the data. There are two alternative methods of displaying 
and analyzing the raw scalar field. One treats the volume data in its original form, as in both morphology 
and volume rendering [ 1, 2. 3]. The other transforms the data into something that is more readily displayed, 
[4, 5, 6, 7, 8]. However. a more powerful approach generates of the scanned objects using the volume 
data the object configuration [9, 10, 111. This differs such as a surhce geometric models as a measure 
of from the second method in that it approximates rather (ban interpolates the data. Tbe major motivation 
behind this approach is that a geometric model provides the greatest number of options for analyzing 
and visualizing the original object. Once created, such a model can be used for inspection, visualization, 
or subjected to a series of geometric measurements and operations. Generating a model bas the effect 
of removing the noise from scanned data making object identification easier. Defects in an object will 
result in a model that is malformed, thus emphasizing the defect. A geometric measurement, such as volume, 
may be easily performed on a geometric model. CSG operations may be applied to both tbe model and other 
geometry in order to convey further information about the extents and interrelationsbips of the structures. 
In this paper, we present a methodology for extracting a topolog­ically closed geometric model from a 
volume data set. The tech­nique, called Geometrically Deformed Models (GDM s), starts with a simple model 
that is already topologically closed, and de­forms the model based on a set of constraints, so that the 
model grows (or shrinks) to fit the object within the volume while main­taining its closed and locally 
simple (non-self-intersecting) nature. The initial model is a non-self-intersecting polyhedron that is 
ei­ther embedded in tbe object or surrounds the object in the volume data representation. A function 
is associated with every vertex of the polyhedron that associates costs with local deformation, adherence 
to properties of simple polyhedra, and the relationship between noise and feature. By minimizing these 
constraints, one achieves an effect similar to inflating a balloon within a container or collapsing a 
piece of shrink wrap around an object. ,{,I(fy} A( M -()-89791-4M-X/9I/00702 17 $ot)7s 217 Contour for 
Slice N+ I Triangular Strip  Contour for Slice N Figure 1 A surface can be c eated by stitching together 
the 2D contours extracted from adjacent slices in a volume data set. 2 PREVIOUS WORK Previous techniques 
for extracting three-dimensional geometries from volume data fall into three categories: contour stitching, 
surface construction, and de Formable models. Fuchs, Kedem and Uselton developed a means of stitching 
a series of two­dimensional contours together by fitting a triangular strip between adjacent contours 
[6] (Figure 1). Lin, Chen and Chen con­nected two-dimensional contours using spline theory, quadratic 
variation-based surface interpcJation, and dynamic elastic contour interpolation [5]. In either mtthod, 
every contour that composes the object needs to be identified for every slice in the data set. Plus the 
complexity of the algorithms increases when adjacent slices have a different number of c,mtours, referred 
to as the branch­ing problem. GDM s have nei [her of these complications because they treat the data 
set as a complete volume as opposed to a series of slices. This allows the branching problem to be handled 
im­plictly by treating concavities in the direction normal to the slice plane (branches) in the same 
manner as any other concavity in the data set. The problem of identl fying all the contours that compose 
the object is removed because a GDM naturally probes through the entire object following all of its branches. 
Herman, Frieder, and Artzy tracked the surface of an object using the voxel data as a graph [4]. A voxel 
containing the surface of the object is identified and the algorithm traverses the neighboring voxels 
genert ting a topology that is guaranteed to be closed. This work does not suffer from the branching 
problem discussed with contour stitching because the algorithm follows the surface as it travels through 
the volume. Lorensen and Cline developed marching cubes [7] to simply extract a list of polygons from 
vohtme data w th no connectivity information. In their algorithm, a cube is bounded by eight pixels located 
on two adjacent slices. Each vertex is coded as either inside or outside the object relative to the surface 
defining threshold. Based on the configuration of vertices that lie inside and outside the objec~ the 
cube is triangulated, each :riangle indicating a portion of the surface. Marching cubes was extended 
into dividing cubes [8] by Cline et al. Dividing cubes rwrnples the voxels to the desired display resolution 
in order to generate points with normals instead of triangles. Marching and Dividing cubes do not suffer 
from the branching problem becau:;e they extract the entire surface located in the volume. The problem 
with this group of surface construction algorithms is thal they are restricted to generating models where 
each element ir the model is at most the size of a voxel, hence they cannot approximate the data. Also, 
these algorithms are not applicable :0 the task of generating a closed model of an object that is nc,t 
necessarily closed, for instance the interior of an opened wire bottle. In this case, they will either 
extract a model with little resemblance to the desired object, or they will extract multiple objects. 
GDM s on the other hand 218 can produce models of varying resolution. This provides a data reduction 
and aides in the GDM s ability to bridge over the holes in the boundary of an object. Kass, Witkin, and 
Terzopolous have developed snakes [9] which model the contours of an image by minimizing the energy associ­ated 
with a spline. The energy of a snake configuration is based upon the image and its first and second derivative, 
the curvature of the edge components in the image, and the first and second derivative of the spline. 
Terzopotshss, Wltkin, and Kass extended the concept of snakes into symmetry-seeking models [ 10], that 
derive a threedimensional shape from a two-dimensional image by modelling an axisymmetric elastic skin 
spread over a flexible spine. These approaches provide a compact representation of an object or feature 
and should be tolerant of noise, but they are cur­rently limited to 2D data and at most 2.5D models (for 
symmetry­seking models). Snakes and symmetry-seeking models can take advantage of u priori information 
about the configuration and ori­entation of the object being modelled, but they do not provide a multi-resolution 
approach to probing the data. Finally, since the internal energy of the spline is a global operation, 
it would appear to be difficult to parallelize the algorithm. GDM s are very similar to snakes except 
they can probe volume data, thus generating 3D models; they can probe the data with a low resolution 
model then substitute a higher resolution model; and a GDM is controlled through local geometric operations 
on a discrete model, hence it is easily parallelized. In another deformable matching technique, Bajcsy 
and Kovatlii5 used a mukiresohttion approach to elastically deform a known brain atlas to match a scanned 
brain[ 12]. This approach decreases the resolution of the data set then deforms the brain atlas so the 
outer edge and ventricles matches the data. The resolution is then increased and the deformation process 
repeated. This approach motivated GDM s to operate on the slice data as a true volume and to vary the 
resolution of the model during its deformation. The drawback to deforming an atlas to tit an object is 
that an atlas is required for every object to be modelled. The proposed solution of deforming a model 
to fit an object is based upon Witkin et al. s [13] work on energy constraints and Breen s work on goal-oriented 
motion for computer animation [14], and reflects a simpler approach to the problems presented by Kass 
et al. [9], Terzopmdos et al. [15, 10], and Bajcsy et al. [12]. These other approaches model the elastic 
nature of a curve or surface to control the model s deformation. Such models are based on the differential 
equations of elastic materials. GDM s, on the other hand, do not try to model an elastic substance; in 
contrast they model a simpler discrete deforming structure influenced by local geometric constraints. 
3 CONSTRAINT MODELUNG AND MINIMIZATION GDM s may be envisioned as a semi-permeable balloon located inside 
the scanned object. The balloon expands until its surface reaches the boundary of the scanned object. 
The balloon is actually a collection of discrete polygons. The volume data is sampled only at the vertices 
of these polygons. Permeability is achieved because elements of noise and insignificant features pass 
through the faces of the polyhedron, thus allowing the vertices of the polygonal mesh to miss or work 
around these elements. By placing a cost function at each vertex in the mesh, the relevant characteristics 
of the balloon can be modelled. By minimizing these cost functions, the balloon is expanded while maintaining 
its topology. 3.1 CONSTRAINT MODELLING GDM s are created using a top down algorithm specification. First 
the behavior and characteristics of the model are defined. Then constraints m-e selected to achieve the 
desired behavior. Finally, functions are developed that model the constraints. Three or­thogonal behaviors 
must be specified. The first is a mechanism for generating gross deformations. In the balloon analogy, 
this mechanism expands the balloon. Second. a mechanism is needed rha[ will interact with the data set 
and identify voxels possibly containing the object boundary. This function restricts the bal­loon from 
expanding through the boundary of the object being modelled. Finally, since all operations are performed 
locally and the boundary of the object may be incomplete, the third function maintains the local topology 
of the model. This keeps the balloon from intersecting itself locally. Each of these behaviors can be 
modelled by a term in a local cost function associated with each vertex in the model (cost functions 
are also referred to as potential functions). As each cost function is minimized. the model deforms while 
searching for the boundary of the object and maintaining its topology ([ 11] provides cost functions 
suitable for a 2D GDM). At each time step, every model point has the opportunity to move to a position 
of lower potential. Each constraint function, therefore, must produce a lower cost as the model moves 
towards satisfying that constraint. The cost for the current position of the vertex is a linear combination 
of the individual cost functions, which allows for one term to dominate the deformation. Each cost term 
must therefore have the ability to assert itself and dominate the overall cost function when its constraint 
is being violated, as well as seem insignificant when its constraint is being satisfied. The cost function 
associated with the current location of a model point is the weighted sum C ,(,/.//. :) = (/,,D(.I.!/. 
:) + (111( .r. !/.:) + (JIT, (1) where: C ,(r. {I. : ) is the cost associated with this position of 
the current model point. D( .r. {i. : ) is the potential field that drives the model point towards the 
boundary. 1( .r. V. : ] is the image term that identities feature events, T, is a measure of how the 
local configuration of polygonal faces satisties the topology of the model, ({~~.(J1. II2 are the individual 
weighting coefficients that allow the magnitudes of the various parameters to be scaled, C,(.r. :/. 
:). D(.r. {I. : ). 1(.r. v. :). ~,.flo. (II. f{j z 0. 3.1.1 DEFORMATION POTENTIAL D(.r. {/.:) The 
deformation potential defines a scalar field where each posi­tion in space is assigned a value based 
on a frame of reference. In this case. a frame of reference can be any configuration of image or model 
parameters. The frame of reference may be a point in­side the feature to be model led. or it may be a 
set of vertex points in their previous configuration. The deformation potential must monotonically decrease 
(or increase) from the frame of reference and will repel (or attract) the current model point away from 
(or towards) its frame of reference. Normal Ikacking: Simple concave models can be created using a localized 
deformation potential. Each vertex is attracted to a Computer Graphics, Volume 25, Number 4, July 1991 
Stql I SIql 2 step 3 Figure 2 Surface normals directing a model to bend around a concavity. point located 
in the direction of the polyhedron surface normal at that vertex. During each deformation cycle, each 
vertex moves in the general direction of the local surface normal. As a concavity is encountered, the 
topology and image event constraints influence the deformation, The surtiace normal rotates around the 
concavity, allowing the model to continue its deformation inside of the region that was previously hidden 
from view (Figure 2).  3.1.2 IMAGE EVENTS 1(.r. //. : J This class of constraint counterbalances the 
deformation potential. It is used to restrict, direct. tsnd oppose the general progression of the deformation. 
Basically this constraint informs the vertex that it may be in contact with a voxel containing the original 
object (feature voxel). This constraint need not be able to distinguish noise and object since at the 
resolution of I voxel the two are indistinguishable, but must be able to identify the transition from 
a region of the data set that could be a feature to a region of the data set that is definitely not a 
feature. The important aspect of this constraint is that it introduces a local minimum at boundary events. 
Operations that identify boundary events include digital gradients [ 16], the Canny operator [ 17], and 
morphological opcmtions [2]. Although any of these opcrfitor\ would \uffice. GDM \ can operate with a 
much simpler event detector. A shifted threshold opemtor where: l)t),/!/I (r. y. : ) is the grcy-level 
intensity of the voxel at (X,y,z), T is a threshold value that identities the object: is shown in Figure 
3. Recall that the image event detector identifies the transitions from regions that are definitely not-object 
to regions of the image that could be object. The threshold, T. categorizes each voxel as either not-object 
or possibly object. Here a voxel that is not part of the object returns a value of zero, while a voxel 
that i\ part of the object returns the amount it exceeds the object identit ying threshold. The image 
event operator in conjunction with the minimization process and the trilinear interpolation of voxel 
values allows for the true object edge to be located. When a model point steps over the edge of an object. 
1( .r. g. : ) returns a value that should increase the overall cost of the system. The minimization process 
is forced, therefore, to either move the vertex by a smaller amount or to not move the vertex at all. 
Hence the vertex will approach the edge without crossing over it (unless it\ nei.gbbors pull it over 
the edge). SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 ~ I Baseface-notpatlofGDM Baseface-notparlofGDM 
butpartofsolid butpatlofsolid (a) (b) d. distancefromcemroid D=Maximumofbaseplane dimensioncurvature 
-d/D (c) Figure 4 (a) A local solid motel can be cut out of a GDM, by assuming that adjacent neighbors 
are connected in a fashion that will close the local solid model. ( ~) A vertex is conlained by its base 
if the projection of the vertex onto the base is a point interior to the base. (c) The ratio of :he distance 
between a model point and the centroid of its neighbors to the maximum dimension of the base plane gives 
an estimate of the curvature. I(x,y,z) I / / /,/ / L .__.-L~. T Intensity Figure 3 The image event dete;tor 
used for GDM s is a simple shifted threshold (.1- T)+. H,:re the cost function returns zero if the voxel 
value is below the edge threshold, otherwise it returns a value that indicates how much the voxel value 
exceeds the edge threshold. 3.1.3 MAINTAINING TOPOLOGY T, The final constraint maintains the topological 
integrity of the model and controls the spatial frequency of the model. The first two constraints cause 
the model to deform until all the vertices reach the boundary of the object. These two constraints are 
not sufficient to extract a georr etric model from real data. For instance, the boundary of the objsct 
may be incomplete, consisting of gaps and holes. This may allow the vertices of the model to leak out 
of the object and travc I without restriction towards the boundary of the data set. Alternatively, the 
data set may have elements of noise that could cz use the image event detector to incorrect ly categorize 
the noise as the boundary of the object. These two situations, coupled with the expansion or lack of 
expansion of the remainder of tht model, may result in a geometric model that has little resemblance 
to the original object. h is therefore necessary to have the geometry of the model irrflu­ence a portion 
of the deformation. Since a topologically simple geometric model is desired, a constraint is added to 
the system that will maintain the locally simple nature of the initial model. The topological constraint 
is also referred to as a maintenance con­straint. This term also controls the spatial frequency of the 
mcdel by keeping vertices from leaking out of the holes in the boundary of object, as well as preventing 
vertices from being caught on an element of noise. These two behaviors are essentially duals. In the 
case of a vertex leaking out of a hole, there is a single vertex that is continuing its deformation while 
its neighbors have reached the bounda~ of the object. In the case of noise confrontation, a single vertex 
believes that it has found the boundary of the object while its neighbors continue their deformation. 
In either case, the faces associated with this vertex will become much larger than the faces in the immediate 
vicinity. It is desirable for a vertex not to stray far from its neighbors or have its neighbors stray 
far from it. h is also desirable that the topology be maintained. Therefore, a vertex should be contained 
by its neighbors. A solid can be formed by the current mcidel point and its neighbors. Imagine that the 
current model point and its neighbors are cut out of the GDM. By connecting the adjacent neighbors, a 
solid is created. (Figure 4(a)). Any face of this solid that contains the current model point is also 
a face of the GDM, Any face strictly composed of the current model point s neighbors is not a face in 
the GDM, but will be referred to as the base in the new solid. For a planar base , the current model 
point is contained by its neighbors if, when it is projected onto the base plane, the projected point 
is in the interior of the polygon defined by the base (Figure 4(b)). If the base is not planar, this 
concept can still be applied to a polygon that is a planar approximation to the base. Curvature Estimation: 
Keeping a model point contained by its neighbors while keeping the model point from straying too far 
from its neighbors suggests that the local curvature of the model should be constrained. The ratio of 
the distance from the current model point to the centroid of its neighbors and the maximum disttince 
belwccn the rrcighhors of the current model poim gives tin indication 01 the curvature (Figure 4(c)). 
This mtio defines the topologicid constraint ,, (././/.:)-+~(J , .#) .:/) ~;. ­ 1 (3) lll:ix( ll(.l , 
.!/, .:,1 [.r A. YA. :A)ll) ,A where: (r. (i. : ) is [ht curren[ model poim, t) is the number of neighbors 
to the current model point, (.[ , .!/,. :,1. (.! h. [/k. :L ) are (he neighbors of the current model 
poinl. 1 ~ ,j. L ~ It. Thi\ function dirccvs Ihc vertex towtirch the centroid of the btise, which in 
turn. attcmpIs to mtihe all the faces incident to the current model point coplanar. Since all the vertices 
arc simultaneously trying to mo\fe onto the plane of their neighbors, the entire model defauhs to being 
spherictil (in [he absence of the other constraints). Dividing Ihc distwscc 10 the centroid by the maximum 
bme point repartition mointains \cale invurionce. 3.2 OPTIMIZATION METHOD The cost function minimization 
technique utilizes an adaptive ~lgorithm to move a vertex of the model in the direction of steepest descent 
tilorrg the cost surface. This direction is opposite to the gradient of the C(MIfunction C ,. and is 
estimated by numerically <fiq approxirnuting the differentials ,,, . ,,,, . ,j The amount ()that it point 
moves is adjusted based upon the current configuration of the COSIspace. The stepsize can be reduced 
three times if movement by the current \tepsize results in an increase in the COSIfunction, If a step 
cannot be completed that will reduce the cost of the vertex point, then [he vertex point is not moved. 
For the purposef of geometrically deformed models, the stepsizes are maintained in [he ronge of [ l/4, 
I ] voxels. This allows for rdpid changes in the dimensions of the model when it is in a void, m well 
a\ fine adjustments in the model when it encounters an elcmcot of noise or the boundary of the cavity. 
This technique will lind local minima. No global minimization techniques such m simulated annealing [ 
1Xl are performed; so global minima urc not tilways found: however, a gradient descent has pro\en sufficient 
for the data sets tested. The algorithm actually exploits the l~ct that only local minima are found, 
by detining its cost functions to introduce local minima whenever a critical point is crossed. A critical 
point occurs whenever a maintemmcc constr~in~ (T, ) is violated or when a possible feature \,oxel is 
encountered. 4 3D MODELS The initial model chosen for 3D GDM s is an icosahedron. An icowthedron is 020 
sided approximation to a sphere. The method­ology does no[ require an icosahcdron for its initial model; 
it was simply chosen for the property that when resampled, forming a geodesic. the connectivity remaim 
relatively uniform. Triangular faces ensure thtit the laces of the model are planar ond allow the model 
the greatest degree ot flexibility when fitting the scanned object. Each vertex in an icosahedron is 
connected to five other \wtices, If the entire icosahedmn is resampled, then each new vertex is six connected 
while the original vertices remain five connected. All vertices added through subsequent global resam­plings 
of the geodesic result in new vertices that are six connected Figure 5 An icosahedron s triangular Iacc 
is divided into four faces by connecting the midpoints of etich edge. The connectivity of the new vertices 
i\ six while the connectivity of the original vertices remains tive. while maintaining the 12 original 
vertices as five-connected. Fig­ure 5 illustrates how the triangular faces in an icosahedmrr can be resampled 
to form the faces of a geodesic [ 191. Bisection Ot each edge produces three vertices that are connected 
to form four fhces from the original f~ice. A global resampling of a GDM follows the same \teps as a 
global resampling of a geodesic. It is irrelevant that the fices of the GDM may not be as regular as 
the faces of a geodesic. Any triangular face can be divided into four fwes by connecting the midpoint\ 
of the edges. A global resamplirrg of a GDM refines the entire model on command. This allow\ a low resolution 
model to probe the data initially, while a higher resolution GDM can be substituted in order to capture 
finer detail. Using an initial low resolution GDM greatly reduces the computation time in extracting 
models. Note that the number of vertice\ increase\ with the number of edges (each edge is subdivided 
to form a new vertex). The number of vertices in the globally resampled model is roughly four time\ the 
number of vertices in the original model. Although a global resampling of a GDM retinef the model. the 
in­crease in the number of model points limits its appeal. After each refinement, the amount of work 
to deform the model increa\e\ b? a factor of four. Thus a global resampling must be used judi-CiOUSly. 
Alternatively the resampling may be localized, increas­ing the complexity of the model only in those 
regions where it is nece\sary. A local resampling can be performed in two operations. The first operation 
identities the regions of the model that need 10 be resamplcd. The second step subdivide\ the msociotcd 
face\ while maintaining the topological database wrd keeping all Iaccs triangular. The simplest way to 
identify the regions of the model that need to be resampled if based upon the desired level of detail. 
The level of detail in the extrdcted model is essentially the number of voxels approximated by a single 
face. Thu\ in order to maintain the level of detail, subdivide the face\ that exceed the lhreshold \ct 
by the level of detail. Identifying these faces can be accomplished by a simple area calculation. Miller 
[20] discusses the details of face resampling 5 CREATING GDM S Before a GDM can mobc J data set. several 
txwameter\ and facets of the algorithm must be specified: the obje~t (( )I,jt{v ) and not-object (-) 
classification, the deformation mode (grow, shrink), and the GDM p~rameters (~1~,.(I1. {IJ. T,). Fortunately 
this process benefits from the high degree of duality inherent to a GDM. Figure 6 and Table 1 summarize 
the duality between both 221 s166m AfHtl - Table I Duality relationships 1 I . object Image IImage 
Duals 1 7= Duals Definition _ Definition Duals +-Deformation Process Grow Shrink Figure 6 Duality relationships 
-the rows indicate duals formed by changing the deformation mode while the columns indicate duals formed 
by changing the object definition. the deformation mode and objet t classification. Growing a GDM with 
one classification of ol~je~tand -results in the same model as shrinking a GDM witt the roIes of object 
and ­reversed. The two models differ only in deformation time. Due to the resampling process e:nbedded 
in the GDM topological database, it is possible for a vel~ex to be added to the model on the wrong side 
of the object -+ m boundary. Recall that the minimization technique doe! not allow a vertex to move to 
a position of higher potential. Therefore all of the model points will approach the boundary of the ob,ject 
from the same side. A model point that tries to move to the opposite side of the boundary will have its 
image event detector active and thus will have a higher potential. But the resampling a gorithm may place 
new vertices on the opposite side of this boundary. Therefore, in order to move these model points to 
the other side of the boundary and hence increase the accuracy and quality of the model, the surface 
normal used in the deformation potential is defined to point in the opposite direction. This lot ally 
flips the deformation mode (i.e. from growing to shrinking) The effect is that a model point will migrate 
towards the true boundary of the object regardless of whether the model point is Iocaled in Object or 
. Ela Shrink Shrink (b) (d) Object (a) tEIQl Grow Grnw (c) (e) Figure 7 A GDM intersects the boundary 
of the Object ~m. The two deformation modes are equivalent in this case because the normals locally flip 
(dotted arrows indicate a change in the deformation sense). A beneficial side effect of a GDM locally 
reversing the sense of deformation is related to the placement of the initial model. As long as the initial 
model intersects the Object ~ -bound­ary (i.e. some of the model points are inside object, the remain­der 
are inside not-object), the model tends to seek out the true boundary of the object regardless of the 
deformation mode. This is a direct consequence of the duality and locality of deforma­tion modes. Note 
that the model extracted from growing will differ from the model extracted by shrinking only by the dimen­sions 
of the boundary. Figure 7(a) shows a model intersecting an object ~ -boundary. The deformation direction 
is shown for shrinking (Figure 7(b)) and growing (Figure 7(c)) a model. The solid deformation arrows 
indicate the deformation direction agrees with the primary deformation mode while the dotted deformation 
arrows indicate that the deformation mode has locally flipped sense. Figures 7(d) and (e) show the models 
at a later time step. Note that the two models approach the same boundary but they approach the boundary 
from different sides. The duality and locality of deformation modes works in favor of a GDM if the GDM 
intersects both object and not-object and if the GDM does not intersect muhiple objects. If a GDM does 
not intersect both regions of the data, then the deformation mode must agree with the placement of the 
initial model (in object or not-object). If the deformation mode is indeed correct, the GDM process extracts 
a geometric model of the boundary of the object. Otherwise, the GDM either collapses upon itself or extends 
out to infinity. Note that from the duality and locality of deformation modes, either case is feasible 
with either deformation mode. Our experiments show that the GDM parameter values (00, a ~. (IZ) are relatively 
data independent. This is due to aII. 01, a2 governing the GDM process, not the sampled data. Table 2 
summarizes the suggested parameter values. Note that the object classifying threshold, T, is data dependent. 
6 RESULTS The 3D GDM figures all present a GDM expanding within an object. The figures contain four frames. 
The first frame shows the initial model (upper-left). The second frame (upper-right) shows the model 
after several iterations. The third frame (lower-left) presents the GDM after an initial convergence 
to the shape of the 63 Computer Graphics, Volume 25, Number 4, July 1991 3D Parameters Deformation Gain 
a0 1 Image Event Gain al 1 Topological Gain a2 5 Resampling Threshold face area 10 Table 2 3D Suggested 
Parameters object. The final frame (lower-right) presents the final model. The final model was created 
by performing a global resampling on the GDM after the initial convergence to the shape of the object. 
The GDM was then allowed to converge to the shape of the object a second time. 6.1 CUBE The first 3D 
example is an artificially generated cube with one of its comers removed (Figure 8). The voxels inside 
the cube were assigned one intensity while the voxels outside the cube were assigned a different intensity 
(creating a 64x64~64 volume). The initial model consisted of 20 triangles and the resampling algorithm 
added roughly 1000 triangles. A global resampling was then performed to increase the model quality. The 
final model contains 4080 triangles. The marching cubes model consists of 11528 triangles. Therefore, 
a substantial data reduction was achieved (1000 triangles vs. 11528 triangles) before the final global 
resampling was applied (1000 face model is in the lower-left of Figure 8). A moderate data reduction 
is achieved if a final global resampling is applied to the model after the initial convergence (4080 
triangles vs 11528 triangles). The lower-right frame of Figure 8 shows the 4080 triangle GDM. The entire 
deformation required 50 iterations (approximately 15 minutes on an HP9000 835). 6.2 TURBINE BLADE The 
next 3D GDM example is a cooling chamber of a turbine blade. The source of the data is 96 industrial 
CT slices (256 by 256). The data is very clean, and the resulting GDM is shown in Figure 9. This model 
consists of 6560 faces and required 100 deformation cycles (approximately 30 minutes on an HP9000 835). 
The marching cubes model for this object is composed of 19000 triangles. 6.3 TOOTH The final 3D GDM is 
a model of the nerve in a tooth (Figure 10). The tooth was scanned using industrial CT (161 slices at 
256 by 256 pixels). The initial model was placed in one of the roots of the nerve. This GDM illustrates 
that highly concave models can be created. The final model has remarkable detail and is composed of only 
7392 faces while the marching cubes model for this object is composed of 20944 triangles.. This model 
required 200 deformation cycles (approximately 1.25 hours on an HP9000 835). 6.4 VERTEX GENERATION Figure 
11 shows a GDM where each vertex is assigned a scalar value based upon the generation (deformation cycle) 
of its cre-ation. The red vertices were created early in the deformation, Figure 8 A 3D GDM expanding 
within a cube with a comer missing. The final model is composed of 4080 faces. Note that the comers and 
edges of the cube are rounded. The topology constraint lowered the spatial bandwidth of the model below 
the spatial bandwidth of the original data. Figure 9 A 3D GDM of the cooling chamber in a turbine blade. 
The normal tracking deformation potential allows for the concave model to be extracted. hence they are 
the oldest vertices. The yellow and green ver-tices were added later in the deformation process, hence 
they are progressively younger. Finally the blue vertices were added to the model as it approached its 
final orientation, hence they are the youngest of all. This illustrates how the vertices are added only 
in expltiin the global crossings in a simple object. An edge of a concavity can be smaller [him the 
faces in the GDM, [f new vertices are added in this region, imprecision may place them on different sides 
of the edge m perhaps within the other faces of [he model, The surhce normal ctin also be affected by 
a lack of precision. If the faces in the model are rather small, small errors in arithmetic can produce 
a large errors in the sur~dce normal, Therefore the larger neighborhood is essentially Wrfonning a low 
pass filter on tbe surface normals in order 10 compensate, for precision problems. Precision also limits 
the choice of initial models. For example. a 640 point geodesic approximation to a sphere of radius I 
created a very nonuniform model until the size of the model increased to a sphere of reasonable radius, 
8 FUTURE WORK The fmmework for CIDM s is complete; however, there are a few ideas and concepts that could 
not be completely investigated. These concep(s are secondary in nature. in that they are not essen­tial 
to tbe theory or operation of a GDM. but they may improve perfomuuw or create additional applications. 
The current imple­mentation of GDM s was established so that various ideas and geometrical rclaticsnships 
could be tested with relative case. As such, the implementation is fw from optimal. An alternative data 
structure [hat slore~ semi-permanent relations (information thal is constant through a deformation iteration) 
could reduce the defor­mation time by an order of magnitude. Future research efforts should concentrate 
on two basic areas: model quality and alternative data sets. Model quality may be improved by an alternative 
resampling algorithm and by prevent­ ing global crossings (model self-intersection), GDM s should also 
be extended to automatically handle data sets with multiple ob­jects and to handle higher dimensional 
spaces, for instance time varying volumes, 9 CONCLUSION A GDM extracts a closed topologically simple 
(non-self­intersecting) geometric model of an object located in a discrete or continuous data set. An 
initially closed model is embedded in the data set and defomled to fit the object through the minimization 
of a set of constraints. These constraints are local operations that quantify the deformation, the properties 
of simple polyhedra, and the relationship between object and not-object. The final model remains closed. 
because the initial model is closed and the con­straints used to deform the model maintain the closed 
and locally simple nature. The major benetit of GDM s is that they aggregate sampled data by placing 
geometrical relationships on the model, as opposed 10 interpreting and analyzing the sampled data directly. 
This allows the model to interact favorably with artifacts of noise that either remove portions of the 
boundary or insert false boundaries. GDM s are highly adaptive allowing for a generic initial convex 
model to be transformed into a highly concave object. Alternative initial models can be used that reduce 
the deformation time. GDM s explicitly hitndle the branching problem, multiple contours in one slice 
of a volume data set mapping into one contour in an adjacent slice, by treating a collection of 2D slices 
m a true 3D data set, Therefore. concavities in the direction normal to the slice plane are treated with 
[he same mechanism as any other concavity in the data set. GDM s can use a local resampling algorithm 
to minimize the amount of work required to deform a model and to Com~uter GraDhics, Volume 25, Number 
4, JUIV 1991 increase the model s quality. Tbe level of detail can be set by the user, so quick estimates 
of an object can be generated and later refined for higher quality, GDM s provide a considerable data 
reduction in comparison to traditional techniques, A GDM can be used for visualization, object recognition, 
geomet­ric measurements, or subjected to a series of geometric operations, Applications abound in such 
fields as medicine, where GDM s could be used to genemte models of internal organs: engineer­ing, where 
GDM s could be used to model scanned mechanical parts or their fwlts: and science. where GDM \ could 
be used to model higher dimensional spaces not accessible using traditional algorithms. The computation 
10 extract a model is proportional to the size and complexity of the object, not the size of the original 
data. GDM \ are controlled through local geometric operations rather than the physical modelling of an 
elastic or plastic structure, hence tbe computations are much simpler. Finally, the dual GDM problem 
may be simpler to solve. rc\ulting in a model of the same quality as the primal problem but with a much 
shorter deformation time. 10 ACKNOWLEDGMENTS We would like to thank Prof. W. Randolph Franklin for his 
sug­gestions on the geodesic data structure and Dr. Donald House for his comments on this manuscript. 
This research was partially funded by General Electric Corporate Research and Development through the 
Rensselaer Design Research Center s Industrial Asso­ciates Program. The research was conducted at both 
GE CR&#38;D and the RDRC. REFERENCES [1] J. Serra. image Anulysis und Muthemuticul Morphol{),yy ti~lume 
/. Academic Press, 1982, [2] S,R. Steinberg. Grayscale morphology. C~jmpu/el-11.swn. Gruphi[.~,andlmageP 
r<J[t .~.~in<q,(1986. 35):333-355, [31 R. ADrebin, L. Carpenter, and P. Hanmhan. Volume render­ing, Ctjmpl{fcrGt-aplli(,r, 
22(4):65 74, 19W. [4] E. Artzy, G. Frieder, and G. Herman. The theory, design, im­plementation. and evaluation 
ofa three-dimensional surface detect ion algorithm, C ompu/er Graphics and /ma<geProce.ss ­in,y, 15:1 
24, 198f). [5] W.C. Lin, S,Y. Chen, and C.T. Chen, A new surface interpolation technique for reconstructing 
3d objects from serial cross-sections. Computer }1.rion, Graphics, undlmu,qr Pro~e.ssit~<q,48:124143, 
1989. [61 H. Fuchs, Kedem Z. M.. and Uselton S.P. Optimal sur­face reconstruction from planar contours. 
Cornm. ACM, 20(10):693-702. 1977. [71 W. E. Lorensen and H. E, Cline. Marcbing cubes: Ahighre\­olution 
3d surface construction algorithm. CompurcrGrup//­;[.s. 21(4):163 169. 19X7. [8] H.E, Cline, W.E, Lorensen. 
S. Ludke, Crawford C. R., and B.C. Teeter. Two algorithms for the three-dimensional reconstruction of 
tomograms. Medi~a/ Phv.sits, 15(3):32W 327, 1988. [9] M. Kass. A. Witkin. and D. Terzoooulos. Snakes: 
Active . contour models. International Journal of Computer Vision, pages 321-331, 1988. [15] [10] 
D. Terzopoulus, A. Witkin, and M. Kass. Symmetry-seeking models and 3d object reconstruction. International 
Journal [16] of Computer Vision, 1(3):2 11 221, October 1987. [11] J.V. Miller, D.E. Breen, and M.J. 
Wozny. Extracting geomet­[17]ric models through constraint minimization. Visualimfion 90 Proceedings, 
pages 74-82, 1990. [12] R. Bajcsy and S. KovatiL Multiresohstion elastic matching. [18] Computer Vision, 
Graphics and Image Processing, (46): 1­ 21, 1989. [13] A. Whkin, K. Fleischer, and A. Barr. Energy constraints 
on [19] parametenzed models. Computer Graphics, 21(4):225-232, hdy 1987. [20] [14] D.E. Breen. Choreographing 
goal-oriented motion using cost functions. State-of-the-Art in Computer Animation (Computer Animation 
89 Conference Proceedings), pages 141 151. eds N. Magnenat-Thalmann and D. Thalmann (Springer-Verlag, 
Tokyo, June 1989). D. Terzopoulos and K. Fleischer. Deformable models. The Visual Computer, 4:306-311, 
1988. R.C. Gonzalez and P. Wintz. Digifa/ image Processing. Addison-Wesley, 1987. J.F. Canny. Finding 
edges and lines in images. Masters thesis, Massachusetts Institute of Technology, Cambridge, Massachusetts, 
June 1983. S. Kirkpatrick, C.D. Gelatt, and M.P. Vecchi. Optimization by simulated annealing. Science, 
220(4598):67 1-680, 1983.  M.J. Bennington. Spherical Models. Cambridge Univerity Press. J.V. Miller. 
On gdm s: Geometrically deformed models for the extraction of closed shapes from volume data. Masters 
thesis, Rensselaer Polytechnic Institute, Troy, New York, December 1990.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122743</article_id>
		<sort_key>227</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Volumetric shape description of range data using &#8220;Blobby Model&#8221;]]></title>
		<page_from>227</page_from>
		<page_to>235</page_to>
		<doi_number>10.1145/122718.122743</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122743</url>
		<abstract>
			<par><![CDATA[Recently in the field of computer vision, there have been many attempts to obtain a symbolic shape description of an object by fitting simple primitives to the range data of the object. In this paper, we introduce the "<i>Blobby Model</i>" for automatically generating a shape description from range data. This model can express a 3D surface as an isosurface of a scalar field which is produced by a number of field generating primitives. The fields from many primitives are blended with each other and can form a very complicated shape. To determine the number and distribution of primitives required to adequately represent a complex 3D surface, an energy function is minimized which measures the shape difference between the range data and the "<i>Blobby Model</i>". We start with a single primitive and introduce more primitives by splitting each primitive into two further primitives so as to reduce the energy value. In this manner, the shape of the 3D object is slowly recovered as the isosurface produced by many primitives. We have successfully applied this method to human face range data and typical results are shown. The method herein does not require any prior range segmentation.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[blobby model]]></kw>
			<kw><![CDATA[energy minimization]]></kw>
			<kw><![CDATA[generalized algebraic surface]]></kw>
			<kw><![CDATA[implicit surface]]></kw>
			<kw><![CDATA[range data analysis]]></kw>
			<kw><![CDATA[ray tracing]]></kw>
			<kw><![CDATA[volumetric shape description]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Range data</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP31087966</person_id>
				<author_profile_id><![CDATA[81100027771]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shigeru]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Muraki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Electrotechnical Laboratory, Tsukuba, Ibaraki, 305 Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Marr, D.: "Vision", Freeman, San Francisco, 1982.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, A.H.: "S up erquadrics and Angle-Preserving Transformations", IEEE Computer Graphics and Applications, Vol.1, No.l, pp.ll-23, 1981.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kaneta, M., Yokoya, N. and Yamamoto, K.: "Recovery of Superquadric Primitives from Range images by Simulated Annealing",SIG Notes of the Information Processing Society o} Japan, SIGCV 65-6, 1990. (in Japanese).]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Pentland, A.P.: "Recognition by Parts", SRI International Technical Note, No.406, 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Boult, T.E. and Gross, A.D.: "Recovery of Superquadrics from Depth Information", Proc. of Workshop on Spatial Reasoning and Multi.Sensor Fusion, pp.128-137, 1987.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Horikosi, T. and Kasahara, H.: "A 3D Indexing Method for an Image Database", Technical Report of the Institute of Electronics, ln}ormation and Communication Engineers of Japan, IE88-111, pp. 33-40, 1988. (in Japanese).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>80997</ref_obj_id>
				<ref_obj_pid>80983</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Solina, F. and Bajcsy, R.' "Recovery of Parametric Models from Range Images: The Case for Superquadrics with Global Deformations", IEEE Trans. PAMI, Vol. 12, No.2, pp.131-147, 1990.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>89155</ref_obj_id>
				<ref_obj_pid>89081</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ferrie, F.P., Lagarde,J. and Whaite, P.: "Recovery of Volumetric Object Descriptions From Laser Rangefinder Images", Proc. of ECCV 90, pp.387- 396, 1990.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Blinn, J.F.: "A Generalization of Algebraic Surface Drawing", A CM Trans. on Graphics, Vol.1, No.3, pp.235-256, 1982.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Nishimura, H., Hirai, M., Kawai, T., Kawata, T., Shirakawa, I. and Omura, K."Object Modeling by Distribution Function and a Method of Image Generation", Trans. IEICE Japan, VoI.J68-D, No.4, pp.718-725, 1985. (in Japanese).]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wyvill, G., McPheeters, C. and Wyvill, B.:"Data Structure for Soft Objects", The Visual Computer, Vol.2, pp.227-234, 1986.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rioux, M. and Cournoyer, L.: "The NRCC Threedimensional Image Data Files", Thec. Report, CNR C 29077, National Research Council Canada, Ottawa, Canada, 1988.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Press, W.H., Flannery, B.P., Teukolsky, S.A. and Vetterling, W.T.: "Numerical Recipes in C", Cambridge, 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74364</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kalra, D. and Barr, A.H.: "Guaranteed Ray Intersections with Implicit Surfaces", Computer Graphics (SIGGRA PH '89 Proceedings), Vol.23, No.3, pp. 297-306, 1989.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Volumetric Shape Description of Range Data using 
Blobby Model Shigeru Muraki Electrotechnical Laboratory Tsukuba, Ibaraki, 305 Japan  Abstract Recently 
in the field of computer vision, there have been many attempts to obtain a symbolic shape de­scription 
of an object by fitting simple primitives to the range data of the object. In this paper, we intro­duce 
the BIoJ Jy Mode/ for automatically generat­ing a shape description from range data. This model can express 
a 3D surface as an isosurface of a scalar field which is produced by a number of field generat­ing primitives. 
The fields from many primitives are blended with each other and can form a very compli­cated shape. To 
determine the number and distribu­tion of primitives required to adequately represent a complex 3D surface, 
an energy function is minimized which measures the shape dMerence between the range data and the Blobby 
Mode! . We start with a single primitive and introduce more primitives by splitting each primitive into 
two further primitives so as to re­duce the energy value. In this manner, the shape of the 3D object 
is slowly recovered as the isosurface pro­duced by many primitives. We have successfully ap­plied this 
method to human face range data and typ­ical results are shown. The method herein does not require any 
prior range segmentation. Keywords: blobby model, generalized algebraic surface, implicit surface, volumetric 
shape description, range data analysis, energy minimization, ray trac­ing< Permission k} copy without 
fee all m part of this material is granted provided that the copies are not made or distributed for dired 
commercial idvmtagc, the ACM copyright notice and the title of the publication and its date appear, and 
notice is given that copying is by permission nf the Assw]ation for Computing Machinery. To copy otherwise. 
or to republish, requires a fee and/or specific permission. 1 Introduction Inthe field of computer vision, 
one of the most im­port ant problems is to obtain scene information from 2D images. The typical method 
is stereo matching which obtains the depth information from the dis­parity of the images of two cameras 
placed parallel. The recovered information from this method is often called a 2 ~ D modef [1], because 
it consists of depth data which is measured from a single direction and so it does not form a full 3D 
description of the object. There have been many attempts to fit 3D volumet­ric shape description models, 
such as superquadrics[2] to range data[3~8]. However, the shape primitive of these models is usually 
very simple and so one must combine many primitives in order to adequately ex­press the shape of a complicated 
object. Then one needs to divide the range data into segments so each segment can be approximated by 
a single primitive. However, this segmentation problem is also a serious problem in the field of computer 
vision. Further, the connections between primitives are not smooth and it is difficult to express soft 
objects with smooth chang­ing shapes. Hence, a 3D shape description model is needed that can express 
a smooth object with a small number of primitives which preferably avoids the seg­ment at ion problems. 
In the field of computer graphics, modeling and rendering of 3D objects are both important problems. 
Regular shapes such as machine parts can be sim­ply described. However, a large amount of numeri­cal 
data is necessary to describe a smooth and soft object such as a human body. At present, design­ers obtain 
such descriptions by tedious manual meth­ods. Recently, a new modeling method, which is called Blobby 
ModeP[9], has been used to describe smooth objects. This method expresses a surface of an object ACM-O-897Yl 
-436-8/9 l/C07/0227 $W.75 SIGGRAPH 91 Las Veaas, 28 JuIv-2 Auaust 1991 as an isosurface of a scalar 
field which is generated from field generating primitives. Since the shapes of the primitives are blended 
with each other, it is pos­sible to express the surface of a complicated object with a small number of 
primitives. However, because of the fusion of the primitives, it is very dMicult to de­sign B1o bby Models 
manually and so an automatic method of obtaining Blob by Models of 3D objects is desired. In this paper 
we present a method for automat­ically generating a B[obby Modef of a complex 3D object, given a set 
of range data. The 2; D model obtained by a computer vision technique can be pre­cisely described with 
a set of blended shape primitives. If the number of primitives is small, then this method also becomes 
au efficient 2 ~ D or 3D data compres­sion method. Since the B1o bby Mode/ obtained by this method changes 
its form from a simple shape to a complicated shape as the number of primitives is increased, we don 
t need to segment the range data in advance. Further, the history of the changes of the shape show the 
hierarchical structure of the object and this may be used to further analyze the structure of the object. 
By adding different kinds of primitives, such as superquadrics, this method can be used as a general 
modeling tool for computer graphics. In the following section, the Blobby Mode! concept is ex­plained 
and then our method for automatically fitting the model to a set of range data is presented in section 
3. Experimental results for human face range data are shown in section 4. Blobby Model Blinn( 1982) 
developed a generalized algebraic model­ing method which is now called the Blob by Model . This model 
can express a 3D object in terms of the isosurface of a scalar field which is generated from many field 
generating primitives[9]. The field value at any point (z, y, z) created by a primitive Pi at a point 
(Xi, y;, 21), is expressed as follows. ~(~, ~, Z) = bieZp{ a:/:(Z, ~, 2)} (1) The function /i (z, y, 
z) defines the shape of the scalar field. For example, in the case of a spherically sym­metric field, 
Ji (z, y, z) is the square of the distance between (z, Y, -z) and (~it yi, zi) .fi(~, ?4,z) = (~-$i)2+ 
(!J -!Ji)2+(Z Zi)2, (2) bi \ bi Ie . ... ... Ti Figure 1: The decay of field value ~ (s, y, z) according 
to the distance ~i from the point (~i, yi) ~i). Eq. (2) WaS used for the function fi (x, y, z) of Eq.( 
1). and in the case of a superquadric[2] shaped field, it is written as fi(~t Y, 2, = {(.T-Zi)2/ +(7J 
-yi)2/v }vi/Pi + (Z %:)2ipi, (3) where ~i and ~i are the parameters related to the shape of the superquadrics. 
If Eq.(2) is used, the field value ~ decays exponentially with the distance from (~i, yi, zi) = shown 
in Fig. 1. Parameter ai(> O) affects the degree of the decay and bi affects the strength of the field. 
If several primitives are used at once, then the scalar field from each primitive is summed and the resulting 
isosurface can show a very complicated shape. From Eq.( 1) the field which is produced from N primitives 
for any point (z, y, z) is expressed as fol­lows. V(z,y,z) = ~61eZP{-aiti(~,Y,z)} (4) j=l Consequently, 
the isosurface of value T( > O) is ex­pressed as an implicit function: V(z,?J,2)=T . (5) If an attribute 
value is defined, such as the color com­ponent Ci, for each primitive, we can calculate the value for 
a point (z, y, z) as follows:  C(z,y, z) = (~yy, Z)~ CiK(Z y~z). (6) 1-1 If there is only one primitive, 
the primitive makes an isosurface of the function ~i (z, y, z). Fig.2(a) shows  SIGGRAPH 91 Las Vegas, 
28 JuIY-2 August 1991 (Y, Y +1) (x -l,y) (x+ l,y) (Z, y) e (Z,y -1) Figure 3 The surftie normal vector 
of each pixel (z, g) is calculated by averaging the normal vectors of the 4 triangles that consist of 
the pixel and its 4 neighbors. However, if the range data forms a flat surface, the primitive which is 
placed infinitely far from the surface and h= values a: = Oand bi = T exactly satisfies both Eq.(7) and 
(10). But the computed surface is not limited only to the vicinity of the range data points. Further, 
the constraints of Eq.(7) and (10) are defined only at range data points, and consequently there is no 
constraint on the shape forming primitive in the area where there is no range data. Therefore, there 
is a possibility y that the primitive which fits to the range data makes strange shapes away from the 
vicinity of the range data points. To avoid these problems, a new constraint is added which minimizes 
the influence of the field of each primitive. From Eq.( 1) and (2), the integration of the field of a 
primitive over 3D space can be expressed as, Considering the case where bi has a negative value, the 
new constraint is defined as follows: i=l This constraint has a shrinking effect on the primi­tives. 
Consequently, the desired arrangement of prim­itives can be obtained by minimizing the following en­ergy 
fimction, which is the summation of Em., and (12). Here CYand B are weighting parameters which control 
the strength of the surface normal constraint and the shrhk constraint. By changing these values, we 
can change the behavior of the fitting to be suitable for the range data. 3.2 Procedure for Blobby Model 
Fit­ting A set of N primitives which minimizes Eq.(13) must be found. Since each primitive has five parameters, 
we must solve the minimization problem of Eq. (13) for 51V unknowns. The minimization of Eq.( 13) is 
a non­linear problem and cannot be solved by an analytical technique. A numerical method such as the 
Newton method could be used, but it would be extremely dif­ficult to find all of the 5N unknowns simultaneously 
when IV is a large number. Our approach is to make an initial fit between a primitive and the range data, 
and then divide the primitive into two primitives so as to increase the goodness of fit. Continuing this 
division for all primitives, the detailed surface of the object can be expressed by the isosurface, which 
is generated by the primitives. A 5D vector is used to express the parameters of a primitive Pi S f0110W5: 
Pi = (Zi,yi,Z:,~i,t i). (14) For the initial primitive Po, the center of the mass of the range data 
is used for (z., yo, Z. ), the reciprocal of the variance of the range data is used for ao, and b. is 
set at the value eT(e ~ 2.718). The minimization problem of Eq. ( 13) is solved using these initial values 
and then the five parameters of P. are determined. A primitive list is created and the primitive P. is 
added to the list. Our method is based on the selection of a primitive Pi from this list and its division 
into two new primitives. At this stage P. is the only primitive in the list and so P. is used zs Pi. 
Then Pi is deleted from the primitive list and two new primitives P: and P/ are appended to the list 
inst cad. The initial paramet er values of P; and P? are calculated as, P: = P: = (~1, yi, zi,ai, bi/2). 
(15) We then solve the minimization problem of Eq.(13) for the 10 parameters of P: and P? and determine 
the parameter values. Now there are two primitives in the primitive list. After this the procedure that 
se­lects a primitive Pi from the primitive list is repeated and then it is divided into two primitives 
while holding fixed the parameters of the other primitives in the list. Since the potential field of 
each primitive is blended, 63 Define the initial value of PO from the range data. 1 Fit PO to the range 
data by solving the energy minimization problem. I Append POto the primitive list. I Select a primitive 
Pi from the p rimitive list. I 1 I Split Pi into Pi and Pi . I I Delete Pi from primitive list and append 
Pi and P,f to the list. 1 Fit P,! and P,! to the range data by solv-ing the energy minimization problem. 
1 Yes STOP Figure 4: The flow chart of the Blobby Model fitting procedure. the selection order of the 
primitives strongly influences the result of the minimization of Eq.(13). So it is best to choose the 
effective division in order to ob-tain a Blobby Mode! which preferably approximates the range data with 
a small number of primitives. To find this effective division, one must examine all of the primitives 
in the primitive list and determine how much the energy value is reduced by the division of the primitive, 
and then adopt the division which re-duces the energy value the most. However this selec- tion method 
consumes so much time, so other methods should be used when N becomes a large number. In any case, by 
continuing this selection and division Computer Graphics, Volume 25, Number 4, July 1991 Figure 5: A 
range image of a human face distributed by NRCC (Face 5). sequence until the energy value becomes sufhciently 
small, the Blobby ModeP gradually comes to approx- imate the range data as the number of primitives is 
increased. Fig.4 shows the flowchart of this procedure.   4 Experimental Results 4.1 Application to 
Human Face Range Image We have applied our method to real range data. Fig.5 shows a human face range 
image (Face 5) distributed by the National Research Council Canada (NRCC) [12]. This image has 256x256 
pixels. The depth val-ues are expressed by the intensity of the pixels. The surface normal vector of 
each pixel is calculated by us- ing the value of neighboring pixels as shown in Fig.3. In order to reduce 
the amount of calculation, the range image of Fig.5 is blurred by a Gaussian filter of u = 2 and one 
value for every 3x3 pixels is used and 2893 points are obtained with a depth value and a unit nor- mal 
vector. Then we calculate the parameters of the initial primitive and start the dividing sequence ac-cording 
to Fig.4. To solve the minimization problem of Eq.(13), an approximate solution is determined by using 
the downhill simplex method[l3], which is used as the initia.l value of the quasi-Newton method[l3]. 
The downhill simplex method is used initially to ob-tain a reasonable estimate of the unknowns. However, 
this method is slow. Consequently, the quasi-Newton method is then used, which is much faster, but it 
does need to have a reasonable estimate of the unknowns. The parameters we used were cy = 1.0, ,0 = 0.01 
and T = 1. Fig.6 shows the change of the Blobby Modet 231  63 Comwter Graehics. Volume 25. Number 4. 
Julv 1991 Figure 7: A panoramic range with the number of primitives by using a ray tracing technique[l4]. 
It is clearly seen that the detailed fea- tures of the face become more apparent as the number of primitives 
increases. By the image of Fig.G(e), the selection method of a primitive described in section 3.2 was 
used, however this method was too slow to con- tinue, so we changed the selection method as to choose 
a primitive merely successively from the primitive list until we obtained Fig.G(f). 4.2 Application 
to Panoramic Human Face Range Image Since the range image of Fig.5 has been taken from a single direction, 
it does not have any information from behind the head. Hence, from the effect of the shrinking constraint 
of Eq.(l2), the resultant Blobby Model only represents the facial surface as shown in Fig.6. To obtain 
the whole shape of a 3D object, one must use multiple range images taken from many di-rections. Fig.7 
is a panoramic range image of a movie actor which has been taken by a special range finder (Cyberware 
402O/PS 3-D Digitizer). This image has 512x256 pixels. After we blurred this image by the - same Gaussian 
filter as described in section 4.1, we used one value for every 4x4 pixels from the face area of Fig.7 
and obtained 5334 points with a depth value and a normal vector. Fig.8 is the resultant Blobby Model 
from this data. In comparison to Fig.6, one can see that the entire shape of the head is correctly reconstructed. 
The parameters used were (Y = 0.1, ,O = 0.1 and T = 1. As in Fig.6, we also changed the selection method 
of a primitive between Fig.8(e) and Fig.8(f). image of an actor s face. 5 Conclusions We have proposed 
a method to obtain a volumetric shape description of range data by a Blobby Mode? and have successfully 
applied this method to human face range data. Sufficiently fine features of the faces were restored by 
using several hundreds of primitives. The history of the primitive division shows a quad tree structure 
and can be used for hierarchical analy- sis of an object. For example, one can use a color to represent 
a branch of the tree and see how the prim- itives in the branch work. Fig.S(a) shows a Blobby Mode? obtained 
in the experiment of section 4.1. This model consist of 11 primitives and we used red color for the primitive 
which formed the nose area of the face. Fig.S(b) is a Blobby Mode! which consists of 243 primitives. 
We used a red color for the 13 primi- tives generated by the division of the initial red prim- itive 
of Fig.S(a). Since the primitives are stored in a list structure, this kind of procedure is very simple. 
Fig.S(c) is the isosurface when these red primitives are removed from Fig.S(b). These pictures show that 
we can deal with the object structure by parts by using the list structure of the primitives of the Blobby 
Mode! . In future work, we are going to apply this method to object recognition problems. We also intend 
to exper- iment using superquadrics as the primitive. This method is computationally expensive. For the 
 data of Fig.G(f), it took a few days on a UNIX worksta- tion (Stardent TITAN3000 2CPU). To deal with 
larger range data sets, further improvement of the algorithm is necessary. The range data we used was 
obtained by using special devices. To apply this method to the problems of computer vision, one needs 
to use depth values obtained by stereo matching.    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122744</article_id>
		<sort_key>237</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Piecewise surface flattening for non-distorted texture mapping]]></title>
		<page_from>237</page_from>
		<page_to>246</page_to>
		<doi_number>10.1145/122718.122744</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122744</url>
		<abstract>
			<par><![CDATA[This paper introduces new techniques for interactive piecewise flattening of parametric 3-D surfaces, leading to a non-distorted, hence realistic, texture mapping. Cuts are allowed on the mapped texture and we make a compromise between discontinuities and distortions. These techniques are based on results from differential geometry, more precisely on the notion of "<b>geodesic curvature</b>": isoparametric curves of the surface are mapped, in a constructive way, onto curves in the texture plane with preservation of geodesic curvature at each point. As an application, we give a concrete example which is a first step towards an efficient and robust CAD tool for shoe modeling.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[differential geometry]]></kw>
			<kw><![CDATA[geodesic curvature]]></kw>
			<kw><![CDATA[non distorted texture mapping]]></kw>
			<kw><![CDATA[piecewise surface flattening]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P42645</person_id>
				<author_profile_id><![CDATA[81375608161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chakib]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bennis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institut Fran&#231;ais du P&#233;trole 1 et 4 avenue du Bois-Pr&#233;au 92506 Rueil-Malmaison and INRIA, BP. 105, 78153 Le Chesnay cedex France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31098560</person_id>
				<author_profile_id><![CDATA[81100190813]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jean-Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[V&#233;zien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA, BP. 105, 78153 Le Chesnay cedex France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P88254</person_id>
				<author_profile_id><![CDATA[81100138041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[G&#233;rard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Igl&#233;sias]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Soci&#233;te Strat&#233;gies, 41-43 rue de VilleneuveSilic 429- 94583 Rungis France and INRIA, BP. 105, 78153 Le Chesnay cedex France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J.M. Beck, R.T. Farouki, and J.K. Hinds. Surface analysis methods. IEE CGA, pages 18-37, December 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Bennis. Synth~se de textures hi~rarchiques planes - d~veloppement de surfaces 3d pour un placage de textures minimisant les distorsions. Th~se de Doctorat en Science, Universitd de Parts XI, centre d'Orsay, D~cembre 1990.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Bennis and A. Gagalowicz. Hierarchical texture synthesis on 3-d surfaces. EUROGRAPHICS' 89, pages 257-268, September 1989.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Bennis and A. Gagalowicz. Mapping de textures sur une approximation triangulaire des surfaces. PIXIM' 89, pages 139-152, 1989.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Bier and K. Sloan. Two-part texture mapping. IEEE Computer Graphics and Applications, pages 40-53, September 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>360353</ref_obj_id>
				<ref_obj_pid>360349</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J.F. Blinn and M.E. Newel_l. Texture and reflection in computer generated images. Communications o} the A CM, i9, 10, pages 542-547, October 1976.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M.F. Do Carmo. Differential geometry of curves and surfaces. Prentice.Hall, Englewood Cliffs, Inc., 1976.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Catmull. A subdivision algorithm for computer display of curved surfaces. Ph.D. Dissertation. Dept. o} Computer Sciences, University of Utah, December 1974.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>807505</ref_obj_id>
				<ref_obj_pid>965105</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[F. Catmull and A.R. Smith. 3-d transformation of images in scanline order. Computer Graphics, 14(3), July 1980.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808600</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[F.C. Crow. Summed-area tables for texture mapping. SIG- GRAPH 8,~, Proc. of Computer Graphics, pages 207-212, July 1984.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617415</ref_obj_id>
				<ref_obj_pid>616000</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E.L. Schwartz et al. Computational neuroscience: Applications of computer graphics and image processing to 2d and 3d modelling of functional architechture of visual cortex. CGA, Vol. 8, No. 4, pages 13-23, July 1988.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83600</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Farin. Curves and surfaces for aided geometric design. Academic Press, San Diego, Inc., 1988.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Flume, A. Fournier, and V. Canale. Conformal texture mapping. EUROGRAPHICS' 87, pages 53-64, 1987.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>893978</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[P. Heckbert. Fundamentals of texture mapping and image warping. UCB/CSD 89/516, Computer Science Dept, Univ. of Caliyornia, Berkeley.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. Iglesias and S. Coquillart. Curve design on surfaces. In preparation.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S.D. Ma and A. Gagalowicz. Determination of local coordinate systems for texture synthesis in 3-d surface. EURO- GRAPHICS'85, September 1985.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S.D. Ma and H. Lin. Optimal texture mapping. EURO- GRAPHICS'88, pages 421-428, September 1988.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37424</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Oka, K. Tsutsui, A. Ohba, Y. Kurauchi, and T. Tago. Real-time manipulation of texture-mapped surfaces, SIG- GRAPH 87, Proc. o1 Computer Graphics, 21(4):181-188, 1987.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer GraDhics, Volume 25, Number 4. Julv 1991 Piecewise Surface Flattening for Non-Distorted 
Texture Mapping Chakib Bennis Jean-Marc V6zien G&#38;ard Igl&#38;ias t INRIA BP. 105, 78153 Le Chesnay 
cedex France Abstract This paper introduces new techniques for interactive piecewise flat. tcning of 
parametric 3-D surfaces, leading to a non-distorted, hence realistic, texture mapping. Cuts arc allowed 
on the mapped tex­ture and we make n compromise between discontinuities and dis­t ortions. These techniques 
are based on results from different al geometry, more precisely on the notion of geodesic curvature : 
isoprmametric curves of the surface are mapped, in a constructive way, onto curves in the texture plane 
with preservation of geodesic curvature at each paint. As an application, we give a concrete ex­ample 
which is a first step towards an efficient ruralrobust CAD tool for shoe modeling. CR Categories and 
Subject Descriptors: 1.33 [Computer Graphics]: Picture/Image Generation; 1.4.3 [Image Processing]: Enhtu~cement-Geometric 
Correction, Texture. Additional Keywords and Phrases: Non Distorted Texture Mnpping, Piecewise Surface 
Flattening, Differential Geon~ctryl Geodesic Curvature  Introduction Texture mapping techniques rare 
widely used to reproduce textural infornmtion available in a planar image onto a 3-D surface. This is 
made possible by making a correspondence between a plnrmr imnge rmd a 3-D surface, in order to give each 
sample point of the output screen remched by the projected 3-D surface an intensity value computed from 
n point or a set of points of the 2-D image sample. This correspondence is called the mapping function 
Catmull [8] first introduced a recursive subdivision algorithm to map a 2-D rectangular image onto a 
3-D bicubic patch. This method hns been refined and enhanced by several authors [9, 6]. These techniques 
are equivalent to warping the phmar rectangle until it takes the shape of the bicubic patch. Unfortunately, 
these techniques do not preserve distances or angles, resulting in spra­tial distortions of texture patterns, 
which can sometimes change the visual apperwrmce of the texture on the surface, Other au. thors have 
proposed solutions to reduce these distortions. Bier et rd. [5] proposed a 2-print mapping which consists 
in decomposing the mapping in two steps: the texture pattern is first embedded . Current address: Institut 
FrrmSnis du P+trole 1 et 4 nvcnuc du Bois-Pr6au 92506 Rueil-Mrdmaison, tcln-rerlt nddrcss: Soci.4tc Strat&#38;gies, 
41-43 rue de ViHeneuvc -Silic 429-94583 Rungis France. Pcrruission(ncopywithoutfeeall w part of this 
material is gmnlcd prnvided(halthecnpwsarc not madenr distributedfor direct ctnnmcrcml mlvwrhigc, the 
ACM cnpyrigh! notice wrd the title ~Jlthe publication and N, date appetir. ttnd nolicc N given that cnpying 
is by permissmn d the Awoc-iiuwn fnr Ctnnputmg Mtichincry To copy otherwise. (Jrto republish, requires 
a fec imti/or spccitic perm!s>ion. in a 3-D intermediate surface and then projected onto the target surface 
iu a way that depends only on the geometry of the tar­get object. The distortion is reduced by heuristically 
choosing the appropriate intermediate surface and the projection method. l.Jn­fortunntely this is not 
always easy todo. Fiume et al. [13] have proposed n polygonal conformal mapping to map a polygon (e. 
g., a square) onto an arbitrary convex polygon with preservation of angles. This technique gives good 
results on polygons for some applications. However, the technique does not preserve distances, thus creating 
distortions. Moreover, it is not easily cxtendable to free form surfaces. k [17], Ma et al. used an optimization 
tech­nique to minimize distortions for general surfaces. The mapping is performed on a grid of sample 
points of the 3-D surface. Start­ing from an arbitrary initial mapping, the algorithm converges to the 
optimrd mapping by minimizing a global metric taking into account distances between each point and its 
direct neighbors on the 3-D grid. A similar technique was proposed at the same time by Schwsmtz et al. 
[11] for general surfoce flattening. Since most surfaces me not developable (i.e. unfolded without deformations 
or cuts, think of a sphere), distortions still remain. Moreover, op­timization techniques offer uo control 
on the distribution of the remaining distortions A non-distorted mapping of a planar texture onto a 3-D 
surfnce is equivalent to n nou-wrwped flattening of the surfnce. As it is well known, fully sprending 
out a non-developable surfnce would induce distortions. The basic idea of this work is to permit discontinuities 
on the mapped texture rmd to make a compromise between cuts and distortions. The cuts here play the role 
of seam lines (such as on a cloth). The surfnce is first piecewise flattened (with different maps in 
the phme), then texture is computed on the surface using the flattened parts. This could have mauy applications 
in differ­ent fields, varying from graphics concerning non-distorted texture mapping, to cmtogrrtphy 
smd manufacturing (cloth modeling) for piecewisc flattening. The example emphasised here is a first step 
towards nn efficient and robust CAD tool for shoe modeling. This paper introduces new techniques for 
interactive piece wise flat­tening of parametric 3-D surfaces, leading to a non-distorted tex­ture mapping. 
The flattening of n region grows around an isopara­metric curve selected by hand. A distortion metric 
is introduced to control and stop the growth when the rtccumulnted distortion exceeds a previously determined 
threshold. The flattening meth­ods m-c based on results from differential geometry ([7] [12]), more precisely 
on the notion of geodesic curvature : isopnmmetric curves of the surfcrce me mapped in a constructive 
wny onto curves in the texture plnne, with prescrvrttiou of geodesic curvature at each point. The next 
section gives the outlines of the global texture mapping approach. This section rrlso reviews our previous 
work [3] On rev. olution surfnce flattening. In section 3, concepts from differen­tirrl geometry (geodesic 
curvature) arc introduced rind utilized to strnightforwnrdly extend the previous work to more general 
sur­fnces. A ~nore robust technique (bnsed on n rclnxatirm procedure) [(.Ilwl ACM -()-X979I-436.8/9 1,(W7/02.17 
$04),7s   SIGGRAPH 91 Las Veqas, 28 JuIv-2 Aucwst 1991 is proposed in section 4. All these techniques 
are compared on well known examples: a cone and a hemisphere. Section 5 presents an application to shoe 
modeling. The paper concludes with CIdiSCUS. sion of the limitations of the proposed techniques and with 
some suggestions for future developments. 2 General considerations and previous work The surfaces considered 
here are given by a piccewisc parametric represent ation: x= *(U, v) Y = Y(U, v) z = Z(U, v) { We require 
the surfaces to be C2 (to have continuous second order derivatives at each point), especially on the 
joining curves (the reason for this constraint is explained later). Moreover, the two families of isoparametric 
lines must be nowhere tangent to each other (i.e. a normal and a tangent plane exist at every point), 
The surface is fist regularly sampled into a grid of 3-D points, along the isoparametrics (in parmnetcrs 
space). Moreover, the sampling must be refined enough to approximate the arc length between two successive 
sample points along an isoparametric by their euclidian dist ante. In the following, sample curves along 
u smd u directions are respectively denoted C.j (u = Oj ) and C;, (U = til). We note the points of the 
3-D grid Mlj , and their correspondents in the flattening planel Pij. The euclidian distance between 
two points Ml and Mz is loosely denoted d(A41, Mz ) or IImf, -M,ll, 2.1 Outlines of the general approach 
The texture mapping algorithm can bc divided into two main steps: I) An initial chord curve (a portion 
of an isoparamctric) is first selected on the grid and the surface is unfolded around this curve until 
a preliminarily fixed distortion threshold is reached. The same process is repeated on the unprocessed 
region of the grid until all the surface, or an interesting part of it, is covered. II) The processed 
regions of the grid are then triangulated, ond a locally affine interpolation, atline in each triemglc, 
is used to texture them. Step I) constitutes the piecewise flattening part of the algorithm. More precisely, 
for each presented flattening technique, an appro­priate distortion metric is defined. The initial curve 
is chosen by hand depending on where the texture is desired to be the lCSSdis­tort cd. This curve divides 
the surface into two sub-regions, e.g. left and right . Let the curve be C: O., where Vjl <v<Vj,}. Unfolding 
the surface around this curve is done in three steps: 1. Develop the initial curve: iind for each sample 
point &#38;fiOJ of this curve a corresponding point PiOj in the flattening plane (e.g., a texture plane) 
. 2. develop the surface on the left side of the initinl curve: fix a left side threshold, then develop 
successively curves {Ci., ~ < h ,Vjl < v < Vj, } (parallel to the initial one) until the provided distortion 
exceeds the left side threshold, or the current curve belongs to an already developed region.  3. Develop 
the surface on the right side of the initial curve usirur a right side threshold (the same as the leftside 
development but developed curves are {C1., i > io, ~j, < u < 0j2 })  Step II) constitutes the texturing 
part: the triangula­tion of a processed region is obtained by splitting each quad {Mi lj-l, lfi-lj, lkfij-1, 
Mij }, of four neighboring samp­le points, into two triangles {Mi-lj l , Mij-l , Mi-lj } ~d {Ikfi-~j, 
Mij-~, Mij}. This gives rise to two triangles in the 1For the texture mapping application the flattening 
plnne is considered to be the texture space. 238 texture plane, {Pi_l J_l , Paj l , Pi-lj} and {Pi-lj, 
Pij 1 , Pij } , where the Pkl are the corresponding points of the Jfkl and have already been obtained 
with the flattening process. The 3-D tri­angular faces are project cd onto the output scrccn. A triangle-to­triangle 
atline interpolation from the texture plane to the output screen is used to compute the texture value 
at each pixel of the output screen. A Z-buKer is used for hidden surface parts elimi­nation and a prefdtcred 
summed table [10] is used for antialiasing. The locally atline approximation of the mapping function 
is well explained in [4], and compared with the approximation proposed by Oka. and al. in [18] (see [4] 
for more details). Local affie approximations to a mapping are also discussed in [14]. Fkom now on we 
will emphasize the geometrical aspect of the non distorted piecewise flattening. 2.2 Previous work In 
[3] we have proposed a piecewise flattening technique for surfaces of revolution. The outllne of the 
algorithm is: 1. Map an initial meridian C ;.. of the surface onto a straight line D~o. in the plane 
with distance preservation between sample points. One has only tojiz a correspondence for a starting 
point and a direction for the straight line. Obtaining the other comcspondences is immediate. 2. Extend 
the development step by step around Cg.. (at each step a meridian Ci, is reached) while mapping parallels 
onto straight lines orthogonal to DIO. with distance preserva­tion between sample points, until the distortion 
threshold is reached. (SCC Figure 1). If dtstorfion ~ thrmhold stop 1 . , :,qj,l M,j+l , , , M, .y 
: C.J D.j ; 1 1 ,: $ r -; ~b, c,. 1 m. b,, SURFACE PLANE Figure 1: Previous flattening of surfaces 
of revolution. This method preserves distances on the initial meridian Cio, and on parcdlcls C,j but 
not on the other meridians CD. (unless the surface is a cylinder). Moreover, we preserve the cross angles 
between CIO. and C.j Distance distortion on meridians and cross angle distortion (between the two families 
of curves) increase as one gets far from the first meridian. All distortions me concentrated on meridians 
C,., i # i., so we choose as a distortion metric for each successive curve C:,, the mean of the errors 
induced on its chord segments:  - I d(~ij, ~ij+l) -d(J ij, Pij+l) I (1) CT(Ci. ). &#38; ~ d(~ij, ~ij+l 
) j=O Here, N is the number of sample points of C1., and P~l are the corresponding texture points of 
3-D points MkJ. Note that here, due to revolution symmetry, one has only one threshold for both leftside 
and rightside development. Figure 2 shows the development of a cone and a hemisphere with this technique. 
We have developed them entirely, onto only one piece, to emphasize the nature of distortions. Note that 
there are fewer distortions thnn with Catmull s technique ([8]) where both surfaces would be mnppcd onto 
a rectangle. Moreover, wc find    SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 The vrwiables [k(s) 
l=llt (a)[l and lT(a)l=[lb 11 are called respec­tively maan curvature and torsion at s. Curvature and 
torsion have an intuitive geometric meaning: let da(s) and d8(s) be respectively the angle between t(s) 
and t(s+ d) and the angle between b(s) and b(s + cfs), rtt consecutive points X(s) and X(s + ds). Then: 
 In other words k nnd r are the angular velocities of the tangent rmd the osculating plmm, respectively, 
as the frame is moved along the curve with s playing the role of time . Moreover, these two variables 
are independent of parametrization. When k is zero everywhere the curve is a straight tine, and when 
7 is zero everywhere the curve is planar. Now, consider a surface S given by a parametric function from 
R2 to R=: Z(U, v) X(u, v) = y(u, v) ,(u, v)~[a, b] x [a, b] CR2, [1 4% U) where the Crmtesinn coordinates 
z, y, z of a surface point are dif­ferentiable functions of u and v. Let us suppose in add]tion, that 
the isoprarametric lines are nowhere tangent to each other: iV(u, v)= Xti AX. #O Vu, ve[rz, b] where 
X,. mr X, rare first derivatives vectors according to u pa­rameter and v parnmeter respectively. The 
vector n=&#38; is cedled the normal vector to S at point X(u, u). The plrme Tp spanned by the set of 
points Y such that: (X -Y).n = O, (where dot denotes the scalar product of vectors) is called the tangent 
plane to surface S at point X. Let C5 be a curve belonging to surface S and given by arc length parametric 
function X(s). Recall that the curvature is defined by the acceleration t =km of CS. This vector can 
be expressed with two components where the one, t g, is tangent tO the surface and the other, t ,,, is 
normal to the surface: t = t g +t n t ,, = (t .n)n Seen from a view-point finked to the surface, the 
acceleration t is reduced to tangential component t g. Definition : The geodesic curvature kg of a curve 
C5 belonging to a surface S, at a point X, is the norm of tangential acceleration of C5 at X according 
to arc length parameter: lkgl = [It gll. kg corresponds to the curvature of C s seen from a view-point 
at­tached to the surface S. It is different from main curvature k (kg could be null while k is not null). 
CS is mid to be geodesic at a point X if and only if kg is nil at X emd CS is called a geodesic if it 
is geodesic at every point. One necessary emd sufficient condition for C s to be geodesic at point X 
is thmt the main normal vector m of curve C5 at X is parallel to the normrd vector n to surface S at 
X. At rmy point X the local projection of a curve Cs on the trmgent phmc along the normal vector to the 
surface S provides a straight line if CS is a geodesic, and non-zero curvature (at X) on the pla­nar 
curve otherwise. Figure 4 shows the behavior of circles of a sphere: n circle is a geodesic if and only 
if it is a great circle. Lemma: The Geodesic curvature kg of a curve Cs bclowriw tO a surface S at a 
point X is equal to curvature at X of the planar curve CTP obtained by locally projecting CS onto the 
tangent plane (Tp) .lOng f~c normal to surface S at point X. vector As for mstin curvature, intuitively 
geodesic curvature kg(s), at a point X(s), is the angular velocity of tangents to the resulting projected 
curve CTP(s) according to arc length s. This Lemmn leads us to an efficient and constructive numericnl 
wny of mapping a chord line of a surface onto a chord line in a plane with preservation of chord length 
and geodesic curvature. This is the bnsis of the new flattening algorithm described below. 2That is the 
reason why we require a surface tO bc C2. 3.2 Outline of the new general algorithm The new algorithm 
runs as follows (see Figure 5): 1. Map the initial selected curve Cau. of the surface (for instance {v 
= M,U, j, <j<j2}) onto a curve in the plane with geodesic curvature preservation at sample points and 
with arc length preservation ( distance preservation between any pair of successive sample points). 2, 
Extend step by step the development on the left side of CiO.. At each step one reaches a curve C,., (i 
< io ) while mapping transversal curves C.j ({u = rJj, jl < j < j2 }) O==tO c~ves in the pleme with geodesic 
curvature rmd arc length preservation. At the same time, one requires preservation of the cross angle 
between the initial curve CiO. and each trrmsversal curve C.j. The process is stopped when the left side 
distortion threshold is reached, or curve Ci. belongs to rm already flattened region. 3 Extend the development 
on the right side of C,.. according to the right side threshold (snme process as the left side one). 
if distortion> threshold Surface Plane Figure 5: Geodesic curvnture preservation flattening. Notice 
that here again distances are preserved along the initial curve C i O,and in the transversal ones C.j. 
All distortions are con­centrated on curves Ci. parallel to CiO,. So, the dktortion metric for a specific 
curve Ci, is the same as for the previous technique (formula (l)). 3.3 Mapping a 3D surface curve onto 
a planar curve with arc length and geodesic curva­ture preservation Let us recall that the surface is 
sampled and that surface curves are given by chord lines, arc length between two consecutive points being 
approximated with euclidian distance. Suppose the curve C that we want to map onto the plane contains 
n + 1 sample points &#38;fi, i = O..n. Let US denote by ni and TPi, respectively, the normnl vector and 
the tangent plane to the surface at point MD. The curve flattening algorithm can then be described as 
follows: i) Map the first curve segment i%90A91 onto a segment POPI in the plane (let us call this plane 
OZV) such that d(hfo, MI ) = d(Po, PI ). It is sufficient to fix an initiaf point PO and a direction 
in the plane. ii) For each j, 2< j<n, P, is iteratively computed in the plane as follows (see Figure 
6): 1. project illj and JfJ 2 onto the tangent pkme to the surface nt Mj_l. This provides two points 
in Tp, _l, called fiJ and fi~-z and given by the formulas: M, = M, + ((Mj 1 -Mj).n) i)m) i. M)_z = Mj 
2 +((Mj-1 -Mj z).nj-l)nJ-l.   @ @ Computer Graphics, Volume 25, Number 4, July 1991 2. Use a dilation 
in TPj_l to tmnsform IWj into a point kf~ su.h that d(Mj-l, Mj)=d(Mj_l, M~). !J- j- (tij -Mj-1) llMj 
~~ = J-; + -~j-111 3. As Pj_2 and Pj_l are akady computed, the de­sired point Pj is the point of OZMthat 
preserves si­mult aneousl y the angle Oj-I between ~j -2 Jfj -I tid M1-l M~, and the distance d(Mj-l, 
M~). d(Pj-l, Pj) = d(Mj-l, M~) The way we obtain pj is to first compute coordinates  Plane Surface Figure 
6: Mapping a curve of a surface onto a planar curve: step ii). (z , , Z 2 ) of M; according to the local 
orthogonal frame (hf, -l, e~, ej) in Tpj_l where axes e{ and e; and the coordinates are given by the 
formulas: Pj is the point of OZy having the same coordi­nates according to the orthogonal and positive 
frame (P)-l, el ,ez) given by: where (0,;, ~) is the canonical coordinate system of Oxy. Step ii) of 
this algorithm will be used in other circumstances, in what follows It can be thought of as an operator 
P. Given three neighboring surface points (MI, MZ, M3 ) and two corresponding points (Pl, PZ ) of (Ml, 
M2) in the flattening plane Ozg, F com­putes point P3 in Ozy, that preserves the distance d(M2, M3 ) 
and the projection of the angle Oa=(MI ~aMs ) in TpM,. We will ca~ this operator the angle prrserver 
and we will write:- R = Pe, (Jf3) Theorenr The above curve flattening algorithm preserves geodestc 
curvature and arc lengths within the chord line approxi­mation. As we initially have d(Po, PI ) = d(Mo, 
MI) ~d h Constmction Of Pj, j, 2<j<n, we have d(pj-1, Pj)=d(M)-l, Mj), so arc lengths me preserved. As 
the sampling is sufficiently refined, the trmgents to a curve can be approximated with chord segments. 
SO, at step 11), @j -I CDII be considered as the angle variation between two consecutive tangent vectors 
to the locally projected curve, intO Tpj_l. We preserve 8J_ 1 and chord lengths. We then preserve locally 
the anguhir velocity of tangents to the curve prOjectiOn int O Tp j _ ~. (Q. E. D). Notice that the computation 
of Pj involves geodesic curvature preservation at M, 1   S.4 Preserving the cross angles between the 
ini­tial curve and a transversal curve In fact, the preserved angles are the cross angles between the 
1­cal projection of the two curves onto the tangent plane at their intersecting point (see Figure 7). 
Suppose that the initial curve Mb-i Figure 7: Cross angle preservation. C,., and a trrmsversal curve 
C7.J meet at the point JfiOJ Let us denote by M,o) 1 , MiuJ+I and by Jfio -] j, Mio+ 1j, respectively, 
the neighbors of M,oj along the uand v dire. tiOn. When we project these four neighboum onto TPiOj, we 
obtain a quasMat­ eral (fii,uj _l, ific,-lj, Mi{,, +I , ~iO + I, ) -Four angles must then be preserved: 
03 = (&#38;,uJ+1M~3MqU+11) 84 = (Mio+i)M,oj Mioj-i) As the initial curve c,,,, is a~eady mapped, the 
pOints Pioj _ ~, P,UJ, P,uj+ ~ are available in the flattening plane. k addition, we have (P,,, j_l~P,oJ+I 
)=(mioj-lM~J~i.j+l) (geodesic curvature preservation at MioJ, On Cio.) we then O~Y have to preserve 01 
and 64, respectively, when we initialize the mapping of C,J on the left side of C,., (when we .Omwte 
Pi. -1 j ) and on the right side of C,,,. (when WC compute Pi. + ij ). This implies the preservation 
of all the Other angles. Pi. 1 j and Pio+ lJ are then given by the angle preserver operators: Moreover, 
this preserves the angle (M,. 1, M,OJ Mio+ lJ ), h-e, geodesic curvature at Jf,<, J on C.l  3.5 Flattening 
of the cone and the hemisphere Figure 8-a and 8-b show the flnttenings of the cone with this tech­nique. 
In 8-a, the cone is spread out around a generatrix. In &#38;b a circle is used as initial curve. Both 
give the same result, which is the proper development of the cone (an angular sector of a disc). In Figure 
9, we show the mapping of a checkerboard pattern onto the cone according to three different techniques: 
With Catmull s technique, in 9-st and 9-b, squares are compressed along circles M one gets close to the 
tip. The advnntrige of this technique is that   @ @ Computer Graphics, Volume 25, Number 4, July 1991 
tion when necessary. 2. A relaxation procedure is then used to reduce and better distribute the distortions 
in the flattened region. For simplicity, in the following, the projected angle (in the tangent plane) 
between two intersecting curves is loosely called the angle. 4.1 Development technique The new development 
aluorithrn is almost the same as the alm­rithm of the previous sect~on. One first maps the initial curve 
CIO. onto the plane with geodesic curvature and arc length preservm tion. The development of the region 
is then propagated step by step to the curves parallel to CiO., on the left side of Cio,, then on the 
right side of C i O, The new feature introduced here is the way in which the points of the paraflel curves 
are mapped onto the flattening plane. As illustrated in Figure 10, let Aflj = Cg, fl C,j be the point 
be­ing processed, PiJ is obtained by preserving at each neighbour &#38;fkI G {M1 lj , 1141J+1, Mi+l , 
MIJ_l} already processed, the 1 three angles (61~1,@*~1,@3~1). (1 &#38;land #2kl are cross angles (fac­ing 
&#38;fiJ ) between the curves that intersect at ~~1. preserving @s kl is equivalent to preserving the 
geodesic curvature at Alkl on the curve containing Mij and &#38;fkl, One can not always preserve all 
three angles. For instnnce, in Figure 10 the pOint Mt+l j I has not yet been processed, so one cannot 
preserve 02ij 1 Each angle / lq Surface Plane bp I-2J Figure 10: Preserving angles at processed neighbors 
(develop­ ment step). preservation provides a different point in the flattening plane. This point is 
obtained using the angle preserver: P;~ =P@.,,(M:j), r= 1,2,3; kl E {i lj, ij+l, i+lj, ij 1} The point 
P,, corresponding to MiJ in the flattening Pl=e is then 3 ~r,kl the ccntroid of the points The choice 
of the centroid in ~uces slight errors on the angles and distances. The accumulation of these errors 
provides a gradient of distortions in the scanning direction. So, for a better distribution of the distortions 
the curve being processed is not scanned from one extremrJ point to the other extremal point. Instead, 
the curve is scanned from the central point to the extrcmal points, With this technique distortions are 
present on both C:., C,j curves. The distortions increase in diagonal directions as one gets far from 
the central point of the initial curve. Let Wjl < u < V)z On the 3When the surface is developable the 
preservation of each angle gives the same point in the flattening plane. initial curve C,., . The distortion 
metric for a specific curve Ci. is then:   = -1 lld(~~kj~lk+~)-~(~l~jp~~+,)ll+C(c,.) = *( x d(~ik,kf~k+~) 
k=jl = - lld(~kji,~k+ljl) -d(pkj, IPk+lji )1! + E d(~kJ1,Mk+l),) k=*o = -1 lld(MkJ,! Mk+l),) -d(pk)zopk+lj>)lll 
x d(Mkj2s Mk+1J2)k=,. Here one has Z=i io rmd J=jl -jl 4.2 Relaxation procedure In the above development, 
when mapping a point onto the flat­tening plane, one does not take into account all the neighboring points 
(see figure 11). The reason is that some neighbors have not been processed yet. In nddition, for a given 
ncighbour one can not always preserve all the angles. The relaxation procedure consists Ui / j Figure 
11: Preserving three rmgles at four neighboura (relaxation Step). of recomputing points of the obtained 
flat piece several times until the change becomes insignificant. At each iteration one uses the results 
of the previous itemtion. The location of a point P,; at iteration n is then: P/~ is thus the ccntroid 
of the twelve points obtained by preserving the three angles of each neighbour. The angle preserver P 
-l uses the flattening points of iteration n 1. Let PI, P2, , P,, be a cluster of n points within a 
plane and let P be a point in this plane. One calls the dispersion of the cluster around P the value: 
k=i Dsp(P) is minimum for the centroid P , of the cluster of points. Dap(P,,, ) is then called the dispersion 
Of the cluster Of points. FOr our purposes, the quality of the flattening at a given point Pij can be 
measured by the dispersion D#p(PiJ ) of the twelve points given by the twelve nngle preservers. The smaller 
D~p(pij ) k the better is the flattening at P,, . Thus tnking the centroid of the twelve points nt each 
itcrntion is better for distributing and reducing the distortions.  @ ~ ComDuter Graphics, Volume 25, 
Number 4, JUIV 1991 As described above, we use isoparametrics as cut lines: starting from a given curve, 
we develop the shoe surface until a deforma­tion threshold is reached. As the whole surface is not developable, 
we c~n play on the width of the pieces by vsrying the distortion threshold. The shoe form is cut into 
three pieces (which flattening are shown in Figures 14-c, 14-d and 14-e): the sole, the interior and 
the exte­rior sides. The sole, m relatively flat, is flattened with the simple geodesic curvature flattening. 
The relaxation process has been ap­plied to both sides. Figures 14-f and 14-g show, from different viewpoints, 
the entirely text ured shoe shape, obtained by mapping on it successively a dig-Itized nciturcd leather 
and an artificisf weaving. Figures 14-h and 14-i show the modeling of a sandal and its flat­tened pieces. 
Small pieces have been obtained with the geodesic curvnture preservation algorithm. The big piece has 
needed the re­laxation algorithm. Finally, one can see the sandal textured with the lenthcr and the artificial 
material in Figures 14-j rmd 14-k. Each of the shoe models has taken less than 3s computation time for 
flattening the pieces. The atline interpolation for texture map­ping has taken between 15 and 20s. From 
a practical point of a view, an efficient CAD tool should en­nble one to draw manuslly the region edge 
curves cm the 3-D surface. Our techniques could then be used for the flattening of each region, by developing 
the parametric pattern cent aining the selected region, projecting the edges on the 2-D mapping, and 
fi­nc-dly cut ting the plane along these borders. In this case, the choice of the initird development 
curve could even be automatic: the user needs only to know the distortion rate induced on each piece 
of the shoe. This will be pursued in future work. The edgoritbm of drnwing curves on 3-D sucfaces is 
described in [15].  Conclusion We have presented in this paper new and efficient algorithms for non-distorted 
texture mapping. Unlike more conventional ap­pronchcs based on global minimization of distortions, our 
tech­niques ennble n controlled unfolding around an initial curve by choosing n distortion metric on 
isoparametrics of the surface. Moreover, distortions are lessened by introducing discontinuities on the 
unfolded surface. Possible applications (among others) could be umbrella and underwear designing, and, 
more generally, mrmu­fncturing. The new algorithms are easy to implement, although they me based on uncommon 
concepts (from differential geometry); nev­ertheless, they present several aspects for further study. 
First, a IIuman intervention for the choice of the initial curve and the dis­tortion threshold is necessary. 
Also, our techniques con only be used on surfnces given explicitly by their parametric equations, thus 
reducing their scope. The generalization to polygonal sur­faces would then be desirable. Another disadvantage 
is that seam lines (cuts) nrc locnted on isoparametric curves, and thus depend on the pnrnmetrizrdion 
chosen. On most natural objects covered with phmnr texture (clothes and walls for example), seam lines 
arc locnted on lines of mnin curvature, giving a harmonious look to the mnpping. It could then be useful 
to parametrize the surface again cdong the main directions ([1]) before flattening it. This is not cdways 
true, though, and in certain cases (shoe modeling for ex­ample) aesthetics m-e important. This is a very 
subjective notion; drawing edge curves by hand on the surface becomes neccssnry in such cases. Another 
interesting problem consists of how to reduce as much as possible the number of cut pieces . A preliminary 
idea would be to extend n previously mapped piece, by choosing its borders as be­ing the initial curves 
of the flattening algorithms described in this paper. Another solution consists of finding a strategy 
to merge different pieces previously obtained. This is still an open problcm. The last point that could 
be explored is the texture orientation: how can one locate and orient the several flattened pieces in 
the texture plnne, in order to obtain a good appearance at seam lines. A possible solution would consist 
of minimizing a global metric of positions and orientations on the common borders of the unfolded parts. 
 Acknowledgements The authors are very grateful to Dr. D. Geman, Dr. J. Ralston and Dr. P. Sander for 
revising the pnper; to Dr. M. Gangnct and Dr. F. Schmitt for their valuable comments; to L. Doghman, 
F. Ledru snd L. Vinet for their precious help; smd to Dr. A. Gagalowicz for his support. References 
[1] J.M. Beck, R.T. Farouki, rmd J .K. Hinds. Surface analysis methods. IEE CGA, pages 18 37, December 
1986. [2] C. Bennis. Syllth&#38;c de textures hi6rarchiques planes -d6vel­ oppernent dc surfnccs 3d pour 
un placage de textures min. imisant lcs distortions. 2 hisc de Doctorat en Sc:encc, Uni­vcrsitl de Pans 
XI, centre d Orsay, D4cembrc 1990. [3] C. Bennis and A. Gngalowicz. Hierarchical texture synthe­sis on 
3-d surfnces. EURO GRAPHICS 89, pages 257 268, September 1989. [4] C. Bennis and A. Gngnlowicz. Mapping 
de textures sur une approximation tricmgdaire des surfaces. PIXIM $9, pages 139-152, 1989. [5] E. Bier 
and K. Sloan. Two-part texture mapping. IEEE Computer Graphtcs and Apphcations, pages 40 53, Septem­ber 
1986, [6] J.F. Blinn and M.E. Newell. Texture and reflection in com­puter generated images. Communications 
ofthe A CM, 19, 10, pages 542 547, October 1976. [7] M.F. Do Cnrmo. Differential geometry of curves and 
surfaces. Prentice-Hall, Englewood Clifis, Inc., 1976. [8] E. Catmull. A subdivision algorithm for computer 
display of curved surfnces. Ph.D. Dissertation. Dept. of Computer Sciences, University .} Utah, December 
1974. [9] E. Catmull and AR. Smith. 3-d transformation of images in scanline order, Computer Graphicsl 
14(3), July 1980. [10] F.C. Crow, Summed-nrea tnbles for texture mapping. SIG- GRAPH 84, PT.c. o/ Computer 
Graphws, pages 207-212, July 1984. [11] E.L. Schwartz et cd. Computational neuroscience: Applica­tions 
of computer graphics nnd image processing to 2d and 3d modelling of functional architecture of visual 
cortex. CGA, ~0/. 8, No. 4, pages 13-23, July 1988. [12] G. Farin. Curves and surfnces for aided geometric 
design. Academsc Press, San Diego, Inc., 1988. [13] E. Fiume, A. Fournier, and V. Canale. Conforrnal 
texture mapping. EURO GRAPHICS 87, pages 53 64, 1987. [14] P, Hcckbert. Fundamentrds of texture mnpping 
and image warping. UCB/CSD 89/516, of Cdiforn:a, Berkeley. [15] G. Iglesias and S. Coquillart. preparation. 
[16] SD. MCI cmd A. Gngrdowicz. Computer Science Dept, Univ. Curve design on surfaces, In Determination 
of locaf coor­ dinate systems for texture synthesis in 3-d surface. EURO­GR.4PHICS 85, September 1985. 
[17] S.D. Mn cmd H. Lin. Optimal texture mapping. EURO-GRAPHICS 88, pages 421-428, September 1988. [18] 
M. Olin, K. Tsutsui, A. Ohba, Y. Kurauchi, and T. Tago. Renl-time manipulation of texture-mapped surfaces. 
SIG-GRAPH 87, Pro.. of Computer Graphics, 21(4):181-18-8, 1987. ___I---..---------__. . ..------. --------:- 
__--   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122745</article_id>
		<sort_key>247</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Generalized implicit functions for computer graphics]]></title>
		<page_from>247</page_from>
		<page_to>250</page_to>
		<doi_number>10.1145/122718.122745</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122745</url>
		<abstract>
			<par><![CDATA[We describe a method of generalizing implicit functions by use of modal deformations and displacement maps. Modal deformations, also known as free vibration modes, are used to describe the overall shape of a solid, while displacement maps provide local and fine surface detail by offsetting the surface of the solid along its surface normals. The advantage of this approach to geometric description is that collision detection and dynamic simulation become simple and inexpensive even for complex shapes. In addition, we outline an efficient method for fitting such models to three dimensional point data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[collision detection]]></kw>
			<kw><![CDATA[computer modeling]]></kw>
			<kw><![CDATA[deformations]]></kw>
			<kw><![CDATA[dynamics]]></kw>
			<kw><![CDATA[implicit surfaces]]></kw>
			<kw><![CDATA[solid modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP131033664</person_id>
				<author_profile_id><![CDATA[81332525857]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sclaroff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vision and Modeling Group, The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39024874</person_id>
				<author_profile_id><![CDATA[81452609331]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alex]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pentland]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Vision and Modeling Group, The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>97881</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Baraff. Curved Surfaces and Coherence for Nonpenetrating Rigid Body Simulation. Computer Graphics, 24(4): 19-28, 1990.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Barr. Global and Local Deformations of Solid Primitives. Computer Graphics, 18(3):21-30, 1984.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Barr. Superquadrics and Angle-Preserving Transforms. IEEE Computer Graphics and Applications, 1(1): 1 1-23, 1981.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>247</ref_obj_id>
				<ref_obj_pid>245</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[P. J. Burr and E. H. Adelson. A Multiresolution Spline With Application to Image Mosaics. ACM Transactions on Graphics, 2(4):217-236, 1983.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>87568</ref_obj_id>
				<ref_obj_pid>87526</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Foley, D. Lane, and G. Nielson. interpolation of Scattered Data on Closed Surfaces. Computer Aided Geometric Design, 7:303-312, 1990.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378530</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. K. Hahn. Realistic Animation of Rigid Bodies. Computer Graphics, 22(4):299-308, 1988.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74364</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Kalra and A. H. Bart. Guaranteed Ray Intersections with Implicit Surfaces. Computer Graphics, 23(3):297-306, 1989.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Moore and J. Wilhelms. Collision Detection and Response for Computer Animation. Computer Graphics, 22(4):289- 298, 1988.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91444</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Pentland. Computational Complexity Versus Virtual Worlds. Computer Graphics, 24(2): 185-192,1990.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>117761</ref_obj_id>
				<ref_obj_pid>117754</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Pentland and S. Sclaroff. Closed-Form Solutions for Physically-Based Shape Modeling and Recognition. IEEE Trans. on Pattern Analysis and Machine Intelligence, 13, to appear in July 1991. Special Issue on Physically-Based Modeling.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74355</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Pentland and J. Williams. Good Vibrations : Modal Dynamics for Graphics and Animation. Computer Graphics, 23(4):215-222, 1989.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97883</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. von Herzen, A. Barr, and H. Zatz. Geometric Collisions for Time-Dependent Parametric Surfaces. Computer Graphics, 24(4):39-48, 1990.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97906</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[L. Williams. Performance-Driven Facial Animation. Computer Graph~:s, 24(4):235-242, 1990.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Generalized Implicit Functions For Computer Graphics 
 Stan Sclaroff and Alex Pentland Vision and Modeling Group l%e Media Laboratory Massachusetts Institute 
of Technology Cambridge, MA 02139  Abstract We describe a method of generalizing implicit functions 
by use of modal deformations and displacement maps. Modal deformations, also known as free vibration 
modes, are used to describe the overall shape of a solid, while displacement maps provide local and tine 
surface detail by offsetting the surface of the solid along its surface normals. The advantage of this 
approach to geometric description is that collision detection and dynamic simulation become simple and 
inexpensive even for complex shapes. In addition, we outline an efficient method for fitting such models 
to three dimensional point data. CR Categories: 1.3.5 [Computer Graphics]: Computational Ge­ometry and 
Object Modeling; 1.3.7 [Computer Graphics]: Graphics and Realism. Additional Keywords: Collision Detection, 
Implicit Surfaces, Simulation, Dynamics, Deformations, Solid Modeling, Computer Modeling. 1 Introduction 
 In many graphics applications, and especially in physical simula­tions, the ability to efficiently detect 
and characterize collisions and intersections is essential. Unfortunately, the polygon and spline representations 
normally employed in computer graphics are ill suited to this task. When using a polygon representation, 
for instance, the computational complexity of collision detection is O(nrrz) operations, where n is the 
number of polygons and m is the number of pints to be considered after pinning via bounding box considerations 
[8]. As a consequence, collision detection is one of the most costly operations in many graphics applications 
[6], despite significant efforts to optimize algorithms for collision and intersection detection [I; 
8]. In contrast, one can perform collision detection relatively effi­ciently when employing an implicit 
function representation (e.g., spheres, swept solids, deformable superquadrics [3]) by making use of 
their inside-outside function. hr each case, the computational complexity of this type of collision checking 
is only O(m) rather than 0( nrn) [9]. A more subtle but perhaps equally important advantage of this approach 
is that the collision surface may of­ten be characterized analytically [7; 12], allowing more accurate 
simulation of mukibody collisions. Permission to copy without fee all or part of this materialis grarrtcd 
providedthai the copies are not made or distributed for direct commercial advantage, the ACM copyright 
notice and the title of the publication and its date appear. and notice is given that copying is by permission 
of the Association for Compuling Machinery. To copy otherwise, or to republish, requires a fee arrrthr 
specific permission. Unfortunately, implicit function representations have not been sufficiently expressive 
for general use. The contribution of this paper will be to show how implicit function representations 
maybe generalized to allow fast collision detection for more general shapes, and to outline an efficient 
technique for fitting these generalized implicit functions to three dimensional point data.  2 Generalized 
Implicit Functions An implicit function representation defines a surface as a level set of a function 
~, most commonly the set of points for which ~(x) = O. For instance, the inside-outside function we use 
for superquadric ellipsoids, before rotation, translation or deformation, is: In practice we have found 
this better behaved than the standard superquadric inside-outside function, as it is more similar to 
the a normal LJ distance metric. A solid deftned in this way can be easily positioned and oriented, by 
transforming the implicit function: 2= Mx+b (2) where M is a rotation matrix, and b is a translation 
vector. Similarly, the implicit function s positioned and oriented inside­outside function becomes: /(X) 
= f(M- (k -b)). (3) To detect a collision between a point x = (z, y, z ) and the volume bounded by this 
surface, one simply substitutes the coordinates of x into the function ~. If the result is negative, 
then the point is inside the surface and a collision has occurred. Generalizations of this basic operation 
may be used to find line-surface intersections or surface-surface intersections [12]. 2.1 Deformations 
As in Barr [2; 3], this basic set of functions can be generalized further by defining an appropriate 
set of global deformations D with parameters u. For particular values of u the new deformed surface is 
defined using a deformation matrix Du: i= MDux+b (4) where x is the position vector after rotation, deformation, 
and translation. Similarly, the inside-outside function becomes j(X) = j(D; M- (i -b)). (5) This inside-outside 
function is valid as long as the inverse deforma­tion D~i exists. Thus by selecting a set of deformations 
that can be easily invefied, we can greatly expand the class of shapes that can be described using an 
implicit function representation. 0[991 AC M-O-K9791-436-tWlrsoo75 007/0247 247 @@ For example, the 
projection function ~(~) = (q, w) for su­perquadnc ellipsoids is computed as follows. We first find u 
by observine: . cos 1 ~ sinez w ~= : = tane~ u (lo) Cos I ~ COS 2w where (~, ~, ~)T = ~ is the undeformed, 
displaced surface point. From Equation 10, we see that u = atan] / (j/2). The remaining parameter, q, 
is determined by either T = atan /c ((Z Cosezw )/5) )/J) depending on whether E or tj is ;Jr= atan f 
((.Zsinel ~ 2.3 An Example Figure 1 shows two frames from a physically-based animation in which three 
seashell-like shapes drop through a viscous medium (e.g., seawater), hit the sea bottom, bump into each 
other, and then come IO rest. The simulations were conducted using the technique of modal dynamics as 
implemented in the ThingWorld system [11]. The seashell shapes were modeled as supequadric ellipsoids 
with displacement maps. Each displacement map consisted of a 100 x 100 uniformly spaced grid generated 
by combinations of sines and cosines. The shells were polygonalized for display and simulation purposes 
 approximately 2300 polygons for the spike seashell, and 576 polygons for the other seashells. Bounding 
boxes were also computed for the objects. During the simulation, if these bounding boxes crossed, then 
polygon vertices were plugged into the offending objects inside/outside functions to test for collisions. 
Execution time for the three active objects was 0.05 seconds per time step during the initial frames 
of the animation (before any contact), and 0.08 I seconds per time step during the final few frames, 
when the three seashells were colliding with the seabed (which is not planar), and the shells were colliding 
with each other. Subtracting the pre-contact time from the execution time during contact, we find it 
took approximately 0.031 seconds per time step for contact detection and calculation of the non-rigid 
dynamics. Contact detection, physical simulation, and geometric updates were computed on a Sun 4/330, 
with a TAAC board performing rendering. 3 Fitting 3-D Point Data It is useful to be able to fit a generalized 
implicit function rep­resentation to three-dimensional point data, so that objects in the world can be 
sampled and brought into our computer where they can participate in simulations. To fit point data with 
a general­ized implicit function requires determining both the deformation parameters u = (u1,.. um)~ 
used in Du, and a displacement map. Let us assume that we are given n three-dimensional sensor measurements 
~ (in the global coordinate system) that originate from the surface of a single object: x=[il, j,, z,, 
. ..in. gn, zn]~ (11) We need to determine a mapping between X, points on the undefotrned surface, and 
~, the sensor measurements that specify the points target positions after displacement and deformation. 
To determine this mapping, we first define an ellipsoidal coordinate system by examination of the data 
s center of mass and central moments of inertia. For a detailed description of this initialization step, 
see [10]. This ellipsoid will serve as our initial guess of the undeformed implicit surface, The sensor 
measurements are then projected onto this ellipsoid by using the projection function, P(x). This projection 
implicitly defines a correspondence between the undeformed surface points and their desired positions 
after deformation. When the number of data points is large it is more efficient to project the data onto 
a predetermined grid of undeformed surface points. Each data point s position is distributed among nearby 
surface points using a Gaussian weighting [13]. Computer Graphics, Volume 25, Number 4, July 1991 3.1 
Recovering Oeformatlon Modes Once point correspondences have been established, we can proceed with fitting. 
The task will be to deform the original undefomned points, X, to their desired positions, ~. At the end 
of this process, we will have recovered the deformed implicit function which best fits the data points. 
To begin with, the effect of each of them deformation parameters Ui in % on the position of the undeformed 
points, X is calculated, to obtain a m x 3n matrix -whose ith column di. is: ~i* = ~azl ~Yl ~zl 82. ayn 
azn ~ (12) aUi ~Ui ~ K K G] The matrix @ can be computed by finite differences i.e., analytically, 
or by applying a small amount of each deformation W; and measuring the resulting change in the coordinates 
of each point. In the ThingWorld modeling system the deformations used are the object s free vibration 
modes, so that the columns of @ define a coordinate transformation that diagonalizes the object s finite 
element equations. This allows the object s rigid and non­rigid dynamics to be simulated very inexpensively, 
as described in reference [11 ]. The marnx @ is the Jacobian of Du at each point in X, and so may be 
used in a modified Newton-Raphson iteration to obtain the minimum RMS error estimate of deformation parameters 
u as follows: k+l=@-l(x_x~)+uk u (13) where Xk is the pro~ction of the data points on the surface defined 
by the deformations Uk at iteration k, and U = O, XO = X. We have found that a single iteration is often 
sufficient to obtain a satisfactory estimate of the deformation parameters u. Because -is usually not 
square, use of the pseudoinverse * f = ( ~~~ )-1Q T is required; as (~~T ) is only an m x m matrix, this 
calculation is inexpensive.  3.2 Computing a Displacement Map If there are more degrees of freedom in 
the data points than in the deformation parameters, the deformed model will not generally pass through 
the data points exactly (i.e., f( Dfil M- (i b))# 0).A more accurate approximation to the data points 
can be obtained by incorporating these residual differences into a displacement map. This is done by 
solving for the displacement map value d( q, J ) that yields x = MDU(X + dn) + b for some point x on 
the undeformed implicit surface. The final result is a generalized implicit function representation that 
normally provides an exact fit to the set of initial data points, and provides a smoothly interpolated 
surface between those points except in certain degenerate cases, such as when Nyquist criteria are not 
satisfied. To compute the displacement map each data point Z is sub­jected to the inverse deformation 
Dfii to obtain ~, the point in the undeformed space. Next, we project ~ along the surface nor­mal using 
P(~) to obtain its two-dimensional parametric space coordinate (q, w). Finally, we compute the undeformed 
point s normal distance to the undeformed implicit surface by substituting it s coordinates into the 
surface s inside-outside function: d(rj , w) = f(i). (14) In the ThingWorld system displacement maps 
are represented by a regularly spaced grid in the surface s parametric space. Thus as each point is projected 
and its displacement determined, the result is spread to nearest grid points by Gaussian weighted averaging. 
This interpolation method works well when data points are fairly dense, however when there are only a 
few data points more sophisticated interpolation methods must be used [5], 249    
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122757</article_id>
		<sort_key>251</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Convolution surfaces]]></title>
		<page_from>251</page_from>
		<page_to>256</page_to>
		<doi_number>10.1145/122718.122757</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122757</url>
		<abstract>
			<par><![CDATA[Smoothly blended articulated models are often difficult to construct using current techniques. Our solution in this paper is to extend the surfaces introduced by Blinn [Blinn 1982] by using three-dimensional convolution with skeletons composed of polygons or curves. The resulting convolution surfaces permit fluid topology changes, seamless part joins, and efficient implementation.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[blends]]></kw>
			<kw><![CDATA[convolution]]></kw>
			<kw><![CDATA[implicit surface]]></kw>
			<kw><![CDATA[parametric surface]]></kw>
			<kw><![CDATA[solid modeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P150698</person_id>
				<author_profile_id><![CDATA[81100193431]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jules]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bloomenthal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center, Palo Alto, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31096537</person_id>
				<author_profile_id><![CDATA[81100026146]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ken]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shoemake]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xerox Palo Alto Research Center, Palo Alto, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bajaj, C., and ihm, I. Algebraic S~u,face Design with Hermite Interpolation. Technical Report CSD-TR-939, Computer Sciences Dept., Purdue University, January 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>808573</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barr, A. "Global and Local Deformations of Solid Primitives." Proceedings of SIGGRAPH'84 (Minneapolis, Minnesota, July 23-27, 1984). In Computer Graphics 18 (3), (July 1984), 21-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blinn, J.F. "A Generalization of Algebraic Surface Drawing." ACM Transactions on Graphics i (3) (July 1982), 235- 256.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[BIoomenthal, J. "Polygonization of implicit Surfaces." Computer Aided Geometric Design 5 (1988), 341-355.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, J. "Techniques for Implicit Modeling." Xerox PARC Technical Report P89-00106. 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Colbum, S. "Method for Global Blending of Computer Modeled Solid Objects using a Convolution Integral." United States Patent No. 4,791,583, December 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Colbum, S. "Solid Modeling with Global Blending for Machining Dies and Patwrns." SAE Technical Paper Series #900878, Society of Automotive Engineers, Inc., 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>912585</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[DeRose, T.D. Geometric Continuity: a Parametrization- Independent Measure of Continuity for Computer-Aided Geometric Design. Ph.D. dissertation, Computer Science division, University of California, Berkeley, California, August 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>88575</ref_obj_id>
				<ref_obj_pid>88560</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dobkin, D., Levy, S., Thurston, W., and Wilks, A. "Contour Tracing by Piecewise Linear Approximations." A CM Transactions on Graphics, 9 (4), (October 1990), 389- 423.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>574891</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Dudgeon, D. and Mersereau, R. Multidimensional Digital Signal Processing. Prentice Hall, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Duff, T. "Polygon Scan Conversion by Exact Convolution." Proceedings of the International Conference On Raster Imaging and Digital Typography (Lausanne, Switzerland, October, 1989), 154-168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83600</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Farin, G. Curves and Surfaces for Computer Aided Geometric Design, 2nd Edition. Academic Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Foley, J., van Dam, A., Feiner, S., and Hughes, J. Computer Graphics: Principles and Practice, 2nd Edition. Addison- Wesley, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617601</ref_obj_id>
				<ref_obj_pid>616014</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hall, M., and Warren, J. "Adaptive Polygonalization of Implicitly Def'med Surfaces." IEEE Computer Graphics and Applications 10 (6), (November 1990), 33-42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>866097</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hoffman, C. and Hopcroft, J. The Potential Method for Blending Surfaces and Corners. Technical Report TR 85- 674 Computer Science Dept., Cornell University, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97915</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lengyel, J., Reichert, M., Donald, B.R., and Greenberg, D.P. "Real-Time Robot Motion Planning Using Rasterizing Computer Graphics Hardware." Proceedings of SIGGRAPH'90 (Dallas, Texas, August 6-10, 1990). In Computer Graphics 24 (4), (August 1990), 327-335.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77059</ref_obj_id>
				<ref_obj_pid>77055</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Loop, C., and DeRose, T. "A Multisided Generalization of Bezier Surfaces." ACM Transactions on Graphics 8 (3), (July 1989), 2(N-234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>325231</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Middleditch, A.E. and Sears, K.H. "Blend Surfaces for Set Theoretic Volume Modeling Systems." Proceedings of SIGGRAPH'85 (San Francisco, California, July 22-26, 1985). In Computer Graphics 19 (3), (July 1985), 161- 170.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Nevatia, R. Machine Perception. Prentice-Hall, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Nishimura, H., Hirai, A., Kawai, T., Kawata, T., Shirakawa, I., and Omura, K. "Object modeling by distribution function and a method of image generation." Journal of papers given at the Electronics Communications Conference 1985, J68-D(4), 1985 (In Japanese).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Requicha, A.A.G. "Toward a Theory of Geometric Tolerancing." International Journal of Robotics Research 2 (4) (Winter 1983), 45-49.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Ricci, A. "A Constructive Geometry for Computer Graphics." The Computer Journal 16 (2), (May" 1973), 157-160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77271</ref_obj_id>
				<ref_obj_pid>77269</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Rockwood, A.P. "The Displacement Method for Implicit Blending Surfaces in Solid Models." ACM Transactions on Graphics 8 (4), (October 1989), 279-297.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Rossignac, J.R. and Requicha, A.A.G. "Constant-Radius Blending in Solid Modeling." Computers in Mechanical Engineering (July 1984), 65-73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>911263</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. Implicit and Parametric Curves and Surfaces }'or Computer Aided Geometric Design. Ph.D. dissertation, Mechanical Engineering, Purdue University, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. "Piecewise Algebraic Surface.Patches." Computer Aided Geometric Design, 2, (1985), 53-59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T., and Parry, S. "Free-Form Deformations of Solid Geometric Models." Proce~ings of SIGGRAPH'86 (Dallas, Texas, August 18-22, 1986). In Computer Graphics 20 (4) (August 1986), 151-160.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Sederberg, T. "Algebraic Geometry for Surface and Solid Modeling." Geometric Modeling: Algorithms and Trends, G. Farin, ed., SIAM Press, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77270</ref_obj_id>
				<ref_obj_pid>77269</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Warren, J. "Blending Algebraic Surfaces." ACM Transactions on Graphics 8 (4) (October 1989), 263-278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>66822</ref_obj_id>
				<ref_obj_pid>62847</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Woodwark, J.R. "Blends in Geometric Modelling." The Mathematics of Surfaces II, ed. R. Martin, 255-297.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Wyvill, G., McPheeters, C., and Wyvill, B. "Data Structure for Soft Objects." Visual Computer 2 (4), (August 1986), 227- 234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Convolution Surfaces JulstJ Bloomenthal Ken Shoemake 
Xerox Pab Alto Research Center Palo Alto,California94304 Abstract Smoothly blended articulated mo&#38;ls 
are often dtificult to construct using current techrtiiues. Our solution in this paper is to extend the 
surfaces introduced by Blinn ~lii 1982] by using three-dimensional convolution with skeletons composed 
of ~lygons or curves. The resulting convolution surfaces permit fluid topology changes, seamless part 
joins, and efficient implementation. CR Categories and Subject Descriptors: 1.3.5 [Computer Graphlca]: 
Computational Geometry and Obje@ Modeliig -curve, surface, solid, and object representations. Additional 
Keyworda and Phraaes: Implicit Surface, Parametric Surface, Convolution Solid Modeling, Blends. INTRODUCTION 
Animators seek models that flex and transfonrn, but which are easy to position and mold. Designers often 
create these lively shapes by skillfully combining ~ltives, such as parametric surfaces (includrng polygons), 
or implicit surfaces and solids. A parametric surface is given by a spatial position function: p (u, 
v) = [x(u, v), y(u, v), Z(U,v)]. In practice, the functions are splines defined by pieces of polynomials, 
or ratios of polynomirds [Farin 1990], and are shaped by a sparse set of control points with an intuitive 
geometric relation to the surface. A single B-spline surface is naturally smooti despite its piecewise 
construction. It is difticulL however, to create a smooth union of surfaces automatically. An implicit 
surface is the zero-set of an implicit f%rtctionf(p) = f(x, y, z). Including points for which f(p) is 
positive gives a solid. In practice the most common functions used are polynomials, especially quadratics. 
The resulting algebraic surfaces can represent arty rational polynomial parametric surface, as shown 
by classical algebraic geometry theory [Sederberg 1983]. The reverse is not true, however, suggesting 
that algebraic surfaces are more powerful than parametric surfaces. Unfortunately, qutilcs are liiited 
in shape, higher degree surface methcds are in their infancy [Sederberg 1985] [Bajaj 1990], and blending 
surface construction ~srren 1989] seems difilcult to automate. Although algebraic surfaces show promise, 
in this paper we explore the advantages of implicit surfaces based on skeletons. Like control points 
for a spline surface, a simple lower dimensional objec~ the skeleton, resembles and controls the shape 
of a more complicated object. Vtilon research suggests that stick figure skeletons are natural abstractions 
for shapes [Nevatia 1982]. Permission to copy without fee all or parI of this material is granted provided 
[hat the copies are not made or distributed for direct commercial advamage, the ACM copyright notice 
and the tide of [he publication and its date appew, and notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee andkrr 
specific permission. In particular, we extend the approach of Blinn ~lirm 1982], Wyvill et al. ~yvill 
1986], and Nmhimura et al. [Nishimura 1985], who used implicit functions defii by the summation of point 
potentials. The points generate spherical iso-surfaces which blend smoothly into each other when brought 
togethw, hence a point maybe considered a skeleton which is fleshed out to form a body. Points, however, 
are not entirely satisfactory skeletons; for example, points that approximate a flat surface must be 
closely packed to avoid bumps. After briefly considering an alternative generalization, we propose the 
use of convolution surfaces, and show they are a natural, powerful re-interpretation and generalization 
of potential surfaces. Colburn has used implicit surfaces based on convolution to round a solid model 
[Colburn 1990]; we use convolution with piecewise planar skeletons to generate models. Convolution surfaces 
incorporate the smooth blending power and easy manipulability of potential surfaces while expanding the 
skeletons born points to lines, polygons, planar curves and regions, and in principle, any geometric 
primitive. We exploit properties of convolution in general, and Gaussian convolutions in particular, 
to compute our surfaces efficiently.  POTENTIAL SURFACES Blimt stepped beyond algebraic surfaces for 
molecular modeliig by generating an exponentially decreasing field from the center of each atom and rendering 
the iso-potential surfaces [Blii 1982]. That is, from a set S of atom centers an implicit function is 
defined at any point p in space as f(S, p) = ~exp (- s~p 2) Ses The surface is given by those points 
p satisfying f(S,p)-c = O, where c is the iso-poterttial value. Others have preferred pieces of polynomials 
for the field functions [Wyvill 1986], [Nishimttra 1985]. Essential features of any such function are 
that it decrease monotonically, and drop to a negligible value beyond a moderate radius. (Although Blinn 
observed that the decay need not be spherically symmetric, this possibility seems to have been largely 
neglected.) Thus a single point generates a spherical shell, and well-separated points generate separate 
spheres. As two points are brought together, their shells reach out and merge smoothly. When the points 
are coirtciden~ a single larger sphere results. Because the non-negative regions of these implicit functions 
define solid volumes, CSG set operations are also possible. Simple arithmetic operations on the function 
values suffice [Ricci 1973]; for example, max(f(Sl, p), f(S2, p)) gives the union of the two volumes 
generated by S 1 and S2. Negating the implicit function is also of interesL allowing us to subtract volumes. 
 01991 ACM-O-tf979J-436-8/91/007/025 I $4X).75 251  : SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 
One advantage of potential surfaces is that they blend smoothly. Another is that they are simple to edit; 
to alter the surface one merely moves, adds, or deletes points. Unfortunately, flat surfaces can only 
be approximated. DISTANCE SURFACES Point skeletons can be generalized to polygonal skeletons in at least 
two ways: by computing the potential from only the nearest point of the polygon. or by summing the potentials 
from all the points. The second possibility gives convolution surfaces; the first gives distance surfaces-or 
offset solids in the sense of Requicha [Requicha 19831. Distance surfaces are iso-surfaces of I@, p). 
the function value at a point p defined by @, p) = min IIs-p II. SE s When S is a spline curve or planar 
polygon, ~.t can be computed without explicitly calculating the distance to each point s of the curve 
or polygon [Bloomer&#38;al 19891. For a polygon, projecting p onto the plane of S reduces the problem 
to one in two dimensions. If the projection lies inside S, use the distance to the plane; otherwise, 
use the distance to the nearest point on an edge. As defined, P is not suitable for blending; however 
we can use it to replace the distance calculation in Blirm s exponential, giving one generalization of 
potential surfaces, f(S, p) = exp(p2(S. p)/2). Because this is a composition of monotonic functions, 
one of which is decreasing, it can be written as f(S, p) = z; exp(-II 2 It ). This function gives the 
union of the volumes generated by all the individual points of the collective skeleton. S. When the skeletons 
are not convex, the resulting distance surfaces can show creases, or curvature discontinuity, as seen 
in Figure 1; these are often undesirable. Figure 1: Distance surfaces-skeletons, sum, union The blending 
of primitives within a solid modeling system has received considerable study, as shown by the survey 
of methods in [Woodwark 19861. and the more recent [Rockwood 19891, [Sederberg 19871, and [Warren 19891. 
As Warren [Warren 19891 has shown, for algebraic surfaces blends have a well- defined form involving 
a weighted sum of products of the defining polynomials. The simplest approach for blending distance surfaces 
is to sum the values from each of the skeletons. This eliminates creases but also creates bulges. For 
polygonal skeletons, especially, it is awkward to achieve blends without bulges. One bulge prevention 
method for algebraic surfaces is proposed in [Middleditch 19851; it is expensive and complex, however, 
especially for more than two primitives. Furthermore, our surfaces are not algebraic. CONVOLUTION SURFACES 
We propose to have the best of both worlds: the spline and polygon generators of distance surfaces plus 
the well-behaved blends of potential surfaces. Although potential functions based on ~.t reduce to Blimr 
potentials when applied to a skeleton consisting of a single point. they behave differently for extended 
skeletons like polygons. One particular difference is instructive: the surface from a skeleton broken 
into pieces is not the same as that of the unbroken skeleton. For example, two halves of a line segment 
produce a surface which bulges at the joint. This is because each skeleton generates a surface which 
is a union, using max, while the blending uses summation. If the skeleton is broken down into infinitesimal 
pieces, i.e., individual points, the union becomes irrelevant, and the result is a pure summation, f(S,p) 
= Cexp (- 2 ). IE s or more properly, an integration, m -II s-p II ) n ds. This new f is. in fact, 
the convolution of a spatially extended skeleton, not just a point, with a three-dimensional Gaussian 
filter kernel [Dudgeon 19841. Formally, let S(p) be the characteristic function for the skeleton (meaning 
S(p) = 1 if p is a point of the skeleton, otherwise 0). and let h(p) = exp (For the sake of brevity, 
we omit a more rigorous development involving Dirac delta functions.) Then, using * to represent convolution, 
we have f(P) =~@*Sxp) = lsexp (-II 2 112) ds. Convolution is usually considered part of the signal processing 
theory used to discuss and deal with abasing in rendering [Foley 19901; it is not commonly thought of 
for modeling shapes. Yet uniform B-spline curves and surfaces can be defined as the convolution of the 
B-spline basis functions with the control points [Farin 1990. p. 1471, and robot path planning is simplified 
by convolving the room obstacle geometry with the robot s shape (the robot can then be treated as a point 
[Lengyel 19901). Colbum has used an implicit surface based on convolution of a solid model with a Gaussian 
kernel as a way to round the comers of the solid [Colbum 1988, 19901. Since we base our kernel on the 
potential function, when the skeletons are points convolution exactly reproduces the potential surface. 
For isolated convex skeletons such as triangles, rectangles, or line segments, convolution surfaces have 
almost the same shape as distance surfaces. Now, however, concave skeletons will also be smooth, and 
adjacent surfaces will blend seamlessly. Indeed, the superposition property of convolution guarantees 
that two abutting polygons will yield the same surface as a single more complex polygon which is their 
union: h*(St+S2) = (h*Sl)+(h*S2). This is shown diagrammatically in Figure 2. 63 Figure 2: Superposition 
 To construct a smooth, complex surface from simple skeletons, we need only sum their convolutions. Figure 
3 illustrates results for the animation of two adjacent rectangular skeletons, with the upper one rotating; 
the primitives merge smoothly into a single shape. In contrast, the sum of algebraic surfaces is completely 
unsatisfactory, since the complexity of the surface is limited by the degree, which summing does not 
increase. For example. the sum of any number of quadric surfaces, say spheres, is a single quadric surface! 
Figure 3: Model articulations. IMPLEMENTATION One motivation for using distance surfaces is that they 
are reasonable to compute; it is not immediately clear that the same is true for convolution surfaces. 
In some sense, however. convolution is less complicated than minimizing distance, and is more efficient 
to compute.. Because of the superposition property, we are free to partition a skeleton. Still, it is 
impossible to evaluate the convolution, even for a polygon, by explicitly summing the influence of each 
point. A Gaussian filter, however. has the special property of being separable; it can be factored into 
a product of  Computer Graphics, Volume 25, Number 4, July 1991 lower-dimensional Gaussians. We can, 
for example, separate the 2 component: h@) = exp (F) = exp ry ) = exp (F) exp ($). Thus to convolve 
with a polygon lying in the x-y plane, we can fist perform a planar convolution, then convolve in z. 
Because polygons have infinitesimal depth, the z convolution is trivial. The planar convolution requires 
more work, but is again separable into x and y. We have reduced the spatial convolution of a polygon 
to ix ) dx dy. For a skeleton such as a line segment, the y integral collapses like z; a point requires 
no integration. A Gaussian is also spherically symmetric-it looks the same in all directions-so this 
same kind of three axis separation can be used no matter how the skeleton is oriented in space. This 
suggests a convenient approach for planar skeletons. Scan convert each polygon into its own digital image, 
filter the image in two directions by a Gaussian, then multiply a Gaussian function of the distance from 
p to the plane of the image by the intensity at the point onto which it projects. Figure 4 illustrates 
the process. The images cache planar convolution results, and can be computed efficiently if convolution 
is performed during scsn conversion. P T Y Figure 4: Computing value of the three-dimensional convolution 
at a point in space. In practice, we approximate a Gaussian with a cubic spline. to simplify computation 
and to limit kernel width. Artifacts of the scan conversion can be avoided by choice of a suitable resolution. 
A Gaussian kernel approximates an ideal low-pass filter, removing high frequency details of the skeletons. 
Hence the effective bandwidth of the Gaussian can be used to determine the sampling frequency needed 
to preserve accuracy in the sampled images. and can guide the choice of spatial sampling frequency for 
polygonization [Bloomenthal 19881. [Hall 19901, [Dobkin 19901. A standard Gaussian passes less than 1% 
of the energy in frequencies higher than half a unit, so :: SIGGRAPH 91 Las Vegas, 28 July-2 August 
1991 in this case four samples per unit should suffice. Colbum discusses analogous resolution requirements 
for his octrees. Although Colbum quotes compute times of days, we polygonize a surface in minutes. Colbum, 
however, is solving a different problem: he wants to make miniial changes to an existing solid. The solid 
is diced into tiny cubes before convolving; and while he uses separability, he cannot cache planar convolutions 
as we do. His method requires significant operator input to define patches through which to trace rays. 
Our planar approach can be especially fast for animation; when a skeletal piece is used in many frames 
without change in shape. the planar images can be reused. Convolution surfaces are cheap in other situations 
as well. For a potential surface, evaluating the implicit function at a point requires calculating the 
distance to each nearby point, mapping each distance through a Gaussian and summing. For a convolution 
surface, a swarm of co-planar points can be replaced by a single planar image, which requires only one 
distance calculation, one Gaussian evaluation, and interrogation of the image. The sum over points has 
been replaced by a planar convolution that is factored out of the inner evaluation loop and need only 
be calculated within a kemel width of the polygon perimeter. Any point, line, or planar skeleton can 
be handled, and more general skeletons can be diced into polygons or polylines using standard techniques; 
the bandwidth of the Gaussian filters provides a least upper bound on the size of the pieces. As an example 
of the versatility of our method, Figure 5 is a convolution surface whose skeleton is a live-sided S-patch 
[Loop 19891. Figure 5: Convolution surface from S-patch skeleton. VARIATIONS The shape of a convolution 
surface can be varied in (at least) five ways: by changing the iso-value, changing the shape of the skeleton, 
changing the skeleton weight, changing the convolution kernel. and by spatial deformation. These can 
be illustrated with the two-dimensional potential function depicted as a height field in Figure 6. The 
usual CSG operations are still possible, so components of a model need not blend together. As noted previously, 
unions and intersections can be obtained by applying max and min to the component functions. Figure 6: 
Convolution variations. The iso-value defining the surface (or curves, in this tsvo-dimensional example) 
is represented by a horizontal plane that intersects the mounds in a contour. Raising and lowering the 
plane, which is equivalent to adding a constant to the potential field, causes the plane to intersect 
different contours. Contours could also be determined as the intersection of some curved surface with 
the mounds; but again the same effect can be had by changing the potential field. Changes in the shape 
of the skeleton correspond to moving the mounds. This is the most basic design variation. It is not necessary 
for S(p) to be restricted to 0 or 1. When S is a set of points, each point can be given its own weight, 
and its influence will be Scaled accordingly. In the illustration, this corresponds to the differences 
in height of the mounds. Negative weights correspond to pits rather than mounds, and offer a way to avoid 
unwanted blending, such as between the fingers of a hand. Decreasing the skeleton weight along a line, 
for example, gives a tapered shape, like a carrot. Incorporating a weight function, W(S). in our defining 
function yields f@, PI = Jsw(s) exp (- I 2 I ) da. If the kernel is to remain a Gaussian, the only 
aspect of its shape that can change is its width. It is not necessary to convolve all parts of a skeleton 
with the same width Gaussian; narrow widths can be used where more detail is desired, while still blending 
well. This difference is illustrated by the low mounds in the figure. We speculate that Gaussians with 
broader widths can be used to provide models with less detail for small or distant objects. Deformations 
[Barr 19841 [Sederberg 19861 can be applied to any form of surface, but convolution surfaces allow new 
possibilities. For example, the skeleton offers a convenient reference frame for a spatially variant 
function, such as a stretch perpendicular to the skeleton, breaking the symmetry of the Gaussian. The 
general quadric kernels Blimt used for his Blobby Man can also be considered deformations [Blimr 19821. 
Note that deforming the skeleton produces a different effect than deforming the surface. Figure 7 illustrates 
a surface in which the convolution is twisted, the arm muscles in Figure 8 are stretched.   SIGGRAPH 
91 Las Vegas, 28 JuIY-2 August 1991 Duff, T. Polygon Scan Conversion by Exact Convolution. Proceedings 
of the International Conference on Raster hnaging and Digital Typogr~hy (Lausrmne, Switzerland, October, 
1989), 154-168. Farin, G. Curves and Surfaces for Computer Aided Geometric Design, 2nd Edition. AcademicPress, 
1990. Foley, J., van Dam, A., Feiner, S., and Hughes, J. Computer Graphics: Principles and Practice, 
2nd Edition. Addkon-Wesley, 1990. Hall, M., and Warren, J. Adaptive Polygonalization of Implicitly Defined 
Surfaces. IEEE Computer Graphics and Applications 10 (6), (November 1990), 3342. Hoffman, C. and HopCroft, 
J. The Potential Method for Blending Surfaces and Corners. Technical Report TR 85­674 Computer Science 
Dept., Cornell University, 1985. Lengyel, J., Reicher~ M., Donal~ B. R., and Greenberg, D.P. Real-Time 
Robot Motion Planning Using Rasterizing Computer Graphics Hardware. Proceedings of SIGGRAPH 90 (Dallas, 
Texas. August 6-10, 1990). In Computer Graphics 24 (4), (August 1990), 327-335. Loop, C., and DeRose, 
T. A Multisided Generalization of  Bezier Surfaces. ACIU Tratwzctiom on Graphics 8 (3), (July 1989), 
204-234. Middleditch, A.E. and Sears, K.H. Blend Surfaces for Set Theoretic Volume Modeling Systems. 
Proceedings of SIGGRAPH 85 (San Francisco, California, July 22 26, 1985). In Computer Graphics 19 (3), 
(July 1985), 161­ 170. Nevatia R. Machine Perception. Prentice-Hall, 1982. Nishimur% H., Hirsi, A., Kawai, 
T., Kawa@ T., Shirskaw~ I., and Omur% K. Object modeliig by distribution function and a method of image 
generation. Journal of papers given at the Electronics Communications Conference 1985, J68-D(4), 1985 
(In Japanese). Requich~ AA.G. Toward a Theory of Gennetric Tolerancing. International Journal of Robotics 
Research 2 (4) (Wktter 1983), 45-49. Ricci, A. A Constructive Geometry for Computer Graphics. The Computer 
Journaf 16 (2), (May 1973), 157-160. Rockwood, A.P. The Displacement Method for Implicit Blending Surfaces 
in Solid Models. * ACM Transactiotu on Graphics 8 (4), (October 1989), 279-297. Rossignac, J.R. and Requicha, 
A.A.G. Constant-Radius Blending in Solid Modeling. Computers in Mechanical Engineering (July 1984), 65-73. 
Sederberg, T. Implicit and Parametric Curves and Su@ces for Computer Aided Geometric Design. Ph.D. dissertation, 
Mechanical Engineering, Purdue University, 1983. Sederberg, T. Piec-ewise Algebraic Surface. Patches. 
Computer Aided Geometric Design, 2, (1985), 53-59. Sederberg, T., and Parry, S. Free-Form Deformations 
of Solid Geometric Models. Proceedings of SIGGRAPH 86 (Dallas, Texas, August 18-22, 1986). In Computer 
Graphics 20 (4) (August 1986), 151-160. Sederberg, T. Algebraic Geometry for Surface and Solid Modeling. 
Geometric Modeling: Algorithms and Trends, G. FarirL cd., SIAM Press, 1987. Warren, J. 4 Blendmg Algebraic 
Surfaces. ACM Transactions on Graphics 8 (4) (October 1989), 263-278. Woodwark, J.R. Blends in Geometric 
Modeling. The Mathematics of Surj%ces II, ed. R. Martin, 255-297. Wyvill, G., McPheeters, C., and Wyvill, 
B. Data Structure for Soft Objects. Visual Computer 2 (4), (August 1986), 227­ 234.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122746</article_id>
		<sort_key>257</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Deformable curve and surface finite-elements for free-form shape design]]></title>
		<page_from>257</page_from>
		<page_to>266</page_to>
		<doi_number>10.1145/122718.122746</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122746</url>
		<abstract>
			<par><![CDATA[The finite element method is applied to generate primitives that build continuous deformable shapes designed to support a new free-form modeling paradigm. The primitives autonomously deform to minimize an energy functional subject to user controlled geometric constraints and loads. The approach requires less user input than conventional free-form modeling approaches because the shape can be parameterized independently of the number of degrees of freedom needed to describe the shape.Both a curve and a surface finite element are developed. The properties of these geometric primitives have been engineered to support an interactive three phase approach for defining very fair free-form shapes as found in automobiles, ship hulls and car bodies. The shape's character lines or folds and edges are defined with deformable curve segments. These character lines are then "skinned" with a deformable surface. The final shape is sculpted interactively by applying loads to the surface to control the surface shape between character lines. Shapes created with this technique enjoy the advantage that they are already meshed for further finite element analysis.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.6.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P95310</person_id>
				<author_profile_id><![CDATA[81100612710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Celniker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Schlumberger Laboratory for Computer Science, P.O. Box 200015, Austin, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P60201</person_id>
				<author_profile_id><![CDATA[81100084160]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dave]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gossard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Massachusetts Institute of Technology, Department of Mechanical Engineering, Computer Aided Design Laboratory, 77 Massachusetts Ave., Cambridge, Ma.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>94446</ref_obj_id>
				<ref_obj_pid>94424</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bloor, M.I.G. and Wilson, M.J., "Blend Design as a Boundary-Value Problem", Theory and Practice of Geometric Modeling, Wolfgang Staber and Hans-Peter Seidel (Eds.), 1989]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Celniker G., Gossard D., "Energy-Based Models for Free-Form Surface Shape Design", ASME Design Automation Conference, Montreal Canada. Sep. 1989]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Celniker G., ShapeWright: Finite Element Based Free- Form Shape Design, M.I.T. Ph.D., Dept. of Mechanical Engineering, September, 1990]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Farin, Gerald and Sapidis, Nickolas, "Shape Representation of Sculpted Objects: the Fairness of Curves and Surfaces", Proceeding of Sea Grant Conference, MIT, October, 1988]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61954</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Farin, Gerald, Curves and Surfaces for Computer Aided Geometric Design, Academic Press Inc., Harcourt Brace Jovanovich Publishers, Boston, 1988]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>43652</ref_obj_id>
				<ref_obj_pid>43647</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hagen, H., and Schulze, G., "Automatic Smoothing with Geometric Surface Patches", Computer Aided Geometric Design, Vol. 4, pp. 231-236, 1987]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kass, Michael and Witkin, Andrew, and Terzopoulos, Demetri, "Snakes" Active Contour Models", International Journal of Computer Vision, 1988]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>96529</ref_obj_id>
				<ref_obj_pid>96526</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kallay, Michael and Ravani B., "Optimal twist vectors as a tool for interpolation a Network of curves with a minimal energy surface", CAGD, 1990]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kjellander, J.A., "Smoothing of bicubic parametric surfaces", Computer-Aided Design, Vol. 15, pp. 288- 293, 1983]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kjellander, J.A.P., "Smoothing of cubic parametric splines", Computer-Aided Design, vol 15, No. 3, May, 1983]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>63739</ref_obj_id>
				<ref_obj_pid>63735</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lott, N.J. and Pullin, D.I., "Methods for fairing B- Spline surfaces", Computer-Aided Design, vol. 20, no. 10, December, 1988]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Nielson, G.M., "Some piecewise polynomial alternatives to splines in tension", in Bamhill, RE and Riesenfeld, RF (eds) Computer Aided Geometric Design, Academic Press, 1974]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Nowacki, H. and Reese, D., "Design and fairing of ship surfaces", in Barnhill R.E. and Boehm, W. (eds), Surfaces in CAGD, North-Holland, Amsterdam, pp 121- 134, 1983]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Pramila. A., "Ship Hull Surface design using finite elements", Int. Shipbuild. Prog. Vol. 25 No. 284, pp. 97-I07, 1978]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Sacks, E., and Stoops, D. and Roberts, A., "3-Draw: A Three Dimensional Computer Aided Design Tool", proceedings IEEE international conference of systems, man, and cybernetics, pp 1194-1196, November 1989]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>87213</ref_obj_id>
				<ref_obj_pid>87203</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sapidis, N. and Farin, G., "Automatic fairing algorithm for B-spline curves", Computer-Aided Design, Vol. 22, No. 2 pp. 121-129, March 1990]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Schweikert, D.G., "An interpolation curve using a spline in tension", Journal of Math and Phys. No 45, pp. 312-317, 1966]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Strang, Gilbert, Introduction to Applied Mathematics, Wellesley-Cambridge Press, Massachusetts, 1986]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37427</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Terzopoulos, Demetri and Plait, John and Barr, Alan and Fleischer, Kurt, "Elastic Deformable Models", ACM, Computer Graphics, vol. 21, no. 4, July, 1987]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Zienkiewicz, The Finite Element Method, third edition, McGraw-Hill Book Co., U.K., 1967]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Deformable Curve and Surface Finite-Elements for Free-Form Shape Design George Celnikera and Dave Gossardb 
aSchlumbergerLaboratoryforComputerScience, P.O. Box 200015, Austin, Texas 78720 bMassachusetts Institute 
of Technology, Department of Mechanical Engin@ring Computer Aided Design Laboratory, 77 Massachusetts 
Ave., Cambridge, Ma. 02139 ABSTRACT The finite element method is applied to generate primitives that 
build continuous deformable shapes designed to support a new free-form modeling paradigm. The primitives 
autonomous y deform to minimize an energy functional subject to user controlled geometric constraints 
and loads. The approach requires less user input than conventional free-form modeling approaches because 
the shape can be parametrized independently of the number of degrees of freedom needed to describe the 
shape. Both a curve and a surface finite element are dcvclopcd. The properties of these geometric primitives 
have been engineered to support an interactive three phase approach for defining very fair free-form 
shapes as found in automobiles, ship hulls and car bodies. The shape s character lines or folds and edges 
are defined with deformable curve segments. These character lines are then skinned with a deformable 
surface. The fiial shape is sculpted interactively by applying loads to the surface to control the surface 
shape between character lines. Shapes created with this technique enjoy the advantage that they are already 
meshed for further finite element analysis. Categories and Subject Descriptors 1.3.5 [Computer Graphics]: 
Computational Geometry and Object Modeling; 1.3.7 [Computer Graphics]: Thrce­dimensional Graphics and 
Realism; 1.6.3 [Simulation and Modeling]: Applications; J.6 [Computer-Aided Engineering]: Computer-Aided 
Design (CAD); Additional Key Words and Phrases Finite Elements, Deformable Modeling, Computer Aided 
Geometric Design, Dynamics, Interactive Sculpting 1 INTRODUCTION The objective of thk work is to develop 
an improved computer­based free-form design methodology capable of interactively defining fair shapes 
with a minimal amount of user input. The central idea is that shapes can be sculpted with energy-based 
deformable computer models that mimic real surface behavior to achieve this objective. Pernl]\\mn k) 
c(Ipy w][htm[ fcc all [Jrpart ()( this material is granted pr(wiclcdthat Ihc o!pies tire not mmk or dis(rlbutcd 
({wdirect c(m]nvxcl~l wi~antagc, the ACM cnpyrigh[ notice ml the title of the puhllcati(m md i[i cktc 
tippcm. and notice IS given thtitcnpying is by Pernllii)tm ot the A\ww!:ititm for C{mputing Machinery. 
To cnpy t)therwIW, or [(I republish, rcquircx u Ice andf{)r \pccIlic parmssi on. , 1991 AcM-(1-x9791-436.8/91 
/M)7/02s7 $00.75 Physical deformable media are commonly used for sculpting because their naturally properties 
can simplify creating controlled shapes. For example long slender beams resist bending and so deform 
in gracefully smooth curves. Such beams are used for the lofting of ship hulls. Physical shapes are dlftlcult 
to describe and so are dlfflcult to use for a variety of downstream applications such as manufacturing, 
analysis, and visualization. AS a resul~ an extensive literature has developed to support computer-based 
design of free-form shapes (see [5]). The problem has been that these approaches lack the ease of use 
of sculpting in a deformable medium. The challenge is to recreate this sculpting effect in a computer 
where the shape is defined exactly and is available for other applications. Computer-based deformable 
shape modeling is the combination of parametrically described geometry and an energy minimization algorithm. 
The energy minimization algorithm automatically adjusts a shape to minimize its energy as measured by 
an energy functional subject to user controlled geometric constraints and loads. This automatic adjustment 
mimics the behavior of physical media and so can be exploited. Figure 1 shows the three step paradgrn 
proposed for the design of free-form shapes. First the object s essence is defined as a set of three 
dimensional character lines. A character line is added wherever the object s surface tangent is discontinuous 
such as at edges and rdong creases. The object is then skinned so that over every face there is a deformable 
surface. Finally, the object s shape is completed by interactively sculpting the surfaces with forces 
and loads. Once completed the object s shape can be modified by changing the character lines or by continued 
sculpting of the surfaces. This is the Shape Wright paradigm.  x5? a. character b. skinned c. sculpted 
lines Figure 1) The ShapeWright design Pardlgm  The deformable curve and surface primitives presented 
in this paper have the following interesting properties. 1.) Continuous Curve and Surface representations 
2.) C1 enforced shape with solutions that tend to C3 in the presence of continuous loads and geometric 
constraints 3.) Explicitly enforced geometric constzairtts a) enforced point lwations b) enforced point 
tangent and normal dinxtiona c) enforced curve shapes within and on edges of a surface d) enforced normal 
diredon along an edge or internal curve within a surface 4.) Arbitrarily shaped and topologically arbitrarily 
meshed parametric domains Geometric constraints can be freely mixed with sculpting. All geometric constraints 
are satisfied while sculpting and addhional constraints can be added or modified at any time. Interactive 
control is generated by parametrizing the shape with sculpting loads and geometric constraints. The user 
can create a mix of sculpting loads and geometric constraints to defiie shape modeling effects. Each 
load and constraint is a separate entity. Any load or constraint parameter can be assigned to a slider 
bar to be used to sculpt shape as an interactive, dynamic search of a parameter space. The size of this 
parameter space is independent of the number of degrees of freedom (dofs) needed to describe the free-form 
surface. This strategy encourages the user to work at a high level, thinking in terms such as bigger, 
smaller, fatter, thinner, etc. 2 PREVIOUS WORK Terzopoulos, Witkfi Kass et. al.[7,19] introduced the 
use of deformable models for extracting shapes from video images and for simplifying the generation of 
realistic animations. To extract shape from video images, the video intensity array is converted into 
a force field that operates on the deformable model. In this manner deformable models are able to automatically 
extract features of the video image. Schweikert [17] introduced energy-based shape formulations to the 
Computer Aided Geometric Design field with his splines in tension made for improved interpolating. Nielson 
[12] noted that solving Schweikert s differential problem for shape was equivalent to fiiding the shape 
that minimizes art equivalent energy functional and developed a piecewise polynomial interpolant that 
approximated the minimum while interpolating the constraints. Since then energy-based or minimization 
algorithms have subsequently been used by a variety of researchers to incrementally improve the fairness 
of a shape by tuning the parameters of a shape model after setting them interactively [4,6,8,9,10,1 1,13,1 
6]. Previous deformable based shape modeling systems used fiite difference techniques [1,2]. Consequently 
continuous shapes were approximated as sets of distinct po mts yielding a shape representation inappropriate 
for manufacturing applications. This work presents a method to model shape with deformable models using 
continuous representations. 3 DEFORMABLE MODELING 3a) Deformable Models 258 A deformable model s shape 
is calculated indirectly by tlmdmg a minimum to an energy functional or by solving a set of differential 
equations. It is this indwection that enables the geometry to act autonomously. The deformable models 
used in this work have functional of the general form 1 ~= (a wretch+13bending)do I0 The energy stored 
in a shape is the sum of an u weighted stretching term and a p weighted bending term. By fiidmg the shape 
which minimizes the above functional subject to geometric constraints and user loads we build a shape 
which naturally attempts to resist s~etching and bending. The curve and surface energy functional presented 
in this paper are 2 &#38; ( (a(u) W$ + fl(u)wum2-2 f w) du JC9m and (allw.2 + 2a12wuwv + a22wv2)k= -2fw 
dudv + (pl 1WU2 +2p12%v* + P22%V2)  /[( )1 3 a where w is a contiguous set of points in 3-space. w= 
w(u) = [X(u),y(u),z(u)] for a curve w = W(u,v) = [X(u,v),y(u,v),z(u,v)] for a surface The range on the 
parametric variables u and v may vary for each shape but are limited to the real number set. Wu is shorthand 
for ~w hu while Wvv is shorthand for ~~/ vz f = f(w,t) denotes the applied sculpting forces which are 
changed over time t by the user. The term 2fw represents the amount of work added to the system due to 
deformations caused by the application of external sculpting loads. A result of the calculus of variations 
shows that the one shape W which minimizes a functional of the form used here will also satisfy a related 
set of differential equations known ss the Euler equations. The Euler equations for the curve are 4dz(pwau) 
d(awu) f - = &#38;P&#38; and for the surface are 5 albuwuu) +d1312wuv) +a@ww) &#38;2 3V2 ( auav ) .f 
i3(allwU + a12wv) + il(a12wm + auwv) -( au av) Note that the above single vector equations represents 
three independent scalar equations in x, y and z. The effect of the sculpting forces f are best seen 
in the Euler equations. They balance the internal forces due to stretching and bending. In some sense 
the shape is made to deform until the resulting internal forces exactly balance the applied external 
forces. For a discussion of the generation of the Euler equations and the relationship between the integral 
and differential forms of the problem see Strsng s text on applied mathematics [18]. The curve and surface 
behavior is best described by the terms of the defining energy functional. These shapes resist stretching 
and bending. The curve tends to minimize ita length and the surface tends to minimize it area. These 
properties were selected to help avoid folding while shrinking a shape. The resistance to bending tends 
to distribute local bending over large regions. The effect of this property is to produce very smooth 
shapes. The combination of these properties builds well behaved geometric primitives suitable for shape 
design. The curve scalar a and ~ vahtes become 2nd order tensors in the surface equation described as 
2x2 matrices. Nonisotropic material behavior can be generated by varying the different vahres of these 
matrices. Adding dynamic terms to the Euler equations introduces time dependent behavior into the system. 
Time dependence allows a user to select between different local minimum solutions and adds realism to 
the interface to further enhance the system s ability to mimic physical behavior. j t~ +p= +Lw = f(w,t) 
6 i) where p is a mass density p is a viscous damping term needed for stability and Lw is short for 
the left hand side of equations 4 or 5 TMs scheme depends on finding a method for solving for shape which 
is interactive and supports a continuous shape representation. For this problem there are two main numerical 
schemes for generating approximate solutions to the actual shape w. These me the ffite difference method 
and the fiite element method. Finite difference solutions begin by approximating the continuous solution 
w as a set of discrete pointa in space. The disadvantage of the approach is that the final solution is 
always stated as a set of pointa in space. The original continuity of the solution haa been lost. 3.b) 
Solving for Deformable Shape The solution scheme for finding w presented here is based on Ritz s finite 
element method and results in continuous deformable geometric curve and surface primitives, or finite 
elements, appropriate for interactive geometric modeling. The Ritz solution method for solving the ShapeWright 
deformable model problem starts with the variational statement of the problem: find the shape w to minimize 
the energy functional in equations 2 and 3. The first step is to approximate the actual solution w by 
Wh a weighted sum of continuous shape functions. 7 W(U,V) = W7U,V) = ~ Xi ~i(U,V) i Comwter Grac)hics, 
Volume 25, Number 4, Julv 1991 The shape functions ~i are fixed in advance and the weights xi are the 
unknowna. This step discretizes the problem since there are always a ftite number of Xi values. The next 
step is to select a class of allowed sculpting functions f. All functions of fiite energy will be used 
such that 8 f(a)2 da c 00 I a This set of functions includes the important point load as well as all 
continuous functions. Having selected the class of functions allowed for the sculpting loads we can determine 
what class of functions need to be considered for the shape functions ~i of the solution. hs~ting the 
Euler equations 4 and 5 we might want to consider all functions that have ftite energy in their 4th derivatives. 
As it turns OULthe ffite element theory shows that this is too stringent a requirement. Since the Ritz 
method uses only the variational statement of the problem, we need only to consider functions that have 
ftite energy in their 2nd order derivatives. This is the set of C1 functions. This is an important attribute 
of the Ritz theory. Although the approximate solution wh is attempting to generate a solution with finite 
energy in its fourth order derivatives it can be generated from functions that have finite energy in 
the 2nd order term. As more ~i functions are usecL the approximation Wh will ~nvmge to the. actual sohttion 
w. This ProFV as significant implications for shape smoothness. Although the ~i shapes need only guarantee 
Cl continuity, the final shape Whwill tend to be C3 continuous. Placing the approximation for shape into 
the original miniium principle yields the matrix minimum principle 9 min(XTKa X-F:X) where the unknowns 
and the shape functions are ordered into vectors as XT= [xl X2... XJ and 0=[Q192... ~ 10 and IG and Fo 
define the stift%ess matrix and forcing vector. These terms are given by   W- =[:J s=[:l Ill all 
m~=~z E= [ alz az f312 1[1 Finding the minimum of equation 9 is equivalent to solving the matrix problem 
 12 The Ritz method becomes the fiite element method when the shape functions are constrained to be zero 
everywhere except in the neighborhood of some node in the surface. The principle advantage of using local 
support shape functions is the ease of matching complicated boundary conditions. These boundary conditions 
include the previously cited requirements that the curves and surfaces must be able to interpolate sets 
of points and maintain specified tangent conditions. The time dependent Euler equation 6 can be rewritten 
using the finite element stiffness matrix as 13 These equations are integrated through time by approximating 
the temporal partials with ffite differences which results in a matrix equation relating the shape at 
time t+At to the shape and sculpting loads at time t (see [2]). Once the unknowns in X are found the 
fiial shape can be generated by using the original parametric representation for shape given in equation 
7. The matrix K ~ is guaranteed to be symmetric and positive defiiite due to the form of the selected 
energy functional. The finite element constraint on the shape functions will make Ka sparse and usually 
banded. These properties reduce the cost of solving equation 12 and help to support interactivity. Both 
the finite difference and the fiite element solutions for shape w result in an approximation found by 
solving a set of algebraic equations. The difference between the two methods is the semantics of the 
unknown variables. In ftite differences the unknowns are a discrete set of points in space. In ftite 
elements the unknowns are a dkrete set of weights used to sum continuous functions to generate a continuous 
description of shape appropriate for the ShapeWright modeling scheme. 3.c) Enforcing Geometric Constraints 
A geometric modeling package needs a general means to enforce geometric constraints. A restricted class 
of geometric constraints, which includes quite a useful number of situations, can be achieved by operating 
on the problems explicit dofs. When the system dofs are chosen with care this scheme can implement quite 
general constraints. In this application this approach will be used to support all the geometric constraints 
listed in the introduction. For the matrix problem AX=G 14 Where A = The system Matrix X = A column 
vector of the dofs G = A column forcing vector any set of linear functions of the problem s dofs is 
expressed as X= DY+DO. 15 Where Y = A vector of unknowns generally smaller than X D=A matrix, generally 
non-square, Do= A column vector. Constraints using equations of this form cart be automatically enforced 
by substituting the constraint ~uations in the system matrix equation and premultiplying by D to yield 
the new set of system matrix equations [DTAD] Y = DTG -DTADO The matrix DTAD retains the symmetry, positive 
definiteness and usually the handedness of the original A matrix. In practice, the most common constraint 
is to fix one of the dis lacement locations at a known location. Generating the J D AD matrix for this 
case becomes very simple. It is just A with one row and one column deleted. For most simple constraints 
the A matrix can be modified without multiplying. 4 DEFORMABLE SURFACE ELEMENT A deformable surface is 
made of a set of connected triangular elements. Triangular elements were chosen so that a large range 
of topological shapes could be modeled. In these transformations comers in the shape of the parametric 
region are mapped to comers in the deformed 3-space object. If a surface is to be modeled with 5 comers 
then the parametric region will need to be a pentagon. Using a triangular ftite element in the parametric 
domain allows any polygonal parametric region to be modeled. 4a) Barycentric Coordinates in 2 Dimensions 
Barycentric coordinates in 2 dimensions are a natural choice for &#38;fming shape functions over a triangular 
domain. Functions written in Barycentric coordinates can be mapped to any shaped triangle simply by changing 
the vertex locations of the mapping triangle. Barycentric coordinates are defined by the mapping shown 
in Figure 2. (U3,V3)  ~ (0,0,1) constant L1 A \ 3,.5) (Ul,vl) (U2,V2)  (1,0,0) (0,1,0) Figure 2) B 
arycentric coordinates in 2 dmensions A point location in the uv plane is given as [u,v] in Cartesian 
coordinates and [Ll ,L2,L3 ] in Barycentric coordinates. The locations [u 1,V 1 ], [u2,v2], and [us ,v3 
] define the vertex locations of the mapping triangle. The Barycentric mapping can always be inverted 
as long as the three mapping vertices are not co-linear. This relationship is where A = area of the mapping 
triangle and Cartesian partial derivatives of Barycentric functions can be found by using the chain rule 
as 18 19 wher( blbl Clcl 2blcl a2­ blc2 ~aL1 2blbZ 2C1C2 2 + ()b2c, aLlaL2 bzbz C2C2 2bzcz Y aL2aL2 
Ji T = b2c3 8 2bzbJ 2czcJ () 2 + b3c2 ;LaL3 aL3aL3bJbs C3C3 2b3c3 7 I [ aL3aLl _ The rmrtial derivatives 
in a direction mrallel or normal @ one of h-e mapping triangle edges can be found by rotating the Cartesian 
first order derivatives as 20 The normal and tangent direction partials can be related dmectly to VL 
by the transformation matrix Trn~ J %jJil. The terms of the Ttn matrix are constant depending only on 
the L matrix. Figure 3 defines the edge angle y and shows how the edge normal is defined so that there 
is always a common definition of the normal direction for an edge shared by two elements. Figure 3) Bsrycentric 
triangle edge tangents and normals 4.b) Triangular Shape Functlorts The triangle shape functions are 
built in two steps. First the weighta of each function are selected to be a physical triangle dof. Each 
of these dofs will have three values, e.g. the location of a triangle vertex haa an [x,y,z] location. 
The second step is to generate shape functions which set the physical dofs independently. This is accomplished 
by defining functions which have a value of 1 for one of the dofs and a value of O for the rest. One 
function is needed for each selected triangle dof. We start with a 9 dof triangle and later expand to 
12 dofs. The dofs selected include the position and the tangent vectors in the u and v directions at 
each triangle vertex as shown in Figure 4. A c)= W,w.,w Figure 4) 3 node, 9 dof triangular element The 
shape functions for the 9 dof triangle as published in Zienkiewicz s text on the Ftite Element Method 
[20] are 21  #=N9a where N9 = @(LI,L2,Ls,L) = [N; N? N?] L1+ L12L2+ LI%3 -L1L22 -L1L32 N?T= C3(L~%2 
+ .5f4L&#38;3) -C2(L12L3 + .5 L1L 2L3) [ -b3(L/L2 + .5 L1L2J-3) + b2(L12L3 + .5 L1L2L3) 1 ~d the fi, 
fij, and eij are &#38;f~ed in figUre 5 The triangle s symmetry in Barycentric coordinates can be used 
to generate the shape functions for the 2nd and 3rd nodes in terms of the first. To generate N? use the 
above equations but addalto eachindex sothatl =>2and2=>3and3=>l. The N?. functions are made by adding 
another 1 to each index. These functions independently set the triangle s 9 dofs as required. However 
they do not guarantee C 1 continuity between adjacent triangular elements. To see thk consider that to 
be C1 across an edge boundary both triangles must generate the same 261 f, = Lt + L&#38;+L&#38; -L&#38;? 
-L1L32 f23 = L22L3+&#38;&#38; fro = L22L3+:IA&#38; ,,e12,, _ LIL22bt l+LI) -( Lt+@-t+b) Figure 5) The 
e and f functions used in the shape functions edge shape and the same partial of shape in the direction 
of the edge normal. These shape functions vary cubically along each triangle edge. Their first partial 
in the edge normal direction varies parabolically. It takes 7 dofs to set the shape and the edge normal 
direction along an edge. The 9 dof triangle has only 6 dofs on an edge and can not set the shape and 
tie normal direction based only on the dof values located on that edge. These shape functions can be 
made C1 continuous by adding a 7th dof on each edge to make the 12 dof triangle in Figure 6. = w, Wn,w 
~ =Wm  is in the normal direction of one of the three edges. Along that edge, the normal derivative 
varies parabolically with a maximum of 1/4 at the edge s center. The 12 dof shape functions can be generated 
by adding the appropriately weighted e functions to set the mid-side normal derivatives to equal the 
values of the mid-side nodal dofs. L w9,(.5,0.s) J The new set of shape functions can be written as 
22 #= N12 ~ defining AT * = [WI W,l W.1 W2W.2W,2W3 W.3 W.3 W.12 W-Wall] This builds a set of shape functions 
that has the required 7 dofs per edge needed to support C1 continuity between adjoining elements, The 
triangle shape varies cubically and the normal derivative varies parabolically along each edge. 4.c) 
Triangular Deformable Surface Element Forcing and Stiffness Matrices Once the dofs ~ and the associated 
shape functions N12 for the triangular element and the mtilmum principle have been selected the actual 
generation of the element stiffness and forcing matrices is just an exercise m algebra and calculus. 
The energy contributed by each element can be calculated as 23 ~. ST(N:m+N: T&#38;N/2) ~N;2&#38;&#38;ldV 
\ ~ And taking the element dofs ; out of the integral since they are constant over the integral domain 
and rewriting yields &#38;=~T&#38;;-2Fd$ 24  with &#38;= NFJiT F JilNi: + NL7Ji EJi Ntf ddf \ q Fai= 
f N12dudv / q The stiffness and forcing matrix integrals are evaluated Figure 6) Triangular element 
with 12 dofs approximately with Gaussian quadrature because the ration~ e functions are too complicated 
to bother evaluating them The e function introduced by Zienkiewicz [20] and shown in analytically. These 
stiffness matrices are built at run time and Figure 5 has the properties that its shape value along all 
three whenever the triangle s [u,v] node values change. The applied edges is zero and that the only non-zero 
shape edge derivative sculpting loads can vary at each iteration of the solution and so the forcing vector 
must be recalculated at each iteration. The terms of each element stiffness matrix are combined into 
a a single system stiffness matrix. The final system stiffness matrix size will be nxn where n is the 
number of dofs for the entire surface. For details on using Gaussian quadrature and for building the 
system matrix see Zienkiewicz s text [20]. 5 DEFORMABLE CURVE ELEMENT In this section the ftite element 
method is applied to the curve equations to develop a deformable curve primitive. The resulting curve 
is piecewise cubic and Cl continuous. The curves were made Cl piecewise cubic so that they could easily 
interface with the surface primitive during a skinning step. Each segment of a deformable character line 
will mau. to one edge of a deformable surface primitive. 5a) Cubic Shape Functions The developed finite 
element curve is shown in Figure 7. It has 4 dofs distributed between two nodes located at the ends of 
the curve segment. The dofs at each node correspond to its position and tangent. W.(h w (o) ( =W, w 
w.(o) Figure 7) 4 dof curve element The curve s shape is the weighted sum of a set of Hermite polynomials 
as 25 The Hermite polynomials and their associated geometric weights are listed below in Figure 8. where 
O< us h = length of element Figure 8) Hermite polynomials Herrnite polynomials are not commonly found 
in CAGD tools. They are notably unstable when the nodal positions and tangents are set directly. These 
stability problems are avoided when energy minimization is used to control the curve s dofs. The Hermite 
polynomials were selected as the shape functions because they explicitly represent the geometric terms 
that will Computer Graphics, Volume 25, Number 4, July 1991 be constrained. This simplifies the implementation, 
increases the understanding of the system, and uses the previously described constraint approach in its 
simplest form. The selection of the shape basis functions is a question of preference and convenience. 
If desired, any piecewise cubic parametric representation could serve as acceptable shape functions for 
the curve ekrnent. 5.b) The Curve Stiffness and Forcing Matrices The stiffness andcurve matrices are 
made by substituting the approximate shape Wh into the energy minimum principle of equation 2. The approximate 
curve equation becomes The stiffitess matrix is found by evaluating this integral as 27 Km =aK, +~Kb 
12 6h-12 6h [ 1 6h 4h2 -6h 2h2 where Kb= ~ h -12 -6h 12 -6h L 6h 2h2 -6h 4h2 J 36 3h-36 3h r 1 3h 
4h2 -3h -h2 ~= L 30h -36 -3h 36 -3h L 3h -h2 -3h 4h2] Calculating the element forcing vector exactly 
for every supported forcing timction requires a unique evaluation of equation 11. To simplify the implementation, 
ali forcing functions are approximated by a linear interpolation between the actual force nodal values. 
The force integral becomes 28 F.= (fo+fi-fO))@du ~o where fo = applied force on nodeo and fl = applied 
force on nodei Taking this integral for cubic Hermite polynomials yields 219 29 3h2h fo FC=..$ 9 21 [1 
fl [1 -2h -3h The element stiffness and forcing matrices are functions of the parametric element length 
h. Each element in a curve can be of a different length so that small elements can be used in regions 
of complicated geometry and large elements used for simple geometry to save on the size of the model. 
263 RESULTS Continuous deformable curves and surfaces were implemented on a Silicon Graphics work station 
under the 4Sight window manager and using the GL graphics library. The graphical primitives can be shaped 
interactively by applying point, slope, and edge geometric constraints and user defined loads and by 
modifying the alpha and beta values. A deformable surface s fairness was evaluated qtridhatively by viewing 
light shaded images annotated with contour lines made by intersecting a family of parallel planes with 
the object. This graphical report was adopted because other surface curvature reports tended to obscure 
the shape of the object. Using the light shaded models with contour lines greatly enhanced the perception 
of shape and deformation. Figure 9 shows two sequences of shapes made by varying a single load parameter 
on a 5 triangle deformable surface. The surface s parametric shape is a pentagon so that the 3 space 
object has five distinct comers. The surface has 28 3-space dofs that are specified by 84 scalar quantities. 
The initial shape of each sequence is made by constraining the 5 comer vertices to be fixed in space 
leaving the rest of the dofs free to move to minimize the energy functional of the total surface. The 
fiist sequence renders 3 of the 5 elements to help visualize the internal shape of the object and shows 
the shape responding to an increase in its resistance to bending along the spine of the bird like object. 
As the ~11 term increases the bird to flattens. The second sequence shows all 5 elements of the shape 
responding to an increasing pressure applied to the bottom of the entire surface. Both cases illustrate 
how a single load parameter can be used to modifi the global shape. Figure 10 shows a car door shape 
built as an exercise in controlled geometry building. The door was made by fiiing the outer edge shapes 
with constraints and using a pressure to generate a nicely convex surface. The rib in the door panel 
was made in two additional steps. First the edges on either side of the rib were constrained in advance 
to isolate the rib deformation from the rest of the door shape. Then the edge running along the center 
of the rib was constrained so that its shape would be fixed but the surface normal along the edge could 
vary. Once the appropriate consbaints were in place the rib was made by moving the constrained central 
edge a fixed distance normal to the surface. The depth of the hinge was modified by the user while the 
algorithm modifkd the model s free dofs to build nice blending surfaces. The final image in Figure 10 
shows the results of a finite element linear stress analysis simulating someone leaning on the door with 
a point load. One exciting potential for this free­form design approach is the possibility for automating 
the transition from shape models to analytic models. Because the shape is defined as the result of a 
ffite element analysis the computer based representation of shape is appropriate for further ftite element 
analysis. The analytic model of Figure 10s central image was made by refbg the grid of the original shape 
and adding material properties and mechanical boundary conditions. The equations for the stress analysis 
were compiled and solved using the same code as the deformable shape models but using a different subroutine 
for generating the element stiffness matrix. Extending the original program for this analysis was done 
by MIT post doctorate Hiroshi Sskurai in one week. The deformable curves were applied to fairing hand 
drawn 3 dimensional curves. Andy Roberts and Dave Stoops created the 3-Draw program at the MIT CADlab 
[15]. The 3-Draw program captures a sequence of discrete point locations while a user draws 3 dimensional 
curves in space using a magnetic detector made by the Polhemus Company. This package has been optimized 
to assist a user in drawing complicated geometric wire frame models. Figure 11 shows the results of fairirtg 
a ewe. The fust curve is shown as originally captured in 3-Draw where the noise in the shape was deliberately 
exaggerated. The first application of fairing is automatic and applied to [he whole curve. This step 
tends to eliiinate high frequency noise from the overall shape. The second phase of faking allows the 
user to artfully smooth out larger scale disturbances in the curve. A . Figure 11) Fairing a curve. 
A. curve as input B: Curve after initial smoothing C: Curve after final smoothing The ShapeWright modeling 
paradigm was tested in an earlier program based on a finite difference implementation of the deformable 
surface Euler equations. The objective of the exercise was to sculpt an object defied by skinning the 
surface of a set of character lines. Figure 12 shows the results of this exercise, a goblet. The initial 
goblet was made by cortstraining a surface to interpolate two circles centered on the z axis. The hyperbolic 
surface shape was due to the efftxt of the cz weighted energy minimization terms which tend to minimize 
the area of the surface. The character line set of the goblet was augmented by adding two squares to 
the middle of the shape. The surface, no longer axis symmetric, automatically defined the complicated 
blending shapes needed to transition from a circle to a square. The final goblet shape was made by sculpting. 
Pressures were applied internally to the goblet bowl until an acceptable looking shape was generated. 
While sculpting the user mo&#38;fied the the magnitude of the pressure and the _lzation algorithm automatically 
updated the dofs of the model. This exercise was run in less than a minute. It took 4 commands to specify 
the character lines and another 3 to parsmeterize the pressure load so that it acts on the upper surface 
of the gobleL There were a total of 204 3-space dofs in this model.  7 CONCLUSIONS AND FUTURE WORK The 
ShapeWright deformable surface modeling paradigm works well for the interactive definition of objects 
with free-form surfaces. Complicated free-form shaps were defined with very few commands. The shapes 
were prmrneterized with the use of loads so that the design of shape was accomplished as a search in 
a small user built parameter space independent of the number of dofs in the surface. Solving the deformable 
model equations using the Ritz ftite element method supports continuous shape models suitable for aesthetic 
design with representations that can support applications like manufacturing and analysis. The range 
of topological structures that could be modeled was greatly extended by using triangular finite elements 
instead of square ones. An additional benefit of using the finite element solution scheme was that these 
models could be exploited to directly generate finite element models for applications liie stress-strain 
analysis. REFERENCES 1. Bloor, M.I.G. and Wilson, M. J., Blend Design as a Boundary-Value Problem , Theory 
and Practice of Geometric Modeling, Wolfgang Staber and Hans-Peter Seidel (Eds.), 1989 2. CeIniker G., 
Gossard D., Energy-Based Models for Free-Form Surface Shape Design , ASME Design Automation Conference, 
Montreal Canada Sep. 1989 3. Celniker G., ShapeWright: Fhite Element Baaed Free-Form Shape Design, M.I.T. 
Ph. D., Dept. of Mechanical Engineering, September, 1990 4. Farin, Gerald and S apidis, Nickolas, Shape 
Representation of Sculpted Objects: the Fairness of Curves and Surfaces , Proceeding of Sea Grant Conference, 
MIT, October, 1988  5 Farin, Gerald, Curves and Surfaces for Computer Aided .. Geometric Design, Academic 
Press Inc., Hmcourt Brace Jovartovich Publishers, Boston, 1988 6. Hagen, H., and Schulze, G., Automatic 
Smoothing with Geometric Surface Patches , Computer Aided Geometric Desig~ Vol. 4, pp. 231-236, 1987 
 7. Kass, Michael and Witkin, Andrew, and Terzopoulos, Demetri, Snakes: Active Contour Models , Intemationaf 
Journal of Computer Vision, 1988 8. Kallay, Michael and Ravani B. , Optimal twist vectors as a tool 
for interpolation a Network of curves with a minimal energy surface , CAGD, 1990 9. Kjellander, J.A., 
Smoothing of bicubic parametric surfaces , Computer-Aided Desig~ Vol. 15, pp. 288­293, 1983 10. Kjellander, 
J.A.P., Smoothing of cubic parametric splines , Computer-Aided DesigL VOI15, No. 3, May, 1983  The curve 
and surface geometric shape primitives were designed to work together to support the ShapeWright paradigm 
for modeling objects with free-form surfaces. The deformable curve s shape was made piece-wise cubic 
so that it would easily fit with the edge of a deformable surface which varies cubically. The curves 
were made to be used to defiie the character lines of an object and the surfaces were made to skin and 
sculpt the final form of that object. What remains as future work is to combine these primitives into 
a single geometric package. The remaining technical issues for this task include automating the skinning 
of a set of character lines and the generation of a reasonable finite element grid appropriate for subsequent 
sculpting. ACKNOWLEDGMENTS The authors gratefully acknowledge the financial support provided for thk 
work by Schlumberger and the Ford Motor Comuanv. ll.= Lot~ N.J. and Pullin, D.I., Methods for fairing 
B-  Spline surfaces , Computer-Aided Design, vol. 20, no. 10, December, 1988 12. Nielson, G. M., Some 
piecewise polynomial alternatives to splines in tension , in Bamhill, RE and Riesenfeld, RF (eds) Computer 
Aided Geometric Design, Academic Press, 1974 13. Nowack~ H. and Reese, D., Design and fairing of ship 
surfaces , in Bamhill R.E. and Boehm, W. (eds), Surfaces in CAGD, North-Holland Amsterdam, pp 121­134, 
1983 14. Prami14 A., Ship Hull Surface design using finite elements , Int. Shipbuild. Prog. Vol. 25 
No. 284, pp. 97-107, 1978 15. Sacks, E., and Stoops, D. and Roberts, A., 3-Draw: A Three Dimensional 
Computer Aided Design Tool , proceedings IEEE international conference of systems, man, and cybernetics, 
pp 1194-1196, November 1989 16. Sapidia, N. and Farin, G., Automatic fairing algorithm for B-spline 
curves , Computer-Aided Design, Vol. 22, No. 2 pp. 121-129, March 1990 17. Schweikert, D. G., An interpolation 
curve using a spline in tension , Journal of Math and Phys. No 45, pp. 312-317, 1966 18. Strang, Gilbe~ 
Introduction to Applied Mathematics, Wellesley-Cambridge Press, Massachusetts, 1986 19. Terzopoulos, 
Demetri and Plat~ John and Barr, Alan and Fleischer, Kurt, Elastic Deformable Models , ACM, Computer 
Graphics, vol. 21, no. 4, July, 1987 20. Ziertkiewicz, The Finite Element Method, third edition, McGraw-Hill 
Book Co., U.K., 1967   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122747</article_id>
		<sort_key>267</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Sculpting]]></title>
		<subtitle><![CDATA[an interactive volumetric modeling technique]]></subtitle>
		<page_from>267</page_from>
		<page_to>274</page_to>
		<doi_number>10.1145/122718.122747</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122747</url>
		<abstract>
			<par><![CDATA[We present a new interactive modeling technique based on the notion of sculpting a solid material. A sculpting tool is controlled by a 3D input device and the material is represented by voxel data; the tool acts by modifying the values in the voxel array, much as a "paint" program's "paintbrush" modifies bitmap values. The voxel data is converted to a polygonal surface using a "marching-cubes" algorithm; since the modifications to the voxel data are local, we accelerate this computation by an incremental algorithm and accelerate the display by using a special data structure for determining which polygons must be redrawn in a particular screen region. We provide a variety of tools: one that cuts away material, one that adds material, a "sandpaper" tool, a "heat gun," etc. The technique provides an intuitive direct interaction, as if the user were working with clay or wax. The models created are free-form and may have complex topology; however, they are not precise, so the technique is appropriate for modeling a boulder or a tooth but not for modeling a crankshaft.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D interaction]]></kw>
			<kw><![CDATA[antialiasing]]></kw>
			<kw><![CDATA[free-form modeling]]></kw>
			<kw><![CDATA[sculpting]]></kw>
			<kw><![CDATA[volumetric data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor>Display algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Interaction styles (e.g., commands, menus, forms, direct manipulation)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P282976</person_id>
				<author_profile_id><![CDATA[81100291883]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tinsley]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Galyean]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Media Laboratory, Massachusetts Institute of Technology, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024462</person_id>
				<author_profile_id><![CDATA[81100166298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Hughes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Department of Computer Science, Box 1910, Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>357310</ref_obj_id>
				<ref_obj_pid>357306</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J.E Blinn. A generalization of algebraic surface drawing. ACM TOG, 1(3):235-256, 1982.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91427</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Bloomenthal and B. Wyvill. Interactive techniques for implicit modeling. Computer Graphics, 24(2):109-116, March 1990.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97900</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Coquillart. Extended free-form deformation: A sculpting tool for 3d geometric modeling. Computer Graphics, 24(4):187-196, August 1990.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Foley, A. van Dam, S. Feiner, and J. Hughes. Computer Graph!cs: Principles and Practice. Addison-Wesley, second edition, 1990.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15921</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P.S. Heckbert. Filtering by repeated integration. Computer Graphics, 20(4):315-321 ,August 1986.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15887</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Van Hook. Real-time shaded nc milling display. Computer Graphics, 20(4): 15-20, August 1986.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W.E. Lorenson and H.E. Cline. Marching cubes: A high resolution 3d surface construction algorithm. Computer Graphics, 21(4):163-169, July 1987.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91451</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Minsky, M. Ouh-young, O. Steele, and E Brooks. Feeling and seeing: Issues in force display. Computer Graphics, 24(2):235-243, March 1990.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>93302</ref_obj_id>
				<ref_obj_pid>93267</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. E Naylor. Sculpt: An interactive solid modeling tool. in Proceedings of Graphics Interface '90, pages 138-148, May 1990.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91434</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Pentland, I. Essa, M. Friendmann, B. Horowitz, and S. Sclaroff. The thingworld modeling system: Virtual sculpting by modal forces. Computer Graphics, 24(2):143-146, March 1990.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Perlin. An image synthesizer. Computer Graphics, 19(3):287-296, July 1985.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15903</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T.W. Sederberg and S.R. Parry. Free-form deformation of solid geometric models. Computer Graphics, 20(4): 151-160, August 1986.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378522</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Terzopoulos and K. Fleischer. Modeling inelastic deformation: Viscoelasticity, plasticity, fracture. Computer Graphics, 22(4):269-278, August 1988.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801144</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. Whitted. Anti-aliased line drawing using brush extrusion. Computer Graphics, 17(3):151-156, July 1983.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91450</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[L. Williams. 3d paint. Computer Graphics, 24(2):225-233, March 1990.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Wyvill and D. Jevans. Table driven polygonization. In SIGGRAPH "90 Course Notes, Modeling and Animation with Implicit Surfaces, pages 7/1-7/6, August 1990.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[B. Wyvill, C. McPheeters, and G. Wyvill. Data structure for soft objects. The Visual Computer, 2(4), 1986.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Sculpting: An Interactive Volumetric Modeling 
Technique* Tinsley A. Galyean The Media Laboratory Massachusetts Institute of Technology Cambridge, MA 
02139 John F. Hughes Department of Computer Science Box 1910 Brown University Providence, RI 02906 ABSTRACT 
 We present a new interactive modeling technique based on the notion of sculpting a solid material. A 
sculpting tool is controlled by a 3D input device and the material is represented by voxel data; the 
tool acts by modifying the values in the voxel array, much as a paint program s paintbrush modifies bitmap 
values. The voxel data is converted to a polygonal surface using a marching­cubes algorithm; since the 
modifications to the voxel data are local, we accelerate this computation by an incremental algorithm 
and accelerate the display by using a special data structure for determining which polygons must be redrawn 
in a particular screen region. We provide a variety of tools: one that cuts away material, one that adds 
material, a sandpaper tool, a heat gun, etc. The technique provides an intuitive direct interaction, 
as if the user were working with clay or wax. The models created are free-form and may have complex topology; 
however, they are not precise, so the technique is appropriate for modeling a boulder or a tooth but 
not for modeling a crankshaft. CR Categories: 1.3.5 [Computer Graphics]: Computational Ge­ometry and 
Object Modeling; Curve, surface, solid, and object rep­resentations; 1.3.3 [Computer Graphics]: Pictureflmage 
Generation; Display algorithms; 1.3.6 [Computer Graphics]: Methodologies and Techniques; Interaction 
techniques. Additional Keywords: Sculpting, volumetric data, 3D interac­tion, antialiasing, free-form 
modeling. lNTRODUCTION We present a new modeling technique for computer graphics based on the notion 
of sculpting a solid material with a tool. This technique is derived from traditional 2D paint systems, 
from Blinn s blobby objects [1], and from the soft objects of Wyvill et al. [17]. The term sculpting 
has been used by others: Naylor [9] uses it to describe a polyhedral CSG system that is capable of interactive 
performance when implemented on a Pixel Machine; Coquillart [3] uses it to describe her interface to 
free-form deformations [12], that edit the geometry of an object but not its topology; Pentland et al. 
[10] use it to describe the altering of shapes by modal forces. In related work, Williams 3D paint system 
[15] lets the user edit the z-depths *This work was supported in part by grants from IBM, NCR, and Sun 
Microsystems. Permission to copy without fee all or par[ of this material is granted provided tha! the 
copies are not madeur distributed for direct commercial advantage, the ACM copyright notice md the title 
of the puhlicatimr and its date appear, and notice is given that copying N by permission of the Association 
for Computing Machinery. To cnpy otherwise, or m republish, requires a fee andlor specific permission. 
of points on an object that is a union of two topological disks, using color as a proxy for height. Bloomenthal 
et al. [2] describe an object by forming a geometric skeleton, associating a potential function with 
it, and drawing isosurfaces of the potential function; editing the skeleton then modifies the surface. 
We prefer to avoid the fixed structure of these last four systems and the potential proliferation of 
polygons of the first, and aim instead for a system that gives the user control of both the geometry 
and topology of an object and at the same time provides an extremely intuitive interface. Our sculpting 
may appear similar to work of Van Hook on milling machines [6], but his system only removes material 
from an object (i.e., no additive tools are allowed), and retains an image of the object but not the 
structure of the object itself. The resulting object cannot be viewed from any direction other than the 
one in which it was constructed. Our fundamental notion is to describe the shape of a piece of clay by 
its charucreristic function, whose value is 1.0 at any point in space where there is clay and 0.0 elsewhere. 
1 Modifying the shape of the clay is therefore equivalent to modifying this function. The same idea applies 
in a traditional 2D paint system: we think of the canvas as the cartesian plane and assign values to 
the pixels of the canvas; certain values indicate the presence of ink and others indicate its absence. 
Painting is done in such systems by moving a brush across the canvas, and data associated with the brush 
edits the data in the pixmap; for example, moving the tip of a pen across the canvas changes the vahtes 
of all pixels underneath it to the current color. Our system modifies the values of volumetric data by 
moving a 3D tool through space, in exact analogy to the brush. Our standard tool is the opposite of the 
pen in a paint system, however, in that we start with a block of material and remove it bit-by-bit, and 
hence we refer to the process as sculpring. Just as traditional paint systems offer many ways to apply 
and remove paint, we provide several different tools with which to edit the volumetric data, including 
ones that add material, smooth a surface, or melt away material as a heat gun melts styrofoam. Many users 
are familiar with paint programs, and therefore readily accept this variety of tools. The models created 
by our technique are free-form and often lack tine detail, but they can have complex topology. They are 
nor precise geometric models of the sort traditionally generated by CAD systems. However the technique 
opens the door to modeling that would otherwise be difficult; it is also well-suited to a free-form design 
process, in which the user starts with no particular goal, and just plays with the material in an intuitive 
fashion. While the underlying idea of our technique is simple and attrac­tive, making it work in practice 
is not trivial, Paint systems have the advantage that they work by modifying the data in a framebuffer 
or an offscreen copy of the screen canvas; this memory is typically easy to read and write, and the image 
can be transferred to the screen 1We represent volumetric functions by giving their values at the vertices 
of a rectangular lattice in 3-space, and call this t oxel dafa, or a \,o,rrrrapfor short. {:)1991 ACM-()-X979 
1-436-8/91/007/0267 $fst175 .   SIGGRAPH 91 Las Veqas, 28 JuIv-2 August 1991 EE s1661APu$l ­ extremely 
quickly with most current hardware. This is partly be­cause we always look at a 2D painting from the 
same point of view. By contrast, we may wish to view volumetric data from any angle. Also, since we actually 
want to see the boundary between the mate­rial and the empty space, this boundary must be computed by 
some thresholding algorithm. The computation of an isosurface from the volumetric data is O(rt3), using 
the marching-cubes algorithm [7], for an n x n x n data array. Clearly, for interactivity, we must improve 
the algorithm. Fortunate y, sculpting the data modifies it only locally, so one need not recompute an 
entire isosurface. Of course, the isosurface for such data may contain many polygons, and even if we 
recompute only the local data and replace some polygons with others, we must find a way to redisplay 
only the local area or the process becomes polygon bound. Even with only local updates, over 509 of the 
time is spent rendering polygons on an HP835 Turbo SRX. Simply sampling the characteristic function of 
a solid will lead to aliasing, We avoid this by using a low-pass filtered version of the characteristic 
function. This means that certain samples may be neither 1.0 nor 0.0, but rather some intermediate value, 
indicating transition from material to empty space. To avoid the introduction of aliases, the values 
written by the tool must also be band-limited, as discussed in Section 3.1. Before giving a detailed 
explanation of the technique and the associated algorithms, we make two important remarks: 1. The success 
of the program is greatly enhanced by the use of 3D interaction devices. We use the Polhemus lsotrack 
device, and have begun to experiment with the Ascension Bird and a 3D force-feedback joystick with good 
results [8]. 2. User response indicates that this method of modeling has sub­stantial initial appeal 
and is extremely easy to learn. -Although we have not performed any perceptual stuches on the system, 
we have found that many users of the system say one of two things: Can I come back and use this again 
later? or, fmm  the more experienced users, This is what I ~hought that 3D modeling would be like when 
I first started learning about computers. The remainder of this paper describes the modeling technique 
at two levels: the user s view of the system and the internal imple­mentation. We include throughout 
ideas for future work. While the system is a full-fledged modeling system, we view it as comparable to 
early painting programs like MacPainC the future work is what will make it more like the painting programs 
of today. 2 THE USER S VIEW In calIing our modeling technique sculpting, we hope to connote a very free-form 
interaction; a sculptor can carve away bits of material, stick on new pieces of clay, change the topology 
of a sculpture, etc. (A sculptor using physical clay can also squeeze or flex the clay; our system does 
not yet provide this functionality.) To present this free-fosm modeling technique, we provide the user 
with a cubical lump of clay (called the objecr) and a small tool. The tool, displayed as a sphere or 
cube, is directly controlled by a 3D interaction device such as the Polhemus Isotrack. In a separate 
window, the user has a traditional user interface, consisting of menus for file management and buttons 
for selecting how the tool shotdd act on the object and for resetting the system. Interaction with this 
part of the interface is done with a mouse and keyboard. A typical session begins with the default (a 
cube of clay) or with the selection of a previous sculpture, and continues as the user holds the Polhemus 
device and sculpts away material. When the user wishes to change the effect of the tool, she uses the 
mouse to select a new tool type (see Figure 1). 268 2.1 Types of Tools The tool, in its simplest form, 
is analogous to the eraser pmvided in many paint programs: wherever the tool moves, it cuts away the 
object. In 3D terms, the tool acts like a milling head or a muter, but unlike these, the tool leaves 
no chips. We call this a routing tool or subtractive tool. The analogy between the subtractive tool and 
a paint program s eraser is of considerable value. Most users are familiar with 2D paint programs, and 
are used to the notion that the mouse can have different effects. This makes it simple to give the user 
a variety of sculpting tools and to invent new types of tools. Here are the tools we have implemented: 
Additive Tool or Toorhpas/e Tube. This tool leaves a trail of material wherever it moves, much like a 
tube of toothpaste that is squeezed as it is moved. Heat Gun. This tool melts away material much as a 
heat gun melts styrofoam. If held in one place for a while, it removes all the material, like the muting 
tool; if moved quickly pasta region, it melts the material there slightly. Sandpaper. This smoothing 
tool alters the object by wearing away the ridges and filling the valleys. (This is analogous to the 
low-pass filter brushes available in some sophisticated 2D paint systems.) Other possible tools include 
a filleting tool, to smooth the joins between adjacent surfaces, and geometric construction tools, which 
would allow the user to create a cylindrical tube between two points, or create a torus with a certain 
center and radii, much the way that painting programs allow one to draw straight lines and circles. We 
also envision adding tools for deforming the object as a clay model, squeezing or bending it, as described 
in [13]. We have also implemented a primitive color tool, which assigns a chosen RGB color triple to 
each vertex of the data array that lies within the current tool region. We currently apply a low-pass 
filter to these assigned color values to create a smoother appearance. There is much more work to be 
done in this area.  2.2 Interaction 2.2.1 Low and high resolution modes To make a good sculpture the 
user must be allowed to view it from different perspectives and work on the back as well as the front. 
Furthermore, it is often desirable to rough out the coarse shape of a sculpture first, and work on finer 
detail afterwards. Making this coarse sculpting efficient requires a larger tool for the initial shaping. 
Thus we provide both low-resolution (Iow-res) and high-resolution (hi-res) modes. In Iow-res mode, we 
provide full control of the view and all tool functions, but with coarse tools. In hi-res mode, view 
control is unavailable, but much greater resolution is provided. In Iow-res mode, the object is displayed 
by applying the marching cubes algorithm to a subsample of the data that represents the object. In hi-res 
mode we use a 30 x 30 x 30 voxel array; in low-res mode the array is 10 x 10 x 10. The visual effect 
is that the Iow-res view of an object is very coarse and shows only its general fomt. Of course, subsampling 
is not ideal because of the aliasing implicit in the process: small details may disappear completely. 
The correct approach is to filter the large voxel array into the smaller array; we will do this in the 
future, but have not found it to be a significant problem in the current implementation. In low-s-es 
mode, the 10 x 10 x 10 array might give rise to an object with as many as 5000 polygons (five polygons 
from each cube in the array). This would be extremely unusual, and 500 polygons is more likely. On the 
HP835 Turbo SRX, 5000 polygons can be displayed with a refresh rate of 7 per second, allowing the user 
to rotate the view of the low-res representation of the object in real time. The conversion from low-res 
to hi-res mode requires a substan­tial computation, since the full marching-cubes algorithm must be 
    : SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 Figure 3: Low-res model of a tree: 1138 polygons 
Figure 6: Teapot, chiseled from stone: 9244 polygons Figure 7: Teapot, after application of sanding tool: 
8374 polygons Figure 5: The thinker: only 2118 polygons! Figure 8: Sculpture made with dial box control 
 SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 surface sh Figure 11: With a 0/1 tool, the surface of 
the object jumps as the tool approaches. This figure shows the analogous behavior in 2D: the gray square 
is the tool and the solid black line is the isocurve. by a voxmap filled with 0s, and that the act of 
cutting away material would consist of copying data values from the tool voxmap to the object voxmap. 
This is, however, only approximately correct. Values in the tool voxmap m-e combined with those in the 
object map; the combination roles are described in Section 3.2.1. But the actual values in the tool voxmap 
are not as simple as they might seem. If values of O are copied directly from the tool voxmap to the 
object voxmap, the results are jumpy. As the tool moves towards the object, nothing happens for a while; 
then, when it is sufficiently close, the object voxmap values change all at once, and the surface of 
the object moves rapidly. This is a consequence of the low sampling rate used to represent the characteristic 
function of the object (see Figure 11 for the analogous behavior in a 2D system). We compensate for this 
with two tricks based on the notion of antialiased brushes [14]. First, we create a voxmap for the tool 
that is sampled at a higher rate than is the object (four times as many samples in each direction). The 
tool voxmap, for a spherical subtractive tool, is filled with 0s on the inside of a sphere, and Is elsewhere, 
i.e., with the characteristic function of the sphere. We then remove most of the high-frequency components 
of this voxmap by filtering it twice with a 2 x 2 x 2 box filter [5]: Second, we apply the tool to the 
object voxmap by determining its sub-voxel location and then selecting particular values from the tool 
voxmap to combine with the object voxel values. The details are presented in the following section. 
 3.2 Tool-Object Interaction The central loop of the program is essentially 1. Poll repeatedly until 
the tool has an effect.4 2. Modify values in the object voxmap. 3. Recompute isosurface. 4. Redisplay 
isosurface and tool. 5. Return to step 1.  We will describe these steps in ordec step 2 in the following 
subsection, and steps 3 and 4 in Section 3.3. 3,2.1 Applying the tool to the object voxmap Points in 
the voxmap are identified by three indices, so that a typical voxel value is referenced as v[i][j][k], 
where each of i, j, and k is an integer between O and 29. We can think of any point in the object region 
as having ijk-coordinates: a point whose coordinates are (i, j, k) = (1.5,2, 2) is on the line segment 
between the points represented by the voxels v[1][2][2] and v[2][2][2]. We compute the ijk-coordinates 
of the tool s location, and then round 30ur choice of this filter size and number of iterations was determined 
by experimentation. qFor most tools, this means until the tool has moved. e melting tool, however, has 
an effect at every instant. 272  ttt--Y- Figure 12: The 2D paintbrush location is determined to a finer 
resolution than that of the canvas. Values that correspond to pixel centers are actually used in applying 
the brush to the canvas. each coordinate to the neamt 1/4. We then imagine the tool s voxmap as superimposed 
on the object voxmap at that position; l/64th of the tool s voxel locations correspond exactly to the 
object voxel locations, and it is this subsample of the tool s voxmap that is combined with the object 
voxmap. Figure 12 shows the analogous situation in 2D. How are object voxel values and tool voxel values 
combined? We use the rnin operator on each voxel: OBJECT -min(OBJECT, TOOL); this prevents the 1s in 
the tool s voxmap from depositing material in empty space. The additive tool is created by filtering 
a sphere full of 1s (with 0s outside), and applied by using the max operator. lMo other tools use this 
tool data as well. The heat gun is applied by the rule OBJECT t max(O, OBJECT TOOL), and the building 
tool, which gradually pastes new material on in the same way that the heat gun removes it, is applied 
by the rule OBJECT + min( 1, OBJECT + TOOL). The sandpaper tool is anomalous, in that it has no associated 
data. It is applied as follows: each voxmap value within the tool s extent is replaced by a weighted 
average of its current value and those of its six adjacent voxels. The central voxel is given a weight 
between 4 and 24, and the adjacent voxels are given weight 1. The user then adjusts the rate of sanding 
by varying the weight of the central voxel. The tool voxel data and the object voxel data armys must 
both have the same axes in this model. We would like to add other tools in the future, and allow the 
tool orientation to be controlled by the orientation of the Polhemus pointeu however, this requires resampling 
the tool voxel data to get a rotated sample, and at present this is not feasible at a reasonable refresh 
rate. 3.3 Regenerating the Isosurface When the tool voxmap is applied to the object voxmap, the object 
data is modified only in a small region. Thus we need not recompute the entire level 0.5 isosurface 
only cestain polygons change, namely those that arose from cubes the values of whose vertices have been 
modified. Since we know exactly which vertices these are, we can readily compute the new polygons to 
be displayed. We call this the incremental marching-cubes algorithm. To redisplay the isosurface, we 
wish to dkplay the newly com­ puted polygons and remove the polygons formerly associated with the modified 
regions. The removal of these defunct polygons might @ @ Computer Graphics, Volume 25, Number 4, July 
1991 screen T< T= ,;*  -+4Q update Figure 13: When the square tool cuts away material, polygons that 
were formerly obscured may be revealed, as shown in the right hand case. expose certain other polygons. 
These obscured polygons are no longer in the z-buffer, having been overwritten by the now-defunct polygons, 
so we must redisplay the formerly obscured polygons too (see Figure 13 for a 2D slice of this situation). 
To facilitate this, we use a data stmcture we call a ha.shgrid. The hashgnd makes it easy to determine 
which cubes in the object voxel army contribute polygons to a specific screen region. We divide the screen 
into a grid of squares, which we call cc//s, and associate a bucket (implemented as a linked list) to 
each. Whenever a cube that contributes polygons has a screen projection overlapping a cell, that cube 
is added to the cell s bucket. Once this array of cells, the hashgrid. has been computed, it is easy 
to determine which cubes polygons must be redrawn to update a region of the screen. To make the hashgnd 
efticient, we make two requirements: ( I ) a hashgnd cell must be at least as large as the projection 
of any cube to the screen: (2) a hashgrid cell must be at least as large as the largest screen extent 
of [he projection of the tool from any point in the sculpting space. Since our tools are always at least 
as large as a single cube. it suffices to satisfy the second condition. We compute the bounding rectangle 
of this maximum-size tool projection analytically. This is possible because the tool is con­strained 
to lie in the sculpting space and the camera s field of view is fixed. We also compute the bounding rectangle 
for the projection of the entire sculpting-space cube. The larger dimension of the first rectangle is 
what we choose for the size of each cell edge in the hashgrid; the larger dimension of the second rectangle, 
divided by this cell edge length, determines the size of the array of cells. We initialize the hashgrid 
during the marching-cubes algorithm. Each cube in the voxmap is examined to see whether it contributes 
polygons to the object: if so, it is flagged (the confribwion flag of the cube is set), we determine 
which cells the cube s projection overlaps, and add the cube to the bucket for each such cell. To determine 
which cells a cube hits, we project the eight ver­tices of the cube. and note which cells these projected 
vertices lie in (because of the tirst requirement on the size of grid cells, the projected vetiices can 
lie in at most four different cells). Then, if the projected vertices lie in exactly three cells, we 
add a fourth cell to the list. as shown in Figure 14. which indicates why we must do this: it is possible 
for the screen extent of a cube s projection to intersect a cell in which no projected vertex lies. This 
L-.shupF ~JnwmJ/ywill arise again when we discuss the effect of tool motion. The obvious way to project 
the vertices of a cube to the screen is 10 take the coordinates of each vertex, multiply them by the 
current (4 x 4) transfommtion matrix. and then project to screen space via the perspective projection 
transformation. Both of these operations we linear functions. except for the homogeneous division in 
the perspective transformation. We use this linearity as follows: We project the comers of the entire 
object voxmap to homogeneous coordinates (just before the perspective divide ),and use the resulting 
coordinates to infer the locations of each small cube s comers in this space via linear interpolation. 
We then perform the homogeneous division; this interpolated computation of the projected vertices reduces 
the per-cube computation of associated hashgrid cells from 128 multiplies. 96 additions. and 16 divisions 
(the cost of the two Figure 14: A projected cube may intersect four grid cells even though the projected 
vertices lie in only three cells. Because of this, we always add the cube to the bucket of the fourth 
cell. matrix multiplies and the perspective divide of the naive approach) to just 9 multiplies, 30 additions, 
and 16 divisions. To update the hashgrid when the tool is moved, each cube in the voxmap whose vertices 
have been modified by the tool is examined. If the cube s contribution flag is not set but the cube now 
contributes polygons, the flag is set and the cube is added to the hashgrid data structure. If the cube 
s contribution flag is set but the cube no longer contributes polygons, the flag is cleared and the cube 
is removed from the hashgnd. The display is updated by determining which cells in the hashgrid might 
have been affected by the tool. By the second condition on hashgrid cell size, the screen projection 
of the tool intersects at most four cells. As btfore, in the event of an L-shape anomaly, the fourth 
cell is added to the list of affected cells. This cell list is merged with the list of cells associated 
with the previous tool position (these two lists often overlap, especially when the tool is being moved 
slowly). The screen area and z-buffer area associated with these cells are cleared. Then, for each cube 
in the bucket of each grid cell on the list, the polygons are regenerated and drawn. (We regenerate the 
polygons to save the prohibitively large space required to store them). When we alter our view of the 
object, the hashgrid must be recomputed. Rather than recompute it from scratch, we use the old hashgnd 
to compute the new one. By examining only those cubes that appear in some bucket in the old hashgrid, 
we avoid performing marching-cubes computations on those parts of the object voxmap that will not contribute 
polygons. The process for creating the new hashgnd is therefore: ( 1) for each cell of the old hashgrid, 
look at the cubes in its bucket; (2) for each such cube, check a flag (the ulreudy-processed flag); if 
it is not set, set it, perform the marching-cubes algorithm on that cube, and inserl the cube into the 
new hashgrid; (3) once the whole old hashgrid has been processed, clear the already-processed flags on 
all cubes. Using the already­processed flag is necessary because a single cube is likely to be in the 
buckets of more than one hashgrid cell (but no more than four).  4 FUTURE WORK We have many plans for 
future work in extending this modeling paradigm. We are in the process of improving the color editing 
in the system, and look forward to adding patterning or even solid textures like those described in [1I]. 
We would like to develop a voxmap with so many cubes that the screen projection of a typical cube is 
about the size of a screen pixel. This actually simplifies some of . .SIGGRAPH 91 Las Vegas, 28 July-2 
August 1991 El: !ls614rn!l ­ the algorithms (polygon rendering in the display device is no longer needed, 
for example); unfortunately, the memory requirements are still prohibitive. We are eager to experiment 
further with force feedback, as we feel that this will provide an extremely intuitive user interface. 
We want to add tools that have orientation, so that we can use the full range of data from the Polhemus 
device. We want to add various high-level operations on the sculpture such as scaling, translation, cutting, 
copying, and pasting regions of the sculpture, reflecting and rotating portions of the sculpture; in 
general, we would like to make available as many as possible of the other operations available in traditional 
paint programs. We would like to add hierarchy to the system, so that in regions where more detail is 
needed, we could locally increase the resolution of the voxel lattice. Finally, we want to gain experience 
with a wide selection of users so that we know better how to make sculpting a natural inclusion in the 
standard repertoire of modeling techniques. This should include further study of the user interface and 
its ease of use; our current experience involves no rigorous perceptual studies, and we feel that these 
may considerably enhance the interface. 5 ACKNOWLEDGMENTS Much of this work was done by the first author 
as his Master s project under the direction of the second author. We appreciate the support of the Brown 
Computer Graphics Group, in particular Bob Zeleznik and Dan Robbins, and of the MIT Media Lab, especially 
the Computer Graphics and Animation Group.The author first  thanks Shen Galyean for her support and 
encouragement. References [1] J.F. Blinn. A generalization of algebraic surface drawing. ACM TOG, 1(3):235 
256, 1982. [2] J. Bloomenthal and B. Wyvill. Interactive techniques for im­plicit modeling. Compurer 
Graphics, 24(2) :109-1 16, March 1990. [3] S. Coquillart. Extended free-form deformation: A sculpt­ing 
tool for 3d geometric modeling. Computer Graphics, 24(4): 187-196, August 1990. [4] J. Foley, A. van 
Dam, S. Feiner, and J. Hughes. Computer Graphics: Principles and Practice. Addison-Wesley, second edition, 
1990. [5] P.S. Heckbert. Filtering by repeated integration. Computer Graphics, 20(4):3 15 321, August 
1986. [6] T. Van Hook. Real-time shaded nc milling display. Compurer Graphics, 20(4): 15-20, August 1986. 
[7] W.E. Lorenson and H.E. Cline. Marching cubes: A high reso­lution 3d surface construction algorithm. 
Compurer Graphics, 2 1(4): 163 169, July 1987. [8] M. Minsky, M. Ouh-young, O. Steele, and F. Brooks. 
Feel­ing and seeing: Issues in force display. Computer Graphics, 24(2):235-243, March 1990. [9] B. F. 
Naylor. Sculpti An interactive solid modeling tool. In Proceedings of Graphics Inte#ace 90, pages 138 
148, May 1990. [10]A. Pentland, 1. Essa, M. Friendmann, B. Horowitz, and S. Sclamff. The thingworld modeling 
system: Virtual sculpt­ing by modal forces. Computer Graphics, 24(2): 143 1 46, March 1990. [11]K. Perlin. 
An image synthesizer, Computer Graphics, 19(3):287-296, July 1985. [12] T.W. Sederberg and S.R. Parry. 
Free-form deformation of solid geometric models. Compufer Graphics, 20(4):151 160, August 1986. 274 [13] 
D. Teszopoulos and K. Fleischer. Modeling inelastic deforma­tion: Vkcoelasticity, plasticity, fracture. 
Compu~er Graphics, 22(4):269-278, August 1988. [14] T. Whhted. Anti-aliased line drawing using brush 
extrusion. Compurer Graphics, 17(3):151 156, July 1983. [15] L. WNiams. 3d paint. Computer Graphics, 
24(2):225 233, March 1990. [16] B. Wyvill and D. Jevans. Table driven polygonization. In SIGGRAPH 90 
Course Notes, Modeling and Animation with Implicit Surfaces, pages 7/ 1 7/6, August 1990. [17] B. Wyvill, 
C. McPheeters, and G. Wyvill. Data structure for soft objects. The Visual Computer, 2(4), 1986.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122758</article_id>
		<sort_key>275</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A coherent projection approach for direct volume rendering]]></title>
		<page_from>275</page_from>
		<page_to>284</page_to>
		<doi_number>10.1145/122718.122758</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122758</url>
		<abstract>
			<par><![CDATA[Direct volume rendering offers the opportunity to visualize all of a three-dimensional sample volume in one image. However, processing such images can be very expensive and good quality high-resolution images are far from interactive. Projection approaches to direct volume rendering process the volume region by region as opposed to ray-casting methods that process it ray by ray. Projection approaches have generated interest because they use coherence to provide greater speed than ray casting and generate the image in a layered, informative fashion. This paper discusses two topics: First, it introduces a projection approach for directly rendering rectilinear, parallel-projected sample volumes that takes advantage of coherence across cells and the identical shape of their projection. Second, it considers the repercussions of various methods of integration in depth and interpolation across the scan plane. Some of these methods take advantage of Gouraud-shading hardware, with advantages in speed but potential disadvantages in image quality.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43135087</person_id>
				<author_profile_id><![CDATA[81341498533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wilhelms]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer and Information Sciences, University of California, Santa Cruz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31039547</person_id>
				<author_profile_id><![CDATA[81100376420]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Allen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Van Gelder]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer and Information Sciences, University of California, Santa Cruz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>801255</ref_obj_id>
				<ref_obj_pid>965145</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jim F. Blinn. Light reflection functions for simulation for clouds and dusty surfaces. Computer Graphics, 16(3), July 1982.]]></ref_text>
				<ref_id>Bli82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378484</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Robert A. Drebin, Loren Carpenter, and Pat Hanrahan. Volume rendering. Computer Graphics, 22(4):65-74, July 1988.]]></ref_text>
				<ref_id>DCH88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Gouraud. Continuous shading of curved surfaces. IEEE Transactions on Computer, 20(6):623-628, 1971.]]></ref_text>
				<ref_id>Gou71</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808594</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[James T. Kajiya and B. P. Von Herzen. Ray tracing volume densities. Computer Graphics, 18(4):165-174, July 1984.]]></ref_text>
				<ref_id>KH84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44652</ref_obj_id>
				<ref_obj_pid>44650</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Marc Levoy. Display of surfaces from volume data. IEEE Computer Graphics and Applications, 8(3):29-37, March 1988.]]></ref_text>
				<ref_id>Lev88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[William E. Lorensen and Harvey E. Cline. Marching cubes: A high resolution 3D surface construction algorithm. Computer Graphics, 21(4):163- 169, July 1987.]]></ref_text>
				<ref_id>LC87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5515</ref_obj_id>
				<ref_obj_pid>5513</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Nelson Max. Light diffusion through clouds and haze. Computer Vision, Graphics, and Image Processing, 33:280-292, 1986.]]></ref_text>
				<ref_id>Max86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99315</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Nelson Max, Pat flanrahan, and Roger Crawfis. Area and volume coherence for efficient visualization of 3d scalar functions. Computer Graphics, 24(5):27-33, December 1990.]]></ref_text>
				<ref_id>MHC90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Thomas Porter and Tom Duff. Compositing digital images. Computer Graphics, 18(3):253- 260, July 1984.]]></ref_text>
				<ref_id>PD84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378476</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Paolo Sabella. A rendering algorithm for visualizing 3D scalar fields. Computer Graphics, 22(4):51-58, July 1988.]]></ref_text>
				<ref_id>Sab88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99322</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley and Allan Tuchman. A polygonal approximation to direct scalar volume rendering. Computer Graphics, 24(5):63-70, December 1990.]]></ref_text>
				<ref_id>ST90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Craig Upson and Michael Keeler. The v-buffer: Visible volume rendering. Computer Graphics, 22(4):59-64, July 1988.]]></ref_text>
				<ref_id>UK88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97919</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lee Westover. Footprint evaluation for volume rendering. Computer Graphics, 24(4):367-76, August 1990.]]></ref_text>
				<ref_id>Wes90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99318</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms, Judy Challinger,, Naim Alper, Shankar Ramamoorthy, and Arsi Vaziri. Direct volume rendering of curvilinear volumes. Computer Graphics, 24(5), December 1990.]]></ref_text>
				<ref_id>WC+90</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Coherent Projection Approach for Direct Volume Rendering Jane Wilhelms and Allen Van Gelder Computer 
and Information Sciences University of California, Santa Cruz 95064 Abstract Direct volume rendering 
offers the opportunity to visualize all of a three-dimensional sample volume in one image. However, processing 
such images can be very expensive and good quality high-resolution images are far from interactive. Projection 
approaches to direct volume rendering process the volume region by region as opposed to ray-casting methods 
that process it ray by ray. Projection approaches have generated interest because they use coherence 
to provide greater speed than ray casting and generate the image in a layered, informative fashion. This 
paper discuwes two topics: First, it introduces a projection approach for directly rendering rectilinear, 
parallel-projected sample volumes that takes advantage of coherence across cells and the identical shape 
of their projection. Second, it considers the repercussions of various methods of integration in depth 
and interpolation across the scan plane. Some of these methods take advantage of Gouraud-shading hardware, 
with advantages in speed but potential disadvantages in image quality. Introduction The two main approaches 
for rendering three-dimensional scalar sample volumes are extraction of isosurfaces [LC87] and direct 
volume rendering [DCH88, Lev88, Sab88, UK88, Wes90, MHC90, ST90]. While extraction of isosurfaces produces 
clearcut delineation of features, the bhrary decision made about the location of surfaces means that 
only a limited amount of the total information contained in the volume can be presented in one image. 
Direct volume rendering can use semi-transparency to visualize much more of the volume contents, and 
all cells become capable of Permission to copy without fee all m part of this material is granted provided 
that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice 
md the title nf the publication md its date app-sar,md notice is given that copying is by permission 
of the Association for Computing Machinery. To copy otherwise. nr In republish. requires a fee and/or 
ipecific permission. contributing to the image. The use of independent transfer functions to map the 
volume s original scalar values to color and opacity makes it possible to combhre continuous variations 
with feature extraction in a very flexible fashion. Because the amount of information presented in one 
directly rendered image and its sometimes blurry appearance can make it difficult to fully understand, 
the ability to view the volume interactively from various positions is of considerable importance. Unfortunately, 
direct volume rendering is very expensive and most animations depend upon precalculated images which 
are replayed as film loops. Techniques that do provide fast rendering tend to do so at the expense of 
image quality. This paper presents an approach to direct volume ren­ dering using projection of individual 
volume cells [DCH88, UK88, Wes90]. Processing is cell by cell, not pixel by pixel as in the alternative 
ray-casting approach [Lev88, Sab88, UK88]. Pro~ction seems in many ways preferable to ray casting. It 
can take advantage of coherence when a cell projects onto many neighboring pixels. It can avoid some 
of the aliasing inherent in point-sampling approaches. It can process the image plane by plane, so that 
if the total rendering time is considerable, the viewer can gain useful information during the rendering 
process by watching the image being created. This is particularly useful if the image is drawn back to 
front, because regions of the image that might be obscured later are all visible at some point during 
rendering. It has been suggested that projection is more amenable to parallel processing [U K88]. The 
coherent pro~ction approach presented here takes advantage of the regularity of rectilinear volumes in 
two ways. First, the projection of each cell is an exact but translated geometrical copy of every other 
cell, so an analysis of the geometry of a single cell can be used to hasten processing of every other 
cell. This assumes parallel projection, though perspective projection is possible if cells are individually 
projected at some extra cost. Second, a cell projects as one to seven polygons. The intensity and opacity 
values of the pixels involved can be found by interpolating (in one of several ways) between their vertices. 
 ACM-O-lW791$0075 -436-S/91/007/0275 Several methods are presented for calculating cumulative intensity 
and opacity by integration in depth and interpola­tion across the scan plane. They are investigated in 
terms of their speed and image quality.  2 Coherent Projection Algorithm A cell refers to the rectilinear 
region bounded by eight neighboring sample points, the ceU corners. Cells are modeled as containing a 
semi-transparent material that both emits light and occludes it in amounts dependent upon the scalar 
data values of the cell corners and their mapping to intensity (red, green, and blue) and opacity values 
using transfer functions. The coherent projection method depends upon three observations concerning the 
parallel projection of rectilinear cells. (For simplicity, cells are assumed to be identical in size. 
The algorithm also works for hierarchical volumes where cells are uniformly scaled versions of each other 
~~ 90].) 1. The pro~ction of each of these cells is geometrically a translated copy of the projection 
of any one cell. 2. From any eyepoint, a generic cell can be simplified into at most seven subcells 
with the same front and back face. 3. The projection of these subcells is either a triangular or a quadrilateral 
projected polygon.  The first step of coherent projection is to determine an appropriate template for 
the particular shape and orientation of the cells making up the volume (Section 2.1). The volume is then 
traversed, relying on the template for geometry, but takhg into account the unique data values of each 
cell (Section 2.2). For each cell, intensity and opacity values for the subcell vertices are determined 
(Section 2.3), and then intensity and opacity values of the pixels that the subcells project onto are 
determined using interpolation (Section 2.4). These pixels are composite with the accumulating image 
in the frame buffer (Section 2.5). 2.1 Determining the Generic Cell Type Depending upon orientation, 
one, two, or three faces will form the front of the rectilinear cell (Figure 1). If the projection of 
the cell is divided into regions having the same front and back face, up to seven subcells result from 
each cell. (Use of coherence in regions with the same front and back cell faces has also been investigated 
elsewhere [UK88, MHC90, ST90].) Subcells are polyhedra whose front and back faces project to the same 
screen location and form projected polygons. Thus, each projected polygon vertex can be thought of as 
a vertez pair, consisting of a front vertex and a back vertex which may have no distance between them 
along silhouette edges. Some subcell vertices are original cell corners. Others are intersection points 
that must be calculated. The distance from front to back between the One Face Two Faces Three Faces 
Figure 1: Cell Projections vertex pairs is the same for all pairs with a non-zero distance, and can 
be precalculated. When only one face is visible (see Figure 1), there is only one pro jetted quadrilateral 
polygon, and its vertices are projections of original cell corners. When two faces are visible (e.g., 
front and left), two or three quadrilateral projected polygons face the front. Two corners of the original 
cell are nearest the front, and two are farthest away. If the two farthest vertices project exactly onto 
the two nearest, no new intersection points are needed and two projected polygons result. Otherwise, 
a face is split and four new intersection points located on cell edges must be found. In this case three 
pro~cted polygons result. If three faces are visible, six or seven polygons are needed to represent the 
cell. There are seven possible subcases, determined by the location of the farthest cell corner relative 
to the nearest. If the farthest cell corner projects onto a face (three cases), four new edge intersections 
and two new face intersections must be calculated. If the farthest cell corner pro jects onto a line 
(three cases), only two new edge intersections are needed. If the farthest cell corner projects onto 
the nearest, no new intersections are needed. In this implementation, a table was generated to specify 
each of these cases, assuming they represent front, front-left, and front-left-bottom faces. All other 
cases are mapped to these. The table describes which edges and faces contain intersections, which ceU 
corners and intersection points form vertex pairs, and which front vertices form polygons. Once a generic 
cell type is determined the table is used to find appropriate properties from one particular generic 
cell. These values are stored and reused for all other cells. 2.2 lkaversal of the Volume The algorithm 
works either by traversing the volume back to front, or front to back. There are advantages to both traversals, 
Back-to-front traversal avoids the need for an opacity buffer to store accumulated opacity values. Furthermore, 
this traversal shows each layer of the image in front of the last, so all cells at some time appear in 
front. If the traversal is front to back, an opacity buffer is needed. A potential advantage of front-to-back 
rendering is that rendering can be bypassed for the new cells that lie behind fully opaque cells. This 
requires a suitable saving strategy, which is being investigated. Because of the regularity of the volume, 
an appropriate traversal order can be determined from its orientation. (The transformation matrix can 
provide this.) More than one traversal order is possible. For example, if only the front face is visible, 
the traversaI can be XYZ, YXZ, XYZ, etc. The current implementation traverses the volume in the order 
that accesses the data most efficiently: if X varies fastest, an XYZ traversal is used when possible. 
This means that sometimes the slice whose projection covers the smallest area is projected, making the 
image less understandable as it is developing. A more visually appealing alternative would be to project 
the slice with the largest pro~cted area first. 2.3 Integration in Depth Each cell is assumed to consist 
of a semi-transparent material which emits its own light, transmits some light coming from behind, and 
occludes some light both from behind and from within the cell. Such a model is related to previous work 
in computer graphics for modeling semi-transparent media [Bli82, KH84, Max86, Sab88]. Luminosity and 
occlusion are represented as intensity and opacity. To create the image, the scalar values from the original 
data are converted to intensity and opacity values using transfer functions stored in red, green, blue, 
and opacity tables. Estimated data values for edge intersections are found by linear interpolation between 
adjacent corner ver­tices, and for face intersections by bilinear interpolation of face vertices; these 
values are then used for mapping. The cumulative intensity and opacity contribution of the medium between 
the front and back cell face must be determined. This process will be referred to as integmtion in depth, 
and involves solving (approximately) a linear differential equation. The discussion that follows is general 
and is applicable to any method that seeks the intensity and opacity contribution along the line of sight 
through the volume, such as ray casting approaches that trace between entry and exit points of cells 
[U K88]. Three approaches are described, providing a trade-off between image quality and speed. For coherent 
projection, one of these methods is used to find intensity and opacity at pro~cted polygon vertices. 
2.3.1 Some Definitions The intensity and opacity contribution of a cell at each pixel (or along each 
line of sight ray) should take into account the emission and occlusion properties of the material being 
modeled, We define material opacity as the fraction of light entering from behind that would be occluded 
if that material were present for o depth distance of I. For example, if the material opacity value is 
0.5, 5070 of any light coming from behind the material would be removed if the material were present 
for a depth of one unit distance. Our implementation treats the value returned by the opacity transfer 
function as the material opacity (in the range Oto 1) and converts it into the differential opacity (in 
the range O to m) as described below. (It would also be reasonable to specify that the transfer function 
return the differential opacity directly, but then there is some awkwardness about representing cm.) 
The differential opacity of a material, denoted by Q, is defined as the rate at which light is occluded 
as it travels through the material. That is, in an infinitesimal distance dz, a fraction fl(z)dz of light 
is occluded, and (1 -Q(z)dz) of the light is transmitted. From these definitions it follows (see Equation 
7) that a differential opacity fl acting over a unit distance gives a material opacity O=l e-n (1) Inverting 
this function, Q=l OK+ (2) () The color transfer functions return material intensity, which is defined 
as the amount of light emitted by the material if present for a depth distance of 1. However, the material 
intensity value is the same as the differential intensity value. The intensity and opacity contributed 
by the material between the front and the back of a cell along the line of sight are called cumulative 
intensity and cumulative opacity. These quantities are defined as solutions of differential equations; 
they are found and used in compositing.  2.3.2 Integration Methods Throughout this discussion we use 
integration somewhat liberally to mean (exact or approximate) solution of a differ­ential equation. Three 
approaches have been implemented. In all cases the underlying differential equations are the same, as 
described next. Let z represent distance through the cell from the back vertex. Let Q(z) be differential 
opacity and let Et(z) be the differential intensity of light of color c (which, as mentioned before, 
is the same as material intensity). Let T(z) denote the fraction of light entering the cell that is transmitted 
through distance z (needed for compositing). Let l.(z) denote the intensity of light of color c that 
is emitted within the cell and reaches z. Then: dT !3(2)7 (2) (3) z= dI. 42(2)1=(Z) + E.(z) (4) z= 
 The boundary conditions are that T(O) = 1 and 1.(0) = O. Letting d be the back-to-front distance between 
vertices, the cumulative intensity of color c is l=(d) and the cumulative opacity is O. -=(1 -T(d)). 
Assuming Cl(z) haa a closed form integral (it is normally a simple interpolation function of some kind), 
Equation 3 has the standard closed form solution, -JO n[ti)dti T(z) =e (5) The solution of Equation 
4 can also be expressed as an integral: (6) However, this integral has a closed form expression only 
in special cases. For example, if there is a constant p. such that E.(z) = p.$l(z), then the substitution 
Uc(z) = Z.(z) -PC in Equation 4 gives a differential equation for U. that is the same as Equation 3 (except 
for the boundary condition), and 1(z) is ss solvable as as T(z); this method is employed by Max et al. 
[MHC90]. The conditions E.(z) = p.fl(z) effectively restrict the mapping from scalar values to a single 
transfer function plus dMerent multipliers M. for different colors. It is not employed here because we 
wished to permit the specification of independent transfer functions for all four quantities+ For the 
rest of the dkcussion, we shall drop the subscript c on intensities E and I, with the understanding that 
intensity calculations are done independently for each color. An important case that has closed form 
solutions is used in several of the methods, sometimes as an approximation: that is when Q(z) and E(z) 
are constant within the cell. Then we have T(z) = e-n (7) (8) (z) = ~ (1-e-nz) Substituting d for z 
gives the cumulative values, Oc.m = (1 -T(d)) and 1~~~ = I(d). 1. Average C*D Integration: A simple way 
to determine cumulative intensity and opacity is to average the front and back intensity and differential 
opacity values, and to -nd b min(l, ~d) in Equations 7 ad 8. approximate (1 -e ) Y This gives o..~ = 
min(l, &#38;.ed) (9) E.aue I cum = cum (lo)()T ave The name C*D is based on the fact that in the common 
case that OCw~ < 1, the cumulative intensity becomes color times distance . This is not always a desirable 
choice: for example, the intensity and opacity calculated for a ray through a homogeneous volume (constant 
data values throughout) will generally not be the same if the volume is treated as one large cell compared 
to the same volume treated as many small cells composite together (see Section 3.1 ). However, this approach 
is fast, as no transcendental functions are used, and for large volumes may be visually indistinguishable 
from more expensive methods (see Section 3.4). This method tends to overestimate intensity and opacity. 
2. Exponential Homogeneous Integration: A more complex and yet computationally acceptable method is to 
assume the region between the front and back of the cell is homogeneous. The front and back material 
intensity and opacity are averaged to provide the average material intensity Eave and average material 
opacity Oawe. Then Oave is converted to Qave by Equation 2, and the closed form solutions in Equations 
7 and 8 are used with Eave for E and n a.. for Q. Related exponential methods have been used by other 
visualization researchers [MHC90, ST90, Sab88]. The distance d between front and back vertices can be 
scaled by a user-defined factor for flexibility. 3. Exponential Linear Integration: Here the material 
intensity and opacity are assumed to vary linearly (but independently) between front and back cell faces. 
A closed form solution does not exist in general, and numerical solution is used. The user defines a 
number of divisions between the front and back faces, and linear interpolation is used to estimate the 
material intensity and opacity values at those points. Then exponential homogeneous integration is applied 
to each of the subregions, and these are composite as described in Section 2.5. As mentioned before, 
Max et aL [MHC90] require that intensity is some constant multiple of opacity, and use the faster analytical 
SOIUtion based on Equation 5 and the discussion following it. 2.4 Interpolating to Pixel Values Once 
the intensity and opacity of the polygon vertices have been determined, it is necessary to find the values 
of the pixels that lie bet ween them and are projected onto. These pixels are located by the usual process 
of polygon scan conversion, either in hardware or software. A ma~r motivation of this method is that 
this job can be relegated to hardware. The cumulative intensity and opacity associated with the pixels 
pro~cted onto are found by one of the three methods described below. These will be referred to as interpolation 
methods, though, more correctly, they are a choice of which integration to apply to each pixel. Again, 
there is a tradeoff of cost and accuracy. Three approaches have been implemented: 1. Gouraud Shading 
Interpolation: This is an extension of the common Gouraud shading model [Gou71] which first linearly 
interpolates cumulative color and opacity along edges from scan line to scanline, and, within each scanline, 
linearly interpolates between the values for edge pairs. Shirley and Tuchman [ST90] recently published 
a method using Gouraud-shaded tetrahedrons for volume rendering. The assumption of a linear variation 
between vertices is not completely in keeping with the basic model of a semi­transparent gas. However, 
the method often works quite weU in practice (see Section 3). Many graphics workstations have hardware-assisted 
Gouraud shading and this step can done efficiently and in parallel with the rest of the volume renderer. 
It is essential, however, that the Gouraud shader interpolates in the opacity channel, as well as red, 
green, and blue. The limited precision of interpolation in hardware can also cause aliasing, so a software 
version which works in floating point has also been implemented. 2. Exponential Homogeneous Interpolation: 
This uses exponential homogeneous integration to calculate the cumulative intensity and opacity at each 
pixel. First, the average material intensity and opacity are found for each projected polygon vertex. 
Then, polygon scan conversion is used to Linearly interpolate across the projected polygon face and find 
the average material intensity and opacity at each pixel. ] Finafly, exponential homogeneous integration 
~ is used between front and back faces to find the cumulative intensity and opacity at each pixel. 3. 
Exponential Linear Interpolation: This approach uses exponential linear integration at each pixel pro~cted 
onto. In this case, the material intensity and opacity values of the front and back face polygons are 
linearly interpolated separately, again using scan conversion to find these values at each pixel. Then 
exponential linear integration is applied at each pixel. This is most closely related to the work of 
Max et al. [MHC90], but permits separate independent transfer functions for different colors and opacity. 
 2.5 Compositing Compositing is nsed at each pixel to combine the effects of cells that pro~ct there 
[PD84]. For back-t~front traversal c . . . =(1 -O.ew)cacc + c.. (11) o .c. = (1 -OIIew)O.C. + O..W (12) 
 1This facilitates comparison of methods. More consistent here and in the next method would be to interpolate 
on data, then apply the tr=sfer functions. Exponential Average C* D   I Intensity Opacity Intensity 
Opacity 1 Cell 91.97 0.500 127.50 0.693 2 Cells 91.97 0.500 105.41 0.573 5 Cells 91.97 0.500 96.72 0.526 
10 Cells 91.97 0.500 94.26 0.512 50 Cells 91.97 0.500 92.42 0.502 100 Cells 91.97 0.500 92.19 0.501 10000 
Cells 91.97 0.500 91.97 0.500 Table 1: Combining Compositing and Integration where C .,W and O..W are 
the color and opacity values of the newly calculated cell at a particular pixel, and Cat= and O~cC are 
the accumulated color and opacity values of the pixel projected onto before and after projection. However, 
it is not necessary to calculate Oa=c or store it. For front-to-back traversal, c ... =(1 -O.cc)cnew 
+ c... (13) o .,2. =(1 -O.cc)on.w + Oa.c (14)  and 04== must be stored. 3 Experimental Results Coherent 
projection methods have been explored on a number of data sets. This section will explore: 1) integration 
approaches; 2) interpolation approaches; 3) compositing; and 4) cost and quality of final images. 3.1 
Results Concerning Integration in Depth Three issues to consider in choosing an integration method are: 
behavior within a single cell; behavior when composit­ing many cells; and time costs. After some illustrative 
ex­amples are used to explore these issues, values are compared for two real data volumes. Behavior within 
a Single Cell: Consider integration of one front-back vertex pair. Generally, cumulative intensity and 
cumulative opacity are higher using average C*D integration, compared to the exponential integration 
methods. The exponential homogeneous approach averages out differences between front and back faces, 
while the exponential linear approach interpolates. Consider three cases with the same cell depth: Front 
Vertex Back Vertex opacity intensity opacity intensity (A) 0.4 100 0.4 100 (B) 0.8 200 0.0 0 (c) 0.0 
200 0.8 0  Exponential homogeneous integration will find the same cumulative intensity and opacity 
for aU three because of averaging. Exponential linear integration wiU not. In fact, as the number of 
subdivisions increases, cell B will become increasingly dark, because the high opacity at the front will 
occlude both light from behhtd and light being emitted within the cell itself. (In cases where opacity 
is very high, even ceUs with high material intensity values wiU become very dark. This is a rather undesirable 
though not unrealistic property of high opacity regions in this approach.) If, instead of material opacity, 
the diflerentiol opacity were linear] y interpolated through the cell in the exponential linear integration 
method, then cases A and B would give identical results because intensity is a linear multiple of opacity 
and the opacities have the same integrals, so the discussion following Equation 6 applies. Case C, however, 
would still differ. Compositing Between Cells Combined with Integra­tion within Cells: Compositing brings 
out an inadequacy of Gouraud interpolation methods. Inter-cell compositing is itself an exponential process, 
comparable to the exponential integration methods described above. Table 1 shows the problem with a simple 
example: a constant value region with intensity 127.5, material opacity 0.5, and distance 1. (Compositing 
was done in floating point.) Using exponential integration methods, the same intensity and opacity result 
from treating the region as one cell or many ceUs, as should occur in reality. This is not the case when 
average C*D integration is used. [f a hierarchy or progressive refinement is used, the resultant image 
will vary in intensity depending upon the number of subdivisions. Intensity variations can also occur 
when viewing the volume at an angle, because the line of sight rays through pixels paas through different 
numbers and depths of cells. Time Costs: The exponential integration methods are clearly more expensive. 
Considering only the subroutines involved in integration in depth, the average C*D method was from 25% 
to 50% 0faster than exponential homogeneous integration, and this latter was about three times as fast 
as exponential linear integration with five subdivisions. The relative costs of these routines in the 
whole program depend upon volume size and orientations. On tested volumes (40x32x32 and 256x256x51 resolution), 
exponential homogeneous integration routines took from 35% to 60% of the total running time. Integration 
on Two Larger Volumes: The effect of the three approaches on two real data sets was examined. One was 
a 256x256x50 section of an MR brain data set.z 2MR d~a fmm a Siernens Magneton and provided WSS courtesy 
of Siemens Medical Systems, Inc., Is&#38;n, MJ. Data edited by Dr. Julian Rosemnan, North Carolina Memorial 
Hospital. The transfer functions for this were a mostly linear ramp with increased red and opacity in 
the middle ranges. (See Figure 5). The other volume was the pressure scalar field from a computational 
fiuid dynamics simulation of air flow around a blunt fin.3 The originaJ curvilinear-gridded data was 
resampled to a regular grid with dimensions 115x1 OOX51 [WC+90]. Transfer functions mapped high pressure 
regions to red and medium pressure regions to blue. (See Figure 2 for a smaller 40x32x32 version of this 
volume.) The cumulative intensity and opacity values found by the three integration methods for each 
front/back vertex pair were compared. In summary, comparing mean values and standard deviations, differences 
were at most 2%. OccaaionaUy, C*D integration differed by 8%. 3.2 Interpolation Between Projected Vertices 
Next, methods for finding cumulative intensity and opacity at pixels were explored (see Section 2.3). 
When Gouraud interpolation was used, all of the three integration methods were used to find cumulative 
intensity and opacity at the subcell vertices. When exponential interpolation methods were used, both 
subcell vertices and interpolated pixels used the same method. Interpolation within One Cell: When viewing 
a sin­ gle cell, aU methods appear visually reasonable, though Gouraud-interpolated cells are somewhat 
darker around the borders when viewed with more than one face visible. This is because the cumulative 
intensity and opacity at some silhouette vertices is zero, due to the distance between front and back 
subcells vertices being zero. For example, as we move horizontally across a cell of constant opacity 
fl, say <rem z ==Oat a silhouette vertex of ceU-depth Oto an interior vertex at z = a, where the cell-depth 
is d, intensity should increase according to the nonlinear function (1 e -n di )lfl. However, linear 
interpolation yields only the smaller function ~ (1 -e-n ) /fl. Exponential interpolation methods use 
the correct nonlinear function for pixel calculations and do not have this problem. It is possible to 
somewhat alleviate linear interpolation artifacts and still use hardware Gouraud interpolation through 
the use of blend functions and multiple blendings. We have implemented a three-pass method inspired by 
a suggestion of Pat Hanrahan and Peter Shirley. It requires back-to-front traversal. The essential step 
is to compute a half-way opacity such that (1-0kaJj)2 = (l-Octi~). Blending the back twice with this 
Ohalf causes the hardware (effectively) to multiply two linear interpolations yielding a net quadratic 
interpolation that more closely approximates the desired exponential function. In the third pass the 
hardware blends the intensity of the new cell into the background. Additional details are omitted for 
lack of Data is from UNC 1969 Volume Visualization Workshop dataaet. 3 CFD data Courtmy of NAS/NASA Ames 
Research Center. Subcells Double Real Float Real 16-bit Integer 8-bit Integer Iris 4D-50GT Int. 92 92 
92 92 92 1 Opac. 128 128 128 128 128 Int. 92 92 92 92 91 2 Opac. 128 128 128 127 127 Int. 92 92 92 87 
87 10 Opac. 128 128 127 124 119 lnt. 92 92 92 83 34 50 Opac. 128 128 127 122 32 Int. 92 92 90 1 1 100 
Opac. 128 128 127 101 1 Table 2: Comparison of Compositing Using Integer or Real Arithmetic (Intensity 
and Opacity) space. This method is inaccurate when fld << 1 due to limited hardware precision, but may 
be useful when the scene consists of a few large cells, as shown in Figure 3. B. Interpolation with Layers 
of Cells: Problems with Gouraud interpolation methods become more obvious when layers of cells are composite. 
The inaccurate interaction of integration and compositing described in Section 3.1 will occur when linear 
methods are used, because the integration method simulated at each pixel is inaccurate. However, this 
problem is not very obvious unless the volume consists of a few large cells. Figure 3 illustrates this 
effect on a 4x4x4 constant value volume rendered using four methods: the upper left image used exponential 
homogeneous integration at subcell vertices and hardware Gouraud interpolation; the upper right used 
the same methods but with the multiple blending mentioned above; the lower left used average C*D integration 
at subcells vertices and hardware Gouraud interpolation; and the lower right used exponential homogeneous 
integration and interpolation. It is possible to see some artifacts between cells in all images except 
the lower right. Precision ProbIems with Hardware Shading: A much greater problem may occur when using 
hardware Gouraud shading as opposed to software Gouraud shading, because if the individual cells of the 
volume are uery dim, precision and truncation errors become a ma~r consideration. Figure 4 shows the 
problems due to hardware interpolation that show up when many layers are composite together. These images 
show a 20X20X20 scalar field with material opacity values decreasing radially from the center. Left images 
use exponential homogeneous integration at subcell vertices and right images uses average C*D integration 
at subcell vertices. Upper images use hardware Gouraud shading and lower images use software Gouraud 
shading. AU images use hardware compositing, so the compositing behavior itself is not the problem here. 
Rather the accumulation of tiny (one bit) errors from each dim cell layer (average cumulative intensity 
was 7 and average opacity 0.1 ) when many layers are composite together produce this result. Further, 
the blocky nature of the pictures is also seen on a single layer of ceils when the monitor brightness 
is enhanced. These problems become much less noticeable if cells are bright, because truncation is less 
significant. 3.3 Compositing A related problem can occur due to hardware compositing that uses only eight 
bits for the opacity channel. To explore this, a single cell of homogeneous material intensity and opacity 
(both 128 from a maximum of 255) wss used. As described in Section 2.3, using exponential methods, integration 
in depth through this cell should provide the same intensity and opacity whether it is treated as one 
or many cells. This is the c~e using floating point arithmetic. Compositing in software on a Sun 4 provides 
the results in Table 2 for double-and single-precision floating point, eight-bit integer, and sixteen-bit 
integer arithmetic. The cell depth is 1 and the cell is divided into 1, 2, 10, 50, and 100 subcells. 
The final row shows results gained from compositing on an Iris 4D-50GT and reading the frame buffer. 
Of course, most graphics systems are designed to render fairly bright objects and composite a few layers. 
This was what they were designed for, and they are very good at it. However, some of us insist on trying 
to extend their uses in new directions, and encounter the problems described above. For us, it would 
certainly be desirable that the machines use more bits per pixel for interpolation and compositing. 3.4 
Timings and Image Quality ln this section the various approaches are compared in terms of the images 
produced and time taken on few data sets (See Table 3). The machine used for timings and still images 
was a Silicon Graphics Iris 4D50-GT, and images for timings were drawn into a 500X500 pixel window. As 
a brief comment, coherent projection takes advantage of the identical parallel pro~ction of all cells. 
If perspective projection were used, each cell would have to be indepen­dently projected. This would 
approximately double the cost of rendering when using hardware Gouraud interpolation. Considering subcell 
vertex integration methods, average C*D integration was only slightly less expensive than exp~ nential 
homogeneous integration considering the overall time 28 I Integration Method Interpolation Method %here 
20x20x20 Front 2xZoom Rot. 30,30,30 Blunt Fin 40x32x32 Front 2xZoom Rot. 30,30,30 + m Pixel Ave. C*D 
Exp.Homog. Exp.Lin.(5) Coverage Hrd.Gour. Hrd.Gour. Exp.Lin.(5) 13X13 3 4 48 103 359 25x25 3 4 155 373 
1395 5 6 96 193 623 7x8 16 21 13x16 16 21 27 32 495 542 516 545 830 833 Table 3: Timings on Projection 
Methods (seconds) of image creation. This is particularly true on large volumes with small dim cells, 
where the integration approximates by multiplying color times distance. Exponential linear integration 
did incur a large time cost and provided min­imal differences in image quality compared to exponential 
homogeneous integration on most volumes viewed anyway. Considering methods of determining pixel values, 
software Gouraud interpolation was considerably more expensive than hard ware Gouraud interpolation, 
dependent upon the cell size. The interpolation decreases with cell size. only a few pixels, artifacts 
due to though how much is extra cost of software Also, when cells cover hardware interpolation also 
become less significant. But then, advantages of any type of coherent projection dkappear when cells 
are only a pixel or a few pixels in area. A considerable advantage of hardware interpolation is seen 
when volumes are zoomed. Hardware interpolation is little affected by cell size, while software methods 
become far more expensive. Applying either of the exponential integration methods at each pixel was prohibitively 
expensive for medium to large volumes. When a few large cells are visible, however, these methods do 
produce better images. The figures show some illustrative images done using exponential homogeneous integration 
at polygon vertices and hardware Gouraud interpolation. Figure 2 is a 40x32x32 resampled volume based 
on a CFD simulation of the blunt fin. Figure s shows two views of the MR Brain data set. Both volumes 
were cited in Section 3.1. Figure 6 shows part (zoomed) of the SOD enzyme volume (resolution 97x97x1 
16).4 Figure 7 is an image of a sampled function, 4 Elmtmn &#38;MjtY -p of active site of superoxide 
dismut~e [SOD] enzyme as dek-min ed by X-ray crystallography y, Duncan McRee, Srrippz Clinic, La Jolla, 
California. Data is from UNC 19S9 Vohune Visualization Workshop datset. which shows the present implementation 
s rudimentary isosurface extraction (green) and gradient shading (red and blue) abilities. 4 Future Directions 
There are several improvements that can be implemented. Exponential linear integration is important only 
when a large variation exists between front and back vertex values. To avoid the expense of the calculation 
when unnecessary, the system could compare values and choose between the two exponential methods based 
on their variation. The advantages of projection disappear when cells are very small. When this occurs, 
it would be intelligent to automat ica.11y reduce the calculations on each cell, perhaps treating each 
as one projected polygon with values that are an average of corner vertices. When imaging front to back, 
it would be useful to stop rendering cells that project to already opaque regions. The implementation 
for this is preliminary. Most images shown here assume the only light is that emitted by the volume. 
Better gradient shading and isosurface extraction should be implemented. Preliminary tests suggest this 
should be feasible. It has become obvious in exploring volume rendering on real data sets that speed 
is only a small part of the problem. The laborious process of finding an appropriate mapping from data 
values to color and opacity deserves much future attention. The ability to shade according to gradients 
and isolate surfaces would also improve the program s usefulness. 5 Conclusions Coherent projection offers 
rapid imaging, good quality images, and the ability to watch the whole image appear in   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122748</article_id>
		<sort_key>285</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Hierarchical splatting]]></title>
		<subtitle><![CDATA[a progressive refinement algorithm for volume rendering]]></subtitle>
		<page_from>285</page_from>
		<page_to>288</page_to>
		<doi_number>10.1145/122718.122748</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122748</url>
		<abstract>
			<par><![CDATA[This paper presents a progressive refinement algorithm for volume rendering which uses a pyramidal volume representation. Besides storing average values, the pyramid stores estimated error, so an octtree can be fit to the pyramid given a user-supplied precision. This octtree is then drawn using a set of splats, or footprints, each scaled to match the size of the projection of a cell. The splats themselves are approximated with RGBA Gouraud-shaded polygons, so that they can be drawn efficiently on modern graphics workstations. The result is a real-time rendering algorithm suitable for interactive applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[coherence]]></kw>
			<kw><![CDATA[interactive techniques]]></kw>
			<kw><![CDATA[progressive refinement]]></kw>
			<kw><![CDATA[volume rendering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010247</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Image segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010248</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Video segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P62534</person_id>
				<author_profile_id><![CDATA[81414611192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Laur]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University, Princeton, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77026114</person_id>
				<author_profile_id><![CDATA[81100482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hanrahan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Princeton University, Princeton, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>15889</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Larry Bergman, Henry Fuchs, Eric Grant, and Susan Sl~aC.b .|~nage rendering by adaptive refnement. Computer Graphics (SIGGRAPH '86 Proceedings), 20(4):29-38, August 1986.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>55285</ref_obj_id>
				<ref_obj_pid>55279</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Jules Bloomenthal. Polygonization of implicit surfaces. Computer Aided Geometric Design, 5(4):341-555, November 1988.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Harvey E. Cline, William E. Lorensen, Sigwalt Ludke, Carl R. Crawford, and Bruce C. Teeter. Two algorithms for the reconstruction of surfaces from tomograms. Medical Physics, 15(3):320-327, June, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>78965</ref_obj_id>
				<ref_obj_pid>78964</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Marc Levoy. Efficient ray tracing of volume data. A CM Transactions on Graphics, 9(3):245-261, July 1990.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91449</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Marc Levoy and Ross Whitaker. Gaze-directed volume rendering. Computer Graphics (Symposium on Interactive 31) Graphics}, 24(2):217-223, March 1990.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99315</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Nelson Max, Pat Hanrahan, and Roger Crawfis. Area and volume coherence for efficient visualization of 3d scalar functions. Computer Graphics (San Diego Workshop on Volume Visualizaton), 24(5):27-33, November 1990.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808606</ref_obj_id>
				<ref_obj_pid>800031</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Thomas Porter and Tom Duff. Compositing digital images. Computer Graphics (SIGGRAPH '84 Proceedings), 18(3):253-260, July 1984.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99322</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Peter Shirley and Allan Tuchman. A polygonal approximation to direct scalar volume rendering. Computer Graphics (San Diego Workshop on Volume Visualizaton), 24(5):63-70, November 1990.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378482</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Craig Upson and Michael Keeler. V-buffer: Visible volume rendering. Computer Graphics (Proceedings of SIGGRAPH '88), 22(4):59-64, August 1988.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97919</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lee Westover. Footprint evaluation for volume rendering. Computer Graphics, 24(4):367-376, August 1990.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>122758</ref_obj_id>
				<ref_obj_pid>122718</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms. A coherent projection approach to direct volume rendering. Computer Graphics (SIG- GRAPH '9i Proceedings}, July 1991.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99321</ref_obj_id>
				<ref_obj_pid>99308</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jane Wilhelms and Allan Van Gelder. Octrees for faster isosurface generation. Computer Graphics (San Diego Workshop on Volume Visualizaton), 24(5):57-62, November 1990.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lance Williams. Pyramidal parametrics. Computer Graphics (SIGGRAPH '83 Proceedings), 17(3):1-1 1, July 1983.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Brian Wyvill, Craig McPheeters, and Geoff WyviU. Data structure for soft objects. The Visual Computer, 2(4):227-234, 1986.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 ~ @ Computer Graphics, Volume 25, Number 4, July 1991 Hierarchical Splatting: A Progressive Refinement 
Algorithm for Volume Rendering David Laur and Pat Hanrahan Princeton Princeton, Abstract This paper presents 
a progressive refinement algorithm for volume rendering which uses a pyramidal volume repre­sent at ion. 
Besides storing average values, the pyramid stores estimated error, so an octtree can be fit to the pyramid 
given a user-supplied precision. This octtree is then drawn using a set of splats, or footprints, each 
scaled of the projection of a cell. The splats proximate with RGBA Gouraud-shaded they can be drawn efficiently 
on modern tions. The result is a real-time rendering for interactive applications. to match the size 
themselves are ap polygons, so that graphics worksta­algorithm suitable CR Categories and Subject Descriptors: 
1.3.7 [Com­ pu ter Graphics]: Three-Dimensional Graphics and Realism. Key Words: volume rendering, coherence, 
progressive re­finement, interactive techniques. Introduction Volume visualization is a collection of 
techniques for visual­izing 3D functions. The earliest methods extracted conven­tional computer graphics 
primitives such as surfaces, curves, or points, and then displayed them. More recent methods render the 
volume directly, without this intermediate conver­sion. This involves forming an RGBA (color and opacity) 
volume, and projecting it from the desired point of view. RGBA volumes can represent both interiors and 
the sur­faces representing the boundaries between different regions. If just surfaces are shown, the 
pictures look quite similar to those generated by first extracting surfaces and then render­ing them. 
However, if interiors are also shown, they appear as clouds with varying density and color. A big advantage 
of volume rendering is that this interior information is not thrown away; a disadvantage is that cloudy 
interiors are hard to interpret. This paper presents an algorithm for rendering opacity projections at 
interactive rates on a typical high performance graphics workstation. Motion is very helpful in understand­ing 
opacity projections. For example, the output of com­mercial medicaJ imaging systems generate film loops 
and not just static imagery. Furthermore, the amount of information gained from a motion study is much 
greater if the motion is under interactive control, for then the user can vary the motion to highlight 
what they are currently focusing on. Pem]ission [o cnpy w!lhmrlfw dll nr p~rt !~fthis material is grtintccl 
provided that the cnpiei are nut made nr distributed for direct commercial advantage. the ACM cnpyright 
nnt!cc md [he d[Ie nf the puhli~dtimrtindits date appear, iindnnticcisgtvcn[hatcopying ISby pcm~issionof 
the Asnciation f t~rComputing Mtichlnery. To cnpy otherwise. or to rcpuhlish, requires a fce anchr specific 
permission. ( 1 1991 ACM-O-89791 -436-8/!Tl/007/f)285 $00.75   University NJ 08544, USA Our algorithm 
is based on two key ideas: coherence and progressive refinement. Recent research has shown how to take 
advantage of coherence when performing opacity pro­jections of large cells filled with cloudy material 
[9; 8; 6; 11]. The most relevant to the work reported here are those methods that approximate the projection 
with a collection of Gouraud-shaded RGBA polygons [8; 11]. Progressive re­finement involves simplifying 
either the model or the ren­dering algorithm, or both, until pictures can be produced at interactive 
rates, and then computing successively better images when free time is available, for example, when the 
user pauses to examine an interesting image [1]. This paper proposes a splatting aigorithm [3; 10] that 
works on a pyramidal representation of the volume. Splat­ting works by first sorting cells from back 
to front and then compositing the projection of each cell, called its @­print, into an accumulating projection 
image. Our algorithm builds a set of footprints at different sizes one for each level in the pyramid. 
The time to draw a splat is constant, or at worst rrroDortional to its area. so substantial time is saved 
by dra~in~ a single large splat instead of a volume of smaller splats. More interestingly, the algorithm 
does not just draw a reduced resolution version of the volume, but determines the number of the splats 
by fitting a collection of cells at dif­ferent resolutions in the pyramid to the original data based 
on a user-supplied error criten a. Progretwive refinement pr­ceeds by gradually reducing the error associated 
with the fit, 2 Reconstruction and Projection The ideal volume rendering algorithm performs the following 
three steps: (i) reconstructs the continuous function from the discrete samples, (ii) transforms the 
continuous function for viewing, and (iii) evaluates the opacity integral along each line-of-sight. Splatting 
algorithms approximate this proce­dure. The reconstruction function is transformed according to the current 
viewing transformation, and then is projected using the opacity integral to form a 2D footprint. There 
is only one footprint per view per volume if the data is uni­formly sampled and the viewing transformation 
is a parallel projection. To generate the complete image, the footprints are composite on top of each 
other in back to front orderl. Splatting algorithms are not equivalent to the idealized ren­dering process 
outlined above, because reconstruction and projection cannot be reordered, if the reconstruction func­tions 
from different samples overlap, which is necessary to Actually Westover s ples from a Ianar slice posltes 
the Y s lce Image rdgorithm reconstructs all the sam­into a slice ima e,. and then com­onto the accumu 
f atmg final Image.      
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122749</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Generating textures on arbitrary surfaces using reaction-diffusion]]></title>
		<page_from>289</page_from>
		<page_to>298</page_to>
		<doi_number>10.1145/122718.122749</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122749</url>
		<abstract>
			<par><![CDATA[This paper describes a biologically motivated method of texture synthesis called <i>reaction-diffusion</i> and demonstrates how these textures can be generated in a manner that directly matches the geometry of a given surface. Reaction-diffusion is a process in which two or more chemicals diffuse at unequal rates over a surface and react with one another to form stable patterns such as spots and stripes. Biologists and mathematicians have explored the patterns made by several reaction-diffusion systems. We extend the range of textures that have previously been generated by using a cascade of multiple reaction-diffusion systems in which one system lays down an initial pattern and then one or more later systems refine the pattern. Examples of patterns generated by such a cascade process include the clusters of spots on leopards known as rosettes and the web-like patterns found on giraffes. In addition, this paper introduces a method which reaction-diffusion textures are created to match the geometry of an arbitrary polyhedral surface. This is accomplished by creating a mesh over a given surface and then simulating the reaction-diffusion process directly on this mesh. This avoids the often difficult task of assigning texture coordinates to a complex surface. A mesh is generated by evenly distributing points over the model using relaxation and then determining which points are adjacent by constructing their Voronoi regions. Textures are rendered directly from the mesh by using a weighted sum of mesh values to compute surface color at a given position. Such textures can also be used as bump maps.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[biological models]]></kw>
			<kw><![CDATA[reaction-diffusion]]></kw>
			<kw><![CDATA[texture mapping]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39080372</person_id>
				<author_profile_id><![CDATA[81100457973]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bard, Jonathan, "A Unity Underlying the Different Zebra Striping Patterns," Journal of Zoology, Vol. 183, No. 4, pp. 527-539 (December 1977).]]></ref_text>
				<ref_id>Bard 77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bard, Jonathan B. L., "A Model for Generating Aspects of Zebra and Other Mammalian Coat Patterns," Journal of Theoretical Biology, Vol. 93, No. 2, pp. 363-385 (November 1981).]]></ref_text>
				<ref_id>Bard 81</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bard, Jonathan and lan Lauder, "How Well Does Turing's Theory of Morphogenesis Work?," Journal of Theoretic'al Biology, Vol. 45, No. 2, pp. 501-531 (June 1974).]]></ref_text>
				<ref_id>Bard and Lauder 74</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bier, Eric A. and Kenneth R. Sloan, jr., "Two- Part Texture Mapping," IEEE Computer Graphics and Applications, Vol. 6, No. 9, pp. 40-53 (September 1986).]]></ref_text>
				<ref_id>Bier and Sloan 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>800248</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blinn, James F., "Simulation of Wrinkled Surfaces," Computer Graphics, Vol. 12, No. 3 (SIGGRAPH "78), pp. 286--292 (August 1978).]]></ref_text>
				<ref_id>Blinn 78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325249</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bloomenthal, Jules, "Modeling the Mighty Maple," Computer Graphics, Vol. 19, No. 3 fSIGGRAPH '85), pp. 305-311 (July 1985).]]></ref_text>
				<ref_id>Bloomenthal 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Catmull, Edwin E., "A Subdivision Algorithm for Computer Display of Curved Surfaces," Ph.D. Thesis, Department of Computer Science, University of Utah (December 1974).]]></ref_text>
				<ref_id>Catmull 74</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325248</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gardner, Geoffrey Y., "Visual Simulation of Clouds," Computer Graphics, Vol. 19, No. 3 (SIGGRAPH '85), pp. 297-303 (July 1985).]]></ref_text>
				<ref_id>Gardner 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97903</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hanrahan, Pat and Paul Haeberli, "Direct WYSIWYG Painting and Texturing on 3D Shapes," Computer Graphics, Vol. 24, No. 4 (SIGGRAPH '90), pp. 215-223 (August 1990).]]></ref_text>
				<ref_id>Hanrahan and Haeberli 90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Heckbert, Paul S., "Fundamentals of Texture Mapping and Image Warping," M.S. Thesis, Department of Electrical Engineering and Computer Science, University of Califomia at Berkeley (June 1989).]]></ref_text>
				<ref_id>Heckbert 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>44231</ref_obj_id>
				<ref_obj_pid>44227</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ho-Le, K., "Finite Element Mesh Generation Methods: A Review and Classification," Computer Aided Design, Vol. 20, No. 1, pp. 27-38 (January/February 1988).]]></ref_text>
				<ref_id>Ho-Le 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hubel, David H. and Torsten N. Wiesel, "Brain Mechanisms of Vision," Scientific American, Vol. 241, No. 3, pp. 150-- 162 (September 1979).]]></ref_text>
				<ref_id>Hubel and Wiesel 79</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hunding, Axel, Stuart A. Kauffman, and Brian C. Goodwin, "Drosophila Segmentation: Supercomputer Simulation of Prepattern Hierarchy," Journal of Theoretical Biology, Vol. 145, pp. 369-384 (1990).]]></ref_text>
				<ref_id>Hunding 90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Koenderink, Jan J., "The Structure of Images," Biological Cybernetics, Vol. 50, No. 5, pp. 363-370 (August 1984).]]></ref_text>
				<ref_id>Koenderink 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Lengyel, Istv~n and Irving R. Epstein, "Modeling of Turing Structures in the Chlorite-Iodide-Malonic Acid-Starch Reaction System," Science, Vol. 251, No. 4994, pp. 650--652 (February 8, 1991).]]></ref_text>
				<ref_id>Lengyel and Epstein 91</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808605</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lewis, John-Peter, "Texture Synthesis for Digital Painting," Computer Graphics, Vol. 18, No. 3 (SIGGRAPH '84), pp. 245-252 (July 1984).]]></ref_text>
				<ref_id>Lewis 84</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74360</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lewis, J. P., "Algorithms for Solid Noise Synthesis," Computer Graphics, Vol. 23, No. 3 (SIGGRAPH '89), pp. 263-270 (July 1989).]]></ref_text>
				<ref_id>Lewis 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ma, Song De and Andre Gagalowicz, "Determination of Local Coordinate Systems for Texture Synthesis on 3-D Surfaces," Eurographics '85, edited by C. E. Vandoni.]]></ref_text>
				<ref_id>Ma and Gagalowicz 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Meinhardt, Hans, Models of Biological Pattern Formation, Academic Press, London, 1982.]]></ref_text>
				<ref_id>Meinhardt 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1923</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Melhorn, Kurt, Multi-dimensional Searching and Computational Geometry, Springer-Verlag, 1984.]]></ref_text>
				<ref_id>Melhorn 84</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Murray, J. D., "On Pattern Formation Mechanisms for Lepidopteran Wing Patterns and Mammalian Coat Markings," Philosophical Transactions of the Royal Society B, Vol. 295, pp. 473--496.]]></ref_text>
				<ref_id>Murray 81</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Peachey, Darwyn R., "Solid Texturing of Complex Surfaces," Computer Graphics, Vol. 19, No. 3 (SIGGRAPH '85), pp. 279-286 (July 1985).]]></ref_text>
				<ref_id>Peachey 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Perlin, Ken, "An Image Synthesizer," Computer Graphics, Vol. 19, No. 3 (SIGGRAPH '85), pp. 287-296 (July 1985).]]></ref_text>
				<ref_id>Perlin 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74359</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Perlin, Ken and Eric M. Hoffert, "Hypertexture," Computer Graphics, Vol. 23, No. 3 (SIGGRAPH '89), pp. 253-262 (July 1989).]]></ref_text>
				<ref_id>Perlin and Hoffert 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Samek, Marcel, Cheryl Slean and Hank Weghorst, "Texture Mapping and Distortion in Digital Graphics," The Visual Computer, Vol. 2, No. 5, pp. 313-320 (September 1986).]]></ref_text>
				<ref_id>Samek 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>22919</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Toffoli, Tommaso and Norman Margolus, Cellular Automata Machines, MIT Press, 1987.]]></ref_text>
				<ref_id>Toffoli and Margolus 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Turing, Alan, "The Chemical Basis of Morphogenesis," Philosophical Transactions of the Royal Society B, Vol. 237, pp. 37-72 (August 14, 1952).]]></ref_text>
				<ref_id>Turing 52</ref_id>
			</ref>
			<ref>
				<ref_obj_id>90772</ref_obj_id>
				<ref_obj_pid>90767</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Turk, Greg, "Generating Random Points in Triangles," in Graphics Gems, edited by Andrew Glassner, Academic Press, 1990.]]></ref_text>
				<ref_id>Turk 90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801126</ref_obj_id>
				<ref_obj_pid>800059</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Williams, Lance, "Pyramidal Parametrics," Computer Graphics, Vol. 17, No. 3 (SIGGRAPH '83), pp. 1-11 (July 1983).]]></ref_text>
				<ref_id>Williams 83</ref_id>
			</ref>
			<ref>
				<ref_obj_id>122750</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Witkin, Andrew and Michael Kass, "Reaction- Diffusion Textures," Computer Graphics, Vol. 25 (SIGGRAPH '91).]]></ref_text>
				<ref_id>Witkin and Kass 91</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15895</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Yeager, Larry and Craig Upson, "Combining Physical and Visual Simulation -- Creation of the Planet Jupiter for the Film 2010," Computer Graphics, Vol. 20, No. 4 (SIGGRAPH '86), pp. 85-93 (August 1986).]]></ref_text>
				<ref_id>Yeager and Upson</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Generating Textures on Arbitrary Surfaces Using Reaction-Diffusion Greg Turk University of North Carolina 
at Chapel Hill Abstract This paper describes a biologically motivated method of texture synthesis called 
reacriorr-dlfusion and demonstrates how these textures can be generated in a manner that directly matches 
the geometry of a given surface. Reaction-diffusion is a process in which two or more chemicals diffuse 
at unequal rates over a surface and react with one another to form stable patterns such as spots and 
stripes. Biologists and mathematicians have explored the patterns made by several reaction-diffusion 
systems. We extend the range of textures that have previously been generated by using a cascade of multiple 
reaction-diffusion systems in which one system lays down an initial pattern and then one or more later 
systems refine the pattern. Examples of patterns generated by such a ca.seade process include the clusters 
of spots on leopards known as rosettes and the web-like patterns found on giraffes. In addition, this 
paper introduces a method by which reaction-diffusion textures are created to match tbe geometry of an 
arbitrary polyhedral surface. This is accomplished by creating a mesh over a given surface and then simulating 
the reaction­diffusion process directly on this mesh. This avoids the often difficult task of assigning 
texture coordinates to a complex surface. A mesh is generated by evenly distributing points over the 
model using relaxation and then determining which points are adjacent by constructing their Voronoi regions. 
Textures are rendered directly from the mesh by using a weighted sum of mesh values to compute surface 
color at a given position. Such textures can also be used as bump maps, CR Categories and Subject Descriptors: 
1.3.3 [Computer Graphics!: Picture/Image Generation; 1.3.5 [Computer Graphics]: Three-Dimensional Graphics 
and Realism -Color, shading, shadowing and texture; J.3 [Life and Medical Sciences]: Biology.  Additional 
Keywords and Phrases: Reaction-diffusion,biological models, texture mapping. Permission m copy without 
fee all or part of [his material is granted provided that [he copies are nnt made or distributed fnr 
direct comrrwrcial advantage. the ACM copyright notice and the title of the publicatimr and ![s date 
appear, and notice is given that copying is by permission of the Assceiation for Computing Machinery. 
Trr copy ntherwise, or to republish, requires a fee and/or specific permission. Introduction Texture 
mapping was introduced in [Catmull 74] as a method of adding to the visual richness of a computer generated 
image without adding geomet~. There are three fundamental issues that must be addressed to render textures. 
First, a texture must be acquired. Possibilities include creating a texture procedurally, painting a 
texture, or digitally scanning a texture from a photograph. Next, we need to define a mapping from tbe 
texture space to the space of the model to be textured. Defining this mapping should not require a great 
deal of a user s time. This mapping should not noticeably distort tbe texture. Finally, we require a 
method of sampling the texture during rendering so that the final image contains no artifacts due to 
aliasing or resulting from the underlying texture representation [Heckberf 891, These three issues are 
often interrelated, and this is true of tbe techniques in this paper. This paper explores a procedural 
method for texture synthesis and also introduces anew methed for fitting a texture to a surface. Either 
of these techniques can be used separately, but the examples given here shows the strength of using them 
together to produce natural textureson complex models. After a discussion of previous texturing methods, 
tbe majority of the paper is divided into two parts, one for each of these topics. The first part of 
this paper describes a chemical meehanism for pattern formation know as reaction-diffusion. This mechanism, 
first described in [Turing 52], shows how two or more chemicals that diffuse across a surface and react 
with one another can form stable patterns. A number of researchers have shown bow simple patterns of 
spots and stripes can be created by reaction-diffusion systems [Bard 8 [; Murray 8 l; Meinhardt 82]. 
We begin by introducing the basics of how a reaction-diffusion system can form simple patterns. We then 
introduce new results that show how more complex patterns can he generated by having an initial pattern 
set down by one chemicals ystem and further refined by later chemical systems. llt is widens the range 
of patterns that can be generated by reaction­diffusion to include such patterns as tbe rosettes found 
on leopards and tbe multiple-width stripes found on some fish and snakes. These patterns could be generated 
on a square grid and then mapped onto an object s surface using traditional techniques, but there are 
advantages to synthesizing the pattern directly on tbe surface to be textured in a manner that will be 
described next. The second part of this paper presents a method of generating a mesh over tbe surface 
of a polyhedral model that can be used for texture synthesis. The approach uses relaxation to evenly 
distribute points across tbe model s surface and then divides the surface into cells centered at these 
points. We can simulate reaction-diffusion systems directly on this mesh to create textures. Because 
there is no mapping from texture space to the object, there is no need to assign texture ( )199] ACM-()-X9791-436-S/91/fX)7/02fW 
WO.75 289  SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 coordinates to polygons and there is no distortion 
of the textures. At no time is the texture stored in some regular mxn grid, as are most textures. It 
is likely that other texture generation methods in addition to reaction-diffusion could also make use 
of such a mesh. Images of surfaces that have been textured using a mesh do not show aliasing artifacts 
or visual indication of the underlying mesh structure. These textures can also be used for bump mapping, 
a technique introduced in [Blinn 78] to give the appearance of a rough or wrinkled surface. The three 
steps involved in texturing a model as in Figures 4,5 and 6 are: (1) generate a mesh that fits the polyhedral 
model,(2) simulate a reaction-diffusion system on the mesh (solve a partial differential equation) and 
(3) use the final values from the simulation to specify surface color while rendering the polygons of 
the model. Artificial Texture Synthesis A great strength of procedurally generating textures is that 
each new method can be used in conjunction with already existing functions. Several methods have been 
demonstrated that use composition of various functions to generate textures. Gardner introduced the idea 
of summing a small number of sine waves of different periods, phases and amplitudes to create a texture 
[Gardner 85]. Pure sine waves generate fairly bland textures, so Gardner uses the values of the low period 
waves to alter the shape of the higher period waves. This method gives textures that are evocative of 
patterns found in nature such as those of clouds and trees. Perlin uses band-limited noise as the basic 
function from which to construct textures [Perlin 85]. He has shown that a wide variety of textures (stucco, 
wrinkles, marble, fire) can be created by manipulating such a noise function in various ways. [Lewis 
89] describes several methods for generating isotropic noise functions to be used for texture synthesis. 
A stunning example of using physical simulation for texture creation is the dynamic cloud patterns of 
Jupiter in the movie 2010 (Yaeger and Upson 86]. Recent work on texture synthesis using reaction-diffusion 
is described in [Witkin and Kass 9 I ]. They show the importance of anisotropy by introducing a rich 
set of new patterns that are generated by anisotropic reaction-diffusion. In addition, they demonstrate 
how reaction-diffusion systems can be simulated rapidly using fast approximations to Gaussian convolution. 
A texture can be created by painting an image, and the kinds of textures that may be created this way 
are limitless. An unusual variant of this is to paint an image in the frequency domain and then take 
the inverse transform to create the final texture [Lewis 84]. Lewis demonstrates how textures such as 
canvas and woodgrain can be created by this method. An extension todigitalpainting, described in [Hanrahan 
and Haeberli 90], shows how use of a hardware z-buffer can allow a user to paint interactively onto the 
image of a three­dimensional surface. Mapping Textures onto Surfaces Once atexturehasbeencreated,amethodis 
neededto mapitonto the surface to be textured. This is commonly cast into the problem of assigning texturecoordinates(u,v) 
from a rectangle to the vertices of the polygons in a model. Mapping texture coordinates onto a complex 
surface is not easy, and several methods have been proposed to accomplish this. A common approach is 
to define a mapping from the rectangle to the naturaI coordinate system of the target object s surface. 
For example, latitude and longitude can be used to define a mapping onto a sphere, and parametric coordinates 
can be used when mapping a texture onto a cubic patch [Catmull 74]. In some cases an object might be 
covered by multiple patches, and in these instances care must be taken to make the edges of the patches 
match. A successful example of this is found in the bark texture for a model of a maple tree in [Bloomenthal 
85]. Another approach to texture mapping is to project the texture onto the surface of the object. One 
example of this is to orient the texture square in R3(Euclidean three-space) and perform a projection 
from this square onto the surface [Peachey 85]. Related to this is atwo-step texture mapping method given 
by [Bier and Sloan 86]. The first step maps the texture onto a simple intermediate surface in Rs,such 
as a box or cylinder. The second step projects the texture from this surface onto the target object. 
A different method of texture mapping is to make use of the polygonal nature of many graphical models. 
In this approach, taken by [Samek 86], the surface of a polyhedral object is unfolded onto the plane 
one or more times and the average of the unfolded positions of each vertex is used to determine texture 
placement. A user can adjust the mapping by specifying where to begin the unfolding of the polyhedral 
object. Each of the above methods has been used with success for some models and textures. There are 
pitfalls to these methods, however. Each of the methods can cause a texture to be distorted because there 
is often no natural map from the texture space to the surface of the object. This is a fundamental problem 
that comes from defining the texture pattern over a geometry that is different than that of the object 
to be textured. Some of these techniques also require a good deal of user intervention. One solution 
to these problems for some images is the use of solid textures. A solid texfure is a color function defined 
over a portion of RJ,and such a texture is easily mapped onto the surfaces of objects [Peachey 85; Perlin 
85]. A point (x,y,z) on the surface of an object is colored by the value of the solid texture function 
at this point in space. This method is well suited for simulating objects that are formed from a solid 
piece of material such as a block of wood or a slab of marble. Solid texturing is a successful technique 
because the texture function matches the geometry of the material being simulated, namely the geometry 
of Rs. No assignment of texture coordinates is necessary. Quite a different approach to matching texture 
to surface geometry is given in [Ma and Gagalowicz 85]. They describe several methods for creating a 
local coordinate system at each point on the surface of a given model. Statistical properties of a texture 
are then used to synthesize texture on the surface so that it is oriented to the local coordinate system. 
Part One: Reaction-Diffusion This section describes a class of patterns that are formed by reaction­diffusion 
systems, These patterns are an addition to the texture synthesist s toolbox, a collection of tools that 
include such procedural methods as Perlin s noise function and Gardner s sum-of­sine waves. The reaction-diffusion 
patterns can either be u~d alone or they can be used as an initial pattern that can be built on using 
other procedures. This section begins by discussing reaction-diffusion as it relates to developmental 
biology and then gives specific examples of patterns that can be generated using reaction-diffusion. 
A central issue in developmental biology is how the cells of an embryo arrange themselves into particular 
patterns. For example, how is itthat the cells in the embryo of a worm become organized into segments? 
Undoubtedly there are many organizing mechanisms working together throughout the development of an animal. 
One possible mechanism, first described by Turing, is that two or more chemicals can diffuse through 
an embryo and react with each other until a stable pattern of chemical concentrations is reached [Turing 
52]. These chemical pre-pattems can then act as a trigger for cells of different types to develop in 
different positions in the embryo. Such chemical systems are known as reaction-diflusion systems, and 
the hypothetical chemical agents are called morphogens. Since the introduction of these ideas, several 
mathematical models of such systems have been studied to see what patterns can be formed and to see how 
these matched actual animal patterns such as coat spotting Figure 1: One-dimensional example of reaction-diffusion. 
Chemical concentration is shown in intervals of 400 time steps.  and stripes on mammals [Bard81; Murray 
81]. Only recently has an actual reaction-diffusion system been observed in the laboratory [Lengyel and 
Epstein 91 ]. So far no direct evidence has been found to show that reaction-diffusion is the operating 
mechanism in the development of any particular embryo pattern. This should not be taken as a refutation 
of the model, however, because the field of developmental biology is still young and very few mechanisms 
have been verified to be the agents of pattern formation in embryo development. The basic form of a simple 
reaction-diffusion system is to have two chemicals (call them a and b) that diffuse through the embryo 
at different rates and that react with each other to either build up or break down a and b. These systems 
can be explored in any dimension. For example, we might use a one-dimensional system to look at segment 
formation in worms, or we could look at reaction-diffusion on a surface for spot-pattern formation. Here 
are the equations showing the general form of a two-chemical reaction-diffusion system: au ;= F(a,b) 
+ Da v2a *= G(a,b) + Dh V2b af The first equation says that the change of the concentration of a at 
a given time depends on the sum of a function F of the local concentrations of a and b and the diffusion 
of a from places nearby. I?reconstant D. says how fast a is diffusing, and the Laplacian V2 a is a measure 
of how high the concentration of a is at one location with respect to the concentration of a nearby. 
If nearby places frave a higher concentration of a, then V* a will be positive and a diffuses toward 
this position. If nearby places have lower concentrations, then V~a will be negative and a will diffuse 
away from this position. The key to pattern formation based on reaction-diffusion is that an initial 
small amount of variation in the chemical concentrations can cause the system to be unstable initially 
and to be driven to a stable state in which the concentrations of a and b vary across the surface. A 
set of equations that Turing proposed for generating patterns in one dimension provides a specific example 
of reaction-diffusion:  As, =.!(16-a, b,) +Do (a,+, +a,l b,) Ab,= s(a,b,-b,-~,)+Dh(b,+,+b,,-2b,) These 
equations are given for a discrete model, where each a, is one cell in a line of cells and where the 
neighbors of this cell are a,, and a,+,. The values for fl, are the sources of slight irregularities 
in chemical concentration across the line of cells. Figure I illustrates the progress of the chemical 
concentration of b across a line of 60 cells as its concentration varies over time. Initially the values 
of a, and b, were set to 4 for all cells along the line. The values of ~, were clustered around 12, with 
the vahresvarying randomly by ~0.05. The diffusion constants were set to Da = .25 and D~ = .0625, which 
means that a diffuses more rapid] y than b, ands = 0.03125. Notice how after about 2000 iterations the 
concentration of b has settled down into a pattern of peaks and valleys. The simulation results look 
different in detail to this when a different random seed is used for ~,, but such simulations have the 
same characteristic peaks and valleys with roughly the same scale to these features. Reaction-Diffusion 
on a Grid The reaction-diffusion system given above can also be simulated on a two-dimensional field 
of cells. The most common form for such a simulation is to have each cell be a square in a regular grid, 
and have a cell diffuse to each of its four neighbors on the grid. The discrete form of the equations 
is: Aa,J=s(I6 a,,, b,,) + Da (a,+,,, + a, ,,, + a,,+l + a,, , 4U,J) Ah,, =s (a,,, b,, -b,, -~,,)+ Dh 
(b,+,,, + b,,, + b,,+, + b,., -4b,,,) In this form, the value of V2a at a cell is found by summing each 
of the four neighboring values of a and subtracting four times the value of a at the cell. Each of the 
neighfxrring values for a are given the same weight in this computation &#38;cause the length of the 
shared edge between any two cells is always the same on a square grid. This will not be the case when 
we perform a similar computation on a less regular grid, where different neighbors will be weighted differently 
when calculating V~a. Figure 2 (upper left) shows the result of a simulation of these equations on a 
64 x 64 grid of cells. Notice that the valleys of concentration in b take the form of spots in two dimensions. 
It is the nature of this system to have high concentrations for a in these spot regions where b is low. 
Sometimes chemical a is called an inhibifor because highvaluesfor a in a spot region prevent other spots 
from forming nearby. In two-chemical reaction-diffusion systems the inhibitor is always the chemical 
that diffuses more rapidly. We can create spots of different sizes by changing the value of the constants 
for this system. Small values for .r (.s = 0.05 in Figure 2, upper left) cause the reaction part of the 
system to proceed more slowly relative to the diffusion and this creates larger spots. Larger values 
fors produce smaller spots (.s= 0.2 in Figure 2, upper right). The spot patterns at the top of Figure 
2 were generated with ~,, = 12 +0. 1. If the random variation of P,J is increased to 12+ 3, the spots 
become more irregular in shape (Figure 3, upper left). The patterns that can be generated by this reaction-diffusion 
system were extensively studied in [Bard and Lauder 74] and [Bard 81]. Reaction-diffusion need not be 
restricted to two-chemical systems. For the generation of striped patterns, Meinhardt has proposed a 
system involving five chemicals that react with one another [Meinhardt 82]. See the appendix of this 
paper for details of Meinhardts s system. The result of simulating such a system on a two-dimensional 
grid can be seen in Figure 3 (Iowerleft). Notice that the system generates random stripes that tend to 
fork and sometimes form islands of one color or the other. This pattern is like random stripes found 
on some tropical fish and is alsasimilar to the pattern of right eye and left eye regions of the ocular 
dominance columns found in mammals [Hubel and Wiesel 79].    on polygons that share an edge with 
A are rotated about the common edge until they lie within the given plane. Points on more remote polygons 
are first rotated about the nearest edge of A and then projected onto the plane, We use this method for 
mapping nearby points onto the plane because of its simplicity. A different method, at the cost of execution 
speed and algorithm complexity, would be to search for a geodesic path between P and a given nearby point 
and then to unfold along this path. Making (he points repel one another becomes straightforward once 
we can map nearby points onto a given point s plane. For each point P on the surface we need to determine 
a vector.$ that is the sum of all repelling forces from nearby points. The new position for the point 
P on polygon A will be P =P +M, where A-is some small scaling value. In many cases the new point P will 
lie on A, [fP is not on A, it will often not even he on the surface of the polyhedron. In this case, 
we determine which edge of A that P was pushed across and also find which polygon (call it B) that shares 
this edge with A. The point P can be rotated about the common edge between A and Bso that it lies in 
the plane of B. This new point may not lie on the polygon B, but we can repeat the procedure to move 
the point onto the plane of a polygon adjacent to B. Each step of this process brings the point nearer 
to lying on a polygon and eventually this process will terminate. Most polygons of a model should have 
another polygon sharing each edge, but some polygons may have no neighbor across one or more edges. If 
a point is pushed across such an edge, the point should be moved back onto the nearest position still 
on the polygon.   Mesh Cells from Voronoi Regions The positions of these points become the locations 
of the mesh cells once relaxation has evened out the distribution of points on the surface. Now regions 
need to be formed around each point to determine adjacency of cells and to give the diffusion coefficients 
between adjacent cells. In keeping with many finite-element mesh­generation techniques. we choose to 
use the Voronoi regions of the points to form the regions surrounding the points. A description of Voronoi 
regions can be found in a book on computational geometry, e.g., I Melhom X4]. Given a set of points .S 
in a plane, the Voronoi region of a particular point P is that region on the plane where P is the closest 
point of all points in S. For points on a plane, the Voronoi regions will always be bounded by line segments 
Wsitioned halfway between pairs of points. When we simulate a diffusing system on such a set of cells, 
we will use the lengths of the edges separating pairs of cells to determine how much of a given chemical 
can move between the two cells, Figure 7d shows the Voronoi regions for the set of points shown in Figure 
7c, Finding the exact Vorcmoi regions of the points on a polyhedral surface is not simple since one of 
these regions might be parts of several different polygons. Instead of solving this exactly, a planar 
variation of the exact Voronoi region for a point is used to determine the lengths of edges between cells. 
Using the same procedure as before, all points near a given point P are mapped onto the plane of the 
polygon A containing P. Then the planar Voronoi region of P is constructed and the lengths of the line 
segments that form the region are calculated. It is the lengths of these segments that are used as the 
diffusion coefficients between pairs of cells. In general, computing the Voronoi regions for n points 
in a plane has a computational complexity of CS(nlog n) [Melhom 84]. However, the relaxation process 
distributes points evenly over the surface of the object so that all points that contribute to the Voronoi 
region of a point can be found by looking only at those points within a small fixed distance from that 
point. in practice we have found that we need only consider those points within 2rof a given point to 
construct a Voronoi region, where r is the radius of repulsion used in the relaxation process. Because 
unifomr spatial subdivision can be used to find these points in a constant amount of time, constructing 
the Voronoi regions is of O(n) complexity in this case. The above construction of the Voronoi regions 
assumes that the diffusion over a surface is isotropic (has no preferred direction). The striking textures 
in [Witkin and Kass 9 I ] show that simulation of aoisotropy can add to the richness of patterns generated 
with reaction-diffusion. Given a vector field overa polyhedral surface, we can simulate anisotropic diffusion 
on the surface if we take into account the anisotropy during the construction of the Voronoi regions. 
This is done by contracting the positions of nearby points in the direction of anisotropy after projecting 
neighboring points onto a given point s plane. Then the Voronoi region around the point is constructed 
based on these new positions of nearby points. flse contraction affects the lengths of the line segments 
separating the cells, and thus affects the diffusion coefficients between cel 1s. This contraction will 
also affect which cells are neighbors. Ftgure 8 shows that anisotropic diffusion creates spots that are 
stretched when Turing s system is simulated on the surface of a model.  Reaction-Diffusion on a Mesh 
We can create any of the reaction-diffusion patterns described earlier on the surface of any polyhedral 
model by simulating the appropriate chemical system directly on a mesh for the model. The square cells 
of a regular grid are now replaced by the Voronoi regions that comprise the cells of the mesh. Simulation 
proceeds exactly as before except that calculation of the Laplacian terms now takes into account that 
the segments that form the boundaries of the cel 1sare not all the same length. These boundary lengths 
are the diffusion coefficients, and the collection of coefficients at each cell should be normalized 
so they sum to one. V2a is computed at a particular cell by multiplying each diffusion coefficient of 
the cell by the value of a at the corresponding neighboring cell, summing these values for all neighboring 
cells, and subtracting the value of a at the given cell. This value should then be multiplied by four 
to match the feature sizes generated on the regular square grid. When the simulation is complete, we 
have a concentration for each participating chemical at each cell in the mesh. The next section tells 
how these concentrations are rendered as textures. Rendering Once the simulation on a mesh is finished, 
we require a method for displaying the resulting chemical concentrations as a texture. First, we need 
a smooth way of interpolating the chemical concentrations across the surface. The chemical value can 
then be used as input to a function that maps chemical concentration to color. We have chosen to let 
the chemical concentration at a location be a weighted sum of the concentrations at mesh points that 
fall within a given radius of the location. If the chemical concentration at a nearby mesh cell Q is 
v(Q), the value v (P) of an arbitrary point P on the surface is: ~v(Q)w(lP -Q1/.Y) v (P) =Qmarp ~w(lP 
-Q1/.r) Q lEar P The weighting function w can be any function that monotonically decreases in the range 
zero to one, The function used for the images in this papw is: w(d)= 2d-3d2+l if OSd Sl   W(d)=o ifd> 
1 This function falls smoothly from the value I down to O in the range [0, 1], and its first derivative 
is zero at O and at I [Pedin and Hoffert 891. Any similar function that falls off smoothly could be used 
for  d=r/ loo ,qr = (v (P) -v (P + 140,0])) / d gy = (v (P) -v (P + [O,d,O])) / d ~:= (}, (P) -v (P 
+ [O,O,dJ)) / d perturbation vector = [k * g.x,k * g-y,k * g:] The above method for computing the gradient 
of v evaluates the function at P and at three nearby points in each of the x, y and I directions. The 
value d is taken to be a small fraction of the repulsive radius r to make sure we stay close enough to 
P that we get an accurate estimate for the gradient. The gradient can also be computed directly from 
the definition of\ by calculating exactly the partial derivatives in x, y and z. The scalar parameter 
k is used to scale the bump features, and changing k s sign causes bumps to become indentations and vice 
versa. Figure 10 shows bumps created in this manner based the results of a reaction-diffusion system. 
Implementation and Performance Creatinga textureusing reaction-diffusionfor a given model can b a CPU-intensive 
task. Each of the textures in Figures 4,5 and 6 took several hours to generateonaDEC3100 workstation. 
These meshes contained 64,000 points. Perhaps there is some consolation in the thought that nature requires 
the same order of magnitude in time to lay down such a pattern in an embryo. Such texture synthesis times 
would seem to prohibit much experimenting with reaction-diffusion textures. It is fortunate that a given 
reaction-diffusion system with a particular set of parameters produces the same texture features on small 
square grids as the features from a simulation on much larger meshes. The patterns in this paper were 
first simulated on a 64 x 64 grid of cells where the simulations required less than a minute to finish. 
These simulations were mn on a Maspar MP-1, which is a SIMD computer with 4096 processing elements connected 
in a two­dimensional grid. A workstation such as a DEC 3100 can perform similar simulations on a 32 x 
32 grid in about two minutes, which is fast enough to explore new textures. Once a texture is generated 
by reaction-diffusion, the time to render the model with a texture is reasonably fast. The image in Figure 
4 required 70 seconds to render at 512 x 512 resolution without anti-aliasing on a DEC 3100. The same 
horse without texture takes 16 seconds to render. Future Work The cascade processes that formed the 
textures in this paper are just a few of the patterns that can be generated by reaction-diffusion. More 
exploration should be made on how one chemical system can leave a pattern for later systems. For example, 
one chemical system could affect the random substrate of a second system. What patterns can be formed 
if one system causes different rates of diffusion in different locations in a second system? Other methods 
of pattern creation could be performed on the meshes used for texture synthesis. Examples that might 
be adapted from cellular automata [Toffoli and Margolus 87] include two­dimensional annealing, diffusion-limited 
aggregation and the Belousov-Zhabotinskii reaction. Acknowledgments 1 would like to thank those people 
who have offered ideas and encouragement for this work. These people include David Banks, Henry Fuchs, 
Albert Harris, Steve Molnar, Brice Tebbs, and Turner Whitted. Thanks also for the suggestions provided 
by the anonymous reviewers. Linda Houseman helped cleanup my writing and David Ells worth provided valuable 
photographic assistance. Thanks to Rhythm&#38; Hues for the horse, Steve Speer for the giraffe and Apple 
Computer s Vivarium Program for the sea-slug. This work was supported by a Graduate Fellowship from IBM 
and by the Pixel-Planes project. Pixel-Planes is supported by the National Science Foundation (MIP-9000894) 
and the Defense Advanced Research Projects Agency, Information Science and Technology Office (Order No. 
7510). Appendix: Meinhardt s Stripe-Formation System The stripes of Figure 3 (lower images) and Figure 
6 were created with a five-chemical reaction-diffusion system given in [Meinhardt 82]. The equations 
of Meinhardt s system are as follows: In this system, the chemicals gl and gz indicate the presence of 
one or the other stripe color (white or black, for instance). The concentration of r is used to make 
sure that only one of g, and gz are present at any one location. Chemicals .s} and .S1assure that the 
regions of g, and g2 are limited in width. A program written in FORTRAN to simulate this system can be 
found in [Meinhardt 82].   References [Bard 77] Bard, Jonathan, A Unity Underlying the Different Zebra 
Striping Patterns, Journal of Zoology. Vol. 183, No. 4, pp. 527-539 (December 1977). [Bard 81] Bard, 
Jonathan B. L., A Model for Generating Aspects of Zebra and Other Mammalian Coat Patterns, Journal of 
Theoretical Bio/ogy, Vol. 93, No. 2, pp. 363 385 (November 1981). [Bard and Lauder 74] Bard, Jonathan 
and Ian Lauder, How Well Does Turing s Theory of Morphogenesis Work?, Journal ~~ Them-etica/ Biology, 
Vol. 45, No. 2, pp. 501-531 (June 1974). [Bier and Sloan 86] Bier, Enc A. and Kenneth R. Sloan, Jr., 
Two- Part Texture Mapping, IEEE Computer Graphics and App/icariorr.s, Vol. 6, No. 9, pp. 4W53 (September 
1986). [Blinn 78] Blinn, James F., Simulation of Wrinkled Surfaces, Computer Graphics, Vol. 12. No. 3 
(SIGGRAPH 78), pp. 286-292 (August 1978). [Bloomenthal 85] Bloomenthal, Jules, Modeling the Mighty Maple, 
Compufer Graphin, Vol. 19, No. 3 (SIGGRAPH 85), PP. 305-3 I I (holy 1985). [Catmull 74] Catmull, Edwin 
E., A Subdivision Algorithm for Computer Display of Curved Surfaces, Ph.D. Thesis, Department of Computer 
Science, University of Utah (December 1974).  SIGGRAPH 91 Las Veaas. 28 JuIY-2 Auaust 1991 [Gardner 
85] Gardner, Geoffrey Y., Visual Simulation of Clouds; Computer Graphics, Vol. 19, No. 3 (SIGGRAPH 85), 
pp. 297-303 (July 1985). [Hanrahan and Haeberli 90] Hanrahan, Pat and Paul Haeberli, Direct WYSIWYG Painting 
and Texturing on 3D Shapes, Computer Graphics, Vol. 24, No. 4 (SIGGRAPH 90), pp. 2 15 223 (August 1990). 
[Heckbert 89] Heckbert, Paul S., Fundamentals of Texture Mapping and Image Warping, M.S. Thesis, Department 
of Electrical Engineering and Computer Science, University of California at Berkeley (June 1989). [Ho-Le 
88] Ho-Le, K., Finite Element Mesh Generation Method* A Review and Classification: Computer Aided Design, 
Vol. 20, No. 1, pp. 27-38 (January/February 1988). [Hubel and Wiesel 79] Hubel, David H. and Torsten 
N. Wiesel, Brain Mechanisms of Vision, Scien@7c American, Vol. 241, No. 3, pp. 150-162 (September 1979). 
[Hunding 90] Hunding, Axel, Stuart A. Kauffman, and Brian C. Goodwin, Drosophila Segmentation: Supercomputer 
Simulation of Prepattem Hierarchy, Journal of Theoretical Biology, Vol. 145, pp. 369-384 (1990). [Koenderink 
84] Koenderink, Jan J., The Structure of Images, Biological Cybernetics, Vol. 50, No. 5, pp. 363 370 
(August 1984). [Lengyel and Epstein 91] Lengyel, Istvfi and Irving R. Epstein, Modeling of Turing Structures 
in the Chlorite-Io&#38;de-Malonic Acid Starch Reaction System, Science, Vol. 251, No. 4994, pp. 650-652 
(Febmary 8, 1991). [Lewis 84] Lewis, John-Peter, Texture Synthesis for Digital Painting: Computer Graphics, 
Vol. 18, No. 3 (SIGGRAPH 84), pp. 245 252 (holy 1984). [Lewis 89] Lewis, J. P., Algorithms for Solid 
Noise Synthesis~ Computer Graphics, Vol. 23, No. 3 (SIGGRAPH 89), pp. 263-270 (July 1989). [Ma and Gagalowicz 
85] Ma, Song De and Andre Gagalowicz, Determination of Local Coordinate Systems for Texture Synthesis 
on 3-D Surfaces, Eurographics 85, edited by C. E. Vandoni. [Meinhardt 82] Meinhardt, Hans, Models of 
Biological Pattern Formation, Academic Press, London, 1982. [Melhom 84] Melhom, Kurt, Multi-dimensional 
Searching and Computational Geometry, Springer-Verlag, 1984. [Murray 81] Murray, J. D., Gn Pattern Formation 
Mechanisms for Lepidopteran Wing Patterns and Mammalian Coat Markings, Philosophical Transactions of 
the Royal Society B, Vol. 295,pp. 473496. [Peachey 85] Peachey, Darwyn R., Solid Texturing of Complex 
Surfaces, Computer Graphics, Vol. 19, No. 3 (SIGGRAPH 85), pp. 279-286 (July 1985), [Perlkr 85] Perlin, 
Ken, An Image Synthesizer, Computer Graphics, Vol. 19, No. 3 (SIGGRAPH 85), pp. 287-296 (July 1985). 
[Perlin and Hoffert 89] Perlin, Ken and Eric M. Hoffert, HypertexturevC omputerGraphics, Vol. 23,N0. 
3 (SIGGRAPH 89), pp. 253-262 (July 1989). [Samek 86] Samek, Marcel, Cheryl SIean and Hank Weghorst, Texture 
Mapping and Distortion in Digital Graphics; The Visual Computer, Vol. 2, No. 5, pp. 313-320 (September 
1986). [Toffoli and Margolus 87] Toffoli,Tommaso and Norman Margolus, Cellular Automata Machines, MIT 
Press, 1987. [Turing 52] Turing, Alan, Tire Chemical Basis of Morphogenesis, Philosophical Transactions 
of the Royal Society B, Vol. 237, pp. 37-72 (August 14, 1952). [Turk 90] Turk, Greg, Generating Random 
Points in Triangles, in Graphics Gems, edited by Andrew Glassner, Academic Press, 1990. [Williams 83] 
Williams, Lance, PyrarnidalParametncs, Computer Graphics, Vol. 17, No. 3(SIGGRAPH 83),pp.1-11 (July 1983). 
[Witiln ~d Kass91] Witiln, Andrew and Michael Kass, Reaction-Diffusion Textures, Computer Graphics, Vol. 
25 (SIGGRAPH 91). [Yeager and Upson] Yeager, Larry and Craig Upson, Combining Physical and Visual Simulation 
 Creation of the Planet Jupiter for the Film 2010, Computer Graphics, Vol. 20, No. 4 (SIGGRAPH 86), pp. 
85-93 (August 1986).  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122750</article_id>
		<sort_key>299</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Reaction-diffusion textures]]></title>
		<page_from>299</page_from>
		<page_to>308</page_to>
		<doi_number>10.1145/122718.122750</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122750</url>
		<abstract>
			<par><![CDATA[We present a method for texture synthesis based on the simulation of a process of local nonlinear interaction, called reaction-diffusion, which has been proposed as a model of biological pattern formation. We extend traditional reaction-diffusion systems by allowing anisotropic and spatially non-uniform diffusion, as well as multiple competing directions of diffusion. We adapt reaction-diffusion system to the needs of computer graphics by presenting a method to synthesize patterns which compensate for the effects of non-uniform surface parameterization. Finally, we develop efficient algorithms for simulating reaction-diffusion systems and display a collection of resulting textures using standard texture- and displacement-mapping techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[natural phenomena]]></kw>
			<kw><![CDATA[texture synthesis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003727.10003729</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Differential equations->Partial differential equations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P18516</person_id>
				<author_profile_id><![CDATA[81100295587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Witkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[School Of Computer Science, Carnegie Mellon University, Pittsburgh, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032842</person_id>
				<author_profile_id><![CDATA[81100215003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kass]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Advanced Technnology Group, Apple Computer, Cupertino, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jonathan Bard and lan Lauder. How well does turing's theory of morphogenesis work? Journal of Theoretical Biology, 45:501-531, 1974.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Jonathan B.L. Bard. A model for generating aspects of zebra and other mammalian coat patterns. Journal of Theoretical Biology, 93:501-531, 1981.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>59931</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Michael Barnsley. Fractals Everywhere. Academic Press, San Diego, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. N. Bracewell. The Fourier Transform and its Applications. McGraw-Hill, New York, 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. J. Burt. Fast hierarchical correlations with gaussianlike kernels. Technical Report TR 860, Dept. of Computer Science, U. of Maryland, 1980.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>84123</ref_obj_id>
				<ref_obj_pid>84119</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Ei and M. Mimura. Pattern formation in heterogeneous reaction-diffusion-advection systems with an application to population dynamics. SIAM J. on Mathematical Analysis, 21(2):346-361, 1990.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Andre Gagalowicz and Song De Ma. Sequential synthesis of natural textures. CVGIP, 30:289-315, 1985.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[W. Hackbusch. Multi-Grid Methods and Applications. Springer-Verlag, New York, 1985.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27996</ref_obj_id>
				<ref_obj_pid>27993</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Michael Kass and Andrew Witkin. Analyzing oriented patterns. Computer Vision, Graphics and Image Processing, 37:362-385, 1987.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Granino Korn and Thresa Korn. Mathematical Handbook for Scientists and Engineers. McGraw Hill, New York, 1968.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Kunish and H. Schelch. Parameter estimation in a special reaction-diffusion system modelling man-environment diseases. Journal of Mathematical Biology, 27(6):633-665, 1989.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. Mandelbrot. Fractals: Form, Chance, and Dimension. W.H. Freeman, San Fransico, 1977.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97921</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kazunori Miyata. A method of generating stone wall patterns. Computer Graphics, 24(4):387-394, 1990.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. D. Murray. On pattern formation mechanisms for lepidopteran wing patterns and mammalian coat markings. Philosophical Transactions of the Royal Society (B), 295:473--496, 1981.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. D. Murray. A pre-pattern formation mechanism for animal coat markings. Journal of Theoretical Biology, 88:161- 199, 1981.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Openheim and R. Schafer. Digital Signal Processing. Prentice-Hall, Englewood Cliffs, New Jersey, 1975.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Darwyn R. Peachey. Solid texturing of complex surfaces. Computer Graphics, 19:279-286, 1985.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Ken Perlin. An image synthesizer. Computer Graphics, 19:287-296, 1985.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[C. Price, P. Wambacq, and A. Ooosterlinck. Applications of reaction-diffusion equations to image processing. In Third Int. Conf. on Image Processing and its Applications, pages 49-53, 1989.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Karl Sims. Leonardo's deluge (video). Siggraph '89 Computer Graphics Theater, 1989.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[M. Spivak. A Comprehensive Introduction to Differential Geometry (5 vols). Publish or Perish Press, 1975.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[N.V. Swindale. A model for the formation of ocular dominance stripes. Philosophical Transactions of the Royal Society (B), 208:243-264, 1980.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Alan Turing. The chemical basis of morphogenesis. Philosophical Transactions of the Royal Society (B), 237:37-72, 1952.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>897976</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Greg Turk. Generating synthetic textures using reactiondiffusion. Technical Report TR-90-018, University of North Carolina, Chapel Hill, 1990.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[David Young. A local activator-inhibitor model of vertebrate skin patterns. MathematicalBiosciences, 72( l ), 1984.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, JUIV 1991 Reaction-Diffusion Textures Andrew Wltkin and 
Michael Kasst Keywords Texture Synthesis: Natural Phenomena; Simulation.  Abstract We present a method 
for texture synthesis based on the sim­ulation of a process of local nonlinear interaction, called reaction-diffusion, 
which has been proposed as a model of biological pattern formation. We extend traditional reaction-diffusion 
systems by allowing anisotropic and spatially non-uniform diffusion, as well as multiple com­peting directions 
of diffusion. We adapt reaction-diffusion systems to the needs of computer graphics by presenting a method 
to synthesize patterns which compensate for the effects of non-uniform surface parameterization. Finally, 
we develop efficient algorithms for simulating reaction­diffusion systems and display a collection of 
resulting tex­tures using standard texture-and displacement-mapping techniques. Introduction Texture 
mapping techniques have become so highly de­veloped and so widely used that textureless images tend to 
appear barren, unrealistic, and boring. To date, though, techniques for synrhesizirrg natural textures 
have advanced far less than texture rendering methods. A few noise-based textures, such as marble and 
fractal bumps, have become standard (see, e.g.,[ 12, 18, 17]), and specialized methods School Of Computer 
Science, Carnegie Mellon University, Pittsburgh PA 15213. awf@cs.cmu.edu tAdvanced Technnology Group, 
Apple Computer, Cupertino, CA 95014. kassf@apple.com Pcrrmssmnto copy without fee all or part of this 
material is granted provided that the copies are not made or distributed for direct commercial advantage, 
tbc ACM copyright notice and the title of the publica[iorr iirsditsdateappear,andrs~ticeisgiventhatcopying 
is by permission of the Asstwiaticrnfor Computing Machinery. To copy o[herwtse, or to republish, requires 
a fee imd/or specific permission. for synthesizing stone walls are presented in [ 13]. In [7], a statistical 
method is presented for encoding and reproduc­ing natural textures, while [3 J describes the use of fractal 
methods for statistical texture encoding. Even so, scanned real-world images still provide a principal 
source of real­istic texture maps. In this paper, we investigate a class of patterns that arise from 
local, nonlinear interactions of excitation and inhibition. Our starting point is a chemical mechanism 
that was first proposed by Alan Turing [231 to accountfor pattern formation in biological morphogenesis. 
The basis for Turing s idea is the notion that cell properties, such as pigment production, are fixed 
during the development of the embryo in a way that depends on the concentrations of one or more chemical 
messengers which he dubbed mm-­phogerzs. He postulated that patterning is governed pri­marily by two 
concurrently operating processes: diffusion of morphogens through the tissue and chemical reucrion.s 
that produce and destroy morphogens at a rate that de­pends, among other things, on their concentrations. 
Such mechanisms are called reaction-diffusion (RD) systems. Reaction-diffusion systems give rise to nonlinear 
partial differential equations, in which the time derivative of mor­phogen concentration at each point 
in the medium is given as a function of the current concentration and of derivatives of concentration 
with respect to position. The nonlinear model largely defies analysis; its behavior must be un­derstood 
through numerical simulation. In [23], Turing extensively analyzed a linear approximation to the nonlin­ear 
equation, but lacked the computing tools 10 attack the nonlinear model numerically. Since Turing s initial 
proposal, mechanisms of this kind have been invoked to account for several biologi­cal patterns, including 
spotted and striped coats of cats, zebras and giraffes [1, 15, 2, 25, 24], the markings on certain butterfly 
wings [ 14], and the arrangement of oc­cular dominance columns in mammalian cerebral cortex [22]. Reaction-diffusion 
equations have also arisen in such diverse fieIds as image processing 119], population dynamics[6] and 
epidemiology 11 ]. [n [9] we considered ACM-O-89791-436-WY[/txf7/wr9 $(X)75 299 @@ The discrete Laplacian 
can also be expressed as the convolution of [he concentration array with the 3 x 3 mask  010 L=+ I 41. 
. 010 [1 The values in the mask simply represent the coefficients in equation 3. The convolution form 
offers the advantage that any additional terms that are linear functions of Ci,j and its neighbors may 
be readily combined to form a single 3 x 3 mask. Multiplying the Laplacian by a2, and including the term 
K i,j gives the mask o {12 o ~,2 :1[= ; 4 h~l} 02 , (4) [ *2 1 () o in terms of which equation 1 becomes 
?=31*C+R. using * to denote discrete convolution. To compute ~ using 1, we must integrate 6 through time. 
The simplest integration formula, known as Euler s method, is C,+J, = At(:t/*C t +R, ), (5) which takes 
a timestep of size At.   3 Anisotropic Diffusion The simple model of equation I assumes that diffusion 
occurs at a uniform rate in all directions and at all positions. In relaxing this restriction, we make 
it possible to produce a far wider range of patterns, including oriented patterns typical of zebra stripes 
or sand dunes. Recall that the isotropic diffusion term of equation 1 is Cd = o~(t?2C/~.r~ + 192C/8y2). 
To make C diffuse at different rates in .r and y, we replace a~ by independent rate constants for r and 
,y, so that p~ = o~d2C /~.r2 + a~#C/(9~/2. By varying a I and oz. the RD pattern can be stretched or 
compressed, but only along the two coordinate axes. To handle the general case, we introduce the Hessian 
matrix, defined by H,, =g t 1 where the vector r = [r. y]. In terms of the Hessian, the isotropic diffusion 
term is nz Tr (H ), where Tr (If), the Irate of the Hessian, is the the sum of its diagonal elements. 
For the special case of anisotropic diffusion Computer Graphics, Volume 25, Number 4, July 1991 with 
axis-aligned principal directions, we can define the matrix D= ll0 Oat [1 in terms of which ~d = Tr (D7 
FID). We model diffusion with arbitrary principal directions by rotating the matrix D to bring the .r 
and y axes onto the desired principal direc­tions, giving the diffusion term dd = Tr (DTQ l HQD), where 
Q is the rotation matrix. Rather than working with this compound matrix di­rectly, it is convenient to 
define the single diflusion ma~ri.r .4 = QTDTDQ. in terms of which the diffusion is p~ = ~, ~, .-l,J 
H,, The diffusion matrix is given by (1:Cos219+ a~sin20 (aj cl~)cosfisino .4 = (aj -af)cosflsinfl -O 
a; COS2O + o; sirt [ 1 (6) where a I is the diffusion rate in the principal direction [COS0. sin 0] and 
oz is the diffusion rate in the principal direction [ sin 0, cos 6]. When the Hessian is expressed in 
terms of finite dif­ferences, the quantity ~, ~, .4,1 H,j K , representing diffusion and dissipation, 
can be expressed as the convo­lution of C with a 3 x 3 mask which is a generalization of the isotropic 
mask given in equation 4. That mask is where a II, a 12and all are the three distinct elements of the 
symmetric matrix ,4. The Euler update formula for anisotropic diffusion still has the form C (+A, = At(.v 
* c , + A ,). but now the mask .!1 is the one given in equation 7.  3.1 Space-varying diffusion A diffusion 
matrix that is constant over position can only produce patterns whose direction and degree of elongation 
are constant as well. A further important generalization of the model is obtained by allowing the matrix 
.4 to vary with position. This is done by means of a diffusion map, an array that specifies the three 
distinct elements of .-i at each position. In practice, the diffusion map can be much coarser than the 
concentration map, with bilinear interpo­lation sufficing to obtain intermediate samples. Usually, the 
diffusion map is most naturally specified indirectly. by .E .SIGGRAPH 91 Las Vegas, 28 July-2 August 
1991 $1681Arbll­ giving [0, al, az], or often just 6, as a function of posi­tion. Direction fields may 
in turn be created in a variety of ways for example by interactive specification [20], by analyzing natural 
images [9], or through analytic forms.  4 Mapping onto surfaces A well-known difficulty with parametric 
texture mapping is that textures undergo distortion in the mapping from parameter space to the surface. 
Although solid texture methods [18, 17] are not subject to this problem, they are not well suited to 
modeling textures that actually grow on surfaces, rather than in space. Generally, it is not possible 
to correct parametric distortion by inverse warping a tex­ture after the fact. However, in this section, 
we show how RD textures may be grown in a way that incorporates the inverse warp by transforming the 
diffusion matrix. Like trick pictures that are meant to be viewed in curved mir­rors, the resulting patterns 
appear grossly distorted when viewed in parameter space, but map correctly onto the surface. The correction 
we will describe is based on a simplifying assumption that the parametric surface function is locally 
linear. Under this approximation, we correct fully for parametric stretch and shear, but not for distortion 
due to the second derivative of the parametric function. In our experience to date, this approximation 
has not produced visible artifacts. A related approach to the creation of inverse-warped statistical 
textures is describe in [7]. In a different approach, Turk [24] computes reaction diffusion textures 
directly on the vertices and edges of a polygonal mesh. Previously, we described anisotropic diffusion 
in terms of [0. a 1. a2] where 6 is the angle between the first principal direction and one of the texture 
coordinate axes, and a I and a2 are the rates in the principal directions. We wish to use essentially 
the same description for diffusion on a surface, except that 0 is to be interpreted as the angle on the 
tangent plane of the surface between one of the principal diffusion directions and an arbitrary reference 
direction, which could conveniently be chosen to be one of the two parametric directions. Of course al 
and a2 should describe the desired principal diffusion rates on the surface, not in parameter space. 
If the parametric surface function is x(u), then the .la­cobian matrix, J = 8x/i3u, serves as a basis 
for the surface s tangent plane at x, i.e. dx = Jbu is a tangent vector. First-order distortion arises 
because J generally is not orthonorrnal, so lengths and angles are not preserved. We remove the distortion 
by performing a change of vari­ables from u to V(u) such that ~x/~v is an orthonormal basis. To apply 
the correction, we then post-multiply the diffusion matrix A by the inverse of the matrix th/8u, and 
pre-multiply by the inverse transpose. To orthonormalize J, we must find a 2 x 2 matrix V such that VTJTJV 
z \ TA4V = ~, where .kf = JT J is the metric tensor of the surface, and 1 is the identity matrix. Then 
JT is by definition or­thonormal. Orthonormal bases are only unique down to a rotation, so we must also 
pick an arbitrary reference direction on the surface with respect to which d will be measured. Letting 
a = [1, 0] and /? = [0, 1], we choose Ja as the reference direction, giving the additional condi­tion 
on 1 that 3TI 0 = O, which simply means 2}21= O. This leaves a quadratic system to solve for the remaining 
components of J . Solving and inverting the matrix gives, in terms of the components of M, 1 ml  [: 
=1 8) In summary, given the desired t3relative to the [1,0] pa­rameter direction on the surface and 
the principal rates a I and a2, the corrected diffusion matrix ~ can be computed in the following steps: 
. Compute the uncorrected diffusion matrix .4, in terms of [6. a 1, a2], according to equation 6. . 
Compute the surface Jacobian J = &#38;/i3u.  . Compute the metric tensor Al = JTJ. . Evaluate ~r according 
to equation 8. . Obtain the corrected diffusion matrix by evaluating .4 = ~TA~.  The 3 x 3 convolution 
mask is then computed, and used according to equation 5 to take time steps. Figure 2 shows comparable 
textures, in parameter space and on the sur­face, with and without the correction described in this sect 
ion. 4.1 Sewing patches together Itis often difficult or impossible to describe a complex surface using 
a single parametric function. Even simple surfaces, such as the sphere, cannot be parameterized with­out 
introducing singularities. These problems cannot be solved using the correction described above. However, 
it should be possible to solve them using piecewise param­eterizations, letting each patch provide boundary 
condi­tions for its neighbors. Differential geometry provides a formalism for piecewise parameterizations 
in the construct of coordinate charts and atlases [21]. Roughly speaking, a chart is a parameterization 
for a piece of the surface, and  SIGGRAPH 91 Las Vegas, 28 JuIv-2 August 1991 to the iterative formula 
t,,+At C fo+At = C((, * GAI +h* Gu du, (11) / to where it remains to evaluate the definite time integral 
of the Green s function. Unfortunately, G is not integrable, so even the piecewise constant approximation 
to R is somewhat problematic. We have three natural choices. First, we can perform the integral numerically. 
Second, it is possible to obtain ~OmG dtby means of Hankei Functions [10], allowing us to solve each 
constant approximation to equilibrium. Third, and by far the simplest, we can render the integral trivial 
by approximating R as an impulse applied at t = t,. This option leads directly to the algorithm (12) 
 where ~ is a factor intended to correct for R s application at the beginning of the step, rather than 
throughout. To make the space integral of C after the step be the same as it would have been under a 
constant, rather than impulsive, approximation to R, this factor should be The algorithm that results 
from this approximation al­lows for diffusion with 0( rz) computation using hierar­chic convolutions 
or separable recursive approximations to Gaussians. The chief limitation is that the technique only works 
when the matrix .4 does not vary over space. Subject to this limitation, however, it offers a potentially 
dramatic performance advantage over the methods that have been used previously, particularly for large 
step sizes or high diffusion rates. Swindale [22] arrived at a similar algorithm by a different path 
in the course of modeling the formation of ocular dominance columns. 5.2 Multi Grid Another approach 
to avoiding the 0(r4) behavior of the Euler simulation is to use multi-grid techniques[8]. The basic 
idea of these techniques is to simulate the equations on a series of grids of different sizes. Iterations 
on the coarser grids allow the simulation to proceed very rapidly, while iterations on the finer grids 
provide the detail neces­sary in the final result. If the grid sizes differ by a factor of two in each 
dimension from one level to the next, then the total number of samples in the grids is approximately 
4/3 as many as in the finest grid. As a result, a constant num­ber of iterations on each of the grids 
can be accomplished in 0(r2) time. In some contexts, effective muhi-grid implementations require complex 
control strategies to switch from one grid 304 level to another. In order to synthesize reaction-diffusion 
textures, however, we have found a simple strategy to be very effective. We begin with the coarsest grid 
able to resolve details at the intrinsic scale of the pattern being synthesized. We do a small fixed 
number of iterations on that grid and then interpolate the result onto the next finer grid. This is repeated 
for all the remaining grids. Iterations on the different grids make use of the same 3 x 3 matrix .!1 
as the Euler method. The only change is that the grid­spacing h changes as we move from one grid to another. 
The resulting multi-grid method can be as efficient as the Gaussian convolution method, but is not subject 
to the limitation that the matrix A be constant.  5.3 Binary Convolution Convolutions of binary data 
with an integer-valued mask can be performed efficiently by means of lookup tables: accessing eight consecutive 
binary data points as a byte, the sum of the eight corresponding convolution values can be obtained in 
a single table lookup. Although 0(r4), bi­nary convolution may nevertheless be the fastest option for 
convolution with small masks. For reaction functions that are expressible in binary form, the algorithm 
of equation 12 may be reduced to one of iterated binary convolution by allowing the diffusion constant, 
b to grow very large, rendering the contribution of the old concentrations neg­ligible. In the resulting 
simplified algorithm, the binary reaction function is applied to the concentrations, with binary convolution 
applied to the result. Binary convolu­tion has been used previously to compute RD patterns by Young [25]. 
 6 Results Although we have described one basic pattem-forming mechanism, a wide variety of RD textures 
can be produced by varying the initial and boundary conditions, the number of morphogens involved, the 
rate constants for each, the reaction functions that govern their interactions and the manner in which 
concentrations are mapped into surface appearance. In this section we show the textures we have produced 
and describe the choices that led to their creation. All of the images that accompany this paper were 
ren­dered using Photorealistic RenderMan. RD textures were used as displacement and texture maps. In 
most images, monochrome concentration maps were used to blend be­tween pairs of colors or other parameters 
such as opacity and specularity. 6.1 Isotropic Patterns To create a simple isotropic RD pattern, we can 
use two concentration arrays C+ and C , with different diffusion @ @ Computer Graphics, Volume 25, Number 
4. JUIV 1991 rates {1+ and a -, producing convolution masks .ll+ and :11-according to equation 4. A threshold 
on the difference C+ C-serves as the reaction function: R+= R-= if(C+ > C-)thenkotherwise O (13) where 
k is a reaction constant. Starting this RD system from initial conditions which are zero except on a 
jittered diamond grid produces a roughly cellular pattern that strik­ingly resembles giraffe markings 
(figure 3-1 b). A similar pattern (3-1a), finer in scale and rendered with displace­ment mapping, looks 
reptilian. Varying the reaction rate constant k (from equation 13) over time as the pattern is formed 
produces very different results (3-4a, 3-4c). 6.2 Simple Anisotropy: Stripes The simple two-morphogen 
system used to produce the gi­mffe markings involves two morphogens diffusing isotrop­ically, but at 
different rates. Introducing anisotropy allows more freedom. If we describe an isotropic diffusion using 
triples I = [0, a 1. Oz], for each concentration map C , then branching and merging stripe patterns are 
produced with F + == [H.(s, .s], and P -= [0. (.s. d.s], which makes both morphogens diffuse at the same 
rate in the 8 direction, but different rates in the perpendicular direction. Satisfactory zebra-like 
stripes can be produced with c = 2.0, d = 1.5, s= 1.()./)= 1,0. k= l.O, h = l.O, At = .02, and C+ and 
C initialized to random noise in the interval [ 1. I]. A typical zebra pattern is shown in figure 3-4b. 
A very similar RD pattern, rendered as a displacement map with appropriate coloring, resembles rippled 
sand. The addi­tion of a tine noise-based grain texture (figure 5) enhances the effect. 6.3 Competing 
Orientations: weaves, lat­tices, and mazes The interesting behavior of the anisotropic system de­scribed 
above led us to consider more elaborate systems involving multiple orientations. The general idea we 
con­sidered was to replace the single antagonistic pair of mor­phogens with a set of such pairs, each 
pair differently oriented. Thus, a two-direction system might involve an antagonistic pair of morphogens 
biased toward horizontal diffusion. as well as a vertically biased pair. Within this framework we discovered 
two reaction func­tions that produce particularly interesting patterns. (We denote by D, the difference 
C+ C -for the ith pair of concentrations. ) The first is a max of differences (M-D), R= ~, if maxj Dj 
>P, (14) 0. otherwise. where p is a threshold, and the second, a difference of abs s (D-A): R=k, if 
abs max, D] > abs rein, D] (15) = O. otherwise. Although the D-A and M-D reaction functions appear similar, 
the patterns they produce could hardly be more different. Figure 3-3b shows a two-direction D-A texture, 
which has a maze-like appearance. In contrast, a two­direction M-D texture (3-4e) appears woven, although 
such irregularities as splitting and merging of threads give it a distinctly organic appearance. Figures 
3-2b and 3-lC show three-and five-direction M-D textures, while figure 3-2c shows a five-direction D-A 
texture. All of these derive from uniform random initial conditions. 6.4 Spatial Variation Figures 3b, 
4b, 4c. and 4d show RD patterns governed by diffusion maps. Figure 3-3d is a two-orientation M-D pattern 
grown on a radialjconcentric orientation map. Figure 3-2a shows a similar pattern, but with rotation 
of the map orientations to produce a double spiral. Figure 3­2e shows two competing nearly-radial orientations. 
Figure 3-3c shows the merger, with smoothing, of three uniform orientation fields, resembling a zebra 
s haunch markings. Figures 3-Id and 3-4d show more complicated orientation patterns. All of these diffusion 
maps were generated using simple analytic forms. 6.5 Boundary Conditions An unusual feature of RD textures 
is that texture patches that join seamlessly can be created by copying data across the boundaries at 
each iteration. This is illustrated in figure 3-2d: a texture was grown using doubly cyclic boundary 
conditions, giving it the topology of a torus. This was accomplished simply by wrapping the amay references 
across both horizontal and vertical boundaries while cal­culating the convolution C * .11. In the resulting 
pattern. the left edge joins smoothly to the right, and the upper edge to the lower. The figure shows 
how the replicated pattern tiles the image without seams. The replication itself is easily perceived, 
due to the repetition of gross features within the texture. However, the seams between the tiles are 
invisible.   7 Conclusion Texture synthesis is a hard problem because the range of natural textures, 
and of texture-forming processes, is vast. Given this diversity, we cannot expect to find a single, universal 
texture generator. Nonetheless, by identifying SIGGRAPH 91 Las Veaas, 28 JuIv-2 August 1991 processes 
that are widespread in nature, we can develop models that are broadly useful for texture synthesis. Although 
RD models have been applied to problems in a variety of fields, their use in computer graphics is in 
its infancy. Already, RD models significantly extend the range of textures that can be synthesized. Their 
character­istic organic appearance lends art interesting new element to synthetic imagery. In addition, 
RD textures have the po­tential to extend the range of surfaces to which textures can be applied because 
they can be grown to compensate for parametric distortion and joined smoothly patch to patch.  Acknowledgements 
The research reported in this paper was conducted at Carnegie Mellon University, and at Apple Computer. 
At Carnegie Mellon, work was supported in part by grants from Apple Computer and from the Siemens Corporation, 
and by an equipment grant from Silicon Graphics, Inc. Photorealistic RenderMan software, which was used 
to render all the images appearing in this paper, was provided to Carnegie Mellon through Pixar s RenderMan 
Educa­tion Program. The Space Cookies and Fungi images were created by Drew Olbrich of Carnegie Mellon. 
Drew Olbrich, Michael Gleicher, MWiarn Welch, and Wendy Plesniak provided valuable assistance. References 
[1] Jonathan Bard and Ian Lauder. How well does turing s theory of morphogenesis work? Journal of Theorerica/ 
Biology, 45:501 53 I, 1974. [2] Jonathan B.L. Bard. A model for generating aspects of zebra and other 
mammalian coat patterns. Journa/ of The­oretical Biology, 93:501-531, 1981. [3] Michael Bamsley. Fractals 
Everywhere. Academic Press, San Diego, 1988. [4] R. N. Bracewell. The Fourier Transform and its Applica­tions. 
McGraw-Hill, New York, 1986. [5] P. J. Burt. Fast hierarchical correlations with gaussian­like kernels. 
Technical Report TR 860, Dept. of Computer Science, U. of Maryland, 1980. [6] S. Ei and M. Mimura. Pattern 
formation in heterogeneous reaction-diffusion-advection systems with an application to population dynamics. 
SIAM J. on Mathematical Analysis, 21(2):346-361, 1990. [7] Andre Gagalowicz and Song De Ma. Sequential 
synthesis of natural textures. CVGIP, 30:289-315, 1985. [8] W. Hackbusch. Multi-Grid Methods and Applications. 
Springer-Verlag, New York, 1985. [9] Michael Kass and Andrew Witkin. Analyzing oriented pat­terns. Computer 
Vision, Graphics and Image Processing, 37:362-385, 1987. 10] Granino Kom and Thresa Kom. Mathematical 
Handbook for Scientists and Engineers. McGraw Hill, New York, 1968. 11] K, Kunish and H. Schelch. Parameter 
estimation in a spe­cial reaction-diffusion system modelling man-environment diseases. Journal ofMathematicalBiology, 
27(6):633-665, 1989. 12] B. Mandelbrot. Fractals: Form, Chance, and Dimension. W.H. Freeman, San Fransico, 
1977. 13] Kazunori Miyata. A method of generating stone wall pat­terns. Computer Graphics, 24(4):387 
394, 1990, [14] J. D. Murray. On pattern formation mechanisms for Iepidopteran wing patterns and mammalian 
coat mark­ings. Philosophical Transactions of the Royal Society (B), 295:473-496, 1981. [15] J. D. Murray. 
A pre-pattem formation mechanism for ani­mal coat markings. Journal ofTheoretica/Biology, 88:161 199, 
1981. 16] A. Operrheim and R. Schafer. Digitai Signal Processin~. Prentice-Hall, Englewood Cliffs, New 
Jersey, 1975. I 7] Darwyn R. Peachey. Solid texturing of complex surfaces. Computer Graphics, 19:279-286, 
1985. [18] Ken Perlin. An image synthesizer. Compu(er Graphics, 19:287 296, 1985. [19] C. Price, P. Wambacq, 
and A. Ooosterlinck. Applications of reaction-diffusion equations to image processing. In Third Int. 
Conf. on Image Processing and its Applications, pages 49 53, 1989. [20] Karl Sims. Leonardo s deluge 
(video). Siggraph 89 Com­puter Graphics Theater, 1989. [2 I ] M. Spivak. A Comprehensii e Introduction 
to Di~erential Geometry (5 vol.r). Publish or Perish Press, 1975. [22] N.V. Swindale. A model for the 
formation of ocular dom­inance stripes. Philosophical Transactions of the Royal Society (B), 208:243-264, 
1980. [23] Alan Turing. The chemical basis of morphogenesis. Philo­sophical Transactions of the Royal 
Society (B), 237:37 72, 1952. [24] Greg Turk. Generating synthetic textures using reaction­diffusion. 
Technical Report TR-90-O 18, University of North Carolina, Chapel Hill, 1990. [25] David Young. A local 
activator-inhibitor model of verte­brate skin patterns. Mathemarica/Biosciences, 72( 1), i 984.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122751</article_id>
		<sort_key>309</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Spot noise texture synthesis for data visualization]]></title>
		<page_from>309</page_from>
		<page_to>318</page_to>
		<doi_number>10.1145/122718.122751</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122751</url>
		<abstract>
			<par><![CDATA[The use of stochastic texture for the visualization of scalar and vector fields over surfaces is discussed. Current techniques for texture synthesis are not suitable, because they do not provide local control, and are not suited for the design of textures. A new technique, <i>spot noise</i>, is presented that does provide these features. Spot noise is synthesized by addition of randomly weighted and positioned spots. Local control of the texture is realized by variation of the spot. The spot is a useful primitive for texture design, because, in general, the relations between features of the spot and features of the texture are straightforward. Various examples and applications are shown. Spot noise lends itself well for the synthesis of texture over curved surfaces, and is therefore an alternative to solid texturing. The relations of spot noise with a variety of other techniques, such as radom faults, filtering, sparse convolution, and particle systems, are discussed. It appears that spot noise provides a new perspective on those techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[flow visualization]]></kw>
			<kw><![CDATA[fractals]]></kw>
			<kw><![CDATA[particle systems]]></kw>
			<kw><![CDATA[scientific visualization]]></kw>
			<kw><![CDATA[texture synthesis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Fractals</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010372</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Rendering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P135241</person_id>
				<author_profile_id><![CDATA[81100381561]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jarke]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[van Wijk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Netherlands Energy Research Foundation ECN, P.O. BOX 1, 1755 ZG Petten, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>507101</ref_obj_id>
				<ref_obj_pid>965139</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BLtNN, J.F. Simulation of wrinkled surfaces. Computer ~,raphics 12, 3, (1978), 286-292.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>907242</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[CATMULL, E. A subdivision algorithm fop computer display of curved surfaces. Ph.D. Thesis, Report UTEC-CSc-74- 133, Computer Science Department, University of Utah, Salt Lake City, 1974.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[CHAMPENEY, D.C. Fourier transforms and their physical applications. Academic Press, London, 1973.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[DALLINGA, R. Seakeeping characteristics of SWATH vessels. In Proceedings 13th WEGEMT Graduate st'hool on design techniques fi;r advant'ed marine vehicles and high speed displacement ships, Delft University of Technology, 1989.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325182</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[DIPPE, M.A.Z., AND WOLD, E.H. Anti-aliasing through stochastic sampling. Computer Graphit's 19, 3 (1985), 69-78.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83821</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[FOLEY, J.D., DAM, A. VAN, FEINER, S.K. AND HUGHES, J.F. Computer ,graphics: principles and practice. Second edition, Addison-Wesley, Reading, MA. 1990.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>358553</ref_obj_id>
				<ref_obj_pid>358523</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[FOURNIER A., FUSSEL, D. AND CARPENTER, L. Computer rendering of stochastic models. Communications ACM 25, 6 (1982), 371-384.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15894</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[FOURNIER, A., AND REEVES, W.T. A simple model of ocean waves. Computer Graphics 20, 4 (1986), 75-84.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[GAGALOWICZ, A., AND MA, S.D. Sequential synthesis of natural textures. Computer Graphics, Vision, and Image Processing 30 (1985), 289-315.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>22881</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[GONZALEZ, R., AND WlNTZ P. Digital image processing. Second edition, Addison-Wesley, Reading, MA, 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97902</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[HAEBERLI, P. Paint by numbers: abstract image representations. Computer Graphics 24, 4 (1990), 207-214.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>13027</ref_obj_id>
				<ref_obj_pid>13021</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[HECKBERT, P.S. Survey of texture mapping. IEEE Computer Graphics and Applications 6, I I (1986), 56-67.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[JANSEN, F.W., AND WIJK, J.J. VAN. Previewing techniques in raster graphics. Computer &amp; Graphics 8, 2 (1984), 149-161.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[JULESZ, B. Visual pattern discrimination. IRE Trans. Inform. Theory, IT-8 (1962), 84-92.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378513</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[KRUEGER, W. Intensity fluctuations and natural texturing. Computer Graphics 22,4 (1988), 213-220.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>99312</ref_obj_id>
				<ref_obj_pid>99307</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[KRUEGER, W. Volume rendering and data feature enhancement. In Grave, M., and Y. le Lous (eds.), Proceedings of the Eurographics Workshop on Visualization in Scientific Computing, to be published by Springer-Verlag, Berlin.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808605</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[LEWIS, J.P. Texture synthesis for digital painting. Computer Graphics 18, 3 (1984), 245-252.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>35069</ref_obj_id>
				<ref_obj_pid>35068</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[LEWIS, J.P. Generalized stochastic subdivision. ACM Transactions on Graphics 6,3 (1987), 167-190.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74360</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[LEWlS, J.P. Algorithms for solid noise synthesis. Computer Graphics 23, 3 (1989), 263-270.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[MA, S.D., AND GAGALOWlCZ, A. Determination of local coordinate systems for texture synthesis for 3-D surfaces. In Vandoni, C.E. (ed.), Proceedings Eurographics'85, North-Holland, 1985, 109-118.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[MANDELBROT, B.B. The fractal geometry of nature. W.H. Freeman and Co., New York, 1982.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>806820</ref_obj_id>
				<ref_obj_pid>965161</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[MAX, N. Vectorized procedural models for natural terrains: waves and islands in the sunset. Computer Graphics 15, 3 (1981), 317-324.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[MONNE, J., SCHMIIT, F. AND MASSALOUX, D. Bidimensional texture synthesis by Markov chains. Computer Graphics and Image Processing 17 (198 i), 1-23.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74337</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[MUSGRAVE, F.K., KOLB, C.E. AND MACE, R.S. The synthesis and rendering of eroded fractal terrains. Computer Graphics 23, 3 (1989), 41-50.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[PEACHEY, D.R. Solid texturing of complex surfaces. Computer Graphics 19, 3 (1985), 279-286.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15893</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[PEACHEY, D.R. Modeling waves and surf. Computer Graphics 20, 4 (1986), 65-74.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_obj_id>61153</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[PEITGEN, H.-O., AND SAUPE, D. (eds.). The science offractal images. Springer-Verlag, New York, 1988.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[PERLIN, K. An image synthesizer. Computer Graphics 19, 3 (1985), 287-296.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[RAVEN, H.C. Variations on a theme by Dawson. In Proceedings of the 17th Symposium on Naval Hydrodynamics, The Hague, 1988, 151-172.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
			<ref>
				<ref_obj_id>801167</ref_obj_id>
				<ref_obj_pid>964967</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[REEVES, W.T. Particle systems - a technique for modeling a class of fuzzy objects. Computer Graphics 17, 3 (1983), 389-399.]]></ref_text>
				<ref_id>30</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325250</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[REEVES, W.T., AND BEAU, R. Approximate and probabilistic algorithms for shading and rendering structured particle systems. Computer Graphics 19, 3 (1985), 313-322.]]></ref_text>
				<ref_id>31</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97923</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[SIMS, K. Particle animation and rendering using data parallel computation. Computer Graphics 24, 4 (1990), 405- 413.]]></ref_text>
				<ref_id>32</ref_id>
			</ref>
			<ref>
				<ref_obj_id>33404</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[TUFTE, E.R. The visual display of quantitative information. Graphics Press, Cheshire, Connecticut, 1983.]]></ref_text>
				<ref_id>33</ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[UPSON, C. The visual simulation of amorphous phenomena. Visual Computer I, 2 (1986), 321-326.]]></ref_text>
				<ref_id>34</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617498</ref_obj_id>
				<ref_obj_pid>616006</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[UPSON, C. ET AL. The Application Visualization System: a computational environment for scientific visualization. IEEE Computer Graphics and Applications 9, 4 (1989), 30-42.]]></ref_text>
				<ref_id>35</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[WL~K, J.J. VAN, BRONSVOORT, W.F., AND JANSEN, F.W. Some issues in designing user interfaces to 3D raster graphics. Computer Graphics Forum 4 (1985), 5-10.]]></ref_text>
				<ref_id>36</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[WIJK, J.J. VAN. Rendering lines on curved surfaces. In Grave, M., and Y. le Lous (eds.), Proceedings of the Eurographics Workshop on Visualization in Scientific Computing, to be published by Springer-Vedag, Berlin.]]></ref_text>
				<ref_id>37</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[WIJK, J.J. VAN. A raster graphics approach to flow visualization, in Vandoni, C.E., and D.A. Duce (eds.), Proceedings Eurographics'90, North-Holland, Amsterdam, 1990, 251-259.]]></ref_text>
				<ref_id>38</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, JiJly 1991 Spot Noise Texture Synthesis for Data Visualization 
Jarke J. van Wijk Netherlands Energy Research Foundation ECN P.O. BO.Y 1, 1755 ZG Petten, The Netherlands 
ABSTRACT The use of stochastic textures for the visualization of scalar and vector fields over surfaces 
is discussed. Current techniques for texture synthesis are not suitable, because they do not provide 
local control, and are not suited for the design of textures. A new technique, .YprMnoise, is presented 
that does provide these features. Spot noise is synthesized by addition of randomly weighted and positioned 
spots. Local control of the texture is realized by variation of the spot, The spot is a useful primitive 
for texture design, because, in general, the relations between features of the spot and features of the 
texture are straightfor­ward. Various examples and applications are shown, spot noise lends itself well 
for the synthesis of [exture over curved surfaces, and is therefore an alternative to solid texturing, 
The relations of spot noise with a variety of other techniques, such as random faults, tittering, sparse 
convolution, and particle sys­tems, are discussed. It appears that spot noise provides a new perspective 
on those techniques. CR categories and subject descriptors: 1.3.3 [Computer Graphics]: Picture/image 
generation; 1.3.7 [Computer Graph­ics]: Three Dimensional Graphics and Realism -color, shading, and texture. 
Keywords: texture synthesis, scientific visualization, flow visu­alization, fractals, particle systems. 
1 INTRODUCTION Scalar and vector tields over surfaces have many applications, ranging from common scalar 
functions of two variables, used in many disciplines, to the distribution of pressure and velocity over 
a ship hull or the wings of an airplane. The topic of this paper is the use of texture, loosely defined 
as the local variation in visual properties, for the visualization of fields over surfaces. Tufte [33] 
has shown that the use of fixed patterns leads to poor results. A better result can be expected if the 
texture is based on a stochastic, rather than a deterministic model. Several terms are used for such 
textures: stochastic textures, random fields, and noises. Permission [u copy wilhou((CCall nr part of 
this material is granted provded [ha{ the cop)es are nut made ur distributed for direct ctmlmcrclal iuivmrtagc. 
the ACM copyright mmcc and the ti!le of the ptrbl!catmn imd Its date appear, and notice is given thatcupyirrg 
is hy permission ,)f the Assocmtion for Computing Machinery Tu copy t)[herwise, (w to rcpuhlish, requires 
a fee wrd/or yxcitic permission. Applications of stochastic texture in scientific visualization are rare. 
Krueger [ 16] has used texture to show the differences between related data sets. In the context of flow 
visualization it has been noted [34, 35, 38] that the simulation of particle con­vection leads to texture. 
If many particles are used, the indivi­dual particles cannot be distinguished any more and clouds, smoke 
and other typical textures that are well known in experi­mental flow visualization are perceived. These 
applications show that texture is a useful concept for scientific visualization, but it is not clear 
how the proposed techniques should be used for other applications. [n this paper a more general approach 
to the design and syn­thesis of texture for scientific visualization is presented. In sec­tion 2 the 
requirements are drawn up, and current techniques for texture synthesis are discussed. It appears that 
the techniques used for the synthesis of realistic textures do not fulfill these requirements. In section 
3 spot noise is introduced. Its syn­thesis is based on the principle that the random placement of a small 
pattern, the spot, over a surface leads to texture. In sec­tion 4 it is shown that this technique is 
very appropriate for the design of textures, because the relations between the features of the spot and 
those of the corresponding texture are straightfor­ward. In section 5 various applications of spot noise 
are presented, for data visualization and for image synthesis. In section 6 spot noise is compared with 
existing techniques. and directions for further research are indicated. Finally. in section 7 conclusions 
are drawn. 2 TEXTURE FOR DATA VISUALIZATION 2.1 Requirements Figure I shows a data flow diagram of texture 
synthesis for data visualization. The parameter vaiues for the texture synthesis pro­cess are determined 
in two steps. First, the data are retrieved that correspond to the texture cmrdinates; second, these 
data are converted into parameter values according to a data mapping specified by a designer. Tbe term 
de.sigrrer is used here func­tionality: it can be an expert in visuai communication, but also a researcher 
that wants to visualize his data. With this diagram in mind, the requirements on texture synthesis can 
easily be derived. They-fall into two categories; texture generation and design. The synthesis technique 
has to ailow for non-stationary textures to express the variation in the data. Further. the model has 
to allow for a wide range of textures. The aim of realism is replaced by the aim of expressiveness: it 
must b-e possible for the designer to choose a texture that matches with the nature of the data, and 
variations in the data must lead to clear variations ACM -[)-89791-436-8/91/[X)7/0309 $00 7s  SIGGRAPH 
91 Las Vegas, 28 July-2 August 1991 I Application / Y texture coordinates data data mapping data designer 
visualization Fig. 1 Data flow diagram texture synthesis for data visualization in the texture. The selection 
of a suitable data mapping is an iterative design process. The efficiency of this pmeess depends on several 
aspects. Obviously, the synthesis of the texture has to be efficient. Another way to improve efficiency 
is to use previews, simplified versions of the final result, during the design phase [13]. Finally, the 
number of iterations can be reduced if the relation between the specification and the resulting texture 
is clear to the designer [36]. The closest relation is one-to-one, but in order to limit the designer 
s work we further require that the specification should be of a suitable level: instead of draw­ing the 
texture himself, the designer must be enabled to specify the features of the texture and their relation 
with the data on a higher level. Summarizing, a synthesis technique is required for non­stationary textures 
that cart be specified in a simple, predictable way. In section 2.2 an overview is presented of the main 
current techniques for texture synthesis. In section 2.3 they are tested against our requirements. 2.2 
Texture synthesis Stochastic textures are realizations of a statistical model. There is a general consensus, 
supported by evidence from perception research [14], that second-order, or pairwise statistics suffice 
for the description of textures that can be discriminated by human observers. Techniques that use the 
full second-order statistics [23, 9] are very general and give impressive results [9]. However, they 
are also quite involved and have a brute­force character. A convenient simplification is the restriction 
to so-called Gaus­sian textures. This simplification is similar to the common simplification for first-order 
statistics: if a normal or Gaussian distribution is assumed, the distribution can be fully described 
by its mean and variance. Gaussian textures are described by their autoeorrelation function CJ (~), which 
is the correlation of two random samples of ~ at an interval T. For a one­dimensional stochastic function 
~(r) with zero mean it is defined as Cf(r)=<f(r)f(f+T)>,  where triangular brackets denote averages 
over many samples. C,(0) equals the variance d of ~. If C f (T) =0, the function ~ is completely uncorrelated 
for samples at distance r. For com­mon stochastic functions, Cf (@ approaches O with increasing ~. A 
strongly related technique is spectral modeling, which is based on the use of power spectra. The power 
spectrum P, ((o) of a stochastic function ~(t) is Pf (0.))= #i + lFAto) 12, 310 where F~(tD) is the 
Fourier transform of a sample of ~ (f ) with length T. According to the Wiener-Khintchine relation [3], 
the autocorrelation function and the power spectrum provide equivalent information, because they are 
a Fourier transform pai~ The standard approach of spectral modeling is to filter white noise (with a 
constant power speett-um) with a transfer function H(w). Voss [27] has used this technique to generate 
fractal tex­tures and terrains: noises with power spectra ~ ~. These noises are generalizations of Brownian 
motion (~ = 2), and are called fractal Brownian motions (tBm) [21, 27]. The first simulations of fBm 
were based on considering Brownian motion as the cumulative displacement of a series of independent jumps 
or pulses [21 ]. This technique is generalized to surfaces by using random faults instead of random jumps. 
Foutnier, Fussel, and Carpenter [7] use stochastic subdivision to generate fractal terrains. Lewis [18] 
has generalized the sto­chastic subdivision technique for arbitrary power spectra and autocorrelation 
functions. In [17] a technique is described for the synthesis of textures for digital painting. These 
textures are the result of weighted addl­tions of a displaced, windowed texture sample, where the weights 
and displacements are chosen randomly. This process is equivalent to an out-of-order convolution of the 
sample with a sparse, white noise, hence it is named sparse convolution. Perlin [28] generates solid 
textures through the composition of non-linear functions. For stochastic textures he defines the function 
Noise (x) as a modeling primitive. This function is band-limited, statistically invariant under translations 
(stationary) and statistically invariant under rotations (isotropic). Fractal textures are modeled as 
linear combhations of the scaled noise function: Noise (2i x) f(x)=~ L, k In a similar way turbulence, 
marble and a variety of other natural textures can be modeled. 2.3 Evaluation The issue of local variation 
of texture is not mentioned in most of the literature. An exception is Lewis [18], who states that local 
variations of the texture may be effected by varying the model parameters or by simple postprocessing 
techniques, rather than by incorporating these variations in the original model. Both approaches are 
used by Musgrave et al. [24] for the syn­thesis of eroded terrain. His technique for the initial synthesis 
of the fractal terrain is based on Perlin s: the weights for the Noise function are functions of the 
altitude. This works well for isotropic textures, but the implementation of artisotropic tex­tures with 
local variations is less straightforward. For instance, if we want to visualize a 2-D flow veloeity field 
v(x) with an artisotropic texture, such that the dominant direction aligns with the direction of the 
flow, a natural sohstion would be: f(x) = Noise (x -(xv) v). Here the primitive Noise texture is stretched 
according to the magnitude and direction of the vebeity. If v(x) is constant, this gives the desired 
result, in most other cases, however, it does not. Other solutions in the same spirit could be devised, 
but they all share the same deficit: local deformations of texture cannot be modeled by global transformations 
(scaling etc.) of a  @ @ Comcmter Graphics, Volume 25, Number 4. Julv 1991 texture. The direct spectral 
approach and the random fault technique are not suitable for local, spatial control. With the other techniques 
it is indeed possible to vary the parameters as a function of space, but the Iiterature does not make 
clear how this should be done to realize a desired effect. This is related to the next point of our evaluation: 
the design of textures. As most authors aim at realism, again this issue is not mentioned often. The 
examples given in [28] for the construc­tion of solid textures are based on more or less simplified models 
of physical processes. In [23, 9] the second-order statis­tics are derived by sampling real-world textures, 
for the genera­tion of fractal terrains the power spectrum ~-~ is used as a start­ing point 121, 7, 27]. 
Let us therefore consider possible ways for a designer to specify a texture. For spectral modeling three 
options are available. First, a designer can enter a sample of the desired texture, from which the desired 
parameters are derived, However, it is not simple to render a suitable texture by hand. Further, the 
tauto­logical character of this solution strongly suggests rejecting it. Second, the designer could enter 
an autocorrelation function. Advantages of the autocorrelation function are that the spatial domain is 
more familiar to most people than the spectral domain, and it directly reflects features such as the 
scale, period of oscillation, and directional tendencies. Although this is cer­tainly true if a given 
autocorrelation function is analyzed, the design of an autocomelation function, especially in two dimen­sions, 
is far less simple. Another severe problem is further that not every autocomelation function leads to 
a realizable texture, because its Fourier transform, the power spectrum, must be non­negative. As a third 
approach, the designer could specify the power spectrum. In [ 17] it is stated that it is possible to 
acquire an intuitive feel for the relation between a painted spectrum and its corresponding texture. 
The author of that article could reli­ably paint spectra to simulate some textures, but this might be 
different for an arbitrary designer. Besides the specification of a standard texture, the designer also 
has to specify how the texture has to be varied as a function of the data, which aggravates the problems 
of the three discussed options. As a conclusion, we can state that no current technique for tex­ture 
synthesis provides an easy solution that satisfies our requirements for data visualization. This can 
be explained from the difference between the applications. Traditionally, the focus is on the synthesis 
of realistic, stationary textures, whereas for the application discussed here clarity, ease of design, 
and local control are the main requirements. In the next sections, a tex­ture synthesis technique is 
described that was developed with those requirements in mind. 3 SPOT NOISE 3.1 Definition In this section 
a texture for data visualization is presented: spoi noise. Spot noise has strong relations with the techniques 
dis­cussed in the previous sections. The specific advantages of spot noise will emerge in practical applications, 
discussed in section 4 and 5. Spot noise is the spatial analogue of shot noise. Shot noise [3] is a special 
kind of random function that has many applications in engineering. It is produced by the successive repetition 
at random intervals of independent pulses, If each pulse produces the protile u, h (f f, ), the resultant 
function j (f) is thus .f(f)=~a, h(r -r,), where the values t, of the independent variable (e.g. time) 
form a random sequence. The power spectrum of ~(f) is directly related to the energy spectrum Sh(to) 
= Ilf(to)lz of h(f), where H(tD) is the Fourier transform of h(r), if a, has zero mean, and if on average 
there are v repetitions per unit time, then P, (0) = 1 < u,% Sh((D) The spatial analogue also has many 
applications, for instance in diffraction theory. For the application discussed here, the pulse h (x) 
is considered as a spot that is dropped on the plane, hence we call the noise produced spot noise. The 
size of a spt is limited, and usually small compared to the size of the texture segment to be synthesized. 
In analogy with shot noise, spot noise is defined as j-(x) =~a, h(x-x, ) where x, are random positions 
on the plane. If on average there are \ repetitions per unit area then P,(k) = v<a,2>Sh(k) , where k 
is the two-dimensional frequency vector. 3.2Synthesis The last relation of 3.1 is valuable for the synthesis 
of spot noise. Itstates that the power spectrum of the texture and the energy spectrum of the spot are 
the same, except for a scale fac­tor. So, realizations of spot noise can be constructed in the fre­quency 
domain via the multiplication of the Fourier transfomr H(k) with a scale factor and addition of a ratrdom 
phase shift ak to H(k). The addition of a random phase shift ak is equivalent to muhi­plication with 
W(k)= e %. The power spectrum of w (x) is evenly distributed over all frequencies, so w (x) is white 
noise. According to the convolution theorem, multiplication in the fre­quency domain is equivalent to 
convolution in the spatial domain, hence spot noise can also be synthesized via convolu­tion of h (x) 
with white noise. An example of white noise is a set of random values on a grid. Spot noise can therefore 
be synthesized through the convolution of a randomly filled grid with the spet. This method can be compared 
to the filtering of a very noisy image with the spot as the filter kernel, a standard technique in digital 
image processing [ 10]. In the natural texturing model [ 151 a similar technique is used to synthesize 
texture. Another example of white noise is a Poisson point process: a set of randomly scaled delta functions 
a, 5(x, ), randomly distributed over the plane. Here we close the circle: the convolution of a Poisson 
point process with a spot boils down to dropping s~ts on the plane, which is the original definition 
of spot noise. Random faults [21 ] and sparse convolution [ 17] are based on the same principle. Variation 
of the texture for data visualization can be realized via variation of the spot. This requires a variable 
spot h@, x), whose properties are controlled by a set of parameters p. These parameters are determined 
via a data mapping m from the data d(x) that belong to the texture coordinates x. Spot noise for data 
visualization can thus be synthesized by using variable spots: ~(x)= ~u, h(m(d(x, )), X-X,)  : SIGGRAPH 
91 Las Vegas, 28 July-2 August 1991 A drawback of this method is that the data to be visualized are smeared 
out. At each point several spots that correspond to different data values overlap. This is not a problem 
if the varia- tion in the data is small relative to the size of the spot. Another solution is to use 
an alternative definition for variable spot noise: fCX) = F ih(m(d(x))9 x-xi) , i.e. the texture at 
a point x is considered as if it is part of a sta- tionary texture constructed with identical spots that 
have the properties that correspond to the data at point x. Another interpretation is that the spot is 
used as a (position dependent) filter-kernel for a Poisson point process. A possible implemen-tation, 
though not very efficient for large spots, is via Perlin s approach. The preceding discussion reveals 
how this can be done: not via scaling, but via convolution of Noise : f(x,y) = ~$z(m@f(x)), x +i, Y +j)Noise(x 
+i,r+j) . As a final remark, the variance of spot noise is given by d = v <a;*>jjhz(x)dx Note that in 
general the variance of ai has to be adapted as a function of Xi if a constant variance of the texture 
is desired with a varying spot. 4 SPOT AND TEXTURE In the preceding section we saw the strong relation 
between the energy spectrum of the spot and the power spectrum of the tex-ture, and hence also between 
their autocorrelation functions. In this section the relation between a spot and the resulting texture 
is discussed from a designer s point of view. Given a simple spot, how are its features, such as size 
and shape, related to features of the texture, such as granularity and isotropy ? This will be shown 
with a number of examples, leading to rules of thumb that can be used for texture design. In this section 
all examples of textures are stationary, in the next section the use of space-variant spots will be discussed. 
The images in this section are made via addition of a random phase shift to the Fourier transform of 
the spot, followed by an inverse Fourier transform and normalization. 4.1 Size A disk is the simplest 
spot that can be used. Figure 2 shows three disks with different radii and the corresponding textures. 
The differences in the textures can be explained from their power spectra. In figure 3 the power spectrum 
sine* of the one-dimensional equivalent of a disk, the rectangular pulse, is shown. For the graphical 
display of a random function in the spatial domain, a finite band in the frequency domain has to be selected, 
because of limitations in resolution. The display of a large sample (narrow pulses) comes down to the 
selection of a band in the low frequencies, whereas the display of a small sample (wide pulses) is equivalent 
to selection of a band in the high frequencies. Thus, figure 3 shows that narrow pulses lead to white 
noise. For wide pulses, the right flank is dominant. This flank falls off with f-*, which is the same 
as for Brownian motion. If the width of the pulse lies between those extrema, the corresponding random 
function is white noise that has been passed through a low-pass filter. For two-dimensional signals, 
i.e. textures, a similar result can be derived in the frequency domain. However, a derivation in the 
spatial domain is instructive as well. If small spots are used, samples at different locations are uncorrelated, 
and hence the 312 Fig. 2 Different sizes of spot result is white noise. Large spots degenerate to random 
faults, so the result will be fractal. Here the texture is shown as a variation in the intensity, which 
gives a cloud-like result. For intermediate size spots these two effects occur simultaneously. At a large 
scale the result is white noise, while details have a fractal character. i 1 white ,< 1owq-s =: Brown 
log 0 Fig. 3 Power spectrum rectangular pulse For the autocorrelation function of two-level spots (h(x) 
= 1 or 0), a simple geometric interpretation can be used: the normal-ized autocorrelation K(A) (= C(A) 
10~) is equal to the area of the overlap of a spot h(x) and a displaced spot h (x-A), divided by the 
area of the spot (fig. 4). In general, if two spots do not overlap for a displacement A, then the texture 
is uncorrelated for samples at a distance A. Therefore, the size of the spot deter-mines the maximum 
correlation length or the granularity of the texture. AA  i!YK-A) = area(AOAAA)A area(A 0) A0 Fig. 4 
Autocorrelation function for two-level spots  @ Comwter GraDhics, Volume 25. Number 4. Julv 1991 4.2 
Edges We saw that a sharp edge, i.e. a discontinuity at the transition from the interior to the exterior 
of the spot, leads to a fractal texture. Figure 5 shows the effect of the use of different types of transitions 
from the interior to the exterior of the spot. Besides a disk, a cone-shaped spot with a triangular cross-section 
and a spot with a Gaussian cross-section are used. The last two spots act as steep low-pass filters. 
The right flank of the power spectrum of a triangular filter falls off with fA, the power spectrum of 
a Gaussian filter falls off exponentially. The visual effect is that details below the scale of the spot 
are removed: a smooth texture is generated. Whereas in image pro-cessing usually such filters are preferred 
above the box or pulse filter, for texture synthesis this is a matter of taste. The smooth textures appear 
out of focus, whereas textures that result from spots with sharp edges affirm the theorem f ructal = 
natural. The difference between the use of a triangular and a Gaussian cross-section is small, whereas 
the difference between the smooth and the fractal texture is large. Textures between smooth and fractal 
can be synthesized via the use of spots with a trapezoidal cross-section. Fig. 5 (a) Disk, (b) cone, 
(c) Gaussian spot  4.3 Direction The textures presented so far were invariant under rotation, i.e. isotropic. 
A texture will be isotropic if the spot is rotationally symmetric, or if each spot is, besides randomly 
positioned, also randomly rotated. The power spectrum P,(k) of the noise f(x) that results from the use 
of a randomly rotated spot h (x , y ) with energy spectrum Sh (k ,, k2) is given by 2n Pf(k) = v <a;>- 
1 &#38;(Iklcosa, Iklsincc)da. 2x:lkl If no random rotation is used, the use of straight lines in a spot 
always leads to an anisotropic texture. A simple way to generate an anisotropic texture is to scale a 
spot non-proportionally. Figure 6 shows the effect of the use of ellipses as opposed to disks. For elongated 
ellipses the texture has a fractal character in the direction of the longest axis, and a white noise 
character in the direction of the shortest axis. The effect of scaling the spot is not simply scaling 
the texture. Instead the texture is stretched locally, the large details in the texture remain at the 
same place. Fig. 6 Non-proportional scaling  4.4 Patterns Many textures exhibit patterns, i.e. structures 
are repeated over some distance. Such patterns show up in the autocorrelation function as oscillations 
with a decreasing magnitude. Figure 7 shows that if the spot exhibits some regular pattern, the result-ing 
texture also does. A spot composed of concentric circles leads to an isotropic, enamel-like texture, 
the use of a small sample of a grid as a spot leads to a textile-like texture. The corresponding autocorrelation 
functions are easily imaginable if the rule shown in fig. 4 is used. Such spots have three levels of 
detail; each level corresponds to one feature of the corresponding texture. The global size of the spot 
determines the scale of the white noise component, the width and spacing of the lines determine the width 
and spacing of the pattern, and the sharp edges lead to fractal detail. Fig. 7 Regular patterns  4.5 
Shape The preceding examples show that the shape of the spot strongly influences the texture. Some further 
examples are shown in fig. 8. The use of a square leads to a texture with strong horizontal and vertical 
patterns (fig. 8a). If the square is distorted into a diamond, the result is easily predictable (fig. 
8b). The relation between the shape and the texture is not always so obvious. Fig. 8c shows a spot with 
the shape of a quarter circle. The resulting texture bears a strong resemblance with a top-view of a 
planet surface or lunar landscape (without craters).    @ @ Computer Graphics, Volume 25, Number 
4, July 1991 of an adaptive filter width on white noise is shown in the con­text of stochastic sampling. 
For such applications, the aim is removal of high frequency noise, so the filter kernels are chosen from 
a standard set of rotationally symmetric filter kernels like the tent, the Gaussian, and the squared 
cosine. The observation that the use of a banana-shaped filter leads to lunar landscapes has not yet 
been mentioned in image processing literature, Third, spot noise synthesis can be considered as sparse 
ctrnvo/u­tion. In contmst to using a texture sample [17], however, a spot is used. i.e. a simple geometric 
pattern. The examples in sec­tion 4 show that such a simple pattern is easier to use for tex­ture design 
than the autocorrelation function and the power spectrum, Fourth, spots can be viewed as purricles, or 
brush strokes, and spot noise as the result of particle systems [30, 31, 32], or abstract image representations 
[11 ]. Although it has been noted before that the use of many overlapping particles leads to tex­ture, 
this has not yet been analyzed in the frequency domain. Fifth, spot noise can be viewed as an application 
of Perlin s solid fe.!-turing technique [28]. Perlin typically uses scaling of Noi.w to achieve certain 
effects, here it has been shown that for controlled, local variations convolution has to be used. Another 
relation between the concepts discussed here and Noise can be found in [ 19]. Here sparse convolution 
is used, i.e. convolution of a filter kernel with a Poisson point process, for the imple­mentation of 
Noise itself. We conclude from the preceding discussion that spot noise can be considered as J new concept 
that provides a new perspective on a series of so far unrelated techniques, and that provides an elegant 
basis for their analysis. 6.2Texture for data visualization The application aimed at for spot noise was 
texture synthesis for data visualization. We therefore test spot noise here against the requirements 
of section 2. Spot noise does allow easy local con­trol. and a wide variety of textures can be synthesized. 
The specification of a texture by the designer requires few inputs, and in most cases the relation between 
his input and the result­ing texture is straightforward. The synthesis process is reason­ably efticient. 
Previews can easily be generated by using few spots, so that the separate spots can be distinguished. 
For images such M tig. 13. the use of previews, where the object of interest is covered with iconic representations 
of the texture, is very useful to establish the data mapping from velocity to spot. Another point is 
whether the use of texture for data visualization itself is a useful concept. The use of texture means 
that resolu­tion is sacrificed, i.e. the largest scale of the texture has to be smaller than the scale 
of variation in the data. However, in contrast to the use of color alone, it does allow the display of 
vector fields, and has more degrees of freedom. Further, the examples for flow) visualization show that 
the resulting images are suggestive. if not natural and realistic. Thus, texture is prob­ably more suited 
for global and qualitative visualization of data than for detailed and quantitative analysis, and it 
is more suited for external presentations than for regular use by researchers. Spot noise was used here 
in its simplest form: straightforward mapping of intensity values. Several techniques can be used to 
enhance the results. The mapping of the data to the parameters of the texture used here was continuous, 
an alternative is to use discrete bands or bins. Non-linear transformations of the inten­sity values 
of the texture can be applied to achieve special effects. Examples are squaring the value of texture, 
clamping, and the use of the value of the texture as an index in a color ttible. Finally, besides intensity, 
also the hue and saturation of the spots can be varied as a function of the da(a. 6.3 Further work An 
approach to gain more insight in the relation between the shape of the spot and the resulting texture. 
is to attempt to derive spots from sampled real-world textures. This step is the inverse of that from 
spot to texture. A spot h (x) has to be con­structed such that its energy spectrum is the same as the 
power spectrum of the texture, and such that it corresponds to the notion of the spot used here, i.e. 
satisfies some criterion such as minimal size or minimal variance. If such a technique can be developed, 
the application of the spot might expand from texture design to texture analysis. h is an open question 
whether such derived spots provide additional insight above the autocomelation function and the power 
spec­trum. 7 CONCLUSIONS Texture is a useful visual primitive for data visualization; Spot noise satisfies 
the requirements for texture for data visualization: efficient synthesis with local control, and ease 
of design: Spot noise is an alternative to solid texturing for the syn­ thesis of stochastic textures 
over curved surfaces; Spot noise provides a new perspective on a series of tech­niques: random faults, 
filtering, sparse convolution, particle systems, and solid texturing: Spot noise is a hot noise. ACKNOWLEDGEMENTS 
The discussions with Teun Burgers, Wim Rijnsburger (ECNL and Pieter-Jan Stappers (Delft University of 
Technology DUT) were very helpful during the development of the work described here. Valuable comments 
on earlier versions of this paper were given by Wim Bronsvoort (DUT), and Gonno Leen ­dertse (ECN). I 
further thank Hoyte Raven, Reint Dallinga. Ren6 Huijsmans. and Hans van der Kam (Maritime Research Institute 
Netherlands MARIN ) for providing interesting data sets, for the pleasant cooperation, and for their 
support of the ECN Scientific Visualization project. REFERENCES 1. BL.INN, J.F. Simulation of wrinkled 
surfaces. Comp//wr graphics /2, 3, (1978), 286-292. 2, CATMULL, E. A .~uhdiiisiotta /~(~rirhnlf or<c~mpilterdi 
.$play ofcur~ed su~aces. Ph.D. Thesis, Report UTEC-CSc-74­ 133. Computer Science Department, University 
of Utah. Salt Lake City. 1974. 3. CHAMPENEY, D.C. Fourier transffmns and their ph.vsical applications, 
Academic Press, London, 1973. 4. DALLINGA, R. Seakeeping characteristics of SWATH vessels. In Proceedin,g.y 
13th WEGEMT Graduate school on design techniques fhr ad\ anced marine ~ehicles and hi,qh speed displacement 
ships, Delft University of Technology. 1989. 5. DIPPE, M. A. Z., AND WOLD, E.H. Anti-aliasing through 
sto­chastic sampling. Computer Gruphics 19. 3 (1985), 69-78. 6, FoLEY, J. D., DAM, A.vA~, FEI~ER, S. 
K, AND HLGHES, J,F. Computer ,qraphics: principles and pra(tice. Second edi­tion, Addison-Wesley, Reading. 
MA. 1990.   SIGGRAPH 91 Las Vegas, 28 July-2 August 1991 7. 8, 9. 10. 11. 12, 13. 14. 15. 16. 
17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29.  F0uRNn3R A.. FUSSEL. D. AND CARPENTER, 
L. Commter rendering of stochastic models. Communications ACM 25, 6 ( 1982), 371-384. FOURNIER, A., AND 
REEVES, W.T. A simple model of ocean waves. Computer Graphics 20, 4 (1986), 75-84. GAGALOWICZ, A., AND 
MA, S.D. Sequential synthesis of natural textures. Computer Graphics, Vision, and Image Processing 30 
(1985), 289-315. GONZALEZ, R., AND W]NTZ P. Digital image processing. Second edition, Addison-Wesley, 
Reading, MA, 1987. HAEBERLI, P. Paint by numbers: abstract image representa­tions. Computer Graphics 
24, 4 (1990), 207-214. HECKBERT, P.S. Survey of texture mapping. IEEE Com­ puter Graphics and Applications 
6, I I (1986), 56-67. JANSEN, F. W., AND WIJK, J.J. VAN. Previewing techniques in raster graphics. Computer 
&#38; Graphics 8, 2 (1984), 149-161. JULESZ, B. Visual pattern discrimination. IRE Trans. Inform, Theory, 
IT-8 (1962), 84-92. KRUEGER, W. Intensity fluctuations and natural texturing.  Computer Graphics 22, 
4 (1988), 213-220. KRUEGER, W. Volume rendering and data feature enhance­ment. In Grave, M., and Y. Ie 
Lous (eds.), Proceedings of the Eurographics Workshop on Visualization in Scientific Computing, to be 
published by Springer-Verlag, Berlin. LEWIS, J.P. Texture synthesis for digital painting. Com­puter Graphics 
18, 3 (1984), 245-252. LEWIS, J.P. Generalized stochastic subdivision. ACM Transactions on Graphics 6, 
3 ( 1987), 167-190. LEWIS, J.P. Algorithms for solid noise synthesis. Com­puter Graphics 23, 3 (1989), 
263-270. MA, S. D., AND GAGALOWICZ, A. Determination of local coordinate systems for texture synthesis 
for 3-D surfaces. In Vandoni, C.E. (cd.), Proceedings Eto-ographics 85, North-Holland, 1985, 109-118. 
MANDELBROT, B.B. The fractal geometry of nature. W.H. Freeman and Co., New York, 1982. MAX, N. Vectorized 
procedural models for natural ter­rains: waves and islands in the sunset. Compurer Graphics /5, 3 (1981), 
317-324. MONNE, J., SCHMITT, F. AND MASSALOUX, D. Bidimen­sional texture synthesis by Markov chains. 
Computer Graphics and Image Processing 17 (1981), 1-23. MUSGRAVE, F. K., KOLB, C.E. AND MACE, R.S. The 
syn­thesis and rendering of eroded fractal terrains. Computer Graphics 23, 3 (1989), 41-50. PEACHEY, 
D.R. Solid texturing of complex surfaces. Com­ puter Graphics 19, 3 (1985), 279-286. PEACHEY, D.R. Modeling 
waves and surf. Computer Graphics 20, 4 (1986), 65-74. PEITCEN, H.-O., AND SAUPE, D. (eds.). The science 
of fiac­ tal images. Springer-Verlag, New York, 1988. PERLIN, K. An image synthesizer. Computer Graphics 
19, 3 ( 1985), 287-296. RAVEN, H.C. Variations on a theme by Dawson. In Proceedings of the 17th Symposium 
on Naval Hydrodynam­ics, The Hague, 1988, 151-172. 30. REEVES, W.T. Particle systems -a technique for 
modeling a class of fuzzy objects. Computer Graphics 17, 3 (1983), 389-399. 31. REEVES, W.T., AND BLAU, 
R. Approximate and probabilis­tic algorithms for shading and rendering structured particle systems. Computer 
Graphics 19, 3 (1985), 313-322. 32. SIMS, K. Particle animation and rendering using data paral­lel computation. 
Computer Graphics 24, 4 (1990), 405­  413. 33. TUFTE, E.R. The visual display of quantitative information. 
Graphics Press, Cheshire, Connecticut, 1983. 34. UPSON, C. The visual simulation of amorphous phenomena. 
Visual Computer 1, 2 (1986), 321-326. 35. UPsoN, C. ET AL. The Application Visualization System: a computational 
environment for scientific visualization. IEEE Computer Graphics and Applications 9, 4 (1989), 30-42. 
36. WJJK, J.J. VAN, BRONSVOORT, W. F., AND JANSEN, F.W. Some issues in designing user interfaces to 3D 
raster graphics. Computer Graphics Forum 4 (1985), 5-10. 37. WIJK, J.J. VAN. Rendering lines on curved 
surfaces. In Grave, M., and Y. le Lous (eds.), Proceedings of the Euro­graphics Workshop on Visualization 
in Scientific Comput­ing, to be published by Spnnger-Verlag, Berlin. 38. WIJK, J.J. VAN. A raster graphics 
approach to flow visuali­zation. In Vandoni, C. E., and D.A. Duce (eds.), Proceed­ings Eurographics 90, 
North-Holland, Amsterdam, 1990, 251-259.   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122752</article_id>
		<sort_key>319</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Artificial evolution for computer graphics]]></title>
		<page_from>319</page_from>
		<page_to>328</page_to>
		<doi_number>10.1145/122718.122752</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122752</url>
		<abstract>
			<par><![CDATA[This paper describes how evolutionary techniques of variation and selection can be used to create complex simulated structures, textures, and motions for use in computer graphics and animation. Interactive selection, based on visual perception of procedurally generated results, allows the user to direct simulated evolutions in preferred directions. Several examples using these methods have been implemented and are described. 3D plant structures are grown using fixed sets of genetic parameters. Images, solid textures, and animations are created using mutating symbolic lisp expressions. Genotypes consisting of symbolic expressions are presented as an attempt to surpass the limitations of fixed-length genotypes with predefined expression rules. It is proposed that artificial evolution has potential as a powerful tool for achieving flexible complexity with a minimum of user input and knowledge of details.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Color, shading, shadowing, and texture</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010384</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Texturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31096733</person_id>
				<author_profile_id><![CDATA[81332527789]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sims]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Thinking Machines Corporation, 245 First Street, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aono, M., and Kunii, T. L., "Botanical Tree Image Generation," IEEE Computer Graphics and Applications, Vol.4, No.5, May 1982.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Darwin, Charles, The Origin of Species, New American Library, Mentor paperback, 1859.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dawkins, Richard, The Blind Watchmaker, Harlow Logman, 1986.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dawkins, Richard, "The Evolution of Evolvability," Artijicial Life Proceedings, 1987, pp.201-220.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>534133</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Goldberg, D. E., Genetic Algorithms in Search, Optimization, andMachine Learning, 1989, Addison-Wesley Publishing Co.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_obj_id>645511</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Grenfcnstette, J. J., Proceedings of the First International Conference on Genetic Algorithms and Their Applications, Hiilsdale, New Jersey, Lawrence Erlbaum Associates, 1985.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>42512</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Grenfenstette, J. J., Genetic Algorithms and Their Applications: Proceedings of the Second International Conference on Genetic Algorithms, 1987, (Hillsdale, New Jersey: Lawrence Erlbaum Associates.)]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>72804</ref_obj_id>
				<ref_obj_pid>72797</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Haase, K., "Automated Discovery," Machine Learning: Principles and Techniques, by Richard Forsyth, Chapman &amp; Halt 1989, pp.127-155.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617634</ref_obj_id>
				<ref_obj_pid>616016</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Haggerty, M., "Evolution by Esthetics, an Interview with W. Latham and S. Todd," IEEE Computer Graphics, Vol. I l, No.2, March 199 I, pp.5-9.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>38324</ref_obj_id>
				<ref_obj_pid>38323</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hillis, W. D., "The Connection Machine," Scientific American, Vol. 255, No. 6, June 1987.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>129194</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Holland, J. H., Adaptation in Natural and Artificial Systems, Ann Arbor, MI: University of Michigan Press, 1975.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>892491</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Koza, J. R. "Genetic Progranuning: A Paradigm for Genetically Breeding Populations of Computer Programs to Solve Problems," Stanford University Computer Science Department Technical Report STAN-CS-90-1314, June 1990.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>116558</ref_obj_id>
				<ref_obj_pid>116517</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Koza, J. R. "Evolution and Co-Evolution of Computer Programs to Control Independently Acting Agents," Conference on Simulation of Adaptive Behavior (SAB-90) Paris, Sept.24- 28, 1990.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>1092</ref_obj_id>
				<ref_obj_pid>1090</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Lenat, D. B. and Brown,J.S. "Why AM and EURISKO a~ to work," Artificial intelligence, Vol.23, 1984, pp.269-294.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74360</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Lewis, J. P., "Algorithms for Solid Noise Synthesis," Computer Graphics, Vol.23, No.3, July 1989, pp.263-270.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_obj_id>15892</ref_obj_id>
				<ref_obj_pid>15886</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[~eimer, P. "Real time design and animation of fractal plants and trees." Computer Graphics, Vol.20, No.4, 1986, pp.55-64.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Oppenheimer, P. "The Artificial Menagerie" Artificial Life Proceedings, 1987, pp.251-274.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325246</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Peachy, D., "Solid Texturing of Complex Surfaces," Computer Graphics Vol. 19, No.3, July 1985, pp.279-286.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325247</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., "An Image Synthesizer," Computer Graphics, Vol. 19, No.3, July 1985, pp.287-296.]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74359</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Perlin, K., "Hypertexture," Computer Graphics, Vol.23, No.3, July 1989, pp.253-262.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378503</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Prusinkiewicz, P., Lindenmayer, A., and Hanan, J., "Developmental Models of Herbaceous Plants for Computer Imagery Purposes," Computer Graphics, Vol.22 No.4, 1988, pp. 141- 150.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378505</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Reffye, P., Edelin, C., Francon, J., Jaeger, M., Puech, C. "Plant Models Faithful to Botanical Structure and Development," Computer Graphics Vol.22, No.4, 1988, pp. 151-158.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
			<ref>
				<ref_obj_id>93126</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Schaffer, J. D., "Proceedings of the Third international Conference on Genetic Algorithms," June 1989, Morgan Kaufmann Publishers, Inc.]]></ref_text>
				<ref_id>23</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Sims, K., Panspermia, Siggraph Video Review 1990.]]></ref_text>
				<ref_id>24</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808571</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Smith, A. R., "Plants, Fractals, and Formal Languages," Computer Graphics, Vol.18, No.3, July 1984, pp.l-10.]]></ref_text>
				<ref_id>25</ref_id>
			</ref>
			<ref>
				<ref_obj_id>33425</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Steele, G., Common Id'sp, The Language, Distal Press, 1984.]]></ref_text>
				<ref_id>26</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Thinking Machines Corporation, Connection Machine Model CM-2 Technical Swnmary, technical report, May 1989.]]></ref_text>
				<ref_id>27</ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Todd, S. J. P., and Latham, W., "Mutator, a Subjective Human Interface for Evolution of Computer Sculptures," IBM United Kingdom Scientific Centre Report 248, 1991.]]></ref_text>
				<ref_id>28</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74336</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Viennot, X., Eyrolles, G., Janey, N., and Axques, D., "Combinatorial Analysis of Ramified Patterns and Computer Imagery of Trees," Computer Graphics, Vol.23, No.3, July 1989, pp.3~-4o.]]></ref_text>
				<ref_id>29</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, July 1991 Artificial Evolution for Computer Graphics Karl 
Sims Thinking Machines Corporation 245 First Street, Cambridge, MA 02142 1 ABSTRACT This paper describes 
how evolutionary techniques of variation and selection can be used to create complex simulated structures, 
tex­tures, and motions for use in computer graphics and animation. Interactive selection, based on visual 
perception of procedurally generated results, allows the user to direct simulated evolutions in preferred 
directions. Several examples using these methods have been implemented and are described. 3D plant structures 
are grown using fixed sets of genetic parameters. Images, solid textures, and animations are created 
using mutating symbolic lisp expressions. Genotjps consisting of symbolic expressions are presented as 
an attempt to surpass the limitations of fixed-length genotypes with predefine expression rules. his 
proposed that artificial evolution has potential as a powerful tool for achieving flexible complexity 
with a minimum of user input and knowledge of details. 2 INTRODUCTION Procedural models are increasingly 
employed in computer graphics to create scenes and animations having high degrees of complexity. A price 
paid for this complexity is that the user often loses the ability to maintain sufficient control over 
the results. Procedural models can also have limitations because the details of the pro­cedure must be 
conceived, understood, and designed by a human. The techniques presented here contribute towards solutions 
to these problems by enabIing evolution of procedural models using inter­active perceptual selection. 
Although they do not give complete control over every detail of the results, they do permit the creation 
of a large variety of complex entities which are still user directed, and the user is not required to 
understand the underlying creation process involved. Many years ago Charles Darwin proposed the theoty 
that all species came about via the process of evolution [2]. Evolution is now considered not only powerful 
enough to bring about biological entities as complex as humans and consciousness, but also useful in 
simulation to create algorithms and structures of higher levels of complexity than could easily be built 
by design. Genetic algo­rithms have shown to be a useful method of searching large spaces Permission 
to copy without fee all or part of this rmiteriat is granted provided that [he copies are not made nr 
distrihutcd for direct commercial advantage, the ACM copyright nn(iceand the tine of the publication 
tinciits dtite tippcw, md noticeis gtven [hat copying M by permissi(m of the Asscxlation fbr Computing 
Machinery. To copy otherwise, or to renublish. requires a fee wrd/nr specific permission. using simulated 
systems of variation and seltition [5, 6, 7, 23]. In The Blind Watchmaker, Dawkins has demonstrated the 
power of Darwinism with a simulated evolution of 2D branching struc­tures made from a set of genetic 
parameters. The user selwts the biomorphs that survive and reproduce to create each new gen­eration [3, 
4]. Latham and Todd have applied these concepts to help generate computer sculptures made with constructive 
solid geometry techniques [9, 28]. Variations on these techniques are used here with the emphasis on 
the potential of creating forms, textures, and motions that are useful in the production of computer 
graphics and animation, and also on the potential of using representations that are not bounded by a 
fixed space of possible results. 2.1 Evolution Both biological and simulated evolutions involve the basic 
con­cepts of genotype and phenotype, and the processes of expression, selection, and reproduction with 
variation. The geno/ype is the genetic information that codes for the cre­ation of art individual. In 
biological systems, genotypes are nor­mally composed of DNA. In simulated evolutions there are marry 
possible representations of genotypes, such as strings of binary dig­its, sets of procedural parameters, 
or symbolic expressions. The phenotype is the individual itself, or the form that results from the developmental 
rules and the genotype. Expression is the process by which the phenotype is generated from the genotype. 
For ex­ample, expression can be a biological developmental process that reads and executes the information 
from DNA strands, or a set of procedural roles that utilize a set of genetic parameters to create a simulated 
structure. Usually, there is a significant amplification of information between the genotype and phenotype. 
Selection is the process by which the fitness of phenotypes is determined. The likelihood of survival 
and the numk of new offspring art individual generates is proportional to its fimess mea­sure. Fitness 
is simply the ability of art organism to survive and reproduce. In simulation, it can be calculated by 
art explicitly de­fined fitness evrduation function, or it can be provided by a human observer as it 
is in this work. Reproduction is the prmess by which new genotypes are gen­erated from art existing getrot~ 
or genotypes. For evohrtion to progress there must be variation or mutations in new genotypes with some 
frequency. Mutations are usually probabilistic as opposed to deterministic. Note that selection is, in 
general, non-random and is performed on phenotypes; variation is usually random and is performed on the 
corresponding genotypes [See figure 1]. $<:,Iyyl ACM-()-X979 I-436-x/91/m7/0319 $0075   SIGGRAPH 91 
Las Vegas, 28 July-2 August 1991 .g (--( Sek[ion r Phen.lyp Sk. fm cd mew gaw@m GL.mlyQc  s?w Figure 
1: Phenotype selection, genotype reproduction. The repeated cycle of reproduction with variation and 
selection of the most fit individuals drives the evolution of a population towards higher and higher 
levels of fitness. Sexuul combinurion can allow genetic material of more than one parent to be mixed 
together in some way to create new genotypes. This permits features to evolve independently and Iaterbe 
combined into a single individual. Although it is not necessary for evolution to occur, it is a valuable 
practice that can enhance progress in both biological and simulated evolutions. 2.2 Genetic Algorithms 
Genetic algorithms were first developed by Holland [11] as robust searching techniques in which populations 
of test points are evolved by random variation and selection. They have become widely used in a number 
of applications to find optima in very large search spaces [6, 7, 23]. Genetic algorithms differ from 
the examples presented in this paper in that they usually utilize an explicit analytic timction to measure 
the fitness of phenotypes. Since it is difficult to auto­matically measure the aesthetic visual success 
of simulated objects or images, here the fitness is provided by a human user based on visual perception. 
Some combinations of automatic selection and interactive selection are also utilized< Population sizes 
used for genetic algorithms are usually fairly large (100 to 1000 or more) to allow searching of many 
test points and avoiding only local optima. At each generation, many indi­viduals survive and reproduce 
to create the next generation. For the examples presented in this paper, the success of a solution is 
dependent on human opinion, therefotv there is no single global optimum. Many local optima are potentially 
interesting solutions. For this reason, and also because of user interface practicality, a smaller population 
size has been used (20 -40), and only one or two individuals are chosen to reproduce for each new generation. 
Genotypes used in genetic algorithms traditionally consist of fixed-length character strings used by 
fixed expression rules. This is appropriate for searching predefine dimensional spaces for opti­mum solutions, 
but these restrictions are sometimes limiting. Koza [12, 13] has used hierarchical lisp expressions as 
genotypes such that the dirnensiomlity of the search space itself can be extended to successfully solve 
problems such as artificial ant navigation and game strategies. Dkcovety systems, such as AM, Eurisko, 
and Cyrano, also utilize a form of mutating lisp programs [8, 14]. The examples of evolving images, volume 
textures, and animations presented here also use genotypic representations composed of lisp expressions, 
aMtough the set of functions used includes various vector transformations, noise generators, and image 
processing op­erations, as well as standard numerical functions. In the next section, techniques for 
using artificial evolution to explore samples in parameter spaces are discussed. In section 4, ex­amples 
of evolving images, volume textures, and animations which utilize mutating symbolic expressions as genotypes 
are presented. Fhlly, results, suggestions for future work, and conclusions are given in the last three 
sections. 3 EXPLORING PARAMETER SPACES Proceduralmodels such as fractals, graftals, and procedural textur­ing 
allow a user to create a high degree of complexity with relatively simple input information [18, 19, 
21, 25]. One method of proce­dural structure creation involves a set of N input parameters each of which 
has an effect on a developmental process which assem­bles the structure. The set of possible structures 
corresponds to the Ndimensional space of possible parameter values. Consider an array of knobs, each 
controlling one parameter, that cart be exper­imentally turned to adjust the results. As more options 
am added to the procedure for more wu-iation of results, the number of in­put parameters grows and it 
can become increasingly dWicult for a user to predict the efftxts of adjusting particular parameters 
and combinations of parameters, and to adjust the knobs effectively by hand. An alternative approach 
is to sample randomly in the neigh­borhood of a currently existing parameter set by making random alterations 
to a parameter or several parameters, then inspect and select the best sample or samples of those presented. 
lids rdlows exploration through the parameter space in incremental arlitrary directions without requiring 
knowledge of the specific effects of each parameter. This is artificial evolution in which the genotype 
is the parameter set, and the phenotype is the resulting structure. Se­lection is performed by the user 
picking preferred phenotypes from groups of samples, and as long as the samples can be generated and 
displayed quickly enough, it cart be a useful technique. 3.1 Evolving 3D Plant Structures The first 
example of artificial evolution involves 3D plant structures which can be grown using a set of genetic 
parametem. Plant generation algorithms of various types have been shown to be useful examples of procedurally 
generated structures [ 1,16,21,22,25, 29]. The model used in this work is described briefly below, but 
details have been omitted as the emphasis is on the evolutionary process. Parameters describing fractal 
limits, branching factors, scaling, stochastic contributions, etc., are used to generate 3dimensional 
tree structures consisting of comected segments. Growth rules use 21 genetic parameters and the hierarchy 
location of each segment in the tree to determine how fast that segment should grow, when it should generate 
new buds, and in which directions. The tree structures are grown in arbitrarily small increments for 
smooth simulation of development. Atler a desirable tree structure has been evolved using inter­active 
selection and the mutation methods described below, its  @Q simply evaluated to produce images. Figure 
4 shows examples of some simple expressions and their resulting images. Artificial evolution of these 
expressions is performed by first generating and displaying a population of simple random expres­sions 
in a grid for interactive selection. The expressions of images selected by the user are reproduced with 
mutations for each new generation such that more and mo~ complex expressions and more perceptually successful 
images can evolve. Some images evolved with this prmess are shown in figures 9 to 13. 4.2 Mutating Symbolic 
Expressions Symbolic expressions must be reproduced with mutations for evo­lution of them to occur. 
There are several properties of symbolic expression mutation that are desirable. Expressions should ofien 
be only slightly modified, but sometimes significantly adjusted in structure and size. Large random changes 
in genotype usually result in large jumps in phenotype which are less likely to be im­provements, but 
are necessary for extending the expression to more complex forms. A recursive mutation scheme is used 
to mutate expressions. Lisp expressions are traversed as tree structures and each node is in turn subject 
to possible mutations. Each type of mutation occurs at different frequencies depending on the type of 
node: 1. Any node can mutate into a new random expression. This allows for large changes, and usually 
results in a fairly significant alteration of the phenotype. 2. If the node is a scalar value, it can 
be adjusted by the addition of some random amount. 3. If the ncde is a vector, it can be adjusted by 
adding random amounts to each element. 4. If the node is a function, it can mutate into a different 
fimction. For example (abs X) might become (COSX). If this mutation occurs, the arguments of the function 
are also adjusted if necessary to the correct number and types. 5. An expression can become the argument 
to a new random function. Other arguments are generated at random if necessary. For example X might become 
(* X .3). 6. An argument to a function can jump out and become the new value for that node. For example 
(*X .3) might become X, Ilis is the inverse of the previous type of mutation. 7. Finally, a node can 
become a copy of another node from the parent expression. For example (+ (abs X) (* Y .6)) might become 
(+ (abs (* Y .6)) (* Y .6)). This causes effects similar to those caused by mating an expression with 
itself. It allows for sub-expressions to duplicate themselves within the overall expression.  Other 
types of mutations could certainly be implemented, but these are sufficient for a reasonable balance 
of slight modifications and potential for changes in complexity. It is preferable to adjust the mutation 
frequencies such that a decrease in complexity is slightly mom probable than an increase. This prevents 
the expressions from drifting towards large and slow forms without necessarily improving the results. 
They should still easily evolve towards larger sizes, but a larger size should be due to selection of 
improvements instead of random mutations with no effect. The relative frequencies for each type of mutation 
above can be adjusted and experimental with. The overall mutation frequency is scaled inversely in proportion 
to the length of the parent expmsion. This decreases the probability of mutation at each node when the 
  Com~uter Graphics, Volume 25, Number 4, JUIV1991 parent expression is large so that some stability 
of the phenotypes is maintained. The evaluation of expressions and display of the resulting im­ages can 
require significant calculation times as expressions in­crease in complexity. To keep image evolution 
at interactive speeds, estimates of compute speeds am calculated for each expression by summing pm-computed 
mntime averages for each function. Slow expressions are eliminated before ever being displayed to the 
user. New offspring with random mutations are generated and tested until fast enough expressions result. 
In this way automatic selection is combined with interactive selection. If necessary, this technique 
could also be performed to keep memory usage to a minimum. 4.3 Mating Symbolic Expressions Symbolic 
expressions can be reproduced with sexual combinations to allow sub-expressions from separately evolved 
individuals to be mixed into a single individual. TWOmethods for mating symbolic expressions are described. 
The first method requires the two parents to be somewhat sim­ilar in structure. The nodes in the expression 
trees of both parents are simultaneously traversed and copied to make the new expres­sion. When a difference 
is encountered between the parents, one of the two versions is copied with equal probability. For example, 
the following two parents can be mated to generate four different expressions, two of which are equal 
to the parents, and two of which have some portions from each parenfi parent 1: (* (ab.rX) (madX Y )) 
  parent2: (*(/ YX) (* X -.7)) childl: (* (ab.r X) (mod X Y)) child2: (* (abs X)(*X -.7)) child3: (* 
(JYX) (mad X Y)) child4: (* (1 YX) (* X -.7J) This method is often useful for combming similar expressions 
that each have some desired property. It usually generates offspring without very large variations from 
the parents. Two expressions with different root ncdes will not form any new combinations. fhis might 
be compared to the inability of two different species to mate and create viable offspring. The second 
method for mating expressions combines the parents in a less constrained way. Anode in the expression 
tree of one parent is chosen at random and replaced by a node chosen at random from the other parent. 
This crossing over technique SI1OWSany part of the structure of one parent to be inserted into any part 
of the other parent and permits parts of even dissimilar expressions to be combkkxi. With this method, 
the parent expressions above can generate 61 different child expressions -many more than the 4 of the 
first method. 4.4 Evolving Vohme Textures A third variable, Z, is added to the list of available arguments 
to enable functions to be evolved that calculate colors for each point in (X, Y, Z) space. The@rction 
set shown in section 4.1 is adjusted for better results: 2D functions that require neighboring pixel 
values such as convolutions and warps are removed, and 3D solid noise generating functions are added. 
These expressions are more difficult to visualize because they encompass all of 3D space. They are evaluated 
on the surfaces     SIGGRAPH 91 Las Veqas, 28 JuIv-2 Auaust 1991 F@re 13 was created from this expression: 
(sin (+(-(grad-direction (blur (if(hsv-to-rgb (warped­color-noise #(0.57 0.73 0.92) (1 1.8S (warped-color­noise 
xyO.02 3.08)) 0.11 2.4)) #(0.S4 0.73 0.59) #(1.06 0.82 0.06)) 3.1) 1.46 5.9) (h.rv-to-rgb (warped-color­noise 
y (1 4.5 (warped-color-noise y (/x y) 2.4 2.4)) 0.02 2.4))) X)) Note that expressions only five or six 
liis long can generate images of fair complexity. Equations such as these can be evolved from scratch 
in timescrdes of only several minutes -probably much faster than they could l-wdesigned. Figures 10, 
11, and 12 were also created from expressions of similar lengths. Fortunately, analysis of expressions 
is not required when using these methods to create them. Users usually stop at­tempting to understand 
why each expression generat~ each image. However, for those interested, expressions for other figures 
are listed in the appendix. llvo different approaches of user selection behavior are possi­ble. The user 
can have a goal in mind and select samples that are closer to that goal until it is hopefully reached. 
Alternatively, the user can follow the more interesting samples as they occur without attempting to reach 
any specific goal. The results of these vmious types of evolved expressions can be saved in the very 
concise form of the final genotypic expression itself. This facilitates keeping large libraries of evolved 
forms which camthen be used to contribute to further evolutions by mating them with other forms or ftnther 
evolving them in new directions. FUTURE WORK Artificial evolution has many other possible applications 
for com­puter graphics and animation. Procedures that use various other forms of solid noise could be 
explored, such as those that create ob­jects, create density functions, or warp objects [20, 15]. Procedures 
could be evolved that generate motion flom a set of rules (possibly cellular automa~ or particle systems), 
or that control dktributions and characteristics of 2D objects such as lines, solid shapes, or brush 
 strokes. Algorithms that use procedural construction rules to create 3D objects from polygons, or functions 
that generate, manipulate, and combme geometric primitives could also be exploxed. These techrdques might 
also make valuable tools in domains beyond computer simulations. New possibfities for shapes and textures 
could be explonzxl for use in product design or the fashion industry. Several variations on the methods 
for artificial evolution de­scribed above might make interesting experiments. Mutation fre­quencies could 
be included in the genotype itself so that they also can be mutated. lWs might allow for the evolution 
of evolvability [4]. Frequencies from the most successful evolutions could be kept as the defaults. It 
might be interesting to attempt to automatically evolve a sym­bolic expression that could generate a 
simple specific gord image. An image differencing function could be used to calculate afitness based 
on how close a test image was to the goal, and an expression could be searched for by automatic selection. 
Then, interactive selection could be used to evolve further images starting with that expression. Large 
amounts of information of all the human selection choices of many evolutions could be saved and analyzed. 
A difficultchal­lenge would be to create a system that could generalize and tmder­stand what makes an 
image visually successful, and even generate other images that meet these learned criteria. Combinations 
of random variations and non-random variations using kamed information might be helpful. If a user picks 
pheno­types in a certain dmtion from the parent, mutations for the next generation might have a tendency 
to continue in that same direction, causing evolution to have momentum. Also, combinations of evolution 
and the ability to apply specific adjustments to the genotype might allow more user control over evolved 
results. Automatic genetic engineering could permit a user to request an evolved image to be more blue, 
or a texture more *Y. 7 CONCLUSION Artificial evolution has been demonstrated to be a potentially pow­erful 
tool for the creation of procedurally generated structures, tex­tures, and motions. Reproduction with 
random variations and sur­vival of the visually interesting cart lead to useful results. Repre­sentations 
for genotypes which are not limited to fixed spaces and can grow in complexity have shown to be worthwhile. 
Evolution is a method for creating and exploring complexity that does not require human understanding 
of the specific process involved. This process of artificial evolution could be considered as a system 
for helping the user with creative explorations, or it might be considered as a system which attempts 
to learn about human aesthetics from the user. In either case, it allows the user and computer to interactively 
work together in a new way to produce results that neither could easily produce alone. An important limiting 
factor in the usefulness of artificial evo­lution is that samples need to be generated quickly enough 
such that it is advantageous for the user to choose from random samples instead of carefully adjusting 
new samples by hand. The computer needs to generate and display samples fast enough to keep the user 
interested whale selecting amongst them. As computation becomes more powerful and available, artificial 
evolution will hopefully be­come advantageous in mo~ and more domains. 8 Acknowledgments Thanks to Lew 
Tucker, Jim Salem, Gary Oberbrurtner,Matt Fitzgib­bon, Dave Sheppard, and Zotje Maes for help and suppmt. 
Thanks to Peter Schrtkier for being a helpful and successful user of these teds. Thanks to Luis Ortiz 
and Katy Smith for help with document preparation. And thanks to Danny Hlllis, Larry Yaeger, and Richard 
Dawkins for discussions and inspiration. 9 APPENDIX Figure 5, Parent expression: (warpedalor-noise (wqed-bw-nois.e 
(dissnlve x 2.53 y) z O.CEI12.0) (ivm z) 0.03 -2.06) Figure 6, Marble torus: (dissolve (..s (and 0.25 
#(0.43 0.73 0.74))) (log (+ (warped-bw-noise (rein z 11. 1) (log (rcate-vector (+ (watpcd-bw-noise (cm 
x) (dissolve (cm (and 0.25 #(0.43 0.73 0.74))) (log (+ (warped-bw-noise (mm (rein z 8.26)(/ -0.5 #(0.L120.390. 
19))) (log (+ (warped-bw-noise#(0.820.390.19))#(0.150.340.50))-0.04 (cmx)z-0.040.89)   Computer Graphics, 
Volume 25, Number 4, July 1991 Figure 12. SIGGRAPH 91 Las Vegas, 28 JuIv-2 August 1991 -3.0) y) #(o.150.34 
0.50)) y) 4.04 -3.0) x)zy)#(o.150.34 0.5)) -0.02 -1.79) -0.4) q-o.09 0.34 0.55)) -0.7) Figure 7, Cross 
dissolve: (hsv-to-rgb (bump (hsv-wrgb (ifs 2.290.LK)3(dissolve 1.773.67 time) 2.60.1 (dissolve 5.23,2 
dine) -31,0 (dissolve 23.9-7.4 time) (dissolve 1.139.5 time) (dissolve 4.80.16 time) 20.74,05 (dissolve 
0.4S 0.46 time) (dissolve 2.94 -0.6S rime) (dissolve 0.420.54 time) (dissolve 0.090.54 time))) (stan 
2,25 (dissolve 0.10.11 time) O.15) (dissolve 4.098,23 time) (dissolve #(0.41 0.36 0.08) #(0.68 0.220.3 
1) time) WO.36 0.31 0.91) (dissolve 6.24.3 time) (dissolve 0.160.40 time) (dissolve 2.0S 0.23lime))) 
Figure 8, Fm of Faces (+ (rein10.8(warp-ml image image (bump imsge x 9.6 #(0.57 0.020. 15) #(0.52 0,03 
0.38) 3.212.49 10,8))) (dissdve #(0.81 0.4 0.16)x (dissolvey~0.880.99 o.fi) i~e))) Figure 10 (1 OWC-V-(log 
(+ y (color-@ (round (+ (As (round (log #(0.01 0.67 0.S6) O.19) x)) (hsv-to+gb (bump (if x 10.7 y) qO.94 
O.01 0.4) 0.78 MO.180.28 0.58) #(0.4 0.92 0.58) 10.60.23 0,91))) X) 3. I 1.93 #(0.95 0.7 0.35) 3.03)) 
-0.03)X #(0.76 0.08 0.24)) Figure 11 is unfortunately extinct because it was created before the genome 
saving utility was complete. Figure 12: (COS(round(stan(log(itlVefly)(+(bUMP(+(roundXY)Y)#(0.460.820.65)0.02W. 
I 0.060,1)#(o.99 o,rM0.4 1) 1.47 S.7 3.7) (Colm-gmd (round (+ y y) (log (invert x) (+ (inven Y) (mud 
(+ y x) (bump (warped-ifs (round y y) y 0.0S 0.067.41.656.10.54 3.10.260.7315 .85,78.9 0.497 .215.6 0.98) 
#tO.46 0.82 0.65) 0.02 MO.10.06 0.1) #(0.99 OJM0.41) 0.838.7 2.6))))) 3. I6.8#(0.950.7 0.59) 0.57))) 
W-17 0.08 0.75) 0.37) (vcCtory 0.09 (Cos(round y y))))) Reference [1] Aono, M., and Kunii, T. L., Botanical 
Tree Image Gener­ation, IEEE Computer Graphics and Applications, VOL4, No.5, May 1982. [2] Darwin, Charles, 
T he Origin of Species, New American Li­brary, Mentor paperback, 1859. [3] Dawkins, Richard, The Blind 
Watchmaker, Harlow Logman, 1986.  [4] Dawkins, Richard, The Evolution of Evolvability, Artij$cial Lye 
Proceedings, 1987, pp.201-220. [5] Goldberg, D. E., Genetic Algorithms in Search, Optimization, andMachine 
Learning, 1989, Addison-Wesley PublishingCo. [6] Grenfenstette, J. J., Proceedings of the First International 
Conference on Genetic Algorithms and Their Applications, Hillsdale, New Jersey, Lawrence Erlbaum Associates, 
1985. [7] Grenfenstette, J. J., Genetic Algorithms and Their Applica­tions: Proceedings of the Second 
International Conference on Genetic Algorithms, 1987, (Hillsdale, New Jersey: Lawrence Erlbaum Associates.) 
[8] Haase, K., AutomatedDiscovery, MuChine Learning. Pritr­ciples and Techniques, by Richard Forsyth, 
Chapman&#38; Hall 1989, pp.127-155. [9] Haggerty, M., Evolution by Esthetics, an Interview with W. Latham 
and S. Todd; IEEE Computer Graphics, Vol. 11, No.2, March 1991, pp.5-9. [10]Hillis, W. D., he Comection 
Machine: Scientific Ameri­can, Vol. 255, No. 6, June 1987. [11] Holland, J. H., Adaptation in Natural 
and Artificial Systems, Arm Arbor, MI: University of Michigan Press, 1975. [12] Koza, J. R. Genetic Programming: 
A Parad@n for Genet­ically Breeding Populations of Computer Programs to Solve problems: Stanford University 
Computer Science t@art­ment Technical ReportSTAN-CS-90-1314, June 1990. [13] Koza, J. R. Evolution and 
Co-Evolution of Computer Pro­grams to Control In&#38;pendently Acting Agents, Co~erence on Simulation 
of Aatzptive Behavior (SAB-90) Paris, Sept.24­28,1990. [14] Lenat, D. B. and BrownJ.S. Why AM and EURISKO 
appear to work: Artificial intelligence, VOL23, 1984, pp.269-294. [15] Lewis, J. P., Algorithms for Solid 
Noise Synthesis, Com­puter Graphics, VO1.23,No.3, July 1989, pp.263-270. [16] Oppenheimer, P. Real time 
design and animation of fractrd plants and trees. Computer Graphics, VO1.20, No.4, 1986, pp.55-64. [17] 
Oppenheimer, P. The Artificial Menagerie Arttjicial Life Proceedings, 1987, pp.251 -274. [18] Peachy, 
D., Solid Texturing of Complex Surfaces, Computer Graphics Vol. 19, No.3, July 1985, PP.279-286. [19] 
Perhn, K., An Image Synthesizer: Computer Graphics, VO1.19, No.3, July 1985, pp.287-2%. [20] Perlin, 
K., HypertextureY Computer Graphics, VO1.23,No.3, JUiY 1989, pp.253-262. [21] Prusiiewicz, P., Lindenmayer, 
A., and Hanan, J., 4 DeveIop­ mental Models of Herbaceous Plants for Computer hnage~ PUPWSV Computer 
Graphics, VOL22 No.4, 1988, pp. 141­ 150. [22] Refie, P., Edelin, C., Francon, J., Jaeger, M., Puech, 
C. Plant Modelg Faithful to Botanical Structure and Development, Computer Graphics VO1.22,No.4, 1988, 
pp.151-158. [23] SchatYer,J. D., Tmceedings of the fldrd international Confer­ence on Genetic Algorithms, 
June 1989, Morgan Kaufmann Publishem, Inc. [24] Sims, K., Pansperntia, Siggraph Video Review 1990. [25] 
Smith, A. R., Plants, Fractals, and Formal Languages: Com­puter Graphics, VO1.18,No.3, July 1984, pp.1-10. 
[26] Steele, G., Common Lisp, The Language, Digital Press, 1984. [27] Thiig Machines Corporation, Connection 
Machine Model CM-2 Technical Summary, technical report, May 1989. [28] Todd, S. J. P., and Latham, W., 
Mutator, a Subjective Human Interface for Evolution of Computer sculptures: IBM United Kingdom Scientific 
Centze Report 248, 1991. [29] Viemot, X., Eyrolles, G., Janey, N., and Arques, D., 4 Com­binatorial Analysis 
of Ramified Patterns and Computer fm­agery of Trees~ Computer Graphics, VOL23, No.3, July 1989, pp.3140. 
 
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122753</article_id>
		<sort_key>329</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Specifying gestures by example]]></title>
		<page_from>329</page_from>
		<page_to>337</page_to>
		<doi_number>10.1145/122718.122753</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122753</url>
		<abstract>
			<par><![CDATA[Gesture-Based interfaces offer an alternative to traditional keyboard, menu, and direct manipulation interfaces. The ability to specify objects, an operation, and additional parameters with a single intuitive gesture appeals to both novice and experienced users. Unfortunately, gesture-based interfaces have not been extensively researched, partly because they are difficult to create. This paper describes GRANDMA, a toolkit for rapidly adding gestures to direct manipulation interfaces. The trainable single-stroke gesture recognizer used by GRANDMA is also described.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[gesture]]></kw>
			<kw><![CDATA[interaction techniques]]></kw>
			<kw><![CDATA[statistical pattern recognition]]></kw>
			<kw><![CDATA[user interface toolkits]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Input devices and strategies (e.g., mouse, touchscreen)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Interaction styles (e.g., commands, menus, forms, direct manipulation)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003124</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011666</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Touch screens</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31044887</person_id>
				<author_profile_id><![CDATA[81100497451]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rubine]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Information Technology Center, Carnegie Mellon University, Pittsburgh, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BUXTON, W. Chunking and phrasing and the design of human-computer dialogues. In Information Processing 86 (North Holland, 1986), Elsevier Science Publishers B.V.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BUXTON, W., SNIDERMAN, R., REEVES, W., PATEL, S., AND BAECKER, R. The evolution of the SSSP scoreediting tools. In Foundations of Computer Music, C. Roads and J. Strawn, Eds. MIT Press, Cambridge, Mass., 1985, ch. 22, pp. 387-392.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[COLEMAN, M. L. Text editing on a graphic display device using hand-drawn proofreader's symbols. In Pertinent Concepts in Computer Graphics, Proceedings of the Second University of Illinois Conference on Computer Graphics, M. Faiman and j. Nievergelt, Eds. University of Illinois Press, Urbana, Chicago, London, 1969, pp. 283-290.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>16111</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cox, B. J. Object Oriented Programming: An Evolutionary Approach. Addison-Wesley, 1986.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[DUDA, R., AND HART, 1a. Pattern Classification and Scene Analysis. Wiley Interscience, 1973.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[GUY ON, I., ALBRECHT, P., CUN, Y. L., DENKER, J., AND HUBBARD, W. Design of a neural network character recognizer for a touch terminal. Pattern Recognition (forthcoming).]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97938</ref_obj_id>
				<ref_obj_pid>97924</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[HENRY, T., HUDSON, S., AND NEWELL, G. Integrating gesture and snapping into a user interface toolkit. In UIST '90 (1990), ACM, pp. 112-122.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_obj_id>50759</ref_obj_id>
				<ref_obj_pid>50757</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[KRASNER, G. E., AND POPE, S. T. A description of the Model-View-Controller user interface paradigm in the Smalltalk-80 system. Journal of Object Oriented Programming i, 3 (Aug. 1988), 26--49.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_obj_id>122490</ref_obj_id>
				<ref_obj_pid>122488</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[KURTENBACH, G., AND BUXTON, W. GEdit: A test bed for editing by contiguous gestures. To be published in SIGCHI Bulletin, 1991.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>317461</ref_obj_id>
				<ref_obj_pid>317456</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[LEE, S., BUXTON, W., AND SMITH, K. A multi-touch three dimensional touch tablet. In Proceedings of CHI'85 Conference on Human Factors in Computing Systems (1985), ACM, pp. 21-25.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_obj_id>125251</ref_obj_id>
				<ref_obj_pid>125232</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[LIPSCOMB, J. S. A trainable gesture recognizer. Pattern Recognition (i 991 ). Also available as IBM Tech Report RC ! 6448 (#73078).]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[McAVlNNEY, P. Telltale gestures. Byte 15, 7 (July 1990), 237-240.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_obj_id>808598</ref_obj_id>
				<ref_obj_pid>964965</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[MINSKY, M. R. Manipulating simulated objects with real-world gestures using a force and position sensitive screen. Computer Graphics 18, 3 (July 1984), 195- 203.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_obj_id>93804</ref_obj_id>
				<ref_obj_pid>93791</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[MYERS, B. A., GIUSE, D., DANNENBERG, R. B., ZAN- DEN, B. V., KOSBIE, D., PERVIN, E., MICKISH, A., AND MARCHAL, P. Comprehensive support for graphical, highly-interactive user interfaces: The Garnet user interface development environment. IEEE Computer 23, 11 (Nov 1990).]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>5532</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[NEWMAN, W., AND SPROULL, R. Principles oflnteractive Computer Graphics. McGraw-Hill, 1979.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[NEXT. The NeXT System Reference Manual. NEXT, Inc., ! 989.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[PALAY, A., HANSEN, W., KAZAR, M., SHERMAN, M., WADLOW, M., NEUENDORFFER, T., STERN, Z., BADER, M., AND PETERS, T. The Andrew toolkit: An overview. In Proceedings of the USENIX Technical Conference (Dallas, February 1988), pp. 11-23.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[RHYNE, J. R., AND WOLF, C. G. Gestural interfaces for information processing applications. Tech. Rep. RC12179, IBM T.J. Watson Research Center, IBM Corporation, EO. Box 218, Yorktown Heights, NY 10598, Sept. 1986.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[RUBINE, D. Integrating gesture recognition and direct manipulation. In Proceedings of the Summer '91 USENIX Technical Conference ( 1991 ).]]></ref_text>
				<ref_id>19</ref_id>
			</ref>
			<ref>
				<ref_obj_id>145726</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[RUBINE, D. The Automatic Recognition of Gestures. PhD thesis, School of Computer Science, Carnegie Mellon University, forthcoming, 1991.]]></ref_text>
				<ref_id>20</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[SUEN, C., BERTHOD, M., AND MORI, S. Automatic recognition of handprinted characters: The state of the art. Proceedings of the IEEE 68, 4 (April 1980), 469-487.]]></ref_text>
				<ref_id>21</ref_id>
			</ref>
			<ref>
				<ref_obj_id>275628</ref_obj_id>
				<ref_obj_pid>29933</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[ZIMMERMAN, T., LANIER, J., BLANcHARD, C., BRYSON, S., AND HARVILL, Y. A hand gesture interface device. CHI+G! (1987), 189-192.]]></ref_text>
				<ref_id>22</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Specifying Gestures by Example Dean Rubine Information Technology Center Carnegie Mellon University 
Pittsburgh, PA Dean. Rubine @cs.cmu.edu Abstract Gesture-based interfaces offer an alternative to traditional 
keyboard, menu, and direct manipulation interfaces. The ability to specify objects, an operation, and 
additional pa­rameters with a single intuitive gesture appeals to both novice and experienced users. 
Unfortunate y, gesture-based interfaces have not been extensively researched, partly be­cause they are 
difficult to create. This paper describes GRANDMA, a toolkit for rapidly adding gestures to di­rect manipulation 
interfaces. The trainable single-stroke gesture recognize used by GRANDMA is also described. Keywords 
 gesture, interaction techniques, user interface toolkits, statistical pattern recognition 1 Introduction 
Gesture, as the term is used here, refers to hand markings, entered with a stylus or mouse, that indicate 
scope and com­mands [ 18]. Buxton gives the example of a proofreader s mark for moving text [ I]. A single 
stroke indicates the op­eration (move text), the operand (the text to be moved), and additional parameters 
(the new location of the text). The intuitiveness and power of this gesture hints at the great potential 
of gestural interfaces for improving input from people to machines, historically the bottleneck in human­computer 
interaction. Additional motivation for gestural input is given by Rhyne [ 18] and Buxton [ 1], A variety 
of gesture-based applications have been cre­ated. Coleman implemented a text editor based on proof­reader 
s marks [3]. Minsky built a gestural interface to the LOGO programming language [ 13]. A group at IBM 
con­structed a spreadsheet application that combines gesture and handwriting [18]. Buxton s group produced 
a musical score Permission to copy without fee all or part of (hismaterialisgranted providedthatthecopies 
are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of 
the publicamm and its date appear, and notice is given that copying is by pmnission of the Association 
for Computing Machinery. To copy otherwise. or In republish, requires a fee and/or specific permission. 
 01991 ACM-O-W791-436-W9MW7W329 $OW75 editor that uses gestures for entering notes [2] and more recently 
a graphical editor [9]. In these gesture-based ap­plications (and many others) the module that distinguishes 
between the gestures expected by the system, known as the gesture recognize, is hand coded. This code 
is usually complicated, making the systems (and the set of gestures accepted) difficult to create, maintain, 
and modify, Creating hand-coded recognizes is difficult. This is one reason why gestural input has not 
received greater atten­tion. This paper describes how gesture recognizes may be created automatically 
from example gestures, removing the need for hand coding. The recognition technology is incorporated 
into GRANDMA (Gesture Recognizes Au­tomated in a Novel Direct Manipulation Architecture), a toolkit that 
enables an implementor to create gestural inter­faces for applications with direct manipulation ( click-and­drag 
) interfaces. In the current work, such applications must themselves be built using GRANDMA. Hopefully, 
this paper will stimulate the integration of gesture recogni­tion into other user interface construction 
tools. Very few tools have been built to aid development of gesture-based applications. Artkit [7 ] provides 
architectural support for gestural interfaces, but no support for creating recognizes. Existing trainable 
character recognizes, such as those built from neural networks [61 or dictionary lookup [15], have significant 
shortcomings when applied to ges­tures, due to the different requirements gesture recognition places 
on a recognize. In response, Lipscomb [11] has built a trainable recognize specialized toward gestures, 
as has this author. The recognition technology described here produces a small, fast, and accurate recognizes, 
Each recognize is rapidly trained from a small number of examples of each gesture. Some gestures may 
vary in size anctlor orientation while others depend on size and/or orientation for discrimi­nation. 
Dynamic attributes (Ieft-to-righter right-to-left, fast or slow) may be considered in classification. 
The gestural attributes used for classification are generally meaningful, and may be used as parameters 
to application routines. The remainder of the paper describes various facets of GRANDMA. GDP, a gesture-based 
drawing program built using GRANDMA, is used as an example. First GDP s :!, 0 ,,\,   rlc1 (a) (b) 
(c) o-o­ , ,, un ,, 0 : ,,/ .. . .. . El 1 (e) (f) (g) (h) Figure 1: GDP, a gesture-based drawing 
program. The figure shows a sequence of windows in a GDP session. Ges­tures am illustrated with dotted 
lines, and the resulting graphics with solid lines. The eflect of each gesture is shown in the panel 
which follows it; for example panei (a) shows a rectangle gesture, and panel (b) shows the created rectangle. 
operation is sketched from the user s point of view. Next, the gesture designer s use of GRANDMA to add 
gestures to a click-and-drag version of GDP is described. The details of the single-stroke gesture recognition 
and training algorithms are then covered. This is followed by a brief discussion of two extensions of 
the algorithms, eager recognition (in which a gesture is recognized as soon as enough of it has been 
seen to do so unambiguously) and multi-finger gesture recognition. The paper concludes with an eye toward 
future work. A more detailed treatment of the topics covered in this paper may be found in the author 
s dissertation [20]. 2 GDP, an Example Gesture-based Application Figure 1 shows some snapshots of GDP 
in action. When first started, GDP presents the user with a blank window. Panel (a) shows the screen 
as a rectangle gesture is being entered. The user begins the gesture by positioning the mouse cursor 
and pressing a mouse button. The user then draws the gesture by moving the mouse. The inking, shown with 
dotted lines in the figure, disappears as soon as the gesture is recognized. The end of the gesture is 
indicated in one of two ways. If the user simply releases the mouse button immediately after drawing 
L, a rectangle is created, one comer of which is at 330 the start of the gesture (where the button was 
first pressed), and the opposite comer is at the end of the gesture (where the button was released). 
Another way to end the gesture is to stop moving the mouse for a given amount of time (0.2 seconds by 
default), while still pressing the mouse button. In this case, a reetangle is created with one comer 
at the start of the gesture, and the opposite comer at the mouse s location when the timeout occurs. 
As long as the button is held, that comer is dragged by the mouse, enabling the size and shape of the 
rectangle to be determined interactively. Panel (b) of Figure 1 shows the created rectangle and an ellipse 
gesture,whose starting point is the center of the new ellipse. After recognition the ellipse s size and 
eccentricity y may be interactively determined by dragging. Panel (c) shows the created ellipse, and 
a line gesture. As expected, the start of the gesture determines one endpoint of the line, and the mouse 
position after the gesture has been recognized determines the other endpoint, allowing the line to be 
rubberbanded. Panel (d) shows all three shapes being encircled by a pack gesture. This gesture groups 
all the objects that it encloses into a single composite object, which can then be manipulated as a unit. 
Panel (e) shows a COpY gesture: the composite object is copied and the copy is then dragged by the mouse. 
Panel (f) shows the rotate-scale gesture. The object is made to rotate around the starting point of the 
gesture; a point on the object is dragged by the mouse allowing the user to interactively determine the 
size and orientation of the object. Panel (g) shows the delete gesture, essentially an X drawn with a 
single stroke. In GDP, the start of the gesture (rather than its self-intersection point) determines 
the object to be deleted. Each GDP gesture corresponds to a high-level operation. The class of the gesture 
determines the operation; attributes of the gesture determine the operands (scope) as well as any additional 
parameters. For example, the delete gesture specifiestheobjecttobedeleted,thepack gesturespecifies the 
objects to be grouped, and the line gesture specifies the endpoints of the line. Note how gesturing and 
direct­manipulation are combined in a new two-phase interaction technique: when the gesture collection 
phase ends, gesture classification occurs, and the manipulation phase begins. The gestures used in GDP 
are all single strokes. This is an intentional limitation of GRANDMA, and a marked departure from multi-stroke 
gesture-based systems. The single-stroke restriction avoids the segmentation problem of multi-stroke 
character recognition [21], allowing shorter timeouts to be used. Also, the emphasis on single strokes 
has led to the new two-phase interaction technique as well as to eager recognition (both of which are 
potentially appli­cable to multi-stroke gestures). Finally, with single-stroke gestures an entire command 
coincides with a single phys­ical tensing and relaxing of the user, a property thought to contribute 
positively to the usability of user interfaces [1]. @ @ Computer Graphics, Volume 25, Number 4, July 
1991 Vxew &#38;ipTop :lew GraphlcObjectView ~L  -=-7@i+ e ,:obl Text View L1neDrawlnaV1ew GobiSet View 
\\ Llnel lew ?,ectdngle View ElllpseV1ew (a) Figure 2: GDP view classes and associated gesture One obvious 
disadvantage is that many intuitive symbols (e.g. X and -> ) are ruled out.  3 Design GDP s Gestures 
with GRANDMA Given a click-and-drag interface to an application, the ges­ture designer modifies the way 
input is handled, leaving the output mechanisms untouched. Both the click-and­drag interface and the 
application must be built using the object-oriented toolkit GRANDMA. Figure 2a shows GDP s view class 
hierarchy, the heart of its output mech­anism. The gesture designer must first determine which of the 
view classes are to have associated gestures, and then design a set of intuitive gestures for them. Fig­ure 
2b shows the sets of gestures associated with GDP s GdpTopView and GraphicOb] ectView classes. A GdpTopV 
i ew object refers to the window in which GDP runs. A Graph icObj ect View object is either a line, rectangle, 
ellipse, or text object, or a set of these. GRANDMA is a Model/View/Controller-like system [8]. In GRANDMA, 
a single input event handler (a controller in MVC terms) may be msociated with a view class, and thus 
shared between all instances of the class (including instances of subclasses). This adds flexibility 
while elim­inating a major overhead of Smalltalk MVC, where one controller object is associated with 
each view object that expects input. The gesture designer adds gestures to GDP s initial click­and-dmg 
interface at runtime. First, a new gesture handler is created and associated with the Graphi cOb j ec 
t Vi,ew class, easily done using GRANDMA. Figure 3 shows the gesture handler window after four gestures 
have been cre­ated (using the new class button), and Figure 4 shows the window in which seven examples 
of the delete gesture have been entered. Empirical evidence suggests that 15 training examples per gesture 
class is adequate (see Section 4.5). These 15 examples should reflect any desired variance in size and/or 
orientation of the gesture. DC= % r  P c -/v--l r)l (b  sets (a period marks the first point of each 
gesture).  EGzil es reHan ler- 3 PIP start: EventKind: PickET~ent handle: EventKind: DragE/ent done: 
EventKind: DropE,.,ent em-m Tooli?ind: MouseTool ToolKir.d: 1111 ToolF lr. d: r.il  Figure 3: Manipulating 
gesture handlers at runtime. This window allows ge,stuws tobe added to or deleted,from the set of gestures 
recognized by a particular view class. Normai Delete M P h SemantIcs Dump Delete ALL El- P iQ 
 ? Figure 4: Entering examples of the delete gesture. In this window training examples of a ge.stum=class 
my be udded or deleted. The Delete ALL button delews all the gesture k examples, making it easy to tn 
ou~ various forms of a gestuw.  -=--E-B= recog . [_Seq :[handler mousetool: DeleteCursor] :[view delete] 
] an = E@ done =- El El s r Figure 5: Editing the semantics of the delete gesture. The Semantics button 
is used to initiate editing of the semantics of each gesture in the handler s set, Clicking on the button 
brings up a structured editing and browsing inter­face to a simple Objective-C [4] interpreter (Figure 
5). The designer enters an expression for each of the three seman­tic components: recog is ewduated when 
the gesture is recognized (i.e. when the mouse stops moving), manip is evaluated on subsequent mouse 
points, and done is evalu­ated when the mouse button is released. The delete seman­tics shown in the 
figure simply change the mouse cursor to a delete cursor (providing feedback to the user), and then delete 
the view at which the gesture was aimed. The de­signer may now immediately try out the delete gesture,as 
in Figure 1g. The designer repeats the process to create a gesture handler for the set of gestures associated 
with class GdpTopVi ew, the view that refers to the window in which GDP runs. This handler recognizes 
the line, rectangle, and ellipse gestures (which create graphic objects), the pack gesture (which creates 
a set out of the enclosed graphic objects), the dot gesture (which repeats the last command), the text 
gesture (which alfows text to be en­tered from the keyboard), and the delete, edit, move, rotate-scale, 
andcopy gestures(which are also handled by Graph i cob j ec tVi ew s gesture handler but when made at 
a GdpTopVi ew simply change the cursor without oper­ating directly on a graphic object). The attributes 
of the gesture may be used in the gesture semantics. For example, the semantics of the line gesture are: 
recog = [Seq :[handler mousetool :LineCursor] :[[view createLine] set Endpoint :0 x:<start X> y:<startY>] 
];  manip = [recog set Endpoint :1 x: <current X> y: <current Y>] ; done = nil; The semantic expressions 
execute in a rich environment. For example, view is bound to the view at which the gesture was directed 
(in this case a GdpTopVi. ew) and handler is bound to the current gesture handler. Note that S eq executes 
its arguments sequentially, returning the last value, in this case the newly created line. The last value 
is bound to rec og for later use in the man ip expression. The example shows how the gesture attributes, 
shown in angle brackets, are useful in the semantic expressions. The attributes <s tart x> and < st art 
y>, the coordinates of the first point in the gesture, determine one endpoint of the line, while <currentx> 
and <currentY>, the mouse coordinates, determine the other endpoint. Other gestural attributes are useful 
in gesture semantics. For example, the length of the line gesture can be used to control the line thickness. 
The initial angle of the rectangle gesture can determine the orientation of the rectangle. The attribute 
< enc 1 osed>, which contains the list of views enclosed by the gesture, is used, for example, by the 
pack gesture (Figure Id). When a gesture is made over multiple gesture-handling views, the union of the 
set of gestures recognized by each handler is used, with priority given to the top­most view. For example, 
any gesture made at a GDP Graphi cOb j ec tVi ew is necessarily made over the GdpTopView. A delete gesture 
would be handled by the GraphicObj ectView while a line gesture would be handled by the GdpTopVi ew. 
Set union also occurs when gestures are (conceptually) inherited via the view class hierarchy. For example. 
the gesture designer might create a new gesture handler for the Gob j Set View class containing an unpack 
gesture. The set of gesturesrecog­nized by Gobj SetViews would then consist of the un­pack gestureaswell 
as the five gestures already handled by GraphicObjectView. Space limitations preclude an explanation 
of how GRANDMA s object-oriented user interface toolkh is used to construct applications and their click-and-drag 
interfaces. Also omitted is a discussion of GRANDMA s internals. The interested reader is referred to 
the author s dissertation [20]. 4 Statistical Single-Stroke Gesture Recognition This section discusses 
the low-level recognition of two­dimensional, single-stroke gestures. Both the classification and the 
training algorithms are short and self-contained, making them useful for those wishing to include trainable 
gesture recognition in their interfaces. For the present, it is assumed that the start and end of the 
input gesture are clearly delineated. As mentioned previ­ously, the start of the gesture is typically 
indicated by the pressing of a mouse button, while the end is indicated by releasing the button or ceasing 
to move the mouse. Each gesture is an array g of P time-stamped sample points: !lp = (Jpl.vp+fp) O< f) 
<[ Some simple preprocessing is done to eliminate jiggle: an input point within 3 pixels of the previous 
input point is discarded. The gesture recognition problem is stated as follows: There is a set of ( gesture 
classes, numbered O through ( 1. Each class is specified by example gestures. Given an input gesture 
g, determine the class to which g belongs (i.e. the class whose members are most like g). Statistical 
gesture recognition is done in two steps. First, a vector of features, f = [~1, . . . . jp], is extracted 
from the input gesture. Then, the feature vector is classified as one of the C- possible gestures via 
a linear machine. 4.1 The Features Features were chosen according to the following criteria. Each feature 
should be incrementally computable in con­stant time per input point, which allows arbitrarily large 
gestures to be handled as efficiently as small ones. Since the classification algorithm performs poorly 
when a class has a feature with a multimodal distribution, a small change in the input should result 
in a correspondingly small change in each feature. Each feature should be meaningful so that is can be 
used in gesture semantics as well as for recogni­tion. Finally, there should be enough features to provide 
differentiation between all gestures that might reasonably be expected, but, for efficiency reasons, 
there should not be too many. Figure 6 shows the actual features used, both geometri­cally and algebraically. 
The features are the cosine (jl ) and the sine (J2) of the initial angle of the gesture, the length (j~) 
and the angle (f4) of the bounding box diagonal, the distance (.fs) between the first and the last point, 
the cosine ({~) and the sine (.fT) of the angle between the first and last point, the total gesture length 
(~g), the total angle traversed (f9), the sum of the absolute value of the angle at each mouse point 
(f]()), the sum of the squared value of those angles (fl I), the maximum speed (squared) of the gesture 
(jl?), and the duration of the gesture (jl J). An angle s cosine and sine are used as features rather 
than the angle itself to avoid a discontinuity as the angle passes through 27r and wraps to O. The sharpness 
feature, j] j, is needed to distinguish between smooth gestures and those with sharp angles, e.g. U and 
V. Features ~Iz and ~1~ add a dynamic component so that gestures are not simply static pictures. Some 
applications may wish to disable these two features. The initial angle features, jl and j2, are computed 
from the first and third mouse point because the result is generally less noisy than when computed from 
the first two points. Computer Graphics, Volume 25, Number 4, July 1991 ,(lr ) A \ ( ,./, ,,,,) I , 
  A)=  I j, = Cos(l = (.r~ J ,,)/ (J2 -J-())2+ (,Y2 Yf))2 f2 = sinfi = (.Y2 -.vo)/~(12 -~0)2+(.w 
-yO)2 f3 = J(x777az - ,nin )2 + (.Ym~r -,Yn;,,, )2 !knar !/n]I71 fd = arctan .r,,, ar Z,, t,r, ff = 
(JP-I ro)2 + (!/P-l !4))2 f6 = Cos,j = (.rp-, -.r,,)/j5 f7 = sin~ = (.YP-l -,yO)/f5 LetArp = J p+l 
 .rI, &#38;/,1 = !/p+ I Yp ArpAyp_l Axp-l L?/,) Let Or = arctan Arp&#38; ,,_ I + 3,Yp&#38;/~/-l p=l 
P 2 Let.itp= Ip+l tp J13 = fP-1 lo Figure 6: Features used to identify strokes The aforementioned 
feature set was empirically deter­mined by the author to work well on a number of different gesture sets. 
Unfortunately, there are cases in which the fea­tures fail to distinguish between obviously different 
gestures (e.g. because the features take no account of the ordering of angles in a gesture). In such 
cases an additional feature may be added to discriminate between the thus far indis­tinguishable gestures. 
The extensibility of the feature set is a potential advantage that this statistical gesture recog­nition 
algorithm has over most known methods for online character recognition [21 ]. 4.2 Gesture Classification 
Given the feature vector f computed for an input gesture g, the classification algorithm is quite simple 
and efficient. Associated with each gesture class is a linear evaluation function over the features. 
Gesture class c has weights w~ifor O< i < F, where F is the number of features, currently 13. (Per-gesture-class 
variables are written with hatted subscripts to indicate their class.) The evaluations, v ~, are calculated 
as follows: L ,=w,o+ &#38;,if2 O<c<c (1) i=] The classification of gesture g is simply the c which 
max­imizes v t. The possibility of rejecting g is discussed in section 4.4. 4.3 Training Practitioners 
of pattern recognition will recognize this as the classic linear discriminator [5]. The training problem 
is to determine the weights w ~i from the example gestures. Iterative techniques were avoided to get 
efficient training, Instead, a well-known closed formula is used. The formula is known to produce optimal 
classifiers under certain rather strict normality assumptions on the per-class distributionsof feature 
vectors. Even though these assumptions generally do not hold in practice, the formula still produces 
good classifiers. Let ~te~ be the z thfeature of the eth example of gesture class c, O ~ e < ,!7t, where 
Et is the number of training examples of class c. The sample estimate of the mean feature vector per 
class, ~ ~, is simply the average of the features in the class:  7a= &#38; f ftei e=0 The sample estimate 
of the covariance matrix of class c, X ~ij, is computed as: e=o334 (For convenience in the next step, 
the usual l/(13t 1) fac­tor has not been included in Z ~ij.) The S ~ij are averaged to yield Xij, an 
estimate of the common covariance matrix. c 1 ~ij z X cell Zij = (2)c-1 C+~Et C=o The sample estimate 
of the common covariance matrixXij is then inverted. The result is denoted (X 1)ij. The weights w ~j 
are computed from the estimates as follows: A singular matrix can usually be handled by discarding a 
subset of the features. 4.4 Rejection A linear classifier will always classify a gesture g as one of 
the C gesture classes. This section presents methods for rejecting ambiguous gestures and outliers. Intuitively, 
if there is a near tie for the maximum per-class evaluation function v i the gesture is ambiguous. Given 
a gesture g with feature vector f classified as class i (i.e. vi > v~forallj# i) P(ilg)= ~_, 1 x e(Uj-Ui) 
j =0 is an estimate of the probability that g was classified cor­rectly. Rejecting gestures in which 
F( i Ig) < 0.95 works well in practice. The Mahalanobis distance [5] can be used to determine number 
of standard deviations a gesture g is away from the mean of its chosen class i. Rejecting gestures for 
which 62 > ~F eliminates the obvious outliers. Unfortunately, this thresholding also tends to reject 
many seemingly good gestures, making it less than ideal. Generally, a gesture-based system will ignore 
a rejected gesture, and the user can immediately try the gesture again. In contrast, the effect of a 
misclassified gesture will typi­cally be undone before the gesture is retried. If undo is quick Figure 
7: GSCORE gesture set used for evaluation (a period marks the start of each gesture). . . ~ ii / 5 8 
classes classes +-­+ $ 11 classes -~ - 1 15 classes -*-- II f 20 30 classes classes ~-­*­ - 41 dII I 
I I I 1 I I I O 10 20 30 40 50 60 70 80 90100 training examples per class Figure 8: Recognition rate 
vs. training set size. and easy, the time spent retrying the gesture will dominate. Since rejection 
increases the number of gestures that need to be redone (because inevitably some gestures that would 
have been classified correctly will be rejected), rejection should be disabled in applications with good 
undo facili­ties. Of course in applications without undo, rejection is preferable to misclassification 
and should be enabled. 4.5 Evaluation Despite their simplicity, classifiers trained using this algo­rithm 
usually perform quite well in practice. Performance has been evaluated on 10 different gesture sets. 
Figure 8 shows some typical results for the gesture set shown in Fig­ure 7. The gestures are from GSCORE, 
an editor for musical scores. The plot shows the recognition rate as a function of the number of training 
examples per class for various subsets of the GSCORE gestures. In the cases where 15 or fewer gesture 
classes are recognized by a classifier trained ComDuter GraDhics, Volume 25, Number 4. JtJIY1991 with 
15 or more examples per class, at least 98Yc of the test gestures are classified correctly. The 30 class 
classifier trained with 40 examples per class has a 97% recognition rate. Recognition dropped to 96?Z0when 
given only 15 train­ ing examples per cktss. Many of the misclassifications can be attributed to poor 
mouse tracking. Figure 9 shows the recognition rate for five gesture sets. Each set was trained on fifteen 
examples per class and eval­uated on 50 test gestures per class. In all cases the author was the gesturer; 
preliminary evaluations on other subjects show comparable performance. On a DEC MicroVAX H, the classifier 
spends 0.2 mil­liseconds per mouse point calculating the feature vector, and then 0.3 msec per class 
to do the classification (8 msec to choose between 30 classes). Training time is 4 msec per training 
example, 80 msec to compute and invert the covari­ance matrix, and 5 msec per class to compute the weights. 
The per-mouse point and per-gesture calculations are done incrementally as the gesture is entered and 
thus never no­ticed by the user. Performance improves by a factor of 12 on a DEC PMAX-3 100. in short, 
the classification time is negligible and the training is fast enough to be done in response to user 
input, such m the first time a gesture is made over a particular view class. 5 Extensions Versions of 
GDP utilizing eager recognition and Multi-Finder recognition have been built by the author to demon­strate 
the feasibilityy of the concepts. Unfortunate y, space limitations preclude a thorough discussion. For 
more de­tails, the reader is again referred to [20]. 5.1 Eager Recognition Eager recognition refers to 
the recognition of gestures as soon as they are unambiguous. The author s approach [19, 20] uses the 
basic stroke recognition algorithm to clas­sify subgestures (gestures in progress) as ambiguous or un­ambiguous. 
Note that classification occurs on every mouse point. In GDP, a user presses a mouse button, enters the 
L gesture, stops and waits for a rectangle to appear (while still holding the button), and then manipulates 
one of the rectangle s corners. Eager recognition eliminates the stop: the system recognizes the rectangle 
gesturewhile the user is making it, and then creates the rectangle, allowing the user to drag the comer. 
What begins as a gesture changes into a rubberbanding interaction with no explicit indication from the 
user.  5.2 Multi-finger recognition Recognizing gestures made with multiple fingers simultane­ously 
has recently become of interest due to the availability of new input devices, including multi-fingertouch 
pads [ 10], Number of Recognition;et Name Gesture Classes I Classes I Rate . 1. delete insert swapA 
t t spaceB Coleman &#38;j Iy down 100.0% spaceA ._ join  move -11 bigdelete swapB 1 = 3 < ,0 g~,~~ 
 Digits + g .? ; reqf: uf:e  six seven eight zero ~ a =-J>. c  ab d e Let :a-m b.. f 13 99.2% .mg 
ilJ&#38;.  i 1m lk h fiJH ~  Let :n-z 98.4% ~O.b ;~js_ 4 13 u Vw xY z Letters Union of Let :a-m 
and Let :n-z 26 97.1% Figure 9: Recognition rates for various gesture sets. the VPL DataGlove [22], and 
the Sensor Frame [12]. By gestures with views in the interface, and specify the effeet treating the multi-finger 
input as multi-path data (e.g. the each gesture has on its associated views through a simple paths of 
the fingertips) the single-stroke recognition algo-programming interface. Since the attributes of the 
gesture rithm may be applied to each of the paths individually and are available for use as parameters 
to application routines, the results combined to classify the multi-path gesture. A a single gesture 
can be very powerful. decision tree is used to combine the single-stroke classifi- Some parameters of 
application commands are best de­ cations, and a set of globaJ features is used to discriminate termined 
at the time the gesture is recognized; others require between different multi-path gestures whose corresponding 
subsequent manipulation and feedback to determine. This is paths are indistinguishable. the motivation 
behind the two-phase interaction technique Note that the stroke recognition cannot immediately be that 
combines gesturing and direct manipulation. After applied to DataGlove finger paths, beeause the DataGlove 
recognition the user can manipulate additional parameters has no way of indicating the start of a gesture, 
and also as long as the mouse button remains pressed. Eager recogni­ because the paths are three dimensional. 
This is one area tion smooths the transition from gesturing to manipulation. for future work. The foundation 
of this work is a new algorithm for recognizing single-stroke gestures specified by example. 6 Conclusion 
and Future Directions The combination of a meaningful, extensible feature set and well-understood statistical 
pattern recognition tech-This paper described GRANDMA, a tool that dramatically niques appears to be 
flexible enough to evolve beyond two­reduces the effort involved in creating a gesture-based in-dimensional 
single-stroke gesture recognition into the ges­terface to an application. Starting with an application 
with ture recognizes of the future. The recognition technology a traditional direct manipulation interface, 
GRANDMA lets is in no way dependent on the GRANDMA toolkit and its the designer specify gestures by example, 
associate those integration into other systems is strongly encouraged. 336 allow gestural interfaces 
to be added to existing applica­tions, enabling further use and study of this promising input technique. 
Based on the experience with GRANDMA, gestures are [91 KURTENBACH, G., AND BUXTON, W. GEdit: A test bed 
now being integrated into the NeXT Application Kit [ 16], for editing by contiguous gestures. To be published 
in the Andrew Toolkit 117]. and Garnet [ 14]. This should SIGCHI Bulletin, 1991.   Acknowledgements 
 I wish to thank CMU S School of Computer Science and CMU S Information Technology Center for their support 
of this work. I am also grateful to Roger Dannenberg and some anonymous reviewers for their helpful criticism 
of an earlier draft of this paper. Special thanks goes to Klaus Gross, whose detailed comments greatly 
improved this paper. References [1] BUXTON, W. Chunking and phrasing and the design of human-computer 
dialogues. In Information Pro­cessing 86 (North Holland, 1986), Elsevier Science Publishers B .V. [2] 
BUXTON, W.. SNIDERMAN, R., REEVES, W., PATEL, S., AND BAECKER, R. The evolution of the SSSP score­editing 
tools. In Foundations of Computer Music, C. Roads and J. Strawn, Eds. MIT Press, Cambridge, Mass., 1985, 
ch. 22, pp. 387 392. [3] COLEMAN, M. L. Text editing on a graphic display device using hand-drawn proofreader 
s symbols. In Pertinent Concepts in Computer Graphics, Proceed­ings of the Second Uni\ ersity of Illinois 
Conference on Computer Graphics, M. Faiman and J. Nievergelt, Eds. University of Illinois Press, Urbana, 
Chicago, London, 1969, pp. 283 290. [4] CO~, B. J. Object Oriented Programming: An Evolu­tionary Approach. 
Addison-Wesley, 1986. [5] DIJDA, R., AND HART, P. Pattern Classification and Scene Analysis. Wiley Interscience, 
1973. [6] GUYON, I., ALBRECHT, P., CUN, Y. L., DENKER, J., AND HUBBARD, W. Design of a neural network 
char­acter recognize for a touch terminal. Pattern Recog­nition (forthcoming). [7] HENRY, T., HUDSON, 
S., AND NEWELL, G. Integrating gesture and snapping into a user interface toolkit. In U~ST 90( 1990), 
ACM, pp. i 12-122. [81 KRASNER, G. E., AND POPE, S. T. A description of the Model-View-Controller user 
interface paradigm in the Smalltalk-80 system. .lournal of Object Oriented Programming 1,3 (Aug. 1988), 
26-49. [101LEE, S., BUXTON, W., AND SMITH, K. A multi-touch three dimensional touch tablet. In Proceedings 
of CHI 85 Conference on Human Factors in Computing Systems ( 1985), ACM, pp. 21-25. [111 LIPSCOMB, J. 
S. A trainable gesture recognize. Pal­rern Recognition ( 1991 ). Also available a.. IBM Tech Report RC 
16448 (#73078). [12] MCAVINNEY, P. Telltale gestures. Byte /5, 7 (July 1990), 237-240. [13] MINSKY, M. 
R. Manipulating simulated objects with real-world gestures using a force and position sensitive screen. 
Computer Graphics 18, 3 (July 1984), 195 203. [14] MYERS, B. A., GIUSE, D., DANNENBERG, R. B., ZAN-DEN, 
B. V., KOSBIE, D,, PERVIN, E., MICKISH, A., AND MARCHAL, P. Comprehensive support for graphical, highly-interactive 
user interfaces: The Garnet user in­terface development environment. IEEE Computer 23, 11 (NOV 1990). 
[15] NEWMAN, W., AND SPROULL, R. Principles of inter­active Computer Graphics. McGraw-Hill, 1979. [16] 
NEXT. The NeXT System Reference Manual. NeXT, Inc.. 1989. [17] PALAY, A., HANSEN, W., KAZAR, M., SHERMAN, 
M., WADLOW, M., NEUENDORFFER, T., STERN, Z., BADER, M., AND PETERS,T. The Andrew toolkit: An overview. 
In Proceedings of the USENI.Y Technical Conference (Dallas, February 1988), pp. 11-23. [18 1 RHYNE, J. 
R., AND WOLF, C. G. Gestural interfaces for information processing applications. Tech. Rep. RC 12179, 
IBM T.J. Watson Research Center, IBM Corporation, P.O. Box 218, Yorktown Heights, NY 10598, Sept. 1986. 
[ 19] RUBINE, D. Integrating gesture recognition and di­rect manipulation. In Proceedings ofrhe Summer 
91 USENIX Technical Conference (1991). [20] RUBINE, D. The Automatic Recognition of Gesrures. PhD thesis, 
School of Computer Science, Carnegie Mellon University, forthcoming, 1991. [21 I SUEN, C., BERTHOD, M., 
AND MORI, S. Automatic recognition of handprinted characters: The state of the art. Proceedings of the 
IEEE 68, 4 (April 1980), 469487. [22] ZIMMERMAN, T., LANIER, J., BLANCHARD, C., BRYSON, S., AND HARVILL, 
Y. A hand gesture in­terface device. CHl+G/ ( 1987), 189 1 92.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122754</article_id>
		<sort_key>339</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Computer animation of knowledge-based human grasping]]></title>
		<page_from>339</page_from>
		<page_to>348</page_to>
		<doi_number>10.1145/122718.122754</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122754</url>
		<abstract>
			<par><![CDATA[The synthesis of human hand motion and grasping of arbitrary shaped objects is a very complex problem. Therefore high-level control is needed to perform these actions. In order to satisfy the kinematic and physical constraints associated with the human hand and to reduce the enormous search space associated with the problem of grasping objects, a knowledge based approach is used. A three-phased scheme is presented which incorporates the role of the hand, the object, the environment and the animator. The implementation of a hand simulation system HANDS is discussed.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[grasp planning]]></kw>
			<kw><![CDATA[robotics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.9</cat_node>
				<descriptor>Manipulators</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553.10010554.10010555</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems->Robotics->Robotic components</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31023976</person_id>
				<author_profile_id><![CDATA[81100029745]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hans]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rijpkema]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[SCAN (National Institute for Computer Animation), Groningen, the Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31077334</person_id>
				<author_profile_id><![CDATA[81332500520]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Girard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[SCAN (National Institute for Computer Animation), Groningen, the Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>16590</ref_obj_id>
				<ref_obj_pid>16564</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W.W. Armstrong, M. Green and R. Lake, Near. real-time control of human figure models, Proceedings of Graphics Interface 1986]]></ref_text>
				<ref_id>Armstrong 86</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T.J. Axmstrong and D.B. Chaff'm, An investigation of the relationship between displacements of the finger and wrist joints and the extrinsic fmger flexor tendons, iomechanics, vol. 11, pp 119-128, Pergamon Press Ltd., 1978 (great-Britrain)]]></ref_text>
				<ref_id>Armstrong 78</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31464</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N.I. Badler, K.H. Mmmochehri and G. Waiters, Articulated figure positioning by multiple constraints, IEEE Computer Graphics and Animation 7(6), 1987]]></ref_text>
				<ref_id>Badler 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74356</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Baraff, Analytical Methos for Dynamic Simulation of Non-penetrating Rigid Bodies, Computer Graphics, Vol. 23, No. 3, july 1989]]></ref_text>
				<ref_id>Baraff 89</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378509</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Barzel and A.H. Barr, A Modeling system based on dynamic constraints, Proc. Siggraph, vo122., No. 4, August 1988]]></ref_text>
				<ref_id>Barzell88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R.A. Brooks, Planning Collision Free Motions for Pick-and-Place Operations, The international Journal of Robotics Research, Vol.2, No. 4, Winter 1983]]></ref_text>
				<ref_id>Brooks 83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Denavit and R. Hartenberg, A kinematic Notation for Lower Pair Mechanisms Based on Matrices, I. App. Mech., Vol. 77, pp 215-221, 1955]]></ref_text>
				<ref_id>Denavit 55</ref_id>
			</ref>
			<ref>
				<ref_obj_id>319127</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S.S. Fisher, M. McGreevy, J. Humphries and W. Robinett, Virtual environment display system, Proc 1986 ACM Workshop on Interactive Graphics, October 23-24, Chapel Hill, North Carolina.]]></ref_text>
				<ref_id>Fisher 86</ref_id>
			</ref>
			<ref>
				<ref_obj_id>27013</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K.S. Fu, R.C. Gonzalez and C.S.G. Lee, Robotics: Control, Sensing, Vision and intelligence, McGraw- Hill Book Company, 1987]]></ref_text>
				<ref_id>Fu 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Gilbert, D.W. Johnson and S. Sathiya Kee~thi, A fast Procedure for Computing the Distance Between Complex Objects in Three-Dimensional Space, IEEE Journal of Robotics and Automation, Vol. 4, No. 2, april 1988]]></ref_text>
				<ref_id>Gilbert 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31465</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Girard, Interactive design of 3D Computer Animated Legged Animal Motion. Computer Graphics and Applications june 1987.]]></ref_text>
				<ref_id>Girard 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>111166</ref_obj_id>
				<ref_obj_pid>111154</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Girard, Constrained optimization of articulated animal movement in computer animation, Making them move (mechanics, control, and animation of articulated figures), Eds: Badler, Barsky and Zeltzer, Morgan Kaufmann Publishers, 1990]]></ref_text>
				<ref_id>Girard 90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74335</ref_obj_id>
				<ref_obj_pid>74333</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J.P. Gourret, N.M. Thalmann, D. Thalmann, Simulation of object and human skin deformations in a grasping task., ACM Siggraph Proe, e~dings 1989.]]></ref_text>
				<ref_id>Gourret 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. lberail, J. Jackson, L. Labbe and R. Zampang, Knowledge-based prehension: Capturing Human Dexterity, Proceedings of the IEEE on Robotics and Automation 1988. pp 82-87.]]></ref_text>
				<ref_id>Iberall 88</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37428</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Isaacs and R. Cohen, Controlling dynamic simulation with kinematic constraints, behavior functions and inverse dynamics, Computer Graphics, ACM Siggraph Proceedings 1987]]></ref_text>
				<ref_id>Isaacs 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97897</ref_obj_id>
				<ref_obj_pid>97879</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[H. iwata, Artificial Reality with force-feedback: development of desk-top virtual space with compact master manipulator, Computer Graphics, ACM Siggraph Proceedings 1990]]></ref_text>
				<ref_id>Iwata 90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Kirckanski and M. Vukobratovic, A method for optimal synthesis of manipulation robot trajectories, Trans. ASME, J. Dynamic Systems, Measurements and Control 104, 1982]]></ref_text>
				<ref_id>Kirckanski 82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[C.A. Klein and C.H. Huang, Review of pseudoinverse control for use with kinematically redundant manipulators, IEEE Transactions on systems, Man and Cybernetics, SMC-13(2), march/april 1983]]></ref_text>
				<ref_id>Klein 83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J.U. Korein and N.I. Badler, Techniques for generating the goal-directed motion of articulated structures, IEEE Computer Graphics and applications, pp 71-81, 1982]]></ref_text>
				<ref_id>Korein 82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J.M.F. Lamdsmeer, Anatomical and functional investigations on the articulations of the human fingers, Acta anatomica, suppl. 25, 1-69, 1955]]></ref_text>
				<ref_id>Landsmeer 55</ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J.M.F. Landsmeer, A report on the coordination of the interphalangeal joints of the human finger and it's disturbances, Acta Morphologica Neerlando-Scandinavica 2. 59-84, 1958]]></ref_text>
				<ref_id>Landsmeer 58</ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J.M.F. Landsmeer, The coordination of finger joint motions, J. Bone Jnt. Sur. 45, 1654-1662, 1963]]></ref_text>
				<ref_id>Landsmeer 63</ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[A. Liegeois, Automatic Supervisory control of the configuration and behavior of multibody mechanisms, IEEE Transactions on systems, Man and Cybernetics, SMC-7 (12), december 1977]]></ref_text>
				<ref_id>Liegeois 77</ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[C. Lin, P. Chang and J. Luh, Formulation and optimization cubic polynomial joint trajectories for industrial robots, 1EEE Trans. Automatic Control AC-28(12), 1983]]></ref_text>
				<ref_id>Lin 83</ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[T. Lozano-Perez, Spatial Planning: a Configuration Approach, IEEE Transactions on Computers, Vol C-32, No.2, feb 1982]]></ref_text>
				<ref_id>Lozano-Perez</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617562</ref_obj_id>
				<ref_obj_pid>616011</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[A.A. Maciejewski, Dealing with the illconditioned equations of motion for articulated figures, IEEE Computer Graphics and Applications, May 1990]]></ref_text>
				<ref_id>Maciej 90</ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Vision, Freeman Press, San Fransisco, California, 1982]]></ref_text>
				<ref_id>Marr 82</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378528</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[M. Moore and J. Wilhelms, Collision detection and response for computer animation, Proc. ACM Siggraph 1988, Computer Graphics 22(4)]]></ref_text>
				<ref_id>Moore 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[J. Paillard, The contribution of perifpheral and central vision to visualUy guided reaching, Analysis of visual behavior, (eds: Ingle, Goodale, Mansfield) Cambridge, Mass. MIT Press, pp 367-385, 1982]]></ref_text>
				<ref_id>Paillard 82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[D. Pletinckx, Quatemion calculus as a basic tool in computer graphics, The Visual Computer 1989]]></ref_text>
				<ref_id>Pletinckx 89</ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[M. Girard and H. Rijpkema, efficient collision detection for convex and concave polyhedral objects, to be submitted.]]></ref_text>
				<ref_id>Rijpkema 91</ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[G. Sahar and J. Hollerbach, Plam~g of minimum time trajectories for robot arms, IEEE International Conference on Robotics and Automation, march 1985]]></ref_text>
				<ref_id>Sahar 85</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91403</ref_obj_id>
				<ref_obj_pid>91385</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[P. Schoner and D. Zeltzer, The virtual erector set: Dynamic simulation with linear recursive constraint propagation. Prec. 1990 Symposium on Interactive 3D Graphics March 25-28, Snowbird, Utah]]></ref_text>
				<ref_id>Schoner 90</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325242</ref_obj_id>
				<ref_obj_pid>325334</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[K. Shoemake, Animating Rotation with Quatemion Curves, ACM Siggraph Proceedings 1985]]></ref_text>
				<ref_id>Shoemake 85</ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[H. Tan and R. Potts, Minimum time trajectory planner for discrete dynamic robot model with dynamic constraints, IEEE J. of Robotics and Automation 4(2), 1988]]></ref_text>
				<ref_id>Tan 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[R. Tomovic, G.A. Bekey and W.J. Karplus, A strategy for grasp synthesis with multifmgered robot hands, Proceedings of the IEEE on Robotics and Automation 1987. pp 83-89.]]></ref_text>
				<ref_id>Tomovic 87</ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[M. Walker and D. Orin, Efficient dynamic simulation of robot mechanisms, Trans. ASME, J. Dynamic Systems, Measurements and Control, 1982]]></ref_text>
				<ref_id>Walker 82</ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[G. Wang and H.E. Stephanou, Chopstick manipulation with an articulated hand: a qualitative analysis, Prcw.eedings of the IEEE on Robotics and Automation 1988. pp 94-99.]]></ref_text>
				<ref_id>Wang 88</ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[D.E. Whitney, Resolved motion rate control of manipulators and human protheses, IEEE Transactions on Man-Machine systemsm MMS-10(2) pp 47-53, june 1969]]></ref_text>
				<ref_id>Whitney 69</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[J. Wilhelms, Using dynamic analysis for realistic animation of articulated bodies, IEEE Computer Graphics and Applications 7(6), 1987]]></ref_text>
				<ref_id>Wilhelms 87</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>54852</ref_obj_pid>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[A. Witkin and M. Kass, Spacetime constraints, ACM Computer Graphics, Siggraph Proceedings 1987]]></ref_text>
				<ref_id>Witkin 87</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Computer Animation of Knowledge-Based Human Grasping Hans Rijpkema and Michael Girard SCAN (National 
Institute for Computer Animation) Groningen, the Netherlands Abstract The synthesisof human handmotion 
and grasping of arbitrary and optimhing motion in the presence of kinematic and physically­shaped objects 
is a very complex problem. Therefore high-level bsaed constraints [Girard 90] [Kircksnski 82] [Lm 83] 
[Sahar 85] control is needed to perfonrt these actions. In or&#38;r to satisfy the ~an 88] [Witkin 87] 
have helped to lay the basis for umtrolling kinematic and physical constraints associated with the human 
hand individual fiigers. Howevm, the selection of grasping positions, the and to reduce the enormous 
search space associated with the problem coordination of fingers, and the determination of the pabn s 
motion of grasping objects, a knowledge based approach is used. A three-trajectory during a graapin8 
action requires a higher-level analysis phased scheme is presented which incorporates the role of the 
hand, and a control system that opera&#38;es as a function of the hand s the objec~ the environment and 
the animator. The implementation of geometric, kinematic, and physical characterics taken as a whole. 
a hand simulation system HANDS is discussed. Although we are able to easily pickup most objects with 
tiule eff~ the human capability for manrudly grasping ob~ts is anon-CR Categories: 1.3.5:computationalgcometrysndobjectmodeling; 
trivial task. Grasping strategies must take into account tie geometry 1.3.7:Thr=-Dimensional graphics 
and realism; and dynamic characteristics of the object to be grx the selection Keywords Grasp Planning, 
Animation, Simulatio~ Robotics of contact between the object and the fingers, thumb and patm of the hand 
and the problems associated with finding coUision-free paths in the context of the generat environment. 
1.Introduction Our approach begins with the realization that the ease with which Although there has been 
someprogresson simulating thegeomet-a person is able to decide how and whereto grasp an object depends 
ric deformation of the hand during a grasping contact [Gourret 89], on the person s familiarity with 
that ob~t. We view this human animating the grasping motion behavior of the hand remains a capability 
as a multi-stage process, in an approach that is similar to difficult task for the computer animator. 
Even the use of advanced that suggested by Tomovic ~omovic 871 in the robotics literature. inverse-kinematic 
and physically-based Iiib control techniques Fust, the object is idtmtified accmding to its similarity 
to a given demand that the animator tdously pxition thepalrn, the thumb, and class of shapes, such as 
a block, sphere, torus, cone, or cylinder. each frnger of the hand until the grasped object appears to 
be trapped Then, in the second stage, a grasping strategy associated with the by the hand in a natural, 
physically credible way. object s classification is chosen from a knowlege-bsse of class Special input 
devices that attempt to digitize hand motio~ such specific, pararnetenzed techniques In the thiid stag% 
the grasp is as the dutu-gfove, do not yet record precise individual fiiger and marginally ad@ed to manage 
the object s deviation in shape from thumb joint motion or ~ovide the feedback required for intuitive 
its classified shape. In this way, the asfronornical search spscc of interactive grasping [Fwhcr 86] 
~wata 90]. Augmenting digitized grasping techniques and grasping locations which are possible motion 
with some grasping intelligence may help to reduce the need between the hand and an arbitrary three-dimensional 
object may be for such extensive feedback. However, the focus of this paper is on restricted to the much 
smaller set of frequently used human grasping the problem of synthesizing grasping motion, rather than 
simply re-methods. cording it. In the next section, we begin with a kinematic &#38;acription of the Since 
the hand is a multi-limbed system, recent computer animat-hand. In section 3 the high-level control of 
the hand is discussed. In ion and robotics research directed at problems associated with section 4, we 
give.sn overview of the grsspphmning problem and the modelling limb kinematics and dynamics [Armstrong 
86] ~adler knowledge-based approach toward its solution. Finatly, in section 5, we give our conclusions 
with suggestions for future research. 87] [Girard 87] @acs 87] [Korein 82] ~atkez 82] [Barzel 88] ~ilhehns 
87] [Schoner90], collision detection [Gilbert 89] [Moore 88] [Baraff 89], motion pltig [Lmzano-Perez 
82] [Brooks 83], 2. Kinematics of the hand 2.1 Model of a human hand The fiigers have4 DOF, two at the 
connection with the palm, one Pmnussion to cnpy without fee all or part of this ma[crial is granted 
at the end of the first Figer part andone at the end of the second finger providedthat(hecopiesarcnotmade0[ 
(hs[ribrr!edfordirect cmnmercial~dvmt~ge,Ihc ACM copyrightnnticcandthetillc(JIthe part [See figure 1]. 
From this we can establish the link coordinate Publicationanditsd~tcIpPiII, andnotiw IS~ivcn that copying 
is hy frames of the fingers and obtain the four Denavit-Hmtcrrberg param­permission of the Assmcumnn 
Ior Cmnpu[!ng Machinery. To copy eters [Denavit 55] for each link. otherwise. or t{) rc>puhllsh,require> 
a fce and/or specific Pcmlissmn. ACM-()-KY791$(M)75 339  -436-X/9t/0t17/()33Y  Elf: SIGGRAPH 91 Las 
Vegas, 28 JuIy-2 August 1991 . SIICRIPH !l- F 8a da  ; 900 0~ 2 0II o  30 boo 401300 fig. 1: model 
of ajinger The thumb is very dextrous and therefore a more complicated manipulator. Because a large 
part of the thumb seems to be part of the palm of the hand and the joints are moving along non-trivial 
axes, the motion of a thumb is not easily understood. A workable model of the thumb that approximates 
the motions of a real human thumb is a manipulator with 5 lX)F [See figure 2]. From this we can establish 
the link coordute frames of the thumb and obtain the four Denavit and Hartenberg parameters for each 
link.  2.2 Basic motion control From the Denavit-Hartenberg parameters, itispossibleto find the transformation 
matrices for adjacent coordinate systems. The for­ward kinematics problem is easily solved by using the 
product of these transformation matrices [Fu 87]. Forward kinematics is useful for bending fingers at 
the fiints. However we ae also interested in simulating the human ability to place the tip of the fiiger 
at a certain location. For this inverse kinematics is required. 22.1. Inverse kinematicsof tieffngers 
A human finger has the property that it is (sfmost) impossible to move the joint of the last link(joint4) 
without moving the next to last joint (joint 3) snd vice-versa without forcing one of the two not to 
move in some unnaturaf way. Therefore, there is a dependency (degrees) 1 t 1 I I 1 20 40 60 80 100 ~-@ 
(degrees)  -w fig. 2: tnodelof attuunb 0 between these two joints that is caused by the tendon that 
runs through the finger. Careful observation reveals that there is an almost Iinearrelationship between 
t.hejoint angles q3 and q4. [See figure 3]. After measuring severaf human subjects, we found this could 
be reasonably approximated by: q4=213*q3 By making q4 fully dependent on q3 , the number of degrees of 
tieedom is reduced. The solution of the inverse kinematics will now be of the form:  q=(ql,C@, q3, 
2/3*q3) Landsmer s [Landsmeer 55, 58, 63] empirical studies of the physiology of the human hand addressed 
the relationship between the joint angles of the fingers and the @.ivstion of the tendons. Other studies 
support the finding that the relationship between the joint angles is not completely linear [Armstrong 
78]. We are planning to incorporate this more accurate model in the near future. A second way to simplify 
the problem is to note that the finger is a planar manipulator with the execption of the first joint. 
From this it follows thatql carIbe calculated directly from the dwplacement of the fingertip in the XOand 
yO direction, and that it is completely independent of the other joint angles. [See figure 4a]. From 
the factthatq3 andq4 are fully dcpenden~ itcanbeseenthat in order to reach an arbitrarypoint at distance 
d horn the origin of the Othcoordinate bun% there is a unique solution for q3, and therefore fig. 3: 
dependency of joint angles jig. 4: inverse kinematics of [hejinger jig. 5: single jinger conlrol jig. 
6: group control fig. 7: hand control also for q4. [See figure 4b]. These angles can be calculated using 
a binary search on q3 that converges quickly. The remainiig joint angle q2 can now be calculated such 
that the tip of the finger will be at the correct lsxation. 2.2.2. Inverse kinematics of the thumb Due 
to the greater kinematic complexity of the thumb, a closed­form solution was not found. Instead we empIoyed 
the resolved motion rate control method, in which the desired joint-space solution of the thumb is satisfied 
as a secondary goal [Liegeois 77] [Klein 83]. An excellent review of this method, along with a means 
of solving difficulties with singularities of dtepseudo-inverse jaeobian, may be found in [Maeiej 90]. 
The thumb s joint-space secondary goal, in context of our kinematic model, is recalculated at each position 
to minimize deviations from joint angles matching the following ex­perimental observations: q3 = 2*(q2 
-l/6*n) and q5=7/5 *q4.  3. High level control of the hand Attaining a desired posture by moving all 
the different joints of the fingers separately is a very tedious and time consuming process. Higher level 
control has been incorporated in our system, called HANDS, to ease the burden of manipulating many degrees 
of freedom and to prevent unnatural hand postures horn occuring. The interactive positioning of a hand 
into a desired gesture in HANDS may be accomplished by using a set of functions that give the animator 
different levels of control over the hand. 3.1 Single-finger control The lowest level of control involves 
direet independent control over each fiiger. [see figure 5]. This can be done using both forward and 
inverse kinematics of fingers, which satisfy the constraints of natural movement diseuaaed in the previous 
section. 3.2 Group control The second level of control isthatof groupcontrol. [see figure 6]. The user 
can select which fingers belong to a group andthen use anumber of functions to change the hand posture: 
Closing and cpening of a group. This function closes or opens all fingers that are part of the group 
at the same time, in the same way as this can be done for single fingers.  Spreading ofa group Me fmg~s 
of-the group are spread outward or inward by changing the joint angle of the fust joint of all the fingers 
in the group, depending on their location on the hand and the joint angles of the two most outward fingers. 
33 Hand control The last level of control is complete hand control [see figure 7]. -Hand posture library 
The user can build up a hand pmme library from which he can choose desired hand postures. These hand 
postures are made with the use of tie above functions and can then be stored with an unique name in the 
library. Thus hand postures can be added to and deleted horn the library. The advantage of this is clex 
a posture can lx constructed once and then easily be reeallcd from thelibrary and then pasted in. fig. 
8: tht?fUkbS of the hand Precaleulcatedpostures Beaides the user-de~med hand postures there are also 
system­defmed hand postures. These are hand postures that might be difficult to achieve with theamtrcda 
mentioned above orposturea that are very ofien used. Examples of these hand postures are the hand at 
arestpositio~ af~t andsomepinchea. Aprnchisthestate inwhichthetipof thethumbisplacedagainstthetipof aftnger. 
These postures are calculated using edision detection [Gilbert 88][Rypkema90]sothattheti~ areexaetlytouchingeachother, 
and not interseeting. [see figure 8]. 4. Grasp Planning 4.1 The elemerttainvolvedh grasping When grasping 
behavioris incorporatedintoaninteractivecom­puter animation systenL four elements are of main importance 
-the object the hand -the environment the usex-interface These elements have eertairtcharacteristics 
that influenee the design of the grasping motion [see figure 9]. Characteristics of the target object: 
Geometrical What is the size and the shape of the object? Physicak What are the mass, distribution of 
mass, and inertia of the ob~t? Mechanical: What is the rigidness (i.e. is it completely rigi~ elastic 
or flexible) and the eoefilcient of fiction of the objeet? [Wang 88]. Characteristics qfthe hand. Geometrieak 
How large is the hand, what is the shape of the hand? Physicak What is the strength of the hand? Mechanieak 
DeXtetity (hoW skilled is the hand?), grip (what is the &#38;Iction coefficient of the hand?) Naturdnea= 
Human sensory motor eonmol, muscular con Straints. Topological: What are the connections and degrees 
of free dom at eaeh of the joints of the hand. environment s­dymmicat } 1 1 I + grasping proeeaaea 
+ Characteristics oftk environment Information about the environment is required to determine potential 
obstacles and eollisiona. Spatial complexity Where are all other objects (location and orientation)? 
Dynstnieal complexity: Howdootherobjccts, arrns,etc.move in time? Characteristics c#tk urer-intetjhce 
Expression: How doea a usez want to express his ideas? Automation: How muchdoestheuser want to be done 
automati Cidly? Control: Unk whatcircurnstaneea does auser want tube able to take control? output When 
there are multiple solutions, when should the system offer choices and when must it out put just onq 
working solution? 4.2 A Knowledge Baaed approach Previous research on the analysis of human hand motion 
supports a knowledge-based approach to the synthesis of a grasping behavior ~omovic 87] ~berrdl 88]. 
Human beimgs perform grasping tasks by usrng czxperiertce that has been gathered over time. The appro=h 
followed here is to incorporate this experience into a knowledge base. The knowledge base can be seem 
as a collection of precalculated strategies for dfferent categories of situations, thus partitioning 
the enormous search space of possible solutions into computatiomdly managsble subsets. Each of the knowledge-based 
strategies assumes the form of a three-phased decomposition into tie following subtasks [see figure lo]: 
1. The task initialization phase 2. The target approach phase 3. The grasp execution phase  In the 
task initialization phase, the target objeet is classified as a primitive and the overall strategy for 
grasping the ob~t is &#38;ter­tnined. During the target approach phaa%all pssiblegrasppsitions are faltered 
to obtain the feasible ones from which the hand is preshaped to assume art optimal or user-selected grasp 
position. Once the hand is preshaped to the primitiv~ the grasp execution phase ensures that the fingers 
will close around the setual object. Task initialization phase Target approach phase > + grasp motion 
fig. 10: &#38;compositwn of grasping tark jig. 9: elements involved in grasping dx,*. &#38; 43 The 
fask Ittitlalbrkst phase Whenaspecikgmqing taakiatobecarried oWthemotionis mfkncedby thehigh-levdgaal 
thatleadstothsgraspingmotion. Forexanqieahammesshmkibegrqed differentlydepmdngon w*-*~pdatikm@andmLhfme 
the caaofti -tid~-chrn ti-ktitifla pbrnmkmbtie mexcti~ti-~ mgedl~tik grasp confi~ations thstdonot satis~ 
some deaired goaL The Chlasifkatkn of grasfsl m tetms of goals has not been implemestted. Thus far, otu 
knowledge base consists of classi&#38;Xions baaed O@ ontheSK of ti objw. _ the object identification 
process [see figure131theobjectisclassifiedasoneof tbepitnitive ob~~~~~~tix.)[=fi~ell]~ti valuesof thesmibuteaamspecitied.Classificationof 
complex3D shapeaas geneiicpimitives is a difficultthat has been psobkm addmsed in the computes vision 
literature ~ 87] ~arr 82]. Ohjects can bemmpased withthedifkrent primitive typesby looking atvo-cesttcrof 
gravity, etc.lleprimitivea must also be oricstted m such away that the best matching between the @mitive 
and the target object is afhieved by ntinimii of differences m their Occupkd volumes. Human beings have 
a vexy good twmaeof classifying objects as primitives. Therefore m tlw cusmnt version of the gasping 
Sysm tid-~eof~ob~=a-~ tivekkfi~ti~. ThiacanbedominasimpIe intemcU.ve way by selecting a @mitive fromapop-up 
tnamandtlmt visuaIlypoaitioning the@nitivese that it ckmmwrii the object. Oncethepfimitive isknown, thevahtesfor 
theattributesofthe @mitive can be mmputed automatically. These attributes are very s@k. ha MAtiymtitigti 
dmgtiti===&#38;, * d&#38;Faa*etiymtitiurdfmaqWda­tiymtirtiu rdtiti~h[=fi~ll]. Fiiy, informattmabout theenviNmment 
 . Shmdd be gathered Theenv. uonmuMcanputreslrictiona onthewayanobject is grasped. ~~w~titi~get~~t -bhkhmfmtihti 
mmm~ittipstible m-tiprn~mti=oftie object. 4.4 The target approachphase Thepositionoftbehand inchxkaboththepositionoftlwpalmand 
the positions of the f-. As a convention we will call a hami position that specifies a grnsp a grqptwition. 
The seawhapaceof possible grssp positiona for a given object is emmnously Iarg%so it would be very time 
mmwming to fti a correct and natural grasp by simply searching all these possibilities. This follows 
partially fiutnthe fact that the hand has ahugenumber ofdegrees of freedom. ht themodel evay6nger has4DOF, 
tlE thumb has 5 DOF ad the hand 3 DOF, so this@~ (4x4)+5+3 = 24 DOF,whichshowshowdextrousahumanhandis.Ako, 
whenonly r---evtindu ­ .  antsiderittg fmga+bject cuttact ~ the number of possible cmtacts is extmmelylarge. 
Sahsbury has shown that a hand with five three-linked fingers may touch a ball in S40 ways ~aaon 85]. 
Agraapshould be fomxltkomthialmge solution space thst minimha muack tension and Optimkathestability of 
thegripon the object. Themunber of posaibilitiea may be limited by enforcing a setof candraintsandpr~ies 
that can hedmived from observing how human lx+mgs tend to grasp objects. The ffi pmpesty that deu~ the 
large number of possible sktiotifi~ti~-mfickqo~=wtititi fingers @aced on qpsitejaccs. This also makes 
sense physically, ~rntisw~ti fa=titi fmg--mexmati ob@rntim_astikpqk~Mly l*stitief~ needed whengmspingt 
heobjectina nyotherwsy. Asecondpmperty ofhumangrasping isthattithumb abrwst always takzspart inthegrq. 
Gaspswithout the thumb are very rare and they don t kok natural. Wheat picking up an object using _i@fm, 
titimbb#Am-f=ofti&#38;~tmdti other ilstger sthattakepar tinti grasp srepkcedonthe opposite fsce. rhesetwoconatdt 
tdpqdeameanin thecaseofgrasping a block thatthenumberof grasp typcaislimkedto24 #opp.faces . WWnb I&#38;atw 
. #@n focationl = 3.2.4=24 [see figure 12] jig. 12: grasp positiom for a bzbck object hand I In order 
to automate grasping we need to fiit determine which grasp positions are feasible. Then we wish to select 
fhe best or optimal grasp out of this feasible set. Instead of computing every possible grasp position 
dellrted by the constraints and properties d~cussed in the previous sectiom a series of more computationally 
eftlcient tests may be applied to irtcremezttally rule out infeasible grasps. The target approach phase 
fiist applies these tests and then orders the feasible grasps in accordance with art optimization criterion. 
Then the hand is lead from an arbitraryposition to the vicinity of the object, with the hand preshaped 
to grasp the target object s associ­ated primitive. The target approach phase consists of the following 
subtasks [see fig. 13]: 1. determination of contact surfaces of the object s associated primitive 2. 
selecting the hand position with respect to the feasible contact surf-s  3. selecting the graspmcde 
and hand structure for the chosen hand position 4. preshaping of all fingers to grasp the object s primitive 
 5. path generation of the palm towards the preshaped hand position  4.4.1 Con&#38;act suqface determination 
The fust phase in which infeasible grasp positions are eliminated is the determina tion of contact surfaces. 
To determine whether a certain contact surface combination will lead to incorrect grasps, four tests 
can be applied 1. are the contact surfaces reachable? 2. is it possible to spread the hand enough so 
that the fingers cartclose around the object? 3. are both the contact surfaces free, i.e. are they not 
blocked by other objects? 4. does it make sense to grasp the object with these contact surfaces, i.e. 
does the contact surface combination conflict with the high level goal?  If any of the above tests is 
not satisfie4 that contact surface combwtion should be deleted from the list of possibWies. In the current 
version of the grasping system ordy the fmt two tests are applied. (The other two tests need information 
that should be collected during the task initialization phase, outlined in section 4.3). fig. 13: task 
initialization and target approach The fwst tes~ to determine if the contact surfaces are reachable, 
is done by calculating the dkance from the base of the arm to each contact surface. If the distance for 
at least one of the two contact surfacea is larger than the length of the ~ it means that the contact 
surface combination is not reachable, and therefore it has failed the test. The second test deals with 
the spred of the hand and the size of the primitive. The spread of the hand is a measure for the distance 
between the tip of the thumb and the the tip of another finger. When the hartd is flat and the thumb 
is pointing outwards the maximum spread cart be determimd for each thumb-fmger combination by calculating 
the distamx between the two tips. The maximum spread of the hand is then themaxirmun of all these maximum 
spreads of the fingers. Objects can only be grasped with contact surfaces that are no further apart than 
the maximum spread of the hand. 4.4.2 Determination of the grasp position The second level of deleting 
infeasible grasps is the selection of the grasp position. To do this the following tests can be applied: 
is the hand position within the reach of the arm? will the grasp follow fkom an feasible (and optimal) 
arm motion? The fust test to determine whether the hand psition is within reach of the arm is done by 
calculating the location of the wrist at the desired hand position. Then the distance from the base of 
the arm to the desired wrist location is calculated. If this distance is larger than the length of the 
arm minus the length of the hand then the desired hand position is not reachable and is thmefore excluded 
from further consideration. In the case of the second test a diftlculty is that the selection of the 
best grasp must take into account the motion of the entire arm. For example, the best grasp may be the 
one which is reached by the minimum energy path. The constrained optimization of collision free limb 
~ajectories requires numerical methods such as steepest descent gra&#38;ent techniques [Wltkin 87], or 
dynamic programming [Girard 90]. These techniques are extremely costly, requiring opti­mization of path 
and speed distribution in terms of cost criteria involving both kinematic and dynamics based quantities. 
A further complexity arises due to thenee.d to calculate the actual tension in the tendons and muscles 
rather than the idealized rotationrd torques of inverse-dynamics formulations. Thesefore we use a heuristic 
approach that orders the feasible graspa, but leaves the final decision to the user. A heuristic that 
has proven effective is to minimim the weighted sum of the translational and rotational distance between 
the initial hand position artdthe fimal grasp position. The translational dkplacement is given by the 
dK­tarw horn the inkial wrist location to the final wrist location. The rotational duplacement of rhe 
hand can be calculated by using the quatesrtion formulation [Shoemake 85] [Pletinckx 89]. 4.4.3 Grasp 
made and hand structure se fection Withthecxmtact surfaces for the thumb and the fingers known, we must 
still determine the grasp mode and hand structure for the grasp. The selection of thegraap mode depends 
mairdyon thepurposeof the action. The grasp mode may be a lateral or paltnar grasp [see figure 14]. A 
glass is picked up most of the time with a lateral grasp when the goal is toput the glass on the shelf, 
but whertthe same glass is used for driing it will probably be picked up with apahnar grasp (unless the 
contents of the glass are very hot). Sometimes the selection of the grasp mode can also depend on the 
characteristics of the object. If an object is very heavy, a power grasp is needed to be able to lift 
the object. So when restricting the grasp mo&#38;s to lateral and palmar grasps the determination of 
which of the two should be applied depends on the high-level goal. In in our current implementation the 
selection of graapmode is left to the user. jig. 14: pabnar and iateralgrqn Although there are a large 
number of hand structures that are possible to use when grssping objects, in practice, only a small number 
of them me used. With the following notation T = thumb, 1 = index jinger, M = middfefmger, R = ring finger 
andL = littie finger, the most natural grasps can be defined as ~omovic 87]: 2-fiigered structures (pinches) 
pinch-TI pinch-TM pinch-TR pinch-TL 3-fingered structures three-TIM three-TMR thr=-TRL  Computer Graphics, 
Volume 25, Number 4, July 1991 fig. 15: hand structures 4-fingered structures four-TIMR four-TMRL S-fingered 
structures five-TfMRL The above add to a total of tenhands~ctures [see figure 15]. The selection of 
the hand structure can be subdivided into two different problems: -How many fingers can be used? -Which 
fingers can be used?  The maximum number of fr.ngers that cart be used in the grasp depends on the size 
of the object and the size of the hand. The available space on the object must be compared with the space 
occupied by a single fiiger to give an indication about tie maximum number of fingers. Thedetemma-tionof 
which fmgemarevdidfor thedesiredgmsp dso depends on therehuive sixeof the hmtd and object. The distance 
betweem the two contact surfaces detemdnea how much the figem must be spread to grasp the object. The 
aekction of the contact SurfaceaCmnputedatanearlierstage guaranmeathatthereisatkast onefingerforwhichthemaximum 
Spreadislargerthanthisdistance. All fingers that have amaxinmrn spmd linger than this &#38;stance are 
vslid grasp fingers. After cakzdating the maximum number of grasp fingers Qtd de@min@ which fingers are 
valid we must still choose ths best combination of llngers. Our observation of human grasping have lead 
us to formulate the following genezal ruks to select a hand structure 1) maximize the number of fingers 
(since more contacts improve stabii]ty) artd2) favourthe use of fingers closcz tothethumb (simxthey arestronger).GurimplemmtationHANDS,picb 
ahami structure using the aboveruks [see figure 18] but allows the user to rntmveneand sekct anotherhand 
struchue [see figure 19]. 4.4A Preshaping of thejlngers Having established the contact surfaces, the 
approximategrasp positi~haml structure andgrasptrtodq amoreptecise hand position must now be cdctdatd 
Ihe palm position must allow b fingers to be pkced on the object in such a way that the fotces they exert 
on the object produce a stable grasp. Using the notion of thepinch-fi~, the correct hand position can 
be calcukted m a geomdcal way. The pinch-lrne is the imaginary line between the thumb and a fmgex, called 
the pinch jhger [see figure 16J. l%eforces thatbothfmgemof thepinchexerton the object are directed along 
this pinch-line. In order to establish a stable grasp it makes sense that this pinch-line should go through 
the center of ~avity of theobjezt. Anoth= asaumptionthatcanbe made isthattlw thumb and pinch fmga are 
placed on opposite contact surfacas m such a way that the forces exerted by b fingers are dkected perpendicukr 
to these contact surfacea. fig. 16: thepinch-line The chokeof which of the graapfmgem is thepinch hgercanbe 
basedonthesameobservations made rnaekcting thehandstructmw the grasp fmgex closest to the thumb is most 
likely to be the pinch finger. Theorientationof thepinch-linevariea as a complex furtckt of the natural 
kinematics of the phwh fingers. The co@mation m which thepinchfmgera areacettaindktance apartmaybefound~ 
and khrel&#38;ti@hpsiti-.~xdmd@cb of the-tid as shown m [figure 8], are automatically precalculated to 
aati@ the joint angle constraints of the fingers and thumb using the iltVerSe­kinematics pmmhm?s described 
m section 2 The desired distance between the fingertips may be quickly achieved by using a binary mh. 
~~h-bknwtie bkm-titipoftitib and the tip of the pinch finger expressed with respect to the hatxi coordinate 
system. hmti~dm.Toql-ti~goftiMdl the grasp fiitgers am moved fkom their-position to their relaxed pinch 
position tmtil they collide with the primitive associated with the object. 4A5 Pathgeasnadon Knowing 
theinitial configllration of thehand andarmandthe tOWdSh object needa to be &#38;Wmined. Experimentshaveshowndtstthisqq.nwtchpathhas 
apredhfie shqu ~aillard 82] flornovic 87 J. Seen front one side the hand travels along a S&#38;fightline 
and seen ftvm another si&#38; it travels alongacnrve[see figure 17JThispmpertycanbe. mcqmmedinto thegmaping 
system byaddinganothez key Posi*cdlcxltk approachposidcmalongthedesiiedpath Invemdinematicsusing paeubinvexseccmtrol[Girard90]~egeois77] 
[Maciej90] isused tomovethehand dongthede@mtedpath. topview Sideview jig. 17: ~proachpath of the hnnd 
 4.6 The grasp exectttiott phase To cxxnpkte ~ grasp, the fingem tuzd to move from tlwir position on 
the primitive aamciated witi the object so that they are touching the object itself. The thumb and pinch 
fmgezmove towards each other by intmpolating their Cmrentpoaitionandtheir completed @hptiti~-~ofti-ofti@~mU~tititi 
objt@thatlink catmotbemoved anymore. Thistneansthatwhen linkico~joitttsj withj=(9~,..i must belocked. 
fhesame andthetarget object aremldated bY*mocwee+ decompoaitionmethod for concavepolygondobjects ~jpkema91] 
amlafastpmcedum fwcmnputingtlw distancebeivmstconvex poly~ objects[Gti 88].A discussionof ou mmion -­tionschemeisbeyondthescopeof 
thispaper. 5. conclusion The &#38;velopment of knowledge-basedhandbehavbr hasmade thetaskof cornpubxanimatedgmspingrelatively 
simpl%whik still ~themeativerole andguidanceofti~. We are currently extending our graspingknowkdge-baae 
to include more compkx CkkfiC@iO!t primitive&#38; forexampkpokingOtldS finger through the tile of a torus-like 
cup handle. The approach we have taken willdkwus toaddmorecoq@ued =P== of =i-. mhwstie@ atik W~atik~m 
sti~&#38;fm _ i~ We think thattheuse of kmwkdge-baaed techniques will play an ~ly -t role in * ~lrng 
of mob W involve Cotnpkx physical and geomewic constrain@ particularly what op­timdbehaviors must be 
sekcted fiotn abroad set of feasible actions.   H. Iwaw Artitlcisl RealiWwith force-feedbaclc development 
of desktop virtual space witi compact master manipulator, Computer Graphics, ACM Siggraph proceedings 
1990 [Kirckanski 82] M. Kirckanski and M. Vukobratovic, A method for optimal synthesis of manipulation 
robot traje@ories, Trans. ASME, J. Dynamic Systems, Measurements and Control 104, 1982 [Klein 83] C.A. 
Klein and C.H. Huang, Review of pseudo­inverse control for use with cinematically redundant manipulators, 
IEEE Transactions on systems, Man and Cybernetics, SMC-13(2), march/april 1983 [Korein 82] J.U. Korein 
and N.L Badler, Techniques for generating the goal-directed motion of articulated structures, IEEE Computer 
Gr@ics andapplications,pp 71-81,1982 [Landsmeer55] J.M.F. Landsmeer, Anatomical and fictional investigations 
on the articulationsof the human fingers, Acts anatomic%suppl. 25, 1-69, 1955 [Landsmeer58] J.M.F. Landsmeer,A 
reporton the coordination of the interphalangealjoints of the human finger and it s disturbances,Acts 
Morphologic Neerlando-Scandinavica 2. 59-84,1958 [Landsmeer63] J.M.F.Landsmeer,The coordinationof finger 
joint motions, J.Bone Jnt.Sur.45, 1654-1662,1963 [Liegeois 77] A. Liegeois, Automatic Supervisorycontrol 
of the contlguration and behavior of muhibody mechanisms, JEEE Transactions on systems, Man and Cybernetics, 
SMC-7 (12), december 1977 [Lin 83] C. Lin, P. Chang and J. Luh, Formulation and optimization cubic polynomial 
jornt trajectories for industrial robots, IEEE Trans. Automatic Control AC-28(12), 1983 [Lozano-Perez] 
T. Lozano-PereL Spatial Planning: a Cotilguration Approach, IEEE Transactions on Computexs, Vol C-32, 
No.% feb 1982 [Maciej 90] A.A. Maciejewski, Dealing with the ill­conditioned equations of motion for 
iutictdsted figures, IEEE Computer Graphics and Applications, May 1990 [Marr 82] Vision, Freeman Ress, 
San Fransisco, California 1982 [Moore 88] M. Moore and J. Wilhelrns, Collision detection and response 
for computer animatiom Proc. ACM Siggrsph 1988, Computer Graphics 22(4) [Psilhud 82] J. Psilla@ The contribution 
of peripheral and central vision to visuallly guided reaching, Analysis of visual behavior, (eds: Jngle, 
Goodale, Mansfield) Cam&#38;ldg~ Msss. MIT hSSS, pp 367-385,1982 Pletinckx 89] D. Pletirwkx, Quaternion 
calculus as a basic tool in computer graphics, The Viiual Computer 1989 [Rijpkema 91] M. Girardand H. 
Rijpkem% efficient collision detection for convex and concave polyhedral objects. to be submitted. [Sahm 
85] G. Sahar and J. Hollerbac~ Planning of minimum time trajectories for robot arms, IEEE International 
Conference on Robotics and Automttti~ march 1985 [Schoner 90] P. Schoner and D. Zeltz.er, The virtual 
erector set: Dynamic simulation with linear recursive constraint vP%atim. ~. 1990 Symposium on Interactive 
3D Graphics March 25-28, Snowbird, Utah [Shoemake 85] K. Shoemake, Animating Rotation with Quaternion 
Curves, ACM Siggraph Pmceedm-8s 1985 l-fan 88] H. Tan and R. Potts, Minimum time trajectory planner for 
discrete dynamic robot model with dynamic constraints, IEEE J. of Robotics and Automation 4(2), 1988 
~omovic 87] R. Tomovic, G.A. Bekey and W.J. Karplus, A strategy for grasp synthesis with multifiigered 
robot hands, Proceedings of the IEEE on Robotics and Automation 1987. pp 83-89. ~alker 82] M. Walker 
and D. Grin, Eftlcient dynamic simulation of robot mechanisms, Trans. ASME, J. Dynamic Systems, Measurements 
and Control, 1982 Wang 88] G. Wang and H.E. Stephanou, Chopstick manipulation with an articulated hand 
a qualitative analysis, proceedings of the IEEE on Rolmtics and Automation 1988. pp 94-99. Nhimey 69] 
D.E. Whimey, Resolved motion rate control of manipulators and human protheses, IEEE Transactions on Man-Mschme 
systemsm MMS-10(2) pp 47-53, june 1969 ~ilhehns 871 J. Wilhelms, Using dynamic analysis for realistic 
animation of articulated bodes, IEEE Computer Graphics and Applications 7(6), 1987 ~itkin 87] A. Witkin 
and M. Kass, Space.time constraints, ACM Computer Graphics, Siggraph Proceedings 1987  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122755</article_id>
		<sort_key>349</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Animation of dynamic legged locomotion]]></title>
		<page_from>349</page_from>
		<page_to>358</page_to>
		<doi_number>10.1145/122718.122755</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122755</url>
		<abstract>
			<par><![CDATA[This paper is about the use of control algorithms to animate dynamic legged locomotion. Control could free the animator from specifying the details of joint and limb motion while producing both physically realistic and natural looking results. We implemented computer animations of a biped robot, a quadruped robot, and a kangaroo. Each creature was modeled as a linked set of rigid bodies with compliant actuators at its joints. Control algorithms regulated the running speed, organized use of the legs, and maintained balance. All motions were generated by numerically integrating equations of motion derived from the physical models. The resulting behavior included running at various speeds, traveling with several gaits (run, trot, bound, gallop, and hop), jumping, and traversing simple paths. Whereas the use of control permitted a variety of physically realistic animated behavior to be generated with limited human intervention, the process of designing the control algorithms was not automated: the algorithms were "tweaked" and adjusted for each new creature.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer animation]]></kw>
			<kw><![CDATA[dynamical simulation]]></kw>
			<kw><![CDATA[legged locomotion]]></kw>
			<kw><![CDATA[motion control]]></kw>
			<kw><![CDATA[physically realistic modeling]]></kw>
			<kw><![CDATA[robotics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.9</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010213.10010204</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods->Robotic planning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553.10010554</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems->Robotics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010199.10010204</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Planning and scheduling->Robotic planning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P187525</person_id>
				<author_profile_id><![CDATA[81100621168]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Raibert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Leg Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14028670</person_id>
				<author_profile_id><![CDATA[81100049661]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jessica]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Hodgins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alexander, R, MeN. 1988. Ela,stic Mechani.sms in Ai~.iln.t'/.! ~:~/o~,~~.~(~~.l ((I.'anlbridge University Press' New York).]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alexander, R. MEN., Vernon. A. 197.5. The mechanics of hopping by kangaroos (Macropodidas). ,I. Zoolog.~t (London) 177'26.5-303.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>74357</ref_obj_id>
				<ref_obj_pid>74334</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bruderlin, A., Calvert, T. W. 1989. Goal-Directed. Dynamic Animation of Human Walking. ('om puter Gra.phtcs 23(3):233 242.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31465</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Girard, M. 1987. Interactive design of 3-I) eompurer animated legged animal motion. IEt:.'E ('omput~.r Graphic,s and .4 n.imation June 39-- 51.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>325244</ref_obj_id>
				<ref_obj_pid>325165</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Girard, M. and Maciejewski. A. A. 198.5. (:omputat.ional Modeling for the Computer Animation of Legged Figures. 5'tgqrapfi 19(3) 263~-270.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hemami, H., Weimer, F. C., Koozekanani, S. H. 1973. Some aspects of the inverted pendulum problem for modeling of locomotion systems. IEEE Trans. A ulomatic Control AC-18:658-661.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
			<ref>
				<ref_obj_id>83536</ref_obj_id>
				<ref_obj_pid>83528</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hodgins, j., Raibert, M. H. 1990. Biped Gymnastics. ln~ernalional Journal of Robotics Research, 9(2):115- 132.]]></ref_text>
				<ref_id>7</ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hodgins, J., Raibert, M. H., 1991, Adjusting step length for rough terrain locomotion, IEEE J. Robotics and Automation, Sacramento.]]></ref_text>
				<ref_id>8</ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hodgins, J., Koeeh|ing, J., Raibert, M. H. 1985. Running experiments with a planar biped. Third International Symposium on Robotics Research, Cambridge: MIT Press.]]></ref_text>
				<ref_id>9</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97882</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[McKenna, M. and Zeltzer, D. 1990. Dynamic Simulation of Autonomous Legged Locomotion. Computer Graphics 24(4):29-38.]]></ref_text>
				<ref_id>10</ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[McMahon, T. A. 1984. Muscles, Reflexes, and Locomotion. Princeton: Princeton University Press.]]></ref_text>
				<ref_id>11</ref_id>
			</ref>
			<ref>
				<ref_obj_id>6152</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Raibert, M. tt. 1985. Legged Robots That Balance. Cambridge: MIT Press.]]></ref_text>
				<ref_id>12</ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Raibert, M. H., 1990. Trotting, pacing, and bounding by a quadruped robot, J. Biomechanics, Vol.23, Suppl.1, 79-98.]]></ref_text>
				<ref_id>13</ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rosenthal, D. E., Sherman, M. A., 1986. High performance multibody simulations via symbolic equation manipulation and Kane's method. J. Astronautical Sciences 34:3, 223-239.]]></ref_text>
				<ref_id>14</ref_id>
			</ref>
			<ref>
				<ref_obj_id>97904</ref_obj_id>
				<ref_obj_pid>97880</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[van de Panne M., Flume, E., Vranesic, Z. 1990. Reusable Motion Synthesis Using State-Space Contro|lers Computer Graphics 24(4): 225-234.]]></ref_text>
				<ref_id>15</ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Wi|helms, J. 1986. Virya-A motion control editor for kinematic and dynamic animation. Graphics Interface '86 141-146.]]></ref_text>
				<ref_id>16</ref_id>
			</ref>
			<ref>
				<ref_obj_id>31463</ref_obj_id>
				<ref_obj_pid>31462</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Wilhelms, J. 1987. Using Dynamic Analysis for Realistic Animation of Articulated Bodies. IEEE Computer Graphics and Animation June: 12-27.]]></ref_text>
				<ref_id>17</ref_id>
			</ref>
			<ref>
				<ref_obj_id>378507</ref_obj_id>
				<ref_obj_pid>378456</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Witkin, A., Kass, M., 1988. Spacetime Constraints. Computer Graphics 22(4):159-168.]]></ref_text>
				<ref_id>18</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Animation of Dynamic Legged Locomotion 1 Abstract This paptr is about the use of rent rol algorithms 
to an­inlate dynamic legged locomotion, (. ontrol could free the animator from specifying the details 
of joint and linlh motion whilt producing both physically realistic and natural-looking results, \$ e 
implemented computer animations of a biped robot, a quadruprd robot, and a kangaroo. tar-b crwaturc was 
modelrd as a linked set of rigid bodies wit b compliant actuators at its joints. (. on­t rol algorithms 
regulated the running speed, organized use of tht legs, and maintained halauce. All motions were generated 
by numerically integrating equations of motion cieri~ed from the physical models. The rwult­ing hehayior 
included running at various speeds, trav­eling with several gaits (run, trot. hound, gallop, and hop], 
jumping, and traversing simple paths, Whereas the us~ of control permitted a variety of physically re­alistic 
animated ht, havior to he generated with limited human intcrv(,ntion, the process of designing the con­trol 
algorithms was not automated: the algorithms were t wealmd and adjusted for oar-h nrw crest ure. Key 
Words and Phrases: computer animation, motion control. legged locomotion. robotics, dynamical simulation, 
physically realistic modeling. 2 Introduction An important goal of computer graphics is to generate physically 
realistic animation of frcfrraltti s,ystcwts, Ac­tuate(i sjstem.s are those that use muscles, motors, 
or some other kind of actuator to convert stored energy into time-varying forces that act within the 
system s Inrchanical structurv. Animals, robots, and vehicles are examples of actuated systems. Actuated 
systems r-an creatr their own motions when asked to perform a task, often without help from an outside 
agent. WP distin­guish act uatwl systems from passive physical objects: hot b can Inove with physical 
realism. but only actuated Permission m copy wirhour fee all or part of this marerial is granted provided 
thar Ihe copies are not made or distributed for direct commer cudadvanrage, rhe ACM copyright notice 
and the title of the publication and its dare appear, and notice is given that copying is by permissmn 
of the Association for Computing Machinery. To copy otherwise. or m republish, requires a fee mrd/or 
specific permission. systems can power an(l regulate t heir own motions. A key step in animating actuated 
systr>ms is to for­mulaie control algorit bms t hat t ransforrl] rxprcssions of desired behavior into 
detailorl actuator control sig­rlals that Pi_Odlr CC tbl rll Cl SSar~ rl)CJtlc)rl. 1 biS St(>ff ~all 
he c{uite challenging hwausc tht, relationship Iwtww,r] task and motion is usually itldirect. I)rsirrri 
twhavior is t~pica]]y ( X[)r( ss{>(flat a timo S~a]f) Ml{] II] it fOCJrd­nate system associated with 
the task, whertas actuatc~r control signals operate in thr coorclinatf~ systerrl anfl at the time scale 
of tbr nwcbanical syst(, rt]. For [,xarnpl(,, tb( dmreri behayior Rllrl forward at Y rll/s using trotting 
gait does little to specify how the bi~) jolrlf on leg 2 should move at various times throughout t II(> 
locomotion cycle. In legged locomot icm t be t ransforma­tion from task specification to actuator specification 
is central, in that motions of the legs and feet are only intermittently rclate(l to the hasir flrnctional 
goals c]f providing support, stability, and propulsion. A second reason that control of actl]ated systems 
is challenging is the prfwnf-r of significant system dynamics. In dynamic systems tbe forces and torques 
exerted hy the actuators on the nw, cbanism arc jl]st one of the factors that influence th(> movement, 
Energy stored. recovered, and excbangcd among t be various mechanical components of the system and external 
forces influence t be present and fut Ilrc mot ion of the system. The control algorithms nl(lst anticipate 
the response to actuation in the context of tb~> ongoing activity. In a fast-moving legged system. for 
exan~ph,, kinetic energy stored in t hr rot at ior] of t h,-leg can be large compared to the energy in]rttediat 
ely avai]ah]e from tht~ hip actuators. If the rontrol algoritbnls at-, to swing t ho leg forward soon 
enol]gh to place, t b[, foot for the next step, they mllst begin reversing the leg s motion early in 
the cycle. Each mass, moment of inertia, and compliant olrrnent in the system storm energy that might 
influence behavior. In most cases it is not correct to think of the control as provi{ling .cornrnan[]s 
 to the mechanism tbrougb tht, actuators. 1 be control ir]l)(]ts are more like suggest ions t bat rnl]st 
tw rwonciled wit b the dynamic state and strllcture of tht, systt=m. \Vhereas tbc difficulty of achieving 
rontrol of dy­namic systems poses certain prohlf ]]ls, the system dy­namics also present opporturrit 
im. For instance. the ACM -0-89791 -436-S/9 VfH17/0349 $0075 349 tally by the control system in concert 
with the dynamic model. Mc t(enua and Zeltzer s work on an animated cor-k­roach fully embracetf the idea 
that numerical integra­tion of a tfynamic model could he used to generate all motions of an animated 
creature, and that the control algorithms could influence behavior only through forces exerted by the 
actuators [10]. They implemented a dy­namical model of t.hr= cockroach, and relied on a con­trol systcm 
to pattern its motion. Their cockroach had springy legs, so the load of the body was distributed on the 
support, legs. The walking algorithms they used were based on motion patterns that have been observed 
in insect, locomotion. Mc Kenna and Zeltzer s work is closely related to our own, in that we too rely 
on br­havior of the dynamical model for all motion generation and restrict human intervention to specifying 
desired behavior to the control. Our work differs from theirs in the sort, of locomotion studied and 
the nature of the control algorithms: they concentrated on statically sta­ble multi-legged walking, while 
wc focus on running and jumping with a ballistic flight phase, and on thr role of the springy leg in 
generating the running cycle. Optimization techniques and modern control the­ory offer the hope of automatically 
producing control systems by specifying task constraints or optimization functions. Witkin and Kass used 
their spacetirne ap­ proach to produce a remarkable animation of a dynamic lamp [18]. Panne, Fiume, 
Vranesic used techniques from modern control theory to allow the lamp to perform a flip [15]. The potential 
gent=ralit y of these approaches and their ability to deal with anticipation makes them among the most 
interesting new methods for anima­tion of dynamic systems. The potential liability is the growth of thr 
search spaces when applied to more conl­plex systems. Girard and Maciejewski do not use numerical in­tegration 
of physical models, but rely instead on rules associated with dynamics [4, 5]. For instance, they pro­grammed 
a sinusoidal vertical motion of the body to approximate the motion of a maswfrrl body bouncing on springy 
Irgs. They coordinated the joints of their hu­man figures to km-p the center of mass over the support 
feet, as required for balance. These techniques resulted in some of the best looking animation of legged 
loconm­tion that. we have seen.  Animation, Control, and Modeling Figure 2 shows the general process 
we use for animation. The user provides the control system with information about the desired animated 
behavior, such as speed, gait, path, rtc. The user also initializes the legged mode] by placing it in 
a particular state. Once the animation is started, the control algorithms are responsible for stabilizing 
posture, maintaining the locomotion cycle, controlling speed and direction of travel, and regulating 
the behavior of the joints. Because the control is able to coordinate the lower levels of behavior for 
a task, the animator is free from direct involvement in specifying the joint torques or the details of 
the actual movements, Computer Graphics, Volume 25, Number 4, JUIV 1991 rhe three legged models are 
shown in Figure 1. Two of the models are patterned after physical robots that wc built and use for laboratory 
exprrinwnts. One robot model is of a biped with telescoping legs anti ball­joint hips. 1 he other robot 
model is of a quadruprri with telescoping legs and gimbal hips. The third model is a simplified version 
of a kangaroo. [t is simplifirvf in that it is planar, has one leg and arm instead of two, and it has 
fewer links in the tail than the animal. A total of six gaits were implemented and tested: hiprd running 
and galloping, quadruped trotting, hounding. and galloping. and kangaroo hopping. A II of thrwr gaits 
arc technically classified as running, because they include at least one I 1 desired behavior (w) forces 
and torques (f) control m model P------, I numerical I ~integrator state (x, x) ______-1 graphic 
  Un-1 I Figure 2: Block diagram of animation process The model consists of equations of motion for 
the rigid bodies of the legged system, actuator and sensor models, force equation+ for ground-interaction, 
and a numerical integrator that produces motion as a function of time. The model calculates its behavior 
once every integration interval, 0.0004 s. The control calculates the forr-e or torqur ttr be exerted 
h! each actuator based on the current state of the model, X, X and the user input W. The control calculation 
is done every control interval, which is usually a few MS. Thr human animator specifies desired behavior 
W, which consists of desired running speed, the path along which to travel, artd any event information, 
such as when and how high to jump. The animator specifies his or her input before the animation process 
begins. Jn the current implementation, the animator must also initialize the state of the model. flight 
phase per cycle, a period when all feet leave the ground at the same time. Control [n this section we 
describe the control algorithms used for animation of running. A control system for running must perform 
three primary functions . cause the legs to step, exchanging support. . provide balance to regulat,e 
the running speed, and  . maintain the body in an upright posture.   These three functions can be 
called hopping, speed conirol, and posture control. Hopping Control An idea that developed in biomechanics 
over the last fifteen years is that animals use elastic structures in their limbs to improve the energetic 
efficiency of their locomotion. Tendons and ligaments in the legs and feet stretch during each collision 
with the ground, converting some the system s kinetic energy into elastic strain energy. The stored energy 
is returned during the next step, when the elastic structures rebound. A significant fraction of the 
tdai running energy, perhaps 20% to 40(Z, recirculates from one step to the next, without needing resupply 
from the muscles. Kangaroos use their substantial Achilles tendons to perform this energy recovery function 
whereas Alexander argues that humans store energy in their Achilles tendons and the ligaments that support 
the arch of the foot [1]. Compliant legs and feet also reduce peak loads that occur in running when the 
feet strike the ground at the end of each flight phase [11, 1]. We use compliance in the legs to produce 
the vertical oscillations needed in running. The control algorithms allow the mass of the body to rebound 
on the springy leg during ground collisions and to be drawn back to earth by gravity during the flight 
phase. The biped and quadruped legs were made springy with spring-damper actuator models for the telescoping 
joint. The kangaroo leg was made springy by modeling the ankle actuator as a torsional spring-damper 
with adjustable rest length. Both actuator models have the form f=k(x-.rr)+bi (1) where j is the actuator 
force, k is the spring constant, b the damping constant, x the spring length, and Zr the spring rest 
length. Control of the spring rest length is used to inject or remove energy from the system in order 
to initiate the oscillation. modulate it, or stop it. For vertical hopping with a rnassless leg, the 
altitude of a particular hop is predicted by the sum of the potential strain energy in the leg spring, 
the potential energy of elevation of the system mass, and the kinetic energy due to motion of the body 
h= (PE.,.a, n + PE=,evO,,on + Ii E)/,Wg (2) where h is the expected altitude of the hop, M is the system 
mass, and g is the acceleration of gravity. The control system can inject or remove energy to influence 
this outcome. This hopping control mechanism takes advantage of the dynamic interaction between the me­chanical 
system and the control to generate the motion. No trajectory is specified. Speed Control Legged systems 
are like inverted pendulums: they tip and accelerate whenever the point of support is t neutral pant 
Figure 3: When the foot is positioned at the neutral point, the body travels along a symmetric path that. 
leaves the sys­tem unaccelerated in the forward direction. Displacement of the foot from the neutral 
point accelerates the body by skew­ing the symmetry of the body s trajectory. When the foot is placed 
closer to the hip than the neutral point, the body accelerates forward during stance and the forward 
speed at liftoff is higher than the forward speed at touchdown (left). When the foot is placed further 
from the hip than the neutral point, the body decelerates during stance and the forward speed at liftoff 
is slower than the forward speed at touch­down (right). Horizontal lines under each figure indicate the 
distance the body travels during stance, and the curved lines indicate the path of the body. displaced 
from the projection of the center of mass [6]. If the average point of support is kept under the average 
location of the center of mass, the system may tip for short periods, without tipping over entirely. 
One way to achieve such a balancing relationship between the feet and the center of mass is to move the 
body in a symmetric fashion over the supporting feet during each support period. When the control system 
places the foot to obtain a symmetric sweeping pattern, the forward speed will remain the same at liftoff 
as it was at touchdown. We call this position of the foot the neutral point. When the control system 
displaces the foot from the neutral point, the body accelerates, with the magnitude and direction of 
acceleration related to the magnitude and direction of the displacement, as shown in figure 3. The control 
system displaces the foot from the neutral point by a distance proportional to the difference between 
the actual speed and the desired speed, The control system computes the desired foot position as: y+k.(i 
id) fh, d = (3) where .r,~,~ is the forward displacement of the foot from the projection of the center 
of gravity, i is the forward speed, i. is the desired forward speed, T, is the predicted duration of 
the next support period. and k, is a gain. The first term of equation 3 is an estimate of the neutral 
point and the second term is a correction for any error in forward speed or for a desired acceleration. 
The duration of the next support period is predicted to be the same as the measured duration of the previous 
support period. After the control system finds x,~,~, a kinematic transformation determines the joint 
angles that will position the foot as specified. Fl,ghl-B 3\  L,fmff ~own udoa&#38;B u  Stale .Actions 
FLIGHT Active leg leave+ Interchange active, idle legs ground Lengthen active leg for landing Position 
active leg for landing Shorten idle leg I.O.AI)JY(; .Artiv~ kg touches Zero active hip torque ground 
Keep idle leg short ( OMPRESS1ON Active leg spring Servo pitch with active hip short t,us Keep idle leg 
short THRITST Active leg spring Extend active leg Imrgt hens Servo pitch with active hip Keep idle leg 
short ITNLO.ADIN( : Acti~e leg spring Shorten active leg approaches full Zero hip torques active leg 
leugt h Keep idle leg shorl Figure 4: Finite state machine that coordinates running. The state shown 
in thr left column is entered when the sensory (,vent, listed just below the state name. occurs. Actions 
arc listed on the right. The cent roller advances through Ihe states in sequence. The diagram is for 
a two-Ieggcd gait. Posture Control t)epeucfing on the number of legs. the gait, and whether there is 
a tail, the trunk may pitch and roll during running. [he long-term attitude of the trunk must be st abilizt=d 
if the system is to remain upright. The control system W(J implemented regulates the orientation of the 
trunk by applying torques to the body during the support phase. In the biped and quadruped models, tbe 
hip actuators are ust=d to apply the torques required for attitudt= control. lU the kangaroo model, the 
knee is used t o perform this fuuct ion. Vertical loading on t be feet keeps the leg from slipping when 
the torque is applied, The post ure control torques are generated by a linear servo: 7-= k, (o 0,) 
k (i) (4) Computer Gra~hics, Volume 25. Number 4. Julv 1991 where T is the leg torque, @ is the angle 
of the body, @d is the desired angle of the body, ~ is the angular rate of the body, and k,, kv are gains. 
The control systems for running use separate algo­rithms for stabilizing hopping, forward speed. and 
pos­ture of the trunk. Each of these parts of the control acts independently, as though it influences 
just one comp~  &#38;iiiifizNOsup nent of the behavior. Interactions due to imperfect de­ coupling 
are treated as disturbances. This decoupling simplifies the control implementation. In addition to the 
control algorithms described so far, each implementation uses a finite state machine to track the ongoing 
behavior of the model, to synchronize the control actions to the running behavior, and to do some bookkeeping. 
Figure 4 shows a state machine for the biped. Gaits We implemented a total of six gaits: biped running 
and galloping; quadruped trotting, bounding, and galloping: and kangaroo hopping. The running algorithms 
for all six gaits are based on control originally developed for one-legged hopping. For each gait we 
tailored the state machine to cycle through the legs in the correct order and to invoke suitable versions 
of the algorithms that distribute the load among the support legs. Bipedal runuing is like one-legged 
hopping. except there is an extra idfe leg, in addition to the active leg. The idle leg is kept short 
and out of the way while the active leg performs the functions described earlier to control forward speed. 
hopping height, and balance. The state machine for bipedal running is shown in figure 4. In quadruped 
trotting and bounding, the legs are coordinated to work together in pairs. The coordination we used makes 
each pair of legs act collectively like a single leg, called a mrfual leg. The members of each pair strike 
the ground in unison and leave the ground in unison. Diagonal legs form pairs in trotting and front legs 
and rear legs form pairs in bounding. One can think of these quadruped gaits as rtrtual btperf gait,s. 
with the active pair of legs providing support while the idle pair swings forward in preparation for 
the next step. The higher levels of the control system ignore the individual physical legs, pretending 
to do biped control on the two virtual legs as described earlier. Quadruped galloping is similar to bounding 
exc~pt that the legs of the front and rear pairs no longer strike and leave the ground in perfect unison. 
The stance phase is composed of a single support phase, a double support phase, and then a second single 
support phase. The legs are positioned on the ground with a separation both in time and space. The stance 
phase is extended and the legs of each pair share the work of rebounding the body. Biped galloping is 
similar to quadruped galloping in that the two stanr-e legs share a single support phase. We implemented 
two styles of bips=d galloping. In one style the legs swing forward together during the flight phase. 
In the other style they swing forward independently during the other leg s 3s3 single support phase. 
The first style produces a motion that is similar to the front half of a galloping horse while the second 
is closer to the pattern used by galloping humans. Pitching of the body in response to swinging of the 
legs is greatly reduced in the second form of galloping. Kangaroo cent rol Control algorithms for the 
kangaroo were essentially the same as for the robot models, with additional provisions for coordinating 
the joints of the articulated leg and for moving the tail. Kangaroos have legs with rotary joints. In 
the kangaroo model we eliminated the toe joint, leaving an ankle, a knee, and a hip, all of which have 
axes perpendicular to the sagittal plane. We made several decisions that constrained the behavior of 
the leg and allowed us to program it using methods originally developed for robot telescoping legs. We 
decided to use the ankle joint as the primary energy storage element in the leg. We assumed that the 
ankle actuator consisted of a spring-damper mechanism with an adjustable zero spring length. This mechanism 
models a muscle acting in series with a springy Achilles tendon. We adjusted the spring and damper character­istics 
so that a significant fraction of the energy stored in the spring during leg compression was returned 
dur­ing leg extension. We decided to configure the leg so the ground re­action force generated during 
hopping passes approxi­mately through the knee. This configuration minimizes the moment required at the 
knee to resist support and thrust forces. In balanced running, the ground reaction forces act along a 
line passing from the toe through the system center of mass. The control system servoes the hip joint 
to keep the knee on this thrust line during stance. Because torque about the knee is not needed to support 
the body, we use the knee to maintain the body in a level posture. The linear servo given in equation 
(4) operates at the knee during the stance phase to eliminate errors in body orientation and orientation 
rate. The tail is made to counteroscillate with the leg, keeping the angular momentum of the entire system 
near zero throughout the running cycle. When the leg strokes backward during the stance phase, the tail 
strokes downward. The tail motion is produced by making a step change in the spring rest length for the 
actuator at the base joint of the tail. The spring damper characteristics of the joint is tuned to oscillate 
in period with the running motion. The two peripheral joints in the tail are actuated by a spring damper 
with fixed rest length. The head was servoed to stay level throughout the running mot ion. Modeling Each 
of the legged systems was modeled as a tree of rigid bodies, each connected to its parent by rotary or 
sliding joints. The mass, mass center, and moment of inertia . .. I I //1 \ 4!( 2 system center of 
mass hip knee  ankle w Figure 5: Top) Drawing of real kangaroo used as the basis of the kangaroo model. 
It was a juvenile red kangaroo weighing 6.6 kg. Drawing is from [~]. Bottom) Diagram of kangaroo model. 
Except for the trunk, each link was modeled as the frustum of a cone, with Divots at the base and tip. 
The two legs of the real kangaroo were combined into one-model leg, All dimensions were chosen to match 
the reaf kangaroo in link length and link mass, assuming the kangaroo was the density of water. Mass 
centers and moments of inertia were calculated from the geometric model. for each body were determined 
in one of two ways. For the robot models we used actual measurements of the mass properties. For the 
kangaroo model we used the link length, mass, and mass center data given in [2]. We calculated the moments 
of inertia of the links from the geometry used in the graphics, typically assuming the density of water, 
An actuator capable of exerting forces or torques was located at each joint. The lowest level of control 
used linear servo mechanisms to specify actuator forces: f= Itp(e 0,) kue (5) where ~ is the force 
or torque acting on the joint, 0 is the joint angle or length, and /cp and k. are position and velocity 
feedback gains. These joint servos have the same dynamical behavior as a spring-damper mechanism with 
programmable rest length. Depending on one s point, of view and the design of the control system, these 
joint, servos can be regarded as part of the control system or as part of the model. Environmental interaction 
was restricted to gravi­tational forces and ground contact forces. A single point on each foot could 
make contact with the ground, The ground contact model for each foot consisted of four spring and damper 
sets: one vertical, two tangent to the surface, and one torsional about the ground sur­face normal The 
rest length of ear-h spring was reset when a foot first touched the ground during a support period. The 
ground contact compliance represents the compliance of the -paw pad , the elastic elements on the bottom 
of the feet, plus any compliance provided by the support surface. The kangaroo model used a non-linear 
paw pad spring in the vertical direction: j,=~ for:<O (6) kr+ :-l where ~, is the vertical spring force, 
k~, is the paw pad stiffness, k, is the paw pad thickness, and z is the altitude of the foot contact 
point above the ground. We chose a non-liuear spring for this part of the model because it is consistent 
with compression of an elastic material between two surfaces it reduced the maximum deflection during 
the support period. and it allowed vertical forces to develop more slowly at initial impact. We assume 
that once ground contact is made, there is no slipping between the foot and the ground. This is equivalent 
to an infinite coefficient of friction. To test this assumption we used data from typical runs to calculate 
the coefficient, of friction that would have prevented slipping. For the biped, this value was always 
less than 1. With the exception of the very beginning and end of the support period, a coefficient of 
friction of about 0.5 would have prevented slipping for the quadruped and kangaroo. At the very beginning 
of the support period, when th~ feet begin to make contact with the ground, however, there is a period 
of up to 10 ms during which the coefficient of friction would have had to he almost 2.0 to prevent slipping. 
A similar period occurred at the very end of the stance phase. On a day without oil leaks, the coefficient 
of friction between a robot foot and the floor of our laboratory is about 1.(). Equations of motion were 
generated for the struc­ture with a commercially available program [14]. The program generates efficient 
subroutines (0( n) where n is the number of links) that implement the equations of motion using a variant 
of Kane s method and a symbolic simplification phase. The equations of motion were nu­merically integrated 
using Euler s method, with time steps of ahout 0.0004 s. Simulations of a single creature ran between 
7 and 10 times slower than real time on a SIIN Sparc2. Dynamic Scaling W eused the basic principles 
of allometry to scale Computer Graphics, Volume 25, Number 4, July 1991 Quantity Units Scale Factor Basic 
variables length L L time T [21/2 force F L3 torque FL L Motion variables displacement L L velocity LT., 
L1{2 acceleration LT-2 1 angular displacement 1 angular velocity T-, L-1/2 angular acceleration T-2 L-1 
Mechanical parameters mas+ FL-1~2 L, stiffness FL- I L damping FL- T LVZ moment of inertia FLT2 L torsional 
stiffness FL L torsional damping FLT L~lz Table 1: Scaling rules that preserve geometric similarity. 
If a system is scaled in size by a factor L and its mechanical parameters are each scaled according to 
the table. then the motion of the scaled system can be found from the motion of the original unscaled 
system. The table is derived assuming uniform scaling in all dimensions (geometric similarity), and that 
the acceleration of gravity is invariant to scaIe. the size of a model, along with its control system 
and movements. Adult animals of a single species generally scale uniformly in all linear dimensions. 
and thereby maintain their proportions [11]. For a system scaled in this fashion, Table 1 gives rules 
for scaling the control system and the motions. Suppose we want to animate a kangaroo that is L times 
bigger than normal. ( sing the table we see that it will hop L times as high, travel ~e~e~t and haw a 
cadmc~ 1/fi of the original There are two ways to use these scaling rules. One way is to generate a new 
model of the creature and a new control system, based on the scaled mechanical parameters available from 
the table, Behavior of the scaled model can be used directly. An alternative is to implement a single 
model and control system at scab= 1, but to scale all input, to the animation as a function of l/L, and 
all output, as a function of L. For example, if L= 2, initial positions would be scaled by L- = 1/2, 
initial times and the integration time step would be scaled by L-]iz = 1/~, and desired running speed 
would be scaled by L-[/2 = l/fi. The animation could then be run at scale 1, The outputs are scaled before 
displayed: positions and geometry by L= 2 and time b! L / =~. We used the latter approach. but both give 
identical results, I I ! 0,0 0.0 0.5 1.0 :r 0.0 0.5 I.0 01 1 1 0.0 0.5 I.0 20 r o 20 . 40 L 1  OL 
I 0.0 0.5 I.0 time (s) Figure 6: Data recorded from planar kangaroo model during three steps of running 
with a desired speed of 5 m/s. The vertical dashed lines bracket the stance phase. The leg joint angles 
are defined in Figure 5. Key to joints in leg angle plot: (solid) hip, (dashed) knee, (dot-dashed) ankle. 
 5 Results Table 2 compares the behavior of each animated runner to the physical system it is designed 
to model. The data indicate that there are many similarities. For example, the extended flight phase 
is shorter than the gathered flight phase for both the physical and the animated quadruped during bounding. 
The kangaroo s body and tail oscillate as it runs and the magnitude of the oscillations are similar. 
The table also illustrates a number of differences. For instance, the gathered flight phase of the animated 
quadruped is twice that of the robot quadruped. The animated biped spent a great deal more time in flight 
than the robot. Another difference between the animated and real kangaroo is in the behavior of the feet 
at impact. The real kangaroo accelerates its feet to the speed of the ground just before they touch, 
so they do not scuff or have a tangential impact. We call this ground speed Robot/ Quantity Animal Animation 
 Quadruped Bound pitch magnitude (deg) 26.4 25.8 stride length (m) 1.15 ~.~~ stride duration (s) 0.37 
0.43 gathered flight phase duration (s) 0.11 (),~ 2 extended flight phase duration (s) 0.04 0.03 stance 
duration, front legs (s) 0.10 0.10 stance duration, rear legs (s) f)l~ 0.08 change of leg length 0.085 
0.092 during support (m) running speed (m/s) 2.9 2.8 error in running speed (m/s) 1.25 1,2 Quadruped 
Trot pitch magnitude (deg) 2.2 6,? stride length (m) 1,84 1.49 stride duration (s) 0.80 0.54 flight duration 
(s) ().~ 7 0.18 stance duration (s) ().]~ 0.09 change of leg length 0.04 0.03 during support (m) desired 
running speed (m/s) 2.3 2.3 error in running speed (m/s) 0.7 (),Q Biped Run pitch magnitude (deg) 2,0 
3.4 roll magnitude (deg) 6.7 11.5 stride length (m) 0,57 0.74 stride duration (s) 0.36 0.47 flight duration 
(s) 0.18 029 stance duration (s) 0.18 0,18 change of leg length 0.01 0,04 during support (m) error in 
running speed (m/s) -0.3 ().2 Kangaroo Hop peak vertical acceleration (g) 5 4.6 pitch magnitude (deg) 
10 12 magnitude of tail wag 30 31 relative to trunk (deg) stride length (m) ~.~ 1.5 stride duration (s) 
0.35 0.35 flight duration (s) 0.25 ().24 stance duration (s) 0.10 0.11 desired running speed (m/s) 6.2 
5.0 Table 2: Comparison between behavior of physical robot and animation, and between real and animated 
kangaroo. The runs were selected to match running speed as closely as possible, so running speed should 
not be used for compar­ison. The kangaroo data are from [2]. and the quadruped robot data are from [13]. 
matching. The animated kangaroo does not do ground speed matching. The control algorithms were successful 
in provid­ ing halanccd running, regulating the speed of travel to within about 10% of the desired value, 
and in steering the creatures along specified paths. To get each new creature or gait working required 
some adjustment of the control parameters. For example, to improve the ap­ pearance of the quadruped 
trotting and bounding nm­ tions, we redur-e(l the standing length of the legs. To get the kal~garoo tail 
to oscillate in rhythm with the running motion. we atijustrd the spring and damping constants of the 
tail joint servo until the natural fre­queucy w-as ahout equal to the hopping frequency, To makr the 
kangaroo jump over an ohstack, a number of additional stattw were adderi to the stat~ machine. 1 l~ost 
states allowed stiffer operat ion of the legs for the ji]n~p, mrrrr dissipat ion in the legs during landing 
after the jump, and a Ilumhrr of cosmetic changes. Once ad­justed. t bc locomotion proctwlmd without 
adjustment,. 6 Discussion Ihc motions <iescrihe(i in this paper are physically realistic in that they 
were goneratecl hy applying forces an<i torqum to pby;ical models of a mechanical system. Ihe (iegrel 
of physical realism (iept=nds on the degree to \Ybich th{ systenl is accurately modeled. For instance 
the mass parameters of t be links, structural strength of the links. torque available from the actuators, 
actuator ban(lwi,it b. stiffness oft be feet. an(i external frirt ion are paramct{rs that help (If.termine 
thr overall appearance of a Inol ion. Thcrr is no guarantee. however. that physically realist ir motion 
will he natural looking motion . It seems t hat animals move with a smoothness and coor­{iination that 
is not require(i hy physical realism alone. (. onstraints on smoothness, compliance, or energetic ef­ficiency 
cmlld eventually lead to uniformly natural look­ing behavior. }1 e found that increasing the comp lianm 
of the actuators generally improved the appearance of the anin}iitvd motions. W eexpect that crkstraintst 
hat Iowt r t h, (~verall energy expenrlitrire will also coutrihute to rnor(> natural looking ]ocomotion. 
As nwntione~i earlier, the methods desr-rihed in this paper might be t bought of as a tool hox for hand 
crafting control s}-stenis for nrw creatures and behaviors. }\Te expect that further (ievelopnwnt of 
control systems for computer animation will proceed in two steps. First, weexpcct control algorit,hmsf 
orindivi(iualc rt=aturm to l]ecot~l~ (-al~ahlt ofa wider varietjo fhehaviorwith less manual a(ijustment, 
Eventually. it should be possible to design control algorithms that will make creatures autonomous enough 
to do what, they are told , The animator should he able to direct the behavior at a relati~ely high 
le~el, and let the control system propel the system from one plact= to another at the desired rate along 
the spt rifitwi path, usP specified gaits, change hetwccngaits. and maintain halanct=, ail while adhering 
to physical realism. For well defined st%s of creatures and behaviors. this goal is within sight. Computer 
Graphics, Volume 25, Number 4, Julv 1991 !k-ond. wethinkit ispossihle toautomatetheprm ­crws of generating 
control algorithms for new creatures. (.;iveu control algorithms that work correctly for the lo­comotion 
of a horse, for example. it should he possiblo toautomatir-ally generate control algorithms for an an­telope, 
dog, cat. or elephant, Initially such automati­cally generated control might h~ restricted to a limited 
repertoire ofhehavior. Afirst cut might aimath alanced running at a range of speeds with sevmal gaits 
and tran­sitions hctwtw-n gaits, It is difficult to predict how long it will take to arhieve this level 
of control autonlati ­cally, or to go beyond it to automatp more complicated crt=atllres or higher-level 
function. One might expert the various workers involved in the study of control algorithms for legg~d 
locomotion animators. robot engineer-s. and biological scientists to differ in their criteria for successful 
algorithms. Such criteria could include precision of control. generality of control algorithms with respect 
to diverse bt=haviors and diverse creatures, the aesthetic appearance of th~ resulting movement, the 
simplicity and elegance of the solution, or the degree to which an algorithm explains the workings of 
animals. \$ e might find, however, that the solutions that best explain animal behavior will be similar 
to those that produce the best mhot behavior, and that t}],>easiest way to make an animation look animal-like 
is to use a control system Iikr the auimal s. It is also possible that t~chniqum suer-essflrl in producing 
animations that are visually pleasing and natl[r-al will lead to a h~tter understand ingof tho control 
at work in animals and to the construction of more effective robots. 7 Acknowledgements \Ve thank ronl 
Mchlahon for helping us appreciate thr beauty of dynamic scaling laws, and Takashi Aoki and Don Floyd 
for contributing to the software used in this project. This research was supported by cent racts from 
the DA RPA Information Sciences and Technology office and the (. harks St ark Draper Laboratory. 8 References 
1. Alexander, R. JIc!V. 1988. Elasfzc .ifechrrnl.srm ~n ,-lntmal ,tfovfnjtni (( ambridge University Press: 
New }-ork). 2. Alexander, R. \lc N., Vernon. A. 1975. The mechanics  of bopping by kangaroos ( Macropodidas). 
1. Zooiog.y (London) 177:265-303. 3. 13ruderlin, A. Calvert. T. \\ . 1989. Goal-Dirt=cted. I)ynamic Animation 
of Human Walking. ( ompoter Graphic.9 23(3):233 242. 4, (.;irard, hl. 1987. Interactive design of 3-D 
com­puter animat~d legged animal motion. lE. E ~. f omputf r-Graphtcs and .Animrrtlon June: 39 51. 5. 
(;irarri, M. and Nlaciejewski. A. A. 1985. C. omputa­tional Modeling for the ~ omputer Animation of Legged 
Figures, ,\ tggrrzph 19(3): 263270,  6. Hemami, H., Weimer, F, C., Koozekanani, S. H. 1973. Some aspects 
of the inverted pendulum problem for modeling of locomotion systems. IEEE Tkrrns. A rtto­matic Contro! 
AC-18:658 661. 7. Hodgins, J., Raibert, M. H. 1990. Biped Gymnastics. Inter-national Journa/ oj Robotics 
Research, 9(2):115­ 132. 8. Hodgins, J., Raibert, M. H.l 1991, Adjusting step length for rough terrain 
locomotion, IEEE J. Robotics and Automation, Sacramento. 9. Hodgins, J., Koechling, J., Raibert, M. 
H. 1985. Running experiments with a planar biped. T Aird Irrter­national Symposium on Robotics Research, 
Cambridge:  MIT Press. 10, McKenna, M, and Zeltzer, D, 1990. Dynamic Sim­ulation of Autonomous Legged 
Locomotion. Computer Graphics 24(4):29-38. 11. ,McMahon, T. A. 1984. Muscles, Reflexes, and Locomotion. 
Princeton: Princeton University Press. 12. Raibert, M. H. 1985. Legged Robots That Balance. Cambridge: 
MIT Press. 13. Raibert, M. H., 1990. Trotting, pacing, and bound­ing by a quadruped robot, J. Biomechan.its, 
VOI.23, SUPP].1, 79-98.  14, Rosenthal, D. E., Sherman, M. A., 1986. High per­formance multibody simulations 
via symbolic equation manipulation and Kane s method. J. Astronautical Sci­ences 34:3, 223 239. 15. van 
de Panne M., Fiume, E., Vranesic, Z. 1990. Reusable Motion Synthesis Using State-Space Con­trollers Computer 
Graphics 24(4): 225-234. 16. Wilhelms, J. 1986. Virya-A motion control editor for  kinematic and dynamic 
animation, Graphics Interface 86141-146. 17. Wilhelms, J. 1987. Using Dynamic Analysis for Real­istic 
Animation of Articulated Bodies. IEEE Computer Graphics and Animation June: 12-27. 18. Witkin, A., Kaas, 
M., 1988. Spacetime Constraints.  Computer Graphics 22(4):159-168. 9 A ~~e~~dix: Physical Parameters 
of IV? Link Mass Moment of Link length center M asS Inertia (m) (m) (kg) (kg -m ) Biped trunk 23.1 
[.17 .17 ,30] upper leg .20 .095 1,4 [.018 .017 .0014] lower leg .63 , 2p .64 [.02 .02 .00018] Hip location 
wrt trunk center of mass: .c = 0.0, ?J = +0.072, z = 0.0 Quadruped trunk 10.0 [.54 2.35 2.39] upper 
leg .41 .2 1.5 [.043 .043 o] lower leg ,4 .2 1.0 [.0035 .0035 0] Hip location wrt trunk center of mass: 
.r = +0.39, y = +0.12, .2 = 0.0 Kangaroo trunk 3.67 .034 thigh .13 .064 1.62 .0039 shin .26 .105 .60 
.0033 foot .174 .14 .00038 .082 tail 1 .166 .079 ,24 .00058 tai12 .166 .071 .14 .00033 t ai13 .166 .076 
.069 .00016 head .13 .04, .04 .33 .00046 Hip location wrt trunk mass center: [-.11 0] Head location 
wrt trunk mass center: [.21 O] Tail location wrt trunk mass center: [.2 O] Table 3: Physical parameters 
of models used in anima­tions. Link lengths are from proximal joint to distal joint. Mass centers are 
distances from the proximal joint of a link to the mass center. Moments of inertia are about the mass 
center of the link. The diagonal of the moment of inertia tensor is given.  
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>122756</article_id>
		<sort_key>359</sort_key>
		<display_label></display_label>
		<article_publication_date>07-01-1991</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Interactive behaviors for bipedal articulated figures]]></title>
		<page_from>359</page_from>
		<page_to>362</page_to>
		<doi_number>10.1145/122718.122756</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=122756</url>
		<abstract>
			<par><![CDATA[We describe techniques for interactively controlling bipedal articulated figures through kinematic constraints. These constraints model certain behavioral tendencies which capture some of the characteristics of human-like movement, and give us control over such elements as the figures' balanced and stability. They operate in near real-time, so provide behavioral control for interactive manipulation. These constraints form the basis of an interactive motion-generation system that allows the active movement elements to be layered on top of the passive behavioral constraints.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[articulated figures]]></kw>
			<kw><![CDATA[balance]]></kw>
			<kw><![CDATA[behavioral animation]]></kw>
			<kw><![CDATA[interactive manipulation]]></kw>
			<kw><![CDATA[inverse kinematics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Animation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Modeling packages</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011066.10011070</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->Development frameworks and environments->Application specific development environments</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31090214</person_id>
				<author_profile_id><![CDATA[81332521081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cary]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Phillips]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Laboratory, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038212</person_id>
				<author_profile_id><![CDATA[81452608047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Norman]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Badler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Computer Graphics Research Laboratory, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>111171</ref_obj_id>
				<ref_obj_pid>111154</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alan H. Burr, ~Teleological Modeling," in Making Them Move: Mechanics, Control, and Animation o/ Articulated Figures. N. Badler, B. Barsky, and D. geltzer (eds.):315-321, Morgan-Kaufmann, 1990.]]></ref_text>
				<ref_id>1</ref_id>
			</ref>
			<ref>
				<ref_obj_id>617638</ref_obj_id>
				<ref_obj_pid>616016</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Gary Monheit and Norman I. Badler, aA Kinematic Model of the Human Spine and Torso," Computer Graphics and Applications, Vol. 11, No. 2, March, 1991.]]></ref_text>
				<ref_id>2</ref_id>
			</ref>
			<ref>
				<ref_obj_id>62436</ref_obj_id>
				<ref_obj_pid>62402</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cary Phillips, Norman I. Badler, "Jack: A Toolkit for Manipulating Articulated Figures," A CM/SIGGRAPH Symposium on User Interjhce So.ware: 221-229, B~nff, Canada, 1988.]]></ref_text>
				<ref_id>3</ref_id>
			</ref>
			<ref>
				<ref_obj_id>91452</ref_obj_id>
				<ref_obj_pid>91394</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cary Phillips, Jianmin Zhao and Norman I. Badler, "Interactive Real-time Articulated Figure Manipulation Using Multiple Kinematic Constraints," Computer Graphics 24(2):245-250, 1990.]]></ref_text>
				<ref_id>4</ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Craig W. Reynolds, "Flocks, Herds, and Schools: A Distributed Behavioral Model,~ Computer Graphics, 21(4):25-34, 1987.]]></ref_text>
				<ref_id>5</ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jianmin Zhao and Norman I. Badler, aReal Time Inverse Kinematics with Joint Limits and Spatial Constr~ints,~ Technical Report MS-CIS-89-09, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, 1989.]]></ref_text>
				<ref_id>6</ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 @ @ Computer Graphics, Volume 25, Number 4, JUIV1991 Interactive Behaviors for Bipedal Articulated Figures 
Cary B. Phillips Norman I. Badler Computer Graphics Research Laboratory Department of Computer and Information 
Science University of Pennsylvania Philadelphia, Pennsylvania 19104-6389 Abstract We describe techniques 
for interactively controlling bipedal articulated figures through kinematic constraints. These constraints 
model certain behavioral tendencies which cap­ture some of the characteristics of human-like movement, 
and give us control over such elements as the figures bal­ance and stability. They operate in near real-time, 
so provide behavioral control for interactive manipulation. These con­straints form the basis of an interactive 
motion-generation system that allows the active movement elements to be lay­ered on top of the passive 
behavioral constraints. Keywords: Interactive manipulation, inverse kinematics, articulated figurea, 
balance, behavioral animation. 1. Introduction In this paper, we describe techniques for interacting 
with twmfooted articulated figures through kinematic constraints, concentrating on the movement of the 
feet and the center of mass. We particularly address the class of movements which are not bounded by 
dynamics. Such motions are typically executed at slow speed where inertial or frictional effects are 
minimal, and include standing, shifting the weight from one foot to the other, turning around, and taking 
small steps to the front, back, or to the side. In short, these motions en­compass the types of movement 
which people act out while standing and moving but not actively locomoting from one place to another. 
We believe that this type of motion is of great importance to an animator, and we show how we de scribe 
these motions cinematically. We believe this approach provides superior control to dynamics techniques, 
particu­larly since these motions do not need the full complexity of a dynamic simulation. Our movement 
primitives serve as the foundation for sev­eral higher level motion description mechanisms. Since they 
operate in near real time, they provide behavioral control for interactive manipulation, This allows 
the user to push, pull, Permission k) copy withou[ fee all or part of this material is granted prnvided 
that the copies are nnt made or distributed for direct Commercial advamage, the ACM copyright notice 
and [he tide of the publication and its date appear, and notice is given that copying is by permission 
nf the Association for Cnmputing Machinery. To copy  otherwise. or to republish. requires a fce and/or 
specific permission. ([lly)l ACM-()-89791-436-8/91/()()7/()359 $00.75 and twist the figure interactively 
using our 3D direct manip­ulation interface, all while the figure maintains its balance. These primitives 
form the basis of an interactive animation system that allows the active movement elements to be lay­ered 
on top of the passive behavioral constraints. Finally, these primitives provide the necessary interface 
to task level animation programs. 2. Background Systems which provide goal directed motion have been 
used for the most part only on rather simple objects such as chains or mechanisms, and the available 
goals have been rather simplistic aa well, such an point-t-nail or point-t~ point constraints. Although 
such systems are very powerful for generating certain typea of motion, they have not ad­equately addressed 
the problem of how an animator is to assemble a collection of goals which will accurately describe the 
intended motion [11. Stating that such constraints will vary over time does not solve the fundamental 
problems of determining useful sets of constraints for human motion, ne­gotiating their overlapping interactions, 
or organizing their timing for motion realism. In addition, they have not been successfully applied to 
highly articulated figures with ex­pected behaviors. Flocking behavior-constraining functions have demonstrated 
particle motion within a global frame­ work [5], but do not apply to articulated figures. 3. Articulated 
Figures and Inverse Kinematics The techniques described in this paper are implemented as a part of .JackTM, 
a multifaceted system for interactively modeling, manipulating, and animating articulated figures, principally 
human figures. lack represents figures as col­lections of rigid segments connected by joints that may 
have arbitrary rotational or translational degrees of freedom. The model of the human figure that we 
use for the examples in this paper has 36 joints with a total of 88 degrees of freedom, excluding the 
hands and fingers. Ithas a torso consisting of 17 segments and 18 vertebral joints [2]. Jack uses an 
inverse kinematics algorithm that is based on a variable-metric optimization procedure, described in 
t ~aek is a trademwk of the Univernit y of Pennsylvania. Jaclc is a nonsense name, not an acronyrm  
 SIGGRAPH 91 Las Vegas, 28 JuIv-2 Aumst 1991 detail in [6]. This method uaea the gradient descent ap­proach 
to r&#38;nimize the potential energy described by a set of constraints. Each constraint describes a desired 
geometric relationship between an end effecter and a goal position or orientation in space. The algorithm 
is an iterative numerical procedure. At each iteration it computes the Jacobian of the input joint set, 
which relates the change in each joint angle to the change in total potential energy, which is weighted 
sum of the energy from each constraint. This determines a joint-space trajectory to follow which minimizes 
the total energy. The algorithm handles arbitrary numbers of con­straints and arbitrary uumbers of degrees 
of freedom. The constraints may overlap in the sense that a single joint may affect several constraints. 
Generating Motion with Inverse Kinematics Generating motionwith inversekinematicsissomewhatdif­ferent 
from constraint based systems that are based on dy­namics. In particular, the only useful product of 
the inverse kinematics algorithm is the final position with the constraint energy minimized. The interm~late 
stepa during the so­lution process should not be considered as motion . To describe motion with inverse 
kinematics, we must select an appropriate set of end effecters and then describe the &#38; sired positions 
and/or orientations of these end effecters at each time increment. We then invoke the inverse kinemat­ics 
algorithm at each time step to determine the set of joint angles that satisfies the desired relationsh@a. 
The key to successfully describing motion through inverse kinematics is to choose properly the end effectora 
and then design sets of constraints that cause the figure to move in predictable patterns. For the purposes 
of this paper, we consider the inverse kinematics algorithm as a black box that takes as input a set 
of constraints and a set of joints and returns with a set of joint angles that minimize the energy described 
by the constraints. Constraints as Handles We use the constraints as handles by which to control parts 
of the figure. We can make a loose analogy between this and a marionette puppet controlled by strings, 
except that our strings need not hang vertically, and they can twist and push as well as pull. How do 
we pull on the strings to get the figure to move as we want? How many strings do we need? Where should 
we attach them? We choose not to shape the goal-control mechanism into h~ghly specific motion control 
elements to perform tasks like walking or running, but to design general purpose motion building blocks 
that stand by themselves as useful mechanisms of control. We are not overly concerned here with the physical 
laws of nature but in capturing some of the global characteristics of human-like movement. We are willhg 
to sacrifice some degree of Newtonian realism in order to achieve greater in­teractive control. We believe 
that a large portion of these characteristics can be captured through some simple behav­ioral tendencies, 
the moat important of which are balance and stability. By phrasing these tendencies as figure behau­iors, 
we can view the effect of the constraints in a more intuitive light. 4. Behaviors for Articulated FigUrea 
The tile architecture of our system lets us treat time in one of two ways. We can freeze time and make 
postural adjustments to the figure through the real-time interaction mechanism. In this case, we can 
think of each iteration of the interaction as a time step. Alternatively, we can set up a series of primitive 
actiow and then start the system time running from a certain point. The primitive actions cause the motion 
to take place. The Feet We begin by recognizing the importance of the support structure of the human 
body, i.e. its f-t and legs and how they support the body s weight. As bipedal creatures, hu­man beings 
have a built-in closed loop between the feet and legs that they are very good at manipulating. Unfortunately, 
because we model articulated figures as a hierarchy, we must take special care in modeling the connection 
between the feet and the ground. We do this by designating one foot or the other as dominant, and we 
the root the figure hierar­chy through that foot. We hold the other foot in place by a constraint located 
at the ball of the foot. The orientation component of the foot constraint keeps the foot flat on the 
floor while allowing it to twist. The Center of Maas and Balance The centerofmassisofcriticalimportancebecauseso 
many aspects of the movement through space of a human figure are dictated by the need to maintain balance. 
In addition, many typea of movement, such as stepping and walking, involve in­tentional shifts in the 
center of mass away tlom the support polygon, followed by actions of the feet and legs to restore the 
balance. We consider balance as one of the most signifi­cant behaviors to model in a human figure, both 
the abtity to maintain it and the ability to deviate from it. We model balance in the figure au a constraint 
on the cen­ter of mass to remain vertically above a point in the support polygon. We associate the center 
of mass logically with the lower torso region of the figure, and we use thw as the end ef­fecter of the 
constraint, with the ankle, knee, and hip joints of the dominant leg as the constraint variables. During 
the constraint satisfaction process at each time step, the center of mass is not recomputed. Since the 
center of mass belongs logically to the lower torso, its position relative to the torso remains fixed 
as the inverse kinematics algorithm positions the ankle, knee, and hip so that the previously computed 
center of mass point lies above the balance point. There are generally other constraints active at the 
same time, along with other postural adjustments, so that several parts of the figure assume different 
postures during the process. After we solve the constraints, we recompute the center of mass. It will 
generally lie in a different location because of the postural adjustments, indicating that the figure 
is not balanced as it should be. Therefore, we must solve the constraints again, and repeat the process 
until the balance condition ia satisfied. In this case the structure of the hu­man figure helps. Moat 
of the postural adjustments take place on the first iteration, so on subsequent iterations the changes 
in the center of mass relative to the rest of the body are quite minor. We measure the distance that 
the center of @@ mass changes from one iteration to the next, and we accept the posture when the change 
is below a certain threshold. Although it is difiicult to guarantee the convergence theoret­ically, in 
practice it seldom takes more than two iterations to achieve balance. The Spine and Torso Monheit [2] 
has developed a computational model for de­scribing movementsof the spine in terms of total bending angles 
in the forward, lateral, and axial directions. The tech­nique uses weighting factors that distribute 
the total bend­ing angle to the individual vertebrae in such as way that respects the proper coupling 
between the joints. Different weight distributions generate bends of different flavors, such as neck 
curls or motions confined to the lower back. We have an optional behavior that holds constant the global 
orientation of the head. To model this type of be­havior, we monitor the global orientation of the neck 
as the body posture changes at each time step. We measure the dif­ference in euler angles between the 
current and desired neck orientation, and then appIy these rotations to the spine. The Pelvis The pelvis 
connects the lower part of the spine to the upper legs. This is the general area of the center mass, 
so its posi­tion is governed primarily by the center of mass constraint. Therefore, our constraints on 
the pelvis involve only its ori­entation. The passive behavior of the pelvis involves holding its current 
orientation. Because of its central location, ma­nipulations of the pelvis provide a powerful control 
over the general posture of a figure, especially when combined with the balance and torso constraints. 
 5. Real-time Interaction The real-time interaction mechanism is described in [3] and [4]. Using this 
facility, we can interactively move and rotate the goals of constraints around in space through a 3D 
dkect manipulation technique which gets its input from a three button mouse. This mechanism provides 
a nice form of pos­tural control, although it is not so good at choreographing complex motions interactively. 
We provide the following types of interaction. Each of these corresponds to a .Jrrcksystem command which 
allows the appropriate property to be manipulated interactively. bend torso This follows the technique 
described in [2]. The center of mass constraint causes automatic pos­tural adjustments in the legs. For 
example, if we bend the torso forward, the hips automatically shift back­wards so that the center of 
mass remains over the same point. Figure 1 shows how the hips automatically shift backwards to maintain 
balance as we bend the figure forwards. rotate pelvis This interactively changes the orientation of the 
constraint on the pelvis. We can rotate the pelvis forward and backward, side to side, or we can twist 
it vertically. The constraints on the feet keep them planted on the ground. For example, if we set up 
a Comcmter GraDhics. Volume 25, Number 4. Julv 1991 constraint on the torso, and then rotate the pelvis 
for­wards, the figure will automatically squat but keep its head np. move center of mass To do this, 
we move the goal point for the center of mass constraint, which allows us to disturb the figure s balance. 
We can shift the center of forwards or backwards, side to side to concentrate the weight on one foot 
or the other, or up and down to make the figure squat or stand on its toes. move foot One foot is always 
the dominant one, and it serves as the root of the figure hierarchy. The other foot is held in place 
by a constraint. We can interactively move either foot. The passive balance behavior can either hold 
the center of mass at a fixed point or allow it to float to a point between the feet. Figure 2 show the 
center of mass floating between the feet as we move the Ieft foot backwards and to the side.  6. The 
Composition of Actions The notion of action in lack is a scripted change to a con­straint controlling 
the body. An action has three distinct parts: its beginning, its application, and its termination. Each 
action has a distinct starting and ending time. Each action has its own set of constraints controlling 
part of the body. Its parameters control the velocity of the con­straint s goal and the constraint s 
weight as a function of time. Through a windowed interface, we can create, modify, and delete actions 
and get a global picture of a movement sequence. Our system has actions which correspond to each of the 
types of manipulation described in Section 5. Each action causes the appropriate body part to move to 
a specified p­sition or assume a desired orientation. The user specifies the desired posture by moving 
the body part using the manip ulation mechanisms. This may be changed interactively, so if an action 
does not have the desired affect it can be eas­ily adjusted. The position and orientation of the goal 
of an action s constraint are interpolated between a starting and ending value. The starting value is 
the current position or orientation of the end effecter when the constraint is acti­vated. Actions may 
overlap in time, even ones which control the same part of the body. Since each action has its own con­straints, 
this simply means that during the period of over­lap, there will be multiple constraints on that part 
of the body. This is handled automatically by the inverse kine­matics algorithm. We must take special 
care to control the effect of constraints when this overlap occurs. If constraints die out abruptly, 
then their termination may cause discon­tinuities in the motion of the figure. This may happen if a constraint 
is pulling part of a figure in a certain direction opposed to another constraint. In this case, the constraint 
should be phased out gradually rather than terminated in­st antaneousl y. We allow the weight factor 
of each constraint to be a func­tion of time. The weighting function associated with a con­straint may 
increase, decrease, ease in and then ease out, or remain constant over the lifetime of the action. In 
practice, constant weights suffices when there are not many active actions. However, actions controlling 
the same part of the 36 I   
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>1991</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
</content>
</proceeding>

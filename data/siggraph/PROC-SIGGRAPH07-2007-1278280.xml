<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>08/05/2007</start_date>
		<end_date>08/09/2007</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[San Diego]]></city>
		<state>California</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1278280</proc_id>
	<acronym>SIGGRAPH '07</acronym>
	<proc_desc>ACM SIGGRAPH 2007 emerging technologies</proc_desc>
	<conference_number>2007</conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-1-4503-1824-2</isbn13>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2007</copyright_year>
	<publication_date>08-05-2007</publication_date>
	<pages>103</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[<p>Digital innovations that change the way we work, live, and play.</p> <p>Emerging Technologies presents creative, innovative technologies and applications in many fields, including but not limited to: displays, robotics, input devices, interaction techniques, computer vision, sensors, audio, speech, biometrics, wearable computing, information, data and scientific visualization, biotechnology, graphics, collaborative environments, and design.</p> <p>And in several domains, including but not limited to: medicine, music, entertainment, education, home, business, aerospace, communication, transportation, security, military, and technologies for the aging and/or disabled.</p>]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>PP39088351</person_id>
			<author_profile_id><![CDATA[81100236954]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Kathy]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Ryall]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Mitsubishi Electric Research Laboratories]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>PP39111889</person_id>
			<author_profile_id><![CDATA[81100481379]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>2</seq_no>
			<first_name><![CDATA[John]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Sibert]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[The George Washington University]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>2007</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<section>
		<section_id>1278281</section_id>
		<sort_key>1</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Emerging technologies: juried works]]></section_title>
		<section_page_from>1</section_page_from>
	<article_rec>
		<article_id>1278282</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[BYU-BYU-View]]></title>
		<subtitle><![CDATA[a wind communication interface]]></subtitle>
		<page_from>1</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278282</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278282</url>
		<abstract>
			<par><![CDATA[<p>BYU-BYU-View is a novel interface realized with the symbiosis of the input/output of wind and the computer graphics. "BYU-BYU" is a japanese onomatopoeia for a howling wind. It adds a new element, that is, "wind", to the direct interaction with a user and a virtual environment, and the communication through a network, by integrating the graphic presentation with the input and output of wind on a special screen.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P891395</person_id>
				<author_profile_id><![CDATA[81335497031]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Erika]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sawada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891415</person_id>
				<author_profile_id><![CDATA[81335491981]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shinya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ida]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891421</person_id>
				<author_profile_id><![CDATA[81335487898]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tatsuhito]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Awaji]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891404</person_id>
				<author_profile_id><![CDATA[81335494970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Keisuke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Morishita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891423</person_id>
				<author_profile_id><![CDATA[81335487716]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Tomohisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aruga]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891414</person_id>
				<author_profile_id><![CDATA[81335498295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Ryuta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takeichi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891424</person_id>
				<author_profile_id><![CDATA[81547807756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Tomoko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fujii]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891397</person_id>
				<author_profile_id><![CDATA[81335493232]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Hidetoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kimura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891425</person_id>
				<author_profile_id><![CDATA[81335495314]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Toshinari]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakamura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891407</person_id>
				<author_profile_id><![CDATA[81335490502]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Masahiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Furukawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35052283</person_id>
				<author_profile_id><![CDATA[81316490330]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>11</seq_no>
				<first_name><![CDATA[Noriyoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shimizu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891419</person_id>
				<author_profile_id><![CDATA[81365592229]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>12</seq_no>
				<first_name><![CDATA[Takuji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tokiwa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications and The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40037946</person_id>
				<author_profile_id><![CDATA[81100485839]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>13</seq_no>
				<first_name><![CDATA[Hideaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nii]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35027934</person_id>
				<author_profile_id><![CDATA[81100344143]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>14</seq_no>
				<first_name><![CDATA[Maki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sugimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027105</person_id>
				<author_profile_id><![CDATA[81100424140]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>15</seq_no>
				<first_name><![CDATA[Masahiko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>946807</ref_obj_id>
				<ref_obj_pid>946248</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Asai, K., Okuno, Y., Kakuta, H., and Takayama, T. 2003. Jellyfish Party: Blowing Soap Bubbles in Mixed Reality Space, <i>Proc.ISMAR03</i>, pp.358--359.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hatano, K., Masui, D., and Yen, H. W. 2003. Dimension Book, <i>ACM SIGGRAPH 2003 Emerging Technologies</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Iga, S. and Higuchi, F. 2002. Kirifuki: Inhaling and Exhaling Interaction with Visual Objects, <i>International Workshop on Entertainment Computing 2002 Workshop Note</i>, pp.119--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Katsura, M. and Inage, M. 2006. LivePic, <i>ACM SIGGRAPH 2006 Emerging technologies/ Siggraph 2006 Sketches</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kosaka, T. and Hattori, S. 2006. Wind-Surround System, <i>Interaction</i>, pp.187--188]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sekiguchi, D., Inami, M., Kawakami N., Maeda, T., Yanagida, Y., and Tachi, S. 2001. RobotPHONE: RUI for Interpersonal Communication, <i>ACM SIGGRAPH 2001 Conference Abstracts and Applications</i>, pp.134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1186186</ref_obj_id>
				<ref_obj_pid>1186155</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Suzuki, Y., Iwaki, S., Kobayashi, K., Nakamura, A., and Shimada, Y. 2004. Untethered Force Feedback Interface That Uses Air Jets, <i>SIGGRAPH 2004 emerging technologies</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278283</article_id>
		<sort_key>2</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[CoGAME]]></title>
		<subtitle><![CDATA[manipulation using a handheld projector]]></subtitle>
		<page_from>2</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278283</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278283</url>
		<abstract>
			<par><![CDATA[<p>An example of an application enhanced by the "manipulation-by-projection" technique, this cooperative game allows players to visually and intuitively control a robot with projectors. Players interchangeably move and connect their projected images to create a path that leads the robot to its goal.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P669032</person_id>
				<author_profile_id><![CDATA[81331494616]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kazuhiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hosoi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P875256</person_id>
				<author_profile_id><![CDATA[81331491038]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vinh]]></first_name>
				<middle_name><![CDATA[Ninh]]></middle_name>
				<last_name><![CDATA[Dao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35042391</person_id>
				<author_profile_id><![CDATA[81331499809]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Akihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mori]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40033819</person_id>
				<author_profile_id><![CDATA[81100344146]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Masanori]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sugimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1166289</ref_obj_id>
				<ref_obj_pid>1166253</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cao, X., and Balakrishnan, R. 2006. Interacting with dynamically defined information spaces using a handheld projector and ap pen. In <i>The annual ACM symposium on User interface software and technology</i>, 225--234.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1056990</ref_obj_id>
				<ref_obj_pid>1056808</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Miyahara, K., Inoue, H., Tsunesada, Y., and Sugimoto, M. 2005. Intuitive manipulation techniques for projected displays of mobile devices. In <i>ACM CHI2005 Extended Abstract</i>, 1881--1884.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882349</ref_obj_id>
				<ref_obj_pid>882262</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., van Baar, J., Beardsley, P., Willwacher, T., Rao, S., and Forlines, C. 2003. ilamps: Geometrically aware and self-configuring projectors. <i>ACM Transactions on Graphics (TOG) 22</i>, 3, 809--818.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Shoji, M., Miura, K., and Konno, A. 2006. U-tsu-shi-o-mi: the virtual humanoid you can reach. In <i>SIGGRAPH2006 Emerging Technologies</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Siemens. Cell phone with builtin projector. www.physorg.com/news3505.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1187299</ref_obj_id>
				<ref_obj_pid>1187297</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sugimoto, M., Kojima, M., Nakamura, A., Kagotani, G., Nii, H., and Inami, M. 2005. Augmented coliseum: Display-based computing for augmented reality inspiration computing robot. In <i>SIGGRAPH 2005 Full Conference DVD-ROM Disk1 Emerging Technologies</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Toshiba, 2006. Tdp-ff1a(j). http://www.toshiba.co.jp/vis/lineup/portable/ff1/index.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278284</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Fibratus tactile sensor using reflection on an optical lever]]></title>
		<page_from>3</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278284</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278284</url>
		<abstract>
			<par><![CDATA[<p>Among several tactile sensors in use currently, none can evaluate the sense of gentle touch. We have developed a fibratus tactile sensor that utilizes the property of reflection. This sensor enables to evaluate the sense of gentle touch. We propose a new interface device that employs this fibratus tactile sensor.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[fiber]]></kw>
			<kw><![CDATA[image sensor]]></kw>
			<kw><![CDATA[optical lever]]></kw>
			<kw><![CDATA[optical measurement]]></kw>
			<kw><![CDATA[tactile sensor]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P829417</person_id>
				<author_profile_id><![CDATA[81320494720]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Satoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saga]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tohoku University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P883126</person_id>
				<author_profile_id><![CDATA[81331496816]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shinobu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuroki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207192</person_id>
				<author_profile_id><![CDATA[81100173571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawakami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272463</person_id>
				<author_profile_id><![CDATA[81100411569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Susumu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Begej, S. 1984. An optical tactile array sensor. <i>SPIE Intelligent Robotics and Computer Vision 521</i>, 271--280.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BL AUTOTEC LTD. BL NANO Sensor.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042219</ref_obj_id>
				<ref_obj_pid>1042190</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kamiyama, K., Vlack, K., Kajimoto, H., Kawakami, N., and Tachi, S. 2005. Vision-Based Sensor for Real-Time Measuring of Surface Traction Fields. <i>IEEE Computer Graphics & Applications Magazine</i>, 68--75.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Nitta Corporation. Flexi Force.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Saga, S., Kajimoto, H., and Tachi, S. 2006. High-resolution tactile sensor using the deformation of a reflection image. <i>Sensor Review 27</i>, 35--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shin-Etsu Chemical Co., Ltd. 2 liquid-type RTV rubber KE109.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Yamada, K., Goto, K., Nakajima, Y., Koshida, N., and Shinoda, H. 2002. A sensor skin using wire-free tactile sensing elements based on optical connection. In <i>SICE 2002. Proceedings of the 41st SICE Annual Conference</i>, The Society of Instrument and Control Engineers. (SICE), Tokyo, Japan, vol. 1, 131--4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278285</article_id>
		<sort_key>4</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Video game that uses skin contact as controller input]]></title>
		<page_from>4</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278285</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278285</url>
		<abstract>
			<par><![CDATA[<p>In this paper, we present the first stage of our video game prototype which treats skin contact as controller input. Skin contact is communication which has special emotion. Video game also has elements of communication, for instance, Family Computer [Nintendo 1983] has two controllers in order that family or friends can play the game together. We use these two features and propose the interaction that players can enjoy video games with skin contact. We implemented the game controller and two video games. The controller has the mechanism which enables to detect skin contact. One of games of our prototype is a shoot-em-up game. Another is a rhythm action game. Our goal of this research is to show the increase of enjoyment and intimacy at the game with using skin contact.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[communication]]></kw>
			<kw><![CDATA[game controller]]></kw>
			<kw><![CDATA[interaction design]]></kw>
			<kw><![CDATA[interpersonal communication]]></kw>
			<kw><![CDATA[skin contact]]></kw>
			<kw><![CDATA[video game]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Prototyping</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003123.10010860.10011694</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design->Interaction design process and methods->Interface design prototyping</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123.10010860.10011694</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design->Interaction design process and methods->Interface design prototyping</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P823030</person_id>
				<author_profile_id><![CDATA[81319488008]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tetsuaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baba]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kyushu University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35034227</person_id>
				<author_profile_id><![CDATA[81319502887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Taketoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ushiama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kyushu University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37040580</person_id>
				<author_profile_id><![CDATA[81331505544]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Reiji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsuruno]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kyushu University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP18002822</person_id>
				<author_profile_id><![CDATA[81331505568]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kiyoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tomimatsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kyushu University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1179146</ref_obj_id>
				<ref_obj_pid>1179133</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baba, T., and Tomimatsu, K. 2006. Freqtric drums. In <i>SIGGRAPH '06: ACM SIGGRAPH 2006 Emerging technologies</i>, ACM Press, New York, NY, USA, 12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1120435</ref_obj_id>
				<ref_obj_pid>1120212</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brave, S., and Dahley, A. 1997. intouch: a medium for haptic interpersonal communication. In <i>CHI '97: CHI '97 extended abstracts on Human factors in computing systems</i>, ACM Press, New York, NY, USA, 363--364.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274653</ref_obj_id>
				<ref_obj_pid>274644</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fogg, B., Cutler, L. D., Arnold, P., and Eisbach, C. 1998. Handjive: a device for interpersonal haptic entertainment. In <i>CHI '98: Proceedings of the SIGCHI conference on Human factors in computing systems</i>, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 57--64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258636</ref_obj_id>
				<ref_obj_pid>258549</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fukumoto, M., and Tonomura, Y. 1997. Body coupled fingerring: wireless wearable keyboard. In <i>CHI '97: Proceedings of the SIGCHI conference on Human factors in computing systems</i>, ACM Press, New York, NY, USA, 147--154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hachisuka, K., Nakata, A., Takeda, T., Shiba, K., Sasaki, K., Hosaka, H., and Itao, K. 2003. Development of wearable intra-body communication devices. <i>Sensors and Actuators A: Physical 105</i>, 1, 109--115.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Nintendo, 1983. Family computer(nintendo entertainment system). http://www.nintendo.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Nintendo, 2006. Wii. http://www.nintendo.com/channel/wii.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1178847</ref_obj_id>
				<ref_obj_pid>1178823</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Smith, J. D., and Graham, T. C. N. 2006. Use of eye movements for video game control. In <i>ACE '06: Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology</i>, ACM Press, New York, NY, USA, 20.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1124936</ref_obj_id>
				<ref_obj_pid>1124772</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wang, S., Xiong, X., Xu, Y., Wang, C., Zhang, W., Dai, X., and Zhang, D. 2006. Face-tracking as an augmented input in video games: enhancing presence, role-playing and control. In <i>CHI '06: Proceedings of the SIGCHI conference on Human Factors in computing systems</i>, ACM Press, New York, NY, USA, 1097--1106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>243541</ref_obj_id>
				<ref_obj_pid>243519</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Zimmerman, T. 1996. Personal area networks: near-field intrabody communication. <i>IBM system journal 35</i>, 3--4, 609--617.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278286</article_id>
		<sort_key>5</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Full-scale saccade-based display]]></title>
		<subtitle><![CDATA[public / private image presentation based on gaze-contingent visual illusion]]></subtitle>
		<page_from>5</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278286</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278286</url>
		<abstract>
			<par><![CDATA[<p>Pursuing new display techniques based on insights of human visual perception can open up new possibilities for visual information presentation. Here we present the vast refinement of an information display method, which we call a saccade-based display. The saccade-based display can show two-dimensional (2D) images without any screen using only a single line of flickering light emitting diodes (LEDs). The following principle is fundamental to the implementation of this display. It is known that mechanical high-speed movement of a one-dimensional flickering LED array can present 2D images through retinal afterimages (this kind of visual display is commercially available [IMS 2000]) Conversely, when light sources are fixed on a vertical line, and the flashing pattern is changed quickly during a horizontal rapid eye movement called a saccade, 2D images can also be perceived due to spatio-temporal integration in the human vision system as in fig. 1(a). When a vertical line of lights flashes quickly during the horizontal saccade, the flashing pattern is expanded into a spatial pattern by the eye movement. During the eye movement, the vertical light array travels on the retina while changing the flashing pattern. Then, the different vertical images at different retinal locations are integrated into a 2D image as in fig. 1(b). Although the images presented during the saccade can hardly be seen in daily life (e.g. [Latour 1962]), the images with high contrast and high spatial frequency as presented with this display can be recognized [Watanabe et al. 2005b][Watanabe et al. 2005a].</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P715176</person_id>
				<author_profile_id><![CDATA[81100486051]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hideyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ando]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT CS Lab.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P729814</person_id>
				<author_profile_id><![CDATA[81100363092]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Junji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watanabe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[PRESTO JST/NTT CS Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36043710</person_id>
				<author_profile_id><![CDATA[81100595703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tomohiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Amemiya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT CS Lab.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P278536</person_id>
				<author_profile_id><![CDATA[81100065999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Taro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Maeda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[NTT CS Lab.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1152422</ref_obj_id>
				<ref_obj_pid>1152399</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ando, H., Watanabe, J., Amemiya, T., and Maeda, T. 2005. study of saccade-incident information display using saccade detection device. In <i>Proceedings of the 15th International Conference on Artificial Reality and Telexistence</i>, 119--124.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[ASL. <i>Eye Tracking Expertise</i>. Applied Science Laboratories, Retrieved Jan. 1, 2007, from http://www.a-s-l.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bell, B. 1993. <i>Light Stick</i>. Exploratorium, Retrieved Jan. 1, 2007, from http://www.exploratorium.edu/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[The Burning Man Project. 1989. <i>Burning Man</i>, Retrieved Jan. 1, 2007, from http://www.burningman.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[IMS inc. 2000. <i>Fantazein</i>, Retrieved Jan. 1, 2007, from http://www.fantazein.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Latour, P. 1962. Visual threshold during eye movements. <i>Vision Research 2</i>, 261--262.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507092</ref_obj_id>
				<ref_obj_pid>507072</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Triesch, J., Sullivan, B., Hayhoe, M., and Ballard, D. 2002. Saccade contingent updating in virtual reality. In <i>Proceedings of the symposium on Eye Tracking Research and Applications</i>, 95--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1186368</ref_obj_id>
				<ref_obj_pid>1186223</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Watanabe, J., Tavata, T., Verdaasdonk, M. A., Ando, H., Maeda, T., and Tachi, S. 2004. Illusory interactive performance by self eye movement. In <i>Siggraph2004 Conference DVDROM Sketches</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1070895</ref_obj_id>
				<ref_obj_pid>1070893</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Watanabe, J., Maeda, T., and Tachi, S. 2005. Time course of localization for a repeatedly flashing stimulus presented at perisaccadic timing. <i>Systems and Computers in Japan 36</i>, 9, 77--86.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Watanabe, J., Noritake, A., Maeda, T., Tachi, S., and Nishida, S. 2005. Perisaccadic perception of continuous flickers. <i>Vision Research 45</i>, 413--430.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246980</ref_obj_id>
				<ref_obj_pid>1246973</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Watanabe, J., Ando, H., Maeda, T., and Tachi, S. 2007. Gaze-contingent visual presentation based on remote saccade detection. <i>Presence: Teleoperators and Virtual Environments 16</i>, 2, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278287</article_id>
		<sort_key>6</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[fuwapica suite]]></title>
		<page_from>6</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278287</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278287</url>
		<abstract>
			<par><![CDATA[<p>Ancient Japanese used to believe that Gods lived not only in nature but also in artifacts. They thought Gods lived in every pairs of chopsticks, every dishes, and every furniture sorounding them. Legend says ancient people used to talk to the Gods inside such commodities and everyday tools as if such stuffs had their souls themselves. Particularly furniture and houses surrounding people had been thought that they were even breezing (breezing is called <i>ki</i> in Japanese). Those people thought they had breezed together with furniture and house, they had interacted with those artifacts, and they had interacted each other by communicating to and sharing with those artifacts without words.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P822980</person_id>
				<author_profile_id><![CDATA[81319497098]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shinya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matsuyama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891409</person_id>
				<author_profile_id><![CDATA[81335500017]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Masaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yagisawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891405</person_id>
				<author_profile_id><![CDATA[81335492064]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kenji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inokuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891398</person_id>
				<author_profile_id><![CDATA[81335492691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hiroaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawamura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891416</person_id>
				<author_profile_id><![CDATA[81335493626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Shozo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuze]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891399</person_id>
				<author_profile_id><![CDATA[81335495446]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Hisakazu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nabeshima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35034118</person_id>
				<author_profile_id><![CDATA[81536903756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Makoto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirahara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35053676</person_id>
				<author_profile_id><![CDATA[81100617659]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Koji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yamashita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891422</person_id>
				<author_profile_id><![CDATA[81335499039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Tomohiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wakatsuki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891410</person_id>
				<author_profile_id><![CDATA[81335499075]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Mitsuaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watanabe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Prototype Inc., Shibuya, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP18006437</person_id>
				<author_profile_id><![CDATA[81452606695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>11</seq_no>
				<first_name><![CDATA[Ichi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kanaya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University, Toyonaka, Osaka, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. J. Gibson: The Ecological Approach to Visual Perception; Lawrence Erlbaum Associates, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. G. Jung: Synchronicity - An Acausal Connecting Principle; Bollingen Foundation, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Kazuo Kawasaki: Design Gambit (in Japanese), ASCII Press, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Naoko Tosa, Seigow Matsuoka: ZENetic Computer; Proc. ACM Siggraph 2004, Emerging Technologies, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ichi Kanaya, Shinya Matsuyama, and Makoto Hirahara: The RGBy desk; Proc. ACM Siggraph 2006, Poster 0047, ACM, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278288</article_id>
		<sort_key>7</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[GlowBots]]></title>
		<subtitle><![CDATA[robots that evolve relationships]]></subtitle>
		<page_from>7</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278288</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278288</url>
		<abstract>
			<par><![CDATA[<p><i>GlowBots</i> are small wheeled robots that develop complex relationships between each other and with their owner. They develop attractive patterns which are affected both by user interaction and communication between the robots. The project shows how robots can interact with humans in subtle and sustainable ways for entertainment and enjoyment.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[design]]></kw>
			<kw><![CDATA[embodied agents]]></kw>
			<kw><![CDATA[human robot interaction]]></kw>
			<kw><![CDATA[multi agent systems]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P769604</person_id>
				<author_profile_id><![CDATA[81309488890]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mattias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jacobsson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Future Applications Lab, G&#246;teborg, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P507594</person_id>
				<author_profile_id><![CDATA[81100194686]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sara]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ljungblad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Future Applications Lab, G&#246;teborg, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891403</person_id>
				<author_profile_id><![CDATA[81350578555]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Johan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bodin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Future Applications Lab, G&#246;teborg, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891401</person_id>
				<author_profile_id><![CDATA[81335493189]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Knurek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Future Applications Lab, G&#246;teborg, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P168847</person_id>
				<author_profile_id><![CDATA[81100144729]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Lars]]></first_name>
				<middle_name><![CDATA[Erik]]></middle_name>
				<last_name><![CDATA[Holmquist]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Swedish Institute of Computer Science, Kista, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>517699</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Carroll, J. M., "Making Use: scenario-based design of human computer interactions", <i>Cambridge, Mass, MIT Press</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[DiSalvo, C., Gemperle, F., Forlizzi, J., Montgomery, E., Yonkers, W. and Divine, J., "The Hug: An Exploration of Robotic Form for Intimate Communication", <i>In Proceedings of RO-MAN 03</i>, vol., no. pp. 403--408, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fong, T., Nourbakhsh, I. and Dautenhahn, K., "A survey of Socially Interactive Robots", <i>Robotics and Autonomous Systems</i>, 42, 143--166, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1466550</ref_obj_id>
				<ref_obj_pid>1466547</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Forlizzi, J., DiSalvo, C., and Gemperle, F. (2004). "Assistive Robotics and an Ecology of Elders Living Independently in Their Homes." <i>Journal of HCI Special Issue on Human-Robot Interaction</i>, V19 N1/2, January, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1107570</ref_obj_id>
				<ref_obj_pid>1107548</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kaplan, F., "Everyday robotics: robots as everyday objects" <i>In Proceedings of Soc-Eusai 2005</i>, p.59--64, Grenoble, France, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Liu, H. and Hu. H., "Biologically inspired behaviour design for autonomous robotic fish" <i>International Journal of Automation and Computing</i>, Vol. V3, No. 4, pp. 336--347. October 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1107571</ref_obj_id>
				<ref_obj_pid>1107548</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ljungblad, S. and Holmquist, L. E., "Designing Robot Applications for Everyday Envionments", <i>In Proceedings of Smart Objects & Ambient Intelligence 2005</i> (SOC-EUSAI), Grenoble, France, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ljungblad, S., Walter, K., Jacobsson, M. and Holmquist, L. E., "Designing Personal Embodied Agents with Personas". <i>In Proceedings of RO-MAN 06</i>, Hatfield, United Kingdom, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1240738</ref_obj_id>
				<ref_obj_pid>1240624</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ljungblad, S., and Holmquist, L. E., "Transfer Scenarios: Grounding Innovation with Marginal Practices" Submitted to <i>CHI'07</i>, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lund, H. H., "Adaptive Robotics in the Entertainment Industry". <i>In Proceedings of IEEE International Symposium on Computational Intelligence in Robotics and Automation</i> (CIRA2003), 16--20 July, Kobe, IEEE Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{Artemis} http://www.tmsuk.co.jp/artemis/product.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{e-Puck} http://www.e-puck.org]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{Minerva} http://www.cs.cmu.edu/~minerva/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{Roomba} http://www.irobot.com/sp.cfm?pageid=122]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278289</article_id>
		<sort_key>8</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Gravity grabber]]></title>
		<subtitle><![CDATA[wearable haptic display to present virtual mass sensation]]></subtitle>
		<page_from>8</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278289</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278289</url>
		<abstract>
			<par><![CDATA[<p>We propose a wearable haptic display to present the weight sensation of a virtual object, which is based on our novel insight that the deformation on fingerpads makes a reliable weight sensation even when the proprioceptive sensation is absent. This device will provide a new form of ubiquitous haptic interaction.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P882929</person_id>
				<author_profile_id><![CDATA[81331499667]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kouta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minamizawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891417</person_id>
				<author_profile_id><![CDATA[81335490472]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Souichiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fukamachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P536461</person_id>
				<author_profile_id><![CDATA[81100131163]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hiroyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kajimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Electro-Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207192</person_id>
				<author_profile_id><![CDATA[81100173571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawakami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272463</person_id>
				<author_profile_id><![CDATA[81100411569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Susumu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1179160</ref_obj_id>
				<ref_obj_pid>1179133</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amemiya, T., Ando, H. and Maeda, T., 2006. Perceptual Attraction Force: The Sixth Force. In <i>Proceedings of ACM SIGGRAPH 2006, Emerging Technologies</i>, 26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Immersion Co., Ltd., 2000. The CyberGrasp: Groundbreaking haptic interface for the entire hand.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Inaba, G. and Fujita, K. 2006. A Pseudo-Force-Feedback Device by Fingertip Tightening for Multi-Finger Object Manipulation. In <i>Proceedings of the EuroHaptics 2006 Conference</i>, Paris, France, 275--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Johansson, S. and Westling, G. 1984. Roles of Glabrous Skin Receptors and Sensorimotor Memory in Automatic Control of Precision Grip When Lifting Raugher or More Slippery Objects. <i>Experimental Brain Research</i>, vol. 56, 550--564.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Maeno, T., Hiromitsu, S. and Kawai, T. 2000. Control of Grasping Force by Detecting Stick/Slip Distribution at the Curbed Surface of an Elastic Finger. In <i>Proceedings of IEEE International Conference on Robotics and Automation (ICRA2000)</i>, San Francisco, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Minamizawa, K., Tojo, K., Kajimoto, H., Kawakami, N. and Tachi, S. 2006. Haptic Interface for Middle Phalanx Using Dual Motors. In <i>Proceedings of the EuroHaptics 2006 Conference</i>, Paris, France, 235--240.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1264778</ref_obj_id>
				<ref_obj_pid>1264358</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Minamizawa, K., Kajimoto, H., Kawakami, N. and Tachi, S. 2007. Wearable Haptic Display to Present Gravity Sensation -- Preliminary Observations and Device Design, In <i>Proceedings of the Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (World Haptics 2007)</i>, Tsukuba, Tokyo, (to appear.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Nakagawara, S., K., Kajimoto, H., Kawakami, N., Tachi, S. and Kawabuchi, I. 2005. An Encounter-Type Multi-Fingered Master Hand Using Circuitous Joints. In <i>Proceedings of IEEE International Conference on Robotics and Automation (ICRA2005)</i>, Barcelona, Spain.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Nintendo Co., Ltd., 2006. Wii Remote.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sony Computer Entertainment, Inc., 1997. DUALSHOCK.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Tachi, S., Komoriya, K., Sawada, K., Nishiyama, T., Itoko, T., Kobayashi, M. and Inoue, K. 2003. Telexistence Cockpit for Humanoid Robot Control. <i>Advanced Robotics</i>, Vol. 17, No. 3, 199--217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Yao, H. Y. and Hayward, V. 2006. An Experiment on Length Perception with a Virtual Rolling Stone. In <i>Proceedings of the EuroHaptics 2006 Conference</i>, Paris, France, 275--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278290</article_id>
		<sort_key>9</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Grimage]]></title>
		<subtitle><![CDATA[markerless 3D interactions]]></subtitle>
		<page_from>9</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278290</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278290</url>
		<abstract>
			<par><![CDATA[<p>Grimage glues multi-camera 3D modeling, physical simulation and parallel execution for a new immersive experience. Put your hands or any object into the interaction space. It is instantaneously modeled in 3D and injected into a virtual world populated with solid and soft objects. Push them, catch them and squeeze them.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D interactions]]></kw>
			<kw><![CDATA[PC cluster]]></kw>
			<kw><![CDATA[markerless 3D modeling]]></kw>
			<kw><![CDATA[multi-cameras]]></kw>
			<kw><![CDATA[soft objects simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.2</cat_node>
				<descriptor>Distributed/network graphics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010254</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Reconstruction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P464823</person_id>
				<author_profile_id><![CDATA[81100097644]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J&#233;r&#233;mie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Allard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sim Group - MGH/CIMIT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891392</person_id>
				<author_profile_id><![CDATA[81100286375]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cl&#233;ment]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Menier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INPG]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14096507</person_id>
				<author_profile_id><![CDATA[81100252773]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bruno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raffin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36044245</person_id>
				<author_profile_id><![CDATA[81100397682]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Edmond]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UJF]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35048127</person_id>
				<author_profile_id><![CDATA[81100210102]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Fran&#231;ois]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faure]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UJF]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Allard, J., and Raffin, B. 2005. A Shader-Based Parallel Rendering Framework. In <i>IEEE Visualization Conference</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1130421</ref_obj_id>
				<ref_obj_pid>1130237</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Allard, J., and Raffin, B. 2006. Distributed Physical Based Simulations for Large VR Applications. In <i>IEEE Virtual Reality Conference</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Allard, J., Gouranton, V., Lecointre, L., Limet, S., Melin, E., Raffin, B., and Robert, S. 2004. FlowVR: a Middleware for Large Scale Virtual Reality Applications. In <i>Euro-Par 2004 Parallel Processing: 10th International Euro-Par Conference</i>, 497--505. http://flowvr.sf.net.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Allard, J., Cotin, S., Faure, F., Bensoussan, P.-J., Poyer, F., Duriez, C., Delingette, H., and Grisoni, L. 2007. SOFA: an Open Source Framework for Medical Simulation. In <i>Medicine Meets Virtual Reality (MMVR)</i>. http://www.sofa-framework.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>782862</ref_obj_id>
				<ref_obj_pid>782814</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Borovikov, E., Sussman, A., and Davis, L. 2003. A High Performance Multi-Perspective Vision Studio. In <i>17th Annual ACM International Conference on Supercomputing, San Francisco (USA)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882309</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Carranza, J., Theobalt, C., Magnor, M., and Seidel, H. 2003. Freeviewpoint video of human actors. In <i>Proceedings of ACM SIGGRAPH 03</i>, 569--577.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cheung, G., Kanade, T., Bouguet, J.-Y., and Holler, M. 2000. A real time system for robust 3d voxel reconstruction of human motions. In <i>Computer Vision and Pattern Recognition 00</i>, vol. II, 714 -- 720.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Franco, J., and Boyer, E. 2003. Exact Polyhedral Visual Hulls. In <i>Proceedings of BMVC2003</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Franco, J.-S., M&#233;nier, C., Boyer, E., and Raffin, B. 2004. A Distributed Approach for Real Time 3D Modeling. In <i>Proceedings of the IEEE Workshop on Real Time 3D Sensors and Their Use</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goldl&#252;cke, B., and Magnor, M. 2003. Real-Time Microfacet Billboarding for Free-Viewpoint Video Rendering. <i>Proc. IEEE International Conference on Image Processing (ICIP'03)</i>, Barcelona, Spain (September), 713--716.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882350</ref_obj_id>
				<ref_obj_pid>1201775</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gross, M., Wuermlin, S., Naef, M., Lamboray, E., Spagno, C., Kunz, A., Koller-Meier, E., Svoboda, T., Gool, L. V., S. Lang, K. S., Moere, A. V., and Staadt, O. 2003. Blue-C: A Spatially Immersive Display and 3D Video Portal for Telepresence. In <i>Proceedings of ACM SIGGRAPH 03</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2385982</ref_obj_id>
				<ref_obj_pid>2385956</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hasenfratz, J.-M., Lapierre, M., and Sillion, F. 2004. A real-time system for full body interaction with virtual worlds. 147--156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1018644</ref_obj_id>
				<ref_obj_pid>1018408</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hilton, A., and Starck, J. 2004. Multiple view reconstruction of people. In <i>3DPVT '04: Proceedings of the 3D Data Processing, Visualization, and Transmission, 2nd International Symposium on (3DPVT'04)</i>, IEEE Computer Society, Washington, DC, USA, 357--364.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614766</ref_obj_id>
				<ref_obj_pid>614653</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Kanade, T., Rander, P., and Narayanan, P. 1997. Virtualized Reality: Constructing Virtual Worlds from Real Scenes. <i>IEEE Multimedia, Immersive Telepresence 4</i>, 1 (January), 34--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Krueger, M. W., Gionfriddo, T., and Hinrichsen, K. 1985. Videoplace -- an artificial reality. In <i>CHI '85: Proceedings of the SIGCHI conference on Human factors in computing systems</i>, ACM Press, 35--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Li, M., Magnor, M., and Seidel, H.-P. 2003. Hardware-Accelerated Visual Hull Reconstruction and Rendering. In <i>Proceedings of Graphics Interface'2003</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1006064</ref_obj_id>
				<ref_obj_pid>1006058</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Li, M., Magnor, M., and Seidel, H.-P. 2004. A hybrid hardware-accelerated algorithm for high quality rendering of visual hulls. In <i>GI '04: Proceedings of the 2004 conference on Graphics interface</i>, Canadian Human-Computer Communications Society, School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada, 41--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015805</ref_obj_id>
				<ref_obj_pid>1186562</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Matusik, W., and Pfister, H. 2004. 3D TV: A Scalable System for Real-Time Acquisition, Transmission, and Autostereoscopic Display of Dynamic Scenes. In <i>Proceedings of ACM SIGGRAPH 04</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1110166</ref_obj_id>
				<ref_obj_pid>1109719</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wu, X., Takizawa, O., and Matsuyama, T. 2006. Parallel Pipeline Volume Intersection for Real-Time 3D Shape Reconstruction on a PC Cluster. In <i>Proceedings of the Fourth IEEE International Conference on Computer Vision Systems (ICVS'06)</i>, IEEE Computer Society, Washington, DC, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278291</article_id>
		<sort_key>10</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Haptic telexistence]]></title>
		<page_from>10</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278291</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278291</url>
		<abstract>
			<par><![CDATA[<p>"Haptic Telexistence" provides highly realistic haptic interaction among humans and objects located in remote places. We have developed innovative devices and constructed a master-slave system to realize "Haptic Telexistence". Human interaction will be dramatically improved by this concept that perceives us the properties of an object.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P882913</person_id>
				<author_profile_id><![CDATA[81331503619]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Katsunari]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P882929</person_id>
				<author_profile_id><![CDATA[81331499667]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kouta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minamizawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207192</person_id>
				<author_profile_id><![CDATA[81100173571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawakami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272463</person_id>
				<author_profile_id><![CDATA[81100411569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Susumu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Benali-khoudja M., Hafez M., Alexandre J. M., and Kheddar A. 2004. Tactile Interfaces: A State of the Art Survey, In <i>Proceedings of International Symposium on Robotics</i>, March, Paris, 23--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bouzit, M., Burdea, G., Popescu, G., and Roian, R. 2002. The Rutgers Master II - New Design Force-Feedback Glove, In <i>Proceedings of. IEEE/AMSE Transactions on Mechtronics</i>, 7, 2, 256--263.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Butterfass, B., Grebenstein, M., Lieu, H., and Hirzinger, G. 2001. DLR-Hand II: Next Generation of a Dextrous Robot Hand, In <i>Proceedings of IEEE International Conference on Robotics and Automation</i>, Seoul, May, 109--114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hoshino, K. and Kawabuchi, Y. 2005. Pinching at finger tips for humanoid robot hand, <i>Journal of Robotics and Mechatronics</i>, 17, 6, 655--663.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kajimoto, H., Inami, M., Kawakami, N., and Tachi, S. 2003. SmartTouch: A New Skin Layer to Touch the Non-Touchable, In <i>Proceedings of ACM SIGGRAPH 2003</i>, San Diego.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kajimoto, H., Kawakami, N., Maeda T., and Tachi, S. 2004. Electro-Tactile Display with Tactile Primary Color Approach, In <i>Proceedings of International Conference. on Intelligent Robots and Systems(IROS)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1179145</ref_obj_id>
				<ref_obj_pid>1179133</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kajimoto, H., Kanno, Y., and Tachi, S. 2003. Forehead Retin System, In <i>Proceedings of ACM SIGGRAPH 2003</i>, Boston.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kamiyama, K., Kajimoto, H., Kawakami, N., and Tachi, S. 2004. Evaluation of a Vision-based Tactile Sensor, In <i>Proceedings of International. Conference on Robotics and Automation (ICRA2004)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1186161</ref_obj_id>
				<ref_obj_pid>1186155</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kamiyama, K., Mizota, T., Vlack, K. Kajimoto, H., Kawakami N., and Tachi, S. 2004. GelForce --- A Vision Based Tactile Sensor, In <i>Proceedings of ACM SIGGRAPH 2004</i>, Los Angeles.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kwon, D-S., Woo, K. Y., and Cho, H. S. 1999. Haptic control of the Master Hand Controller for a Microsurgicaltelerobot. In <i>Proceedings of IEEE Robotics and Automation</i>, 3, 1722--1727.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lee, M. H. and Nicholls, H. R 1999. Tactile Sensing for Mechatronics: A State of the Art Survey, Mechatronics, <i>9</i>, 1--31.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Methil, N. S., Shen, Y., Zhu, D., Pomeroy, C. A., Mukherjee, R., Xi, N. and Mutka, M. 2006. Development of supermedia Interface for Telediagnostics of Breast Pathology, In Proceedings of <i>IEEE International Conference on Robotics and Automation</i>, Orlando, Florida.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Minsky, M. 1980. Telepresence, <i>Omni</i>. June. 45--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Nakagawara, S., Kajimoto, H., Kawakami, N., and Tachi, S., Kawabuchi, Y. 2005. An Encounter-Type Multi-Fingered Master Hand Using Circuitous Joints, In <i>Proceedings of IEEE International Conference on Robotics and Automation (ICRA2005)</i>, Barcelona, Spain.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Tachi, S., and Abe, M. 1982. Study on Tele-Existence (1): Design of Visual Display. In <i>Proceedings of the 21&#60;sup&#62;st&#60;/sup&#62; Annual Conference of the Society of Instrument and Control Engineers (SIEC)</i>, Tokyo, Japan, July, 167--168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278292</article_id>
		<sort_key>11</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Holographic and action capture techniques]]></title>
		<page_from>11</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278292</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278292</url>
		<abstract>
			<par><![CDATA[<p>We present an integrated 3D capturing, visualization and user interaction system composed of a computer vision based 3D capturing device, a scene composer and a large scale holographic display. The system performs in real-time and provides the facilities required for capturing realistic human 3D body models, inserting the human representations inside virtual scenarios, detecting 3D interactions between the body models and the virtual objects present in the scene and visualizing the resulting 3D performance on a true 3D holographic display.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D display]]></kw>
			<kw><![CDATA[3D human action capturing]]></kw>
			<kw><![CDATA[interactive]]></kw>
			<kw><![CDATA[virtual reality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35051871</person_id>
				<author_profile_id><![CDATA[81100318761]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rodriguez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eptron]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891390</person_id>
				<author_profile_id><![CDATA[81335489623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adolfo]]></first_name>
				<middle_name><![CDATA[Cabo]]></middle_name>
				<last_name><![CDATA[de Leon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eptron]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891391</person_id>
				<author_profile_id><![CDATA[81335498894]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bruno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Uzzan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Total Immersion]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891411</person_id>
				<author_profile_id><![CDATA[81335494341]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Nicolas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Livet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Total Immersion]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36044253</person_id>
				<author_profile_id><![CDATA[81100397682]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Edmond]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Inria]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891396</person_id>
				<author_profile_id><![CDATA[81335490528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Florian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geffray]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Inria]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35047689</person_id>
				<author_profile_id><![CDATA[81351594492]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Tibor]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Balogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Holografika]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35051721</person_id>
				<author_profile_id><![CDATA[81100160906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Zoltan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Megyesi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Holografika]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35046953</person_id>
				<author_profile_id><![CDATA[81100253144]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Attila]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barsi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Holografika]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[{BAL+06} The HoloVizio System. <i>Tibor Balogh</i> Electronic Imaging, Stereoscopic Displays and Virtual Reality Systems XIII (2006) Vol. 6055.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[{DML+00} DODGSON N. A., MOORE J. R., LANG S. R., MARTIN G., CANEPA P.: Time-sequential multiprojector autostereoscopic 3D display. J. Soc. for Information Display 8, 2 (2000), 169-176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[{Dod96} DODGSON N. A.: Analysis of the viewing zone of the cambridge autostereoscopic display. Applied Optics: Optical Technology & Biomedical Optics 35, 10 (1996), 1705-1710.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[{EWO+95} EZRA D., WOODGATE G. J., OMAR B. A., HOLLIMAN N. S., HARROLD J., SHAPIRO L. S.: New autostereoscopic display system. In Stereoscopic Displays and Virtual Reality Systems II (1995), vol. 2409 of SPIE proceedings, pp. 31-40. 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[{FDHN01} FAVALORA G., DORVAL R., HALL D., NAPOLI J.: Volumetric three dimensional display system with rasterization hardware. In Stereoscopic Displays and Virtual Reality Systems VII (2001), vol. 4297 of SPIE Proceedings, pp. 227-235. 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[{HMG03} HUEBSCHMAN M., MUNJULURI B., GARNER H.: Dynamic holographic 3-D image projection. Optics Express 11 (2003), 437-445.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[{MMMR00} MCKAY S., MAIR G., MASON S., REVIE K.: Membrane-mirror based autostereoscopic display for teleoperation and telepresence applications. In Stereoscopic Displays and Virtual Reality Systems VII (2000), vol. 3957 of SPIE Proceedings, pp. 198-207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015805</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[{MP04} MATUSIK W., PFISTER H.: 3D TV: a scalable system for real-time acquisition, transmission, and autostereoscopic display of dynamic scenes. ACM Transactions on Graphics 23, 3 (Aug. 2004), 814-824.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344933</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[{PPK00} PERLIN K., PAXIA S., KOLLIN J. S.: An autostereoscopic display. In SIGGRAPH 2000, Computer Graphics Proceedings (2000), Akeley K., (Ed.), Annual Conference Series, ACM Press / ACM SIGGRAPH / Addison Wesley Longman, pp. 319-326.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[{RR05} RELKE I., RIEMANN B.: Three-dimensional multiview large projection system. In Stereoscopic Displays and Virtual Reality Systems XII (2005), vol. 5664 of Proc. SPIE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[{RS00} ROBERTS J. W., SLATTERY O.: Display characteristics and the impact on usability for stereo. In Stereoscopic Displays and Virtual Reality Systems VII (2000), vol. 3957 of SPIE proceedings, p. 128.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[{SCC+00} STANLEY M., CONWAY P., COOMBER S., JONES J., SCAT-TERGOOD D., SLINGER C., BANNISTER B., BROWN C., CROSSLAND W., TRAVIS A.: A novel electro-optic modulator system for the production of dynamic images from giga-pixel computer generated holograms. In Practical Holography XIV and Holographic Materials VI (2000), vol. 3956 of SPIE Proceedings, pp. 13-22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[{SHLS+95} ST.-HILLAIRE P., LUCENTE M., SUTTER J., PAPPU R., SPARRELL C. G., BENTON S.: Scaling up the mit holographic video system. In Proc. Fifth International Symposium on Display Holography (1995), SPIE, pp. 374-380.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[{vPF96} VAN BERKEL C., PARKER D., FRANKLIN A.: Multiview 3d-lcd. In Stereoscopic Displays and Virtual Reality Systems III (1996), vol. 2653 of SPIE proceedings, p. 32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[{WEH+98} WOODGATE G. J., EZRA D., HARROLD J., HOLLIMAN N. S., JONES G. R., MOSELEY R. R.: Autostereoscopic 3d display systems with observer tracking. Image Communication - Special Issue on 3D Video Technology (EURASIP - 1998) (1998), 131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[{WHJ+00} WOODGATE G. J., HARROLD J., JACOBS A. M. S., MOSELEY R. R., EZRA D.: Flat-panel autostereoscopic displays: characterisation and enhancement. In Stereoscopic Displays and Virtual Reality Systems VII (2000), vol. 3957 of SPIE proceedings, p. 153.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1110208</ref_obj_id>
				<ref_obj_pid>1109719</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[{ALL+06} The Grimage Platform: A Mixed Reality Environment for Interactions. J. Allard, J.-S. Franco, C. M&#233;nier, E. Boyer and B. Raffin. In Proceedings of International Conference on Computer Vision Systems, 2006 (ICVS'06).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1032922</ref_obj_id>
				<ref_obj_pid>1032634</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[{FRC+04} <i>A Distributed Approach for Real-Time 3D Modeling</i>. J.-S. Franco, C. Menier, E. Boyer and B. Raffin. IEEE CVPR Workshop on Real-Time 3D Sensors and their Applications, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[{FRC+03} <i>Exact Polyhedral Visual Hulls</i>. J.-S. Franco and E. Boyer. In Proceedings of British Machine Vision Conference, 2003 (BMVC'03).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628563</ref_obj_id>
				<ref_obj_pid>628309</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[{LAU+94} The Visual Hull Concept for Silhouette-Based Image Understanding. <i>A. Laurentini</i>. IEEE Transactions on PAMI, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278293</article_id>
		<sort_key>12</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Illumination sensitive dynamic virtual sets]]></title>
		<page_from>12</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278293</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278293</url>
		<abstract>
			<par><![CDATA[<p>We will demonstrate new methods of flexible scene capture (including motion, orientation, and incident illumination), to create a dynamic 'virtual recording set.' We use tracking tags that are imperceptible under attire; inserted Computer Graphics elements can match the lighting on the presenter, making the technique ideal for real-time broadcast.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40030372</person_id>
				<author_profile_id><![CDATA[81100485839]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hideaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nii]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40037877</person_id>
				<author_profile_id><![CDATA[81335489449]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[deDecker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P779713</person_id>
				<author_profile_id><![CDATA[81311484645]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hashimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P890264</person_id>
				<author_profile_id><![CDATA[81335494767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dylan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40030391</person_id>
				<author_profile_id><![CDATA[81340493437]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Summet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40038192</person_id>
				<author_profile_id><![CDATA[81335500473]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P822704</person_id>
				<author_profile_id><![CDATA[81319504113]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Westhues]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P221214</person_id>
				<author_profile_id><![CDATA[81100246613]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dietz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P812296</person_id>
				<author_profile_id><![CDATA[81318497879]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barnwell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027105</person_id>
				<author_profile_id><![CDATA[81100424140]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Masahiko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40037593</person_id>
				<author_profile_id><![CDATA[81100093388]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>11</seq_no>
				<first_name><![CDATA[Philippe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bekaert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40022814</person_id>
				<author_profile_id><![CDATA[81100022847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>12</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raskar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories (MERL)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1033707</ref_obj_id>
				<ref_obj_pid>1032652</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cotting, D., Naef, M., Gross, M., and Fuchs, H. 2004. Embedding imperceptible patterns into projected images for simultaneous acquisition and display. In <i>International Symposium on Mixed and Augmented Reality</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Kang, S.-H., and Tesar, D. Indoor gps metrology system with 3d probe for precision applications. <i>The University of Texas at Austin</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095045</ref_obj_id>
				<ref_obj_pid>1095034</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Lee, J. C., Hudson, S. E., Summet, J. W., and Dietz, P. H. 2005. Moveable interactive projected displays using projector based tracking. In <i>UIST '05: Proceedings of the 18th annual ACM symposium on User interface software and technology</i>, ACM Press, New York, NY, USA, 63--72.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Mark Bolas and Ian McDowall, 2004. Snared illumination. Emerging Technologies, Siggraph.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Motion Analysis Corporation, 2006. Hawk-i digital system.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Nii, H., Sugimoto, M., and Inami, M. 2005. Smart light ultra high speed projector for spatial multiplexing optical transmissio. <i>Procams</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Phase Space Inc, 2007. Impulse camera. http://www.phasespace.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[PTI Inc, 2006. Visualeyez vz 4000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015738</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Beardsley, P., van Baar, J., Wang, Y., Dietz, P., Lee, J., Leigh, D., and Willwacher, T. 2004. Rfig lamps: interacting with a self-describing world via photosensing wireless tags and projectors. <i>ACM Transactions on Graphics 23</i>, 3 (Aug.), 406--415.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1276422</ref_obj_id>
				<ref_obj_pid>1276377</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Nii, H., de Decker, B., Hashimoto, Y., Summet, J., Moore, D., Zhao, Y., Westhues, J., Dietz, P., Inami, M., Nayar, S., Barnwell, J., Noland, M., Bekaert, P., Branzoi, V., and Bruns, E. 2007. Luminetra: High speed scene point capture and video enhancement using photosensing markers and multiplexed illumination. <i>ACM Transactions on Graphics 26</i>, 3 (Aug.).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Silicon Light Machines, 2006. Gated light valve.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[ViconPeak, 2006. "camera mx 40".]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618940</ref_obj_id>
				<ref_obj_pid>616079</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Welch, G., and Foxlin, E. 2002. Motion tracking: No silver bullet, but a respectable arsenal. <i>IEEE Comput. Graph. Appl. 22</i>, 6, 24--38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>897890</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Welch, G. F. 1996. Scaat: Incremental tracking with incomplete information. Tech. rep., Chapel Hill, NC, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073258</ref_obj_id>
				<ref_obj_pid>1073204</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wenger, A., Gardner, A., Tchou, C., Unger, J., Hawkins, T., and Debevec, P. 2005. Performance relighting and reflectance transformation with time-multiplexed illumination. <i>ACM Trans. Graph. 24</i>, 3, 756--764.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278294</article_id>
		<sort_key>13</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[An interactive 360&#176; light field display]]></title>
		<page_from>13</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278294</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278294</url>
		<abstract>
			<par><![CDATA[<p>While a great deal of computer generated imagery is modeled and rendered in 3D, the vast majority of this 3D imagery is shown on 2D displays. Various forms of 3D displays have been contemplated and constructed for at least one hundred years [Lippman 1908], but only recent evolutions in digital capture, computation, and display have made functional and practical 3D displays possible.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40028546</person_id>
				<author_profile_id><![CDATA[81100556708]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jones]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC Centers for Creative Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40028418</person_id>
				<author_profile_id><![CDATA[81100542223]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McDowall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fakespace Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P890271</person_id>
				<author_profile_id><![CDATA[81335499838]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hideshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yamada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sony Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P189952</person_id>
				<author_profile_id><![CDATA[81100467115]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bolas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC School of Cinematic Arts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P221188</person_id>
				<author_profile_id><![CDATA[81100086933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Debevec]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC Centers for Creative Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1130465</ref_obj_id>
				<ref_obj_pid>1130237</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agocs, T., Balogh, T., Forgacs, T., Bettio, F., Gobbetti, E., Zanetti, G., and Bouvier, E. 2006. A large scale interactive holographic display. In <i>VR '06: Proceedings of the IEEE Virtual Reality Conference (VR 2006)</i>, IEEE Computer Society, Washington, DC, USA, 57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1179152</ref_obj_id>
				<ref_obj_pid>1179133</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Balogh, T., Dobranyi, Z., Forgacs, T., Molnar, A., Szloboda, L., Gobbetti, E., Marton, F., Bettio, F., Pintore, G., Zanetti, G., Bouvier, E., and Klein, R. 2006. An interactive multi-user holographic environment. In <i>SIGGRAPH '06: ACM SIGGRAPH 2006 Emerging technologies</i>, ACM Press, New York, NY, USA, 18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Batchko, R. G. 1994. Three-hundred-sixty degree electro-holographic stereogram and volumetric display system. In <i>Proc. SPIE</i>, vol. 2176, 30--41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344932</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chai, J.-X., Tong, X., Chan, S.-C., and Shum, H.-Y. 2000. Plenoptic sampling. In <i>Proceedings of ACM SIGGRAPH 2000</i>, Computer Graphics Proceedings, Annual Conference Series, 307--318.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cossairt, O., Travis, A. R., Moller, C., and Benton, S. A. 2004. Novel view sequential display based on dmd technology. In <i>Proc. SPIE, Stereoscopic Displays and Virtual Reality Systems XI</i>, A. J. Woods, J. O. Merritt, S. A. Benton, and M. T. Bolas, Eds., vol. 5291, 273--278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cossairt, O. S., Napoli, J., Hill, S. L., Dorval, R. K., and Favalora, G. E. 2007. Occlusion-capable multiview volumetric three-dimensional display. <i>Applied Optics 46</i>, 8 (Mar), 1244--1250.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1083846</ref_obj_id>
				<ref_obj_pid>1083811</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dodgson, N. A. 2005. Autostereoscopic 3d displays. <i>Computer 38</i>, 8, 31--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826557</ref_obj_id>
				<ref_obj_pid>826029</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Endo, T., Kajiki, Y., Honda, T., and Sato, M. 2000. Cylindrical 3d video display observable from all directions. In 8th <i>Pacific Conference on Computer Graphics and Applications</i>, 300--306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1083847</ref_obj_id>
				<ref_obj_pid>1083811</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Favalora, G. E. 2005. Volumetric 3d displays and application infrastructure. <i>Computer 38</i>, 8, 37--44.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237200</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gortler, S. J., Grzeszczuk, R., Szeliski, R., and Cohen, M. F. 1996. The lumigraph. In <i>Proceedings of SIGGRAPH 96</i>, Computer Graphics Proceedings, Annual Conference Series, 43--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Halle, M. W., Benton, S. A., Klug, M. A., and Underkoffler, J. S. 1991. The ultragram: A generalized holographic stereogram.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383907</ref_obj_id>
				<ref_obj_pid>2383894</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hou, X., Wei, L.-Y., Shum, H.-Y., and Guo, B. 2006. Real-time multiperspective rendering on graphics hardware. In <i>Rendering Techniques 2006: 17th Eurographics Workshop on Rendering</i>, 93--102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344929</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Isaksen, A., McMillan, L., and Gortler, S. J. 2000. Dynamically reparameterized light fields. In <i>Proceedings of ACM SIGGRAPH 2000</i>, Computer Graphics Proceedings, Annual Conference Series, 297--306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jones, A., Debevec, P., Bolas, M., and McDowall, I. 2006. Concave surround optics for rapid multiview imaging. In <i>Proceedings of the 25th Army Science Conference</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jones, A., McDowall, I., Yamada, H., Bolas, M., and Debevec, P. 2007. Rendering for an interactive 360 degree light field display. In <i>ACM Transactions on Graphics</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237199</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Levoy, M., and Hanrahan, P. M. 1996. Light field rendering. In <i>Proceedings of ACM SIGGRAPH 96</i>, Computer Graphics Proceedings, Annual Conference Series, 31--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lippman, G. 1908. Epreuves reversibles donnant la sensation du relief. <i>Journal of Physics 7</i>, 4 (Nov), 821--835.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946848</ref_obj_id>
				<ref_obj_pid>946248</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Maeda, H., Hirose, K., Yamashita, J., Hirota, K., and Hirose, M. 2003. All-around display for video avatar in real world. In <i>ISMAR '03: Proceedings of the The 2nd IEEE and ACM International Symposium on Mixed and Augmented Reality</i>, IEEE Computer Society, Washington, DC, USA, 288.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383326</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ostromoukhov, V. 2001. A simple and efficient error-diffusion algorithm. In <i>Proceedings of ACM SIGGRAPH 2001</i>, Computer Graphics Proceedings, Annual Conference Series, 567--572.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1110750</ref_obj_id>
				<ref_obj_pid>1110642</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Otsuka, R., Hoshino, T., and Horry, Y. 2006. Transpost: A novel approach to the display and transmission of 360 degrees-viewable 3d solid images. <i>IEEE Transactions on Visualization and Computer Graphics 12</i>, 2, 178--185.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Tanaka, K., and Aoki, S. 2006. A method for the real-time construction of a full parallax light field. In <i>Stereoscopic Displays and Virtual Reality Systems XIII. Edited by Woods, Andrew J.; Dodgson, Neil A.; Merritt, John O.; Bolas, Mark T.; McDowall, Ian E. Proceedings of the SPIE, Volume 6055, pp. 397--407 (2006).</i>, A. J. Woods, N. A. Dodgson, J. O. Merritt, M. T. Bolas, and I. E. McDowall, Eds., 397--407.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Travis, A. R. L. 1997. The display of three-dimensional video images. <i>Proceedings of the IEEE 85</i>, 11 (Nov), 1817--1832.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073259</ref_obj_id>
				<ref_obj_pid>1073204</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Wilburn, B., Joshi, N., Vaish, V., Talvala, E.-V., Antunez, E., Barth, A., Adams, A., Horowitz, M., and Levoy, M. 2005. High performance imaging using large camera arrays. <i>ACM Transactions on Graphics 24</i>, 3 (Aug), 765--776.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581907</ref_obj_id>
				<ref_obj_pid>581896</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Yang, J. C., Everett, M., Buehler, C., and McMillan, L. 2002. A real-time distributed light field camera. In <i>Rendering Techniques 2002: 13th Eurographics Workshop on Rendering</i>, 77--86.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1187314</ref_obj_id>
				<ref_obj_pid>1187297</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Yendo, T., Kawakami, N., and Tachi, S. 2005. Seelinder: the cylindrical lightfield display. In <i>SIGGRAPH '05: ACM SIGGRAPH 2005 Emerging technologies</i>, ACM Press, New York, NY, USA, 16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383905</ref_obj_id>
				<ref_obj_pid>2383894</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Zwicker, M., Matusik, W., Durand, F., and Pfister, H. 2006. Antialiasing for automultiscopic 3d displays. In <i>Rendering Techniques 2006: 17th Eurographics Workshop on Rendering</i>, 73--82.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278295</article_id>
		<sort_key>14</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[inter-glow]]></title>
		<page_from>14</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278295</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278295</url>
		<abstract>
			<par><![CDATA[<p>Inter-glow is a system that facilitates close interaction and communication among users in real space by using multiplexed visible-light communication technology. By shining light on an object containing an embedded photo sensor, users can get information about the object. In addition, several users can communicate with each other intimately by shining light on the object at the same time.</p> <p>We built a prototype to demonstrate the technology. In our prototype, when users point their lamps at the table in a miniature living room, the system can recognize which lamps are illuminating the table. According to the combination of illuminating lamps, the system produces the family conversations.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[intelligent space]]></kw>
			<kw><![CDATA[interactive art]]></kw>
			<kw><![CDATA[pervasive computing]]></kw>
			<kw><![CDATA[visible-light communication]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P875246</person_id>
				<author_profile_id><![CDATA[81331500452]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Takuji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Narumi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P875170</person_id>
				<author_profile_id><![CDATA[81331494695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Atsushi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hiyama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P498943</person_id>
				<author_profile_id><![CDATA[81100172183]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tomohiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tanikawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025385</person_id>
				<author_profile_id><![CDATA[81100257385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Michitaka]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirose]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1187299</ref_obj_id>
				<ref_obj_pid>1187297</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Maki Sugimoto, Minoru Kojima, Akihiro Nakamura, Georges Kagotani, Hideaki Nii, Masahiko Inami: Augmented Coliseum: Display-Based Computing for Augmented Reality Inspiration Computing Robot, SIGGRAPH 2005 Full Conference DVD-ROM Disk1 Emerging Technologies, 2005]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Visible Light Communication Consortium, http://www.vlcc.net/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Tanaka, S. Haruyama and M. Nakagawa: Wireless optical transmission with the white colored LED for the wireless home links, Proc. 11&#60;sup&#62;th&#60;/sup&#62; Int. Symp. on PIMRC, pp.1325 - 1329, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Komine, Y. Tanaka, S. Haruyama and M. Nakagawa: Basic study on visible-light communication using light emitting diode illumination, Proc. 8&#60;sup&#62;th&#60;/sup&#62; Int. Symp. on ISMOT, pp. 45 - 48, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>826330</ref_obj_id>
				<ref_obj_pid>826025</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Pingali, G., Pinhanez, C., Levas, A., Kjeldsen, R., Podlaseck, M., Chen, H. and Sukaviriya, N.: Steerable Interfaces for Pervasive Computing Spaces, First IEEE International Conference on Pervasive Computing and Communications (PerCom'03), pp. 315--322 (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1175909</ref_obj_id>
				<ref_obj_pid>1175877</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Shklovski, I., Chang, M. (2006).: Urban computing: Navigating space and context., <i>IEEE Computer</i> Sept 2006, V. 39(9) p. 36--37]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278296</article_id>
		<sort_key>15</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Lensless stereo microscopic imaging]]></title>
		<page_from>15</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278296</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278296</url>
		<abstract>
			<par><![CDATA[<p>A simple inexpensive high-contrast stereo microscopic is constructed from a single video imager sensor. Two field-synchronous LEDs illuminate the subject creating disparity. The stereo microscope outputs standard field-sequential 3D video and is compatible with commercial head mounted displays and LCD shutter glasses.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP35053836</person_id>
				<author_profile_id><![CDATA[81100030187]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Zimmerman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Almaden Research Center, San Jose, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP311034000</person_id>
				<author_profile_id><![CDATA[81539766956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Barton]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Almaden Research Center, San Jose, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Berg, H. C., Brown, D. A. 1972 Chemotaxis in Escherichia coli analyzed by Three-dimensional Tracking. <i>Nature</i>, 239:5374, 500--504.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Charoy, C. 1995. Modification of the swimming behaviour of Brachionus calyciflorus (Pallas) according to food environment and individual nutritive state. <i>Journal Hydrobiologia</i>, 313--314:1, 197--204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Coulon, P. Y., Charras, J. P., Chasse, L., Clement, P, Cornillac, A., Luciani, A., Wurdak, E., 1983. An experimental system for the automatic tracking and analysis of rotifer swimming behaviour. <i>Journal Hydrobiologia</i> 104:1, 197--202.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Garcia-Sucerquia, J., Xu, W., Jericho, S. K., Klages, P., Jericho, M. H., Kreuzer, H. J., 2006. Digital in-line holograhic microscopy. <i>Applied Optics</i> 45, 836--850.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Heng, H., Erickson, D., Psaltis, D., Yang C., 2005. A new imaging method: optofluidic microscopy. Invited Talk, <i>SPIE Optics East</i>, Boston MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hoeling, B., Fernandez, A., Haskell, R., Huang, E., Myers, W., Peterson, D., Ungersma, S., Wang, R., Williams, M., Fraser, S., 2000. An optical coherence microscope for 3-dimensional imaging in developmental biology, <i>Optics Express</i> 6, 136--146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015779</ref_obj_id>
				<ref_obj_pid>1015706</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Raskar, R., Tan, K., Feris, R., Yu, J. Turk, M. 2004. Non-photorealistic camera: Depth edge detection and stylized rendering using multi-flash imaging. <i>ACM Transactions on Graphics</i>. 23, 3, 679--688.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Reed Mariculture 2007, 520 McGlincy Lane #1, Campbell, CA 95008 www.reed-mariculture.com/rotifer/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Supercircuits 2007. Video Security Camera Model PC100XS. Supercircuits Inc, 11000 N. Mopac Expressway Suite 300 Austin, Texas 78759 www.supercircuits.com]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Yuferal, M., Pascuall, E., Olivares, J. M. 2005. Factors Affecting Swimming Speed in the Rotifer Brachionus plicatilis. <i>Journal Hydrobiologia</i>, 546:1, 375--380.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278297</article_id>
		<sort_key>16</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[SCP camera]]></title>
		<page_from>16</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278297</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278297</url>
		<abstract>
			<par><![CDATA[<p>Shoot Cut & Play Camera (SCP.Camera) is an application combining a real-time montage interface and an immersive device. It provides to film-maker or camera operator an easy tool to set up their work or previsualization. User can activate actors animations, record the virtual world, and edit sequences before exporting them to a 3D software.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[animation]]></kw>
			<kw><![CDATA[camera]]></kw>
			<kw><![CDATA[cameraman]]></kw>
			<kw><![CDATA[device]]></kw>
			<kw><![CDATA[immersive]]></kw>
			<kw><![CDATA[interactive]]></kw>
			<kw><![CDATA[montage]]></kw>
			<kw><![CDATA[motion tracking]]></kw>
			<kw><![CDATA[prototyping]]></kw>
			<kw><![CDATA[realtime]]></kw>
			<kw><![CDATA[storyboarding]]></kw>
			<kw><![CDATA[virtual reality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P891426</person_id>
				<author_profile_id><![CDATA[81442604743]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xavier]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gouchet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University Paris]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891413</person_id>
				<author_profile_id><![CDATA[81335496473]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Remi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Quittard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University Paris]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891412</person_id>
				<author_profile_id><![CDATA[81335497225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nicolas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Serikoff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University Paris]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278298</article_id>
		<sort_key>17</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Soap]]></title>
		<subtitle><![CDATA[a pointing and gaming device for the living room and anywhere else]]></subtitle>
		<page_from>17</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278298</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278298</url>
		<abstract>
			<par><![CDATA[<p>Soap is a pointing device based on hardware found in a mouse, yet works in mid-air. Soap consists of an optical sensor device moving freely inside a hull made of fabric. As the user applies pressure from the outside, the optical sensor moves independent from the hull. The optical sensor perceives this relative motion and reports it as position input. Soap offers many of the benefits of optical mice, such as high-accuracy sensing. We describe the design of a soap prototype and report our experiences with four application scenarios, including a wall display, Windows Media Center, slide presentation, and interactive video games.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14058749</person_id>
				<author_profile_id><![CDATA[81100137268]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baudisch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37030899</person_id>
				<author_profile_id><![CDATA[81318498872]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sinclair]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39054371</person_id>
				<author_profile_id><![CDATA[81350567780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wilson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1166261</ref_obj_id>
				<ref_obj_pid>1166253</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baudisch, P., Sinclair, M, and Wilson, A. 2006. Soap: a pointing device that works in mid-air. In <i>Proc. UIST 2006</i> (technote), Oct 15-18, 2006, pp. 43--46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Buxton, W. & Myers, B. 1986. A study in two-handed input. In <i>Proc. CHI'86</i>, pp. 321--326.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Buxton, W. 1986. There's More to Interaction than Meets the Eye: Some Issues in Manual Input. In Norman, D. A. and Draper, S. W. (eds.). <i>User Centered System Design: New Perspectives on Human-Computer Interaction</i>. Lawrence Erlbaum Associates. Hillsdale, New Jersey. 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Card, S., Mackinlay, J., and Robertson, G. 1991. A morphological analysis of the design space of input devices. In <i>TOIS</i> 9(2):99--122, April 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1089511</ref_obj_id>
				<ref_obj_pid>1089508</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hachet, M., Pouderoux, J., Guitton, P. 2005. TangiMap---A Tangible Interface for Visualization of Large Documents on Handheld Computers. In <i>Proc. GI'05</i>, pp 9--15.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>234387</ref_obj_id>
				<ref_obj_pid>234313</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jacob, R. 1996. Human-Computer Interaction: Input Devices. <i>ACM Computing Surveys</i>, vol. 28, no. 1, pp. 177--179 (March 1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1089510</ref_obj_id>
				<ref_obj_pid>1089508</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Kohli, L. and Whitton, M. 2005. The Haptic Hand: Providing User Interface Feedback with the Non-Dominant Hand in Virtual Environments. In <i>Proc. GI 2005</i>, pp. 1--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[McLoone, H. 2001. Touchable Objects. In <i>Proc. International Conference on Affective Human Factors Design</i> Asean Academic Press, London, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Penny and Giles Endless Belt www.pennyandgiles.com/products/products.asp?intElement=1174]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237115</ref_obj_id>
				<ref_obj_pid>237091</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Rekimoto, J. 1996. Tilting Operations for Small Screen Interfaces. In <i>Proc. UIST'96</i>. pp. 167--168]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Vlack, K., Mizota, T., Kawakami, N., Kamiyama, K., Kajimoto, H., Tachi, S. 2005. GelForce: A Traction Field Tactile Interface. In <i>CHI'05 Extended Abstracts</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642706</ref_obj_id>
				<ref_obj_pid>642611</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wilson, A. and Shafer, S. 2003. XWand: UI for Intelligent Spaces, In <i>Proc. CHI'03</i>, pp. 545--552.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1027946</ref_obj_id>
				<ref_obj_pid>1027933</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wilson, A. 2004. TouchLight: An Imaging Touch Screen and Display for Gesture-Based Interaction, <i>Proc. ICMI'04</i>, pp. 69--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971522</ref_obj_id>
				<ref_obj_pid>971478</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Zhang, Z., Wu, Y. Shan, Y., and Shafer, S. 2001. Visual Panel: Virtual Mouse, Keyboard and 3D Controller with an Ordinary Piece of Paper. In <i>Proc. ACM Workshop on Perceptive User Interfaces 2001</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278299</article_id>
		<sort_key>18</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[The sound of touch]]></title>
		<subtitle><![CDATA[a wand and texture kit for sonic exploration]]></subtitle>
		<page_from>18</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278299</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278299</url>
		<abstract>
			<par><![CDATA[<p>In this paper we describe the Sound of Touch, a new instrument for real-time capture and sensitive physical stimulation of sound samples using digital convolution. Our hand-held wand can be used to (1) record sound, then (2) brush, scrape, strike or otherwise physically manipulate this sound against physical objects. These actions produce sound in a manner that leverages peoples existing intuitions about sonic properties of physical materials. The Sound of Touch permits real-time exploitation of the sonic properties of a physical environment, to achieve a rich and expressive control of digital sound that is not typically possible in electronic sound synthesis and control systems.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[digital convolution]]></kw>
			<kw><![CDATA[digital sound manipulation]]></kw>
			<kw><![CDATA[electronic music controller]]></kw>
			<kw><![CDATA[sensing]]></kw>
			<kw><![CDATA[tangible user interface]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP35038436</person_id>
				<author_profile_id><![CDATA[81328489350]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Merrill]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P507458</person_id>
				<author_profile_id><![CDATA[81100381813]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hayes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raffle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MIT Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aimi, R. 2006. <i>Extending Physical Instruments Using Sampled Acoustics</i>. PhD thesis, Massachusetts Institute of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hunt, A., Wanderley, M., and Paradis, M. 2003. The importance of parameter mapping in electronic instrument design. <i>Journal of New Music Research 32</i>, 4, 429--440.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Oppenheim, A., and Schafer, R. 1989. <i>Discrete-time signal processing</i>. Prentice-Hall, Inc. Upper Saddle River, NJ, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Zhang, J., Harbottle, G., Wang, C., and Kong, Z. 1999. Oldest playable musical instruments found at jiahu early neolithic site in china. <i>Nature 401</i>, 6751, 366--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278300</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Spinning-disc 3D television]]></title>
		<page_from>19</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278300</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278300</url>
		<abstract>
			<par><![CDATA[<p>In this work, we have incorporated a novel LED-projection technology into the simple structure of a spinning-disc television. In order to display a 3D image, we have replaced the conventionally used light bulbs with an LED array. With the aid of this technology, users can view different images from different viewing angles.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40034504</person_id>
				<author_profile_id><![CDATA[81100485839]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hideaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nii]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P882929</person_id>
				<author_profile_id><![CDATA[81331499667]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kouta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minamizawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207192</person_id>
				<author_profile_id><![CDATA[81100173571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawakami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272463</person_id>
				<author_profile_id><![CDATA[81100411569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Susumu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cruz-Neira, C., Sandin, D. J., and DeFanti, T. A. 1993. Surround-screen projection-based virtual reality: The design and implementation of the cave. In <i>Proc. of Computer Graphics</i>, vol. 27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1187314</ref_obj_id>
				<ref_obj_pid>1187297</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Endo, T., Kawakami, N., and Tachi, S. 2005. Seelinder: The cylindrical lightfield display. In <i>Conference Abstracts and Applications of ACM SIGGRAPH2005</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hamagishi, G., Sakata, M., Yamashita, A., Mashitani, K., Nakayama, E., Kishimoto, S., and Kanatani, K. 1996. Stereoscopic lc displays without special glasses. <i>SID Digest of Applications Papers</i>, 75--78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. 1968. A head-mounted three dimensional display. In <i>Proc. fall Joint Computer Conference, AFIPS Conf. Proc.</i>, vol. 33, 757--764.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1242116</ref_obj_id>
				<ref_obj_pid>1242073</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Tanaka, K., Hayashi, J., Kunita, Y., Inami, M., Maeda, T., and Tachi, S. 2002. Twister: A media booth. In <i>Conference Abstracts and Applications of ACM SIGGRAPH2002</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Tiltman, Ronald F. Kennedy, L. A. 1933. <i>Baird of television: the life story of John Logie Baird</i>. London: Seeley Service.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278301</article_id>
		<sort_key>20</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[String walker]]></title>
		<page_from>20</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278301</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278301</url>
		<abstract>
			<par><![CDATA[<p>The String Walker is a locomotion interface using eight strings actuated by motor-pulley mechanisms mounted on a turntable. It enables the user to walk in virtual environment while his/her position is maintained. The mechanism enables omni-directional walking. The device allows the walker to various gait, such as side-walking.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[locomotion interface]]></kw>
			<kw><![CDATA[string]]></kw>
			<kw><![CDATA[turntable]]></kw>
			<kw><![CDATA[walking]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Haptic I/O</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011752</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Haptic devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP40026665</person_id>
				<author_profile_id><![CDATA[81100382304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hiroo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Iwata]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tsukuba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P110718</person_id>
				<author_profile_id><![CDATA[81100255856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hiroaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tsukuba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891408</person_id>
				<author_profile_id><![CDATA[81335498354]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Masaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tomiyoshi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tsukuba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Brooks, F. P., Jr. A dynamic graphics system for simulating virtual buildings. Proceedings of the 1986 Workshop on Interactive 3D Graphics(Chapel Hill, NC, October 1986). ACM, New York, 9--21.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Hirose, M. and Yokoyama, K. VR Application for Transmission of Synthetic Sensation. Proceedings of ICAT'92, (1992), 145--154]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Noma, H., and Miyasato, T. Design for locomotion interface in a large scale virtual environment. ATLAS: ATR Locomotion INterface for Active Self Motion. Proc. ASME Dynamic Systems and Control Division, DSC-Vol. 64, (1998), 111--118]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Christensen, R., Hollerbach, J. M., Xu, Y., and Meek, S. Inertial force feedback for a locomotion interface. Proc. ASME Dynamic Systems and Control Division, DSC-Vol. 64, (1998), 119--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Prat, David R. et. al., Insertion of an Articulated Human into a Networked Virtual Environment, Proc. of the 1994 AI, Simulation, and Planning in High Autonomy Systems Conference,(1994), 7--9]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lorenzo, M. et. al. OSIRIS. SIGGRAPH'95 Visual Proceedings, (1995), 129]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Slater, M. et. al. Steps and ladders in Virtual Reality. Virtual Reality Technology, World Scientific Publication. (1994), 45--54]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>263550</ref_obj_id>
				<ref_obj_pid>263407</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Darken, R., Cockayne, W., Carmein, D., The Omni-directional Treadmill:A Locomotion Device for Virtual Worlds, Proceedings of UIST'97,(1997)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Iwata, H. Artificial Reality for Walking About Large Scale Virtual Space. Human Interface News and Report 5,1 (1990), 49--52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Iwata, H. and Matsuda, K. Artificial Reality for Walking About Uneven Surface of Virtual Space. Proceedings of 6th Symposium on Human Interface, (1990), 21--25.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Iwata, H. and Matsuda, K. Haptic Walkthrough Simulator: Its Design and Application to Studies on Cognitive Map. Proceedings of ICAT'92, (1992), 185--192]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836041</ref_obj_id>
				<ref_obj_pid>832290</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Iwata, H. and Fujii, T., Virtual Perambulator: A Novel Interface Device for Locomotion in Virtual Environment, Proc. of IEEE 1996 Virtual Reality Annual International Symposium, (1996), 60--65]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618662</ref_obj_id>
				<ref_obj_pid>616061</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Iwata, H., The Trous Treadmill: Realizing Locomotion in VEs, IEEE Computer Graphics and Applications, Vol.9, No.6 (1999) 30--35]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835815</ref_obj_id>
				<ref_obj_pid>580521</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Iwata, H., Yano, H. and Nakaizumi, F., Gait Master: A Versatile Locomotion Interface for Uneven Virtual Terrain, Proceedings of IEEE Virtual Reality 2001 Conference, (2001) 131--137]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042218</ref_obj_id>
				<ref_obj_pid>1042190</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Iwata, H., Yano, H., Fukushima, H., and Noma, H., CirculaFloor, IEEE Computer Graphics and Applications, Vol.25, No.1 (2005) 64--67]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Iwata, H, Yano, H., and Tomioka, H., Powered Shoes, SIGGRAPH 2006 Conference DVD (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278302</article_id>
		<sort_key>21</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[TORSO]]></title>
		<subtitle><![CDATA[completion of egocentric telegnosis system]]></subtitle>
		<page_from>21</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278302</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278302</url>
		<abstract>
			<par><![CDATA[<p>We have proposed a system that can acquire natural and comfortable visual information and can accurately track the head motion of the person. The conventional imaging device for head-mounted display was only able to express the 3-axis rotation of the neck but our device has expressed the head motion as well as the translation motion of the neck.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[head motion]]></kw>
			<kw><![CDATA[master-slave]]></kw>
			<kw><![CDATA[telexistence]]></kw>
			<kw><![CDATA[torso]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P830180</person_id>
				<author_profile_id><![CDATA[81321488549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kouichi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watanabe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35049636</person_id>
				<author_profile_id><![CDATA[81335492863]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ichiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawabuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kawabuchi Mechanical Engineering Laboratory, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207192</person_id>
				<author_profile_id><![CDATA[81100173571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawakami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P278536</person_id>
				<author_profile_id><![CDATA[81100065999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Taro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Maeda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272463</person_id>
				<author_profile_id><![CDATA[81100411569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Susumu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cruz-Neira, C., Sandin, D. J., and DeFanti, T. A. 1993. Surround-screen projection-based virtual reality: The design and implementation of the cave. In <i>Proceedings of SIGGRAPH '93</i>, 135--142.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311983</ref_obj_id>
				<ref_obj_pid>311625</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Inami, M., Kawakami, N., Sekiguchi, D., Maeda, T., and Tachi, S. 1999. Head-mounted projector. In <i>Conference Abstracts and Applications of SIGGRAPH '99</i>, 179.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. E. 1968. A head-mounted three dimensional display. In <i>Proceedings of Fal Joint Computer Conference, AFIPS Conf. Proc.</i>, 757--764.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Yanagida, Y., Mitsuhashi, A., Maeda, T., and Tachi, S. 1999. Implementation of fixed-screen-based telexistence visual system. In <i>Proceedings of the ICAT '99 (9th International Conference on Artificial Reality and Telexistence)</i>, 123--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278303</article_id>
		<sort_key>22</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Transparent cockpit]]></title>
		<page_from>22</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278303</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278303</url>
		<abstract>
			<par><![CDATA[<p>We propose a "transparent cockpit" that is aimed toward improving the operativeness, safety, and comfort during controlling a vehicle. In the transparent cockpit, the interior appointments of the vehicle are virtually transparent; this is enabled by using the retro-reflective projection technology.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P891420</person_id>
				<author_profile_id><![CDATA[81421594598]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Takumi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yoshida]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891406</person_id>
				<author_profile_id><![CDATA[81335492333]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kensei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P882929</person_id>
				<author_profile_id><![CDATA[81331499667]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kouta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minamizawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40034504</person_id>
				<author_profile_id><![CDATA[81100485839]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hideaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nii]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207192</person_id>
				<author_profile_id><![CDATA[81100173571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawakami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272463</person_id>
				<author_profile_id><![CDATA[81100411569]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Susumu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Cruz-Neira, C., Sandin, D. J., and DeFanti, T. A. 1993. Surround-screen projection-based virtual reality: The design and implementation of the cave. In <i>Proc. of Computer Graphics</i>, vol. 27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835773</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Inami, M., Kawakami, N., Sekiguchi, D., Yanagida, Y., Maeda, T., and Tachi, S. 2000. Visuo-haptic display using head-mounted projector. In <i>Proceedings of IEEE Virtual Reality 2000</i>, 233--240.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946825</ref_obj_id>
				<ref_obj_pid>946248</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Inami, M., Kawakami, N., and Tachi, S. 2003. Optical camouflage using retro-reflective projection technology. In <i>Proceedings of the Second IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'03)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>281305</ref_obj_id>
				<ref_obj_pid>280953</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kawakami, N., Inami, M., Maeda, T., and Tachi, S. 1998. The object oriented displays. In <i>Conference Abstracts and Applications (SIGGRAPH 98)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Sonoda, T., Endo, T., Kawakami, N., Suzuki, Y., and Tachi, S. 2005. X'tal visor. In <i>Conference Abstracts and Applications of ACM SIGGRAPH2005</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sutherland, I. 1968. A head-mounted three dimensional display. In <i>Proc. fall Joint Computer Conference, AFIPS Conf. Proc.</i>, vol. 33, 757--764.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Toyofuku, K., Iwata, Y., Hagisato, Y., and Kumasaka, T. 2003. The "night view system" using near-infrared light. In <i>SAE 2003 World Congress & Exhibition</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278304</article_id>
		<sort_key>23</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[TransPen & MimeoPad]]></title>
		<subtitle><![CDATA[a playful interface for transferring a graphic image to paper by digital rubbing]]></subtitle>
		<page_from>23</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278304</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278304</url>
		<abstract>
			<par><![CDATA[<p>Frottage and rubbing are drawing techniques that allow interesting visual expression through simple rubbing actions revealing a texture or a pattern hidden in the background. Specifically, frottage is a drawing technique where one puts a textured surface, such as wooden planks, metal sheets, wire nets, and hemp cloth, under a sheet of paper and rubs over it with a charcoal or a colored pencil to make appear various strange images [Simpson 1989]. Frottage has been loved by many artists since it enables them to add incidental textured effects to an intentional drawing (Fig. 1(a)). With rubbing, on the other hand, one transfers a carved image by putting a sheet of paper on an object with a carved pattern and rubbing on it with a pencil, a charcoal, or a colored pencil. Putting a piece of paper over a coin and then rubbing over it with a pencil to copy the image of the coin can be regarded as a type of rubbing (Fig. 1(b)). This activity is done for visual amusement itself or for a primitive means of copying graphic information.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14136143</person_id>
				<author_profile_id><![CDATA[81100384795]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Woohun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[KAIST]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P854758</person_id>
				<author_profile_id><![CDATA[81324492738]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jinhee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[KAIST]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P854784</person_id>
				<author_profile_id><![CDATA[81324491023]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Seoktae]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[KAIST]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891400</person_id>
				<author_profile_id><![CDATA[81452601021]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hyunjung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[KAIST]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14136181</person_id>
				<author_profile_id><![CDATA[81100384871]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Geehyuk]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ICU]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>958207</ref_obj_id>
				<ref_obj_pid>958160</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Gutwin, C., Dyck, J., and Burkitt, J. 2003. Using cursor prediction to smooth telepointer jitter. In <i>Proceedings of the 2003 international ACM SIGGROUP Conference on Supporting Group Work (Sanibel Island, Florida, USA, November 09 - 12, 2003)</i>. GROUP '03. ACM Press, New York, NY, 294--301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>281439</ref_obj_id>
				<ref_obj_pid>281388</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Ho. 1998. A digital frottage. In <i>ACM SIGGRAPH 98 Electronic Art and Animation Catalog (Orlando, Florida, United States, July 19 - 24, 1998)</i>. SIGGRAPH '98. ACM Press, New York, NY, 27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1029682</ref_obj_id>
				<ref_obj_pid>1029632</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Lee, J. C., Dietz, P. H., Leigh, D., Yerazunis, W. S., Hudson, S. E. 2004. Haptic Pen: A Tactile Feedback Stylus for Touch Screens, <i>ACM Symposium on User Interface Software and Technology (UIST)</i>, 291--294.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Neustetter, M. 2005. Physically Digital, Digitally Physical, <i>LEONARDO</i>, Vol.38, No.3, 181]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Printdreams, PrintBrush#8482;, Retrieved on January 12, 2007 from <i>http://www.printdreams.com/print brush/</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Simpson, I. 1989. <i>The Encyclopedia of Drawing Techniques</i>, Headline.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Random International, PixelRoller, Retrieved on April 4, 2007 from <i>http://random-international.squarespace.com/pixel roller-overview/</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278305</article_id>
		<sort_key>24</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Video agents]]></title>
		<page_from>24</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278305</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278305</url>
		<abstract>
			<par><![CDATA[<p>This project establishes an interactive environment in cyberspace in which users interact with autonomous agents generated from video images of real-world creatures. Each agent has autonomy, personality traits, and behaviors that reflect the results of various interactions, which are determined by an emotional model.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[authoring tool]]></kw>
			<kw><![CDATA[autonomous agent]]></kw>
			<kw><![CDATA[character animation]]></kw>
			<kw><![CDATA[video agent]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Virtual device interfaces</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP35047753</person_id>
				<author_profile_id><![CDATA[81335487848]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kazuhiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Asai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891418</person_id>
				<author_profile_id><![CDATA[81335495162]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishimoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891427</person_id>
				<author_profile_id><![CDATA[81381604194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yoshinori]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891394</person_id>
				<author_profile_id><![CDATA[81335491149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Emiko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P306500</person_id>
				<author_profile_id><![CDATA[81100273942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Yoshifumi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kitamura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14122116</person_id>
				<author_profile_id><![CDATA[81100339162]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Fumio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kishino]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Costa, P. T., and McCrae, R. R. 1985. <i>The NEO Personality Inventory</i>. Psychological Assessment Resources.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028559</ref_obj_id>
				<ref_obj_pid>1028523</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[De Juan, C., and Bodenheimer, B. 2004. Cartoon textures. In <i>Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation</i>, ACM Press, New York, NY, USA, 267--276.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Ekman, P., and Davidson, R. J. 1994. The nature of emotion: fundamental questions. Oxford University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>281310</ref_obj_id>
				<ref_obj_pid>280953</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kombis, S. 1998. Virtual fishtank. In <i>ACM SIGGRAPH 98 Conference abstracts and applications</i>, ACM Press, New York, NY, USA, 116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566605</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kovar, L., Gleicher, M., and Pighin, F. 2002. Motion graphs. In <i>Proceedings of ACM SIGGRAPH 2002</i>, ACM Press, New York, NY, USA, 473--482.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kruskal, J. B., and Seery, J. B. 1980. Designing network diagrams. In <i>Proceedings 1st General Conference on Social Graphics</i>, 22--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028532</ref_obj_id>
				<ref_obj_pid>1028523</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Loyall, A. B., Reilly, W. S. N., Bates, J., and Weyhrauch, P. 2004. System for authoring highly interactive, personality-rich interactive characters. In <i>Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation</i>, ACM Press, New York, NY, USA, 59--68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[RADICA, 2005. Cube world. http://www.radicauk.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545281</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Sch&#246;dl, A., and Essa, I. A. 2002. Controlled animation of video sprites. In <i>Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation</i>, ACM Press, New York, NY, USA, 121--127.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345012</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sch&#246;dl, A., Szeliski, R., Salesin, D. H., and Essa, I. 2000. Video textures. In <i>Proceedings of ACM SIGGRAPH 2000</i>, ACM Press/Addison-Wesley Publishing Co., New York, NY, USA, 489--498.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073375</ref_obj_id>
				<ref_obj_pid>1073368</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Starck, J., Miller, G., and Hilton, A. 2005. Video-based character animation. In <i>Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation</i>, ACM Press, New York, NY, USA, 49--58.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1109209</ref_obj_id>
				<ref_obj_pid>1109180</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Su, W.-P., Pham, B., and Wardhani, A. 2005. High-level control posture of story characters based on personality and emotion. In <i>IE2005: Proceedings of the second Australasian conference on Interactive entertainment</i>, Creativity & Cognition Studios Press, Sydney, Australia, Australia, 179--186.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545263</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Tomlinson, B., Downie, M., Berlin, M., Gray, J., Lyons, D., Cochran, J., and Blumberg, B. 2002. Leashing the alphawolves: mixing user direction with autonomous emotion in a pack of semi-autonomous virtual characters. In <i>Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation</i>, ACM Press, New York, NY, USA, 7--14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Wang, J., Bhat, P., Colburn, R. A., Agrawala, M., and Cohen, M. F. 2005. Interactive video cutout. In <i>SIGGRAPH '05: ACM SIGGRAPH 2005 Papers</i>, ACM Press, New York, NY, USA, 585--594.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1278306</section_id>
		<sort_key>25</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Emerging technologies: Invited works]]></section_title>
		<section_page_from>25</section_page_from>
	<article_rec>
		<article_id>1278307</article_id>
		<sort_key>25</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Buzz]]></title>
		<subtitle><![CDATA[measuring and visualizing conference crowds]]></subtitle>
		<page_from>25</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278307</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278307</url>
		<abstract>
			<par><![CDATA[<p>This exhibition explores the idea of using technology to understand the movement of people. Not just on a small stage, but in an expansive environment. Not the fine details of movement of individuals, but the gross patterns of a population. Not the identifying biometrics, but patterns of group behavior that evolve from the structure of the environment and the points of interest embedded in that structure. In this instance: a marketplace, and in particular, the marketplace of ideas called SIGGRAPH 2007 Emerging Technologies (ETech).</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[behavior]]></kw>
			<kw><![CDATA[marketing]]></kw>
			<kw><![CDATA[sensor networks]]></kw>
			<kw><![CDATA[visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.1</cat_node>
				<descriptor>Marketing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010488</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Marketing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39088623</person_id>
				<author_profile_id><![CDATA[81100653096]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Wren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P308288</person_id>
				<author_profile_id><![CDATA[81100375009]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuri]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Ivanov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P60017</person_id>
				<author_profile_id><![CDATA[81100491228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Darren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leigh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891402</person_id>
				<author_profile_id><![CDATA[81319504113]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Joanathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Westhues]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Mitsubishi Electric Research Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abowd, G., Bobick, A., Essa, I., Mynatt, E., and Rogers, W. 2002. The aware home: Developing technologies for successful aging. In <i>Proceedings of AAAI Workshop on Automation as a Care Giver</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2094966</ref_obj_id>
				<ref_obj_pid>2094945</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Aipperspach, R., Cohen, E., and Canny, J. 2006. Modeling human behavior from simple sensors in the home. In <i>Proceedings Of The IEEE Conference On Pervasive Computing</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502389</ref_obj_id>
				<ref_obj_pid>502348</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dietz, P. H., and Leigh, D. L. 2001. Diamondtouch: A multiuser touch technology. In <i>Symposium on User Interface Software and Technology (UIST)</i>, ACM, 219--226. also MERL TR2003-125.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>313556</ref_obj_id>
				<ref_obj_pid>313451</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Estrin, D., Govindan, R., Heidemann, J., and Kumar, S. 1999. Next century challenges: scalable coordination in sensor networks. In <i>MobiCom '99: Proceedings of the 5th annual ACM/IEEE international conference on Mobile computing and networking</i>, ACM Press, New York, NY, USA, ACM, 263--270.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>379006</ref_obj_id>
				<ref_obj_pid>378993</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hill, J., Szewczyk, R., Woo, A., Hollar, S., Culler, D. E., and Pister, K. S. J. 2000. System architecture directions for networked sensors. In <i>Architectural Support for Programming Languages and Operating Systems</i>, 93--104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Horton, H. B., 1855. Machine for registering music. US Patent Office 13,946.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ivanov, Y., and Wren, C. 2006. Toward spatial queries for spatial surveillance tasks. In <i>Pervasive: Workshop on Pervasive Technology Applied to Real-World Experiences with RFID and Sensor Networks</i>, vol. EI123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kaur, I. 2007. <i>OpenSpace: Enhancing Social Awareness at the Workplace</i>. Master's thesis, Massachusetts Institute of Technology. in submission.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Miller, S. A. 2000. <i>How to Get the Most Out of Trade Shows</i>. McGraw-Hill Professional.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2094953</ref_obj_id>
				<ref_obj_pid>2094945</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Munguia Tapia, E., Intille, S. S., Lopez, L., and Larson, K. 2006. The design of a portable kit of wireless sensors for naturalistic data collection. In <i>Proceedings of PERVASIVE 2006</i>, Springer-Verlag, Dublin, Ireland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rahimi, A., Dunagan, B., and Darrell, T. 2004. Simultaneous calibration and tracking with a network of non-overlapping sensors. In <i>Computer Vision and Pattern Recognition</i>, IEEE Computer Society, 187--194.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. J., and Wren, C. R. 2006. Worse is better for ambient sensing. In <i>Pervasive: Workshop on Privacy, Trust and Identity Issues for Ambient Intelligence</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2154280</ref_obj_id>
				<ref_obj_pid>2154273</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wilson, D. H., and Atkeson, C. 2005. Simultaneous tracking & activity recognition (star) using many anonymous, binary sensors. In <i>The Third International Conference on Pervasive Computing</i>, 62--79.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278308</article_id>
		<sort_key>26</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Globe4D, time-traveling with an interactive four-dimensional globe]]></title>
		<page_from>26</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278308</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278308</url>
		<abstract>
			<par><![CDATA[<p>Globe4D is an interactive four-dimensional globe. It is a projection of the Earth's surface on a physical sphere. The sphere can be freely rotated along all axes, viewed from any angle and enables the user to control time as its fourth dimension. An application was created that shows the historical movement of the continents, known as continental drift. Besides the Earth, any planet or spherical object can be projected. This paper describes the background, aims, results and progress of this student project.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[continental drift]]></kw>
			<kw><![CDATA[direct manipulation device]]></kw>
			<kw><![CDATA[earth]]></kw>
			<kw><![CDATA[globe projection]]></kw>
			<kw><![CDATA[physical interaction]]></kw>
			<kw><![CDATA[spherical display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Image display</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P824145</person_id>
				<author_profile_id><![CDATA[81320489014]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Companje]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Leiden University, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35034694</person_id>
				<author_profile_id><![CDATA[81536946256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nico]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[van Dijk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Leiden University, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP35049889</person_id>
				<author_profile_id><![CDATA[81335491433]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hanco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hogenbirk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Leiden University, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891393</person_id>
				<author_profile_id><![CDATA[81320492283]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dani&#263;a]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mast]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Leiden University, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P Bourke, "Using a Spherical Mirror Projection into Immersive Environment", Graphite, ACM Siggraph, Dunedin, Nov/Dec 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Y. Chen, J. Au, P. Kazlas, A. Ritenour, H. Gates, M. McCreary, "Flexible active-matrix electronic ink display" Nature, Volume 423, Page 136, May 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Richard J. Lisle, "Google Earth: a new geological resource", Geology Today, Volume 22, Page 29, January 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1038818</ref_obj_id>
				<ref_obj_pid>1038262</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Eben Myers, Peter Coppin, Michael Wagner, Karl Fischer, Luisa Lu, W. Ronald McCloskey, David Seneker, "EventScope: Bringing Remote Experience of Mars to the Public through Telepresence", Infovis, Page 16, IEEE Symposium on Information Visualization (INFOVIS'04), 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Kettner, C. Madden, R. Ziegler, "Direct Rotational Interaction With a Spherical Projection", Interaction: System, Practice and Theory, ACM SIGCHI 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Peter Freudling, Roland Haring, Helmut H&#246;ller, Horst H&#246;rtner, Andreas Jalsovec, Hirokazu Kato, Christopher Lindinger, Dietmar Offenhuber, "Gulliver's World", Ars Electronica Linz, 2004 http://www.aec.at/en/center/project.asp?iProjectID=12771]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1278309</article_id>
		<sort_key>27</sort_key>
		<display_label></display_label>
		<article_publication_date>08-05-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Optical sensors embedded within AMLCD panel]]></title>
		<subtitle><![CDATA[design and applications]]></subtitle>
		<page_from>27</page_from>
		<page_to>es</page_to>
		<doi_number>10.1145/1278280.1278309</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1278309</url>
		<abstract>
			<par><![CDATA[<p>A new approach to data input into AMLCD panels has been conceived and demonstrated. This integrates an array of TFT optical sensors into the a-Si backplane of the AMLCD. The concept, design considerations, and specific applications such as touch panel input, hand recognition, and image capture will be discussed.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P891370</person_id>
				<author_profile_id><![CDATA[81335487504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Adi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abileah]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Planar Systems, Beaverton, OR]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P891381</person_id>
				<author_profile_id><![CDATA[81539441656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Green]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Planar Systems, Beaverton, OR]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W. den Boer et al. "Active Matrix LCD with Integrated Optical Touch Screen"; SID'03 (Baltimore) pg.1494--1497.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. G. J. Barten, "Contrast Sensitivity of the Human Eye", SPIE Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Abileah et al. "Integrated optical Touch Panel in a 14.1" AMLCD"; SID'04 (Seattle) pg.1544--1547.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Abileah et al. "Optical Sensors Embedded within AMLCD panel: Design and Applications"; ADEAC'06, SID (Atlanta) pg. 102--105]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. J. Hong et al. "Smart LCD using a-Si photo sensor"; IMID'05 Digest pg. 280--283]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Brown et al, "A 2.6 inch VGA LCD with Optical Input Function using a 1-Transistor Active-Pixel Sensor"; ISSCC 2007 (&7.2) pg.132--133]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Booth demo of several Toshiba Matsushita image capture AMLCDs based on poly-silicon technology; SID 2004--2006 exhibitions. No papers presented.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. J. Tulbert, "Low Cost, Display-Based, Photonic Touch Interface with Advanced Functionality"; SID 05 Digest (Boston) pg. 1222--1225]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
</content>
</proceeding>

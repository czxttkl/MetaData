<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>08/03/2009</start_date>
		<end_date>08/07/2009</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[New Orleans]]></city>
		<state>Louisiana</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES382</series_id>
		<series_title><![CDATA[International Conference on Computer Graphics and Interactive Techniques]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1667265</proc_id>
	<acronym>SIGGRAPH '09</acronym>
	<proc_desc>ACM SIGGRAPH 2009 Art Gallery</proc_desc>
	<conference_number>2009</conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2009</copyright_year>
	<publication_date>08-03-2009</publication_date>
	<pages>137</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[<p>SIGGRAPH 2009, in collaboration with Leonardo/ISAST, honors not only artists and artwork, but also the process of making art and its place in society. We are presenting papers that illuminate and explore these topics, helping people understand the changing roles of artists and art-making in our increasingly computerized, networked, multi-sensory, online world.</p> <p>Art Papers present excellent ideas in accessible ways. They inform artistic disciplines, set standards, and stimulate future trends. In addition to the core topics of the digital arts and interactive techniques, Art Papers explore the theme of SIGGRAPH 2009's juried art gallery, BioLogic Art.</p>]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>P1797179</person_id>
			<author_profile_id><![CDATA[81100508902]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Jacquelyn]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Martino]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[IBM Research]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
	<ccc>
		<copyright_holder>
			<copyright_holder_name>ACM</copyright_holder_name>
			<copyright_holder_year>2009</copyright_holder_year>
		</copyright_holder>
	</ccc>
</proceeding_rec>
<content>
	<section>
		<section_id>1667266</section_id>
		<sort_key>10</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Art papers]]></section_title>
		<section_page_from>1</section_page_from>
	<article_rec>
		<article_id>1667267</article_id>
		<sort_key>20</sort_key>
		<display_label>Article No.</display_label>
		<display_no>1</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Wearable forest clothing system]]></title>
		<subtitle><![CDATA[beyond human-computer interaction]]></subtitle>
		<page_from>1</page_from>
		<page_to>7</page_to>
		<doi_number>10.1145/1667265.1667267</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667267</url>
		<abstract>
			<par><![CDATA[<p><i>Wearable Forest</i> is a garment that bioacoustically interacts with distant wildlife in a remote forest through a networked remote-controlled speaker and microphone. it expresses the unique bioacoustic beauty of nature and allows users to interact with a forest in real time through a network to acoustically experience a distant forest soundscape, thus merging humans and nature without great environmental impact. This novel interactive sound system can create a sense of unity between users and a remote soundscape, enabling users to feel a sense of belonging to nature even in the midst of a city. This paper describes the theory of interaction between the Human and the Biosphere through the design process of the Wearable Forest concept.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>C.3</cat_node>
				<descriptor>Signal processing systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.3</cat_node>
				<descriptor>Real-time and embedded systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797180</person_id>
				<author_profile_id><![CDATA[81384598619]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hiroki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kobayashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo, Bunkyo-ku, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797181</person_id>
				<author_profile_id><![CDATA[81365595636]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ryoko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ueoka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo, Meguro-ku, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797182</person_id>
				<author_profile_id><![CDATA[81100257385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michitaka]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirose]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Tokyo, Bunkyo-ku, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Ueoka and H. Kobayashi, <i>SIGGRAPH 2008 Electronic Art&amp;Animation Catalog</i> (New York: ACM Press, 2008) 103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1459600</ref_obj_id>
				<ref_obj_pid>1459359</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Kobayashi, R. Ueoka, and M. Hirose, "Wearable forest: feeling of belonging to nature," <i>Proc. of International Conference on Multimedia</i>, 1133--1134 (Oct--Nov 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1520355</ref_obj_id>
				<ref_obj_pid>1520340</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Kobayashi, R. Ueoka, and M. Hirose, "Human Computer Biosphere Interaction: Towards a Sustainable Society," <i>Extended Abstracts on Human Factors in Computing Systems</i>, SIGCHI (April 2009).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Murayama, et al., Tsushima Leopard Cat Conservation Planning Workshop, Mitsushima Community Center (Tsushima City, Nagasaki, Japan, 2006) 6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Suzuki, <i>Zen and Japanese Culture</i> (New York: Pantheon Books, 1959).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Live Sound from Iriomote Island, SoundBum: http://www.soundbum.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[The Stethoscope for the Earth's water, Aquascape: http://aqua-scape.jp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Kobayashi, et al., "Development of a networked remote sensing embedded system for bio-acoustical evaluation," <i>J. Acoust. Soc. Am.</i>, Vol. 120, No. 5, 3324--3325 (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Definition of Human Computer Interaction, ACM SIGCHI: http://sigchi.org/cdg/cdg2.html#2_1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1149823</ref_obj_id>
				<ref_obj_pid>1149818</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. P. Lee, et al., "A mobile pet wearable computer and mixed reality system for human-poultry interaction through the internet," <i>Personal and Ubiquitous Computing</i>, Vol. 10, No. 5, 301--317 (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>506609</ref_obj_id>
				<ref_obj_pid>506443</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Y. Itoh, et al., "TSUNAGARI communication: fostering a feeling of connection between family members," <i>Proc. on Human Factors in Computing Systems</i>, SIGCHI, 810--811 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1012666</ref_obj_id>
				<ref_obj_pid>1012647</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Lisa Stead, et al., "The Emotional Wardrobe," <i>Personal and Ubiquitous Computing</i>, Vol 8, No. 3--4, 282--290 (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1386567</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Seymour, <i>Fashionable Technology, The Intersection of Design, Fashion, and Technology</i> (Wien, Austria: SpringerWienNewYork, 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Ueoka and M. Hirose, "SoundTag: children's interactive play based upon RFID employed wearable computer," <i>Digital Creativity</i>, Vol. 19, No. 3, 162--173 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[K. Hartman, et al., Botanicalls: The Plants Have Your Number: http://www.botanicalls.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>559497</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[K. Goldberg, <i>The Robot in the Garden: Telerobotics and Telepistemology in the Age of the Internet</i> (Cambridge, Massachusetts: MIT Press, 2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Begon, J. L. Harger, and C. R. Townsend, <i>Ecology: Individuals, populations and communities</i>, 3rd ed., (Oxford, England: Blackwell Science, 1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. E. Ricklefs and D. Schluter, <i>Species diversity in ecological communities, historical and geographical perspectives</i> (Chicago, Illinois: The University of Chicago Press, 1993).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. P. Reagan and R. B. Waide, <i>The food web of a tropical rain forest</i> (Chicago, Illinois: University of Chicago Press, 1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[W. A. Searcy and S. Nowicki, <i>The evolution of animal communication: reliability and deception in signaling systems</i> (Princeton, New Jersey: Princeton University Press, 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[B. Krause, "Bioacoustics, Habitat Ambience in Ecological Balance," <i>Whole Earth Review</i>, Vol. 57, Winter (1987).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Muuss, Packet Internet Grouper: http://ftp.arl.mil/~mike/ping.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[H. Kobayashi, et al., "Wearable Forest---HCBI clothing embrace our bodies with the sense of unity with nature by trolling a tune with remote soundscape," <i>Journal of the Soundscape Association of Japan</i> (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[M. Kass, et al., "Snakes: active contour models," <i>International Journal of Computer Vision</i>, Vol. 2, No. 4, 321--331 (1988).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[M. J. Lowis, "Music as a trigger for peak experiences among a college staff population," <i>Creativity Research Journal</i>, Vol. 14, No. 3--4, 351--359 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[M. Gurevich, C. Chafe, G. Leslie, and S. Tyan, "Effect of Time Delay on Ensemble Accuracy," <i>Proc. of Intl. Soc. Musical Acoustics</i>, Nara (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[K. Williams and D. Harvey, "Transcendent Experience in Forest Environments," <i>Journal of Environmental Psychology</i>, 258 (2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Wearable Forest Clothing System: Beyond Human-Computer Interaction Hiroki Kobayashi, Ryoko Ueoka, Michitaka 
Hirose Abstract Wearable Forest is a garment that bioacoustically interacts with distant wildlife in 
a remote forest through a networked remote-controlled speaker and microphone. It expresses the unique 
bioacoustic beauty of nature and allows users to interact with a forest in real time through a network 
to acoustically experience a distant forest soundscape, thus merging humans and nature without great 
environmental impact. This novel interactive sound system can create a sense of unity between users and 
a remote soundscape, enabling users to feel a sense of belonging to nature even in the midst of a city. 
This paper describes the theory of interaction between the Human and the Biosphere through the design 
process of the Wearable Forest concept. Introduction: Contradictive Link Between Human Beings and Nature 
Wearable Forest, shown in Figure 1, is a clothing system that bioacoustically interacts with distant 
wildlife in a remote forest through a networked remote-controlled speaker and microphone as shown in 
Figure 2 [1, 2]. It is based on the concept of human-computer biosphere interaction (HCBI) [3], described 
in Figure 3. It aims to express the unique bioacoustic beauty of nature and allow users to interact with 
a forest in real time through a network and acoustically experience a distant forest soundscape, thus 
merging human beings and nature without great environmental impact. Our relationship with nature is constantly 
evolving to maintain human civilization. And yet, nature is being destroyed in the process of urbanization. 
The environmental movement, which promotes conservation areas for preservation purposes, has ironically 
increased the demand for tourism in these areas and thus accelerated the speed of environmental destruction 
[4]. Nevertheless, a sense of connection with nature is indispensable for emotional balance. Japanese 
Zen Buddhism, for example, encourages deep meditation in order to achieve a sense of being at one with 
nature [5]. The sounds of birdsong, buzzing insects, gently swaying leaves, and the trickling of water 
in a forest can imprint the beauty of nature in our memory. In previous studies, the authors developed 
a networked bioacoustic streaming and record­ing system by which environmental sounds in a sub-tropical 
forest on Iriomote Island, Japan, moving water in a pond in Tokyo, aqua-music instruments in a Japanese 
garden in Kyoto, and a street in Mumbai, India are continuously streamed in real time by networked microphones 
[6, 7]. The authors also developed a human-wildlife bioacoustic interaction system for efficient remote 
monitoring of wildlife that introduces the concept of HCBI [8]. This system, Wearable Forest, presents 
the possibility of a new relation­ship: non-verbal interaction with nature in daily life through the 
telepresence of different species. HCBI Concept Overview Wearable Forest is based on the concept of HCBI, 
described in Figure 3, presented as an extension of human-computer interaction (HCI) [9] and human-computer-pet 
interaction (HCPI) [10]. The field of computer-supported cooperative work (CSCW) is based on such computer-interac­tion 
paradigms to support specific activities. For instance, we exchange our ideas, thoughts, theories, and 
messages by encoding them into transferable words, communicating them through computer systems, and decoding 
them. However, in our daily lives, we implicitly exchange and share a great deal of additional non-verbal 
information, such as the presence and mood of others, to maintain our social relationships [11]. The 
consideration of implicit (background) information opens up new possibilities for interaction through 
non-linguistic, wearable forms and non-verbal, remote communication among different species. Wearable 
computing enables us to express ourselves through fashion in order to develop human-to-human communication 
[12, 13, 14]. HCPI, as described in Figure 3, is a novel type of physical interaction paradigm that proposes 
to create symbiosis between humans and pets through a computer and the internet as a new form of media. 
Botanicalls was developed to provide a new way for plants and people to interact in order to develop 
better, longer-last­ing relationships that go beyond physical and genetic distance [15]. Thus, computer 
systems become a medium to express telepresence among different species in the biosphere through their 
non-linguistic expression as perceived and understood by individuals, violating the rules of linguistic 
science [16]. However, no matter how advanced the technologies are, these are human-centric interactions. 
We expect some perceivable feedback from others in response to our command before we end an interaction. 
On the contrary, in our daily lives, there are many non-human-centric interactions. The sounds of singing 
birds, buzzing insects, swaying leaves, and trickling water in a beautiful forest implicitly imprint 
the beauty of nature in our minds. When we are emotionally stressed, recalling the beauty of nature can 
help us recover a sense of well-being. The crucial factor here is not the means of conveyance (words 
or language), but something hovering around, or an atmosphere that we cannot exactly identify. This interaction 
follows the teaching of Zen Buddhism, the Japanese love of nature. Zen is one of the products of the 
Chinese people, which was introduced into China in the first century AD after their contact with Indian 
teachings of Buddhism. The authors propose HCBI, the concept of human-computer biosphere interaction, 
to extend the field of interaction from countable objects, pets, and plants to their auditory environment, 
which is an uncountable, complex, non-linguistic soundscape, something surrounding, much like Zen elements. 
In the HCBI vision, the sounds in a forest, or other natural environments, are integral to helping us 
feel one with nature. Thus, with HCBI, we listen to and feel the telepresence of the global ecological 
system, integrating all living beings and their relationships, including their interaction with the elements 
of the biosphere. With HCBI, we begin to interact with subjects beyond physical and inter-species barriers. 
Interaction Design: From a Law of Acoustic Ecology Natural communities contain a spectrum of life forms 
that interact with one another [17]. Many scientists agree with the statement that the essence of ecology 
is the study of interactions among species in their native habitats [18]. In particular, animal communities 
in tropical forests have extremely complex interactions involving vast numbers of species [19]. The natural 
sounds in a rainforest convincingly demonstrate the special relationships among the many insects, birds, 
mammals, and amphibians [20]. Several field recordings prove that when one creature stops vocalizing, 
another immediately joins the chorus [21]. Therefore, the animals interact bioacousti­cally with other 
animals according to the biological diversity of their habitat. We used bioacoustic information to develop 
the concept of human-computer biosphere interaction. To establish non-verbal interaction between different 
species, an HCBI interface artificially creates a virtual acoustical field to acquire feedback from remote 
wildlife. It is modeled on three kinds of natural interaction: interspecies predator-prey relationships, 
intraspecies communica­tion, and mixed-reality intraspecies communication. First, a predator hunts prey 
in its native habitat as shown at the top of Figure 4. Bioacoustic information is one of the signals 
employed by predators to detect the existence of prey in the surrounding area. A scarcity of prey in 
the habitat indicates the absence of predators. Secondly, intraspecies communication is considered to 
be a chorus produced by a group of the same species in Figure 4 (middle), rather like the Packet Internet 
Grouper (PING) command of the Internet Control Message Protocol between two computers [22]. A single 
individual, the caller, starts calling other individuals to confirm their presence. The other members 
of the species then randomly respond to the call and report their existence to the caller. Third, a species 
can conduct intraspecific communication in mixed reality. The bottom of Figure 4 shows a user playing 
back a pre-recorded sound of an initial call from an acoustic speaker; the speaker is placed in the natural 
environment and controlled by a remote-controlled PC over the internet. The real frogs answer the initial 
call and report their existence. The initial call (the virtual call played by the speaker) can deceive 
the real frogs into believing that it was made by a real frog in the vicinity. This human-biosphere interaction 
through computer systems can breach the physical and inter-species barriers. Wearable Forest System: 
Description and Discussion Wearable Forest consists of a local audio-visual interactive clothing system 
as shown in Figure 1 and an audio I/O system placed in a remote forest as shown in Figure 2. The remote 
and local systems perform remote interaction with non-human creatures. The remote system, consisting 
of weather-resistant microphones and speakers, is placed in an uninhabited subtropical forest on Iriomote 
Island in Japan (24°20 N, 123°55 E). The songs of small birds, the trickling of a stream, and the sounds 
of insects moving about in the forest represent the diversity of organisms on the island. The audio I/O 
system continuously captures and transfers the live soundscape to a local system over the internet. The 
local clothing system consists of two paper-thin speakers embroidered on the fronts of both shoulders, 
a matrix array of 256 white-colored light-emitting diodes (LEDs) sewn with conductive thread, and sleeve-shaped 
textile sensors woven with thin wires. An embedded CPU system receives the live soundscape data from 
the remote forest wirelessly, immediately quantizes the bioacoustic activity of wildlife from the data, 
and visualizes the result as a luminescent pattern through the LED array. To visualize and illuminate 
the bioacoustic activity contained in the remote forest soundscape as clothing fashion in real time, 
we proposed a bio-activity index (BAI) to convert this activity into numerical data using the internet 
[23]. BAI uses active contour models to quantify the bioacous­tic activity of the calculated area into 
the shape of the visualized bioacoustic patterns of the live soundscape data [24]. Higher levels of bioacoustic 
activity are conveyed as larger LED patterns. To interact with wildlife, users can touch the textile 
sensors, which transfer the user-selected, pre-recorded sounds of wildlife from the garment to the speakers 
in the forest on the remote island. This bioacoustic loop, which transfers live sounds bi-directionally 
from the remote and local sites, gives the user the opportunity to interact with wildlife. For example, 
in a relatively quiet period after a brief rain shower in the subtropical forest, the users at their 
urban location can play back the croaking of frogs through the remote speaker; in response, actual frogs 
might start croaking. If an appropriate sound is played back at an appropriate time, the actual wildlife 
might respond to the initial call. In this chorus-like experience, intraspecies communication in mixed 
reality between the user and the frogs could then possibly give the users a sense of belonging to nature 
in an experience similar to the peak experience in music therapy, which is triggered by choral singing 
[25]. First, the user can send an initial pre-recorded animal call to the remote host through the local 
host as shown in Figure 5. The pre-recorded calls of the Elegant Scopes Owl (Otus Elegans) and the Ruddy 
Kingfisher (Halcyon coromanda) are used to initiate the interaction with wildlife in the forest. Both 
species actually live in the forest. The Elegant Scopes Owl is nocturnal. The remote host receives the 
call, plays back the call from the speaker in the forest, and performs a loopback operation. If the wildlife 
is present in the forest, it listens to the call. The loopback call at the remote host occurs because 
the playback sound from the speaker is captured and trans­ferred to the user by the remote host. When 
the users receive the loopback call from the forest, they recognize that the initial call did actually 
travel through the forest environment. The users wait for sounds that indicate that the wildlife is actually 
responding. The system was exhibited and evaluated over five days during SIGGRAPH 2008 in Los Angeles, 
USA, and over six days during ACM Multimedia 2008 and Science World British Colombia in Vancouver, Canada. 
During the first exhibition, the out of synchronization problem was confirmed [26]. Visitors were unable 
to identify a specific sound from other sounds on the audio live feed from the remote forest. This resulted 
in users inability to recognize the potential auditory response from the wildlife, even if the response 
had occurred to the user in the distant forest. Therefore, even if no response is transferred from the 
wildlife after the loopback call of the initial call, other acoustical activities in the forest can be 
perceived as believable responses, such as the sounds of birdsong, buzzing insects, gently swaying leaves, 
and a tree falling. Those sounds indicate the non-linguistic telepresence of entities in the forest. 
From a psychological aspect, participants who experienced Wearable Forest in the ACM Multimedia 2008 
art exhibi­tion described a sense of oneness with the remote forest. They rated the episode on a number 
of scales indicating characteristics of transcendence [27], such as sense of union and timelessness. 
The result indicates that the Wearable Forest HCBI interface is able to create a sense of oneness between 
human beings and wildlife beyond physical and genetic distance. Conclusions The HCBI paradigm defines 
a new conceptual approach to establishing communication between humans and natural environments through 
the use of computer-based media in order to create a sense of unity. We believe that the fundamental 
work outlined through the Wearable Forest project will create new possibilities for relationships among 
humans, computers, and the biosphere. Acknowledgement We appreciate the kindness of many friends who 
contributed to our research: Dr. Abe, Mr. Takagi, Mr. Kawasaki, Mr. Nishimura, Mrs. Nishimura, Mr. Murata, 
and Ms. Fujita. The photograph of the clothing in Figure 1 was taken by Masaharu Hatta. The textile sensor 
is provided by Fukui Research Center for Industry and Technology. This research is partially supported 
by SoundExplorer participants, Sound Bum participants, NTT-WEST, Inc. Okinawa Branch, IMS.JP Co., Ltd, 
ACM SIGGRAPH 2008 participants, and ACM Multimedia 2008 participants. References 1. R. Ueoka and H. Kobayashi, 
SIGGRAPH 2008 Electronic Art &#38; Animation Catalog (New York: ACM Press, 2008) 103. 2. H. Kobayashi, 
R. Ueoka, and M. Hirose, Wearable forest: feeling of belonging to nature, Proc. of International Conference 
on Multimedia, 1133-1134 (Oct-Nov 2008). 3. H. Kobayashi, R. Ueoka, and M. Hirose, Human Computer Biosphere 
Interaction: Towards a Sustainable Society, Extended Abstracts on Human Factors in Computing Systems, 
SIGCHI (April 2009). 4. A. Murayama, et al., Tsushima Leopard Cat Conservation Planning Workshop, Mitsushima 
Community Center (Tsushima City, Nagasaki, Japan, 2006) 6. 5. D. Suzuki, Zen and Japanese Culture (New 
York: Pantheon Books, 1959). 6. Live Sound from Iriomote Island, SoundBum: http://www.soundbum.org/. 
7. The Stethoscope for the Earth s water, Aquascape: http://aqua-scape.jp. 8. H. Kobayashi, et al., Development 
of a networked remote sensing embedded system for bio-acoustical evaluation, J. Acoust. Soc. Am., Vol. 
120, No. 5, 3324-3325 (2006). 9. Definition of Human Computer Interaction, ACM SIGCHI: http://sigchi.org/cdg/cdg2.html#2_1. 
10. S. P. Lee, et al., A mobile pet wearable computer and mixed reality system for human-poultry interaction 
through the internet, Personal and Ubiquitous Computing, Vol. 10, No. 5, 301-317 (2006). 11. Y. Itoh, 
et al., TSUNAGARI communication: fostering a feeling of connection between family members, Proc. on Human 
Factors in Computing Systems, SIGCHI, 810-811 (2002). 12. Lisa Stead, et al., The Emotional Wardrobe, 
Personal and Ubiquitous Computing, Vol 8, No. 3-4, 282-290 (2004). 13. S. Seymour, Fashionable Technology, 
The Intersection of Design, Fashion, and Technology (Wien, Austria: SpringerWienNewYork, 2008). 14. R. 
Ueoka and M. Hirose, SoundTag: children s interactive play based upon RFID employed wearable computer, 
Digital Creativity, Vol. 19, No. 3, 162-173 (2008). 15. K. Hartman, et al., Botanicalls: The Plants Have 
Your Number: http://www.botanicalls.com. 16. K. Goldberg, The Robot in the Garden: Telerobotics and Telepistemology 
in the Age of the Internet (Cambridge, Massachusetts: MIT Press, 2000). 17. M. Begon, J.L. Harger, and 
C.R. Townsend, Ecology: Individuals, populations and communities, 3rd ed., (Oxford, England: Blackwell 
Science, 1996). 18. R.E. Ricklefs and D. Schluter, Species diversity in ecological communities, historical 
and geographical perspectives (Chicago, Illinois: The University of Chicago Press, 1993). 19. D.P. Reagan 
and R.B. Waide, The food web of a tropical rain forest (Chicago, Illinois: University of Chicago Press, 
1996). 20. W.A. Searcy and S. Nowicki, The evolution of animal communication: reliability and deception 
in signaling systems (Princeton, New Jersey: Princeton University Press, 2005). 21. B. Krause, Bioacoustics, 
Habitat Ambience in Ecological Balance, Whole Earth Review, Vol. 57, Winter (1987). 22. M. Muuss, Packet 
Internet Grouper: http://ftp.arl.mil/~mike/ping.html. 23. H. Kobayashi, et al., Wearable Forest HCBI 
clothing embrace our bodies with the sense of unity with nature by trolling a tune with remote soundscape, 
Journal of the Soundscape Association of Japan (2008). 24. M. Kass, et al., Snakes: active contour models, 
International Journal of Computer Vision, Vol. 2, No. 4, 321-331 (1988). 25. M. J. Lowis, Music as a 
trigger for peak experiences among a college staff population, Creativity Research Journal, Vol. 14, 
No. 3-4, 351-359 (2002). 26. M. Gurevich, C. Chafe, G. Leslie, and S. Tyan, Effect of Time Delay on Ensemble 
Accuracy, Proc. of Intl. Soc. Musical Acoustics, Nara (2004). 27. K. Williams and D. Harvey, Transcendent 
Experience in Forest Environments, Journal of Environmental Psychology, 258 (2001). Hiroki Kobayashi 
Research Fellow Japan Society for the Promotion of Science PhD candidate Cyber Interface Laboratory The 
University of Tokyo 8F Room 83C2, Engineering Building 2 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656 Japan 
hill_koba@cyber.t.u-tokyo.ac.jp Ryoko Ueoka Researcher Research Center for Advanced Science and Technology 
The University of Tokyo 4-6-1 Komaba, Meguro-ku, Tokyo 153-8904 Japan yogurt@cyber.t.u-tokyo.ac.jp Michitaka 
Hirose Educator Cyber Interface Laboratory The University of Tokyo 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656 
Japan hirose@cyber.t.u-tokyo.ac.jp  Figure 1. Wearable Forest Local System for Human-Computer-Biosphere 
Interaction. Non-verbal communication beyond the physical and inter-species barriers. &#38;#169; 2008 
Hiroki Kobayashi, Ryoko Ueoka, Michitaka Hirose. Photo Masaharu Hatta. &#38;#169; 2009 Hiroki Kobayashi, 
Ryoko Ueoka, Michitaka Hirose |  Leonardo, Vol. 42, No. 4, pp. 300 306, 2009  Figure 2. Wearable Forest 
Remote System for Human- Computer-Biosphere Interaction. Networked audio I/O system placed in an uninhabited 
subtropical forest on Iriomote Island, Japan (24°20 N, 123°55 E). &#38;#169; 2008 Hiroki Kobayashi. 
Wearable Forest Clothing System  |  Hiroki Kobayashi , et al.  Figure 3. Human-computer-biosphere 
interaction (HCBI) concept, an extension of HCI and HCPI. &#38;#169; 2008 Hiroki Kobayashi, Ryoko Ueoka. 
 Hiroki Kobayashi, et al.  |  Wearable Forest Clothing System  Figure 4. Interspecies predator-prey 
relationship (top), intraspecies communication (middle), and intraspecies communication in a mixed reality 
(bottom). &#38;#169; 2008 Hiroki Kobayashi. Wearable Forest Clothing System  |  Hiroki Kobayashi, 
et al.  Figure 5: Diagram of non-verbal interaction between user and wildlife. &#38;#169; 2008 Hiroki 
Kobayashi, Ryoko Ueoka. Hiroki Kobayashi, et al.  |  Wearable Forest Clothing System Wearable Forest 
Clothing System  |  Hiroki Kobayashi, et al. Hiroki Kobayashi, et al.  |  Wearable Forest Clothing 
System  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667268</article_id>
		<sort_key>30</sort_key>
		<display_label>Article No.</display_label>
		<display_no>2</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Re-visioning the interface]]></title>
		<subtitle><![CDATA[technological fashion as critical media]]></subtitle>
		<page_from>1</page_from>
		<page_to>7</page_to>
		<doi_number>10.1145/1667265.1667268</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667268</url>
		<abstract>
			<par><![CDATA[<p>This paper elucidates two positions (the positivist and the critical) that inform the creative design of technological fashion. On the one side is the instrumentalist trend toward the minimized or disappearing interface. On the other, some theorists and artists suggest that increased invisibility presents social and ethical concerns (such as invasiveness and control) when networking and communication devices are involved.</p> <p>The positivist side has roots in modernist design. Positivist designers create responsive and controllable fabrics using shape-changing polymers, e-textiles, and nano-scale electronics to resolve clumsy and prohibitive problems of hardware vs. body. The critical side draws upon archetypal ideas about technology and the body that are familiar from literature and science fiction, and includes writers and media artists who emphasize the intractable or mechanic nature of technological clothing to enhance, rather than erase, the body. The paper concludes that both positions must be considered as the field of technological fashion moves forward.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797183</person_id>
				<author_profile_id><![CDATA[81458647557]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Susan]]></first_name>
				<middle_name><![CDATA[Elizabeth]]></middle_name>
				<last_name><![CDATA[Ryan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Louisiana State University, Baton Rouge, Louisiana]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[William Gibson, <i>Neuromancer</i> (New York: Ace Books, 2000) 66--67, original publication 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[http://www.design.philips.com/probes/projects/dresses/index.page, and http://news.softpedia.com/news/Flammable-Ego-Philips-lights-Up-Your-Inner-Self-74355.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[http://www.primidi.com/2008/10/15.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[http://www.news.cornell.edu/stories/May07/nanofibers.fashion.aj.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Smart Second Skin Dress: http://www.smartsecondskin.com/main/scentsorydesign.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gilles Lipovetsky, <i>The Empire of Fashion: Dressing Modern Democracy</i>, trans. Catherine Porter (Princeton, New Jersey: Princeton University Press, 1994) 264.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1146301</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bernadette Wegenstein, <i>Getting Under the Skin: The Body and Media Theory</i> (Cambridge, Massachusetts: MIT Press, 2006) 12--13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lipovetsky, <i>The Empire of Fashion</i>, 131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Berzowska, "Electronic Textiles: Wearable Computers, Reactive Fashion, and Soft Computation," <i>Textile</i>, Vol. 3, No. 1, 16 (2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Susan Elizabeth Ryan, "A Virtual Interview With Geert Lovink," <i>Intelligent Agent</i>, Vol. 8, No. 1 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gilles Deleuze, "Postscript on Societies of Control" (October 1988), reprinted in <i>The Cybercities Reader</i>, ed. Stephen Graham (London: Routledge, 2004) 73--77.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Peter Galloway, <i>The Exploit</i> (Minneapolis, Minnesota: University of Minnesota Press, 2007) 78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Andra&#382; Petrov&#269;i&#269;, "Reconfiguring Socialities: The Personal Networks of ICT Users and Social Cohesion," <i>tripleC</i>, Vol. 6, No. 2, 163 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Re-Visioning the Interface: Technological Fashion as Critical Media Susan Elizabeth Ryan Abstract This 
paper elucidates two positions (the positivist and the critical) that inform the creative design of technological 
fashion. On the one side is the instrumentalist trend toward the minimized or disappear­ing interface. 
On the other, some theorists and artists suggest that increased invisibility presents social and ethical 
concerns (such as invasiveness and control) when networking and communication devices are involved. The 
positivist side has roots in modernist design. Positivist designers create responsive and control­lable 
fabrics using shape-changing polymers, e-textiles, and nano-scale electronics to resolve clumsy and prohibitive 
problems of hardware vs. body. The critical side draws upon archetypal ideas about technology and the 
body that are familiar from literature and science fiction, and includes writers and media artists who 
emphasize the intractable or mechanic nature of technological clothing to enhance, rather than erase, 
the body. The paper concludes that both positions must be considered as the field of technological fashion 
moves forward. Designers of material computing promote the minimized or disappearing interface in techno­logical 
fashion applications. At the same time, some media critics and theorists suggest that increased invisibility 
presents social and ethical concerns, especially when networking and communication devices are involved. 
This paper will elucidate these positions, which I call the positivist and the critical, and suggest 
some of the issues at stake in this debate. Furthermore, it will compare the interpreta­tion of wearable 
technology garments as, on the one hand, a process of invisibility based on an ideal of pure functionality, 
and, on the other, a process of technologically elaborating an age-old creative dialogue between society 
and the body. The positivist position on wearable computing is historically anti-fashion and anti-dress, 
and essentially modernist in its cultural viewpoint, in accordance with traditional science. The idea 
that clothing must be minimized, standardized, and muted amounts to a classic tendency known among fashion 
historians as anti-fashion. Anti-fashion maintains there is a neutral or natural way to dress, or that 
it is most natural to dispense with dress alto­gether. Not fabric but skin is the mantra. When conjoined 
with technology, positivist wearable systems ignore clothes cultural connotations and seek a pure functionality 
that harks back to early 20th-century modern­ist prototypes in cinema and art, such as utopianist avant 
gardes like Russian construc­tivism (Vladimir Tatlin s Worker s Clothing, Figure 1). A perfect recent 
expression of this purism is Susumu Tachi s Invisibility Cloak. Designed for medical and military applications, 
it is more like a cloaking device, which echoes not only episodes of Star Trek, but ultimately a similar 
idea in Gibson s 1984 Neuromancer (Figure 2): the garment that appears to erase the body altogether [1]. 
Gibson s mimetic polycarbon suit achieves an even older mythological essence, that of the invisible man, 
popularized in H.G. Wells 1897 novella of that name, in which the protagonist, a scientist named Griffin, 
theorizes and carries out a procedure that changes his body s refractive index to that of the ambient 
air so that his body cannot reflect light. Anti-fashion, along these lines, I would argue, is another 
masculinist myth about the visual body. We note that the other Invisible Man, the 1952 American novel 
by Ralph Ellison, provides us with the critique of Wells story: invisibility as a function not of optics 
but of social dynamics and cultural conditioning. Ellison s book is rich with allusion and metaphor, 
revealing the dynamics of the visible, and his novel, more than Wells , is suggestive of the critical 
position of wearable technology art, to which I will return. In the fast-paced field of mobile technologies, 
responsive and computationally controllable fabrics including shape-changing polymers, e-textiles, and 
nano-scale electronics resolve awkward, clumsy, and prohibitive problems of hardware vs. body. New-media 
wearables researchers like Christa Sommerer, Maggie Orth, and Joey Berzowska, among others, and corporations 
like Philips Electronics, are rapidly advancing the reach of smart-fabrics concepts. They are developing 
conformable and stretchable sensing and networking surfaces. For example, Philips SKIN project was first 
reported on in December 2007. According to Philips, these dresses show emotive technology and how the 
body and the near environment can use pattern and colour change to interact and predict the emotional 
state. Each emotion, such as stress, fear, or arousal, will affect the body s temperature and consequently 
the sweat levels that generate light, which changes the pattern and color of a gown [2]. In this view, 
a modernist and techno-futurist one, the realm of human emotions is equally measurable and manipulable, 
even predictable, and can be configured for an expanding array of communication products. As of October 
2008, smart fabrics and interactive textiles, or SFIT, is a multi-million dollar industry growing at 
an annual rate of around 25 per cent [3]. Much research is being prompted by strides in nanotechnology. 
Last year at Cornell University, design student Olivia Ong collaborated with fiber scientist Juan Hinestroza 
on a Glitterati line of fashion made of cotton bonded to silver and palladium nanoparticle solutions. 
The results were antibacterial couture cocoons (Figure 3) that keep wearers free of allergens and pollutants 
in the air [4]. But like antibacterial soaps, caution is required, as these garments might retard our 
own immune systems capabilities. Scentsory Design s 2003-2005 collection of responsive clothing uses 
nanotechnology and microfluidics to sense the wearers body heat and interpret emotional states, especially 
stressful ones (Figure 4). The garments provide aromas that boost the limbic system in the brain, our 
emotional center. The designers and researchers offer an anti-depressive form of embodiment and propose 
design that breaks down the taboo on mental health and [improves] quality of life [5]. These responsive 
garments interpret self-expression as an involuntary emotional condition that is instantly addressed 
by the system. This trend toward automatic responsiveness is not interactive and participatory, but follows 
the drift of emphasis from clothing to the body that has taken place alongside the commercializa­tion 
of mobile media and especially ICT (information and communications technologies) concepts. According 
to Gilles Lipovetsky, since the beginning of the information age we have witnessed increased commercial 
activity linked to a growing anxiety-producing cult of the body characterized by the desire to avoid 
looking old, to avoid cellulite and wrinkles, a desire mani­fested in the endless task of vigilance, 
prevention, and self-improvement [6]. So, with SFIT, the body is enhanced, augmented, given super powers, 
as it were; it is no longer clothed, so the sensual (visible, audible, tactile, and even olfactory) aspects 
of clothing and dress as social behavior are left behind. The positivist lineage of this trend is hard 
to shake: it is the figure of the disembodied cyborg or posthuman, and the reciprocity of humans and 
intelligent machines. As Barbara Wegenstein has pointed out, such ideas have been echoed by techno-futurist 
writers from Warren McCulloch to Ray Kurzweil and Nicholas Negroponte [7]. On the other hand, many artists 
working in new media have taken an opposing viewpoint, sometimes exploring the intractable or mechanic 
nature of devices in mobile contexts like garments and fashion to enhance, rather than erase, the potential 
for statement making. Rather than hiding the interface, they use the social presence of clothing to emphasize 
or exaggerate both digital and garment operations. Examples from the exhibition Social Fabrics, which 
took place in Dallas in 2008, include Joanna Berzowska/XS Labs Skorpions (2007), a series of dresses 
with Nitinol, a shape-memory alloy, and customized circuitry that move on their own, even opening on 
their own to expose the body. They are poeticized garment malfunctions. Similarly, Heidi Kumao s Posture 
Generator (2005) is a bondage-style leather corset that screams at the wearer when she begins to slouch, 
demanding a return to correct and adopt perfect (vampish) posture, and providing viewers and hearers 
with uncomfortable reminders of the dysfunction of fetishized display. A number of artists have addressed 
the concept of personal space in an overcrowded world by creating pneumatic attire. Teresa Almeida s 
Space Dress (2005) expands at will to achieve a little more breathing room on a crowded subway, and shields 
its wearer from probing hands (Figure 5). Among the endless examples that could be cited, some visualize 
operations of the body that are not normally aestheticized or even much noticed. Suzi Webster s Electric 
Skin is a bio-responsive garment that turns the intimate breath of the wearer into pulses of aqua blue 
light (Figure 6). A breath-controlled electro-luminescent panel embedded in the hood flares off of the 
garment. It does not diagnose its wearer or suggest a treatment. It merely focuses the experience of 
breathing in both a metaphysically and digitally enhanced way, and, at the same time, it buzzes, encourag­ing 
an awareness of connectivity to electrical circuitry. In another vein, Stephanie Sandstrom s EPA Dress 
(2008) responds not to breath but to bad air. Rather than being functional and staying wrinkle-free, 
the dress crumples up in response to pollutants. An important subset of wearable-technology art deals 
with social relations online and off, and how these are enhanced (or not) by mobile technologies. Laura 
Beloff, Erich Berger, and Martin Pichlmair s Seven Mile Boots (2003) enable their wearer to surf audio 
chats on the internet by walking on actual ground. The conversations are broadcast in the boots vicinity, 
unbeknownst to the chat room participants (Figure 7). Big and covered with hardware, the boots are showy 
and evoke fabulous boots of cultural myths and fairy tales. In another work that represents network connectivity 
in the real world, Katherine Moriwaki s umbrella.net (Dublin) is a network of umbrellas that emit an 
electronic signal when opened and light up when nearing others of their kind. Umbrellas always make an 
appealing display for pedestrians walking in any rainy urban landscape. Umbrella.net references this 
picturesque phenomenon and discloses offline awareness of the online world as well. In all these examples, 
the exploration of visibility as well as physical fact or even physical flaw invokes more the recalcitrant 
figure of Ellison s Invisible Man than the erased one of Wells . Most wearables artists are acutely aware 
of the history of clothing as intellectual context for their work. But even in the realm of fashion design, 
we find the utilization of digital technologies to visualize complexity. Hussein Chalayan s 2007 animatronic 
collection presented dresses that expand and contract. Beneath each model s skirt was a computer-driven 
system designed by the creative engineering firm 2D3D. The point of these clothes was to digitally perform 
the history of fashion within a single dress. The collection emphasizes the act of change in a larger 
fabric of behavior and time. But why garments and wearables as an artistic strategy, and why now? While 
wearable art had a conflicted development within the institutional contexts of museum and art historical 
discourse in the 20th century, the increasingly mobile and participatory public of today favors performative 
and interventionist practices over traditional art objects, and the old barriers between aesthetics and 
functionality seem to be breaking down. Moreover, increasing numbers of researchers are studying garment 
history and theory, and some argue, as Lipovetsky does, that, far from being materialistic incentives 
for the growth of market economies, ideas about what we put on our bodies are implied in the very infrastructure 
of democratic societies. He writes: We have reached the era of consummate fashion, the extension of the 
fashion process to broader and broader spheres of collective life. Fashion is not so much a particular 
peripheral sector, now, as a general form at work in society as a whole. Everyone is more or less immersed 
in fashion, more or less everywhere. [8] For Lipovetsky this is not a bad thing: fashion (or, more broadly, 
dress) is not merely a commer­cial, but rather a quintessential element in the life of individuals functioning 
in societies. In fact, despite the cult of the body, interest in dress is everywhere, in both commercial 
and DIY manifestations, and throughout popular culture, from the Project Runway Effect (Americans buying 
more sewing machines) to the centrality of costume in virtual online worlds. To reference an idea of 
Gilles Deleuze, the increased interest in dress embodies (as it were) what he terms control society, 
the formation that has replaced Michel Foucault s disciplinary society, based upon institutional spaces 
like hospitals and prisons. Control society s lack of enclosure, its nomadic present, is the vehicle 
for dress. Dress is everywhere. It is our primary interface to our environment and transmits and receives 
emotions, experiences, and meanings. But dress, like other technolo­gies, is ruled by codes and susceptible 
to protocological control. Critical media artists working in wearables incorporate technologies in ways 
that not only reference the history of garments as (indeed) the oldest mobile IT, but also and this is 
in line with what dress has always done through­out its history to examine given forms and technologies, 
and discover inherent weaknesses or flaws in the systems that embed them. These flaws reveal attitudes 
and intentionalities that some might call problematic. Joanna Berzowska writes: As designers of wearable 
technologies we need to step back and ask why we want our fabrics to be electronic The clothing and electronic 
industries are looking for the killer applica­tion, the next big thing that will introduce wearable computing 
to a mass market. However, many research directions are misguided. The focus on health monitoring and 
surveillance technologies clearly reflects the military funding structures and fails to deliver appealing 
product ideas that respond to personal, social, and cultural needs. [9] Media theorist Geert Lovink claims 
that the vanishing interface makes us vulnerable. He states: The integration of technology into clothing 
has the danger to become invisible and merely expand corporate functionality, which is not beneficial 
for the user [10]. Lovink is especially wary of the developing ubiquitous use of RFID tags, RF fibers, 
and micro-sensing devices. The idea that our clothing (or our personal environments, for that matter) 
can regulate our health or physical performance or cater to our desires has a dark side that calls to 
mind Deleuze s notions of control societies [11]. Critical wearables artists are hacking the protocological 
networks of the body in a manner Alexander Galloway describes as life-resistance [12]. They position 
themselves as intervention­ists by drawing attention to social phenomena rather than actually attacking 
corporate technology. But the systems these artists bring together for scrutiny are more diverse and 
subtly related than those of any programmer, and include technological protocols, bio-power, EMF environmental 
pollution, gendered representational patterns in both dress and technology contexts, and the mimetic 
or mime-like nature of both dress and technology. More than anything else, critical wearables artists 
explore something that technological design rarely does: the complexity of online and offline combinations, 
i.e. the metaphysical messiness of digitized life. As Andra Petrovcic found in his recent study of personal 
networks in Slovenia, users tend to combine multiple media modes to sustain their personal networks. 
Furthermore, results regarding the distance of ties in the personal networks of ICTs users and offline 
socialization indicate that the new forms of sociality, although promoting spatially extended personal 
communities, are firmly embedded in physical settings [13]. Given the tactical and critical roles that 
new media artists have played in the past, plus the social commentary inherent in radical fashion design, 
we might ask: Does fully integrated material computing represent greater creative freedom, or an area 
that can be occupied by political interests or any means of social control? Can we compare wearable technologies 
to the pencil or the printing press, a kind of medium with powerful reach and impact that we must learn 
to use with subtle understanding? The growing use of wearable technology as a critical art practice dramatizes 
such questions and allows us to fine-tune our reactions to them. The positive and the critical views 
frame how we use technology and how we imagine it will be used in society. Clearly, neither position 
is exclusively correct, and wearable technology art and design will encompass both on an ongoing basis. 
But with the advancement of material comput­ing technologies, more and more smart wearables will enter 
the social and commercial fields. Since the body itself and our corporeal existence are at stake here, 
these respective positions should be carefully considered as we incorporate the new technologies seamlessly 
into our practice of dress. References 1. William Gibson, Neuromancer (New York: Ace Books, 2000) 66-67, 
original publication 1984. 2. http://www.design.philips.com/probes/projects/dresses/index.page, and http://news.softpedia.com/news/Flammable-Ego-Philips-lights-Up-Your-Inner-Self-74355.shtml. 
3. http://www.primidi.com/2008/10/15.html. 4. http://www.news.cornell.edu/stories/May07/nanofibers.fashion.aj.html. 
5. Smart Second Skin Dress: http://www.smartsecondskin.com/main/scentsorydesign.htm. 6. Gilles Lipovetsky, 
The Empire of Fashion: Dressing Modern Democracy, trans. Catherine Porter (Princeton, New Jersey: Princeton 
University Press, 1994) 264. 7. Bernadette Wegenstein, Getting Under the Skin: The Body and Media Theory 
(Cambridge, Massachusetts: MIT Press, 2006) 12-13. 8. Lipovetsky, The Empire of Fashion, 131. 9. Berzowska, 
Electronic Textiles: Wearable Computers, Reactive Fashion, and Soft Computation, Textile, Vol. 3, No. 
1, 16 (2005). 10. Susan Elizabeth Ryan, A Virtual Interview With Geert Lovink, Intelligent Agent, Vol. 
8, No. 1 (2008). 11. Gilles Deleuze, Postscript on Societies of Control (October 1988), reprinted in 
The Cybercities Reader, ed. Stephen Graham (London: Routledge, 2004) 73-77. 12. Peter Galloway, The Exploit 
(Minneapolis, Minnesota: University of Minnesota Press, 2007) 78. 13. Andra Petrovcic, Reconfiguring 
Socialities: The Personal Networks of ICT Users and Social Cohesion, tripleC, Vol. 6, No. 2, 163 (2008). 
 Susan Elizabeth Ryan Educator School of Art 123 Art Building Louisiana State University Baton Rouge, 
Louisiana 70803 USA faryan@lsu.edu  Figure 1. Vladimir Tatlin s New Way of Life. Functional worker s 
clothing with sewing patterns, 1924. From En.wikipedia, PD-Russia-2008. Leonardo, Vol. 42, No. 4, pp. 
307 313, 2009  |  &#38;#169; 2009 Susan Elizabeth Ryan  Figure 2. Invisibility Cloak (Retro-Reflective 
Projection Technology, Optical Camouflage), &#38;#169; 2004 Susumu Tachi. Photo Tachi Laboratory, The 
University of Tokyo.  Figure 3. Glitterati Garments, Cornell Design League Fashion Show, 2007 Olivia 
Ong and Juan Hinestroza. Runway still, &#38;#169; 2007 Michael Grace-Martin. Susan Elizabeth Ryan  
|  Re-Visioning the Interface  Figure 4. Smart Second Skin Dress, 2003 Scentsory Design. &#38;#169; 
2003 Jenny Tillotson. Photo Guy Hills. Illustrator Wendy Latham. Re-Visioning the Interface  |  Susan 
Elizabeth Ryan  Figure 5. Modes for Urban Moods: Space Dress at the 13th International Festival of Computer 
Arts, Slovenia. &#38;#169; 2005 Teresa Almeida. http://www.banhomaria.net/modes.html Susan Elizabeth 
Ryan  |  Re-Visioning the Interface  Figure 6. Electric Skin, &#38;#169; 2006 Suzi Webster. Re-Visioning 
the Interface  |  Susan Elizabeth Ryan  Figure 7. Seven Mile Boots, 2003-04 Laura Beloff, Erich Berger, 
Martin Pichlmair. &#38;#169; 2003 Beloff-Berger-Pilchlmair. Photo Laura Beloff. Susan Elizabeth Ryan 
 |  Re-Visioning the Interface Re-Visioning the Interface  |  Susan Elizabeth Ryan  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667269</article_id>
		<sort_key>40</sort_key>
		<display_label>Article No.</display_label>
		<display_no>3</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[The 200 year continuum]]></title>
		<page_from>1</page_from>
		<page_to>10</page_to>
		<doi_number>10.1145/1667265.1667269</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667269</url>
		<abstract>
			<par><![CDATA[<p><i>The 200 Year Continuum</i> is the producer, recorder, and exhibitor in Christian Kerrigan's advancing anthology of narratives. Central to Kerrigan's practice is storytelling and mythmaking as a means of engaging his audience. Kerrigan uses drawing as his primary mode of research into these narratives, which are consequently offered in the form of live internet-feed installations acting as ecological sites, scientific experiments introducing new organic technologies, and digital images of worlds unseen. Each addition acts as a "middle story" within <i>The 200 Year Continuum</i>. In his narrative, <i>The Amber Clock</i>, a ship is grown in the yew forest of Kingley Vale over a period of 200 years. The narrative explores the possibilities of time in relationship to technology and the natural world. In his narrative, artificial and wild systems are choreographed, and the natural production of resin is harvested from the yew trees as a way of measuring time.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405</concept_id>
				<concept_desc>CCS->Applied computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797184</person_id>
				<author_profile_id><![CDATA[81448600834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kerrigan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Artist, London, United Kingdom]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Tisdall, Joseph Beuys, <i>We Go This Way</i> (London: Violette Editions, 1998) 36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Parasol Unit Foundation for Contemporary Art London, Charles Avery The Islanders: An Introduction: http://www.parasol-unit.org/index.php?id=313.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N. Spiller, "Deformography: the poetics of cybridised architecture": http://www.surrealismcentre.ac.uk/papersofsurrealism/journal4/acrobat%20files/Spillerpdf.pdf (2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. Gibson, <i>The Shameful Life of Salvador Dali</i> (London: Faber and Faber, 1997) 157.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Spiller, <i>Cyber Reader: Vacillating Objects</i> (London: Phaidon, 2002) 306.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. T. Coleridge, The Rime of the Ancient Mariner: http://etext.virginia.edu/stc/Coleridge/poems/Rime_Ancient_Mariner.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[(op. cit.) Gibson.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The 200 Year Continuum Christian Kerrigan Abstract The 200 Year Continuum is the producer, recorder, 
and exhibitor in Christian Kerrigan s advancing anthology of narratives. Central to Kerrigan s practice 
is storytelling and mythmaking as a means of engaging his audience. Kerrigan uses drawing as his primary 
mode of research into these narratives, which are consequently offered in the form of live internet-feed 
installations acting as ecological sites, scientific experiments introducing new organic technologies, 
and digital images of worlds unseen. Each addition acts as a middle story within The 200 Year Continuum. 
In his narrative, The Amber Clock, a ship is grown in the yew forest of Kingley Vale over a period of 
200 years. The narrative explores the possibilities of time in relationship to technology and the natural 
world. In his narrative, artificial and wild systems are choreographed, and the natural production of 
resin is harvested from the yew trees as a way of measuring time. The Premise The premise of my paper 
is to outline the form and function of The 200 Year Continuum as producer and recorder of a fictional 
visual narrative referring to society s relationship to emerging technologies and the natural world. 
For this paper, I will explain the construction of the fictional project of growing a ship in the real 
site of Kingley Vale in West Sussex, one of the last remaining (2005) yew forests. The narrative tells 
the story of The Amber Clock. Defined as a symbiotic fictive perfor­mance, growing a ship over 200 years 
displays the choreography between a natural system of growth and the artificial presence of manmade interventions. 
Using three-dimensional drawing technologies and historical references to the existing site, combined 
with professional dendrochrono­logical expertise, I create an integrated description of this mythology. 
The fabric of the myth consists of the descriptive fictional narrative told alongside drawings to contextualize 
the description by depicting typological characteristics for each stage of the mythology. The narrative 
describes how the trees are shaped, using elaborate Bonsai techniques, to form the ship s structure. 
As the trees grow, the ship emerges in the forest. The shape of the ship inside the forest also alters 
the sound of the trees, making the ship an acoustic instrument within nature. Meanwhile, as artificial 
and wild systems are choreographed, the natural production of resin is harvested from the yew trees as 
a way of measuring time. In creating this fictional narrative, I explore the possibilities of time in 
relationship to technology and the natural world. The Process The starting point of this work was a series 
of drawings in which I explored the worlds of artificial and natural systems, and developed the choreography 
of the forest as a metaphor for our relationship to the natural world. I chose the yew forest of Kingley 
Vale as a theoretical site for my intervention since it contained existing historical narratives and 
mythologies that form the background on which to construct my own narrative. I began to formulate my 
theoretical framework based on existing and imagined mythologies regarding humanity s relationship to 
nature, as I wanted to use the narrative to speak of society s shifting focus and interpretation of its 
surrounding environment. From the assumption that nature remains, itself, a very slow-changing system, 
the narrative explains how natural and artificial systems could potentially work symbiotically to generate 
a new kind of dynamic architectural phenomenon, whose effect would be most clearly observed over an extended 
period. My production process involved successive drawing, which choreographed the narrative and generated 
direction for the complete body of work. Joseph Beuys described the focus on drawing and image as a convergence 
of thought and space on which to create a dialogue. My drawing process involved mapping, using 3D modeling, 
various spaces within the forest. The making of these three-dimensional drawings orga­nized the spatial 
and visual language for the space-time continuum and provided a visual test space for the narrative to 
exist and play out in situ. As the narrative displays a time-based continuum, the act of drawing has 
the ability to record the process in a forward-looking scenario. The recording of my manipulation of 
the initial spaces, through drawing, was, in a sense, the dialogue Beuys denoted, as it informed the 
decision-making process at theoretical junctions within the narrative. Thus, the mythology played out. 
This process was further informed by research into the art of Bonsai and the input of relevant real-world 
scenarios offered by Martin Bridge, dendrochronologist at the Institute of Archaeol­ogy, University College 
London. He described the body language of trees and pre-empted how the natural system will cope within 
my narrative. However, as the narrative is set over 200 years, it is the use of drawing, within the virtual 
landscape, that provides the facility to stretch beyond real-world experiments and logic. To again herald 
Beuys, I quote a passage on the artist by his chief photographer, Caroline Tisdall: The widening of language 
is the key to the process of change in thinking. For Beuys the widening of language came through drawing. 
Drawing becomes a way to reach areas which are limited by speech or abstract thinking alone, to suspend 
all notions of limits or limita­tions of a field so that it encompasses everything. The widening principle 
means the pulling together of man s experience through time. [1] I am heavily influenced, in my work 
as a whole, by Joseph Beuys, for the way he tackled his working practice through a constant deciphering 
of the relationship between man and matter, and also, perhaps, for his avid interest in alchemy, botany, 
ecology, literature, philosophies, mythologies, and shamanism! In the conception of The 200 Year Continuum, 
I have aligned myself with artists and practitioners such as Charles Avery and Neil Spiller. In Avery 
s project The Islanders, texts, drawings, installations, and sculptures depict a fictional topology and 
cosmology of an imagined island. In creating all these parts, and in his dedication to the aesthetic, 
to humour, and to the spirit of philosophical proposition [2], Avery propagates an exploration into a 
philosophical conundrum by enticing the viewer to assemble the whole and recreate the Island in their 
own minds. Neil Spiller has spent the last 20 years developing a personal architectural language that 
rejoices in the surreal poetics of contemporary technology. Spiller s work explores the harvesting of 
cybernetic, genetic and cyberspatial space-time vectors and their transmission, transmutation and growth, 
to dissolve the old dichotomy of what defines the architectural and landscape. He has developed associated 
tactics of representation that illustrate his research into open-ended architectural systems. Spiller 
s world is full of vacillating objects, sensing mechanisms, and poetic Pataphysical swerves [3]. The 
Narrative The narrative defines a spatial and time-based metaphor for future scenarios in which our society 
may find itself. With advancing technology, new mythologies will emerge, and our society will inhabit 
newly imagined worlds that can only be navigated through human extension by techno­logical means. I start 
the narrative by citing where society is in the history of dialogue between technology and the natural 
world, and follow this by presenting the existing historical mytholo­gies surrounding Kingley Vale. These 
mythologies have fascinated generations and have reflected our changing perspective on what our nature 
is, thus making this forest an ideal backdrop to begin my own metaphorical fiction. 1. Hidden architectures 
find niches as moist technology We have reached a point in our evolution where we are now capable of 
creating design criteria to manipulate natural growth and development. Through stem-cell research and 
fabrication at the nano-scale, the spectrum of opportunity now open to the exploration of complex systems 
has reinterpreted our existing understanding of the natural world and our relationship to mortality. 
2. Walk down the chalk road past the meadows On the chalk downland of North West Chichester is Kingley 
Vale, one of the last surviving natural yew forests in existence. The forest covers roughly 300 acres 
in a combe facing towards Chichester, just outside of London. In the heart of the wood, the oldest trees 
stand at around 900 years, and the rest of the forest landscape is approximately 500 years old. Legends 
say that many of the trees were planted to commemorate the death of Sygbert, King of the West Saxons, 
who was stabbed to death there by a swineherd in 894. The mythology regarding the planting of the forest 
tells the tale of a marauding Viking war band that came to attack Chichester in the 9th Century. While 
the attack was furious, most of the warriors were killed by the defenders of the town. The trees in Kingley 
Vale descend from those planted as a memorial on the site of the battlefield, and four large barrows 
were built from the surrounding trees over the graves of the leaders on the ridge above the forest. The 
story is further embellished by the idea that the Danes, before attacking the Chichester men, first buried 
treasure in the form of a golden calf in an Iron Age hill fort known as The Trundle, which lies to the 
east of Kingley Vale. In adding my narrative to this already dense mythology, I introduce three key players: 
Nature, Technology, and Time. I interpret Nature as being the natural system of growth for the newly 
planted yew trees at Kingley Vale. The planting, insertion, and evolution of this site choreograph Nature 
and its hidden architectures. From the ancient use of the tool to the digital age, the forest, as a symbol 
for our complex environment, has been an extensive source of information. It presents clues as to how 
our society could begin to understand new interpretations of Nature. Woodlands are wild places that often 
generate a sense of infinity through time. In my narrative, it is the engagement of Time that makes the 
yew forest a unique site for new spatial fields. In a society organized increasingly on a short-term 
basis, the slow maturing of distance and time evokes a powerful sense of technology as longevity. The 
mythology carried through 200 years extends a life cycle beyond that of the human life span. If we trace 
the relationship between man and landscape, positing architectures that last beyond their generation 
creates a natural sustain­ability for the architectures to self-organise. Technology is understood as 
an artificial system that is created to fulfill a given task, in this case creating an imaginary world 
inside the natural forest. Technology generates the narrative for the system to alter and steer Nature 
into producing a hidden vessel. The artificial system is calibrated by a sequence of changes within the 
artificial devices. Over time, the choreography displays the curvature of the ship. The mechanisms call 
upon the tree as live formwork to contain the hull of the ship. Across the lake, the silhouette of the 
ship within the forest evolves as a hidden piece of mythical architecture. 3. No one is ever seen entering 
or leaving The form of the ship is controlled by individual corsets wrapped around the trunk of the tree, 
manipulating the growth of separate parts of the vessel. As the tree grows through the corset, the shape 
of the designed armature controls the extrusion. The Macresco harvests the growth imperative of trees; 
it is structuring the launching pier, hull, and rudder as the wet system grows dense (Figure 1). As the 
ship ages inside the forest, hybrid systems interact with the object. The cell structure at the nano-scale 
alters, while natural ecosystems in the forest find new relation­ships to the growing object. The rudder, 
located within the body of the tree, exists as a hidden section within the forest (Figure 2). This section 
of the tree is trained by tensioned cables that act as counterweights to the growing system. As the mechanistic 
piece for the corset shapes the tree, it later becomes embed­ded to become part of the ship s rudder. 
The geometry of the vessel is a combination of extrusion and tension, which sets up the complex system 
of interdependencies of natural growth. Climatic changes, both globally and in the microcosm, act as 
an added force in defining the ship s evolution, since the forest itself weathers and ages. In ancient 
Japanese culture, nature is seen as an extension of the people themselves. As an ancient union of art 
and nature, Bonsai is an example of how people order nature and their surroundings. The tree is alive 
and continually changing. The slow manipulation, through wiring, of Bonsai trees to attain desired shapes, 
is a simple gesture in a relationship of two systems of organisation. The control the Japanese exert 
upon nature is meant to evoke the essential spirit of the plant being used. The manipulation of nature 
is seen as a way of provoking a new perspective on society s surroundings. The art of Bonsai performs 
an ongoing cycle throughout the life of the tree, plying the mind to believe in a greater possibility 
of the tree and its individual manipulation. Dynamic technologies choreograph a sustainable system of 
shifting geometries and densities. In the work Heliometer For the Deaf and Dumb, Salvador Dalí explains: 
It was an instrument of high physical poetry formed by distances and by relationships between these distances; 
these relationships were expressed geometrically in some parts, and arithmetically in others; in the 
centre, a simple indicating mechanism served to measure the saint s death-throes. The mechanism was composed 
of a small dial of graduated plaster, in the middle of which a red blood clot, pressed between two crystals, 
acted as a sensitive barometer for each new wound. In the upper part of the heliometer was Saint Sebastian 
s magnifying glass. This was at once concave, convex and flat. [4] In The Amber Clock, a corset wrapped 
around the tree trunk is used to bleed resin to generate the clock s momentum (Figure 3). The Amber Clock 
acts as the calibrating device between the tree s timescale and the artificial system, and it acts as 
an artifact for a generation 200 years from now to find, reconstruct, and add to the system s history. 
The apertures slowly create holes within the pieces of the ship. As the growing material ages, the calibrating 
devices co-ordinate so that the pieces of the ship may eventually slot together. Neil Spiller explains 
the site as vacillating objects: Our technologies have developed a series of interlinked spatial fields, 
each with differing qualities and with blurred boundaries. The objects that inhabit those fields are 
becoming schizophrenic . An object will have many selves, many simultaneous forms. Technology is forcing 
the object to become a subject, partial and anamorphic. The anamorphic object changes form when viewed 
from different viewpoints, in different fields or in distorted mirrors. [5] 4. The myth, the symbol, 
and the amber The yew tree has played an important role in the formation of human culture and consciousness. 
It has provided wood for shelter, tools, and weapons, and foliage and bark for every medicine bag. Its 
greatest influence on culture was its myriad spiritual associations with goddess, afterlife, and immortality. 
Although the yew tree was revered in nearly every culture of the northern temperate zones, yew trees 
were destroyed for their utility. Today, their remnants are threatened throughout the world because yew 
bark and foliage provide taxol, the most promising new anti-cancer drug in 30 years. With stem-cell research, 
manipulation in society is extending to our human interior. The ship growing from the yew trees is the 
ship from the Rime of the Ancient Mariner. A poem of death and immortality of human existence, it relates 
a story of supernatural events experienced by a mariner on an epic, life-changing voyage at sea. The 
story is told as the mariner stops a man who is on his way to a wedding ceremony and begins to recite 
his tale [6]. The Mariner s tale begins with his ship leaving harbour; the ship is driven off course 
by a storm and driven south to Antarctica. An albatross appears and leads them out of the threatening 
waters; even as the albatross is praised by the ship s crew, however, the Mariner shoots it with a crossbow. 
The other sailors are angry with the Mariner and blame him for the change in weather that subsequently 
occurs as he killed the bird that was leading them to safety. This crime arouses the wrath of supernatural 
spirits who then pursue the ship; the south wind which had initially led them from Antarctica now sends 
the ship into uncharted waters. When the weather becomes misty, the sailors change their minds and hail 
the Mariner for killing the bird that brought the fog. Eventually, the ship encounters a ghostly vessel, 
which murders the ship s crew. The Mariner manages to pray, the albatross which is hung from his neck 
for his act of slaughter, falls and his guilt is partially redeemed. The bodies of the crew, possessed 
by good spirits, rise again and steer the ship back home, leaving only the Mariner behind. In penance 
for his deed, the Mariner is forced to wander the earth and tell his story. The Mariner s tale loses 
touch with the world of ordinary existence and slips into the realm of the imaginary. This ship, navigating 
its path, is an image, for many, of lives passing towards mortal death. It is part of our human obligation 
that we are condemned both to hear out our fellow human beings in their extremity and to recognize, in 
their stories, potential stories of ourselves. Technology does not presume to act on mere practical reasons 
but to facilitate new human conditions of interaction. The Amber Clock is strapped to the tree trunk 
to keep track of passing time (Figure 4). The resin from the tree bleeds into the 200-year hourglass. 
Much like Egyptian water clocks, it slowly fills and, when full, the clock stops, signaling the end of 
the system. The passing of fluid from the natural system into the artificial system of the clock monitors 
the time passed relative to the growth of the tree. Harvesting resin production as the forest matures 
allows the Amber Clock to slowly keep time. Each of the yew trees fitted with an Amber Clock informs 
the tightening devices how much they are to calibrate. This incremental alteration within the system 
informs the Amber Clock as it measures the passing of time. This time-based exhumation evokes an algorithm 
based on tree growth as the amber hourglass registers the ship s evolution. The clocking can register 
the longevity of the system and tweak the degree of tension according to the maturing of the forest. 
As the hourglass fills over time, the resin slowly hardens and the clock begins to jam. Ultimately, the 
volume of the hourglass is filled, the clock stops, and the system is complete. Dalí saw the benefit 
of useless objects that perhaps have other meanings than the overtly mechanistic and functional: The 
museums will fast fill with objects whose uselessness, size and crowding will necessitate the construction, 
in the desert, of special towers to contain them. The doors of these towers will be cleverly effaced 
and in their place will be an uninterrupted fountain of real milk, which will be avidly absorbed by the 
warm sand [7]. Poetic and metaphorical objects can thereby occupy worlds and will the spaces around them 
to change geographically. The resin clocks are consumed as a fossilized fragment of the system, creating 
a time capsule of the ship s evolution in the past 200 years. The ship s figurehead, a carved ornamental 
and painted figure erected on the bow, is an iconic symbol of culture. In my narrative, the figurehead 
evolves from the splitting of the yew tree as an iconographic piece between time and technology (Figure 
5). As the yew tree ages, the centre of the tree splits as it begins a new life cycle, sending a live 
shoot down through the trunk of the tree. The rotting outside protects the new growth to maintain the 
time-based evolution of the forest. 5. Tuning trees for an acoustic ship Trees have a natural frequency 
specific to their type of wood. The system calibrates the density of the trees and, in the process of 
growing the ship, the acoustic frequency of the forest changes. As the shape of the ship begins to emerge 
within the forest, the yew trees take on unnatural forms. With this alteration, the acoustic properties 
throughout the forest begin to heighten. As with the forest s natural resonance, a higher density of 
mature wood will articulate a lower intonation. By manipulating the density of the trunks, the alteration 
of the forest begins to take on the acoustic resonance of a ship, and the system produces an instrument 
within the forest. Each tree becomes an individually tuned, natural instrument within the body of the 
forest, and will play new acoustic frequencies as harmony to the rhythm of the woodpecker s tapping. 
The hull within the forest begins to embody a languorous high-density wood as it drifts through the yew 
landscape, while the sound of the ship s furniture adopts a variable lightness compared to the acoustic 
dampening of the heavy stern (Figure 6). The evolution of the forest can then be traced as feedback sound 
that, in turn, records the frequency of the wood. An acoustic resonance technique detects deterioration 
in trees with the sound of decaying hollow tree trunks. The acoustic feedback acts as a register, with 
the frequency outlining the edges of the system. 6. Obelisk in the forest Coming to the end of its system, 
the armatures have the potential to alter, again, the geometries of the copse. Spliced into the hull 
of the ship, these armatures deal with the new end of making the ship s own cargo. As the ship leaves 
the edge of the forest, it reconfigures itself to take root in granite fields as it engages in the time-based 
carving of its own obelisk. In certain cases, the parameters of the obelisk exist hidden within the forest, 
as the process moves to completion. The Conclusion Having completed the narrative, I posted the 3D drawings 
from the project and a short blurb defining the objective. I received a response from a father and his 
young son who had gone to visit Kingley Vale in search of my growing ship. We spent hours, he wrote, 
roaming the forest looking for this any clues? The Amber Clock began as a project seeking to describe 
a complex system through the use of detailed drawings and text. The striking and unanticipated conclusion 
to the creation of the project, and, indeed, this paper, is in the reaction of this man and his son. 
By offering the narrative to a public forum, and in so doing, blurring the boundaries between reality 
and fiction, it turned an architectural vision into a mythology. Storytelling has been used throughout 
history to teach, through the use of metaphor and abstraction, new visions and morals of the world. Each 
time I speak of the Amber Clock, even now, in this paper I present to you, I am perpetuat­ing the myth. 
In so doing, my primary objective, to speak of the idea of environmental and manmade interactions as 
a means of communicating a new disposition to future natures or synthetic ecologies, can be realised. 
This conclusion, in the aftermath of The Amber Clock, led to the inception of The 200 Year Continuum.  
Acknowledgement Thanks to Ms. Phoebe Boswell for her ongoing support and generosity. References 1. C. 
Tisdall, Joseph Beuys, We Go This Way (London: Violette Editions, 1998) 36. 2. Parasol Unit Foundation 
for Contemporary Art London, Charles Avery The Islanders: An Introduction: http://www.parasol-unit.org/index.php?id=313. 
3. N. Spiller, Deformography: the poetics of cybridised architecture : http://www.surrealismcentre.ac.uk/papersofsurrealism/journal4/acrobat%20files/Spillerpdf.pdf 
(2005). 4. I. Gibson, The Shameful Life of Salvador Dalí (London: Faber and Faber, 1997) 157. 5. N. Spiller, 
Cyber Reader: Vacillating Objects (London: Phaidon, 2002) 306. 6. S. T. Coleridge, The Rime of the Ancient 
Mariner: http://etext.virginia.edu/stc/Coleridge/poems/Rime_Ancient_Mariner.html. 7. (op. cit.) Gibson. 
 Christian Kerrigan Artist 15 Michael Cliffe House London EC1R 0WW United Kingdom studio@christiankerrigan.com 
 Figure 1. Growing the Bow, digital drawing. The mechanisms shown describe how the tree grows into the 
formwork to take the shape of the bow of the ship. The natural system can be artificially trained over 
time. &#38;#169; 2006 Christian Kerrigan. &#38;#169; 2009 Christian Kerrigan  |  Leonardo, Vol. 42, 
No. 4, pp. 314 323, 2009  Figure 2. Bonsai Corset, digital drawing. The designed corsets wrapped around 
the early growth of a tree trunk are used to create the extruded sections of the ship throughout the 
length of each tree. The corsets form various shapes using techniques of Bonsai within the copse. &#38;#169; 
2006 Christian Kerrigan. The 200 Year Continuum  |  Christian Kerrigan  Figure 3. Growing Holes, 
digital drawing. The mechanism shown describes how the tree is articulated to take the shape of the bow 
of the ship and how the natural system can be artificially trained to grow holes so that the pieces may 
slot together. &#38;#169; 2006 Christian Kerrigan. Christian Kerrigan  |  The 200 Year Continuum 
 Figure 4. The Amber Clock, digital drawing. An amber clock is strapped to the tree trunk to keep track 
of passing time. The resin from the tree bleeds into the 200-year hourglass. Much like Egyptian water 
clocks, the hourglass slowly fills and, when full, the clock stops, signaling the end of the system. 
&#38;#169; 2006 Christian Kerrigan. The 200 Year Continuum  |  Christian Kerrigan  Figure 5. The 
Figurehead, digital drawing. The figurehead is a carved ornamental and painted figure erected on the 
bow of a ship, as an iconic symbol of its time. In this project, the figurehead evolves from the splitting 
of the yew tree as an iconographic piece between nature and technology. &#38;#169; 2006 Christian Kerrigan. 
 Christian Kerrigan  |  The 200 Year Continuum The 200 Year Continuum  |  Christian Kerrigan  Figure 
6. The Amber Forest After 150 Years, digital drawing. The forest landscape, shown from above, is manipulated 
to take the curvature of the ship as the forest evolves. The ship becomes consumed within the body of 
the trees and will act as an artifact for future generations 300 years from now to reconstruct the system 
s history. &#38;#169; 2007 Christian Kerrigan. Christian Kerrigan  |  The 200 Year Continuum The 
200 Year Continuum  |  Christian Kerrigan Christian Kerrigan  |  The 200 Year Continuum The 200 
Year Continuum  |  Christian Kerrigan  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667270</article_id>
		<sort_key>50</sort_key>
		<display_label>Article No.</display_label>
		<display_no>4</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Experimental interaction unit]]></title>
		<subtitle><![CDATA[commodities of mass destruction]]></subtitle>
		<page_from>1</page_from>
		<page_to>8</page_to>
		<doi_number>10.1145/1667265.1667270</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667270</url>
		<abstract>
			<par><![CDATA[<p>This paper describes several projects by the now-defunct Experimental Interaction Unit that use product design, software engineering, and digital networking to uncover collective behaviors that contribute to systems of social control. Biology and human behavioral studies are essential aspects of this critique. Experimental Interaction Unit's projects from 1996 to 2001 represent subversive use of technology to reveal unrecognized aspects of human interaction with networks, such as how telematic distance psychologically absolves individuals from taking responsibility for their actions. The fear of vulnerability to terrorist actions, including biological warfare and electronic interference, is exploited in these works, in order to expose the ways in which security is promised in exchange for control.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797185</person_id>
				<author_profile_id><![CDATA[81458649343]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anuradha]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vikram]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Curator and Critic, Richmond, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bey, Hakim, <i>The Temporary Autonomous Zone, Ontological Anarchy, Poetic Terrorism</i> (New York: Autonomedia, 1991): http://www.hermetic.com/bey/taz3.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Christopher, Roy, "ExperiMental InterAction," <i>Frontwheeldrive</i> (January 26, 2000): http://frontwheeldrive.com/eric_paulos.html. (Interview with Eric Paulos. Describes SRL collaboration and future plans. Talks about establishing trust between humans and machines through a user interface as a central element of EIU's practice.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Critical Art Ensemble, <i>Flesh Machine: Cyborgs, Designer Babies, and New Eugenic Consciousness</i> (New York: Autonomedia, 1998). (Describes the phenomenon of technology integrated with the body and the potential sacrifices that this requires in exchange for increased human capacity. Written by contemporaries of the artists under consideration.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[CTRL {SPACE}, <i>Rhetorics of Surveillance from Bentham to Big Brother</i> (Karlsruhe, Germany: ZKM Center for Art and Media, and Cambridge, Massachusetts: Massachusetts Institute of Technology, 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Experimental Interaction Unit: http://www.eiu.org/. (Provides detailed descriptions and images of projects, as well as Eric Paulos' statement about the effect of the 9-11 attacks on his practice and approach.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Federal Trade Commission, "Identity Theft Survey Report," <i>Synovate</i> (September 2003): http://www.ftc.gov/os/2003/09/synovatereport.pdf/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335968</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Goldberg, Ken, ed., <i>The Robot in the Garden: Telerobotics and Telepistemology in the Age of the Internet</i> (Cambridge, Massachusetts: Massachusetts Institute of Technology, 2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hunt, David, "Rx for Disaster," <i>Rhizome</i> (September 6, 1999): http://www.rhizome.org/ars99/9.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lee, Pamela M., <i>Chronophobia: On Time in the Art of the 1960s</i> (Cambridge, Massachusetts: MIT Press, 2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1211156</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Leopoldseder, Hannes, and Christine Sch$oUpf, <i>CyberArts 99: International Compendium Prix Ars Electronica</i> (Vienna and New York: Springer, 1999). (Contains a section on Dispersion by Eric Paulos, awarded an Honorable Mention in the category of Interactive Art, documenting the project's presence at the festival.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Stanley, Jay, "An ACLU Report. The Surveillance-Industrial Complex: How the American Government is Conscripting Businesses and Individuals in the Construction of a Surveillance Society," <i>American Civil Liberties Union</i> (September 2004): http://www.aclu.org/Privacy/Privacy.cfm?ID=162298c=130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Zeller, Tom Jr., "Breach Points Up Flaws in Privacy Laws," <i>The New York Times</i> (February 24, 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Zero News Datapool, "The Mythology of Terrorism on the Net": http://www.t0.or.at/cae/mnterror.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Experimental Interaction Unit: Commodities of Mass Destruction Anuradha Vikram Abstract This paper describes 
several projects by the now-defunct Experimental Interaction Unit that use prod­uct design, software 
engineering, and digital networking to uncover collective behaviors that contribute to systems of social 
control. Biology and human behavioral studies are essential aspects of this critique. Experimental Interaction 
Unit s projects from 1996 to 2001 represent subversive use of technology to reveal unrecognized aspects 
of human interaction with networks, such as how telematic distance psy­chologically absolves individuals 
from taking responsibility for their actions. The fear of vulnerability to terrorist actions, including 
biological warfare and electronic interference, is exploited in these works, in order to expose the ways 
in which security is promised in exchange for control. Experimental Interaction Unit: Commodities of 
Mass Destruction An investigation of the relationship between monitoring and accountability is central 
to the work of Experimental Interaction Unit (EIU). Like many contemporary artists working with new media 
technologies, EIU founder and primary artist Eric Paulos has a substantial under­standing of the ethics 
as well as the scientific concerns that inform the medium [1]. Appre­hensive of trusting in machine, 
industrial, or government architectures, he indulges the temptation to do so long enough to make a point 
about the seductiveness and dangers of willfully giving up self-determination to any system of control. 
Cloaked in a narrative of itself as a research organization rather than a single artist s project, EIU 
is modeled after government contractors, and like the agencies it mimics and parodies, it provides a 
comple­ment of market-friendly text to accompany each project. EIU artworks, particularly Dispersion 
(1999) and Limelight (2001), are promoted as techno-savvy consumer products for the new age of private 
security. Paulos founded EIU in the late 1990s, during a period of collaboration with the seminal perfor­mance 
group Survival Research Laboratories (SRL), known for constructing tableaux of destruction in which machines 
go to war with one another. Whereas an SRL show presents conflict as spectacular, EIU s projects are 
more casually encountered. They often appear to be both easily accessible and quite dangerous. Paulos 
applies his technical knowledge of robotics and software to build machines that invoke the fear of terrorism 
and invite audience participa­tion in threatening activities. These include dangers to physical health 
and safety, as well as to electronic data. EIU s projects highlight the legitimacy of these threats, 
the ease with which they can be carried out, and the frequent failures of law enforcement to accurately 
identify and prevent them. These works underscore Americans willingness to give up their privacy for 
security, and question whether this genuinely makes anyone safer. They ask us to consider whether our 
approach to security is effective, and how its loopholes might be exploited. Posi­tioned within an art 
context, these works incriminate the art institution in their criticisms. They are ambiguous, creating 
a gray area where representation becomes the thing itself. It is never clear whether EIU s statements 
are factual or fictional, as there is no empirical evidence made available on which to base that assessment. 
While a PhD candidate, Paulos was part of a group of researchers based at the University of California, 
Berkeley, who achieved significant developments in the field of telerobotics. These engineer/artists 
work with robotics as a means to preserve as much of the experience of real-time action as possible over 
virtual distances. They construct systems involving robotic hardware, which can be manipulated and controlled 
via online user interfaces. The telematic systems include video, audio, and manually controlled elements 
that maximize the remote controller s access to visual and physical stimuli to approximate a live experience. 
One telerobotic project that Paulos co-devel­oped during this period was Legal Tender (1996) (Figure 
1), created with collaborators Ken Goldberg, John Canny, Judith Donath, and SRL founder Mark Pauline 
[2]. In this project, internet distance was shown to release participants from fears about transgressing 
legal and social barriers, by disassociating them from the consequences of their actions. Once the participant 
s identity was registered in a database, the participant could, from afar, use a remote-controlled robotic 
arm to deface $100 bills. Paulos and Canny wrote: This is a criminal act, as defined by United States 
Code, Title 18, Section 333: Mutilation of National Bank Obligations. But only if the bills are real, 
the web site is authentic, and the experiment actually performed [3]. The remote participant must register 
his identity in order to experience the transgressive thrill of destroying someone else s money. Though 
it is impossible for him to verify whether or not a crime has actually taken place, he may still be culpable 
if it has. A primary interest in this work is to question how a criminal act can occur in virtual space, 
and whether accountability is preserved in the event that it does. Another is to examine our belief in 
the validity of an action carried out remotely, and our trust that what we see is what we know. I-Bomb, 
an electromagnetic pulse-emitting device first presented in San Francisco in November 1999, was designed 
to demonstrate our dependence on vulnerable electronic data profiles. Data can only be damaged by I-Bomb 
within a radius of a few feet, so the threat is largely a symbolic one. When the electromagnetic pulse 
is transmitted, access to wireless networks is momentarily cut off, portable electronic devices are temporarily 
disabled, and magnetically stored data such as that on credit cards may be erased, creating a technology-free 
zone [4]. EIU describes this project as one of liberating individuals from economic and social pressures. 
The project literature makes clear that they consider this action to be a threat only to technology. 
TFZ (Technology-Free Zone) systems are very selective. They do not affect organic or non-technological 
systems and are therefore safe for most humans [5]. The idea of a TFZ recalls Hakim Bey s concept of 
the Temporary Autonomous Zone (TAZ), a conceptual space in which complete freedom from social participation, 
with its constraints and regulations, can be briefly realized [6]. I-Bomb offers one way to realize this 
concept, offering a space where we are momentarily freed from our electronic data doppelgängers whether 
we wish to be or not. In March 2001, I-Bomb v2.0 (Figure 2) appeared unannounced one evening in front 
of the San Francisco Museum of Modern Art, in a heavily trafficked area of the city s downtown. Technol­ogy 
kills from the event, cheekily posted on EIU s website, included erased credit cards and a wiped laptop 
computer [7]. The museum, though closed, was implicated as a site where technol­ogy and commerce merge 
to engender social control. SFMOMA is a canonical institution with great influence over the arts culture 
of the region. Its benefactors are enormously wealthy industrialists. Endangering their financial and 
social data profiles is an action that implies subversion, yet avoids real consequences. After all, the 
data are still preserved in the network, where they are much more difficult to eliminate. Dispersion 
(Figure 3), introduced at the Ars Electronica Festival in 1999, poses an even greater potential danger 
to humans. Your easy one stop choice for personal lethal biological pathogens [8], this project appears 
to endorse tactics that many would consider horrific. Offering people, including children, pathogens 
custom-mixed to their specifications, Dispersion proposes to take the Second Amendment to its extreme 
conclusion guaranteeing every individual access to the most advanced and lethal biological weaponry. 
In doing so, the project highlights the central role of civilian casualties in any act of contemporary 
warfare. Central to its concept is a critique of advertising and marketing strategies that manipulate 
the populace, by perpetuating a climate of paranoia alongside a culture of competitive ownership. Through 
fear and envy, we are persuaded to support corporate and government practices that are harmful to us 
personally. Easy access to these materials via a vending machine makes them desirable, despite the fact 
that no one would want such horrible stuff if he or she were thinking rationally. The tall metal box, 
sized to the specifications of a commercial vending machine, is covered with glossy blow-ups of microscope 
photos of bacteria and viruses. One image bears the work s title and aforementioned slogan. A window 
reveals the robotic arm that carefully dispenses the desired agents via small plastic vials (Figure 4), 
and to its right is a touch-screen monitor. The user interface enables the choice of a pathogen on the 
basis of several factors: dispersion radius, spore survival time, infection rate, degree of contagion, 
desired symptoms, level and duration of suffering induced, diagnosis difficulty and vaccine availability, 
and mortality rate. As the user navigates through the interface (Figure 5), images of the devas­tating 
effects of these pathogens on human beings appear alongside the questionnaire. Users are led to believe 
that the substance they are receiving is potentially lethal and extreme­ly potent. These substances are 
unlikely to be truly hazardous, but that is irrelevant. It is more important that we pay attention to 
the implica­tions, rather than to the facts, of the project. The point the work makes is that people 
will voluntarily exchange personal biometric information for access to an object perceived as having 
power, because we are willing to give up privacy for the perception of defensive strength. Whether the 
threat that causes us to consider this trade-off is fictional or real is unimportant, because either 
way we begin to question long-held beliefs about our assumption of personal safety in public space. The 
advertising conglomerates that drive consumer societies such as ours are built on convincing people to 
want products that promise more than they deliver. We are in a moment as a nation when the appearance 
of security is frequently prioritized over verifiable results, a tendency that EIU both exploits and 
critiques. Security cameras and armed guards make the population feel safer, because they are perceived 
to be a deterrent. Soldiers with guns are still powerless against an anthrax attack or a dirty bomb if 
emer­gency room beds are scarce and ambulance response times are slow, but these aspects of preparedness 
are less visible to the average person. As such, they remain inadequate and underfunded in most American 
cities. Anoth­er risk incurred when government and law enforcement adopt the methods of private commercial 
entities is that we will convince ourselves that we are protected by putting on a show of it and miss 
signs of impending danger that we might otherwise avoid. All of the data provided through Dispersion 
s user interface are collected from the results of previously documented experiments and incidents involving 
these pathogens, most occurring at the hands of defense researchers in the USA and abroad. To operate 
the machine, each user must register his or her fingerprint in a database along with personal and biometric 
information, which is stored along with a blueprint of the agent dispersed. This information may be distrib­uted 
to appropriate law enforcement agencies should they desire to monitor the recipients of any pathogens. 
These systems will be required to automatically and safely cultivate, monitor, contain, package, and 
properly dispense lethal biological pathogens. Furthermore, the vending device must accurately record, 
track, and monitor the individuals using the system and observe social trends in viral demands to make 
long term predictions about humanity [9]. While Dispersion pretends to make obtaining lethal agents easy, 
using them covertly would be difficult. In this transaction, personal information is the currency, and 
privacy can be traded for access to the means of mass destruction. Dispersion functions as both a model 
for democratic access to terrorist methods and a data bank of potential terrorists. EIU s final project 
is Limelight (2001), a tabletop sculpture approximately 15 inches high that promises to constantly monitor 
and indicate the degree of threat in an individual s environment. Taking its cue from the Department 
of Homeland Security s color-coded Threat Advisory System, which advises citizens to continue to be vigilant, 
take notice of their surroundings, and report suspicious items or activities to local authorities immediately 
[10], Limelight will assess the user s biometric and environmental conditions, communicate them to a 
central server via a low-bandwidth wireless connection, download information from databases of global 
threat conditions to determine a personalized and immediate level of threat, and send warnings back to 
the database when potential dangers are encountered. When the degree of risk is low, Limelight is an 
oddly pretty, unobtrusive object. Colored lights, sounds and vibrations indicate the threat level, becoming 
more intense as the danger intensifies. Limelight, a sleekly designed commercial product, is an appealing 
commodity marketed to private individuals as a protective agent. One photo on EIU s website shows it 
positioned next to a coffee cup, for scale (Figure 6). This is a domestic appliance. As with previous 
EIU projects, protection is again bartered against privacy. Limelight requires a fingerprint reading 
to initialize and communicates any information it collects about the user s body and environment to the 
database. Relinquishing this data is an important prerequisite to the overall operation of Limelight 
as it establishes a biometric guarantee of the location of the individual user. This allows for tracking, 
monitoring, and surveilling of the user during its operation as well as during subsequent uses [11]. 
This information is recorded by the same EIU server that communicates threat warnings to Limelight, which 
profiles each user and incorpo­rates this into its determination of the level of threat. Therefore, Limelight 
s ability to identify threats is increased when more individuals request their conditions to be monitored. 
Like the national ID card system proposed by many in the US and British governments, Limelight also positions 
each user as a potential threat. The safeguarding it offers is actually protection from other participants 
in the program. Experimental Interaction Unit is hacking in social space. Such tactics, long employed 
by programmers, have met with some success in redirecting the discourse of power into distributed networks 
and making centralized control of power more difficult to maintain. EIU attempts to bring those distributed 
networks back into the physical world through their actions and to shake up centralized power in the 
same way. By laying bare our vulnerabilities to both internally and externally generated dangers, EIU 
operates in a manner similar to other contemporary art collectives including Critical Art Ensemble, RTMark, 
the Yes Men, and eToy. Each of these groups replicates systems of bureaucratic control and coercion, 
identified in the sciences and corporations as well as in legislative and defense agencies, in order 
to deconstruct and critique them. References and Notes 1. One example is Natalie Jeremijenko, an engineer 
whose artistic practice centers on dispelling the perceived neutrality of technology. In collaborations 
with the Bureau of Inverse Technology, she has also worked under the rubric of a research corporation. 
Jeremijenko redeploys commercially available products for her own critical purposes. Her Feral Robotic 
Sniffer Dogs (2001-05) are modified versions of mass-marketed toy robots, which anyone can alter according 
to her instructions. For more information, see Timothy Druckrey, Bureau of Inverse Technology_Bit Plane, 
CTRL [SPACE] (Karlsruhe, Germany: ZKM Center for Art and Media, and Cambridge, Massachusetts: Massachusetts 
Institute of Technology, 2002) 603, and the Feral Robotic Sniffer Dogs web site: http://xdesign.ucsd.edu/feralrobots/. 
2. Paulos developed Legal Tender while a PhD candidate in computer science and engineering at the University 
of California, Berkeley, under department chair Ken Goldberg. He received his degree from that department 
in May 2001. ACM SIGGRAPH 96 Visual Proceedings: The Art and Interdisciplinary Programs of SIGGRAPH 96 
(New York: ACM Press, 1996) 43-44. 3. John Canny and Eric Paulos, Tele-Embodiment and Shattered Presence: 
Reconstructing the Body for Online Interaction, The Robot in the Garden: Telerobotics and Telepistemology 
in the Age of the Internet, ed. Ken Goldberg (Cambridge, Massachusetts: Massachusetts Institute of Technology, 
2000) 283. 4. John Canny and Eric Paulos, Tele-Embodiment and Shattered Presence: Reconstructing the 
Body for Online Interaction, The Robot in the Garden: Telerobotics and Telepistemology in the Age of 
the Internet (op. cit.) 283. 5. Experimental Interaction Unit, I-Bomb: http://eiu.org/experiments/i-bomb/tech_killed.html. 
6. Hakim Bey, The Temporary Autonomous Zone, Ontological Anarchy, Poetic Terrorism (New York: Autonomedia, 
1991): http://www.hermetic.com/bey/taz3.html. 7. Experimental Interaction Unit, I-Bomb: http://eiu.org/experiments/i-bomb/tech_killed.html. 
8. Ibid. 9. Experimental Interaction Unit, Dispersion: http://eiu.org/experiments/dispersion/. 10. US 
Department of Homeland Security, Threats &#38; Protection: http://www.dhs.gov/dhspublic/display?theme=29. 
11. Experimental Interaction Unit, Limelight: http://eiu.org/experiments/limelight/info.htm. Annotated 
Bibliography Bey, Hakim, The Temporary Autonomous Zone, Ontological Anarchy, Poetic Terrorism (New York: 
Autonomedia, 1991): http://www.hermetic.com/bey/taz3.html. Christopher, Roy, ExperiMental InterAction, 
Frontwheeldrive (January 26, 2000): http://frontwheeldrive.com/eric_paulos.html. (Interview with Eric 
Paulos. Describes SRL collaboration and future plans. Talks about establishing trust between humans and 
machines through a user interface as a central element of EIU s practice.) Critical Art Ensemble, Flesh 
Machine: Cyborgs, Designer Babies, and New Eugenic Consciousness (New York: Autonomedia, 1998). (Describes 
the phenomenon of technology integrated with the body and the potential sacrifices that this requires 
in exchange for increased human capacity. Written by contemporaries of the artists under consideration.) 
CTRL [SPACE], Rhetorics of Surveillance from Bentham to Big Brother (Karlsruhe, Germany: ZKM Center for 
Art and Media, and Cambridge, Massachusetts: Massachusetts Institute of Technology, 2002). Experimental 
Interaction Unit: http://www.eiu.org/. (Provides detailed descriptions and images of projects, as well 
as Eric Paulos statement about the effect of the 9-11 attacks on his practice and approach.) Federal 
Trade Commission, Identity Theft Survey Report, Synovate (September 2003): http://www.ftc.gov/os/2003/09/synovatereport.pdf/. 
Goldberg, Ken, ed., The Robot in the Garden: Telerobotics and Telepistemology in the Age of the Internet 
(Cambridge, Massachusetts: Massachusetts Institute of Technology, 2000). Hunt, David, Rx for Disaster, 
Rhizome (September 6, 1999): http://www.rhizome.org/ars99/9.html. Lee, Pamela M., Chronophobia: On Time 
in the Art of the 1960s (Cambridge, Massachusetts: MIT Press, 2004). Leopoldseder, Hannes, and Christine 
Schöpf, CyberArts 99: International Compendium Prix Ars Electronica (Vienna and New York: Springer, 1999). 
(Contains a section on Dispersion by Eric Paulos, awarded an Honorable Mention in the category of Interactive 
Art, documenting the project s presence at the festival.) Stanley, Jay, An ACLU Report. The Surveillance-Industrial 
Complex: How the American Government is Conscripting Businesses and Individuals in the Construction of 
a Surveillance Society, American Civil Liberties Union (September 2004): http://www.aclu.org/Privacy/Privacy.cfm?ID=162298c=130. 
Zeller, Tom Jr., Breach Points Up Flaws in Privacy Laws, The New York Times (February 24, 2005). Zero 
News Datapool, The Mythology of Terrorism on the Net : http://www.t0.or.at/cae/mnterror.htm. Anuradha 
Vikram Curator and Critic P.O. Box 5041 Richmond, California 94805 USA durgaakv@gmail.com  Figure 1. 
Legal Tender, &#38;#169; 1996 Legal Tender Mark Pauline, Ken Goldberg, Eric Paulos, John Canny, Judith 
Donath. &#38;#169; 2009 Anuradha Vikram  |  Leonardo, Vol. 42, No. 4, pp. 324 331, 2009  Figure 2. 
I-Bomb v2.0, installed outside the SFMOMA, March 2001. &#38;#169; 1999 Eric Paulos/Experimental Interaction 
Unit. Experimental Interaction Unit  |  Anuradha Vikram  Figure 3. Dispersion, installed at Ars Electronica. 
&#38;#169; 1999 Eric Paulos/Experimental Interaction Unit. Anuradha Vikram  |  Experimental Interaction 
Unit  Figure 4. Dispersion (capsule detail), &#38;#169; 1999 Eric Paulos/ Experimental Interaction Unit. 
 Experimental Interaction Unit  |  Anuradha Vikram  Figure 5. Dispersion (user interface detail), 
&#38;#169; 1999 Eric Paulos/Experimental Interaction Unit.  Figure 6. Limelight, &#38;#169; 2001 Eric 
Paulos/Experimental Interaction Unit. Anuradha Vikram  |  Experimental Interaction Unit Experimental 
Interaction Unit  |  Anuradha Vikram Anuradha Vikram  |  Experimental Interaction Unit Experimental 
Interaction Unit  |  Anuradha Vikram  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667271</article_id>
		<sort_key>60</sort_key>
		<display_label>Article No.</display_label>
		<display_no>5</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[MobiSpray]]></title>
		<subtitle><![CDATA[mobile phone as virtual spray can for painting BIG anytime anywhere on anything]]></subtitle>
		<page_from>1</page_from>
		<page_to>10</page_to>
		<doi_number>10.1145/1667265.1667271</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667271</url>
		<abstract>
			<par><![CDATA[<p>This paper presents <i>MobiSpray</i>, a novel interactive art tool for creating ubiquitous ephemeral digital art. The mobile phone is employed as a virtual spray can to spray dabs of digital paint onto the physical environment via large-scale projections. The gesture-based control of the mobile phone provides a natural pointing mechanism for the virtual spray can. Experiences from extensive field use around the world testify in favor of a successful design. Most importantly, <i>MobiSpray</i> liberates and empowers the artist to change the environment via large-scale artistic expressions.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Paint systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797186</person_id>
				<author_profile_id><![CDATA[81342510272]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J&#252;rgen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheible]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Art and Design Helsinki, Helsinki, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797187</person_id>
				<author_profile_id><![CDATA[81100252483]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Timo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ojala]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Oulu, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blinkenlights: http://www.blinkenlights.net/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Land art: http://en.wikipedia.org/wiki/Land_art.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Environmental art: http://en.wikipedia.org/wiki/Environmental_art.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Christo and Jeanne-Claude: www.christojeanneclaude.net/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Maeda, <i>Creative Code</i> (London: Tames&amp;Hudson, 2004) 121.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Z. Lieberman, <i>Drawn</i> installation (2006): http://www.thesystemis.com/drawnInstallation/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1027704</ref_obj_id>
				<ref_obj_pid>1027527</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Foote, D. Kimber, "Remote interactive graffiti," <i>Proceedings of ACM Multimedia 2004</i> (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1459532</ref_obj_id>
				<ref_obj_pid>1459359</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Scheible, T. Ojala, P. Caulton, "MobiToss: A novel gesture based interface for creating and sharing mobile multimedia art on large public displays," <i>Proceedings of ACM Multimedia 2008</i>, 957--960 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1178838</ref_obj_id>
				<ref_obj_pid>1178823</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Garner, O. Rashid, P. Coulton, R. Edwards, "The Mobile Phone as a Digital SprayCan," <i>Proceedings of the 2006 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology 2006</i>, 1--7 (2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[WiiSpray: http://www.wiispray.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Rackham, "UR SPACE," <i>Filter Magazine</i>, Vol. 67, No. 4 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Claudio Sinatti: http://www.claudiosinatti.com/blog/?cat=13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Krzysztof Wodiczko: http://www.pbs.org/art21/artists/wodiczko/clip2.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Graffiti Research Lab: http://graffitiresearchlab.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Tag tool: http://www.tagtool.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Banksy: http://en.wikipedia.org/wiki/Banksy.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1436491</ref_obj_id>
				<ref_obj_pid>1435641</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Kindberg, M. Chalmers, E. Paulos, "Urban Computing," <i>IEEE Pervasive Computing</i>, Vol. 6, No. 3, 18--20 (2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Sheridan, A. Dix, S. Lock, "Understanding Interaction in Ubiquitous Guerrilla Performances in Playful Arenas," People and Computers XVIII -- Design for Life <i>Proceedings of Human-Computer Interaction 2004</i>, 3--18 (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Digital Fringe: http://digitalfringe.com.au/?q=node/25.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Friedensreich Hundertwasser: http://en.wikipedia.org/wiki/Hundertwasser.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1557545</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Scheible, V. Tuulos, <i>Mobile Python: Rapid Prototyping of Applications on the Mobile Platform</i> (Chichester, England: John Wiley&amp;Sons, 2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Pygame -- python game development: http://www.pygame.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Nintendo Wii remote: http://wii.nintendo.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Graffiti Research Lab: http://graffitiresearchlab.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>985731</ref_obj_id>
				<ref_obj_pid>985692</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[K. Ryokai, S. Marti, H. Ishii, "I/O Brush: Drawing with Everyday Objects as Ink," <i>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems 2004</i>, 303--310 (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[A. Clark, "Minds in space": http://www.indiana.edu/~cogdev/labwork/clark.doc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Banksy, <i>Wall and Piece</i> (London: Century, 2006) 237.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513034</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[P. Dourish, <i>Where The Action Is: The Foundations of Embodied Interaction</i> (Cambridge, Massachusetts: MIT Press, 2001) 55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>861852</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[H. G. Nelson, E. Stolterman, <i>The Design Way: Intentional Change in an Unpredictable World: Foundations and Fundamentals of Design Competence</i> (Englewood Cliffs, New Jersey: Educational Technology Publications, 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[D. H. Parker, <i>The Principles Of Aesthetics</i> (La Vergne: Lightning Source Inc, 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Flash mob: http://en.wikipedia.org/wiki/Flash_mob.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MobiSpray: Mobile Phone as Virtual Spray Can for Painting BIG Anytime Anywhere on Anything Jürgen Scheible, 
Timo Ojala Abstract This paper presents MobiSpray, a novel interactive art tool for creating ubiquitous 
ephemeral digital art. The mobile phone is employed as a virtual spray can to spray dabs of digital paint 
onto the physical environment via large-scale projections. The gesture-based control of the mobile phone 
provides a natural pointing mechanism for the virtual spray can. Experiences from extensive field use 
around the world testify in favor of a successful design. Most importantly, MobiSpray liberates and empowers 
the artist to change the environment via large-scale artistic expressions. Introduction This work stems 
from our desire to change, through digital art, the appearance of the physical environment to something 
different, unexpected, and unpredictable, but without inflicting any permanent or illicit damage. To 
achieve this, we developed the MobiSpray art tool for imposing large-scale ephemeral digital artistic 
projections on the environment. They serve as a vehicle for experiencing space and time in new ways, 
drawing inspiration from both the artistic process itself and the final artistic outcome. MobiSpray combines 
existing technologies into a novel art tool. A mobile phone is employed as a virtual spray can. A drawing 
client on the mobile phone (the virtual spray can) commu­nicates wirelessly with a drawing server on 
a standard PC for the purpose of painting on a virtual canvas. The canvas is projected with a video projector 
onto some backdrop. The projection distance and surface determine the scale, appearance and visibility 
of the resulting artistic presentation. MobiSpray is truly ubiquitous, as the equipment can be carried 
in a rucksack, allowing the creation of ephemeral digital art anytime, anywhere, and on anything (Figure 
1). For us, MobiSpray has become a creative tool to paint wherever we go (Figure 2). At times, we also 
take the opportunity to turn ugly-looking trash into treasure, at least temporarily (Figure 3). All projections 
shown in photos are projections on real buildings or objects. Creating art with mobile phones in public 
spaces is an emerging form of artistic expression. While MobiSpray is related to light art or light graffiti 
(for example, Blinkenlights [1]), it is also a form of mobile interactive art within the field of media 
arts. The ephemeral projections onto the environment relate the MobiSpray to land art [2] or environmental 
art [3] (for example, Christo [4]), in which the landscape and the artwork are inextricably linked, and 
the intention of the artist is to cause no harm to nature or environment through the artwork. The innovative 
aspect of MobiSpray lies in the provision of a novel, portable, gesture-controlled art tool for creating 
large-scale, full-color projections in the environment in real time. Related drawing interfaces include 
Cho s motion-sensitive brush [5], whose big movements result in big strokes while smaller ones produce 
thinner lines. In Drawn [6], painted ink forms appear to come to life, rising off the page to interact 
with the very hands that drew them. Remote interac­tive graffiti [7] invites distributed internet participants 
to draw via a browser-enabled interface on a common (installation based) canvas such as a white board 
or a projection on the sidewalk of a street. MobiSpray employs the gesture control of a mobile phone 
to provide a natural interface that allows the phone to be manipulated as a spray can for painting. Related 
work includes MobiToss, a rare example of employing a gesture-controlled mobile phone as an art tool 
[8]. In MobiToss, a photo or video is first captured with a camera phone and then thrown onto a public 
display for the purpose of manipulating it with effects and gesture control. Garner, Rashid, Coulton 
and Edwards employed a mobile phone as a digital spray can for the purpose of reading and writing RFID 
tags attached to particular locations, as the digital age s virtual and undamaging version of the genuine 
spray-can graffiti [9]. The WiiSpray turns a real spray can into a digital spray can by placing a Nintendo 
Wii controller inside the can to create digital graffiti on a TV set [10]. Projections have been widely 
used for creating artistic installations as interventions in physical and social space. Artists discard 
barricades and insert themselves into streets, laneways, alleys and shopping centers [11]. For example, 
Sinatti has used a 40-inch touch-screen display to paint and project on huge surfaces [12], and Wodiczko 
has created large-scale video projections of politically charged images on architectural façades and 
monuments worldwide [13]. Some projection-based installations involve different interactive techniques. 
For example, GRL s Laser Tag tracks a green laser pointer across the face of a building, generates graphics 
based on the laser pointer s position, and projects them back onto the building [14]. Tagtool is a VJ 
tool and drawing instrument that utilizes a graphics tablet and controllers to create animated graphics 
for video projections [15]. A particular artistic movement that builds heavily on video projections is 
guerilla art known through artists like Banksy [16]. It is closely related to urban street art, a subtopic 
of the emerg­ing research field of urban computing, which studies the integration of computing technologies 
into everyday urban settings and lifestyles [17]. Due to their complex ownership and legal ramifications, 
urban settings are challenging places for experimentation and deployment, as the installation and operation 
of an application or an art piece typically require permissions from many stakeholders. Thus it is no 
surprise that the inherent freedom of playful arenas combined with intimate ubiquitous technologies such 
as video projection has led to a new breed of guerrilla performances [18]. For example, Digital Fringe 
s Mobile Projection Unit supports guerrilla art by providing a car, a projector, and batteries to various 
Melbourne pixelists [19]. The painter, architect, and sculptor Hundertwasser is known for expressing 
his artistic vision in pictorial art on façades [20]. The MobiSpray Art Tool System components MobiSpray 
is a simple client-server application comprised of three components (Figure 4, left): a mobile drawing 
client, a simple drawing server operating on a PC, and a video projector for projecting the current drawing 
onto some surface. The mobile drawing client (Figure 5) is implemented with Python for an S60 Symbian 
camera phone with a built-in motion sensor for the gesture-controlled pointing mechanism (for example, 
Nokia N95) [21]. Keyboard keys are used for controlling the drawing tools. The client communicates with 
the server using the UDP protocol over a WLAN (IEEE 802.11b/g) connection. WLAN provides sufficiently 
low latencies for real-time interaction and allows communication over much greater distances than Bluetooth. 
The drawing server programmed with Pygame receives drawing commands from the client and renders them 
accordingly on the drawing canvas displayed on the PC s screen [22]. The video projector projects the 
screen (the current drawing) onto some surface or backdrop. If no electric­ity plug is expected to be 
found in the drawing location, a portable petrol-driven generator or a battery with a DC/AC converter 
can be brought along. Gesture-controlled pointing mechanism with a zoomable navigator The current drawing 
area is indicated with a black rectangular navigator placed within the drawing canvas corresponding to 
the white region in Figure 5. The size of the navigator can be changed with a keyboard key, ranging from 
the full canvas to the minimum size of 100 x 100 pixels. In this way the level of detail can be changed 
dynamically, from painting on the entire canvas to inserting tiny details, such as the character 3 and 
the word by in Figure 4 (right). The location of the navigator within the canvas is controlled with the 
phone s navigation key. The gesture control of the pointing mecha­nism is implemented by mapping the 
phone s motion-sensor readings onto x and y coordi­nates within the navigator in real time. When the 
phone is held flat horizontally to the ground, the motion sensor generates the value 0 for both x and 
y axis, and the drawing blob is placed at the centre of the navigator. When the phone is tilted between 
0 and 90 degrees to the left/right or forward/backward, the values change incrementally between 0 and 
-50/+50 in steps of 1, and the blob is moved accordingly from the centre of the navigator towards left/right/upper/lower 
edge. The two major advantages of this pointing mechanism are that it does not require any calibration 
before use or any pointing signal receiver such as the sensor bar in Wii [23], or the camera in GRL s 
Laser Tag [24]. Virtual spraying nozzles The user can choose among four different drawing modes, each 
representing a virtual spraying nozzle. In the blob mode, the nozzle creates a simple color blob on the 
canvas consisting of a circular element with a color fill. In the brush mode, the nozzle randomly creates 
a multitude of pixels of the same color within a certain radius. In the image mode, the nozzle places 
plain images on the canvas. In the stencil mode, the nozzle places stencils on the canvas to spray on. 
In the blob and brush modes, the blobs are continuously drawn on the canvas with high frequency. In idle 
state (when the phone s navigation key is not pressed), previous blobs are overwritten. However, if the 
user presses the phone s navigation key, which is comparable to pressing the nozzle on a real spray can, 
previous blobs are no longer overwritten, but by moving the blob with hand gestures a color trace is 
created (Figure 6). In the image mode, the image to be placed on the canvas can either be chosen from 
the image files residing on the phone, or it can be captured with the camera of the phone and sent over 
to the drawing server. The image can be placed either once or multiple times at any position, such as 
the MobiSpray logo and photo in Figure 4 (right). Alternatively, the image can be used for image brush 
painting comparable to the I/O Brush [25]. The user can also spray instantly into the image by switching 
back to the blob or brush mode (Figure 7). In the stencil mode, images and related image masks can be 
chosen from ready-made files residing on the phone or on the server. The stencil can be moved around 
with gesture control and is placed at the desired position by pushing the navigation key once. Switching 
to the brush mode allows spraying onto the stencil s empty areas. The stencil is removed by pressing 
the hash key. Multi-user mode The MobiSpray can also be employed in multi-user mode, which allows collaborative 
drawing by up to four people simultaneously (Figure 8). The canvas can be split between the multiple 
users in three different ways: the full canvas accessible by all users (one user can draw on top of another 
user s), each user with an individual section, or user-specific sections that are partially overlapping. 
Some Design and Artistic Aspects of the MobiSpray The MobiSpray art tool has been used extensively throughout 
the world, both privately during guerilla spraying sessions in New York (painting at the Guggenheim and 
New Museums), Sydney (Opera House premises) and London (Houses of Parliament and the Tate Modern) and 
in many public events, such as the Urban Screens 2008 festival in Melbourne or the Web 2.0 event in New 
York. In the following sections, we discuss various design and artistic aspects that have become prominent 
in the field use. We enclose some user comments in italics. They originate from three different sessions 
where a total of 17 people (age 13-70 years) were video-interviewed after they had sprayed. They were 
passers-by at Melbourne s Federation Square, where we had a fixed installation of MobiSpray over several 
days; or visitors at the London Smartphone Show evening party where an indoor MobiSpray setup served 
as entertainment; or a group of new-media enthusiasts at an ad-hoc guerilla spraying occasion in downtown 
Vancouver. Natural interaction with transparent equipment It s quick to understand what you can do, and 
you can instantly do it. Although MobiSpray s gesture-controlled pointing mechanism may sound clumsy, 
novice users typically learn it quickly and find painting with the virtual spray can natural. An important 
aspect of the gesture-controlled interaction is that one can draw by moving the hand without looking 
at the mobile phone. This demonstrates the concept of transparent equipment [26], in which the user sees 
through the equipment to the task at hand, such as when you sign your name, the pen is not normally your 
focus unless it is out of ink. Liberating and empowering the artist This is fascinating, now I understand 
why kids do graffiti. I like that it is not premade content to view. This has been the biggest picture 
I ve ever painted in my life. MobiSpray liberates and empowers the artist on many complementary levels. 
With the movable equipment, the artist can effectively start painting anytime, anywhere, on anything. 
MobiSpray allows artists to reach and access the surface of a building, even if they do not own it or 
have the keys for it. Fences, closed yards or large heights are not a problem, but in fact may present 
interest­ing opportunities for guerilla art. MobiSpray allows not only painting on man-made objects such 
as buildings, but also on nature, revealing highly exciting surface patterns (Figure 9). While painting 
on objects like sculptures has been done for a long time, it has not been possible to paint on nature 
in such a clean and eco-friendly way as with MobiSpray. When painting on snow sculptures (Figure 4), 
for example, we could even speak of 100% recyclable art. A great advantage of MobiSpray over traditional 
graffiti and painting techniques is that the artist can digitally preview the placing of a new blob, 
and with an undo key, the artist can always go back. Thus, with MobiSpray, the artist can visualize future 
compositions and explore the consequences of bringing a particular composi­tion into existence. Furthermore, 
the artist can spray exactly the type of art desired (for example, graphics can be mixed with photos). 
Legalizing the artist First I didn t dare to do it because you have some kind of illegal feeling, but 
then when you do it it feels liberating. I like the fact that your painting goes away, and you live the 
moment while you create it. It reminds me of Buddhist sand paintings. Whereas guerilla actions such as 
traditional spray-can graffiti sometimes cause damage to property or the environment, MobiSpray legalizes 
the artist since the outcome is an ephemeral digital projection that does no permanent damage to the 
property. Nevertheless, the question of legal implications remains, especially in urban spaces. Despite 
the ephemeral nature of Mobi-Spray projections, some artists confessed that they felt guilty or naughty 
as they spray-painted public buildings. Apparently, the artists should go with the street artist Banksy 
s motto: It s always easier to get forgiveness than permission [27]. Embodied interaction with physical 
objects MobiSpray allows the artist to roam freely (walk, stand, lie) around the target object, far or 
near in real physical space, while looking directly at its surface to see how the painting appears in 
real time (Figure 10). This allows the artist to draw inspiration for a composition directly from the 
object itself and its context. This is a form of embodied interaction where the artist s interaction 
with physical objects is augmented by computational abilities [28]. Mental ownership of physical objects 
A strong observation about MobiSpray has been that after painting on a building or some object, the artist 
feels a sense of ownership of the physical object. By adding something new (the painting) to something 
that already exists (a building or rock), a new whole is created. The experience of the creative process, 
which results in a deep insight of consequence, contributes to the creation of new meaning and value. 
This new whole is perceived as one s own creation [29]. Aesthetics of the resulting drawings The process 
that leads to the aesthetic outcome often starts with searching and selecting a designated architectural 
façade or object to serve as the pictorial backdrop. Creating the visual expression not only involves 
transform­ing the building or object by projecting ready-made imagery, signs, or letters on its surface, 
but also, through the very colors (combina­tions), lines, or shapes used in the drawing, producing an 
aesthetic and emotional response. In this way, through some grace of line, symmetry of form or harmony 
of color, the designated building or object acquires new power to communicate with the artist or viewer. 
It becomes alive and of value on its own account, just like the trash turning into treasure (Figure 3). 
As a base for drawing, simple adjustable graphical elements such as a circle (blob or brush) or line 
are used to create the overall visual form or focus of the compositions. Whereas repetition of symmetrical 
rings (bull s-eyes) and splashes give rhythm, logic, and balance, their placement is often orientated 
on the shape of the building or object. The drawing allows artists to break the patterns of the objects 
natural appearance, creating a new whole with its own aesthetic value. An acquired drawing style might 
be explained by Parker s claim that the drawing effects, found by chance perhaps in the first instance, 
would later be created consciously [30]. The question is, if the MobiSpray tool is given to other people, 
could they produce something that looked like it was not made with MobiSpray? When artists build the 
tool for themselves, they adjust that tool to support what they want to express in the manner they want 
to see it. What is interesting is that while this mannerism is supported by the tool, it is not the tool 
itself. Results from our field tests show a wide variety of drawing outcomes made by different people 
using MobiSpray, which indicates that a variety of drawing styles can emerge with this tool. Multi-user 
and spectator view This is fascinating, I have never seen something like that before. We liked the abstract 
thing, playing with colors. When MobiSpray is employed in the multi-user mode, the artists have great 
fun together, both collaboratively working toward a common goal and destroying each other s contributions. 
For example, the group in Figure 8 met for the first time at the MobiSpray stand. After a short period 
of random painting, they started to negotiate and agreed on the themes and colors to draw collaboratively. 
Furthermore, our experiences from field use underline the role of the spectators in the social setting. 
People often gather close by, watching and commenting on the work of the artists, and contributing to 
the social atmosphere by laughing and shouting. Future Work As the current version of MobiSpray still 
needs several hundred watts of electricity, we are exploring opportunities to allow a spectator crowd 
to generate electricity and thus become part of collaborative artwork creation. Furthermore, by building 
a cluster of MobiSpray units with multiple projectors, we aim to paint whole neighborhoods of a city 
in a flash-mob manner [31]. Other concepts that could be attached to MobiSpray are media activism, urban-planning 
simulation, or theater and music performances. In order to achieve a wider variety in visual styles, 
we will create additional spraying nozzles, as well as a stencil-creation functionality utilizing the 
phone s camera. We are also developing a lightweight implementation based on a battery-driven pico projector 
for creating small-scale projections. Conclusion MobiSpray combines a personal mobile phone, a PC and 
a video projector into a novel art tool for creating ubiquitous digital art. Experiences from extensive 
field use testify in favor of successful design, liberating and empowering artists to change their surroundings 
at their own will, in an ephemeral manner. An off-the-shelf mobile phone has proven to be highly attractive 
as an interface for a virtual spray can, not only because it is personal, ubiquitous, and wirelessly 
connected. It is also a freehand drawing tool for virtual color spraying, an image-capturing device, 
and a processing unit for handling digital stencils. Providing a high degree of freedom, it affords the 
luxury of painting while at the same time roaming around your target object in real physical space, near 
or far. References 1. Blinkenlights: http://www.blinkenlights.net/. 2. Land art: http://en.wikipedia.org/wiki/Land_art. 
3. Environmental art: http://en.wikipedia.org/wiki/Environmental_art. 4. Christo and Jeanne-Claude: www.christojeanneclaude.net/. 
5. J. Maeda, Creative Code (London: Thames &#38; Hudson, 2004) 121. 6. Z. Lieberman, Drawn installation 
(2006): http://www.thesystemis.com/drawnInstallation/. 7. J. Foote, D. Kimber, Remote interactive graffiti, 
Proceedings of ACM Multimedia 2004 (2004). 8. J. Scheible, T. Ojala, P. Caulton, MobiToss: A novel gesture 
based interface for creating and sharing mobile multimedia art on large public displays, Proceedings 
of ACM Multimedia 2008, 957-960 (2008). 9. P. Garner, O. Rashid, P. Coulton, R. Edwards, The Mobile Phone 
as a Digital SprayCan, Proceedings of the 2006 ACM SIGCHI International Conference on Advances in Computer 
Entertainment Technology 2006, 1-7 (2006). 10. WiiSpray: http://www.wiispray.com/. 11. M. Rackham, UR 
SPACE, Filter Magazine, Vol. 67, No. 4 (2008). 12. Claudio Sinatti: http://www.claudiosinatti.com/blog/?cat=13. 
13. Krzysztof Wodiczko: http://www.pbs.org/art21/artists/wodiczko/clip2.html. 14. Graffiti Research Lab: 
http://graffitiresearchlab.com/. 15. Tag tool: http://www.tagtool.org/. 16. Banksy: http://en.wikipedia.org/wiki/Banksy. 
17. T. Kindberg, M. Chalmers, E. Paulos, Urban Computing, IEEE Pervasive Computing, Vol. 6, No. 3, 18-20 
(2007). 18. J. Sheridan, A. Dix, S. Lock, Understanding Interaction in Ubiquitous Guerrilla Performances 
in Playful Arenas, People and Computers XVIII Design for Life Proceedings of Human-Computer Interaction 
2004, 3-18 (2004). 19. Digital Fringe: http://digitalfringe.com.au/?q=node/25. 20. Friedensreich Hundertwasser: 
http://en.wikipedia.org/wiki/Hundertwasser. 21. J. Scheible, V. Tuulos, Mobile Python: Rapid Prototyping 
of Applications on the Mobile Platform (Chichester, England: John Wiley &#38; Sons, 2007). 22. Pygame 
 python game development: http://www.pygame.org. 23. Nintendo Wii remote: http://wii.nintendo.com. 24. 
Graffiti Research Lab: http://graffitiresearchlab.com/. 25. K. Ryokai, S. Marti, H. Ishii, I/O Brush: 
Drawing with Everyday Objects as Ink, Proceedings of the SIGCHI Conference on Human Factors in Computing 
Systems 2004, 303-310 (2004). 26. A. Clark, Minds in space : http://www.indiana.edu/~cogdev/labwork/clark.doc. 
27. Banksy, Wall and Piece (London: Century, 2006) 237. 28. P. Dourish, Where The Action Is: The Foundations 
of Embodied Interaction (Cambridge, Massachusetts: MIT Press, 2001) 55. 29. H.G. Nelson, E. Stolterman, 
The Design Way: Intentional Change in an Unpredictable World: Foundations and Fundamentals of Design 
Competence (Englewood Cliffs, New Jersey: Educational Technology Publications, 2003). 30. D.H. Parker, 
The Principles Of Aesthetics (La Vergne: Lightning Source Inc, 2003). 31. Flash mob: http://en.wikipedia.org/wiki/Flash_mob. 
 Jürgen Scheible Artist University of Art and Design Helsinki Media Lab Hämeentie 135 C, 00560 Helsinki, 
Finland jurgen.scheible@taik.fi Timo Ojala Educator MediaTeam Oulu Research Group University of Oulu 
P.O.Box 4500 90014 University of Oulu, Finland timo.ojala@ee.oulu.fi  Figure 1. MobiSpray in action. 
&#38;#169; 2008 Jürgen Scheible. &#38;#169; 2009 Jürgen Scheible, Timo Ojala  |  Leonardo, Vol. 42, 
No. 4, pp. 332 341, 2009  Figure 2. Examples of MobiSpray s World Tour: Potts Point Neighborhood, Sydney 
(upper left), Guggenheim Museum, New York (upper right), Houses of Parliament, London (lower left), Siwash 
Rock, Vancouver (lower right). &#38;#169; 2008 Jürgen Scheible. MobiSpray  |  Jürgen Scheible, et 
al.  Figure 3. Trash to treasure. &#38;#169; 2008 Jürgen Scheible. Jürgen Scheible, et al.  |  MobiSpray 
 Figure 4. MobiSpray system components (left), painting on a snow sculpture (right). &#38;#169; 2008 
Jürgen Scheible.  Figure 5. The user interface of the mobile drawing client. &#38;#169; 2008 Jürgen 
Scheible. MobiSpray  |  Jürgen Scheible, et al.  Figure 6. Painting made with the brush nozzle mode. 
&#38;#169; 2008 Jürgen Scheible. Figure 7. Painting into photo images. &#38;#169; 2008 Jürgen Scheible. 
 Jürgen Scheible, et al.  |  MobiSpray  Figure 8. Multi-user mode. &#38;#169; 2008 Jürgen Scheible. 
 MobiSpray  |  Jürgen Scheible, et al.  Figure 9. Painting exposes the surface patterns on a stone 
in a forest. &#38;#169; 2008 Jürgen Scheible. Jürgen Scheible, et al.  |  MobiSpray  Figure 10. Mobile 
drawing client allows the artist to roam freely around the object while painting. &#38;#169; 2008 Jürgen 
Scheible. MobiSpray  |  Jürgen Scheible, et al. Jürgen Scheible, et al.  |  MobiSpray MobiSpray 
 |  Jürgen Scheible, et al.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667272</article_id>
		<sort_key>70</sort_key>
		<display_label>Article No.</display_label>
		<display_no>6</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[A new system to appreciate the visual characteristics of a painting]]></title>
		<page_from>1</page_from>
		<page_to>8</page_to>
		<doi_number>10.1145/1667265.1667272</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667272</url>
		<abstract>
			<par><![CDATA[<p>A painting-viewing system is proposed as a tool to help painting appreciation and to improve the museum experience. This system simultaneously highlights certain visual characteristics of multiple paintings, thus informing users of the links between paintings and the semantic elements that may appear superficially different, and also conveying the art-historical explanation of those characteristics. Through this system's evaluation, the approach based on "the awareness of the visual characteristics" may be effective as a method of developing the user's interest in the paintings. When this system is placed in museums and galleries as a mediation tool, it will be useful to a viewer's preparation for the art-viewing experience. This paper presents the concepts behind the system's development and the results of the first survey as a piece of a larger project to explore the improvement of painting appreciation as a museum experience.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Paint systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797188</person_id>
				<author_profile_id><![CDATA[81442609067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tsutomu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miyashita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DNP Digitalcom Co., Ltd., Shinagawa-ku, Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Hall, J. and Clark, K., <i>Dictionary of Subjects and Symbols in Art</i> (London: John Murray Ltd., 1974) 7--12, 15--17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Clark, K., <i>Looking at Pictures</i> (New York: Holt Rinehart and Winston, 1960) 15--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Zeki, S., <i>Nou wa Ikani Bi wo Kanjiruka (Inner Vision: An Exploration of Art and the Brain)</i>, trans. J. Kawachi (Tokyo: Nikkei Inc., 2002) 26--31, 34--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Eternal Egypt, "Connections page," 2005: http://www.eternalegypt.org/EternalEgyptWebsiteWeb/HomeServlet?ee_website_action_key=action.display.context&language_id=1, Proceedings of Communication of The ACM, 2004, 46, 7, 9--10.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[aiSee, "force-directed layout as examples of the graph representation," 2001: http://www.aisee.com/cgi-bin/examples?topic=2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hockenberry, M., "Creative Synthesis: Graph gear page": http://www.creativesynthesis.net/recycling/graphgeardemo/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Nakamura, Y., "MoMA The Museum of Modern Art: Design and the Elastic Mind," 2008: http://www.moma.org/exhibitions/2008/elasticmind/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1357179</ref_obj_id>
				<ref_obj_pid>1357054</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gustafson, S., Baudisch, P., Gutwin, C., Irani, P., "Wedge: Clutter-Free Visualization of Off-Screen Locations," <i>Proceedings of Computer Human Interaction 2008</i>, 787--796 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A New System to Appreciate the Visual Characteristics of a Painting Tsutomu Miyashita Abstract A painting-viewing 
system is proposed as a tool to help painting appreciation and to improve the museum experience. This 
system simultaneously highlights certain visual characteristics of multiple paintings, thus informing 
users of the links between paintings and the semantic elements that may appear superficially different, 
and also conveying the art-historical explanation of those characteristics. Through this system s evaluation, 
the approach based on the awareness of the visual characteristics may be effective as a method of developing 
the user s interest in the paintings. When this system is placed in museums and galleries as a mediation 
tool, it will be useful to a viewer s preparation for the art-viewing experience. This paper presents 
the concepts behind the system s development and the results of the first survey as a piece of a larger 
project to explore the improvement of painting appreciation as a museum experience. Introduction When 
viewers peruse a painting, it does not provide us with a verbal explanation of itself. However, if they 
pay attention to the semantic information contained in the visual characteristics of the painting, this 
may provide cues for how to appreciate it. For example, in religious paintings the saints were depicted 
with similar visual characteristics even by different artists. These charac­teristics were consistent 
as semantic elements of the paintings in their art-historical context. Thus, iconography was a central 
concern in development of this new system of assisting art appreciation [1]. Calling attention to such 
visual characteristics can enhance viewers capacity for art appreciation when they look at paintings 
of similar genres in museums and galleries. In this painting-viewing system, as in all art appreciation, 
the starting point remains the most fundamen­tal act of seeing. The system visually highlights the noteworthy 
characteristics of the painting and provides their semantic context based on art history. The characteristic 
elements of the painting are highlighted so that viewers can become more visually aware of the painting 
and its various aspects. Moreover, the characteristic elements of multiple paintings are shown concur­rently 
in order to compare the semantic elements. This system was developed to enhance viewers perception of 
the art-historical context through awareness of semantic elements linking multiple paintings. Previous 
Work There is much previous research on art appreciation from the perspective of the visual perception 
of art, and this work has provided penetrating insights into the methods of art appreciation. Clark has 
described an approach to art appreciation and how to read paintings through their visual features and 
art historical significance [2]. The relationship between the visual system of the human brain and art 
appreciation has also been explored. Various artworks and artists opinions about looking at art have 
been cited, leading to a definition of the experience of art perception [3]. Earlier projects have explored 
the connection between different art works in an examination of interface design [4]. However, the focus 
there was on presenting information in graphic and relational data form [5]. In terms of interface design, 
this project referred to the Museum of Modern Art s web site, Design and the Elastic Mind [6]. As Clark 
has pointed out that viewers need active participation in order to appreciate a painting at the early 
stage, the focus was on the visual characteristics of paintings as effective elements for the viewers. 
The project assumed that when viewers notice the visual characteristics as semantic elements in multiple 
paintings, they then perceive the clue for appreciating painting. This approach should provide a new 
method of developing viewers perceptions by relating visual elements to verbal understanding. Content 
Development In structuring the content, the system extracts visual characteristics from the paintings 
as semantic elements, then expresses those characteristics as a unified set in semantic terms. Figure 
2 shows the information struc­ture provided by this system. A painting s visual characteristics and the 
links with its respective keywords are emphasized. The keywords are not simply verbalizations of what 
can be seen with the eyes; rather, they are meta-keywords that help users to generally remember the visual 
characteristics as semantic elements. Moreover, the short phrases (hereafter, key sentences) include 
the keywords that explain the context of the visual characteristics based on art history. The keyword 
in Figure 3 shows that the visual characteristics of multiple paintings can be expressed. This allows 
users to understand the points of connection between paintings that seem at first glance to have different 
visual characteristics. The information structure is organized so that the key sentence includes the 
keyword, providing an easily understandable structure: painting s visual characteristics -> keyword -> 
key sentence. Selecting the artworks, deciding on the key sentences and visual characteristics, and preparing 
the final version in art-historical context according to the content structure were the responsibility 
of the painting department of the Musée du Louvre. The museum team featured 17th-century European paintings 
as the theme for the system because of its diverse wealth of excellent painters, such as Rembrandt and 
Vermeer, and the abundant availability of their characteristic works. They selected approximately 120 
examples for use in the system. They also described key sentences expressing 29 themes, with each theme 
highlighting the common visual characteristics of several paintings selected from the entire database 
of 120 paintings. The key sentences explain the visual features of each genre of 17th-century European 
painting (for example, genre scenes, portraits, and landscapes) in art-historical terminology. Moreover, 
two or three key terms within the sentences for each painting are visually linked to specific visual 
characteristics of the painting. Device Design Since the purpose of this device is to evaluate the concept, 
the first prototype adopted commer­cially available products. Efforts were made in the planning process 
to provide imagery that is as large as possible, along with simultaneous display of multiple images. 
The system employs liquid-crystal display panels to provide the high-quality images necessary for viewing 
the paintings. As Figure 4 shows, the display consists of a Sharp 65-inch main screen, with three Sharp 
21-inch sub-screens arranged horizontally beneath the main screen. All four screens are equipped with 
touch-panel functions. Interface Design The content is structured using two basic models for on-screen 
presentation. The first screen serves as a catalogue that stores entire paintings selected by users; 
the second displays multiple paintings and the links between their semantic elements. The interface for 
the first screen was designed for the user to select a painting from among images aligned in a sequence 
determined by the curator. Figure 5 shows the first screen, where users select the painting image that 
interests them. By scrolling the wall to the right or left, the user can glance through all of the paintings 
included in the system. When the user clicks on an image of a painting, as seen in Figure 6, the painting 
appears in the center of the main screen, which simultane­ously displays visual features from related 
paintings. The interface enables the user to intuitively notice how those characteristics are linked 
to other paintings. Connections between the selected painting and the related paintings are graphically 
indicated by connecting lines. Figure 6 shows the paintings on the main screen with the keywords that 
explain the connections between the images, displaying them as a unified set formed by links between 
semantic elements. The limitations of screen resolution prevent display of all of the related paintings 
in the same keyword, so some of the lines run to the edge of the screen, suggesting the presence of other 
images off-screen at their endpoints [7]. Figure 7 shows how giving attention to specific visual characteristics 
changes the animation. The characteristic features of each painting are highlighted according to keyword, 
a view shown whenever the user selects the image of a painting. The attention of the user is focused 
on the visual characteristics of the paintings through repeated viewing of these semantic elements. The 
view of the highlighted characteristics is brief, so a redisplay function is embedded in the icon of 
the keyword. Figure 8 also shows the animation of the circle used to draw the user s attention to the 
key sentence. The timing and order of the display of content are designed to lead the user s gaze from 
the noteworthy characteristics of the image to the text. In terms of user interface, system operation 
has been simplified, focusing on a click-style touching of buttons and images of paintings on both the 
main and sub-screens. Assuming that users will touch all of the displayed images on the main screen, 
the touch function was imbedded in all images and buttons. Figure 9 shows changes in the screen accord­ing 
to which button or image was selected by the user. In particular, it is hoped that users will reconfirm 
the link between the paintings by using the functions to display their visual characteristics. Implementation 
The contents were constructed using Flash technology from Adobe Systems Incorporated. The main and sub-screen 
content is controlled by Adobe Flash Media Server (hereafter, FMS). Utilizing FMS functions, the system 
can synchronize and provide smooth animation between main and sub-screen content. The information architecture 
consists of XML (Extensible Markup Language) files that are loaded into a Flash movie. Figure 10 shows 
the structure of the XML: Painting_master.xml and Keyword_relation.xml are composed of systematized identification 
codes, while Painting_detail.xml, Keyword_detail.xml, and Sentence_detail.xml are rendered in three 
languages (Japanese, English, and French) for text display on the screen. Observation and User Response 
The prototype of this viewing system was completed on 4 December 2008, and evalua­tion is still in progress. 
For this evaluation, as seen in Figure 11, users were classified into four categories according to the 
frequency of their visits to museums and their level of interest in or knowledge of art. A pilot survey 
performed observational research and inter­views with the cooperation of seven subjects distributed among 
these four categories. Of the seven interviewed, six said that they could see some kind of relationship 
between the multiple paintings. They also felt that explanation by linking the visual features of multiple 
paintings would provide a new and interesting way to appreciate art. However, the subjects could not 
immediately grasp that the key sentences explain those related features. The idea of key sentences explaining 
visual characteristics in comprehensible terms was impressive to the subjects. However, they experienced 
difficulty understanding the key sentences with conceptual expressions or technical terms and lost interest 
before they finished reading. Three subjects, including two from category 1, said that the key sentences 
were too abstract and difficult to understand. Two subjects belonged to category 2; they showed interest 
in the system s approach of linking multiple paintings by semantic elements. In their interviews, they 
stated that they were aware of the paintings noteworthy points. Moreover, they realized that the system 
s approach was related to their previous museum experiences. The subjects in category 4 said that they 
understood the concept and purpose of this system, but given their knowledge and experience of art, they 
felt that the system s explanations were too general and not meaningful for them. Rather, they hoped 
for more specific information, such as the artist s biography, or deeper descriptions of the works and 
their techniques. They also said that they were able to notice paintings that they usually would have 
overlooked for not being famous, because multiple paintings were displayed simulta­neously. They understood 
the display of multiple paintings as a new exhibition method employing the semantic elements of the paintings. 
They acknowledged the importance of this trial and felt that if such a system were used in a museum, 
its explanation of a painting s visual characteristics would be useful to prepare viewers to appreciate 
it. In the observational research, six subjects turned their gaze from the images of the paintings to 
the key sentence, following the animation. Most of the subjects focused on browsing through the painting 
images. No subjects used all of the functions. However, according to the interview result, the satisfaction 
rating of this system was high from the subjects who used most of the functions. Conclusion The subjects 
of the first survey were positive about the concept of this system. The basic idea, noticing the visual 
characteristics of multiple paintings, was accepted by the subjects. Given the small size of the first 
survey group, we cannot at present definitively describe the effect of the system. However, this approach, 
based on awareness of visual characteristics, was effective in developing user interest in the paintings 
by displaying the links between the visual charac­teristics of multiple paintings. The survey results 
from subjects in categories 2 and 4 indicate the effectiveness of this system for use in viewer preparation 
for art appreciation. These results will be helpful for advancing development of this system. However, 
the survey shows this approach may be more suitable for art admirers than art beginners. Since art beginners 
are our secondary target, the information structure and content will be examined to make this system 
more useful to them. Continuing evaluation of this system will look for more useful ways to provide painting 
appreciation hints to the user and make learning based on awareness of visual characteristics more intuitive. 
Future Work The goal of this project was to develop tools to help viewers understand paintings by creating 
an awareness of their visual characteristics. The project will continue to develop the process of editing 
and composing the content giving deeper consideration to what the system should convey and how it should 
be used. Production of the animation and the interaction design must also be carefully considered. From 
the user s perspective, this system development will aim toward simple interface design and interaction, 
regardless of how rich or complex the content might be. Acknowledgement Thanks to Professor Hiroshi Ishii 
and Leonardo Bonanni for helpful discussion. Thanks also to the anonymous SIGGRAPH reviewers for their 
astute comments and suggestions. This work was supported by Natacha Villeroy, Gentaro Teshima, and other 
members of the Louvre DNP Museum Lab project. Also, special thanks to Ingrid Fersing and Blais Ducos, 
curators in the Paintings Department of the Musée du Louvre, who created the painting list and provided 
academic resources. References 1. Hall, J. and Clark, K., Dictionary of Subjects and Symbols in Art (London: 
John Murray Ltd., 1974) 7-12, 15-17. 2. Clark, K., Looking at Pictures (New York: Holt Rinehart and 
Winston, 1960) 15-18. 3. Zeki, S., Nou wa Ikani Bi wo Kanjiruka (Inner Vision: An Exploration of Art 
and the Brain), trans. J. Kawachi (Tokyo: Nikkei Inc., 2002) 26-31, 34-36. 4. Eternal Egypt, Connections 
page, 2005: http://www.eternalegypt.org/EternalEgyptWebsiteWeb/ HomeServlet?ee_website_action_key=action.display.context&#38;language_id=1, 
Proceedings of Communication of The ACM, 2004, 46, 7, 9-10. 5. aiSee, force-directed layout as examples 
of the graph representation, 2001: http://www.aisee.com/ cgi-bin/examples?topic=2. 6. Hockenberry, M., 
Creative Synthesis: Graph gear page : http://www.creativesynthesis.net/recycling/ graphgeardemo/. 7. 
Nakamura, Y., MoMA The Museum of Modern Art: Design and the Elastic Mind, 2008: http:// www.moma.org/exhibitions/2008/elasticmind/. 
8. Gustafson, S., Baudisch, P., Gutwin, C., Irani, P., Wedge: Clutter-Free Visualization of Off-Screen 
 Locations, Proceedings of Computer Human Interaction 2008, 787-796 (2008). Tsutomu Miyashita Researcher 
DNP Digitalcom Co., Ltd. 3-5-20, Nishigotanda, Shinagawa-ku Tokyo 141-8001 Japan t-miyashita@digicom.dnp.co.jp 
 Figure 1. The characteristic elements of multiple paintings are displayed concurrently in order to 
indicate the shared elements and links between their meanings. &#38;#169; 2008 DNP Co., Ltd. &#38;#169; 
2009 Tsutomu Miyashita  |  Leonardo, Vol. 42, No. 4, pp. 342 349, 2009  Figure 2. Connection between 
visual characteristics of painting and terms. &#38;#169; 2008 DNP Co., Ltd., Musée du Louvre.  Figure 
3. Keyword for multiple paintings with shared visual characteristics. &#38;#169; 2008 DNP Co., Ltd. , 
Musée du Louvre. A New System  |  Tsutomu Miyashita  Figure 4. The display. &#38;#169; 2008 DNP Co., 
Ltd. Tsutomu Miyashita  |  A New System  Figure 5. Overview of images lined up in a row. &#38;#169; 
2008 DNP Co., Ltd.  Figure 6. Interface design: placement of selected painting and surrounding connected 
paintings. &#38;#169; 2008 DNP Co., Ltd., Musée du Louvre. A New System  |  Tsutomu Miyashita  Figure 
7. A sequence of animation to emphasize the visual characteristics. &#38;#169; 2008 DNP Co., Ltd. Tsutomu 
Miyashita  |  A New System  Figure 8. Display leading the gaze to key sentences. &#38;#169; 2008 DNP 
Co., Ltd., Musée du Louvre.  Figure 9. All main screen functions. &#38;#169; 2008 DNP Co., Ltd. A New 
System  |  Tsutomu Miyashita  Figure 11. User classification by levels of interest and knowl­edge 
of art. &#38;#169; 2008 DNP Co., Ltd. Figure 10. The relation between XML and data component. &#38;#169; 
2008 DNP Co., Ltd. Tsutomu Miyashita  |  A New System A New System  |  Tsutomu Miyashita  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667273</article_id>
		<sort_key>80</sort_key>
		<display_label>Article No.</display_label>
		<display_no>7</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Souvenirs du monde des montagnes]]></title>
		<page_from>1</page_from>
		<page_to>6</page_to>
		<doi_number>10.1145/1667265.1667273</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667273</url>
		<abstract>
			<par><![CDATA[<p>This paper describes a particular book called <i>Souvenirs du monde des montagnes</i>, which draws its iconography from the history of a Swiss mountain family from 1910 to 1930. By simply dipping into the first few pages, the reader will be lost between real and virtual universes, wonder about the evolution of the images' meanings, and question an object's true content. This setup, developed using state-of-the-art computer vision technology, offers unprecedented freedom: we can make technological references disappear to place the user in fruitful turmoil between visible and hidden meanings. The shadow of a bird flies over the pages, foxes' lanterns light up the text, paper mountains emerge. Once the last page has been turned, the reader will never look at books in the same way again.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797189</person_id>
				<author_profile_id><![CDATA[81442594024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Camille]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scherrer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Artist, EPFL+ECAL Lab, Renens, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797190</person_id>
				<author_profile_id><![CDATA[81309513490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Julien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pilet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Keio University, Lausanne, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797191</person_id>
				<author_profile_id><![CDATA[81100205827]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vincent]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lepetit]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EPFL/IC/ISIM/CVLab, Lausanne, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797192</person_id>
				<author_profile_id><![CDATA[81100337078]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Pascal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fua]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[EPFL/IC/ISIM/CVLab, Lausanne, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Bataille, <i>ABC3d</i> (Paris: Albin Michel Jeunesse, 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618818</ref_obj_id>
				<ref_obj_pid>616070</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Billinghurst, H. Kato, I. Poupyrev, "The MagicBook---Moving Seamlessly Between Reality and Virtuality," <i>IEEE Computer Graphics and Applications</i>, Vol. 21, No. 3, 6--8 (2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1605354</ref_obj_id>
				<ref_obj_pid>1605298</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Grasset, A. Duenser, M. Billinghurst, "The Design of a Mixed-Reality Book: Is It Still a Real Book?," <i>Proceedings of the International Symposium on Augmented Reality</i>, 99--102 (2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965573</ref_obj_id>
				<ref_obj_pid>965400</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Saso, K. Iguchi, and M. Inakage, "Little red: Storytelling in mixed reality," <i>Proceedings of ACM SIGGRAPH Sketches&amp;Applications</i> (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[
<i>Atlantica Der grosse Weltatlas</i> (Munich, Germany: Wissenmedia GmbH, 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Fujihata, "Beyond Pages," <i>Leonardo</i>, Vol. 35, No. 5, 545 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Kato, M. Billinghurst, I. Poupyrev, K. Imamoto, K. Tachibana, "Virtual Object Manipulation on a Table-Top AR Environment," <i>Proceedings of the International Symposium on Augmented Reality</i>, 111--119 (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Ozuysal, P. Fua, and V. Lepetit, "Fast Keypoint Recognition in Ten Lines of Code," <i>Proceedings of the Conference on Computer Vision and Pattern Recognition</i> (Minneapolis, MN, 2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[http://cvlab.epfl.ch/software/ferns.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Media&amp;Interaction Design, ECAL/University of Art and Design, Lausanne, Switzerland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Souvenirs du monde des montagnes Camille Scherrer, Julien Pilet, Vincent Lepetit, Pascal Fua Abstract 
This paper describes a particular book called Souvenirs du monde des montagnes, which draws its iconography 
from the history of a Swiss mountain family from 1910 to 1930. By simply dipping into the first few pages, 
the reader will be lost between real and virtual universes, wonder about the evolution of the images 
meanings, and question an object s true content. This setup, developed using state-of-the-art computer 
vision technology, offers unprecedented freedom: we can make technological references disappear to place 
the user in fruitful turmoil between visible and hidden meanings. The shadow of a bird flies over the 
pages, foxes lanterns light up the text, paper mountains emerge. Once the last page has been turned, 
the reader will never look at books in the same way again. Introduction Our setup, consisting of a book, 
a lamp, and a computer screen, seems perfectly harmless at first sight. But as soon as you open the book 
under the lamp, a major confrontation takes place: on the screen, the pages take on new animated and 
mysterious dimensions. The book s iconography, inspired by a family album of the 1930s, changes into 
a virtual fairy tale. The user is swept away by the disconcerting ambiguity of the setup s language because 
the virtual animations refer to traditional collages; the viewer hesitates between traditional paper-based 
media and the virtual world. To further increase this confusion, nothing gives away the technology, although 
in this case it is quite sophisticated. For each of the book s pages, animated worlds miracu­lously appear 
and disappear, with a direct connection to the actual items printed on paper: animal figures appear over 
the moun­tains, peaks emerge in a shadow play, a bird silently flies over the scene, foxes light up the 
text with their lanterns at dusk (Figure 1). The computer screen acts as a revealer, offering viewers 
a reality quite different from the reality they perceive when they look directly at an object. The idea 
of animating a book is not new: attempts include flip books, motion graphics, and pop-up books [1]. More 
recently, webcams and computers have made it possible to augment markers printed on the pages of a book 
with virtual animations [2]. In all these cases the book either disappears or is altered. In our artwork, 
the book keeps its primary role, and the reader can also enjoy it without the augmentations. The installation 
s secret is based on a camera hidden in the lamp, but also on advanced augmented-reality software. The 
integration of technology is successful for two reasons. First, no technical element distracts users 
or makes usage difficult, as opposed to augmented-reality works that require assistance or visually invasive 
markers [3,4]. Using a simple camera, our software is able to use the book illustrations themselves as 
guides to integrate our virtual elements. Second, our animations enhance the real book without superseding 
it. Both electronic and paper media have their own role, and both benefit from each other. This contrasts, 
for example, with a recent commercially published atlas, Atlantica. It features augment­ed content that 
seems to simply overlap with the paper book, instead of cooperating with it [5]. When turning the virtual 
pages of Masaki Fujihata s book with a real pen, the reader is also driven by familiar objects [6]. Fujihata 
used simple and natural interactions in his virtual book, which we consider as both the source and the 
strength of this kind of artwork. Our work goes farther and uses a real book as the main driver of the 
installation. The resulting combination of books and computers creates a new form of interaction in which 
real and virtual elements have a clearly defined role and visual identity. The interaction principles 
of many existing augmented-reality applications lack such a clear role assigned to real and virtual compo­nents, 
making some of them less intuitive [7]. Our installation stands out with its particu­larly convincing 
merging of paper and computer media (Figure 2). This spectacular questioning of the notion of reality, 
this inroad into the visual codes of the real and virtual worlds, leads the eye to another interpretation 
of the book and its representa­tion. The reader/viewer sees objects, their dimensions and iconography, 
in a different light. Does the process conceal other myster­ies, other universes? One does not put this 
book down like an ordinary read. Description The artistic content of the installation was designed by 
this paper s first author. Having grown up in the Swiss mountains, surrounded by fir trees, foxes, and 
squirrels, she wanted to bring this gentle, soothing world together with advanced technology to create 
new feelings and new meanings. The core of our project is to generate interaction between two originally 
conflicting worlds in order to create a new source of creativity. Between paper and screen, we thought 
for awhile that the second medium would be the former s downfall, and we describe in this section how 
our work offers an original way to reconcile or confront both media. We first explain the concept on 
which our work is based, then describe the design and content we chose to illustrate it. We finally turn 
to the more technical aspects, to show how the technological part is integrated seamlessly into ordinary 
objects. Concept Our work offers an original way to reconcile or confront paper and screen, by letting 
each benefit from the other s intrinsic qualities. Our approach makes the real book this age-old medium 
for transferring knowledge cross the path of the power book, leading to interaction in a natural, albeit 
unprecedented, language, as an extension of our reality. The user never feels overwhelmed by technology 
or bound to a technological constraint. A book is essentially an ordinary object. As this is the first 
element of the setup that draws the viewer s attention, the latter is placed in a position of trust and 
availability. The same applies to the desk lamp, whose familiar shape puts the reader/viewer at ease. 
The installation therefore stands out from previous setups with obvious technological devices such as 
cameras, goggles or visual tags [6]. These elements tend not only to discourage the viewer, but also 
to erect barriers to the human eye between the visible and invisible worlds and to impose markers which 
kill any questioning by making it obvious where virtual material should be expected. In our case, technol­ogy 
stays discreet by working directly with the normal book content. With the additional hiding of the camera 
in the lamp, our setup makes it possible to forget the usual technological constraints and provide a 
look of authenticity, which is one of the primary drives of this work of art. Beyond the initial attraction 
for the reader, the subtle integration of technology into ordinary objects serves to increase the magical 
aura of the setup. Freed of keys and cursors, the technology becomes more human, as though swallowed 
by paper, and art can appropriate new spaces and invite the viewer to raise questions about objects, 
information, and technology. Design &#38; Content The book and animations are designed to produce an 
immediate emotional impact on the viewer, so as to distract people from any preconceptions about virtual 
worlds (Figure 3). Through the chosen subjects, shapes, and textures, the artwork plays on the collective 
unconscious. The visual language stages a sweet nostalgia that brings you back to childhood, to the memories 
of yesteryear, turning the experience into an epic in direct contact with popular tradition. We have 
drawn the iconography from a family album with photographs from the years 1910 to 1930 taken at the heart 
of the Swiss mountains. These images are displayed in a beautifully staged layout that resurrects many 
references from that era, though one does feel the onset of a time-shift without immediately realizing 
it. The animations are thus truly startling, as they surge from the universe which readers thought they 
knew, whereas it eludes them in actual fact. To succeed in surprising and troubling the reader, the animations 
mix with reality without looking like pasted artifacts. They provide a specific graphic language to complement 
and blend in with that of the book. The printed images are not a mere background: they seem to contain 
or even conceal something. Neither the book nor the images are supposed to eclipse each other. They are 
both essential elements in the setup and equally valuable. Combining them serves to play with the reader/viewer, 
who sees the frontiers of the familiar universe gradually slip away as a fantasy world emerges. Setup 
Description As depicted in Figure 4, a lamp, a book, and a computer screen lying on a table make up the 
visible part of the setup. Other components are hidden. A standard computer runs our software, and the 
lamp includes an ordinary webcam. So as to strengthen the illusion, the lamp also performs its usual 
lighting function thanks to a diode system designed to avoid any interference with the camera, such as 
overheating. Finally, the table is also part of the setup in that it enhanc­es contrasts to provide a 
consistent stage. The book obeys the overall concept in that in does not include any digital technological 
element. It could be taken from your grandparents library. Augmented-Reality Technology The process we 
followed to prepare our installation started by designing the book. Because our technology does not require 
particular marks, we could concentrate on its actual content. The next step was to take digital pictures 
of each page to be augmented. In the following discussion, we will refer to these pictures as model images. 
We then created the virtual animations on top of these model images as animated layers. During a training 
phase, our software quickly learns to detect and register the pages in new views based on the model images. 
It relies on an algorithm based on image-feature matching [8], our implementation of which is available 
to download [9]. Our software first automatically selects a few hundred characteristic points in each 
model image and trains a classifier to recog­nize these points based on their local appearances. At run 
time, our software automatically extracts characteristic points in the captured images and matches them 
in real time against those extracted in the model images using the classifier it built during the training 
phase. From the matches between the model image and the captured images, it computes the geometric transformation 
between the two images. Applying this transformation to the semi-transparent animated layer drawn on 
the corresponding model image yields the augmentation with the appropriate point of view (Figure 5). 
Because our technology is automatic, easy to use, and robust to illumination changes, we can reliably 
let the public enjoy our installa­tion without assistance. Conclusion The first stages of this work, 
initiated as part of a diploma project [10], have been widely recognized, in particular with the prestigious 
Pierre Bergé award for the best European design diploma. This success stems from an innovative artistic 
exploration into the notions of augmented reality, involving both technological advancements and development 
of visual communication. More generally speaking, the project tantalizes our perception of the virtual 
and real worlds by taking us through an unprecedented experience. We feel that Souvenirs du monde des 
montagnes can offer another view of virtuality to the public. The topic we used and the approach we adopted 
have already convinced unexpected audiences from five to 95 years old: when Pierre Bergé, an 80-year-old 
art connoisseur, looked at our artwork, he immediately felt comfortable and knew how to play with it. 
Our group aims at developing new links between design and engineering, and we consider this work an example 
of renewed dialogue between the two disciplines. Our approach to augmented reality, which allows paper 
and computer to meet concretely and in harmony, solves the inherent competition between the real and 
virtual worlds. References 1. M. Bataille, ABC3d (Paris: Albin Michel Jeunesse, 2008). 2. M. Billinghurst, 
H. Kato, I. Poupyrev, The MagicBook Moving Seamlessly Between Reality and Virtuality, IEEE Computer Graphics 
and Applications, Vol. 21, No. 3, 6-8 (2001). 3. R. Grasset, A. Duenser, M. Billinghurst, The Design 
of a Mixed-Reality Book: Is It Still a Real Book?, Proceedings of the International Symposium on Augmented 
Reality, 99-102 (2008). 4. T. Saso, K. Iguchi, and M. Inakage, Little red: Storytelling in mixed reality, 
Proceedings of ACM SIGGRAPH Sketches &#38; Applications (2003). 5. Atlantica Der grosse Weltatlas (Munich, 
Germany: Wissenmedia GmbH, 2008). 6. M. Fujihata, Beyond Pages, Leonardo, Vol. 35, No. 5, 545 (2002). 
7. H. Kato, M. Billinghurst, I. Poupyrev, K. Imamoto, K. Tachibana, Virtual Object Manipulation on a 
Table-Top AR Environment, Proceedings of the International Symposium on Augmented Reality, 111-119 (2000). 
8. M. Ozuysal, P. Fua, and V. Lepetit, Fast Keypoint Recognition in Ten Lines of Code, Proceedings of 
the Conference on Computer Vision and Pattern Recognition (Minneapolis, MN, 2007). 9. http://cvlab.epfl.ch/software/ferns. 
10. Media &#38; Interaction Design, ECAL/University of Art and Design, Lausanne, Switzerland. Camille 
Scherrer Artist EPFL+ECAL Lab 11, Av. du 24-Janvier CH - 1020 Renens, Switzerland camille.scherrer@epfl.ch 
Julien Pilet Researcher Keio University EPFL/IC/ISIM/CVLab Station 14 CH-1015 Lausanne, Switzerland julien@ozawa.ics.keio.ac.jp 
Vincent Lepetit Researcher CV lab, Ecole Polytechnique Fédérale de Lausanne EPFL/IC/ISIM/CVLab Station 
14 CH-1015 Lausanne, Switzerland vincent.lepetit@epfl.ch Pascal Fua Educator CV Lab, Ecole Polytechnique 
Fédérale de Lausanne EPFL/IC/ISIM/CVLab Station 14 CH-1015 Lausanne, Switzerland pascal.fua@epfl.ch 
 Figure 1. A book and a computer screen showing images taken by a camera hidden in a lamp. This setup 
offers a new language to bring the real and virtual worlds closer to each other, to weave new meanings 
between the visible and the invisible. &#38;#169; 2009 Camille Scherrer. &#38;#169; 2009 Camille Scherrer, 
Julien Pilet, Vincent Lepetit, Pascal Fua  |  Leonardo, Vol. 42, No. 4, pp. 350 355, 2009  Figure 
2. Examples of scenes revealed on the computer screen. The foxes, the deer, and the mountains are added 
and animated by the computer over the real book. They are designed to look like traditional collages, 
to blur the border between traditional paper-based media and the virtual world. &#38;#169; 2008 Camille 
Scherrer. Souvenirs du monde des montagnes  |  Camille Scherrer, et al.  Figure 3. Successive snapshots 
of an animation. Falling wood planks build up a chalet, and the window opens to reveal the picture behind. 
&#38;#169; 2008 Camille Scherrer. Camille Scherrer, et al.  |  Souvenirs du monde des montagnes  
Figure 4. Our setup. The lamp acts as a normal lamp, but also hides a webcam. A standard computer processes 
the images captured by the webcam and adds the virtual elements. The created images are displayed on 
the computer screen. &#38;#169; 2008 Daniela Droz.  Figure 5. Another example of a revealed scene. The 
paper and the text are real, and the darkness effect, the fox, and the light are created by the computer. 
&#38;#169; 2008 Camille Scherrer. Souvenirs du monde des montagnes  |  Camille Scherrer, et al. Camille 
Scherrer, et al.  |  Souvenirs du monde des montagnes Souvenirs du monde des montagnes  |  Camille 
Scherrer, et al.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1667274</section_id>
		<sort_key>90</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[BioLogic Art: A Natural History of Digital Life]]></section_title>
		<section_page_from>8</section_page_from>
	<article_rec>
		<article_id>1667275</article_id>
		<sort_key>100</sort_key>
		<display_label>Article No.</display_label>
		<display_no>8</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[BioLogic]]></title>
		<subtitle><![CDATA[a natural history of digital life]]></subtitle>
		<page_from>1</page_from>
		<page_to>26</page_to>
		<doi_number>10.1145/1667265.1667275</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667275</url>
		<abstract>
			<par><![CDATA[<p>The artworks chosen for the SIGGRAPH 2009 juried art exhibition explore what can happen when nature and technology combine. Recent projects by 11 artists representing 10 countries offer both serious and playful scenarios in which biological forms and life processes are grafted together with digital code and devices. All of the projects are kinetic, most are interactive, and many are large installations that immerse the viewer in fantastic environments of shivering tendrils, singing strands of hair, and fuzzy, cloud-like surfaces that respond when stroked. The complex technologies and intriguing topics encountered in the exhibition offer viewers a compelling survey of ideas and issues that characterize contemporary life - a tangle of digital devices, natural processes, and us.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797193</person_id>
				<author_profile_id><![CDATA[81458642697]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Suzanne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Anker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797194</person_id>
				<author_profile_id><![CDATA[81458644061]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C&#233;zanne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Charles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797195</person_id>
				<author_profile_id><![CDATA[81100280809]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marshall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797196</person_id>
				<author_profile_id><![CDATA[81319499554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sascha]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pohflepp]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797197</person_id>
				<author_profile_id><![CDATA[81458650026]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Sabrina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raaf]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797198</person_id>
				<author_profile_id><![CDATA[81448593600]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Marcia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tanner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Deleuze, Gilles, and Felix Guattari. <i>A Thousand Plateaus</i>, tr. Brian Massumi (London: Athlone Press, 1988) 22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Image on the opposite page generated using Wordle.net (Jonathan Feinberg, jdf@pobox.com). See caption for complete information.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 BioLogic Art Gallery Jury Suzanne Anker Suzanne Anker is an artist, theorist, and chair of the BFA 
program at the School of Visual Arts in New York, where she works at the intersection of art and the 
biological sciences. She has been a guest curator at the New York Academy of Sciences and the author 
of many texts concerning the implications of the bio-technological revolution on culture and society. 
She hosted the Bio-Blurb Show on WPS1 art radio, organized with the Museum of Modern Art in New York. 
As an artist, she has exhibited nationally and internationally, and her work can be found in the permanent 
collections of the Museum of Modern Art Tokyo, the Smithsonian Institute, the Santa Barbara Museum of 
Art, and the Cleveland Museum of Art. She is co-author of The Molecular Gaze: Art in the Genetic Age, 
an exploration of the ethical questions posed by current scientific advances. Cézanne Charles Cézanne 
Charles is an artist, curator, writer, Director of Creative Industries for ArtServe Michigan, and former 
Executive Director of New Media Scotland. She has commissioned, curated, and presented talks, research, 
and works by creative practitioners who are exploring the implications of emerging technologies and scientific 
developments on contemporary culture in both the US and UK. She is co-founder of rootoftwo, a hybrid 
art and design practice. Her work concentrates on the interactions between audiences, objects and sites 
using electronics and digital media to explore these relationships. rootoftwo has exhibited in the US, 
Europe, and Australia and is now based in metro Detroit. She co-curated the exhibition Perimeters, Boundaries 
and Borders (United Kingdom). She has been an invited contributor and presenter at conferences including 
Cool Fusions: Digital Humanities, Contemporary Art at MOCA Cleveland, and Creative Cities Summit 2.0 
Detroit. She also serves on the programming committee at the Museum of Contemporary Art Detroit. John 
Marshall John Marshall is an artist, designer, curator, writer, and assistant professor in the School 
of Art &#38; Design at the University of Michigan. His work concentrates on the development of experimental 
objects and spaces combining coding and electronics with computer-based design and fabrication methods. 
He co-founded rootoftwo to explore art, design, and electronic culture. Selected exhibitions include 
Chain Reaction Museum of the City of Skopje (Macedonia), Digital Media at La Nau Valencia (Spain), Federation 
Square Melbourne (Australia), Museum of Science and Industry Manchester (United Kingdom), and folly Lancaster 
(United Kingdom). He co-curated the art, design, and technology exhibition Perimeters, Boundaries and 
Borders (United Kingdom) and edited the companion catalog. He has published and presented his research 
in China, Europe, Japan, and the US. He has a PhD from Robert Gordon University (United Kingdom) for 
work exploring hybrid art and design practices mediated through computer-based design and fabrication 
technologies. Sascha Pohflepp Sascha Pohflepp is an artist, designer, and writer currently based in London. 
He recently obtained his MA in the Design Interac­tions Program at the Royal College of Arts, London. 
He studied visual communication at the University of the Arts Berlin and at ENSAD, Paris. His work investigates 
notions of the future, social technologies, and business and idealism. He is a member of Mediamatic and 
has organized and participated in exhibitions, salons, and workshops that investigate the co-evolution 
of cultural developments and new technologies. His work has been recognized by IdN/Shift, I.D. magazine, 
PAGE magazine, and Art Review. He has exhibited and given talks internationally including at Eyebeam 
(New York), Nokia Design Center (Los Angeles), O Reilly Foo Camp 2008 (Sebastopol), Dislocate 07 (Tokyo/Yokohama), 
Ars Electronica 2007 (Linz), Musée de l Elysée (Lausanne), Transmediale 07 (Berlin), and SIGGRAPH 2006 
(Boston). He also contributes to the blog we-make-money- not-art. Sabrina Raaf Sabrina Raaf is a Chicago-based 
artist working in experimental sculptural media and photography. Her work has been presented in solo 
and group exhibitions at Mejan Labs (Stockholm), Stefan Stux Gallery (New York), Ars Electronica (Linz), 
Opel Villas Foundation Art Center (Rüsselsheim), Museum Tinguely (Basel), Espace Landowski (Paris), Artbots 
2005 (Dublin), San Jose Museum of Art, Kunsthaus Graz, ISEA (Helsinki), Klein Art Works (Chicago), The 
Lab (San Francisco), and Painted Bride Center (Philadelphia). She is the recipient of an Emerging Fields 
Creative Capital Grant (2002) and an Illinois Arts Council Fellowship (2005 &#38; 2001). Reviews of her 
work have appeared in Art in America, Contemporary, Chicago Tribune Sunday Magazine, Leonardo, and The 
Washington Post. She received an MFA in Art and Technology from the School of the Art Institute of Chicago 
(1999) and is currently an assistant professor in the School of Art and Design at the University of Illinois 
at Chicago. Marcia Tanner Marcia Tanner is a San Francisco Bay Area independent curator and writer with 
a special interest in artists working with science and technology. She is the former director of the 
San Jose Institute of Contemporary Art. In 2008, she organized We Interrupt Your Program at Mills College 
Art Museum (Oakland, California). Her previous exhibitions include Brides of Franken­stein at the San 
Jose Museum of Art (2005), Bad Girls West at the UCLA Wight Art Gallery (1994), Shadow Play and Location 
Location at the San Jose Institute of Contemporary Art, and many others. Author of numerous reviews, 
articles, and catalog essays, her writings on art have appeared in Art+Text, ArtNews, Art Ltd., artnet.com, 
Artweek, Cabinet, Flash Art, Leonardo, Rhizome News, and other publications. She currently chairs the 
Collections Committee of the Judah Magnes Museum, Berkeley, and co-chairs the Advocacy Committee for 
the Northern California chapter of ArtTable. Leonardo, Vol. 42, No. 4, p. 356, 2009 BioLogic: A Natural 
History of Digital Life  Tag cloud generated by submit­ting the text from the BioLogic Art Gallery introductory 
essay, Call for Submissions, and jurors concept map to Wordle.net (http://www.wordle.net/). &#38;#169; 
2009 ISAST  |  Leonardo, Vol. 42, No. 4, p. 358, 2009 Introduction Elona Van Gent The artworks assembled 
for BioLogic: A Natural History of Digital Life explore what can happen when biological forms and life 
processes encounter digital code and devices. A curious mixture of natural and electronic components 
in the exhibition recalls the idio-syncratic combinations of artifacts one would have seen in 17th-century 
cabinets of wonder. Another parallel for the exhibition could be Deleuze and Guattari s conception of 
a plateau. They describe a plateau as a continuous self-vibrating region of intensities, where things 
are connected and related by proximity but never align to an orientation or achieve a collective end 
[1]. The objects and installations in BioLogic query similar topics, but do so with distinct approaches 
and to marvelously divergent ends. The exhibition s enigmatic character became apparent late in the submission 
review process when jurors were finalizing their selections. The six jurors were asked to map the themes 
and associations suggested by the works under consideration in order to organize them around common characteristics 
and conceptual relevance. So with BioLogic in the center of a whiteboard, arrows easily extended to gardening, 
arboretum, and differentiation. From there thoughts moved to landscape, terra-forms, and the post-apocalyptic; 
or branched off toward interface ecologies, fragile systems, and edge effect; which eventually led to 
synthetic life, augmentation, extinction, and muscle memory. Arranging projects in columns under the­matic 
headings inevitably spurred additional, often incompatible sub-themes that required new headings and 
reconsideration of categorizations established earlier. A dense tangle of ideas and issues associated 
with the works quickly expanded beyond the whiteboard like a plateau of intensities with no fixable horizon 
for orientation [2]. Many of the projects in the exhibition do have one feature in common: a focus on 
the viewer. Duchamp famously observed that it is the viewer who finishes a work of art. In BioLogic, 
the viewer often initiates interaction with a piece, activating it with a touch or sound, causing a branch 
to lift up, a muscle to twitch, or an animated form to bulge and sprout. Installations provide customized 
goggles and tactile interfaces to compensate for limited vision, or responsive garments to aid acclimation 
to foreign habitats. Human influ­ence is made apparent, even required, and human capacities are probed 
to manifest their extent and vulnerability. Finding oneself entangled in an exhibition about nature and 
technology should not come as a surprise given our dual status as irreducibly biological and at the same 
time engineers of the technological contrivances that sustain us and threaten our survival. BioLogic 
candidly reminds the viewer, You are here, inescapably snarled in the unruly confluence that is our bio-human-tech 
home. Elona Van Gent UNIVERSITY OF MICHIGAN 1. Deleuze, Gilles, and Felix Guattari. A Thousand Plateaus, 
tr. Brian Massumi (London: Athlone Press, 1988) 22. 2. Image on the opposite page generated using Wordle.net 
(Jonathan Feinberg, jdf@pobox.com). See caption for complete information.  Leonardo, Vol. 42, No. 4, 
p. 359, 2009  |  &#38;#169; 2009 ISAST Philip Beesley Hylozoic Soil Hylozoic Soil is a visually arresting 
and complex installation. Quivering to life as viewers enter into its midst, this beguiling piece is 
made up of a network of micro-controllers, proximity sensors and shape-memory alloy actuators. Hylozoic 
Soil offers layers of intriguing individual and group behaviors. Building upon simple motions embedded 
within individual elements, turbu­lent wave-like reactions are produced. Using its tendrils, fronds and 
bladders to lure visitors into its seemingly fragile web of laser-cut acrylic matrices, this work blurs 
the distinctions between organism and environment. Inspired by the physical behaviors and mechanisms 
of coral reefs, this artificial assembly evokes natural forces to simulate life. As the title suggests, 
matter and life are deemed inseparable in this work, which plays on the botanical and philosophical implica­tions 
of rhizomatic structures. Operating at the intersections of architecture, design, electronics, engineering, 
informatics and art, Hylozoic Soil is a visceral experience exploring the nuanced relationship between 
the biological and the artificial. Philip Beesley is an artist, architect, stage designer, and a professor 
of architecture at the University of Waterloo and co-director of the University s Integrated Centre for 
Visualization, Design and Manufacturing (ICVDM). He works across digital media art and experimental architecture. 
His recent projects have been immersive digitally fabricated lightweight textile structures that often 
feature interactive kinetic systems that use dense arrays of micro-processors, sensors, and actuator 
systems. Distinctions for his work include the Prix de Rome in Archi­tecture (Canada), the Governor-General 
s Award, and the international FEIDAD 2008 Design Merit Award for Digital Media Art. He was recently 
awarded first-prize honors at VIDA 11.0 for Hylozoic Soil. He has degrees in visual art at Queen s University 
and in architecture at the University of Toronto, both summa cum laude, and received a diploma in technology 
at Humber College. Hylozoic Soil was created by Philip Beesley (artist) and Rob Gorbet (engineering director). 
The core design team for Hylozoic Soil includes: Hayley Isaacs, Christian Joakim, Jonah Humphrey, Kirsten 
Robinson, and Jon Cummings. Addi­tional support includes: Yoshi Wachi, Manuel Kretzer, William Elsworthy, 
Jonathan Tyrrell, Eric Bury, Lawrence Chan, David Blackmore, Jane Wong, Elie Nehme, and Matt Schmid. 
David Bowen Growth Rendering Device Growth Rendering Device is a kinetic installation that captures the 
growth of a pea plant over a 24-hour period. Suspended in a nutrient-rich hydroponic solution, the pea 
plant growth is record­ed during the length of the exhibition. Attached to a wall, the plant is connected 
to a vertical scanner, an ink-jet printer, and a growth light. This system provides everything that is 
needed to sustain and record the plant s development. The device produces a rasterized drawing every 
24 hours. After each new drawing is produced, the system scrolls the roll of paper approximately four 
inches to make way for the next drawing cycle to begin. The outcome of this work is not predetermined. 
As the name suggests, the focus is on growth a complete feedback system between machine and plant. However, 
it is possible that what the machine may record is also the decay and demise of the plant. Drawing marked 
parallels to Gregor Mendel s work on inheritance in peas, Growth Rendering Device seems to ask whether 
both the machinic and the artistic parents will leave their mark on their offspring. David Bowen is a 
studio artist and educator. His work has been featured in numerous group and solo exhibitions nationally 
and internationally. He received his BFA degree from Herron School of Art in 1999 and his MFA degree 
from the University of Minnesota, Minneapolis, in 2004. He is currently an assistant professor of sculpture 
and physical computing at the University of Minnesota, Duluth. Petko Dourmana Post Global Warming Survival 
Kit Post Global Warming Survival Kit is a low-light, infrared installation set in a post-apocalyptic 
world where a nuclear winter condition has been created as a radical solution to the problems of global 
warming and climate catastrophe. Viewers are initially confronted with a space seemingly empty except 
for a lone dwelling. Only after using the night vision devices provided are viewers able to perceive 
the desolate coastal landscape displayed as an infrared video projection. In this world, the sun s life-giving 
rays are unable to reach the surface of the Earth, resulting in perma­nent twilight. Without the aid 
of technological augmentation, we would be blind. In the dwelling, viewers are charged with watching 
the sea. Survival aids and communications technology have been provided. The suggestion is that this 
coastal outpost is one of many. Petko Dourmana is a media artist based in Sofia, Bulgaria. He works with 
a variety of contem­porary art forms involving technology and new media. His current artistic interest 
is focused on exploring human perceptions and abilities for communication through the benefits as well 
as the disadvantages of new technologies. Recent works, research, and experiments have been based on 
the visual representation of history and visions for the future. His artistic projects have been shown 
in traditional art spaces like ZKM Karlsruhe, ICA London, the Chelsea Art Museum, and Location One in 
New York. He has also shown in public spaces in Sofia, Berlin, Manchester, and New York. As a founder 
and chairman of InterSpace Association since 1998, he has been involved in production and co-production 
of art events and projects with Bulgarian and interna­tional artists and activists. Post Global Warming 
Survival Kit was one of eight works nominated for a Transmediale 2009 Award. Arthur Elsenaar Electric 
Eigen-Portraits Electric Eigen-Portraits shows the human face in a state of externally triggered resonance. 
Eight facial muscles are subjected to a simple on/off stimulation pattern, with a repetition period that 
varies gradually between 2 seconds and 100 milliseconds. At fast stimulation rates, the external input 
loses its precise control of the muscle contractions: resonance patterns appear which are primarily determined 
by the intrinsic mechanical properties of the facial muscle system. The face thus displays its own mechanical 
properties on the face itself, a self-portrait of the face, mani­fested by its Eigen-frequencies: an 
Eigen-Portrait. The soundtrack is a direct audio rendition of the electrical signals that are applied 
to the face displayed on the screen. Videography by Jeroen Meijer and Josephine Jasperse. In Face Shift, 
identical algorithms control both sides of the face but one is slightly faster, over time creating visual 
patterns shifting from symmetry to asymmetry. Two DECtalk voice synthesis machines are deployed for each 
side of the face, calling out the identification numbers of the activated muscles. Face Shift was originally 
presented as a live performance work. Videography by Ellen Zweig. Electric Eigen-Portraits and Face Shift 
are two video works that both experiment with algorithmic facial choreography. These works turn a computer-controlled 
human face into a medium for kinetic art. Small, precisely controlled electrical impulses are employed 
to trigger the facial muscles of a live human being into rendering involuntary expressions. As the human 
face is controlled by a digital computer instead of a neural brain, it can be made to perform in ways 
that are often unusual and surprising. Arthur Elsenaar is an artist and an electrical engineer. He used 
to run his own pirate radio station, and he built the transmitters for many illegal radio and television 
stations throughout the Netherlands. He has developed radar-controlled interactive sculptures, interactive 
perfor­mance pieces, video installations, and audio installations. Elsenaar has also collaborated with 
Remko Scha, artist, programmer, and professor of computational linguistics at the University of Amsterdam, 
on a series of automatic performance pieces and video installations, which involve computer-controlled 
facial expression, algorithmic music, and synthetic speech. These works have been presented at scientific 
conferences, theater festivals, and art exhibitions throughout Europe and the United States. Elsenaar 
is currently finishing his PhD work, investigating the choreographic capabilities of the computer-controlled 
human face. His work challenges the traditional notion of facial expression as a conveyor of emotion 
and aims to develop a choreographic facial language. Xárene Eskandar Artifacts from a Parallel Universe: 
Tentative Architecture of Other Earth_Coastline Inhabitants Artifacts from a Parallel Universe is an 
electronically enhanced garment designed to help the wearer adapt to temperature changes in the natural 
environment. It was designed for a fictional world called Other Earth, where viewers are asked to consider 
a place where humans live as nomads in technologically advanced, self-sufficient, and low-environmental-impact 
nodal groups. As conceived by Eskandar, Tentative Architecture is an immaterial architecture that can 
happen at any time and any place, responding to the immediate needs and environment of its wearer ideally 
suited to life on Other Earth. This on-demand architecture works with its wearer to regulate body temperature 
by assisting in ventilation. The garment emulates the breathing of its wearer, and its form is inspired 
by marine coral. This work is both a playful and a provocative look at the potential benefits of bio-mimicry 
and ubiquitous computing. Using galvanic-skin-response sensors and shape-memory alloys embedded in hand-knitted 
and felted wool, Artifacts from a Parallel Universe is a garment born from a Utopian vision where human-machine 
co-evolution and interaction are beneficial to the preservation of the natural environment. Xárene Eskandar 
s background ranges from fashion and automotive design to architecture and event production. She has 
given talks internationally on her recently published book vE- jA: Art + Technology of Live Audio/Video, 
which captures a global snapshot of the interna­tional VJ scene. She has a BS in design from the University 
of Cincinnati, and an MFA from the University of California, Los Angeles. She is currently working toward 
her PhD at UCLA in Architecture and Urban Design. Artifacts from a Parallel Universe: Tentative Architecture 
of Other Earth is an ongoing series of works and explorations conceived by Eskandar and produced by Grant 
Davis in collaboration with Joshua Hernandez (electronics engineering) and Christopher O Leary (photography). 
Verena Friedrich TRANSDUCERS TRANSDUCERS is an experimental installation composed of several transparent 
glass tubes hanging at different heights through the space. Hair samples that have been collected from 
different individuals have been implanted into the custom-made laboratory glass tubes. A single human 
hair can be merely debris, but once its information is decoded through DNA analysis it reveals itself 
to be the repository of our biological blueprint. TRANSDUCERS explores this phenomenon by providing an 
alternative means of decoding and classification. Enhanced with electronics, these vessels bring the 
inanimate biological matter to life again: the object under investigation the human hair is triggered 
by the machinery and is stimulated to react. This reaction is registered, amplified, and transduced into 
an audible output that encodes the hair s physiological constitution. Each of the devices generates a 
unique sound based on the donors individual hair samples. TRANSDUCERS seeks to question the dominance 
of science in describing and classifying life and its basic units. Every audible result provides a technological 
interpretation of identity, produced by an arrangement that points beyond itself to a future reference 
system yet to be developed, freely oscillating between life and laboratory work. Verena Friedrich is 
a German artist and tinkerer with a deep interest in science and technology. Starting from a highly personal 
and emotional point, she avails herself of technical media to develop conceptual artworks that critically 
refer to socially relevant issues. Friedrich studied fine arts and electronic media at the University 
of Art and Design Offenbach and at the Academy of Fine Arts Vienna. Her works have been presented at 
various media art festivals and exhibitions and have been granted the \\international\media\award\2005 
for science and art from ZKM Karlsruhe. She received a nomination for the Transmediale Award 2008. Friedrich 
also teaches at the University of Art and Design Offenbach. Yoon Chung Han One One, an interactive art 
installation that immerses viewers in an animated fantasy, consists of a single drop of ink in a small 
suspended Petri dish and a large projection of the same drop. Under the Petri dish, input sensors connected 
to a micro controller generate 2D and 3D animation of the projected drop. Viewer interaction with the 
physical drop of ink induces complex and intricate animated responses in the projection. The animated 
ink blot suggests a microcosm where viewer interaction is the means of evolution. One resists the need 
to taxonomize (associated closely with the practice of scientific illustration and visualization) and 
instead offers an opportunity to consider the reflexive condition between observer and observed. It provokes 
viewers to experiment in order to get the results they believe are positive and beneficial those which 
are visually pleasing. As viewers heedlessly play with this small environment, they are also being acted 
upon. In the end, the message is simple. It is not the tagging, classification, or observation of life 
that will lead to greater social responsibility, but an appreciation of the oneness of all things. Yoon 
Chung Han was born in Seoul, South Korea. She received her BFA and MFA from Seoul National University, 
specializing in interactive media design. She was a graphic designer in the prestigious Samsung Design 
Membership for three years (2003-2006). Her major interest is in interactive art, especially focusing 
on sound. Han is currently pursuing a second MFA from UCLA Design | Media Arts. Gautam Rangan received 
a BA in art history and biology from the University of California, Berkeley in 2005. He has created animations 
for the Discovery Science Channel and the Connecticut Science Center. He recently worked on a series 
of short games to help with physical therapy for Parkinson s patients at the Baker Fitness Center at 
the University of California, San Francisco. He is pursuing an MFA from UCLA Design | Media Arts in game 
and interaction design. Erick Oh is an award-winning animation artist based in Los Angeles. He was born 
in San Francisco but grew up in Korea. His work includes not only animation but also painting, illustration, 
photography, and installation. He received a BFA in fine art from Seoul National University in 2006. 
He received a year-long grant to produce animation and videos at the Seoul Animation Center. He is currently 
pursuing an MFA from the Department of Film, TV and Digital Media, UCLA, specializing in animation. Scottie 
Chih-Chieh Huang MSOrgm (Motivational Sensitive Organism) MSOrgm (Motivational Sensitive Organism) is 
a personal robot designed to interact with the viewer in a quiet and soothing way. As a contrast to the 
sometimes precocious displays of other interactive work, MSOrgm presents the viewer with self-contained 
and graceful gestures. This robot plant uses cameras to track viewers movements through facial recognition 
software lifting or drooping as it responds to human interaction. MSOrgm combines techniques and concepts 
from kinetic sculpture and makes use of shape memory alloys with spring control. MSOrgm (based on the 
Mimosa plant) consists of five leaves that can move independently. Scottie Huang is a PhD student in 
the Department of Architecture at the National Taiwan University of Science and Technology. He is working 
with Shen-Guan Shih and Sheng-Fen Chien as part of his thesis work. He is interested in design artifacts 
that can enhance architec­ture and everyday living. His works explore tangible human-computer interfaces, 
assistive conceptual design tools, smart house design, movable structures, and stage design. He received 
an MS degree in digital media at the Institute of Architecture at the National Chaio-Tung University 
and a BS degree in architecture at the National Taipei University of Technology. MSOrgm was shown in 
2008 at MOCA Taipei as part of Trans 3rd Digital Art Festival of Taipei. Shen-Guan Shih is an associate 
professor in the Department of Architecture at National Taiwan University of Science and Technology. 
His research interests are in computer-aided design in architecture, design theory, and artificial intelligence. 
He teaches architectural design and computer applications for architecture, as well as the methods and 
theory of architectural design. He has an MS from Carnegie Mellon and a PhD from ETH Zürich. Kumiko Kushiyama 
Fur-Fly Fur-Fly is in an interactive tactile display composed of individual pieces of faux fur. It explores 
the borders between the analog and the digital. This artwork uses real-time, sensor-driven computer technology 
to animate and transform visual effects projected onto the soft surface and to control the movement of 
the components in response to the user. Playing with the notion of images in a cloud form, the projected 
display and soft tufts of fur occasionally resolve into recognizable pictures. The warmth, softness, 
and accessibility of the display surface encourage interaction. Fur-Fly seamlessly integrates art, design, 
and entertainment with practical techno­logical developments. It proposes a tactile approach to human-computer 
interface design. While playfully presented, the research and technology that underpin Fur-Fly have wide-ranging 
applications for multi-modal interaction design and assistive technologies. Kumiko Kushiyama is an artist 
and interaction designer. She is currently a professor at Tokyo Metropolitan University. In 2005, she 
was awarded a Japanese Science and Technology Agency PRESTO research grant to develop technology based 
on sight and touch. Her artwork and that of her regular collaborators have been exhibited widely. In 
2006, she exhibited Thermoesthesia at SIGGRAPH and at Ars Electronica. In addition, she has published 
extensively on her work and presented numerous papers and posters on the subject of interactive display 
technologies. Shinji Sasada is an artist and advanced computer graphics designer. He is a graduate of 
the computer graphics program at Japan Electronics College where he is currently an instructor. His artwork 
has been exhibited widely in Europe and Asia, and has been included in media art festi­vals including 
ISEA, Ars Electronica, and the first Media Art Festival at the Agency for Cultural Affairs in Japan. 
Soichiro Takeyama is studying advanced technology and computer graphics at Japan Electronics College. 
Sanghun Lee Mr. Lee Experiment Mr. Lee Experiment is an interactive installation that uses a Bluetooth-enabled 
micro-controller spuit (syringe) to move human experimental subjects between different environments that 
can then be observed. This is a whimsical installation, in which the viewer is asked to engage in human 
testing, moving Mr. Lee from his holding facility to one of the digitally projected Petri-dish environments. 
The viewer is confronted with two testing environments, water and sand. In the water environment, Mr. 
Lee must literally sink or swim. Adjusting to this environ­ment, Mr. Lee must struggle to stay afloat. 
Moving Mr. Lee from the water environment and putting him in the sand Petri dish sees Mr. Lee try to 
use his new-found swimming skills to no avail. Again he is challenged to adapt and overcome or fade away. 
In this work, humans have been reduced to the same status as other species, that of experimental subjects. 
Human testing is one of the last remaining scientific taboos the stuff of nightmarish and cautionary 
science fiction movies and literature. However, seen from another perspective, it is adherence to this 
taboo that has propagated and prolonged the use of animals in testing programs. With Mr. Lee Experiment, 
the viewer is asked to question humanity s right to subject other species to experimentation without 
empathy or consequence. The collaborative team of Sanghun Lee, Jayoung Kim, Hyomi Mun, Jungmi Kim, and 
Junghwan Sung from the Media Department at SoongSil University has created Mr. Lee Experiment drawing 
on their collective skills and interests. These practitioners work across interactive media art, sound 
art, filmmaking, hardware and software design, and electronics. Junghwan Sung is a professor in the Media 
Department at SoongSil University and has participated in numerous exhibitions in Korea and Japan. Nina 
Tommasi Biological Instrumentation Biological Instrumentation is a time-based spatial installation that 
combines organic and computational processes. The viewer is confronted with a hanging garden of mimosa 
plants, each connected by a series of tubes to an air compressor. The plants are wired with audio speakers, 
light sensors, and other electronic equipment. Digital stimulation, produced from the algorithmic application 
of compressed air onto the leaves, forces the plant to contract. Over the next 15 minutes, following 
the blowing of the compressed air, the mimosa plants begin to open their leaves again, triggering sound 
signals to play from the audio speakers that float next to the plants. The generated sound signals gradually 
increase in volume and intensity, culminating with the forced air being released onto the plants again. 
This work explores the poetics involved in creating new relationships between machines and plant life. 
The installation invites the viewer to walk through a spatialized sound environment and observe the machine-plant 
interaction. Regardless of the plant s condition, the machines algorithmic program constantly stimulates 
the mimosa. Nina Tommasi is an Austrian-born media artist and architect. She studied architecture at 
the University of Technology in Innsbruck and digital art at the University of Applied Arts Vienna. Her 
practice fuses spatial design and time-based media practices to investigate naturally occurring phenomena. 
Her work has been shown as part of solo and group exhibitions in Innsbruck and Vienna, including Depth 
of Textures at AREA53 Gallery. She lives and works in Austria and Italy. Philip Beesley University of 
Waterloo Canada pba.inc@rogers.com Collaborator: Rob Gorbet (Engineering Director)  Hylozoic Soil, 
&#38;#169; 2009 Philip Beesley. Photo Philip Beesley Architect Inc. &#38;#169; 2009 Philip Beesley 
 |  Leonardo, Vol. 42, No. 4, pp. 360 361, 2009 Hylozoic Soil, &#38;#169; 2009 Philip Beesley. Photo 
Philip Beesley Architect Inc.  Hylozoic Soil  |  Philip Beesley David Bowen University of Minnesota 
USA dwbowen@hotmail.com  Growth Rendering Device, &#38;#169; 2007 David Bowen. &#38;#169; 2009 David 
Bowen  |  Leonardo, Vol. 42, No. 4, pp. 362 363, 2009  Growth Rendering Device, &#38;#169; 2007 David 
Bowen. Growth Rendering Device  |  David Bowen Petko Dourmana Bulgaria petko@dourmana.com  Post 
Global Warming Survival Kit, &#38;#169; 2008 Petko Dourmana. &#38;#169; 2009 Petko Dourmana  |  Leonardo, 
Vol. 42, No. 4, pp. 364 365 2009  Post Global Warming Survival Kit, &#38;#169; 2008 Petko Dourmana. 
 Post Global Warming Survival Kit  |  Petko Dourmana Arthur Elsenaar Nottingham Trent University 
The Netherlands and United Kingdom arthur@artifacial.org Collaborator: Remko Scha  Electric Eigen-Portraits, 
&#38;#169; 2009 Arthur Elsenaar, Remko Scha. Videography Josephine Jasperse, Jeroen Meijer. &#38;#169; 
2009 Arthur Elsenaar  |  Leonardo, Vol. 42, No. 4, pp. 366 367, 2009 Face Shift  Face Shift, &#38;#169; 
2005 Arthur Elsenaar, Remko Scha. Videography Ellen Zweig. Electric Eigen-Portraits / Face Shift  | 
 Arthur Elsenaar Xárene Eskandar UCLA Design | Media Arts, Architecture USA xarene@ucla.edu Collaborators: 
Joshua Hernandez, Christopher O Leary, Grant Davis  Artifacts from a Parallel Universe: Tentative Architecture 
of Other Earth_Coastline Inhabitants, &#38;#169; 2008 Xárene Eskandar. Photo Christopher O Leary, Grant 
Davis. &#38;#169; 2009 Xárene Eskandar  |  Leonardo, Vol. 42, No. 4, pp. 368 369, 2009  Artifacts 
from a Parallel Universe: Tentative Architecture of Other Earth_Coastline Inhabitants, &#38;#169; 2008 
Xárene Eskandar. Photo Christopher O Leary, Grant Davis. Artifacts From a Parallel Universe  |  Xárene 
Eskandar Verena Friedrich University of Art and Design Offenbach Germany info@heavythinking.org  TRANSDUCERS, 
&#38;#169; 2009 Verena Friedrich. Photo Max Schroeder. &#38;#169; 2009 Verena Friedrich  |  Leonardo, 
Vol. 42, No. 4, pp. 370 371, 2009  TRANSDUCERS, &#38;#169; 2009 Verena Friedrich. TRANSDUCERS, &#38;#169; 
2009 Verena Friedrich. Photo Max Schroeder.  TRANSDUCERS  |  Verena Friedrich Yoon Chung Han UCLA 
Design | Media Arts USA hanyoonjung@gmail.com Collaborators: Gautam Rangan (UCLA Design | Media Arts), 
Erick Oh (UCLA Department of Film, Television, and Digital Media)  One, &#38;#169; 2009 Gautam Rangan, 
Erick Oh, Yoon Chung Han. &#38;#169; 2009 Yoon Chung Han  |  Leonardo, Vol. 42, No. 4, pp. 372 373 
2009  One, &#38;#169; 2009 Gautam Rangan, Erick Oh, Yoon Chung Han. One  |  Yoon Chung Han Scottie 
Chih-Chieh Huang National Taiwan University of Science and Technology Taiwan scottie.c.c.huang@gmail.com 
Collaborator: Shen-Guan Shih (National Taiwan University of Science and Technology)  MSOrgm (Motivational 
Sensitive Organism), &#38;#169; 2008 Scottie Chih-Chieh Huang, Shen-Guan Shih. Photo Summer Yen. &#38;#169; 
2009 Scottie Chih-Chieh Huang  |  Leonardo, Vol. 42, No. 4, pp. 374 375, 2009  MSOrgm (Motivational 
Sensitive Organism), &#38;#169; 2008 Scottie Chih-Chieh Huang, Shen-Guan Shih. Photo Summer Yen. MSOrgm 
 |  Scottie Chih-Chieh Huang Kumiko Kushiyama Tokyo Metropolitan University Japan kushi@ea.mbn.or.jp 
Collaborators: Shinji Sasada (Japan Electronics College) and Soichiro Takeyama (Japan Electronics College) 
 Fur-Fly, &#38;#169; 2008 Kumiko Kushiyama. &#38;#169; 2009 Kumiko Kushiyama  |  Leonardo, Vol. 42, 
No. 4, pp. 376 377, 2009  Fur-Fly, &#38;#169; 2008 Kumiko Kushiyama. Fur-Fly  |  Kumiko Kushiyama 
 Sanghun Lee Soongsil University South Korea andy5090@naver.com Collaborators: Jayoung Kim, Hyomi Mun, 
Jungmi Kim, Junghwan Sung  Mr. Lee Experiment, &#38;#169; 2009 Sanghun Lee, Hyomi Mun, Jayoung Kim, 
Jungmi Kim, Junghwan Sung. &#38;#169; 2009 Sanghun Lee  |  Leonardo, Vol. 42, No. 4, pp. 378 379, 
2009  Mr. Lee Experiment, &#38;#169; 2009 Sanghun Lee, Hyomi Mun, Jayoung Kim, Jungmi Kim, Junghwan 
Sung. Mr. Lee Experiment  |  Sanghun Lee Nina Tommasi Austria tommasi.nina@saegewerk.org  Biological 
Instrumentation, &#38;#169; 2008 Nina Tommasi.  &#38;#169; 2009 Nina Tommasi  |  Leonardo, Vol. 42, 
No. 4, pp. 380 381, 2009  Biological Instrumentation, &#38;#169; 2008 Nina Tommasi. Biological Instrumentation 
 | Nina Tommasi  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1667276</section_id>
		<sort_key>110</sort_key>
		<section_seq_no>3</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Generative Fabrication]]></section_title>
		<section_page_from>9</section_page_from>
	<article_rec>
		<article_id>1667277</article_id>
		<sort_key>120</sort_key>
		<display_label>Article No.</display_label>
		<display_no>9</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Monumental nets]]></title>
		<page_from>1</page_from>
		<page_to>2</page_to>
		<doi_number>10.1145/1667265.1667277</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667277</url>
		<abstract>
			<par><![CDATA[<p>This piece was fabricated using the same techniques employed for Her Secret Is Patience (page 6). Buro Happold created custom software to rationalize the given shape, conduct form-finding and analysis, and output instruction drawings for the fabrication of the net. The final, doubly curved form is resolved by graduating cell sizes, and by using baiting, a traditional lace-making detail, to move from one net size to the next.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797199</person_id>
				<author_profile_id><![CDATA[81458647866]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Janet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Echelman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brookline, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797200</person_id>
				<author_profile_id><![CDATA[81448600182]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keough]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Buro Happold Consulting Engineers PC, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Monumental Nets Janet Echelman Ian Keough 64-R Coolidge Street Buro Happold Consulting Engineers PC 
Brookline, Massachusetts 02446 USA 100 Broadway janet@echelman.com New York, New York 10005 USA www.echelman.com 
www.burohappold.com Janet Echelman and Buro Happold Consulting Engineers have developed a sculptural 
technique that synthesizes traditional fabrication methods with digital form-finding and rationalization 
processes to create monumental public sculptures. This piece was fabricated using the same techniques 
employed for Her Secret Is Patience (page 6). Buro Happold created custom software to rationalize the 
given shape, conduct form-finding and analysis, and output instruction drawings for the fabrication of 
the net. The final, doubly curved form is resolved by graduating cell sizes, and by using baiting, a 
traditional lace-making detail, to move from one net size to the next.   Her Secret Is Patience Her 
Secret Is Patience, a monumental sculpture installed in Phoenix, Arizona, is the result of a collaboration 
between Janet Echelman and Buro Happold. The piece is remarkable for its synthesis of digital and traditional 
fabrication techniques. Fabricated from multi-colored polyester netting of a type commonly used in commercial 
fishing nets, the net employs nearly 64,000 meters of polyester twine and is comprised of more than 200,000 
knots. Custom software was created by Buro Happold to rationalize the shape, conduct form-finding and 
analysis, and output drawings to manufacture. Working closely with the net fabricator, Buro Happold designed 
the software to account for the manual process of controlling the net looms, outputting patterning drawings 
that described knot counts and lengths, and splice locations. For areas of the sculpture where net-loomed 
pieces could not capture the form, the nets were spliced by hand using drawings that represented every 
piece of twine unrolled, with each splice location dimensioned. Material selection was key to the success 
of the project, both structurally and economically. In order to resist 144 km/h winds, the material had 
to be exceptionally strong. The Phoenix site also required consideration of the degradation of the material 
over time due to UV exposure. Polyester, although not UV stable, was chosen for its high strength-to­cost 
ratio. This enabled the city of Phoenix to purchase several versions of the same sculpture, which could 
be changed at five­year intervals. The steel support armature, fabricated by CAID Industries, is comprised 
of four massive towers and cables supporting the primary ring, which is approximately 23 meters in diameter. 
With the steel work already in place, installation of the prefabricated net was a matter of hours from 
delivery to finished form.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667278</article_id>
		<sort_key>130</sort_key>
		<display_label>Article No.</display_label>
		<display_no>10</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Schiara lantern]]></title>
		<page_from>1</page_from>
		<page_to>2</page_to>
		<doi_number>10.1145/1667265.1667278</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667278</url>
		<abstract>
			<par><![CDATA[<p>An approximately six-foot-diameter lantern consisting of a single hollow volume constructed from multiple translucent molded composite parts with numerous apertures at multiple orientations.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797201</person_id>
				<author_profile_id><![CDATA[81458645999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Greg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lynn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Greg Lynn/FORM, Venice, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797202</person_id>
				<author_profile_id><![CDATA[81448600159]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kreysler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kreysler & Associates, American Canyon, California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Schiara Lantern Greg Lynn Bill Kreysler Greg Lynn/FORM Kreysler &#38; Associates 1817 Lincoln Boulevard 
501 Green Island Road Venice, California 90291 USA American Canyon, California 94503 greg@glform.com 
USA An approximately six-foot-diameter lantern consisting of a single hollow volume constructed from 
multiple translucent molded composite parts with numerous apertures at multiple orientations.  Schiara 
Lantern Greg Lynn/FORM and Kreysler &#38; Associates have been working together for some time to develop 
lightweight, translucent, composite building elements and systems using colaborative digital design and 
fabrication tools. The over 40-foot-long luminous ceiling lantern of the Bloom House is one early example. 
As 3D computer models and CNC tools increasingly allow the realization of complex forms, traditional 
material and construction processes become less relevant. We are rapidly moving toward building systems 
based on custom-formed materials. Continuous section structures such as plywood, two-by-fours, and I-beams 
will give way to monocoque structural systems that will improve efficency by combining enclosure with 
structure and by using materials such as composites. Composite materials, those using high modulus fibers 
encapsulated in energy-efficient synthetic resins, can be formed in ways traditional materials cannot. 
These materials, combined with 3D and parametric modeling tools, are fully scalable. This work, Schiara 
Lantern, represents an example of this process and is fully capable of controlling the construction of 
entire buildings in essentially the same way. Furthermore, composite materials, particularly those made 
with unsaturated polyester resins and glass fibers, are more environmentally efficient than typical methods 
of construction. Far less energy is consumed in the manufacture of the materials themselves, likewise 
the fabrication, and usually the installation. Even more environmental efficiency can be realized using 
resins made from soy oil or other bio-based materials and fibers made from natural materials such as 
hemp, flax, bamboo, or seagrass. Using these new tools to integrate design, fabrication methods, and 
materials yields opportunities to explore entirely new ways of building objects, regardless of size or 
purpose. 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667279</article_id>
		<sort_key>140</sort_key>
		<display_label>Article No.</display_label>
		<display_no>11</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Complex form in timber]]></title>
		<page_from>1</page_from>
		<page_to>2</page_to>
		<doi_number>10.1145/1667265.1667279</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667279</url>
		<abstract>
			<par><![CDATA[<p>The advent of digital fabrication technologies has opened the doors to ever-more-complex shapes in architecture. Computer-controlled mills, drills, and cutters are used to transfer the principles of mass customization to the building industry. Those CNC tools can produce thousands of individual components almost at the cost of mass production, allowing construction of complex curved shapes within reasonable budgets.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Geometric algorithms, languages, and systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided manufacturing (CAM)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Industrial control</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010481.10010483</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Computer-aided manufacturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010482.10010486</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Industry and manufacturing->Command and control</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797203</person_id>
				<author_profile_id><![CDATA[81458652588]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fabian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheurer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Erlenbach/Z&#252;rich, Switzerland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Complex Form in Timber Fabian Scheurer designtoproduction 8703 Erlenbach/Zürich, Switzerland info@designtoproduction.com 
www.designtoproduction.com The advent of digital fabrication technologies has opened the doors to ever-more-complex 
shapes in architecture. Computer-controlled mills, drills, and cutters are used to transfer the principles 
of mass customization to the building industry. Those CNC tools can produce thousands of individual components 
almost at the cost of mass production, allowing construction of complex curved shapes within reasonable 
budgets. The combination of parametric CAD systems and computer­controlled fabrication tools makes timber 
the perfect material for free-form architecture.  Complex Form in Timber Timber is especially suited 
for this approach for a number of reasons. It is cheap, available, sustainable, and most importantly 
 perfectly machinable. The common problem with all raw building materials is that they come in straight 
sticks or planar boards. This is where the materials usually associated with curvy shapes run into trouble. 
Bending metal or glass is a trial-and-error process, highly dependent on material properties and prone 
to imprecision. Milling a shape out of a raw block of material is immensely time- and cost-intensive. 
Cutting curved parts from flat sheets is easy and efficient but reconnecting them into a three-dimensional 
structure requires a lot of labor. Here, timber pulls the wild card. It can be machined by computer-controlled 
tools with amazing speed and high precision. The waste is recyclable. And all details like slots, bolt 
holes, and even complex timber connections can be fabricated directly. But file to factory means more 
than just sending a CAD file to a CNC machine. It requires the integration of design, engineering, fabrication, 
and logistics into a seamless process. The complexity shifts from machining the material to managing 
the information. This is what designtoproduction adds to the process. The interdisciplinary team acts 
as a relay among all involved parties and ensures the flow of information transforming the designer 
s intention into parametric CAD models and ultimately into the code controlling a CNC tool. Images: Zplus 
is a modular timber building system for free-form constructions, developed by designtoproduction in collaboration 
with Blumer-Lehmann AG (www.blumer-lehmann.ch) and Création Holz (www.creation-holz.ch). 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667280</article_id>
		<sort_key>150</sort_key>
		<display_label>Article No.</display_label>
		<display_no>12</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Assemblages]]></title>
		<page_from>1</page_from>
		<page_to>2</page_to>
		<doi_number>10.1145/1667265.1667280</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667280</url>
		<abstract>
			<par><![CDATA[<p>The quasi-series is about the pursuit of orders that are rigorously modular but wild---almost out of order. Quasicrystals, a new phase of matter discovered in 1984, represent this kind of material structure, which hovers on the edge of falling apart. Unlike a regular crystal, whose molecular pattern is periodic (or repetitive in all directions), the distinctive quality of a quasicrystal is that its structural pattern never repeats the same way twice. It is endless and uneven, but interestingly, it can be described by the arrangement of a small set of modular parts. Aranda\Lasch furniture and design objects are produced and represented by the Johnson Trading Gallery.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Physics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided design (CAD)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor>Modeling methodologies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010472.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Architecture (buildings)->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010343</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Modeling methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010439.10010440</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Engineering->Computer-aided design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010441</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Physics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797204</person_id>
				<author_profile_id><![CDATA[81448600380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lasch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797205</person_id>
				<author_profile_id><![CDATA[81458649536]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aranda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Assemblages Aranda\Lasch Chris Lasch &#38; Benjamin Aranda 212 Forsyth Street North Storefront New 
York, New York 10002 info@arandalasch.com www.arandalasch.com Quasi-Cabinet The quasi-series is about 
the pursuit of orders that are rigorously modular but wild almost out of order. Quasicrystals, a new 
phase of matter discovered in 1984, represent this kind of material structure, which hovers on the edge 
of falling apart. Unlike a regular crystal, whose molecular pattern is periodic (or repetitive in all 
directions), the distinctive quality of a quasicrystal is that its structural pattern never repeats the 
same way twice. It is endless and uneven, but interestingly, it can be described by the arrangement of 
a small set of modular parts. Aranda\Lasch furniture and design objects are produced and represented 
by the Johnson Trading Gallery.  Assemblages   Rules of Six Rules of Six is a large-scale commission 
by the Museum of Modern Art for the exhibition Design and the Elastic Mind, curated by Paola Antonelli. 
Rules of Six is an experiment in growth. The design explores issues of self-assembly, where top-down 
methods for determining form are replaced by bottom-up rules of formation. The structures presented are 
not carved or composed in a traditional sense; they are grown through simple interactions, hexagonal 
in nature, that are much like the ones molecules follow in the lab. The project was produced in collaboration 
with Matthew L. Scullin, Department of Materials Science and Engineering, University of California, Berkeley 
and Lawrence Berkeley National Labs. The Morning Line The Morning Line is a collaboration with the artist 
Matthew Ritchie and Daniel Bosia of Arup AGU, commissioned by Thyssen-Bornemisza Art Contemporary. It 
explores the interplay among art, architecture, cosmology, and music. The Morning Line is conceived as 
a drawing in space, where each line connects to other lines to construct a spatial picture. Within this 
space, composers and musicians perform. Geometrically based on a three-dimensional fractal, the piece 
can be dissaembled into modular, stackable, and transportable units. A key ambition of the collaboration 
was to produce an integrated approach between art and architecture, where the drawn lines are both the 
structure and the space. 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667281</article_id>
		<sort_key>160</sort_key>
		<display_label>Article No.</display_label>
		<display_no>13</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[MyLight.MGX]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667281</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667281</url>
		<abstract>
			<par><![CDATA[<p>MyLight is a lamp that is different for each customer, due to a manufacturing method (selective laser sintering) that allows for the production of an object without using a mold. The lamps are simply "printed" three-dimensionally.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Signal processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>C.3</cat_node>
				<descriptor>Real-time and embedded systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.3</cat_node>
				<descriptor>Signal processing systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797206</person_id>
				<author_profile_id><![CDATA[81100130626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lars]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spuybroek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Materialise.MGX, Leuven, Belgium]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MyLight.MGX Designed by Lars Spuybroek- NOX Produced by .MGX by Materialise Materialise.MGX Technologielaan 
15 3001 Leuven, Belgium info@mgxbymaterialise.com www.materialise-mgx.com +32 16 396611 MyLight is a 
lamp that is different for each customer, due to a manufacturing method (selective laser sintering) that 
allows for the production of an object without using a mold. The lamps are simply printed three-dimensionally. 
We can now print an object directly from digital information. People have no idea yet what an incredible 
change in technology that is, and what that means for design. All design will become meta-design: objects 
can now be a range-of-objects, like in a family or a species. Like zebra or oaks or strawberries, or, 
of course, people: no two are the same, but they are similar enough to be recognized. We designed the 
object in such a way that the differences would be easily readable, without making them too different. 
They can be big on top, big in the middle, or big below. They can have many holes or just a few. But 
they will always be private; each lamp you buy is different from the other; it is unique.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667282</article_id>
		<sort_key>170</sort_key>
		<display_label>Article No.</display_label>
		<display_no>14</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Holy Ghost]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667282</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667282</url>
		<abstract>
			<par><![CDATA[<p>In Holy Ghost, digitally generated modifications are made to Philippe Starck's iconic Louis Ghost chair. A computer script runs in real time, determining the number, position, size, and shape of elements that make up the form. Real-world chairs are "printed" directly from digital data, each one a unique solution.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797207</person_id>
				<author_profile_id><![CDATA[81458645949]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lionel]]></first_name>
				<middle_name><![CDATA[Theodore]]></middle_name>
				<last_name><![CDATA[Dean]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Artist/Designer]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Holy Ghost Lionel Theodore Dean Artist/Designer www.FutureFactories.com info@FutureFactories.com  In 
Holy Ghost, digitally generated modifications are made to Philippe Starck s iconic Louis Ghost chair. 
A computer script runs in real time, determining the number, position, size, and shape of elements that 
make up the form. Real-world chairs are printed directly from digital data, each one a unique solution. 
FutureFactories began as Blue Skies Research in 2002, created by artist and designer Lionel Theodore 
Dean. It explores a post-industrial age in which 3D artifacts can be printed directly from computer data. 
The aim is to combine computer-aided design (CAD) with computer scripts to create living designs that 
exist in constant metamorphosis. These virtual meta-designs can then be translated into real-world products, 
via direct digital manufacturing, offering a potentially infinite stream of one-off solutions. The project 
has proved a huge success, with outputs ranging from gallery pieces to retail designs for well-known 
manufacturers. The work has been widely published and exhibited around the world. In 2005, one of the 
pieces, Tuber9, was acquired by the Museum of Modern Art in New York for its permanent design collection. 
Academically, the project has developed from an initial design residency into a practice-based PhD study. 
Lionel Theodore Dean has a master s degree from the Royal College of Art, London, and is a graduate engineer. 
Today his work focuses exclusively on digital manufacturing, though the FutureFactories project has pioneered 
the concept of mass individualization, the industrial-scale production of one-off artifacts. The FutureFactories 
concept requires forms capable of mutation and evolution. Growth structures seen in the natural world 
are a great influence in the work. Dean tries to imagine what a product might have evolved from and what 
it might ultimately develop into. His fascination lies in how natural forms have evolved, as much as 
in the shapes themselves. Rather than imitate nature directly, he strives to create the flora and fauna 
of an alien landscape.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667283</article_id>
		<sort_key>180</sort_key>
		<display_label>Article No.</display_label>
		<display_no>15</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Ground substance]]></title>
		<page_from>1</page_from>
		<page_to>2</page_to>
		<doi_number>10.1145/1667265.1667283</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667283</url>
		<abstract>
			<par><![CDATA[<p>Ground Substance presents work from LabStudio, a hybrid architectural-biological design unit founded by Jenny Sabin and Peter Lloyd Jones at the University of Pennsylvania, whose mission is to produce new modes of thinking in design and biomedicine through modeling of multi-dimensional biological systems with experiments in fabrication and material construction.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor>Modeling methodologies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010343</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Modeling methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797208</person_id>
				<author_profile_id><![CDATA[81421599941]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jenny]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Sabin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Ground Substance Jenny E. Sabin Sabin+Jones LabStudio University of Pennsylvania jsabin@cabin-studio.com 
www.sabin-jones.com Ground Substance presents work from LabStudio, a hybrid architectural­biological 
design unit founded by Jenny Sabin and Peter Lloyd Jones at the University of Pennsylvania, whose mission 
is to produce new modes of thinking in design and biomedicine through modeling of multi-dimensional biological 
systems with experiments in fabrication and material construction. The ability to forgo disciplinary 
boundaries allows for unique views of similar issues, even at radically different scales. Whether scientists 
or designers, we are all bound to deal with geometry, matter, and their effects. Technology has afforded 
scientists and designers alike an extraordinary ability to generate information, yet this has resulted 
in an ever-increasing inability to visualize and model diverse datasets. As we become faced with petabyte 
datasets and beyond, it will become increasingly challenging to view and comprehend 4D biomedical and 
architectural data using existing means. While the end goals may differ in science and in architecture, 
there is a driving necessity in both disciplines to model and fabricate complex, emergent, and self-organized 
nonlinear systems. We ask: "How can we intuit, see, and understand complex wholes that are often indiscernible 
from their individual parts?" Information gathers meaning when filtered through multiple modes of expression. 
Intuitive pattern recognition and alternative representations of complex datasets that can be seen, heard, 
and even held (for example, via rapid prototyping) are essential. In the production of relationships 
and correspondences, "tools" such as computer scripts are developed to orchestrate the movement between 
multiple modes of working. A rigorous understanding and analysis of these types of models will allow 
scientists and architects to retool and revaluate how to negotiate visualization and quantification within 
complex 3D biological phenomena. Organic models such as those found in biology afford modes for understanding 
issues of feedback, growth, and self-assembly in architecture as they negotiate truly dynamic environments 
with nonlinear responses. Translation requires all of our senses and intuitions, and this can only be 
achieved using unconventional approaches.  Ground Substance Sabin+Jones LabStudio Directors Jenny E. 
Sabin Peter Lloyd Jones Designers/Researchers Andrew Lucia Erica Savig Scientists/Researchers Kaori Ihida-Stansbury 
Vanesa Karamanian Alexandra Klinger Shawn Sweeney Mathieu Tamby Design Jenny E. Sabin Andrew Lucia Peter 
Lloyd Jones Annette Fierro Production Jenny E. Sabin Andrew Lucia Rebecca Fuchs 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667284</article_id>
		<sort_key>190</sort_key>
		<display_label>Article No.</display_label>
		<display_no>16</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Pluripotent structures]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667284</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667284</url>
		<abstract>
			<par><![CDATA[<p>Pluripotent Structures is an investigation into adaptive and variable formal and structural organizations that have more than one possible outcome while maintaining an overall coherence.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Computations on discrete structures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor>Modeling methodologies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010343</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Modeling methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797209</person_id>
				<author_profile_id><![CDATA[81458648196]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ferda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kolatan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[su11 architecture+design, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797210</person_id>
				<author_profile_id><![CDATA[81448600853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Erich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schoenenberger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[su11 architecture+design, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Pluripotent Structures Ferda Kolatan+Erich Schoenenberger su11 architecture+design 165 Elizabeth Street, 
4F New York, New York 10012 USA fk@su11.com www.su11.com  Pluripotent Structures is an investigation 
into adaptive and variable formal and structural organizations that have more than one possible outcome 
while maintaining an overall coherence. In his book Endless Forms Most Beautiful, Biologist Sean B. Carroll 
argues that innovation in body parts is not based on novel genes but rather on modification of existing 
structures and teaching old genes how to learn new tricks . These tricks, he reasons, are achieved by 
switching on and off so-called tool-kit genes at different times and places through the course of development. 
Thus, design expression is based on sensitive, feedback-oriented interaction between a group of intricately 
networked components rather than a result of linearly unfolding, pre-existing information. The very same 
components enable different scenarios relative to their active and passive relationships within the overall 
system. su11 architecture+design explores novel opportunities that arise when these concepts are translated 
into a parametrically controlled design environment. The firm believes that these ideas hold tremendous 
possibilities for design research, fabrication techniques, and material applications in the field of 
architecture that go beyond mere questions of optimization and efficiency. Pluripotent principles, as 
they maintain developmental plasticity, suggest an alternative scenario for production, one that is based 
on nonlinearity, reciprocity, and convergence rather than linear causality. In addition, their physical 
manifestations generate highly sophisticated and delicate structures governed by seemingly limitless 
degrees of refinement, which result in intricate surface characteristics with exotic atmospheric effects. 
 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1667285</section_id>
		<sort_key>200</sort_key>
		<section_seq_no>4</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Information Aesthetics Showcase]]></section_title>
		<section_page_from>17</section_page_from>
	<article_rec>
		<article_id>1667286</article_id>
		<sort_key>210</sort_key>
		<display_label>Article No.</display_label>
		<display_no>17</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[24X7@PHL:Vectoring]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667286</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667286</url>
		<abstract>
			<par><![CDATA[<p>24X7ATPHL:Vectoring is an investigation into the novel usage of time-based animation software and procedural modeling as a method for visualizing time-based quantitative data via construction of a qualitative, two-dimensional rendering. Treated as an experiment that follows the most basic rules of time-lapse photography, 24X7ATPHL slows down and composites accumulated data on traffic (customer pickup and drop off) over seven days traffic at an international airport. The result not only notates the generations and changes in patterns, but also shows the beauty that can be found in data while unlocking the emergent potential for design. The second in the 24X7@PHL series, Vectoring is based on extraction of the resultant NURBS geometries as a methodology for understanding the specific conditions of movement created by the interaction of existing architecture and users, the results of which are currently being used to develop a new speculative masterplan for the international airport.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Software support</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Animations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10011310</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Simulation by animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797211</person_id>
				<author_profile_id><![CDATA[81320495814]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trempe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 24X7@PHL: Vectoring contact Robert Trempe Temple University trempe@temple.edu  24X7ATPHL:Vectoring 
is an investigation into the novel usage of time-based animation software and procedural modeling as 
a method for visualizing time-based quantitative data via construction of a qualitative, two-dimensional 
rendering. Treated as an experiment that follows the most basic rules of time-lapse photography, 24X7ATPHL 
slows down and composites accumulated data on traffic (customer pickup and drop off) over seven days 
traffic at an international airport. The result not only notates the generations and changes in patterns, 
but also shows the beauty that can be found in data while unlocking the emergent potential for design. 
The second in the 24X7@PHL series, Vectoring is based on extraction of the resultant NURBS geometries 
as a methodology for understanding the specific conditions of movement created by the interaction of 
existing architecture and users, the results of which are currently being used to develop a new speculative 
masterplan for the international airport. www.dis-section.com  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667287</article_id>
		<sort_key>220</sort_key>
		<display_label>Article No.</display_label>
		<display_no>18</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[A_B_peace & terror etc. The computational aesthetics of love & hate]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667287</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667287</url>
		<abstract>
			<par><![CDATA[<p>A_B_peace & terror etc. The computational aesthetics of love & hate blends world politics with the aesthetics of computational data to create a powerful, pertinent, and spellbinding view of the modern world. As an intriguing collection of data, A_B_... reveals the quantitative contribution each of the 192 member states of the United Nations has made toward peace and terror in the world. It is a functional information-design piece that uses computational aesthetic principles to compare complex and socially relevant data derived from researchers working in the field of geopolitics. The dual-sided overlay of the two graphs allows for a direct visual comparison of the peace and terror measures. The functional nature of the poster becomes poignantly relevant when one makes detailed comparisons among nations. Many of the results are quite surprising and stand in contrast to prevailing norms of collective national perception.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human information processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.0</cat_node>
				<descriptor>Cognitive simulation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010194</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Cognitive robotics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797212</person_id>
				<author_profile_id><![CDATA[81458646132]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Crnokrak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Luxury of Protest]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A_B_ peace &#38; terror etc. The computational aesthetics of love &#38; hate contact Peter Crnokrak 
The Luxury of Protest info@theluxuryofprotest.com A_B_ peace &#38; terror etc. The computational aesthetics 
of love &#38; hate blends world politics with the aesthetics of computational data to create a powerful, 
pertinent, and spellbinding view of the modern world. As an intriguing collection of data, A_B_ reveals 
the quantitative contribution each of the 192 member states of the United Nations has made toward peace 
and terror in the world. It is a functional information­design piece that uses computational aesthetic 
principles to compare complex and socially relevant data derived from researchers working in the field 
of geopolitics. The dual-sided overlay of the two graphs allows for a direct visual comparison of the 
peace and terror measures. The functional nature of the poster becomes poignantly relevant when one makes 
detailed comparisons among nations. Many of the results are quite surprising and stand in contrast to 
prevailing norms of collective national perception. theluxuryofprotest.com  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667288</article_id>
		<sort_key>230</sort_key>
		<display_label>Article No.</display_label>
		<display_no>19</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[C-loc software]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667288</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667288</url>
		<abstract>
			<par><![CDATA[<p>In recent years, geographic information systems (GIS) for consumers (Google Maps and Google Earth, for example) have become very popular, and many people enjoy collecting and editing memories using those media. These systems are well designed to visualize diverse geographical data, but they can not present geographical and chronological information at the same time. Some GIS systems have a chronological function, but only as animation.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.4</cat_node>
				<descriptor>Software support</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797213</person_id>
				<author_profile_id><![CDATA[81540970156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yasushi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Noguchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tokyo Polytechnic University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 C-loc Software contact Yasushi Noguchi Tokyo Polytechnic University noguchi@media.t-kougei.ac.jp In 
recent years, geographic information systems (GIS) for consumers (Google Maps and Google Earth, for example) 
have become very popular, and many people enjoy collecting and editing memories using those media. These 
systems are well designed to visualize diverse geographical data, but they can not present geographical 
and chronological information at the same time. Some GIS systems have a chronological function, but only 
as animation. C-loc Software offers a new way to visualize time and space using a time layer-scheme 
and interactive three-dimensional graphics. It is suitable for people who want to investigate the relationship 
between the geographical and chronological information of archeology, ethnology, and history such as 
an archive of earthen vessels. An editor can import chronological maps and define year, month, day, hour, 
minute, and second. Any type of map can be used, depending on the editor s purpose. Time s arrow goes 
from the bottom to the top of the interface. It is the layer of time. Objects can be created and categorized. 
Text, image, sound, or movies are registered as objects, and the size, color, and alpha of the object 
is customized. In addition, lines that connect objects in the same category can be customized as well. 
The position of the camera is registered as a button. Pressing the button moves the camera to a target 
point. Furthermore, there is a function for importing and exporting a CSV file so that an existing database 
can be easily converted into data for C-loc Software. In addition, GPS data can be imported into the 
software. If users photos include location data (for example, latitude, longitude, and time) as EXIF 
data, those photos are automatically imported and placed in C-loc Software. r-dimension.xsrv.jp/projects_e/cloc 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667289</article_id>
		<sort_key>240</sort_key>
		<display_label>Article No.</display_label>
		<display_no>20</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Cultural analytics research environment]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667289</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667289</url>
		<abstract>
			<par><![CDATA[<p>Our team of specialists in visual arts, communication, cognitive science, and structural engineering produces interactive visualizations of cultural flows, patterns, and relationships based on analysis of large sets of data comparable in size to datasets used in sciences.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.0</cat_node>
				<descriptor>Cognitive simulation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010194</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Cognitive robotics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797214</person_id>
				<author_profile_id><![CDATA[81100428913]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lev]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manovich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797215</person_id>
				<author_profile_id><![CDATA[81448592994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jeremy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Douglass]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797216</person_id>
				<author_profile_id><![CDATA[81458642759]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sergie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Magdalin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797217</person_id>
				<author_profile_id><![CDATA[81100140185]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Falko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuester]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797218</person_id>
				<author_profile_id><![CDATA[81448600207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[So]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yamaoko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Cultural Analytics Research Environment contact Lev Manovich University of California, San Diego manovich@ucsd.edu 
Jeremy Douglass University of California, San Diego Sergie Magdalin University of California, San Diego 
Falko Kuester University of California, San Diego So Yamaoko University of California, San Diego  Our 
team of specialists in visual arts, communication, cognitive science, and structural engineering produces 
interactive visualizations of cultural flows, patterns, and relationships based on analysis of large 
sets of data comparable in size to datasets used in sciences. Contemporary science increasingly relies 
on computer-based analysis and visualization of large datasets and data flows. The availability of large 
cultural datasets (through the web and digitization efforts by museums and libraries) and tools already 
employed in the sciences to analyze big datasets makes feasible a new methodology for the study of cultural 
processes and artifacts. Whereas humanities specialists have typically relied on manual analysis of a 
small number of cultural objects, we can now create information visualizations of large cultural datasets 
to discover patterns that have not been visible previously. We believe that we can make field-defining 
progress in this area by bringing together people who study and create digital cultural artifacts, people 
who study distributed human cognition, and people who are developing computational tools for analysis, 
display, and interaction with large datasets. Our team creates new kinds of multi-modal interfaces appropriate 
for the study and experience of large sets of cultural artifacts in different media. We will also combine 
the visualization techniques normally used in science with the techniques developed in digital design 
and new-media art. The practical outcome of our research is the Cultural Analytics Research Environment, 
an open platform that supports analysis of different types of visual and media data and a variety of 
visualization and mapping techniques. We believe that such visualization environments will be used by 
social scientists and cultural theorists, students in art history, media studies, and communication studies 
classes; museum visitors; and cultural creators who want to better understand how their work fits within 
a larger context. lab.softwarestudies.com/2008/05/visualizing-cultural-patterns.html 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667290</article_id>
		<sort_key>250</sort_key>
		<display_label>Article No.</display_label>
		<display_no>21</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[decibel 151]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667290</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667290</url>
		<abstract>
			<par><![CDATA[<p>What happens if you become the search engine? If your participation creates the content? If by entering a space you become the entry?</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.3.5</cat_node>
				<descriptor>Web-based services</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003304</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web services</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003282</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797219</person_id>
				<author_profile_id><![CDATA[81421596557]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michela]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Magas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797220</person_id>
				<author_profile_id><![CDATA[81448592422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stewart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queen Mary University of London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797221</person_id>
				<author_profile_id><![CDATA[81458654442]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fields]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 decibel 151 contact Michela Magas Rebecca Stewart Benjamin Fields Goldsmiths, University of London 
Centre for Digital Music, Goldsmiths, University of London map02mm@gold.ac.uk Queen Mary University of 
London What happens if you become the search engine? If your participation creates the content? If by 
entering a space you become the entry? Inspired by Ray Bradbury s Fahrenheit 451, decibel 151 uses spatial 
audio technology and ideas of social networking to turn individuals into walking soundtracks . decibel 
151 creates a virtual reality environment where participants physically move around each other in a shared 
real space as they listen to a shared virtual space. The virtual space creates a community of listeners 
and an interactive way to explore a collection of music. Upon entering the physical/virtual space, each 
participant is assigned a specific music track in the virtual space; when they move, other participants 
hear their song move. Participants do not hear their own songs, but they can hear the other participants 
s song moving in the space in surround sound. Each participant can move freely and explore the space 
and the songs representing other participants. As they move and explore, they are tracked, and their 
graphical ghost images are positioned within a projected interface with metadata attached, giving information 
about each musical track. The use of recordings of folk music collected by Alan Lomax in the southern 
United States geographically anchors the experience. The interface runs simultaneously on the internet, 
allowing participants to enter the space online and contribute to the virtual experience. The online 
interface can generate environments for music recommendations on social networking sites, where members 
enter the virtual space in order to hear what other participants are listening to at that moment and 
instantly capture the zeitgeist.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667291</article_id>
		<sort_key>260</sort_key>
		<display_label>Article No.</display_label>
		<display_no>22</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Height restriction]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667291</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667291</url>
		<abstract>
			<par><![CDATA[<p>Information visualization affords us the opportunity to view subjects in a way that is not possible by a 1:1 interpretation, with new toolsets and techniques providing a springboard for discovereing new and emergent patterns that are not visible to the naked eye.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797222</person_id>
				<author_profile_id><![CDATA[81320495814]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trempe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Height Restriction contact Robert Trempe Temple University trempe@temple.edu Information visualization 
affords us the opportunity to view subjects in a way that is not possible by a 1:1 interpretation, with 
new toolsets and techniques providing a springboard for discovereing new and emergent patterns that are 
not visible to the naked eye. This work uses techniques in procedural modeling to visualize the density 
of tall buildings in central Philadelphia, Pennsylvania. The rules for the work s execution are simple: 
Notate the heights of existing buildings within the limits of Center City Philadelphia using procedural 
modeling to quickly reach an analytical result. While this is possible with more conventional analog 
means, the use of procedural modeling (specifically the Grasshopper plug-in for Rhinoceros) allows quick 
and precise visualization of large fields of data. In this case, 24,000+ circles are used to notate the 
building heights of Center City on a block-by­block basis, using distance and division objects to generate 
a field of generic circles, one field for each building, each building field composited one atop the 
other. The emergent patterns formed by densities and gradients begin to notate gaps in building heights 
while providing information on potential locations for new large structures. www.dis-section.com  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667292</article_id>
		<sort_key>270</sort_key>
		<display_label>Article No.</display_label>
		<display_no>23</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[I'm not there]]></title>
		<subtitle><![CDATA[extending the range of human senses to benefit wildlife corridors]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667292</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667292</url>
		<abstract>
			<par><![CDATA[<p>How many experiences do we miss -- either through inattention or our own limitations -- when walking through the woods or diving with scuba mask and flippers? All around us, animals communicate and perceive with senses quite different from our own that have evolved from particular needs. Just as humans have employed technology to overcome limitations of physical strength, dexterity, and distance, so can we imagine technologies that enable us to extend our senses by taking cues from birds, whales, and other animals.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.4</cat_node>
				<descriptor>Sociology</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455.10010461</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences->Sociology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797223</person_id>
				<author_profile_id><![CDATA[81361605368]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[LaFayette]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Texas A&M University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797224</person_id>
				<author_profile_id><![CDATA[81100304539]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fred]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Texas A&M University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797225</person_id>
				<author_profile_id><![CDATA[81100069081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ann]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McNamara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Texas A&M University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797226</person_id>
				<author_profile_id><![CDATA[81500647152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Galanter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Texas A&M University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 I m not there: extending the range of human senses to benefit wildlife corridors contact Carol LaFayette 
Fred Parke Texas A&#38;M University Ann McNamara lurleen@viz.tamu.edu Philip Galanter Texas A&#38;M University 
 How many experiences do we miss either through inattention or our own limitations when walking through 
the woods or diving with scuba mask and flippers? All around us, animals communicate and perceive with 
senses quite different from our own that have evolved from particular needs. Just as humans have employed 
technology to overcome limitations of physical strength, dexterity, and distance, so can we imagine technologies 
that enable us to extend our senses by taking cues from birds, whales, and other animals. In an immersive 
environment, users experience extended senses of sight, sound, and locomotion in ways normally perceived 
only by other animals. This is a prototype for a real-time project that provides freedom to roam through 
remote places with enhanced senses and, as a result, benefit wildlife corridors around the world. It 
uses scientific research as the basis for a study that will ultimately result in a real-time application. 
In the prototype, the user embodies the creature and experiences the world through a simulation of the 
creature s audio, visual, and spatial sensations. Audio is manipulated to give a representation of the 
sensation experienced by the creature. Visual information is analyzed and re-represented to perceive 
spectra outside human range. Navigation through the world mimics the locomotion of specific creatures 
(flying, climbing, or swimming, for example). The project explores fundamental questions about our own 
mental, physiological, and technical interpretations. For example, it s possible to imagine sound translated 
from beyond the ear s frequency range, but what would it be like to sense electrical fields like a shark? 
The motivation for our study is a wish to encourage empathy with and curiosity about other species, the 
environment, and our place within it. Our larger ambition is to build an interactive real-time, global 
nature channel . 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667293</article_id>
		<sort_key>280</sort_key>
		<display_label>Article No.</display_label>
		<display_no>24</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[The Katrina project]]></title>
		<subtitle><![CDATA[NO-LA]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667293</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667293</url>
		<abstract>
			<par><![CDATA[<p>The Katrina Project: NO-LA involves collaborators from art, design, behavioral science, journalism, and community outreach. A database-driven, activist web site explores the psychological and social effects of the storm and its aftermath through interviews with, and works by various artists in New Orleans and Los Angeles.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797227</person_id>
				<author_profile_id><![CDATA[81100421713]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Victoria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vesna]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797228</person_id>
				<author_profile_id><![CDATA[81458646986]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Lucas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797229</person_id>
				<author_profile_id><![CDATA[81458646203]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Claes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Andersson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Public Radio]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797230</person_id>
				<author_profile_id><![CDATA[81458654584]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Katrina Project: NO-LA contact Victoria Vesna The Katrina Project: NO-LA involves collaborators 
from art, University of California, design, behavioral science, journalism, and community outreach. Los 
Angeles A database-driven, activist web site explores the psychological and social effects of the storm 
and its aftermath through interviews W.H. Lucas with, and works by various artists in New Orleans and 
Los Angeles. University of California, Los Angeles The Katrina Project was initiated immediately after 
the Katrina disaster by Kenneth Wells, professor-in-residence of Psychiatry and Claes Andersson Biobehavioral 
Sciences at the University of California, Los Angeles, National Public Radio who studies environmental 
effects on mental health. He approached Victoria Vesna, then chair of UCLA Design | Media Jay Yan Arts 
to help devise a communication system that would prepare University of California, victims for the psychological 
impact of the storm. She turned to Los Angeles Henri Lucas, an activist designer who teaches in the department 
and led a class of student researchers for this project. After a few Graduate Students permutations, 
the project reoriented to look at the connection Kimberly Townes between Lousiana and Los Angeles, with 
a focus on the creative Andreas Colubri community that works on raising consciousness around issues Estevan 
Carlos Benson raised by this tragedy. The team was joined by Claess Andersson, a reporter for NPR who 
conducted a series of interviews with Undergraduate Students filmmakers, artists, dancers, musicians, 
architects, and cooks, Spring 2006 Print Class including filmmaker Wendy Gary Berman, film director Laura 
of W.H. Lucas Beesley, and Sam Durant, artist and co-founder of Transforma, who worked with local organizations 
in New Orleans. The web site UCLA Center for extends beyond Los Angeles to become a database of works 
by Community Partnerships moviemakers, photographers, and others in the creative community. It is designed 
by media artist Jay Jiacong. http://artsci.ucla.edu/katrina  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667294</article_id>
		<sort_key>290</sort_key>
		<display_label>Article No.</display_label>
		<display_no>25</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Landmark status]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667294</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667294</url>
		<abstract>
			<par><![CDATA[<p>Travelers and dwellers often use landmarks to navigate within an environment. In the planometric mapping of landmark prominence, emergent patterns and networks articulate not only existing situations, but also future connections.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797231</person_id>
				<author_profile_id><![CDATA[81320495814]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trempe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667295</article_id>
		<sort_key>300</sort_key>
		<display_label>Article No.</display_label>
		<display_no>26</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[The MBTI map]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667295</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667295</url>
		<abstract>
			<par><![CDATA[<p>The MBTI Map represents relationships among the words that describe people's personalities using the methodology of knowledge visualization and a subway map as a metaphor.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor>Sociology</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455.10010461</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences->Sociology</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797232</person_id>
				<author_profile_id><![CDATA[81458644133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Seokhyun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Daum Communications]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797233</person_id>
				<author_profile_id><![CDATA[81458649777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Seonhee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ajou University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797234</person_id>
				<author_profile_id><![CDATA[81547483656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Joohee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bae]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ajou University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797235</person_id>
				<author_profile_id><![CDATA[81458649141]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Suejean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ajou University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797236</person_id>
				<author_profile_id><![CDATA[81458650861]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jisu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ajou University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797237</person_id>
				<author_profile_id><![CDATA[81458652821]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Kyungwon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ajou University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The MBTI Map contact Seokhyun Jang Seonhee Kang Daum Communications Joohee Bae chang13@ajou.ac.kr Suejean 
Ko Jisu Lee Kyungwon Lee Ajou University The MBTI Map represents relationships among the words that 
describe people s personalities using the methodology of knowledge visualization and a subway map as 
a metaphor. MBTI (Myers-Briggs Type Indicator) is a questionnaire designed to identify certain types 
of personality characteristics. A total of 16 types can be identified by the test. This project proposes 
the MBTI Map as a way to signify relationships among the words that describe people s personalities. 
We asked a sample of 80 individuals to rank the degree of closeness between a dyadic pair of words, to 
determine how these concepts are congruently clustered together. The result showed that a total of 39 
representative words were extracted from 161 words that are used in describing personal characteristics 
in the 16 MBTI types. We also obtained distances among 39 representative words through the MDS (Multi-Dimensional 
Scaling) method. The visualization represents the relationships among the 39 representative words and 
16 types of personalities. The subway lines indicate 16 MBTI personality types. All stations are arranged 
based on the semantic distance from the MDS analysis. The x-axis represents warm to cool, and the y-axis 
dynamic to quiet. In addition, 161 words used to describe personalities in the MBTI are hierarchically 
arranged at the outer circle. The MBTI Map helps viewers intuitively understand the overall picture of 
cluster relationships by minimizing the repetition of colors and intersecting points of connection among 
words. design.ajou.ac.kr/~thembtimap  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667296</article_id>
		<sort_key>310</sort_key>
		<display_label>Article No.</display_label>
		<display_no>27</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[MSNBC Hurricane tracker]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667296</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667296</url>
		<abstract>
			<par><![CDATA[<p>Stamen Design worked with MSNBC and Hurricane Mapping to bring hurricane tracking data from the National Hurricane Center to a larger audience in an interactive, visual form. The data include the past, present, and forecast location of the storm; contours for areas affected by high wind speeds; and the probability of hurricane-force winds throughout the United States.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405</concept_id>
				<concept_desc>CCS->Applied computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797238</person_id>
				<author_profile_id><![CDATA[81458651069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Migurski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stamen Design]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 MSNBC Hurricane Tracker contact Michal Migurski Stamen Design mike@stamen.com Stamen Design worked 
with MSNBC and Hurricane Mapping to bring hurricane tracking data from the National Hurricane Center 
to a larger audience in an interactive, visual form. The data include the past, present, and forecast 
location of the storm; contours for areas affected by high wind speeds; and the probability of hurricane-force 
winds throughout the United States. An introductory animation shows the progression of the storm with 
an animated hurricane icon moving at a speed proportional to the ground speed of the hurricane. The animation 
is dynamically generated using the latest hurricane data a significant improvement on early online hurricane 
maps, which were either static or generated by hand. The hurricane data are presented in both chart and 
map form, and the chart and map are linked interactively so that using the mouse to explore the chart 
highlights the appropriate area on the map, and vice-versa. This original approach ensures a closer understanding 
of the relationship between the chart and the map, reinforced by the introductory animation. The map 
itself was desaturated and inverted to give a solid dark background to the data, an unusual approach 
for online maps. The hurricane path and contour data were colored by the strength of winds, with point 
positions using the standard Saffir Simpson scale and wind­speed contours using solid and textured fills 
to indicate the difference between known and predicted information. Stamen s approach was ultimately 
focused on bringing together two commodity data layers, Microsoft s Virtual Earth and the NHC storm tracking 
data, and making them appropriate and useful in a web context. There are many credible alternatives online, 
but this unique approach produced a map that is informative, timely, and visually appealing. hurricanetracker.msnbc.com/ 
 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667297</article_id>
		<sort_key>320</sort_key>
		<display_label>Article No.</display_label>
		<display_no>28</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Multiscale meta shape grammar objects for "...a grain of sand turns the balance" and ATLAS in silico]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667297</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667297</url>
		<abstract>
			<par><![CDATA[<p>This aesthetically impelled work explores the use of dimensional glyphs generated by a custom meta-shape grammar algorithm to visually differentiate individual records from a massive meta-genomics dataset comprised of 17.4 million sequences and place them in a human context to reflect on the digitization of nature and culture. The Global Ocean Sampling Expedition, conducted by the J. Craig Venter Institute, studies genetics of communities of marine microorganisms throughout the world's oceans, which sequester carbon from the atmosphere with potentially significant effects on global climate. The vast dataset contains DNA sequences, 17.4 million associated, predicted amino-acid sequences called ORFs (Open Reading Frames) along with a series of metadata descriptors.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797239</person_id>
				<author_profile_id><![CDATA[81320496219]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ruth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[West]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797240</person_id>
				<author_profile_id><![CDATA[81409595942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Weta Digital]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797241</person_id>
				<author_profile_id><![CDATA[81100629781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Todd]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Margolis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797242</person_id>
				<author_profile_id><![CDATA[81314494181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Joachim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gossmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797243</person_id>
				<author_profile_id><![CDATA[81100047808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jurgen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schulze]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797244</person_id>
				<author_profile_id><![CDATA[81392619075]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tenedorio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797245</person_id>
				<author_profile_id><![CDATA[81100278652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Rajvikram]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Singh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, San Diego]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Multiscale Meta Shape Grammar Objects for ...a grain of sand turns the balance and ATLAS in silico contact 
Ruth West JP Lewis Todd Margolis University of California, Los Angeles Weta Digital Joachim Gossmann 
rwest@cens.ucla.edu Jurgen Schulze Daniel Tenedorio Rajvikram Singh University of California, San Diego 
 This aesthetically impelled work explores the use of dimensional glyphs generated by a custom meta-shape 
grammar algorithm to visually differentiate individual records from a massive meta­genomics dataset comprised 
of 17.4 million sequences and place them in a human context to reflect on the digitization of nature 
and culture. The Global Ocean Sampling Expedition, conducted by the J. Craig Venter Institute, studies 
genetics of communities of marine microorganisms throughout the world s oceans, which sequester carbon 
from the atmosphere with potentially significant effects on global climate. The vast dataset contains 
DNA sequences, 17.4 million associated, predicted amino-acid sequences called ORFs (Open Reading Frames) 
along with a series of metadata descriptors. These images and sculptures are a subset of a vast aesthetically 
impelled in silico atlas. They were created as part of an art­science collaboration developing ATLAS 
in silico, an interactive installation where they take on different forms to function as scalable interactive 
data objects within a virtual environment. Two-dimensional projections of the scalable interactive objects 
are combined with a second distinct format that places each algorithmic object in the role of natural 
specimen. The result is presented in stylistic conventions that illustrate linkages between art and science 
in the 19th century.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667298</article_id>
		<sort_key>330</sort_key>
		<display_label>Article No.</display_label>
		<display_no>29</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[News Knitter]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667298</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667298</url>
		<abstract>
			<par><![CDATA[<p>News Knitter materializes ephemeral online data through wearable garments. Large-scale data gathered from online political news is used as a source to generate patterns for a fully computerized knitting machine. Knitting, a very conventional mode of physical production, is preferred as a medium to embody digital information and to produce daily, wearable, washable sweaters. Digital bits are transformed into physical stitches and the information is visualized through three-dimensional, tactile, personal belongings.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided manufacturing (CAM)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010483</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Computer-aided manufacturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797246</person_id>
				<author_profile_id><![CDATA[81458649006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ebru]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kurbak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#228;t f&#252;r k&#252;nstlerische und industrielle Gestaltung Linz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797247</person_id>
				<author_profile_id><![CDATA[81448592327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mahir]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Yavuz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#228;t f&#252;r k&#252;nstlerische und industrielle Gestaltung Linz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 News Knitter contact Ebru Kurbak Mahir M. Yavuz Universität für künstlerische und Universität für 
künstlerische und industrielle Gestaltung Linz industrielle Gestaltung Linz ebrukurbak@gmail.com News 
Knitter materializes ephemeral online data through wearable garments. Large-scale data gathered from 
online political news is used as a source to generate patterns for a fully computerized knitting machine. 
Knitting, a very conventional mode of physical production, is preferred as a medium to embody digital 
information and to produce daily, wearable, washable sweaters. Digital bits are transformed into physical 
stitches and the information is visualized through three-dimensional, tactile, personal belongings. News 
Knitter proposes an innovative workflow and production pipeline as an alternative for the common methods 
of fabrication of knitted garments. It translates the individual design process of patterning into a 
worldwide collaboration by utilizing live data streams as a source for pattern generation. Due to the 
dynamic nature of live data streams, the elements of worldwide participation and unpredictability are 
introduced into the design process. Situated at the intersection of digital data visualization and analog 
knitting, News Knitter offers a fresh insight to new modes of industrial production. It brings two controversial 
concepts, unique design and mass production, into discussion. casualdata.com/newsknitter/  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667299</article_id>
		<sort_key>340</sort_key>
		<display_label>Article No.</display_label>
		<display_no>30</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Oakland Crimespotting]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667299</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667299</url>
		<abstract>
			<par><![CDATA[<p>Oakland Crimespotting is a research project of Stamen Design developed as a response to the existing Oakland, California Police Department crime-reporting application, CrimeWatch. It is an instance of the now-familiar "mashup", an online application derived from multiple input data sources. Many works in this genre stop at placing colored pins on a map, but we looked at ways to expand the typical functionality of the ubiquitous crime map to make it more useful for local citizens. As with many projects, Crimespotting didn't start with a concrete goal in mind; it was born out of frustration, matured through basic technical research, and finally made public after a traumatic crime in Oakland focused national attention on the city.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.1</cat_node>
				<descriptor>Law</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Statistical databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010442</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Mathematics and statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003244</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Data analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455.10010458</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences->Law</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Legal Aspects</gt>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797248</person_id>
				<author_profile_id><![CDATA[81458651069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Migurski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stamen Design]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797249</person_id>
				<author_profile_id><![CDATA[81458649297]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carden]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stamen Design]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Oakland Crimespotting contact Michal Migurski Tom Carden Stamen Design Stamen Design mike@stamen.com 
 Oakland Crimespotting is a research project of Stamen Design developed as a response to the existing 
Oakland, California Police Department crime-reporting application, CrimeWatch. It is an instance of the 
now-familiar mashup , an online application derived from multiple input data sources. Many works in this 
genre stop at placing colored pins on a map, but we looked at ways to expand the typical functionality 
of the ubiquitous crime map to make it more useful for local citizens. As with many projects, Crimespotting 
didn t start with a concrete goal in mind; it was born out of frustration, matured through basic technical 
research, and finally made public after a traumatic crime in Oakland focused national attention on the 
city. We paid special attention to the ways in which such data can be more web resident, by providing 
every view, list, police beat, and individual report with its own permanent URL. Locally useful information 
of the kind published through Crimespotting is a form of community property and must be available for 
linking and conversation in order to be optimally useful to the population affected by the data. As the 
project has matured since its launch in September 2007, we have expanded it into newer forms of data 
representation. Individual police­beat pages were added in 2008 after feedback from our users suggested 
that these administrative boundaries were an important point of communication with the police department. 
Currently, we re extending the beat pages with maps that we believe address critical shortcomings in 
existing implementations of the concept. oakland.crimespotting.org/  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667300</article_id>
		<sort_key>350</sort_key>
		<display_label>Article No.</display_label>
		<display_no>31</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[OpenStreetMap 2008]]></title>
		<subtitle><![CDATA[a year of edits]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667300</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667300</url>
		<abstract>
			<par><![CDATA[<p>OpenStreetMap is a wiki-style map of the world. In this animation, each time a feature is entered or updated it flashes white and then decays through yellow and red to purple. Some edits are a result of a physical local survey by a contributor with a GPS unit and a notepa. Other edits are done remotely using aerial photography or out-of-copyright maps. Large areas of simultaneous edits are the result of bulk imports of official or donated commercial data.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.2</cat_node>
				<descriptor>Earth and atmospheric sciences</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010437</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Earth and atmospheric sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797250</person_id>
				<author_profile_id><![CDATA[81332490189]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bertram]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ito World Ltd]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 OpenStreetMap 2008: A Year of Edits contact Hal Bertram Ito World Ltd sis@halbertram.com OpenStreetMap 
is a wiki-style map of the world. In this animation, each time a feature is entered or updated it flashes 
white and then decays through yellow and red to purple. Some edits are a result of a physical local survey 
by a contributor with a GPS unit and a notepa. Other edits are done remotely using aerial photography 
or out-of-copyright maps. Large areas of simultaneous edits are the result of bulk imports of official 
or donated commercial data. OpenStreetMap started in 2004, and the rate of contributions is accelerating. 
Four times more people contributed to the project in 2008 compared to 2007. During the year, edits were 
made by over 20,000 individuals, and there were bulk imports of data for many places, including the USA, 
India, Italy, and Belarus, which are clearly visible in the animation. The goal of this animation was 
to show how the OpenStreepMap community had become truly global from its roots in the United Kingdom. 
It was designed to celebrate the combined work of the community, most of whom are working on a much smaller 
scale. www.itoworld.com  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667301</article_id>
		<sort_key>360</sort_key>
		<display_label>Article No.</display_label>
		<display_no>32</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Out of statistics]]></title>
		<subtitle><![CDATA[beyond legal]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667301</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667301</url>
		<abstract>
			<par><![CDATA[<p>With an aesthetic approach, Out of Statistics: Beyond Legal produces a series of abstract drawings based on US crime statistics as archival-ink digital prints on rice paper. Each image represents the crime status in one of the states, with the seven most significant crime-conviction statistics of each state embedded.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.1</cat_node>
				<descriptor>Law</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455.10010458</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences->Law</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Legal Aspects</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797251</person_id>
				<author_profile_id><![CDATA[81458647312]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[Ruige]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Missouri State Univerisity]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797252</person_id>
				<author_profile_id><![CDATA[81335500271]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sean]]></first_name>
				<middle_name><![CDATA[Hongsheng]]></middle_name>
				<last_name><![CDATA[Zhai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Out of Statistics: Beyond Legal contact Rebecca Ruige Xu Sean Hongsheng Zhai Missouri State Univerisity 
floatingcube.org rebeccaxu@missouristate.edu With an aesthetic approach, Out of Statistics: Beyond Legal 
produces a series of abstract drawings based on US crime statistics as archival-ink digital prints on 
rice paper. Each image represents the crime status in one of the states, with the seven most significant 
crime-conviction statistics of each state embedded. In order to bring a fine-art quality and a natural, 
hand-drawn feel into the data visualization, the artists developed an algorithm based on their experience 
and analysis of experimental drawings. The algorithm was implemented using Python programming and SVG 
(Scalable Vector Graphics). As demonstrated in the legend of this work, each type of crime is mapped 
to a unique drawing stroke. Images are then created using these patterns, following a set of composition 
rules defined by the artists. The visual style of the project is influenced by Minimalism and traditional 
Asian art. Rice paper was chosen as the medium because its delicate texture and translucent quality can 
add grace to the images. The images can be viewed and judged solely as abstract artworks and still serve 
the function of visualization. Decoding the embedded information would then become an optional and additional 
interesting experience that viewers may potentially find rewarding. An observant viewer may discover 
that the interplay of black and white reflects the density of unlawful incidents in a particular state. 
Darker areas of the image represent places with more crimes. This project attempts to raise awareness 
of the current social conditions in each US state. Paradoxically, it visualizes crime-related data as 
elegant compositions and visually pleasing images. In this way, it questions the impact of data visualization 
on human perception of information. floatingcube.org/beyondlegal/  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667302</article_id>
		<sort_key>370</sort_key>
		<display_label>Article No.</display_label>
		<display_no>33</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Passing "Place for Games"]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667302</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667302</url>
		<abstract>
			<par><![CDATA[<p>Passing "Place for Games" visualizes the world famous Kizhi site as high-resolution 3D environment. The goal of this project is to create a virtual prototype of the current state of Kizhi wooden architecture. Kizhi museum preserves a concentration of masterpieces of the Russian heritage and protected by World Heritage List of UNESCO. It is located on an island in Lake Onega in northern Karelia in Russia. Word "kizhi" is translated from Karelian as "a place for games". In ancient times people gathered here and performed their religious rituals. The visualization reconstructs the original architecture of Kizhi island based on the detailed photographs, architectural and geometric measurements, textural data and video surveys taken during the visit of Kizhi as well as geometric analysis of the surviving structure. The project strives to advance the development of historical restoration in an artistic direction. It is being developed using latest concepts in real-time graphics, including complex illumination with dynamic irradiance environment mapping, shadow mapping, and complex materials containing normal and gloss mapping.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797253</person_id>
				<author_profile_id><![CDATA[81335498954]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsoupikova]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797254</person_id>
				<author_profile_id><![CDATA[81331496707]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kooima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Louisiana State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Passing Place for Games contact Daria Tsoupikova Robert Kooima University of Illinois at Chicago Louisiana 
State University datsoupi@gmail.com  Passing Place for Games visualizes the world famous Kizhi site 
as high-resolution 3D environment. The goal of this project is to create a virtual prototype of the current 
state of Kizhi wooden architecture. Kizhi museum preserves a concentration of masterpieces of the Russian 
heritage and protected by World Heritage List of UNESCO. It is located on an island in Lake Onega in 
northern Karelia in Russia. Word kizhi is translated from Karelian as a place for games . In ancient 
times people gathered here and performed their religious rituals. The visualization reconstructs the 
original architecture of Kizhi island based on the detailed photographs, architectural and geometric 
measurements, textural data and video surveys taken during the visit of Kizhi as well as geometric analysis 
of the surviving structure. The project strives to advance the development of historical restoration 
in an artistic direction. It is being developed using latest concepts in real-time graphics, including 
complex illumination with dynamic irradiance environment mapping, shadow mapping, and complex materials 
containing normal and gloss mapping. 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667303</article_id>
		<sort_key>380</sort_key>
		<display_label>Article No.</display_label>
		<display_no>34</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Rhythm analysis; a temporal stereopsis of urban telecommunication data topography]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667303</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667303</url>
		<abstract>
			<par><![CDATA[<p>This inspirational installation reveals a stereoscopic representation of temporal and spatial telecommunication data, an urban communication indicator of everyday life, for 24 hours in a central area of Seoul, created by "transparent LED display sheets" of conductive carbon nanotubes.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Stereo</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Signal processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797255</person_id>
				<author_profile_id><![CDATA[81458652394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eunju]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Royal College of Art]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Rhythm Analysis; A Temporal Stereopsis of Urban Telecommunication Data Topography contact Eunju Han 
Royal College of Art eunjuhan.arch@gmail.com This inspirational installation reveals a stereoscopic 
representation of temporal and spatial telecommunication data, an urban communication indicator of everyday 
life, for 24 hours in a central area of Seoul, created by transparent LED display sheets of conductive 
carbon nanotubes. We live in electronic surroundings that are invisible and intangible, though they are 
very powerfully influential in our lives. Communicative devices such as mobile phones are becoming more 
and more dependent on digital technology. This urban telecom data visualization in stereoscopic displays 
on layered, transparent LED sheets reflects data changes hour after hour, so we can recognize telecommunication 
transitions in urban space over time, which makes it possible to deduce the rhythm in everyday life. 
In addition, this urban telecom datascape conveys an inspirational insight on a new cognitive communication 
domain in urban space. By adopting one of the most notable and futuristic high-tech inventions, this 
combination of conceptual design and advanced technology suggests the future direction of cross-disciplinary 
work.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667304</article_id>
		<sort_key>390</sort_key>
		<display_label>Article No.</display_label>
		<display_no>35</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[The Sky Oracle]]></title>
		<subtitle><![CDATA[immersive flowchart representation for the annexation of Tibet]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667304</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667304</url>
		<abstract>
			<par><![CDATA[<p>The Sky Oracle on the University of Florida's Second China Island in Second Life applies an interactive, immersive aesthetic to the representation of structured information in the form of a control-flow diagram (a representation of both information and software). The diagram captures two different time periods in the history of Tibetan annexation, with a two-way branch flow indicating two different perspectives labeled Chinese vs. US. An example of aesthetic computing, this "walk-through" flowchart presents a novel approach for interacting with behavioral information by combining a sense of audio, and visual presence to explore the concept of cognitive dissonance.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>D.2.2</cat_node>
				<descriptor>Flow charts</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405</concept_id>
				<concept_desc>CCS->Applied computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011092.10011094</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development techniques->Flowcharts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797256</person_id>
				<author_profile_id><![CDATA[81327488439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fishwick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797257</person_id>
				<author_profile_id><![CDATA[81414611686]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Henderson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797258</person_id>
				<author_profile_id><![CDATA[81414619471]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Elinore]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fresh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797259</person_id>
				<author_profile_id><![CDATA[81448600313]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Rasha]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kamhawi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797260</person_id>
				<author_profile_id><![CDATA[81458648808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[Jo]]></middle_name>
				<last_name><![CDATA[Coffey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797261</person_id>
				<author_profile_id><![CDATA[81453617802]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hamilton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[SAIC Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Sky Oracle: Immersive Flowchart Representation for the Annexation of Tibet Paul Fishwick Benjamin 
Hamilton Julie Henderson SAIC Corporation Elinore Fresh Rasha Kamhawi Amy Jo Coffey University of Florida 
 The Sky Oracle on the University of Florida s Second China Island in Second Life applies an interactive, 
immersive aesthetic to the representation of structured information in the form of a control­flow diagram 
(a representation of both information and software). The diagram captures two different time periods 
in the history of Tibetan annexation, with a two-way branch flow indicating two different perspectives 
labeled Chinese vs. US. An example of aesthetic computing, this walk-through flowchart presents a novel 
approach for interacting with behavioral information by combining a sense of audio, and visual presence 
to explore the concept of cognitive dissonance. What are the effects of interacting with software in 
this way? Can flow charts be effective in presentation of complex news stories or public affairs issues? 
We are in the planning stages of a human­subject experiment along the lines of a channel study where 
modes of information delivery are compared and contrasted to see what benefits emerge from each form 
of representation.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667305</article_id>
		<sort_key>400</sort_key>
		<display_label>Article No.</display_label>
		<display_no>36</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[STOC (stock ticker orbital comparison)]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667305</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667305</url>
		<abstract>
			<par><![CDATA[<p>STOC is an interactive data visualization, using the metaphor of a planetary system, that maps parameters of stocks in the S&P 500 to animated visual outputs. Existing methods for displaying large amounts of stock-market data do not easily allow comparison between companies, as the data are often presented in tabular format. Some solutions implement a price-over-time graph, with the option of layering on additional stocks or market indices for comparison. STOC allows immediate comparison of hundreds or thousands of stocks, by mapping various stock-specific parameters (such as price percent change, earnings per share, volume, market capitalization, dividend yield, moving average, and comparison to the group average) to easily observable visual outputs (such as size, color, opacity, stroke width, satellite size, orbital distance, orbital direction, and speed).</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797262</person_id>
				<author_profile_id><![CDATA[81545821856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grant]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Advancing Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797263</person_id>
				<author_profile_id><![CDATA[81458651248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Todd]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spencer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Advancing Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797264</person_id>
				<author_profile_id><![CDATA[81458655110]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Armijo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Advancing Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 STOC (Stock Ticker Orbital Comparison) contact James Grant Todd Spencer University of Advancing Technology 
Richard Armijo uniformchaos@gmail.com University of Advancing Technology STOC is an interactive data 
visualization, using the metaphor of a planetary system, that maps parameters of stocks in the S&#38;P 
500 to animated visual outputs. Existing methods for displaying large amounts of stock-market data do 
not easily allow comparison between companies, as the data are often presented in tabular format. Some 
solutions implement a price-over-time graph, with the option of layering on additional stocks or market 
indices for comparison. STOC allows immediate comparison of hundreds or thousands of stocks, by mapping 
various stock-specific parameters (such as price percent change, earnings per share, volume, market capitalization, 
dividend yield, moving average, and comparison to the group average) to easily observable visual outputs 
(such as size, color, opacity, stroke width, satellite size, orbital distance, orbital direction, and 
speed). This visualization is particularly suited for comparisons between items, as users can immediately 
identify the largest, or reddest, or quickest item in the group. Users control the overall speed, zoom 
level, and clustering, and they can extract parametric details for each individual element in the group. 
This system is not limited to displaying stock-market data, and could be used in a wide range of statistical 
visualizations. For example, one could visualize the parameters of students in a university (such as 
grade-point average, credit completion rate, total credits, and student account balance) or the parameters 
of daily weather (daily temperature range, relative humidity, wind speed, precipitation, and comparison 
to record highs and lows).  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667306</article_id>
		<sort_key>410</sort_key>
		<display_label>Article No.</display_label>
		<display_no>37</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Synchronous Objects for One Flat Thing, reproduced]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667306</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667306</url>
		<abstract>
			<par><![CDATA[<p>Synchronous Objects for One Flat Thing, reproduced is an interactive screen-based work developed by The Ohio State University's Advanced Computing Center for the Arts and Design and the Department of Dance in collaboration with renowned choreographer William Forsythe. Pivoting on Forsythe's masterwork of visual complexity, One Flat Thing, reproduced (OFTr), the Synchronous Objects project seeks to enrich cross-disciplinary investigation and creativity by revealing deep structures of choreographic thinking through a vivid collection of information objects in the form of 3D computer animation, annotation, and interactive graphics.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Curve, surface, solid, and object representations</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor>Modeling methodologies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010399</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Parametric curve and surface models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010343</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Modeling methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396.10010401</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling->Volumetric models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797265</person_id>
				<author_profile_id><![CDATA[81319499178]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Maria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Palazzi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797276</person_id>
				<author_profile_id><![CDATA[81442607060]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Norah]]></first_name>
				<middle_name><![CDATA[Zuniga]]></middle_name>
				<last_name><![CDATA[Shaw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797285</person_id>
				<author_profile_id><![CDATA[81546675256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Forsythe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Forsythe Company]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797286</person_id>
				<author_profile_id><![CDATA[81339512248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797287</person_id>
				<author_profile_id><![CDATA[81448593522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Beth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Albright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797288</person_id>
				<author_profile_id><![CDATA[81458646048]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Andereck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797289</person_id>
				<author_profile_id><![CDATA[81448600146]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Sucheta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bhatawadekar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797290</person_id>
				<author_profile_id><![CDATA[81458650490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Hyowon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ban]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797291</person_id>
				<author_profile_id><![CDATA[81458645192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Calhoun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797266</person_id>
				<author_profile_id><![CDATA[81458653109]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Jane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Drozd]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797267</person_id>
				<author_profile_id><![CDATA[81458643498]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>11</seq_no>
				<first_name><![CDATA[Joshua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797268</person_id>
				<author_profile_id><![CDATA[81350587301]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>12</seq_no>
				<first_name><![CDATA[Melissa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Quintanilha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797269</person_id>
				<author_profile_id><![CDATA[81447599049]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>13</seq_no>
				<first_name><![CDATA[Anna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reed]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797270</person_id>
				<author_profile_id><![CDATA[81448593411]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>14</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schroeder]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797271</person_id>
				<author_profile_id><![CDATA[81458655322]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>15</seq_no>
				<first_name><![CDATA[Lily]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Skove]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797272</person_id>
				<author_profile_id><![CDATA[81458647675]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>16</seq_no>
				<first_name><![CDATA[Ashley]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thorndike]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797273</person_id>
				<author_profile_id><![CDATA[81458642761]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>17</seq_no>
				<first_name><![CDATA[Mary]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Twohig]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797274</person_id>
				<author_profile_id><![CDATA[81458654073]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>18</seq_no>
				<first_name><![CDATA[Ola]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ahlqvist]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797275</person_id>
				<author_profile_id><![CDATA[81448593270]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>19</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797277</person_id>
				<author_profile_id><![CDATA[81100499062]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>20</seq_no>
				<first_name><![CDATA[Noel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cressie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797278</person_id>
				<author_profile_id><![CDATA[81458647670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>21</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Turk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797279</person_id>
				<author_profile_id><![CDATA[81458645467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>22</seq_no>
				<first_name><![CDATA[Jill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Forsythe Company]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797280</person_id>
				<author_profile_id><![CDATA[81458653992]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>23</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Roman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Forsythe Company]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797281</person_id>
				<author_profile_id><![CDATA[81458647755]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>24</seq_no>
				<first_name><![CDATA[Elizabeth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Waterhouse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Forsythe Company]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797282</person_id>
				<author_profile_id><![CDATA[81458644588]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>25</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[deLahunta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Amsterdam School of the Arts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797283</person_id>
				<author_profile_id><![CDATA[81350573221]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>26</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haggard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University College London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797284</person_id>
				<author_profile_id><![CDATA[81538028256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>27</seq_no>
				<first_name><![CDATA[Alva]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Noe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Berkeley]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Synchronous Objects for One Flat Thing, reproduced  contact Maria Palazzi Matthew Lewis Jill Johnson 
The Ohio State University palazzi.1@osu.edu Norah Zuniga Shaw The Ohio State University Beth Albright 
Michael Andereck Sucheta Bhatawadekar Hyowon Ban Andrew Calhoun Jane Drozd Christopher Roman Elizabeth 
Waterhouse The Forsythe Company Scott deLahunta Amsterdam School of the Arts William Forsythe The Forsythe 
Company Joshua Fry Melissa Quintanilha Anna Reed Benjamin Schroeder Lily Skove Ashley Thorndike Mary 
Twohig Ola Ahlqvist Peter Chan Patrick Haggard University College London Alva Noe University of California, 
Berkeley Noel Cressie Stephen Turk The Ohio State University Synchronous Objects for One Flat Thing, 
reproduced is an interactive screen-based work developed by The Ohio State University s Advanced Computing 
Center for the Arts and Design and the Department of Dance in collaboration with renowned choreographer 
William Forsythe. Pivoting on Forsythe s masterwork of visual complexity, One Flat Thing, reproduced 
(OFTr), the Synchronous Objects project seeks to enrich cross-disciplinary investigation and creativity 
by revealing deep structures of choreographic thinking through a vivid collection of information objects 
in the form of 3D computer animation, annotation, and interactive graphics. Though dance is notoriously 
difficult to capture and document, Forsythe challenged our research group to develop a new kind of generative 
dance literature to stimulate the exchange of ideas and innovation in a wide range of disciplines. His 
choreography in OFTr is particularly exciting to analyze, due to the challenges it poses for visualizing 
a high density of interdependent relationships distributed across a network of 17 dancers navigating 
a landscape of a 20-table grid and resulting in a contrapuntal dance composition. Co-creative directors 
Maria Palazzi and Norah Zuniga Shaw gathered a multidisciplinary team of researchers from architecture, 
cognitive science, computer science, dance, design, geography, philosophy, and statistics to apply and 
cross­pollinate their disciplinary visualization methodologies in examining Forsythe s strategies. The 
research involved extensive work with The Forsythe Company to systematically analyze the material and 
systems of exchange that make up OFTr. As we parsed the dance into its hundreds of component parts, we 
were challenged to determine means of quantifying these data, using them to drive concrete and abstract 
interpretations, transformations, derivations, and interactive creative tools. This work underscores 
the profound possibilities in collaborations between major artists and interdisciplinary research teams 
using innovative and interpretive information-visualization methods in making meaningful visual literatures 
that have relevance in contemporary society.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667307</article_id>
		<sort_key>420</sort_key>
		<display_label>Article No.</display_label>
		<display_no>38</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Touch the invisibles]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667307</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667307</url>
		<abstract>
			<par><![CDATA[<p>This novel interface superimposes tactile information onto the images displayed on a computer monitor (see also Ando et al., SIGGRAPH 2002 Emerging Technologies). A small vibrator is attached to a user's fingenail, and when a vibration is presented during a finger movement, the vibration can be perceived as the stimulus from a finger pad, instead of a stimulus from the nail. This illusory percept of tactile information is the basis of this interface technology.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.2.10</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797292</person_id>
				<author_profile_id><![CDATA[81100363092]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Junji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watanabe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[PRESTO JST]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797293</person_id>
				<author_profile_id><![CDATA[81331497085]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eisuke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kusachi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Touch the Invisibles contact Junji Watanabe Eisuke Kusachi PRESTO JST Hideyuki Ando watanabe@avg.brl.ntt.co.jp 
Osaka University This novel interface superimposes tactile information onto the images displayed on 
a computer monitor (see also Ando et al., SIGGRAPH 2002 Emerging Technologies). A small vibrator is attached 
to a user s fingenail, and when a vibration is presented during a finger movement, the vibration can 
be perceived as the stimulus from a finger pad, instead of a stimulus from the nail. This illusory percept 
of tactile information is the basis of this interface technology. The vibrator is attached to user s 
nail with double sticky tape. The timing and magnitude of the vibration are controlled based on the position 
of the finger measured with the touch sensor of an LCD panel. When the user rubs an image, tactile feedbacks 
is presented. With this interface technology, any kind of visual image can be displayed with real-time 
tactile feedback. We used it to produce an artwork on the subject of how humans perceive the real and 
digital worlds through the sense of touch. In Touch the Invisibles, invisible Lilliputians are muddling 
on the computer monitor. When the user s finger encounters the invisible Lilliputians, vibrations are 
presented to the nail, and tactile information indicating an encounter is generated. The user cannot 
see the invisible Lilliputians but can touch them. On the other hand, the user cannot touch visible Lilliputians. 
The Lilliputians live in the area where modalities of human senses are partly separated. This artwork 
enables users to feel the association and dissociation of the two modalities, and demonstrates an application 
of haptic interfaces to art and entertainment. www.junji.org/invisibles/  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667308</article_id>
		<sort_key>430</sort_key>
		<display_label>Article No.</display_label>
		<display_no>39</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Towards the memory tower]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667308</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667308</url>
		<abstract>
			<par><![CDATA[<p>This digital installation explores the role of oscillatory brain-network states in memory consolidation. The aim of the work is to reconnect the science of the brain with the experiences that the brain engenders and to communicate complex neuro-scientific understanding in a meaningful and stimulating way to non-experts.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Signal processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.0</cat_node>
				<descriptor>Cognitive simulation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor>Modeling methodologies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010343</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Modeling methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010194</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Cognitive robotics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797294</person_id>
				<author_profile_id><![CDATA[81458646047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Senior]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Duke University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Towards the Memory Tower contact Timothy Senior Duke University timothy.joseph.senior@googlemail.com 
 This digital installation explores the role of oscillatory brain-network states in memory consolidation. 
The aim of the work is to reconnect the science of the brain with the experiences that the brain engenders 
and to communicate complex neuro­scientific understanding in a meaningful and stimulating way to non-experts. 
At the center of the installation is a single memory encoded within the cortex. It takes the form of 
a highly ornate and fragmented tower in the process of being bound into a single, unified entity (consolidated).This 
memory is embedded within a framework of rhythmically positioned towers designed to represent specific 
types of oscillatory brain activity and timing functions. Individual components of the tower are held 
together through ties that connect them to specific oscillatory phenomena during SWS. This reflects the 
input from a structure called the hippocampus, which serves an indexing role for the new memory as it 
is consolidated. These SWS oscillatory states are represented as the two outer rings of towers in the 
installation. Also embedded within this network are related, but older memories. Each expresses a specific 
architectural form that shares strong visual commonality with the central tower. These memories are more 
or less fully consolidated, so they do not require indexing through other structures and are sufficiently 
bound together to form a perceptual whole. By varying the forms of these previously consolidated memories, 
different types of memory processes are modeled; towers, for example, may represent episodic-like events 
(information bound together as an episode), while horizontally orientated buildings capture events that 
occur in time (procedural or sequential memory). As the new memory is being consolidated, a number of 
changes within the memory space occur, and these are reflected within the installation. Firstly, the 
central tower becomes bound to, or interleaved between, older memories, dictated by the similarities 
between architectural elements of the different structures. Secondly, and through this earlier process, 
a new mnemonic context is created for the older memories, one that renders them labile and drives new 
forms of connectivity between them.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667309</article_id>
		<sort_key>440</sort_key>
		<display_label>Article No.</display_label>
		<display_no>40</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Visual Genealogy]]></title>
		<subtitle><![CDATA[Mr. PARK, Myrang-Hwarok Clan]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667309</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667309</url>
		<abstract>
			<par><![CDATA[<p>A human life is not generated spontaneously; our existence is a random combination of hazy vestiges of our ancestors. The idea behind this artwork is to compress half a millennium of data about people's lives into a single computer-generated image. Visual Genealogy shows the family tree of Mr. Park (Myrang clan, hwarok party) and reveals the cognitive meanings of a complex dataset (in this case, the data are life and death).</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.3</cat_node>
				<descriptor>Medical information systems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Fine arts</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010470</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Fine arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010447</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health care information systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797295</person_id>
				<author_profile_id><![CDATA[81319498806]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jin]]></first_name>
				<middle_name><![CDATA[Wan]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chung-Ang University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797296</person_id>
				<author_profile_id><![CDATA[81448593001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gyuwan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Choe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chung-Ang University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Visual Genealogy: Mr. PARK, Myrang-Hwarok Clan contact Jin Wan Park Gyuwan Choe Chung-Ang University 
Chung-Ang University jinpark@cau.ac.kr A human life is not generated spontaneously; our existence is 
a random combination of hazy vestiges of our ancestors. The idea behind this artwork is to compress half 
a millennium of data about people s lives into a single computer-generated image. Visual Genealogy shows 
the family tree of Mr. Park (Myrang clan, hwarok party) and reveals the cognitive meanings of a complex 
dataset (in this case, the data are life and death). Information visualization is an interdisciplinary 
field that combines topics such as computer graphics and user-interface design into a cognitively plausible 
way of presenting information to enhance understanding. The Korean family tree, called a Jokbo, provides 
a unique theme for visualization study. In addition to the usual problems of information visualization, 
it requires display of a large database (sometimes containing over a million records). This artwork can 
be seen as a successful application of techniques for intuitive understanding of large datasets. The 
brightest node in this family tree, right in the center of the image, is one of Mr. Park s ancestors 
who lived about 500 years ago. And Mr. Park himself is located at the very bottom of the picture. His 
grandfather and 20 generations of other descendants may never have read the Biblical sentence: I will 
surely bless you and make your descendants as numerous as the stars in the sky and as the sand on the 
seashore. But the ancestor at the root of this family tree would surely be glad to know that 27,404 
sons and grandsons (stars) sharing his surname lived after him in his world. A preliminary form of this 
artwork was shown in the SIGGRAPH 2007 Art Gallery. Since then, the visualization has been completely 
re-programmed with more data. www.jinwanpark.com  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667310</article_id>
		<sort_key>450</sort_key>
		<display_label>Article No.</display_label>
		<display_no>41</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[VisualPoetry - generative graphic design for poetry on the road]]></title>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667310</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667310</url>
		<abstract>
			<par><![CDATA[<p>VisualPoetry generates poetic and abstract visual representations of poetry. It is unique. Few other design projects embrace the concepts of generative design over such a long period of time. The representations are used for graphic design of the literature festival Poetry on the Road in Bremen, Germany, where VisualPoetry has become an integral part of the festival itself.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797297</person_id>
				<author_profile_id><![CDATA[81458652204]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Boris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mueller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fachhochschule Potsdam]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 VisualPoetry - Generative Graphic Design for Poetry on the Road contact Boris Mueller Fachhochschule 
Potsdam boris@esono.com VisualPoetry generates poetic and abstract visual representations of poetry. 
It is unique. Few other design projects embrace the concepts of generative design over such a long period 
of time. The representations are used for graphic design of the literature festival Poetry on the Road 
in Bremen, Germany, where VisualPoetry has become an integral part of the festival itself. The highly 
interdisciplinary approach and the strong link between the input (poems) and the output (visuals) is 
unusual. as it bridges the disciplines of design, computer science, and literature. While the basic concept 
of VisualPoetry is always the same, the visual strategies change every year. The 2003 version was based 
on the concept of a drawing machine controlled by the sequence of the letters in the poem. In 2005, text 
was used to generate organic, treelike structures. In 2006, the visual resembled an information visualization. 
In the context of the design discipline, the achievement of VisualPoetry is that a specific idea is the 
center of the corporate identity and not a specific form. www.esono.com/boris/projects/poetry06/  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667311</article_id>
		<sort_key>460</sort_key>
		<display_label>Article No.</display_label>
		<display_no>42</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[well-formed.eigenfactor]]></title>
		<subtitle><![CDATA[visualizing information flow in science]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667311</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667311</url>
		<abstract>
			<par><![CDATA[<p>well-formed.eigenfactor presents interactive visualizations to explore emerging patterns in scientific citation networks. The Eigenfactor project calculates a measure of importance for individual journals (the Eigenfactor score), measures citation flow, and creates a hierarchical clustering. Moritz Stefaner turns this information into a set of four information-aesthetic visualizations, each highlighting different aspects of the data.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.3.1</cat_node>
				<descriptor>Abstracting methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003318</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Document representation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010124.10010138.10011119</concept_id>
				<concept_desc>CCS->Theory of computation->Semantics and reasoning->Program reasoning->Abstraction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797298</person_id>
				<author_profile_id><![CDATA[81350572664]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Moritz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stefaner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fachhochschule Potsdam]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797299</person_id>
				<author_profile_id><![CDATA[81442615587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosvall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797300</person_id>
				<author_profile_id><![CDATA[81414618154]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bergstrom]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Washington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 well-formed.eigenfactor: Visualizing Information Flow in Science contact Moritz Stefaner Martin Rosvall 
Fachhochschule Potsdam Carl Bergstrom moritz@stefaner.eu University of Washington  well formed.eigenfactor 
presents interactive visualizations to explore emerging patterns in scientific citation networks. The 
Eigenfactor project calculates a measure of importance for individual journals (the Eigenfactor score), 
measures citation flow, and creates a hierarchical clustering. Moritz Stefaner turns this information 
into a set of four information aesthetic visualizations, each highlighting different aspects of the data. 
In visualizations of citation networks, both ball and-stick like network representations and maps are 
prevalent. This project extends the visual vocabulary on the one hand, by re-purposing existing techniques, 
such as radial-edge bundling and treemaps, and on the other hand, by inventing novel approaches like 
magnetic pins as flow indicators and an alluvial diagram to represent change over time in cluster structures. 
Citation patterns: a clean, yet organic radial network visualization that gives an overview of the whole 
citation graph. The radial-edge bundling technique effectively highlights the cluster structure and interdisciplinary 
citation links. Change over time: This stacked bar-chart diagram displays changes in Eigenfactor score 
and clustering over time. Clustering: Based on the squarified treemap layout algorithm, this visualization 
features magnetic pins to indicate both incoming and outgoing citation flow for any selected journal. 
Map: This map visualization puts journals that frequently cite each other, closer together. You can drag 
the white magnification lens around to enlarge a part of the map for closer inspection. Data: A subset 
of the citation data from Thomson Reuters Journal Citation Reports 1997 2005. For the visualizations, 
400 journals with their approximately 13,000 citation edges were selected, ensuring coverage of the top 
journals in each field. well-formed.eigenfactor.org  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667312</article_id>
		<sort_key>470</sort_key>
		<display_label>Article No.</display_label>
		<display_no>43</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[The state of aesthetic computing or info-aesthetics]]></title>
		<subtitle><![CDATA[curated panel discussion]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667312</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667312</url>
		<abstract>
			<par><![CDATA[<p>Aesthetic computing is one of several related new fields: info-aesthetics, database aesthetics, network aesthetics, and software aesthetics. What are their similarities and differences? What are the aesthetic issues driving them, and how are they linked to technological developments? And what exactly is the role of aesthetics is this context?</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797301</person_id>
				<author_profile_id><![CDATA[81539282256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kelly]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Charlotte]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797302</person_id>
				<author_profile_id><![CDATA[81100421713]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Victoria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vesna]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797303</person_id>
				<author_profile_id><![CDATA[81327488439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fishwick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797304</person_id>
				<author_profile_id><![CDATA[81100050103]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[Vande]]></middle_name>
				<last_name><![CDATA[Moere]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Sydney]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1797305</person_id>
				<author_profile_id><![CDATA[81100516620]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Kenneth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Savannah College of Art and Design]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Curated Panel Discussion: The State of Aesthetic Computing or Info-Aesthetics Monday, August 3, 3:45-5:30pm 
panel Michael Kelly University of North Carolina at Charlotte mjkelly1@uncc.edu Victoria Vesna University 
of California, Los Angeles Paul Fishwick University of Florida Andrew Vande Moere University of Sydney 
Kenneth Huff Savannah College of Art and Design  Aesthetic computing is one of several related new 
fields: info-aesthetics, database aesthetics, network aesthetics, and software aesthetics. What are their 
similarities and differences? What are the aesthetic issues driving them, and how are they linked to 
technological developments? And what exactly is the role of aesthetics is this context? In Paul Fishwick 
s anthology, Aesthetic Computing, Roger Malina outlines two claims about aesthetic computing (art and 
aesthetics applied to computing, not the other direction): The weak claim is that by stimulating the 
flow of ideas and methods from the arts to computing, computer scientists and engineers will achieve 
their objectives more easily, quickly, or elegantly. The strong claim is that by introducing ideas and 
methods from art and design into computing, new practices and approaches will emerge, responding to new 
objectives that would not naturally have evolved within the computing sciences and engineering. In defense 
of the strong claim, we will argue that aesthetic computing is not merely about symmetry, elegance, optimality, 
and other properties that enhance the usability of computing artifacts. Rather, aesthetic computing is 
critical thinking about the cognitive and affective interactions between humans and computers where these 
interactions are not only between humans and computers but among humans and are occasioned by some form 
of visualization (scientific, data, or knowledge visualization, game theory, or the like). How are we 
to identify and understand the aesthetic dimensions of these interactions, especially in relation to 
the technical, ethical, and political values embedded in them? Who gets to make decisions about, and 
is thus responsible for, these interactions? The answers involve good design, but lead back to earlier 
computational decisions constraining and enabling design, and forward to issues of the social-political 
impact of these decisions. In addressing these questions, we also want to clarify how aesthetic computing 
relates to info-aesthetics (the symbiotic relationship between creative design and information visualization 
-Lev Manovich), database aesthetics (the backbone of databases driving the aesthetic of projects - Victoria 
Vesna), and network aesthetics (the production of connections between people and data - Warren Sack). 
This Panel is supported by a kiosk in the Information Aesthetics Gallery, which includes The Sky Oracle 
and The Katrina Project: NO-LA.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1667313</article_id>
		<sort_key>480</sort_key>
		<display_label>Article No.</display_label>
		<display_no>44</display_no>
		<article_publication_date>08-03-2009</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Information aesthetics: designing interactions]]></title>
		<subtitle><![CDATA[juried panel]]></subtitle>
		<page_from>1</page_from>
		<page_to>1</page_to>
		<doi_number>10.1145/1667265.1667313</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1667313</url>
		<categories>
			<primary_category>
				<cat_node>I.3.6</cat_node>
				<descriptor>Interaction techniques</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.3.0</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10010391</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Graphics input devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1797306</person_id>
				<author_profile_id><![CDATA[81458654198]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nicole]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coleman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Stanford University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Juried Panel: Information Aesthetics: Designing Interactions Monday, August 3, 8:30-10:15am Auditorium 
B session chair Nicole Coleman Stanford University  well-formed.eigenfactor: Considerations in Design 
and Data Analysis This talk discusses the rationale, process, and mechanisms behind the interactive visualizations 
for the well-formed.eigenfactor project. Moritz Stefaner Fachhochschule Potsdam Martin Rosvall Carl Bergstrom 
University of Washington, Seattle Synchronous Objects for One Flat Thing, reproduced Synchronous Objects 
is an interactive screen­based work that illuminates, reinterprets, and transforms the choreographic 
structures in William Forsythe s dance One Flat Thing, reproduced through a vivid collection of information 
objects designed by a team of multidisciplinary researchers at The Ohio State University. Maria Palazzi 
Norah Zuniga Shaw The Ohio State University GreenLite Dartmouth: Unplug or the Polar Bear Gets It GreenLite 
Dartmouth visualizes complex, real-time energy data using interactive animations to create an emotional 
relationship between energy use and its effects. When electricity use is low, for example, a polar bear 
is happy and playful. As more energy is used, the bear becomes distressed, and his well-being is endangered. 
Evan Tice Giulia Siccardo Tim Tregubov Jessica Glago Kate Schnippering Stephanie Trudeau Yoon-Ki Park 
Daniel Gobaud Ray diCiaccio Daniel Garcia Max Friedman Craig Slagel Jennifer Huang Lorie Loeb Justin 
Slick Dartmouth College  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2009</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
</content>
</proceeding>
